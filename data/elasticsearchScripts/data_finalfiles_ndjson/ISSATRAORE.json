{"title": "A new biometric technology based on mouse dynamics\n", "abstract": " In this paper, we introduce a new form of behavioral biometrics based on mouse dynamics, which can be used in different security applications. We develop a technique that can be used to model the behavioral characteristics from the captured data using artificial neural networks. In addition, we present an architecture and implementation for the detector, which cover all the phases of the biometric data flow including the detection process. Experimental data illustrating the experiments conducted to evaluate the accuracy of the proposed detection technique are presented and analyzed. Specifically, three series of experiments are conducted. The main experiment, in which 22 participants are involved, reproduces real operating conditions in computing systems by giving participants an individual choice of operating environments and applications; 284 hours of raw mouse data are collected over 998 sessions, with an\u00a0\u2026", "num_citations": "429\n", "authors": ["348"]}
{"title": "Botnet detection based on traffic behavior analysis and flow intervals\n", "abstract": " Botnets represent one of the most serious cybersecurity threats faced by organizations today. Botnets have been used as the main vector in carrying many cyber crimes reported in the recent news. While a significant amount of research has been accomplished on botnet analysis and detection, several challenges remain unaddressed, such as the ability to design detectors which can cope with new forms of botnets. In this paper, we propose a new approach to detect botnet activity based on traffic behavior analysis by classifying network traffic behavior using machine learning. Traffic behavior analysis methods do not depend on the packets payload, which means that they can work with encrypted network communication protocols. Network traffic information can usually be easily retrieved from various network devices without affecting significantly network performance or service availability. We study the feasibility of\u00a0\u2026", "num_citations": "359\n", "authors": ["348"]}
{"title": "Detecting P2P botnets through network behavior analysis and machine learning\n", "abstract": " Botnets have become one of the major threats on the Internet for serving as a vector for carrying attacks against organizations and committing cybercrimes. They are used to generate spam, carry out DDOS attacks and click-fraud, and steal sensitive information. In this paper, we propose a new approach for characterizing and detecting botnets using network traffic behaviors. Our approach focuses on detecting the bots before they launch their attack. We focus in this paper on detecting P2P bots, which represent the newest and most challenging types of botnets currently available. We study the ability of five different commonly used machine learning techniques to meet online botnet detection requirements, namely adaptability, novelty detection, and early detection. The results of our experimental evaluation based on existing datasets show that it is possible to detect effectively botnets during the botnet Command-and\u00a0\u2026", "num_citations": "304\n", "authors": ["348"]}
{"title": "Detection of online fake news using n-gram analysis and machine learning techniques\n", "abstract": " Fake news is a phenomenon which is having a significant impact on our social life, in particular in the political world. Fake news detection is an emerging research area which is gaining interest but involved some challenges due to the limited amount of resources (i.e., datasets, published literature) available. We propose in this paper, a fake news detection model that use n-gram analysis and machine learning techniques. We investigate and compare two different features extraction techniques and six different machine classification techniques. Experimental evaluation yields the best performance using Term Frequency-Inverted Document Frequency (TF-IDF) as feature extraction technique, and Linear Support Vector Machine (LSVM) as a classifier, with an accuracy of 92%.", "num_citations": "222\n", "authors": ["348"]}
{"title": "Detecting new forms of network intrusion using genetic programming\n", "abstract": " How to find and detect novel or unknown network attacks is one of the most important objectives in current intrusion detection systems. In this paper, a rule evolution approach based on Genetic Programming (GP) for detecting novel attacks on networks is presented and four genetic operators, namely reproduction, mutation, crossover, and dropping condition operators, are used to evolve new rules. New rules are used to detect novel or known network attacks. A training and testing dataset proposed by DARPA is used to evolve and evaluate these new rules. The proof of concept implementation shows that a rule generated by GP has a low false positive rate (FPR), a low false negative rate and a high rate of detecting unknown attacks. Moreover, the rule base composed of new rules has high detection rate with low FPR. An alternative to the DARPA evaluation approach is also investigated.", "num_citations": "219\n", "authors": ["348"]}
{"title": "System and method for determining a computer user profile from a motion-based input device\n", "abstract": " The present invention provides a system and methods for computer user profiling based on behavioral biometrics. The approach consists of establishing distinctive profiles for computer users based on how they use a motion-based input device such as, but not limited to, a mouse and/or a keyboard. The profiles computed in the present invention are more accurate than those obtained through the traditional statistical profiling techniques, since they are based on distinctive biological characteristics of users.", "num_citations": "188\n", "authors": ["348"]}
{"title": "Anomaly intrusion detection based on biometrics\n", "abstract": " In this work we introduce the idea of using behavioral biometrics in intrusion detection applications. We propose a new approach to user profiling, which can be used to detect intrusion without the need for any special hardware implementation and without forcing the user to perform any special actions. The technique is based on using \"keystroke dynamics\" and \"mouse dynamics\" biometrics. The profiles computed in this case are more accurate than those obtained through the traditional statistical profiling techniques, since they are based on distinctive biological characteristics of users.", "num_citations": "148\n", "authors": ["348"]}
{"title": "Biometric recognition based on free-text keystroke dynamics\n", "abstract": " Accurate recognition of free text keystroke dynamics is challenging due to the unstructured and sparse nature of the data and its underlying variability. As a result, most of the approaches published in the literature on free text recognition, except for one recent one, have reported extremely high error rates. In this paper, we present a new approach for the free text analysis of keystrokes that combines monograph and digraph analysis, and uses a neural network to predict missing digraphs based on the relation between the monitored keystrokes. Our proposed approach achieves an accuracy level comparable to the best results obtained through related techniques in the literature, while achieving a far lower processing time. Experimental evaluation involving 53 users in a heterogeneous environment yields a false acceptance ratio (FAR) of 0.0152% and a false rejection ratio (FRR) of 4.82%, at an equal error rate (EER\u00a0\u2026", "num_citations": "145\n", "authors": ["348"]}
{"title": "Detecting opinion spams and fake news using text classification\n", "abstract": " In recent years, deceptive content such as fake news and fake reviews, also known as opinion spams, have increasingly become a dangerous prospect for online users. Fake reviews have affected consumers and stores alike. Furthermore, the problem of fake news has gained attention in 2016, especially in the aftermath of the last U.S. presidential elections. Fake reviews and fake news are a closely related phenomenon as both consist of writing and spreading false information or beliefs. The opinion spam problem was formulated for the first time a few years ago, but it has quickly become a growing research area due to the abundance of user\u2010generated content. It is now easy for anyone to either write fake reviews or write fake news on the web. The biggest challenge is the lack of an efficient way to tell the difference between a real review and a fake one; even humans are often unable to tell the difference. In this\u00a0\u2026", "num_citations": "132\n", "authors": ["348"]}
{"title": "Authorship verification for short messages using stylometry\n", "abstract": " Authorship verification can be checked using stylometric techniques through the analysis of linguistic styles and writing characteristics of the authors. Stylometry is a behavioral feature that a person exhibits during writing and can be extracted and used potentially to check the identity of the author of online documents. Although stylometric techniques can achieve high accuracy rates for long documents, it is still challenging to identify an author for short documents, in particular when dealing with large authors populations. These hurdles must be addressed for stylometry to be usable in checking authorship of online messages such as emails, text messages, or twitter feeds. In this paper, we pose some steps toward achieving that goal by proposing a supervised learning technique combined with n-gram analysis for authorship verification in short texts. Experimental evaluation based on the Enron email dataset\u00a0\u2026", "num_citations": "127\n", "authors": ["348"]}
{"title": "Improving mouse dynamics biometric performance using variance reduction via extractors with separate features\n", "abstract": " The European standard for access control imposes stringent performance requirements on commercial biometric technologies that few existing recognition systems are able to meet. In this correspondence paper, we present the first mouse dynamics biometric recognition system that fulfills this standard. The proposed system achieves notable performance improvement by developing separate models for separate feature groups involved. The improvements are achieved through the use of a fuzzy classification based on the Learning Algorithm for Multivariate Data Analysis and using a score-level fusion scheme to merge corresponding biometric scores. Evaluation of the proposed framework using mouse data from 48 users achieves a false acceptance rate of 0% and a false rejection rate of 0.36%.", "num_citations": "95\n", "authors": ["348"]}
{"title": "The proactive and reactive digital forensics investigation process: A systematic literature review\n", "abstract": " Recent papers have urged the need for new forensic techniques and tools able to investigate anti-forensics methods, and have promoted automation of live investigation. Such techniques and tools are called proactive forensic approaches, i.e., approaches that can deal with digitally investigating an incident while it occurs. To come up with such an approach, a Systematic Literature Review (SLR) was undertaken to identify and map the processes in digital forensics investigation that exist in literature. According to the review, there is only one process that explicitly supports proactive forensics, the multicomponent process [1]. However, this is a very high-level process and cannot be used to introduce automation and to build a proactive forensics system. As a result of our SLR, a derived functional process that can support the implementation of a proactive forensics system is proposed.", "num_citations": "88\n", "authors": ["348"]}
{"title": "Biometric authentication using mouse gesture dynamics\n", "abstract": " The mouse dynamics biometric is a behavioral biometric technology that extracts and analyzes the movement characteristics of the mouse input device when a computer user interacts with a graphical user interface for identification purposes. Most of the existing studies on mouse dynamics analysis have targeted primarily continuous authentication or user reauthentication for which promising results have been achieved. Static authentication (at login time) using mouse dynamics, however, appears to face some challenges due to the limited amount of data that can reasonably be captured during such a process. In this paper, we present a new mouse dynamics analysis framework that uses mouse gesture dynamics for static authentication. The captured gestures are analyzed using a learning vector quantization neural network classifier. We conduct an experimental evaluation of our framework with 39 users, in\u00a0\u2026", "num_citations": "83\n", "authors": ["348"]}
{"title": "Continuous authentication using biometrics: data, models, and metrics: data, models, and metrics\n", "abstract": " User authentication is the process of verifying whether the identity of a user is genuine prior to granting him or her access to resources or services in a secured environment. Traditionally, user authentication is performed statically at the point of entry of the system; however, continuous authentication (CA) seeks to address the shortcomings of this method by providing increased session security and combating insider threat. Continuous Authentication Using Biometrics: Data, Models, and Metrics presents chapters on continuous authentication using biometrics that have been contributed by the leading experts in this recent, fast growing research area. These chapters collectively provide a thorough and concise introduction to the field of biometric-based continuous authentication. The book covers the conceptual framework underlying continuous authentication and presents detailed processing models for various types of practical continuous authentication applications.", "num_citations": "81\n", "authors": ["348"]}
{"title": "Detecting Computer Intrusions Using Behavioral Biometrics.\n", "abstract": " In this paper we introduce the idea of using behavioral biometrics in intrusion detection applications. We present a new biometrics-based technique, which can be used to detect intrusion without the need for any special hardware implementation and without forcing the user to perform any special actions. The technique is based on using \u201ckeystroke dynamics\u201d and \u201cmouse dynamics\u201d biometrics. We discuss the efficiency and applicability of such an approach.", "num_citations": "80\n", "authors": ["348"]}
{"title": "Combining mouse and keystroke dynamics biometrics for risk-based authentication in web environments\n", "abstract": " Existing risk-based authentication systems rely on basic web communication information such as the source IP address or the velocity of transactions performed by a specific account, or originating from a certain IP address. Such information can easily be spoofed, and as such, put in question the robustness and reliability of the proposed systems. In this paper, we propose a new online risk-based authentication system that provides more robust user identity information by combining mouse dynamics and keystroke dynamics biometrics in a multimodal framework. Experimental evaluation of our proposed model with 24 participants yields an Equal Error Rate of 8.21%, which is promising considering that we are dealing with free text and free mouse movements, and the fact that many web sessions tend to be very short.", "num_citations": "79\n", "authors": ["348"]}
{"title": "Peer to peer botnet detection based on flow intervals\n", "abstract": " Botnets are becoming the predominant threat on the Internet today and is the primary vector for carrying out attacks against organizations and individuals. Botnets have been used in a variety of cybercrime, from click-fraud to DDOS attacks to the generation of spam. In this paper we propose an approach to detect botnet activity by classifying network traffic behavior using machine learning classification techniques. We study the feasibility of detecting botnet activity without having seen a complete network flow by classifying behavior based on time intervals and we examine the performance of two popular classification techniques with respect to this data. Using existing datasets, we show experimentally that it is possible to identify the presence of botnet activity with high accuracy even with very small time windows, though there are some limitations to the approach based on the selection of attributes.", "num_citations": "79\n", "authors": ["348"]}
{"title": "A framework for metamorphic malware analysis and real-time detection\n", "abstract": " Metamorphism is a technique that mutates the binary code using different obfuscations. It is difficult to write a new metamorphic malware and in general malware writers reuse old malware. To hide detection the malware writers change the obfuscations (syntax) more than the behavior (semantic) of such a new malware. On this assumption and motivation, this paper presents a new framework named MARD for Metamorphic Malware Analysis and Real-Time Detection. As part of the new framework, to build a behavioral signature and detect metamorphic malware in real-time, we propose two novel techniques, named ACFG (Annotated Control Flow Graph) and SWOD-CFWeight (Sliding Window of Difference and Control Flow Weight). Unlike other techniques, ACFG provides a faster matching of CFGs, without compromising detection accuracy; it can handle malware with smaller CFGs, and contains more information\u00a0\u2026", "num_citations": "69\n", "authors": ["348"]}
{"title": "Authorship verification of e-mail and tweet messages applied for continuous authentication\n", "abstract": " Authorship verification using stylometry consists of identifying a user based on his writing style. In this paper, authorship verification is applied for continuous authentication using unstructured online text-based entry. An online document is decomposed into consecutive blocks of short texts over which (continuous) authentication decisions happen, discriminating between legitimate and impostor behaviors. We investigate blocks of texts with 140, 280 and 500 characters. The feature set includes traditional features such as lexical, syntactic, application specific features, and new features extracted from n-gram analysis. Furthermore, the proposed approach includes a strategy to circumvent issues related to unbalanced dataset, and uses Information Gain and Mutual Information as a feature selection strategy and Support Vector Machine (SVM) for classification. Experimental evaluation of the proposed approach based\u00a0\u2026", "num_citations": "63\n", "authors": ["348"]}
{"title": "Authorship verification using deep belief network systems\n", "abstract": " This paper explores the use of deep belief networks for authorship verification model applicable for continuous authentication (CA). The proposed approach uses Gaussian units in the visible layer to model real\u2010valued data on the basis of a Gaussian\u2010Bernoulli deep belief network. The lexical, syntactic, and application\u2010specific features are explored, leading to the proposal of a method to merge a pair of features into a single one. The CA is simulated by decomposing an online document into a sequence of short texts over which the CA decisions happen. The experimental evaluation of the proposed method uses block sizes of 140, 280, 500 characters, on the basis of the Twitter and Enron e\u2010mail corpuses. Promising results are obtained, which consist of an equal error rate varying from 8.21% to 16.73%. Using relatively smaller forgery samples, an equal error rate varying from 5.48% to 12.3% is also obtained for\u00a0\u2026", "num_citations": "57\n", "authors": ["348"]}
{"title": "Biometric-based physical and cybersecurity systems\n", "abstract": " Biometrics represents one of the most robust and reliable forms of human identification in physical and cyber security. The last decade has witnessed tremendous advances in sensor technologies and data processing techniques and algorithms. This has led to the strengthening of traditional biometrics technologies (eg, fingerprint, face, iris, retina, keystroke dynamics, and voice) and the emergence of several new technologies, which are showing great promises. The confiuence of the consumer markets and national security needs have led to a growing demand for biometrics products and services. For instance, the integration of biometric sensors in smartphones and the use of these technologies for online banking have boosted the adoption of biometric technologies for the masses. Biometrics carries a strong ability to establish whether an individual is genuine or an impostor. Such an ability to reliably identify\u00a0\u2026", "num_citations": "55\n", "authors": ["348"]}
{"title": "An outline of PVS semantics for UML statecharts\n", "abstract": " The current UML standard provides definitions for the semantics of its components. These definitions focus mainly on the static structure of UML, but they don't include an execution semantics. These definitions include several\" semantic variation points\" leaving out the door open for multiple interpretations of the concepts involved. This situation can be handled by formalizing the semantic concepts involved. In this paper we present an approach for the formalization of one of the multiple diagrams of UML, namely statechart diagrams. That is achieved by using the PVS Specification Language as formal semantics domain. We present also how the approach can be used to conduct a formal analysis using the PVS modelchecker.", "num_citations": "46\n", "authors": ["348"]}
{"title": "MAIL: Malware Analysis Intermediate Language: a step towards automating and optimizing malware detection\n", "abstract": " Dynamic binary obfuscation or metamorphism is a technique where a malware never keeps the same sequence of opcodes in the memory. Such malware are very difficult to analyse and detect manually even with the help of tools. We need to automate the analysis and detection process of such malware. This paper introduces and presents a new language named MAIL (Malware Analysis Intermediate Language) to automate and optimize this process. MAIL also provides portability for building malware analysis and detection tools. Each MAIL statement is assigned a pattern that can be used to annotate a control flow graph for pattern matching to analyse and detect metamorphic malware. Experimental evaluation of the proposed approach using an existing dataset yields malware detection rate of 93.92% and false positive rate of 3.02%.", "num_citations": "45\n", "authors": ["348"]}
{"title": "Secure mutual authentication and automated access control for IoT smart home using cumulative keyed-hash chain\n", "abstract": " IoT platforms face huge challenge in deploying robust authentication mechanisms due to the fact that edge devices and resource-constrained devices may not have enough compute and storage capability to deploy and run existing mechanisms, which involve in general complex computations. In this paper, we propose a secure lightweight mutual authentication and key exchange protocol for IoT smart home environment based on temporary identity and cumulative Keyed-hash chain. Nodes can anonymously authenticate and establish session with the controller node using dynamic identities and symmetric keys in an unlinkable manner. Moreover, the enforcement of security policy between nodes is ensured by setting up a virtual domain segregation and restricting nodes capabilities of sending and receiving instructions and commands to or from other nodes. Cumulative Keyed-hash chain mechanism is\u00a0\u2026", "num_citations": "43\n", "authors": ["348"]}
{"title": "A new method for learning decision trees from rules\n", "abstract": " Most of the methods that generate decision trees use examples of data instances in the decision tree generation process. This paper proposes a method called \"RBDT-1\"- rule based decision tree - for learning a decision tree from a set of decision rules that cover the data instances rather than from the data instances themselves. RBDT-1 method uses a set of declarative rules as an input for generating a decision tree. The method's goal is to create on-demand a short and accurate decision tree from a stable or dynamically changing set of rules. We conduct a comparative study of RBDT-1 with three existing decision tree methods based on different problems. The outcome of the study shows that RBDT-1 performs better than AQDT-1 and AQDT-2 which are methods that create decision trees from rules and than ID3 which generates decision trees from data examples, in terms of tree complexity number of nodes and\u00a0\u2026", "num_citations": "42\n", "authors": ["348"]}
{"title": "Intrusion detector based on mouse dynamics analysis\n", "abstract": " A biometric intrusion detection system based on mouse dynamics analysis, the analysis of mouse dynamics for a specific user generates a number of factors (Mouse Dynamics Signature) which can be used to ensure the identity of the user, an intelligent detection technique is developed to recognize differences in behaviors and detect intrusion.", "num_citations": "40\n", "authors": ["348"]}
{"title": "Annotated control flow graph for metamorphic malware detection\n", "abstract": " Metamorphism is a technique that mutates the binary code using different obfuscations and never keeps the same sequence of opcodes in the memory. This stealth technique provides the capability to a malware for evading detection by simple signature-based (such as instruction sequences, byte sequences and string signatures) anti-malware programs. In this paper, we present a new scheme named Annotated Control Flow Graph (ACFG) to efficiently detect such kinds of malware. ACFG is built by annotating CFG of a binary program and is used for graph and pattern matching to analyse and detect metamorphic malware. We also optimize the runtime of malware detection through parallelization and ACFG reduction, maintaining the same accuracy (without ACFG reduction) for malware detection. ACFG proposed in this paper: (i) captures the control flow semantics of a program; (ii) provides a faster matching of\u00a0\u2026", "num_citations": "38\n", "authors": ["348"]}
{"title": "Improving performance and usability in mobile keystroke dynamic biometric authentication\n", "abstract": " In the last few years, the number of mobile devices such as smartphones and tablets, in circulation, has increased dramatically. The primary and often only protection mechanism in these devices is authentication using a password or a Personal Identification Number (PIN). Passwords are notoriously known to be a weak authentication mechanism, no matter how complex the underlying format is. A more secure alternative option which has gained interest recently is extracting keystroke dynamic biometrics from supplied passwords for mobile authentication. In this paper, we show that using random forests classifier, improved accuracy performance can be achieved for mobile keystroke dynamic biometric authentication. We also propose a new algorithm for handling typos, which is an essential step in improving usability. We study both timing features and pressure-based features. Experimental evaluation is based on\u00a0\u2026", "num_citations": "36\n", "authors": ["348"]}
{"title": "Method ontology for intelligent network forensics analysis\n", "abstract": " Network forensics is an after the fact process to investigate malicious activities conducted over computer networks by gathering useful intelligence. Recently, several machine learning techniques have been proposed to automate and develop intelligent network forensics systems. An intelligent network forensics system that reconstructs intrusion scenarios and makes attack attributions requires knowledge about intrusions signatures, evidences, impacts, and objectives. In addition, problem solving knowledge that describes how the system can use domain knowledge to analyze malicious activities is essential for the design of intelligent network forensics systems. In this paper we adapt recent researches in semantic-web, information architecture, and ontology engineering to design a method ontology for network forensics analysis. The proposed ontology represents both network forensics domain knowledge and\u00a0\u2026", "num_citations": "36\n", "authors": ["348"]}
{"title": "Toward a framework for continuous authentication using stylometry\n", "abstract": " Continuous Authentication (CA) consists of monitoring and checking repeatedly and unobtrusively user behavior during a computing session in order to discriminate between legitimate and impostor behaviors. Stylometry analysis, which consists of checking whether a target document was written or not by a specific individual, could potentially be used for CA. In this work, we adapt existing stylometric features and develop a new authorship verification model applicable for continuous authentication. We use existing lexical, syntactic, and application specific features, and propose new features based on n-gram analysis. We start initially with a large features set, and identify a reduced number of user-specific features by computing the information gain. In addition, our approach includes a strategy to circumvent issues regarding unbalanced dataset which is an inherent problem in stylometry analysis. We use Support\u00a0\u2026", "num_citations": "33\n", "authors": ["348"]}
{"title": "Experience with engineering a network forensics system\n", "abstract": " Network Forensics is an important extension to the model of network security where emphasis is traditionally put on prevention and to a lesser extent on detection. It focuses on the capture, recording, and analysis of network packets and events for investigative purposes. It is a young field for which very limited resources are available. In this paper, we briefly survey the state of the art in network forensics and report our experience with building and testing a network forensics system.", "num_citations": "33\n", "authors": ["348"]}
{"title": "Enhancing structured review with model-based verification\n", "abstract": " We propose a development framework that extends the scope of structured review by supplementing the structured review with model-based verification. The proposed approach uses the Unified Modeling Language (UML) as a modeling notation. We discuss a set of correctness arguments that can be used in conjunction with formal verification and validation (V&V) in order to improve the quality and dependability of systems in a cost-effective way. Formal methods can be esoteric; consequently, their large scale application is hindered. We propose a framework based on the integration of lightweight formal methods and structured reviews. Moreover, we show that structured reviews enable us to handle aspects of V&V that cannot be fully automated. To demonstrate the feasibility of our approach, we have conducted a study on a security-critical system - a patient document service (PDS) system.", "num_citations": "33\n", "authors": ["348"]}
{"title": "Queue-based analysis of DoS attacks\n", "abstract": " Computer security is very important for any organization that maintains sensitive assets electronically. This is stressed in the statistics collected by the Computer Security Institute and FBI through their annual surveys. Hence, DoS is a very important problem that needs to be dealt with seriously. DoS attacks are of two types: flooding attacks and logic attacks. When an attack has impact on a system parameter, then the parameter can be used as an attack detection metric. In this paper, we qualitatively and quantitatively analyze the impact of DoS attacks on three simple system parameters - request arrival rate, queue-growth-rate, and response time. The importance of this analysis lies in the fact that we don't need to observe the system for a long time to understand the comparative system degradations that may happen under certain types of attacks.", "num_citations": "32\n", "authors": ["348"]}
{"title": "MARD: A framework for metamorphic malware analysis and real-time detection\n", "abstract": " Because of the financial and other gains attached with the growing malware industry, there is a need to automate the process of malware analysis and provide real-time malware detection. To hide a malware, obfuscation techniques are used. One such technique is metamorphism encoding that mutates the dynamic binary code and changes the opcode with every run to avoid detection. This makes malware difficult to detect in real-time and generally requires a behavioral signature for detection. In this paper we present a new framework called MARD for Metamorphic Malware Analysis and Real-Time Detection, to protect the end points that are often the last defense, against metamorphic malware. MARD provides: (1) automation (2) platform independence (3) optimizations for real-time performance and (4) modularity. We also present a comparison of MARD with other such recent efforts. Experimental evaluation of\u00a0\u2026", "num_citations": "31\n", "authors": ["348"]}
{"title": "Empirical relation between coupling and attackability in software systems: a case study on DOS\n", "abstract": " Over the last decades, software quality attributes such as maintainability, reliability, and understandability have been widely studied. In contrast, less attention has been paid to the field of software security. Attackability is a concept proposed recently in the research literature t to measure the extent that a software system or service could be the target of successful attacks. Like most external attributes, attackability is to some extent disconnected from the internal of software products. To improve the quality of software products we need to be able to affect its internal features. So, for attackability measures to be useful for software products enhancement, we need to identify related internal software attributes. We study in this paper the empirical relationship between attackability as an external software quality attribute with coupling as an internal software attribute. Specifically, we use a case study based on denial of\u00a0\u2026", "num_citations": "31\n", "authors": ["348"]}
{"title": "Digital Fingerprinting Based on Keystroke Dynamics.\n", "abstract": " Digital fingerprinting is an important but still challenging aspect of network forensics. This paper introduces an effective way to identify an attacker based on a strong behavioral biometric. We introduce a new passive digital fingerprinting technique based on keystroke dynamics biometrics. The technique is based on free text detection and analysis of keystroke dynamics. It allows building a behavioral model from passively collected data, and identifying users based on a very minimal amount of data.", "num_citations": "30\n", "authors": ["348"]}
{"title": "A new unsupervised anomaly detection framework for detecting network attacks in real-time\n", "abstract": " In this paper, we propose a new unsupervised anomaly detection framework for detecting network intrusions online. The framework consists of new anomalousness metrics named IP Weight and an outlier detection algorithm based on Gaussian mixture model (GMM). IP Weights convert the features of IP packets into a four-dimensional numerical feature space, in which the outlier detection takes place. Intrusion decisions are made based on the outcome of outlier detections. Two sets of experiments are conducted to evaluate our framework. In the first experiment, we conduct an offline evaluation based on the 1998 DARPA intrusion detection dataset, which detects 16 types of attacks out of a total of 19 network attack types. In the second experiment, an online evaluation is performed in a live networking environment. The evaluation result not only confirms the detection effectiveness with DARPA dataset, but\u00a0\u2026", "num_citations": "30\n", "authors": ["348"]}
{"title": "Ensuring online exam integrity through continuous biometric authentication\n", "abstract": " A key challenge in online education is the difficulty in ensuring the authenticity of remote test takers during online exams. This chapter discusses how such challenge can be addressed through continuous authentication using biometric technologies. A multimodal biometric framework involving three modalities is used for such purpose. The framework involves mouse dynamics, keystroke dynamics, and face biometrics. An overview of the ExamShield Virtual Online Exam Center that uses the multimodal framework for test taker authentication is given.", "num_citations": "29\n", "authors": ["348"]}
{"title": "Sliding window and control flow weight for metamorphic malware detection\n", "abstract": " The latest stealth techniques, such as metamorphism, allow malware to evade detection by today\u2019s signature-based anti-malware programs. Current techniques for detecting malware are compute intensive and unsuitable for real-time detection. Techniques based on opcode patterns have the potential to be used for real-time malware detection, but have the following issues: (1) The frequencies of opcodes can change by using different compilers, compiler optimizations and operating systems. (2) Obfuscations introduced by polymorphic and metamorphic malware can change the opcode distributions. (3) Selecting too many features (patterns) results in a high detection rate but also increases the runtime and vice versa. In this paper we present a novel technique named SWOD-CFWeight (Sliding Window of Difference and Control Flow Weight) that helps mitigate these effects and provides a solution to these\u00a0\u2026", "num_citations": "27\n", "authors": ["348"]}
{"title": "Online risk-based authentication using behavioral biometrics\n", "abstract": " In digital home networks, it is expected that independent smart devices communicate and cooperate with each other, without the knowledge of the fundamental communication technology, on the basis of a distributed operating system paradigm. In such context, securing the access rights to some objects such as data, apparatus, and contents, is still a challenge. This paper introduces a risk-based authentication technique based on behavioral biometrics as solution approach to tackle this challenge. Risk-based authentication is an increasingly popular component in the security architecture deployed by many organizations to mitigate online identity fraud. Risk-based authentication uses contextual and historical information extracted from online communications to build a risk profile for the user that can be used accordingly to make authentication and authorization decisions. Existing risk-based authentication\u00a0\u2026", "num_citations": "27\n", "authors": ["348"]}
{"title": "Inverse biometrics for mouse dynamics\n", "abstract": " Various techniques have been proposed in different literature to analyze biometric samples collected from individuals. However, not a lot of attention has been paid to the inverse problem, which consists of synthesizing artificial biometric samples that can be used for testing existing biometric systems or protecting them against forgeries. In this paper, we present a framework for mouse dynamics biometrics synthesis. Mouse dynamics biometric is a behavioral biometric technology, which allows user recognition based on the actions received from the mouse input device while interacting with a graphical user interface. The proposed inverse biometric model learns from random raw samples collected from real users and then creates synthetic mouse actions for fake users. The generated mouse actions have unique behavioral properties separate from the real mouse actions. This is shown through various comparisons\u00a0\u2026", "num_citations": "26\n", "authors": ["348"]}
{"title": "Fluctuation effects in the pairing field of rapidly rotating nuclei\n", "abstract": " Dynamical effects in the pairing field of rapidly rotating nuclei are investigated using the RPA approach both in normal and superfluid systems. Corrections beyond the RPA are discussed in the framework of the nuclear field theory. The theory is illustrated by calculations performed for a two-level model which allows for an exact solution, and for the rotating harmonic oscillator model.", "num_citations": "26\n", "authors": ["348"]}
{"title": "Hypervisor-based cloud intrusion detection through online multivariate statistical change tracking\n", "abstract": " Cloud computing is facing a multidimensional and rapidly evolving threat landscape, making intrusion detection more challenging. This paper introduces a new hypervisor-based cloud intrusion detection system (IDS) that uses online multivariate statistical change analysis to detect anomalous network behaviors. As a departure from the conventional monolithic network IDS feature model, we leverage the fact that a hypervisor consists of a collection of instances, to introduce an instance-oriented feature model that exploits the individual and correlated behaviors of instances to improve the detection capability. The proposed approach is evaluated by collecting and using a new cloud intrusion dataset that includes a wide variety of attack vectors.", "num_citations": "25\n", "authors": ["348"]}
{"title": "Detecting broad length algorithmically generated domains\n", "abstract": " Domain generation algorithm (DGA) represents a safe haven for modern botnets, as it enables them to escape detection. Due to the fact that DGA domains are generated randomly, they tend to be unusually long, which can be leveraged toward detecting them. Shorter DGA domains, in contrast, are more difficult to detect, as most legitimate domains are relatively short. We introduce in this paper, a new detection model that uses information theoretic features, and leverage the notion of domain length threshold to detect dynamically and transparently DGA domains regardless of their lengths. Experimental evaluation of the approach using public datasets yields detection rate (DR) of 98.96% and false positive rate (FPR) of 2.1%, when using random forests classification technique.", "num_citations": "23\n", "authors": ["348"]}
{"title": "P2P botnet detection through malicious fast flux network identification\n", "abstract": " A recent development in botnet technology is the adoption of P2P architecture as way to improve botnet resilience to disruption compared to the centralized architecture used by early botnets. Furthermore, in order to increase stealth and evade detection, many P2P botnets, such as storm, are employing fast flux service networks (FFSNs). We propose in this paper, a new P2P botnet detection approach by identifying malicious FFSNs. We define and compute a number of metrics from captured network flows which are analyzed using machine learning classification. For the proposed approach, we show experimentally that the presence of botnets may be detected with a high accuracy and identify its potential limitations.", "num_citations": "23\n", "authors": ["348"]}
{"title": "Holistic model for http botnet detection based on dns traffic analysis\n", "abstract": " HTTP botnets are currently the most popular form of botnets compared to IRC and P2P botnets. This is because, they are not only easier to implement, operate, and maintain, but they can easily evade the detection. Likewise, HTTP botnets flows can easily be buried in the huge volume of legitimate HTTP traffic occurring in many organizations, which makes the detection harder. In this paper, a new detection framework involving three detection models is proposed, which can run independently or in tandem. The first detector profiles the individual applications based on their interactions, and isolates accordingly the malicious ones. The second detector tracks the regularity in the timing of the bot DNS queries, and uses this as basis for detection. The third detector analyzes the characteristics of the domain names involved in the DNS, and identifies the algorithmically generated and fast flux domains, which are\u00a0\u2026", "num_citations": "22\n", "authors": ["348"]}
{"title": "Unsupervised anomaly detection using an evolutionary extension of k-means algorithm\n", "abstract": " In this paper, we propose a new unsupervised anomaly detection framework for network intrusions. The framework consists of a new clustering algorithm named I-means and new anomalousness metrics named IP Weights. I-means is an evolutionary extension of k means algorithm that estimates automatically the number of clusters for a set of data. IP Weights allow the automatic conversion of regular packet features into a 3-dimensional numerical feature space. Online and offline evaluations show not only strong detection effectiveness, but also strong runtime efficiency, with response times falling within a few seconds ranges.", "num_citations": "22\n", "authors": ["348"]}
{"title": "Complexity measures for secure service-oriented software architectures\n", "abstract": " As software attacks become widespread, the ability for a software system to resist malicious attacks has become a key concern in software quality engineering. Software attack ability is a concept proposed recently in the research literature to measure the extent to which a software system or service could be the target of successful attacks. Like most external attributes, attack ability is to some extent disconnected from the internal of software products. To mitigate software attack ability, we need to identify and manipulate related internal software attributes. Our goal in this paper is to study software complexity as one such internal attribute. We apply the User System Interaction Effect (USIE) model, a security measurement abstraction paradigm proposed in previous research, to define and validate a sample metric for service complexity. We thereby establish the usefulness of our sample metric through empirical\u00a0\u2026", "num_citations": "22\n", "authors": ["348"]}
{"title": "Secure remote anonymous user authentication scheme for smart home environment\n", "abstract": " Smart home technology is an emerging application of Internet-of-Things (IoT) where the user can remotely control home devices. Since the user/home communication channel is insecure, an efficient and anonymous authentication scheme is required to provide secure communications in smart home environment. In this paper, we propose a new scheme for user authentication that combines physical context awareness and transaction history. The new scheme offers two advantages: it does not maintain a verification table and avoids clock synchronization problem. Communication overhead and computational cost of the proposed scheme are analyzed and compared with other related schemes. The security of the scheme is evaluated using three different methods: (1) formal analysis using the Burrows-Abadi-Needham logic (BAN); (2) informal analysis; (3) model check using the automated validation of internet\u00a0\u2026", "num_citations": "20\n", "authors": ["348"]}
{"title": "In-cloud malware analysis and detection: State of the art\n", "abstract": " With the advent of Internet of Things, we are facing another wave of malware attacks, that encompass intelligent embedded devices. Because of the limited energy resources, running a complete malware detector on these devices is quite challenging. There is a need to devise new techniques to detect malware on these devices. Malware detection is one of the services that can be provided as an in-cloud service. This paper reviews current such systems, discusses there pros and cons, and recommends an improved in-cloud malware analysis and detection system. We introduce a new three layered hybrid system with a lightweight antimalware engine. These features can provide faster malware detection response time, shield the client from malware and reduce the bandwidth between the client and the cloud, compared to other such systems. The paper serves as a motivation for improving the current and\u00a0\u2026", "num_citations": "20\n", "authors": ["348"]}
{"title": "Analysis of covert hardware attacks\n", "abstract": " Current embedded system, such as cell phones and smart-cards, in corporate security devices or cryptographic processor. These cryptographic devices often store private keys or other sensitive data, so compromise of this data or the underlying hardware may lead to loss of privacy, forged access, or monetary theft. Even if the attackers fail to gain the secret information that is stored in a hardware, they may be able to disrupt the hardware or deny service leading to other kinds of security failures in the system. Therefore hardware attacks targets this security devices. Hardware attacks could be covert or overt based on awareness of the targeted system. This paper reviews proposed Accessibility/Resources/Time (ART) schema that quantifies hardware attacks. We focus in this paper on presenting covert attacks and quantify the attack using the ART schema.", "num_citations": "20\n", "authors": ["348"]}
{"title": "An unsupervised approach for detecting DDoS attacks based on traffic-based metrics\n", "abstract": " Recently, distributed denial of service (DDoS) attacks have been widely used to compromise computer systems and a lot of free DDoS attacking tools can be easily obtained from the public network. Although many mechanisms were suggested to prevent DDoS attacks, most of them lack in effectiveness and efficiency. Moreover, trace back and prevention for DDoS intrusions are almost impossible because of the distribution and large number of attacking hosts, and the difficulty of identifying their location due to source IP address spoofing. We define in this paper a new traffic-based metrics named IPTraffic by studying the basic principle of DDoS attacks. An outlier detection algorithm based on Gaussian mixture model (GMM) is used to analyze the value of IPTraffic, and then make intrusion decisions according to the outlier detection result. We evaluate our approach on a live networking environment and the\u00a0\u2026", "num_citations": "20\n", "authors": ["348"]}
{"title": "Machine Learning Techniques for Gait Biometric Recognition\n", "abstract": " The last two decades have seen a dramatic increase in the number of stakeholders of biometric technologies. The quality of the technologies has increased due to an improvement in underlying data processing and sensor technologies. A growing and healthy marketplace has emerged, while the number of people using, operating, or impacted by these technologies has been growing exponentially. Several new disruptive technologies have emerged, along with the diversification of the devices and platforms where biometrics are provisioned. The ubiquity of mobile phones and the multiplicity and diversity of sensors available for biometric provisioning (eg, webcam, fingerprint reader, touchscreen, accelerometer, gyroscope, etc.) is contributing significantly to this dramatic growth of the biometric ecosystem. Gait biometrics is one of the new technologies that have appeared in the past few decades. Gait biometric\u00a0\u2026", "num_citations": "19\n", "authors": ["348"]}
{"title": "Extracting attack scenarios using intrusion semantics\n", "abstract": " Building the attack scenario is the first step to understand an attack and extract useful attack intelligence. Existing attack scenario reconstruction approaches, however, suffer from several limitations that weaken the elicitation of the attack scenarios and decrease the quality of the generated attack scenarios. In this paper, we discuss the limitations of the existing attack scenario reconstruction approaches and propose a novel hybrid approach using semantic analysis and intrusion ontology. Our approach can reconstruct known and unknown attack scenarios and correlate alerts generated in multi-sensor IDS environment. Our experimental results show the potential of our approach and its advantages over previous approaches.", "num_citations": "19\n", "authors": ["348"]}
{"title": "Homogeneous physio-behavioral visual and mouse-based biometric\n", "abstract": " In this research, we propose a novel biometric system for static user authentication that homogeneously combines mouse dynamics, visual search capability and short-term memory effect. The proposed system introduces the visual search capability, and short-term memory effect to the biometric-based security world for the first time. The use of a computer mouse for its dynamics, and as an input sensor for the other two biometrics, means no additional hardware is required than the standard mouse. Experimental evaluation showed the system effectiveness using variable or one-time passwords. All of these attributes qualify the proposed system to be effectively deployed as a static authentication mechanism. Extensive experimentation was done using 2740 sessions collected from 274 users. To measure the performance, a computational statistics model was specially designed and used; a statistical classifier based\u00a0\u2026", "num_citations": "19\n", "authors": ["348"]}
{"title": "Distributed architectures for electronic cash schemes: a survey\n", "abstract": " The volume of E-commerce transactions has considerably increased in the last several years. One of the most important aspects of such progress is the efforts made to develop and deploy dependable and secure payment infrastructures. Among these infrastructures is electronic cash, which is an attempt to reproduce the characteristics of paper cash in online transactions. Electronic cash schemes have so far been the purpose of a significant amount of research work. Although real-life deployments of such schemes are expected to take place in highly distributed environments, limited attention has been paid in the literature on underlying architectural issues. So far the focus has mostly been on addressing only security issues. However, for real-life deployment, distributed processing criteria such as performance, scalability and availability are of prime importance. In this paper, through a survey of the literature, we\u00a0\u2026", "num_citations": "19\n", "authors": ["348"]}
{"title": "An integrated framework for formal development of open distributed systems\n", "abstract": " This paper contributes to the discussion on issues related to the formal development of open distributed systems (ODS). The deficiencies of traditional formal notations in this setting are highlighted. We argue that there is no single formalism exhibiting all the features required to capture properties of ODSs. As a solution, we propose an integrated development framework that involves two notations: the Unified Modeling Language (UML) and the Prototype Verification System (PVS). We discuss the motivation for the choice of these notations, provide an overview of a CASE tool we have developed to support the proposed framework, and present a case study to demonstrate our approach.", "num_citations": "19\n", "authors": ["348"]}
{"title": "Dynamic sample size detection in learning command line sequence for continuous authentication\n", "abstract": " Continuous authentication (CA) consists of authenticating the user repetitively throughout a session with the goal of detecting and protecting against session hijacking attacks. While the accuracy of the detector is central to the success of CA, the detection delay or length of an individual authentication period is important as well since it is a measure of the window of vulnerability of the system. However, high accuracy and small detection delay are conflicting requirements that need to be balanced for optimum detection. In this paper, we propose the use of sequential sampling technique to achieve optimum detection by trading off adequately between detection delay and accuracy in the CA process. We illustrate our approach through CA based on user command line sequence and na\u00efve Bayes classification scheme. Experimental evaluation using the Greenberg data set yields encouraging results consisting of a false\u00a0\u2026", "num_citations": "18\n", "authors": ["348"]}
{"title": "Double spending protection for e-cash based on risk management\n", "abstract": " Electronic cash is an attempt to replace and reproduce paper cash in electronic transactions that faces competing challenges when used either online or offline. In effect, while effective protection against double spending for e-cash can be achieved in online payment environments through real-time detection, this comes at the expense of efficiency, the bank representing in such case a performance bottleneck and single point of failure. In contrast, in offline payment environments, while efficiency is improved, double spending can be detected only after the fact, which can be very costly. We propose in this paper a risk management approach for double spending protection which allows suitable tradeoffs between efficiency and effectiveness. This involves using the service of a trader, who is a trusted third party that will cover the risk involved in offline payment transactions, against some remuneration. The main\u00a0\u2026", "num_citations": "18\n", "authors": ["348"]}
{"title": "The impact of google hacking on identity and application fraud\n", "abstract": " In the last several years, identity theft has been on the rise. The Internet represents an appealing place for fraudsters to collect a host of personal and financial data related to many innocent users. Using the collected data they can impersonate the users and commit different fraudulent activities including application fraud. Mining Internet data for fraudulent purposes is commonly referred to as (black hat) Google hacking. We discuss in this paper the impact of Google hacking on identity fraud, with an emphasis on fraudulent applications for identity certificates such as credit cards, passports, and so on. The discussion is based on the results of an experiment performed over the Internet by conducting some (white hat) Google hacking and collecting sensitive identity information for living as well as dead persons. We also outline the architecture of a security tool for detecting application fraud that is currently under\u00a0\u2026", "num_citations": "18\n", "authors": ["348"]}
{"title": "Determining the optimal number of clusters using a new evolutionary algorithm\n", "abstract": " Estimating the optimal number of clusters for a dataset is one of the most essential issues in cluster analysis. An improper preselection for the number of clusters might easily lead to bad clustering outcome. In this paper, we propose a new evolutionary algorithm to address this issue. Specifically, the proposed evolutionary algorithm defines a new entropy-based fitness function, and three new genetic operators for splitting, merging, and removing clusters. Empirical evaluations using the synthetic dataset and an existing benchmark show that the proposed evolutionary algorithm can exactly estimate the optimal number of clusters for a set of data", "num_citations": "18\n", "authors": ["348"]}
{"title": "Verifying online user identity using stylometric analysis for short messages\n", "abstract": " Stylometry consists of the analysis of linguistic styles and writing characteristics of the authors for identification, characterization, or verification purposes. In this paper, we investigate authorship verification for the purpose of user authentication process. In this setting, authentication consists of comparing sample writing of an individual against the model or profile associated with the identity claimed by that individual at login time (ie 1-to-1 identity matching). In addition, the authentication process must be done in a short period of time, which means analyzing short messages. Although a significant amount of literature has been produced showing high accuracy rates for long documents, it is still challenging to identify accurately authors of short unstructured documents, in particular when dealing with large authors populations. In this paper, we pose some steps toward achieving that goal by proposing a supervised learning technique combined with n-grams analysis for authorship verification for short texts. We introduce a new n-gram metric and study several sizes of n-grams using a relatively large dataset. The experimental evaluation shows increased effectiveness of our approach compared to the existing approaches published in the literature.", "num_citations": "17\n", "authors": ["348"]}
{"title": "Dynamic sample size detection in continuous authentication using sequential sampling\n", "abstract": " Continuous Authentication (CA) departs from the traditional static authentication scheme by requiring the authentication process to occur multiple times throughout the entire logon session. One of the main objectives of the CA process is to detect session hijacking. An important requirement about designing or operating a CA system is the need to achieve the quickest detection while maintaining rates of missed and false detections to predetermined levels. We introduce in this paper a new approach for detection based on the sequential sampling theory that allows balancing appropriately between detection promptness and accuracy in CA systems. We study and illustrate the proposed approach using an existing mouse dynamics biometrics recognition model and corresponding sample experimental data.", "num_citations": "17\n", "authors": ["348"]}
{"title": "Impact Study of a Mobile Botnet over LTE Networks.\n", "abstract": " This paper studies the impact of a mobile botnet on a Long Term Evolution (LTE) network by implementing a mobile botnet architecture that initiates a Distributed Denial of Service (DDoS) attack. To understand the behavior of the mobile botnet, a correlation between the mobile devices\u2019 mobility and the DDoS attack is established. Real traces of taxi cabs are used to simulate the mobile devices\u2019 trajectory movements. Indeed, the impact of the random patterns of movements\u2019 behavior (so-called Asymmetric Mobility Model (AMM))(resp. the uniform patterns of movements\u2019 behavior (so-called Symmetric Mobility Model (SMM)) on the mobile botnet\u2019s behavior are studied under a DDoS attack scenario. This reveals the advantage of deploying the SMM model compared to the AMM model, with respect to the number of infected mobile devices, task processing time, traffic load and response time of the victim server, and CPU resource consumption.", "num_citations": "16\n", "authors": ["348"]}
{"title": "Semantic aware attack scenarios reconstruction\n", "abstract": " Intrusion analysis is a resource intensive, complex and expensive process for any organization. The reconstruction of the attack scenario is an important aspect of such endeavor. We tackle in this paper several challenges overlooked by existing attack scenarios reconstruction techniques that undermine their performances. These include the ability to identify and extract novel attack patterns and the correlation of heterogeneous multisensor alerts. We propose a novel attack scenario reconstruction approach that analyzes both implicit and explicit relationships between intrusion alerts using semantic analysis and a new intrusion ontology. The proposed approach can reconstruct known and unknown attack scenarios and correlate alerts generated in multi-sensor IDS environment. Moreover, our approach can handle for the first time both novel attacks and false negative alerts generated by Intrusion Detection Systems\u00a0\u2026", "num_citations": "15\n", "authors": ["348"]}
{"title": "A multiformalism specification framework with statecharts and VDM\n", "abstract": " The issue of integration of partial specifications written in many different specification languages is discussed.We introduce the notion of partial specifications interface as the basis of the integration of the specification fragments. A case study, using notations such as O.M.T information model, Statechart, VDM is developped for the control of a manufacturing cell.", "num_citations": "15\n", "authors": ["348"]}
{"title": "A survey of connection-chains detection techniques\n", "abstract": " A connection-chain is a set of connections created by sequentially logging into a series of hosts, known as stepping-stones. It provides an effective scheme for attackers to manually interact with a victim machine without disclosing their true origin. The victim will only identify the last host in the chain, while the true origin is hidden behind a series of stepping-stones. Addressing connection-chains poses challenges for researchers in the field of computer security. Accordingly, several approaches have been proposed in the literature. In this paper, we review those approaches and classify them according to a proposed taxonomy.", "num_citations": "14\n", "authors": ["348"]}
{"title": "Properties for security measures of software products\n", "abstract": " A large number of attacks on computing systems succeed because of the existence of software flaws (eg buffer overflow, race conditions etc.) that could be fixed through a careful design process. An effective way of improving the quality of software products consists of using metrics to guide the development process. The field of software security metrics however is still in infancy in contrast with the area of traditional software metrics such as reliability metrics for which several key results have been obtained so far. We identify in this paper a number of internal software attributes that could be related to a variety of security qualities. Since theoretical validation is an important step in the development of any metrics program, we focus in this paper on studying the measurement properties associated with these internal attributes. The properties, based on popular security design principles in use in security engineering processes, can be used to guide the search of software security metrics. We study the feasibility of our theoretical framework by presenting case studies based on metrics derived from existing security measurement frameworks, namely the attack surface metrics system and the privilege graph paradigm.", "num_citations": "14\n", "authors": ["348"]}
{"title": "Continuous authentication using writing style\n", "abstract": " The reinforcement of traditional static authentication by performing continuous authentication (CA) while the system is being used ensures that the user is legitimate throughout the computer usage. Stylometry can be a good candidate for CA since writing style can be acquired in a nonintrusive way and also is a good indicator of authorship. In using stylometry, the authentication process consists of comparing sample writing of an individual against the model or profile associated with the identity claimed by that individual at login time (i.e., one-to-one identity matching). Effective CA requires reauthenticating the user over a short period of time, which equates using a short text. Analyzing short texts is challenging since decision-making occurs on a limited amount of available information. High accuracy and resilience to forgery are other key challenges faced by CA. In this chapter, we discuss the key research\u00a0\u2026", "num_citations": "13\n", "authors": ["348"]}
{"title": "Cognitive-based biometrics system for static user authentication\n", "abstract": " In today's globally expanding business world, protecting the identity and transactions of online consumers is crucial for any company to reach out for new markets. This directs digital information technologies towards the adoption of stronger and more secure authentication schemes. Although biometric-based user authentication systems have proven superiority over the traditional ones, there are several barriers for their wide scale deployment and application for Internet security; barriers include high expensive equipment, and low precision sensor technologies. In this paper, we propose a novel biometric system for static user authentication. It introduces two new cognitive factors, namely visual scan & detection, and short-term memory. These two factors are homogeneously combined with mouse dynamics in one biometric system. Experimental evaluation was performed using mass enrollment of 275 participants\u00a0\u2026", "num_citations": "13\n", "authors": ["348"]}
{"title": "A service-oriented framework for quantitative security analysis of software architectures\n", "abstract": " Software systems today often run in malicious environments in which attacks or intrusions are quite common. This situation has brought security concerns into the development of software systems. Generally, software services are expected not only to satisfy functional requirements but also to be resistant to malicious attacks. Software attackability is defined as the likelihood that an attack on a software system will succeed. In this paper, we present a service-oriented framework to analyze attackability of software systems. More specifically, we propose a User System Interaction Effect (USIE) model that can be used systematically to derive and analyze security concerns from service-oriented software architectures. Many aspects of the model derivation and analysis can be automated, which limit the amount of user involvement, and thereby reduce the subjectivity underlying typical security risk analysis process. The\u00a0\u2026", "num_citations": "13\n", "authors": ["348"]}
{"title": "State of the art and perspectives on traditional and emerging biometrics: A survey\n", "abstract": " The last three decades have seen a shift and impressive progress in the biometric technologies landscape. Several major real\u2010world applications of biometrics have been released and are currently being used around the world. At the same time, several new biometrics modalities have emerged and have started making an impact in securing sensitive data, information, and systems. We present in this paper a survey of traditional and emerging biometrics by emphasizing their connection to human body parts, behavior, and cognition. A review of the state of the art in the key technologies is carried out along with a discussion of major applications currently available in the real world.", "num_citations": "12\n", "authors": ["348"]}
{"title": "Mitigating collaborative blackhole attacks on DSR-based mobile ad hoc networks\n", "abstract": " A Mobile ad hoc network (MANET) is a collection of mobile nodes that rely on co-operation amongst devices that route packets to each other. From a security design perspective, MANETs have no clear line of defense. This lack of security leads the network accessible to both legitimate network users and malicious attackers. A blackhole attack is a severe attack that can be employed against data routing in MANETs. A blackhole is a malicious node that can falsely reply for any route requests without having an active route to a specified destination and drop all the receiving data packets. The attack may even lead to more devastating damage if two or more blackhole nodes cooperate with each other to launch an attack. This type of attack is known as collaborative blackhole attack. In this paper, a novel scheme Detecting Collaborative Blackhole Attacks (so-called DCBA) for detecting collaborative blackhole\u00a0\u2026", "num_citations": "12\n", "authors": ["348"]}
{"title": "Towards a formalization of UML class structure in PVS\n", "abstract": " The Unified Modeling Language (UML) is a language for specifying, visualizing and documenting object-oriented systems, and serves as a standard OO modeling notation. As the semantics of UML constructs is given informally in natural language, it is, for example, difficult to formally reason about correctness of a system design. Formal methods provide a rigor that is lacking in most of OO modeling notations in general and UML notations in particular. In this paper, we present a work done on the formalization of UML class diagrams. We assign formal semantics to UML class diagram using PVS specification language (PVS-SL) as underlying semantic foundation.", "num_citations": "12\n", "authors": ["348"]}
{"title": "Data sources and datasets for cloud intrusion detection modeling and evaluation\n", "abstract": " Over the past few years cloud computing has skyrocketed in popularity within the IT industry. Shifting towards cloud computing is attracting not only industry but also government and academia. However, given their stringent privacy and security policies, this shift is still hindered by many security concerns related to the cloud computing features, namely shared resources, virtualization and multi-tenancy. These security concerns vary from privacy threats and lack of transparency to intrusions from within and outside the cloud infrastructure. Therefore, to overcome these concerns and establish a strong trust in cloud computing, there is a need to develop adequate security mechanisms for effectively handling the threats faced in the cloud. Intrusion Detection Systems (IDSs) represent an important part of such mechanisms. Developing cloud based IDS that can capture suspicious activity or threats, and prevent\u00a0\u2026", "num_citations": "11\n", "authors": ["348"]}
{"title": "Continuous authentication using micro-messages\n", "abstract": " Authorship verification consists of checking whether a target document was written or not by a specific individual. In this paper, we study the problem of authorship verification for Continuous Authentication (CA) purposes. Different from traditional authorship verification that focuses on long texts, we tackle the use of micro-messages. Shorter authentication delay (i.e. smaller data sample) is essential to reduce the window size of the re-authentication period in CA. We explored lexical, syntactic, and application specific features. We investigated two different classification schemes: on one hand Logistic Regression (LR) and on the other hand an hybrid classifier combining Support Vector Machine (SVM) and LR. Experimental evaluation based on the Enron email dataset involving 76 authors and Twitter dataset involving 100 authors yield very promising results consisting of Equal Error Rates (EER) of 9.18% and 11.83\u00a0\u2026", "num_citations": "11\n", "authors": ["348"]}
{"title": "Employee surveillance based on free text detection of keystroke dynamics\n", "abstract": " In recent years, many studies have highlighted the unprecedented growth in security threats from multiple and varied sources faced by corporate, as well as governmental organizations. People inside the organization with ready access to confidential or proprietary data can easily violate the organization security policy, maliciously or inadvertently, without being caught. In order to protect their reputation and valuable assets, many organizations take the dramatic but necessary step of deploying and operating employee surveillance and monitoring tools within their network perimeters. In this chapter, we discuss employee surveillance schemes from both technological and legal perspectives. We argue that keystroke dynamics could be used to fight effectively against insider threat, and as such it could play an important role in employee surveillance. We present a keystroke recognition scheme based on free text\u00a0\u2026", "num_citations": "11\n", "authors": ["348"]}
{"title": "Anonymous mutual IoT interdevice authentication and key agreement scheme based on the ZigBee technique\n", "abstract": " Establishing end-to-end device authentication in Internet of Things (IoT) networks is challenging because of the heterogeneous nature of IoT devices. By covering different security properties, various authentication protocols have been introduced to ensure a certain level of security and privacy protection. In this paper, we propose an anonymous device-to-device mutual authentication and key exchange scheme based on the ZigBee technique, designed for a smart home network, an important domain in the IoT. The proposed protocol relies on symmetric encryption and enables IoT devices to authenticate in the network and agree on a shared secret session key when communicating with each other via a trusted intermediary (home controller). To achieve perfect forward secrecy, the session keys are changed frequently after every communication session. The proposed scheme achieves secure anonymous\u00a0\u2026", "num_citations": "10\n", "authors": ["348"]}
{"title": "Detecting Connection-Chains: A Data Mining Approach.\n", "abstract": " A connection-chain refers to a mechanism in which someone recursively logs into a host, then from there logs into another host, and so on. Connection-chains represent an important vector in many security attacks, so it is essential to be able to detect them. In this paper, we propose a host-based algorithm to detect them. We adopt a black-box approach by passively monitoring inbound and outbound packets at a host, and analyzing the observed packets using association rule mining. We first explain the proposed algorithm in greater details, then evaluations are presented to demonstrate its efficiency and detection capabilities. We conduct the evaluation using public network traces, and show that by appropriately setting underlying parameters we can achieve perfect detection, meaning a true positive rate (TPR) of 100% and a false positive rate (FPR) of 0%.", "num_citations": "10\n", "authors": ["348"]}
{"title": "Systematic security analysis for service-oriented software architectures\n", "abstract": " Due to the dramatic increase in intrusive activities architecture security analysis and design has emerged as an important aspect of the development of software services. It is a well-accepted fact in software engineering that security concerns like any other quality concerns should be dealt with in the early stages of software development. However, current software security risk analysis approaches still heavily rely on ad hoc techniques. These involve significant amount of subjective efforts creating greater potential for inaccuracies. In this paper, we propose a user system interaction effect (USIE) model that can be used systematically to derive and analyze security concerns from service-oriented software architectures. Many aspects of the model derivation and analysis can be automated, which limit the amount of user involvement, and thereby reduce the subjectivity underlying typical security risk analysis process\u00a0\u2026", "num_citations": "10\n", "authors": ["348"]}
{"title": "Privacy information in a positive credit system\n", "abstract": " A positive credit history and rating help consumers with good payment history to get lower interest rates, greater flexibility for credit, as well as loans with longer payment terms. In order to establish credit profiles, there is a need to get information (e.g. spending patterns) from the consumers and from the companies that are selling related goods. The problem is how to share private information about customers and companies without compromising the secrecy and confidentiality of such information. In this work, we propose a cryptographic protocol to share sensitive information while preserving the privacy of the customer as well as the information of the commercial institution. Furthermore, we analyse the proposed protocol by using Petri nets to verify the absence of livelocks, deadlocks, and other anomalies in the protocol.", "num_citations": "9\n", "authors": ["348"]}
{"title": "E-MAnt net: An ACO-based energy efficient routing protocol for mobile ad hoc networks\n", "abstract": " In mobile ad hoc networks (MANETs), nodes are mobile and have limited energy resource that can quickly deplete due to multi-hop routing activities, which may gradually lead to an un-operational network. In the past decade, the hunt for a reliable and energy-efficient MANETs routing protocol has been extensively researched. This paper proposes a novel Ant Net-based routing scheme for MANETs (so-called MAnt Net), and an its enhanced energy-aware version (so-called E-MAnt Net), for which the routing decisions are facilitated based on the nodes' residual energy. These protocols were evaluated through simulations using NS2, showing that E-MAnt Net outperforms both MAnt Net and EAODV, in terms of network residual energy, network lifetime, number of established connections, and the number of dead nodes in the network, where E-AODV is an energy-aware version of AODV.", "num_citations": "9\n", "authors": ["348"]}
{"title": "Comparison of two security protocols for preventing packet dropping and message tampering attacks on AODV-based mobile ad Hoc networks\n", "abstract": " In Emergency MANETs (eMANETs), the broadcasting nature of the wireless medium, the lack of pre-established trust relationship among nodes, and the frequent topology changes, cause some serious security challenges, making the network vulnerable to malicious attacks such as wormhole attacks. This paper investigates a recently proposed Advanced Encryption Standard (AES)-based routing algorithm (so-called AODV-Wormhole Attack Detection Reaction - here referred to as AODV-WADR-AES) for securing AODV-based eMANETs against wormhole attacks. The proposal consists of substituting the AES part of the scheme by the Triple Data Encryption Standard (TDES), yielding the AODV-WADR-TDES routing algorithm, with the goal to study the performance of the algorithm where mobile devices that are incompatible with AES are part of eMANET nodes. In doing so, markers in the form of hash codes are\u00a0\u2026", "num_citations": "9\n", "authors": ["348"]}
{"title": "A semantic analysis approach to manage ids alerts flooding\n", "abstract": " In this paper we propose a new approach to manage alerts flooding in IDSs. The proposed approach uses semantic analysis and ontology engineering techniques to combine and fuse two or more raw IDS alerts into one summarized hybrid/meta-alert. Our approach applies a new method based on measuring the semantic similarity between IDS alerts attributes to identify the alerts that are suitable for aggregation and summarization. In contrast to previous works our approach ensures that the aggregated alerts will not lose any valuable information existing in the raw alerts set. The experimental results show that our approach is effective and efficient in fusing massive number of alerts compared to previous works in the area.", "num_citations": "9\n", "authors": ["348"]}
{"title": "Performance analysis of distributed software systems: A model-driven approach\n", "abstract": " The design of complex software systems is a challenging task because it involves a wide range of quality attributes such as security, performance, reliability, to name a few. Dealing with each of these attributes requires specific set of skills, which quite often, involves making various trade-offs. This paper proposes a novel Model-Driven Software Performance Engineering (MDSPE) process that can be used for performance analysis requirements of distributed software systems. An example assessment is given to illustrate how our MDSPE process can comply with well-known performance models to assess the performance measures.", "num_citations": "9\n", "authors": ["348"]}
{"title": "RBDT-1: a new rule-based decision tree generation technique\n", "abstract": " Most of the methods that generate decision trees use examples of data instances in the decision tree generation process. This paper proposes a method called \u201cRBDT-1\u201d- rule based decision tree -for learning a decision tree from a set of decision rules that cover the data instances rather than from the data instances themselves. The method\u2019sgoal is to create on-demand a short and accurate decision tree from a stable or dynamically changing set of rules. We conduct a comparative study of RBDT-1 with three existing decision tree methods based on different problems. The outcome of the study shows that RBDT-1 performs better than AQDT-1 andAQDT-2 which are rule-based decision tree methods in terms of tree complexity (number of nodes and leaves in the decision tree). It is also shown that RBDT-1 performs equally well in terms of tree complexity compared with C4.5, which generates a decision tree\u00a0\u2026", "num_citations": "9\n", "authors": ["348"]}
{"title": "A new evolutionary algorithm for determining the optimal number of clusters\n", "abstract": " Estimating the optimal number of clusters for a dataset is one of the most essential issues in cluster analysis. An improper pre-selection for the number of clusters might easily lead to bad clustering outcome. In this paper, we propose a new evolutionary algorithm to address this issue. Specifically, the proposed evolutionary algorithm defines a new entropy-based fitness function, and three new genetic operators for splitting, merging, and removing clusters. Empirical evaluations using the synthetic dataset and an existing benchmark show that the proposed evolutionary algorithm can exactly estimate the optimal number of clusters for a set of data", "num_citations": "9\n", "authors": ["348"]}
{"title": "Exploratory use of PPG signal in continuous authentication\n", "abstract": " One-time or static authentication is not sufficient in many applications and continuous authentication methods can provide a way to increase security in situations where an application could be compromised or misused after statically authenticating the user. The aim of this work is to evaluate the use of the Photoplethysmographic Signal (PPG) in continuous authentication and identify the requirements of the system that should be used to record and process the signal. Different types of sensors, sampling rates, and analog to digital conversion resolutions were tested in order to identify the configuration that best suits the application requirements. The algorithms used for processing the PPG signal as well as the size of the samples used in the authentication process were also analyzed during the experiments. In order to achieve the set objective, a dataset of PPG signals was developed since it was not possible to find open datasets with long term monitoring samples of individuals.", "num_citations": "8\n", "authors": ["348"]}
{"title": "Current trends and the future of metamorphic malware detection\n", "abstract": " Dynamic binary obfuscation or metamorphism is a technique where a malware never keeps the same sequence of opcodes in the memory. This stealthy mutation technique helps a malware evade detection by today's signature-based anti-malware programs. This paper analyzes the current trends, provides future directions and reasons about some of the basic characteristics of a system for providing real-time detection of metamorphic malware. Our emphasis is on the most recent advancements and the potentials available in metamorphic malware detection, so we only cover some of the major academic research efforts carried out, including and after, the year 2006. The paper not only serves as a collection of recent references and information for easy comparison and analysis, but also as a motivation for improving the current and developing new techniques for metamorphic malware detection.", "num_citations": "8\n", "authors": ["348"]}
{"title": "Introduction to continuous authentication\n", "abstract": " Continuous Authentication (CA) systems represent a new generation of security mechanisms that continuously monitor user behavior and use this as basis to re-authenticate periodically throughout a login session. CA has been around for about a decade. As a result a limited amount of research work has been produced to date, and the first commercial products have only recently started reaching the market. We attempt, in this chapter, to provide some general perspectives in order to help achieve some common and better understanding of this emerging field. The chapter introduces basic CA concepts and terminologies, discusses the characteristics of CA data sources, and identifies major areas of application for CA systems.", "num_citations": "8\n", "authors": ["348"]}
{"title": "Integrated security verification and validation: Case study\n", "abstract": " In most current approaches to software security, security flaws are fixed only after they have been exploited. To increase user confidence in software products, the software industry needs more proactive and durable security solutions by addressing security requirements throughout the software system lifecycle, including requirements and design specification, testing, and maintenance phases. Appropriate security analysis techniques must be used for each of these phases. In this paper, we illustrate an integrated security analysis framework, which combines a quantitative design security analysis technique, with a static program analyzer, which tracks unsafe information flows. We illustrate the framework by presenting a case study based on medical information card", "num_citations": "8\n", "authors": ["348"]}
{"title": "UML-based security measures of software products\n", "abstract": " Better security engineering practice requires incorporating security concerns in the whole software lifecycle from requirements capture to software product delivery and evolution. Software measurement represents an effective tool for improving software product quality. Metrics have so far been developed for a wide variety of software quality attributes such as reliability, performance, and complexity. Security remains an exception: little attention has so far been paid to software security metrics. We propose in this paper a new paradigm, named the User System Interaction Effect (USIE) model that can be used as a basis for software security measurement at the architecural level. A USIE model captures user interactions with the system, and as such it can be derived systematically from UML interaction diagrams. We illustrate our approach by presenting a confidentiality metrics that can be generated for a collection of UML sequence diagrams.", "num_citations": "8\n", "authors": ["348"]}
{"title": "A protection scheme for collaborative environments\n", "abstract": " In collaborative working environments where multiple users use and/or provide multiple services, a more flexible security model is needed. Security must be enforced in such environments without affecting usability, scalability, and performance. In this paper, we propose a flexible protection scheme based on the lattice security model that combines information flow and access control mechanisms in order to address privacy and integrity requirements in scalable collaborative environments.", "num_citations": "8\n", "authors": ["348"]}
{"title": "Multimodal mobile keystroke dynamics biometrics combining fixed and variable passwords\n", "abstract": " Recent works have demonstrated the possibility to craft successful statistical attacks against keystroke dynamic biometric password. Those attacks leverage the possibility to capture several keystroke dynamics samples for a given password string, and then extract and use their distributional properties to craft the attack. These approaches are by design more likely to be successful when launched against fixed passwords, as several samples of the passwords can be captured through successive login sessions. Although the dynamics obtained from specific keys or key sequences for consecutive passwords slightly vary, by definition the distributional properties remain fairly stable for the same user. One way to thwart such that attack to use a variable password, also know as one\u2010time password (OTP). However, the fact that the keystroke dynamic OTP is different from one session to the other, makes it extremely difficult\u00a0\u2026", "num_citations": "7\n", "authors": ["348"]}
{"title": "If-transpiler: Inlining of hybrid flow-sensitive security monitor for JavaScript\n", "abstract": " A key characteristic of modern web applications is their heavy reliance on client-side JavaScript libraries. They use the libraries to achieve interactivity, reactivity, and service composition. Instead of writing their own, modern web applications developers, typically, use several third-party JavaScript libraries to achieve such level of engagement. This poses a security risk of leaking private information to illegal channels. Tracking information flow is one known technique to address such concern. This paper presents a framework that inlines a hybrid flow-sensitive security monitor for JavaScript. To our knowledge, our framework is the first in the literature to propose a hybrid flow-sensitive approach that targets JavaScript. Our approach operates as a source-to-source compiler (a transpiler), in which, the input is JavaScript source and the output is an instrumented version with the flow-sensitive security monitor inlined\u00a0\u2026", "num_citations": "7\n", "authors": ["348"]}
{"title": "Creating Decision Trees from Rules using RBDT\u20101\n", "abstract": " Most of the methods that generate decision trees for a specific problem use the examples of data instances in the decision tree\u2013generation process. This article proposes a method called RBDT\u20101\u2014rule\u2010based decision tree\u2014for learning a decision tree from a set of decision rules that cover the data instances rather than from the data instances themselves. The goal is to create on demand a short and accurate decision tree from a stable or dynamically changing set of rules. The rules could be generated by an expert, by an inductive rule learning program that induces decision rules from the examples of decision instances such as AQ\u2010type rule induction programs, or extracted from a tree generated by another method, such as the ID3 or C4.5. In terms of tree complexity (number of nodes and leaves in the decision tree), RBDT\u20101 compares favorably with AQDT\u20101 and AQDT\u20102, which are methods that create decision\u00a0\u2026", "num_citations": "7\n", "authors": ["348"]}
{"title": "Gait Biometric Recognition\n", "abstract": " The gait biometric has demonstrated potential promises as an alternative or complementary identifier for use in human recognition systems. However, there is no single measure that encompasses the full set of complex dynamics reflecting what we consider to be the human gait. Instead, important aspects of gait can be measured using one or more of several analysis techniques. Among these techniques are                visual approaches                             involving cameras, which can capture differing angles of gait from a distance, and sensor approaches, which collect information about gait while in contact with the subject being analyzed. In this chapter, we explore the ways in which these varying approaches have previously been applied to achieve gait biometric recognition, while also highlighting important possible areas of concern in their usage with respect to practicality, privacy, and security. This chapter\u00a0\u2026", "num_citations": "7\n", "authors": ["348"]}
{"title": "Sms botnet detection for android devices through intent capture and modeling\n", "abstract": " Mobile devices are subject to an increased attack surface vector as compared to desktop computing, due to the nature of sensors, radios, and increased peripherals. We investigate in this work mobile botnets with a specific focus on Android, which is the most widely adopted mobile platform, and a prime target for malicious software, 79% of reported malware threats to mobile operating systems are targeted at Android. Our analysis focuses on a short messaging service (SMS) botnet structure and investigates a new detection model using the concept of intents. We show that transparent control can be achieved by a remote endpoint, yet also detected by our proposed intent detection model. Intents are late run-time bindings mechanisms provided to applications in the Android operating system. Intents provide a clear and accurate picture of device behaviour with external sources, due to their design as a late run time\u00a0\u2026", "num_citations": "7\n", "authors": ["348"]}
{"title": "Detection and mitigation of malicious JavaScript using information flow control\n", "abstract": " JavaScript is the main language used to provide the client-side functionality of the modern web. It is used in many applications that provide high interactivity with the end-user. These applications range from mapping applications to online games. In recent years, cyber-criminals started focusing on attacking the visitors of legitimate websites and social networks rather than attacking the websites themselves. The dynamic nature of the JavaScript language and its tangled usage with other web technologies in modern web applications makes it hard to reason about its code statically. This poses the need to develop effective mechanisms for detecting and mitigating malicious JavaScript code on the client-side of the web. In this paper, we address the above challenges by developing a framework that detects and mitigates the flow of sensitive information on the client-side to illegal channels. The proposed model uses\u00a0\u2026", "num_citations": "7\n", "authors": ["348"]}
{"title": "Software Performance Modeling using the UML: a Case Study\n", "abstract": " The performance analysis of distributed software systems is a challenging task in which the assessment of performance measures is a vital step. Due to its versatility, the concept of software performance engineering (SPE) has been advocated as a promising solution towards realizing that step. This paper illustrates how by using our recently proposed Model-Driven SPE (MDSPE) approach, one can design annotated UML performance models for the performance analysis of distributed software systems, based on the UML profile for Schedulability, Performance and Time. An outline of system performance models and metrics is provided and a case study of a business system is used to validate the stated goal.", "num_citations": "7\n", "authors": ["348"]}
{"title": "Converting declarative rules into decision trees\n", "abstract": " Most of the methods that generate decision trees for a specific problem use examples of data instances in the decision tree generation process. This paper proposes a method called \u201cRBDT-1\u201d-rule based decision tree-for learning a decision tree from a set of decision rules that cover the data instances rather than from the data instances themselves. RBDT-1 method uses a set of declarative rules as an input for generating a decision tree. The method\u2019s goal is to create on-demand a short and accurate decision tree from a stable or dynamically changing set of rules. We conduct a comparative study of RBDT-1 with existing decision tree methods based on different problems. The outcome of the study shows that in terms of tree complexity (number of nodes and leaves in the decision tree) RBDT-1 compares favorably to AQDT-1, AQDT-2 which are methods that create decision trees from rules. RBDT-1 compares favorably also to ID3 while is as effective as C4. 5 where both (ID3 and C4. 5) are famous methods that generate decision trees from data examples. Experiments show that the classification accuracies of the different decision trees produced by the different methods under comparison are equal.", "num_citations": "7\n", "authors": ["348"]}
{"title": "A prevention model for algorithmic complexity attacks\n", "abstract": " Denial of Service (DoS) attack has been identified in security surveys as the second largest cause of monetary loss. Hence, DoS is a very important problem that needs to be dealt with seriously. Many DoS attacks are conducted by generating extremely high rate traffic; these are classified as flooding attacks. Other DoS attacks, which are caused by resource consumption, belong to the so-called logic attacks category, one such example is algorithmic complexity attack. Complexity attacks generate traffic containing data, which exploits the working principle of the algorithms running on a machine. In such an attack, a request imposes worst-case execution time on a resource and repeatedly re-uses the same resource for further services. In this paper, we propose a regression analysis based model that can prevent algorithmic complexity attacks. We demonstrate our model on quick-sort algorithm.", "num_citations": "7\n", "authors": ["348"]}
{"title": "Evaluation of Whitenoise Cryptosystem. Part 1: Encryption Algorithm\n", "abstract": " Whitenoise is a new generation stream cipher invented and developed by BSB Utilities Inc [1]. Stream ciphers convert plaintext to ciphertext one bit at a time. They are useful to encrypt never-ending streams of communications traffic. From our evaluation it appears that whitenoise carries all the characteristics of a one-time pad cryptosystem. To support this argument, first of all, whitenoise uses a key sequence as large as the plaintext message. The key has an extremely high level of randomness, and an extremely low level of repeatability. A one-time pad is considered as a perfect encryption scheme, providing unbreakable security, in which the key sequence has the same size as the plaintext, and is used only once. The security of one-time pad then relies on the randomness and non-repeatability of the key. Our evaluation has focused on verifying these properties for whitenoise. To verify randomness of whitenoise key generation, we used the statistical randomness test set designed by the National Institute of Standard and Technology (NIST) for the Advanced Encryption Standard (AES) competition [1]. To verify the nonrepeatability of the key generation, we engineered and executed a brute force attack using several Unix workstations running in parallel during a week. It is our intention in the future to re-execute the same attack using a 128 nodes supercomputer, and for a longer period. Whitenoise survived all these tests.Traditional one-time pad ciphers are too expensive for most applications, since they use as much key materiel as there is traffic. Hence, they are used currently mostly for high-level diplomatic and intelligence traffic, which require\u00a0\u2026", "num_citations": "7\n", "authors": ["348"]}
{"title": "An integrated V&V environment for critical systems development\n", "abstract": " This paper is an introduction to the demonstration sessions for the Precise UML Development Environment (PrUDE). PrUDE is a software V&V platform that integrates in a cost-effective way various rigorous software analysis methodologies.", "num_citations": "7\n", "authors": ["348"]}
{"title": "Formal development of open distributed systems: Towards an integrated framework\n", "abstract": " This paper contributes to the discussion on the issues related to the formal development of open distributed systems. The deficiencies of traditional formal notations in this setting are highlighted. We argue that there is no single formalism exhibiting all the features required. As a solution, we propose a multiformalism platform that involves three formalisms: UML, OUN and PVS-SL. We discuss the motivation for the choice of these formalisms and the main research issues underlying this kind of platform.", "num_citations": "7\n", "authors": ["348"]}
{"title": "Multilayer ransomware detection using grouped registry key operations, file entropy and file signature monitoring\n", "abstract": " The last few years have come with a sudden rise in ransomware attack incidents, causing significant financial losses to individuals, institutions and businesses. In reaction to these attacks, ransomware detection has become an important topic for research in recent years. Currently, there are two broad categories of ransomware detection techniques: signature-based and behaviour-based analyses. On the one hand, signature-based detection, which mainly relies on a static analysis, can easily be evaded by code-obfuscation and encryption techniques. On the other hand, current behaviour-based models, which rely mainly on a dynamic analysis, face difficulties in accurately differentiating between user-triggered encryption from ransomware-triggered encryption. In the current paper, we present an upgraded behavioural ransomware detection model that reinforces the existing feature space with a new set of features\u00a0\u2026", "num_citations": "6\n", "authors": ["348"]}
{"title": "Information Security Practices\n", "abstract": " With the rapid development of Internet-based technologies and the increasing reliance of society on these technologies, providing security and assurance to information systems has become a critical endeavor for practitioners and the various stakeholders impacted by information and system insecurities. In fact, the omnipresence of threats of malicious attacks has raised the importance of devising new paradigms and solutions in addition to professional skills, knowledge, and human resources in the area of information assurance. This book is a compilation of peer-reviewed papers from the first International Workshop on Information Security, Assurance, and Trust (I-SAT 2016), which introduce novel research targeting technical aspects of protecting information security and establishing trust in the digital space.", "num_citations": "6\n", "authors": ["348"]}
{"title": "Improving vulnerability detection measurement: [test suites and software security assurance]\n", "abstract": " The Software Assurance Metrics and Tool Evaluation (SAMATE) project at the National Institute of Standards and Technology (NIST) has created the Software Assurance Reference Dataset (SARD) to provide researchers and software security assurance tool developers with a set of known security flaws. As part of an empirical evaluation of a runtime monitoring framework, two test suites were executed and monitored, revealing deficiencies which led to a collaboration with the NIST SAMATE team to provide replacements. Test Suites 45 and 46 are analyzed, discussed, and updated to improve accuracy, consistency, preciseness, and automation. Empirical results show metrics such as recall, precision, and F-Measure are all impacted by invalid base assumptions regarding the test suites.", "num_citations": "6\n", "authors": ["348"]}
{"title": "A timed and secured monitoring implementation against wormhole attacks in AODV-based Mobile Ad Hoc Networks\n", "abstract": " Mobile Ad Hoc Networks (MANETs) offer a dynamic environment where data exchange and routing between nodes occur without the help of any centralized server or human intervention, providing that nodes cooperate with each other. In such environment, the presence of malevolent nodes may result in wormhole attacks. In this paper, a secured AODV-based routing scheme (referred to as Timed and Secured Monitoring Implementation - (TSMI)) is proposed for mitigating such attacks. Simulation results are provided to demonstrate the effectiveness of our approach, using the packet delivery ratio, the number of broken links detected, and the number of packets received by destination, as performance indicators.", "num_citations": "6\n", "authors": ["348"]}
{"title": "High performance proactive digital forensics\n", "abstract": " With the increase in the number of digital crimes and in their sophistication, High Performance Computing (HPC) is becoming a must in Digital Forensics (DF). According to the FBI annual report, the size of data processed during the 2010 fiscal year reached 3,086 TB (compared to 2,334 TB in 2009) and the number of agencies that requested Regional Computer Forensics Laboratory assistance increasing from 689 in 2009 to 722 in 2010. Since most investigation tools are both I/O and CPU bound, the next-generation DF tools are required to be distributed and offer HPC capabilities. The need for HPC is even more evident in investigating crimes on clouds or when proactive DF analysis and on-site investigation, requiring semi-real time processing, are performed.", "num_citations": "6\n", "authors": ["348"]}
{"title": "Measurement framework for software privilege protection based on user interaction analysis\n", "abstract": " Software security is a complex notion that has to be analyzed from several perspectives. One such perspective is the restriction and protection of software privileges. In other words, a secure software system should be able to prevent misuse of the privileges granted. Privileges are usually protected in software systems by integrating or implementing appropriate security modules or mechanisms. Knowing how system privileges are protected by security mechanisms helps software developers in reducing the security risks underlying software systems. In this paper, we propose a measurement framework to evaluate quantitatively the privilege protections of a software system at the design level. Our analysis is based on modelling and analyzing user interactions based on the so-called User System Interaction Effect (USIE) Model. Specifically we define some measurement abstractions and associated metrics for assessing software privilege protection. We evaluate our framework by conducting an empirical study based on a medical record keeping software system.", "num_citations": "6\n", "authors": ["348"]}
{"title": "Tracking Inconsitencies in an Integrated Platform\n", "abstract": " A response to the increasing complexity of contemporary systems is the use of integrated platforms for their development. Integrated platforms may involve different technologies and methodologies, that may lead unavoidably to inconsistencies. Tracking inconsistencies in such environments remains still an open issue, especially when we are working with different formalisms. In this paper, we introduce an approach to deal with such kinds of inconsistencies, based on semantic equivalence between constructs in different languages involved. We present a case study involving two specification formalisms, namely UML and OUN.", "num_citations": "6\n", "authors": ["348"]}
{"title": "A game theoretic framework for cloud security transparency\n", "abstract": " Over the past few years cloud computing has skyrocketed in popularity with the IT industry. Connected to this growing popularity is an increasing level of concern over the security of the cloud computing infrastructure. Despite this concern, cloud providers do not disclose any information about their security precautions. With no information on the security precautions, a provider\u2019s clients cannot be certain that their applications are safe from attack. Furthermore, clients are not granted access to the network level of the system to implement any of their own security features.                 In this paper we approach cloud security transparency constraints from a game theoretic perspective. Specifically, we model the security transparency problem as a dynamic non-cooperative game theoretic problem, whereby the provider and client are modelled as the players in the game. A theoretical analysis through which the\u00a0\u2026", "num_citations": "5\n", "authors": ["348"]}
{"title": "Mouse dynamics biometric technology\n", "abstract": " In this chapter the Authors introduce the concepts behind the mouse dynamics biometric technology, present a generic architecture of the detector used to collect and process mouse dynamics, and study the various factors used to build the user\u2019s signature. The Authors will also provide an updated survey on the researches and industrial implementations related to the technology, and study possible applications in computer security.", "num_citations": "5\n", "authors": ["348"]}
{"title": "New physiological biometrics based on human cognitive factors\n", "abstract": " Modeling and quantifying different human factors continue to be one of the major challenges in introducing new biometric systems. For example, drivers of some of our behavior differences are still mysteries, and hence cannot be modeled.In this paper, we propose a novel biometric system; it introduces the visual search and short-term memory human factors to the world of biometrics. This homogeneous system uses only the standard mouse as an input sensor for the two biometric factors. Experimental evaluation was performed using mass enrollment of 275 participants, and Neural Network for classification. Results showed an Equal Error Rate (EER) of 3.88%.", "num_citations": "5\n", "authors": ["348"]}
{"title": "Identity application fraud detection using web mining and rule-based decision tree\n", "abstract": " Identity fraud is becoming a growing concern for most government and private institutions. In the literature, identity frauds are categorized into two classes, namely application fraud and behavioural (or transactional) fraud. Most of the previous works in the area of identity fraud prevention and detection have focused primarily on credit transactional frauds. The work described in this paper is one of the very few works that focus on application fraud detection. We present an unsupervised framework to detect fraudulent applications for identity certificates by extracting identity patterns from the web, and crossing these patterns with information contained in the application forms in order to detect inconsistencies or anomalies. The outcome of this process is submitted to a decision tree classifier generated on the fly from a rule base which is derived from heuristics and expert knowledge, and updated as more information is\u00a0\u2026", "num_citations": "5\n", "authors": ["348"]}
{"title": "Integrating contract-based security monitors in the software development life cycle\n", "abstract": " Software systems, containing security vulnerabilities, continue to be created and released to consumers. We need to adopt improved software engineering practices to reduce the security vulnerabilities in modern systems. These practices should begin with stated security policies and end with systems which are quantitatively, not just qualitatively, more secure. Currently, contracts have been proposed for reliability and formal verification; yet, their use in security is limited. In this work, we propose a contract-based security assertion monitoring framework (CB SAMF) that is intended to reduce the number of security vulnerabilities that are exploitable, spanning multiple software layers, to be used in an enhanced systems development life cycle (SDLC).", "num_citations": "5\n", "authors": ["348"]}
{"title": "An unsupervised anomaly detection framework for network intrusions\n", "abstract": " Anomaly detection consists of analyzing and reporting unusual behavioral patterns in computing systems. According to Axelsson,\u201cthe early anomaly detection systems were self-learning, that is, they automatically formed an opinion of what the subject\u2019s normal behavior was\u201d[1]. This still applies for current anomaly detectors. Anomaly detection schemes can be classified into two categories, according to whether they are based on supervised or unsupervised learning: unsupervised anomaly detection and supervised anomaly detection [18].In supervised anomaly detection, normal profiles of systems or networks are established by training using a labeled dataset. Unsupervised anomaly detection uses unlabelled or noisy data to identify intrusions. The main drawback of supervised anomaly detection is the need to label the training data, which makes the process error-prone, costly and time consuming, and difficult if not impossible to achieve online. Unsupervised anomaly detection addresses these issues by allowing training based on an unlabelled dataset facilitating online detection and improving detection accuracy. By facilitating online detection, unsupervised detection creates a higher potential for timely intrusion response. By removing the need of labeling, unsupervised detection creates a greater potential for accurate detection.", "num_citations": "5\n", "authors": ["348"]}
{"title": "Secure personalized trust-based messages classification system and method\n", "abstract": " Technologies are described for authenticating a sender identity of an online message. For example, an online message having a purported sender identity can be obtained. Various features can then be extracted from the message, including stylometric features, origin location features, attached file features for any files attached to the message, and embedded URL features. The extracted features can then be compared to a sender profile for a known sender identity matching the purported sender identity, or to one or more sender profiles for recognized suspicious senders if the purported sender identity does not match a known sender identity. The sender profile for a given sender identity can include features extracted from one or more messages previously sent by the sender identity. A global risk score for the message indicating a likelihood that the purported sender identity is inauthentic can be determined based\u00a0\u2026", "num_citations": "4\n", "authors": ["348"]}
{"title": "Cloud slicing a new architecture for cloud security monitoring\n", "abstract": " Cloud computing has become one of the popular terms in academia and IT industry. The security of the cloud computing infrastructure is the main concern to adopt it. Despite this concern, cloud providers do not disclose any information about their security precautions. Therefore, a provider's clients cannot be certain that their applications are protected while they are in cloud. Furthermore, clients are not granted access to the network level of the system to implement any of their own security features. In this paper we propose a new model we are naming Cloud Slicing. Cloud Slicing uses a technique called logical partitioning, to divide a cloud servers resources. By doing this division, clients on a server can safely implement their own network security features to reassure themselves, and their customers, that the applications are protected.", "num_citations": "4\n", "authors": ["348"]}
{"title": "Context-aware intrusion alerts verification approach\n", "abstract": " Intrusion detection systems (IDSs) produce a massive number of intrusion alerts. A huge number of these alerts are false positives. Investigating false positive alerts is an expensive and time consuming process, and as such represents a significant problem for intrusion analysts. This shows the needs for automated approaches to eliminate false positive alerts. In this paper, we propose a novel alert verification and false positives reduction approach. The proposed approach uses context-aware and semantic similarity to filter IDS alerts and eliminate false positives. Evaluation of the approach with an IDS dataset that contains massive number of IDS alerts yields strong performance in detecting false positive alerts.", "num_citations": "4\n", "authors": ["348"]}
{"title": "Protection against web 2.0 client-side web attacks using information flow control\n", "abstract": " The dynamic nature of the Web 2.0 and the heavy obfuscation of web-based attacks complicate the job of the traditional protection systems such as Firewalls, Anti-virus solutions, and IDS systems. It has been witnessed that using ready-made toolkits, cyber-criminals can launch sophisticated attacks such as cross-site scripting (XSS), cross-site request forgery (CSRF) and botnets to name a few. In recent years, cyber-criminals have targeted legitimate websites and social networks to inject malicious scripts that compromise the security of the visitors of such websites. This involves performing actions using the victim browser without his/her permission. This poses the need to develop effective mechanisms for protecting against Web 2.0 attacks that mainly target the end-user. In this paper, we address the above challenges from information flow control perspective by developing a framework that restricts the flow of\u00a0\u2026", "num_citations": "4\n", "authors": ["348"]}
{"title": "Application of contract-based security assertion monitoring framework for telecommunications software engineering\n", "abstract": " Telecommunication software systems, containing security vulnerabilities, continue to be created and released to consumers. We need to adopt improved software engineering practices to reduce the security vulnerabilities in modern systems. Contracts can provide a useful mechanism for the identification, tracking, and validation of security vulnerabilities. In this work, we propose a new contract-based security assertion monitoring framework (CB_SAMF) that is intended to reduce the number of security vulnerabilities that are exploitable across multiple software layers, and to be used in an enhanced systems development life cycle (SDLC). We show how contract-based security assertion monitoring can be achieved in a live environment on Linux. Through security activities integrated into the SDLC we can identify potential security vulnerabilities in telecommunication systems, which in turn are used for the creation of\u00a0\u2026", "num_citations": "4\n", "authors": ["348"]}
{"title": "Profiling distributed connection chains\n", "abstract": " A key challenge in network forensics arises because of 'attackers' ability to move around in the network, which results in creating a chain of connections; commonly known as connection chains. They are widely used by attackers to stay anonymous and/or to confuse the forensic process. Investigating connection chains can be further complicated when several IP addresses are used in the attack. In this paper, we highlight this challenging problem. We then propose a solution through hacker profiling. Our solution includes a novel hacker model that integrates information about a hacker's linguistic, operating system and time of activity. It also includes an algorithm to operate on the proposed model. We establish the effectiveness of the proposed approach through several simulations and an evaluation with a real attack data.", "num_citations": "4\n", "authors": ["348"]}
{"title": "Mining and Detecting Connection-Chains in Network Traffic\n", "abstract": " A connection-chain refers to the set of connections created by sequentially logging into a series of hosts. Attackers typically use connection chains to indirectly carry their attacks and stay anonymous. In this paper, we proposed a host-based algorithm to detect connection chains by passively monitoring inbound and outbound packets. In particular, we employ concepts from association rule mining in the data mining literature. The proposed approach is first explained in details. We then present our evaluations of the approach in terms of real-time and detection performance. Our experimentations suggest that the algorithm is suitable for real-time operation, because the average processing time per packet is both constant and low. We also show that by appropriately setting underlying parameters we can achieve perfect detection", "num_citations": "4\n", "authors": ["348"]}
{"title": "Connection-chains: A review and taxonomy\n", "abstract": " A connection-chain is a set of connections created by sequentially logging into a series of hosts, known as steppingstones. It provides an effective scheme for attackers to manually interact with a victim machine without disclosing their true origin. The victim will only identify the last host in the chain, while the true origin is hidden behind a series of stepping-stones. Addressing connection-chains poses challenges for researchers in the field of computer security. Accordingly, several approaches have been proposed in the literature. In this paper, we review those approaches and classify them according to a proposed taxonomy.", "num_citations": "4\n", "authors": ["348"]}
{"title": "Optimal security-aware virtual machine management for mobile edge computing over 5G networks\n", "abstract": " A secure execution of offloaded tasks in the 5G-driven mobile edge computing (MEC) deployment is critical for all societal sectors. To realize it, mobile network operators have to intelligently orchestrate virtual resources in multiple cloud layers to satisfy 5G security requirements. In this article, we formulate a secure virtual machine management (VMM) mechanism using the semi-Markov decision process framework that seeks to jointly minimize the service rejection and the security risk, while meeting the location awareness requirements of latency-sensitive applications in a decentralized fashion. A new metric called mean security risk is proposed to quantify the perceived risk of an offloaded application considering the number of virtual machines (VMs) that is used to execute and to protect it. We also propose a new cost structure that allows for an efficient assessment of the long-term impact of providing additional\u00a0\u2026", "num_citations": "3\n", "authors": ["348"]}
{"title": "Detecting Ransomware in Encrypted Web Traffic.\n", "abstract": " To date, only a small amount of research has focused on detecting ransomware at the network level, and none of the published proposals have addressed the challenges raised by the fact that an increasing number of ransomware are using encrypted channels for communication with the command and control (C&C) server, mainly, over the HTTPS protocol. Despite the limited amount of ransomware-specific data available in network traffic, network-level detection represents a valuable extension of system-level detection as this would provide early indication of ransomware activities and allow disrupting such activities before serious damage can take place. To address the aforementioned gap, we propose, in the current paper, a new approach for detecting ransomware in encrypted network traffic that leverages network connections, certificate information and machine learning. We observe that network traffic characteristics can be divided into 3 categories\u2013connection based, encryption based, and certificate based. Based on these characteristics, we explore a feature model that separates effectively ransomware traffic from normal traffic. We study three different classifiers: random forest, SVM and logistic regression. Experimental evaluation on a diversified dataset yields a detection rate of 99.9% and a false positive rate of 0% for random forest, the best performing of the three classifiers.", "num_citations": "3\n", "authors": ["348"]}
{"title": "Design and Implementation of a Lightweight Authentication Framework for the Internet of Things (IoT)\n", "abstract": " Authentication is a critical issue in the rapidly growing IoT environment, considering that the network security is dependent on how properly the authentication process is done. Cyber attackers are turning their attention from traditional computers to IoT devices in smart homes for malicious activities, such as compromising smart home owner privacy and using smart home devices as stepping stones for large scale attacks through botnets. Many IoT devices run with weak or manufacturer-supplied default passwords, which make them highly vulnerable to various forms of credential theft attacks. Furthermore, the hackers may use stolen identities or counterfeit identities of rogue devices to connect to the IoT network. In this paper, we provide a lightweight authentication framework that uses dynamic identities and temporary keys for IoT nodes in smart homes. We implement the framework using the Objective Modular\u00a0\u2026", "num_citations": "3\n", "authors": ["348"]}
{"title": "Preventing Data Leak through Semantic Analysis\n", "abstract": " The theft and exfiltration of sensitive data (e.g. state secrets, trade secrets, company records, etc.) represent one of the most damaging threats that can be carried by malicious insiders against institutions and organizations. In the last decade, data leak prevention (DLP) has emerged as a new mechanism to detect and block unauthorized data transfer from the organization perimeter. While DLP has gained traction and led to several commercial products in industry, there are still many unresolved challenges hampering its operation and full adoption. Existing DLP systems exhibit relatively limited accuracy and can be circumvented using various evasive tactics. In this paper, we present a new DLP model that tracks sensitive data using a summarized version of the content semantic called document semantic signature (DSS). The DSS can be updated dynamically as the protected content change and it is resilient\u00a0\u2026", "num_citations": "3\n", "authors": ["348"]}
{"title": "A framework architecture for agentless cloud endpoint security monitoring\n", "abstract": " Cloud computing endpoints security monitoring faces more challenges compared with traditional networks due to the ephemeral nature of cloud assets. Existing endpoint security monitors use agents that must be installed on every computing host or endpoint. However, as the number of monitored instances increases, agents installation, configuration and maintenance become arduous and requires more efforts. Moreover, installed agents can increase the security threat footprint and several companies impose restrictions on using agents on every computing system. This work provides a generic agentless endpoint framework for security monitoring of cloud computing endpoints. The endpoints are accessed by the monitoring framework running on a central server. Since the monitoring framework is separate from the machines for which the monitoring is being performed, the various security models of the framework\u00a0\u2026", "num_citations": "3\n", "authors": ["348"]}
{"title": "Data Loss Prevention using document semantic signature\n", "abstract": " Data protection and insider threat detection and prevention are significant steps that organizations should take to enhance their internal security. Data loss prevention (DLP) is an emerging mechanism that is currently being used by organizations to detect and block unauthorized data transfers. Existing DLP approaches, however, face several practical challenges that limit their effectiveness. In this chapter, by extracting and analyzing document content semantic, we present a new DLP approach that addresses many existing challenges. We introduce the notion of a document semantic signature as a summarized representation of the document semantic. We show that the semantic signature can be used to detect a data leak by experimenting on a public dataset, yielding very encouraging detection effectiveness results including on average a false positive rate (FPR) of 6.71% and on average a detection rate\u00a0\u2026", "num_citations": "3\n", "authors": ["348"]}
{"title": "C-SCAN: an energy-efficient network layer security protocol for mobile ad hoc networks\n", "abstract": " This paper continues the investigation of our recently proposed protocol (called E2-SCAN) designed for protecting against network layer attacks in mobile ad hoc networks. The enhancements of the E2-SCAN protocol are twofold: (1) a modified credit strategy for tokens renewal is introduced, and (2) a novel strategy for selecting the routing path, resulting to our so-called Conditional SCAN (CSCAN). Simulation experiments are conducted, establishing the superiority of C-SCAN over E2-SCAN in terms of energy efficiency, where the energy efficiency of a node is defined as the ratio of the amount of energy consumed by the node to the total energy consumed by the network.", "num_citations": "3\n", "authors": ["348"]}
{"title": "Rbdt-2 method: Combining the power of rules and decision trees\n", "abstract": " Decision trees and rule bases are considered important tools in representing knowledge. The decision tree has several advantages that attract decision makers in using it. Decision trees are simple to understand and capable of breaking a problem into smaller problems. They do not have conflicting knowledge, are easily extended to handle non-numeric domains, and can be combined with other techniques. Unlike rule bases, decision trees are capable of revealing the importance of knowledge features by arranging attributes in the tree based on their importance in providing decisions. This makes decision trees provide faster decisions than rule bases. However, decision trees are difficult to modify because of their procedural order of evaluating the attributes in the tree. Rule bases are easier to modify because there is no evaluation order when processing the rules, making modifications easier. The extraction of rules from a decision tree related to a specific decision is not as easy as the rule bases. Despite the last two advantages of rule bases, rules in the rule base can be difficult to interpret. They can contain many conflicts and can be slower in providing a decision compared with decision trees.To combine the advantages of both decision trees and rule bases and overcome the shortcomings in each, the idea of designing rule-based decision tree generation methods emerged. The goal of rule-based decision tree generation methods is to generate a decision tree from a set of rules instead of data. Here, one can apply any modifications to the rules and create a decision tree faster, considering that the amount of rules is usually less than that of\u00a0\u2026", "num_citations": "3\n", "authors": ["348"]}
{"title": "Software Security Engineering\u2013Part I: Security Requirements and Risk Analysis\n", "abstract": " It has been reported in the literature that about twenty new software vulnerabilities are reported weekly. This situation has increased the security awareness in the software community. Nowadays, software services are expected not only to satisfy functional requirements but also to resist malicious attacks. As demand for more trustworthy systems is increasing, the software industry is adjusting itself to security standards and practices by increasing security assessment and testing effort. Even though there is a consensus that better software engineering is to improve software quality in the early stage of software development, so far, various approaches that have been proposed to analyze and quantitatively measure the software security target, primarily show the finished software products in their operational life. There are few achievements on how to reduce or effectively mitigate the security risks faced by software\u00a0\u2026", "num_citations": "3\n", "authors": ["348"]}
{"title": "Heterogeneous multi-sensor ids alerts aggregation using semantic analysis\n", "abstract": " One of the major limitations of current Intrusion Detection System (IDS) technology is alerts flooding which is a time consuming and resource intensive problem for intrusion analysts and organizations. Alerts flooding has been handled using alerts aggregation techniques. In general, the majority of IDS alerts aggregation techniques use alerts similarity to aggregate and summarize alerts. Because intrusion characteristics are expressed using symbolic attributes, measuring the similarity between IDS alerts is difficult. Previous techniques in the area of alerts aggregation mostly use perfect match or ad-hoc techniques to measure the similarity between alerts attributes. In this paper, we propose a new IDS alerts aggregation and reduction technique based on semantic similarity between intrusions. We define a new metric to measure semantic similarity between different intrusion instances. In addition we propose a new\u00a0\u2026", "num_citations": "3\n", "authors": ["348"]}
{"title": "UML-based performance modeling of distributed software systems\n", "abstract": " The performance analysis of distributed software systems is a challenging task in which the assessment of performance measures is a vital step. Due to its versatility, the concept of software performance engineering (SPE) has been advocated as a promising solution towards realizing that step. This paper illustrates how by using our recently proposed Model-Driven SPE (MDSPE) approach, one can design annotated UML performance models for the performance analysis of distributed software systems, based on the UML profile for Schedulability, Performance and Time. A case study of a business system is used to validate the stated goal.", "num_citations": "3\n", "authors": ["348"]}
{"title": "A Secure Document Management Tool for Scalable Collaborative Environments\n", "abstract": " Access control is an essential component for secure computing systems. This paper introduces a security tool for improved privacy through document access control in scalable autonomous collaborative environments. The tool implements the owner-retained control security model which allows the owner (of a document) to retain control of the document even when the document leaves their immediate control. The tool implements a security architecture consisting of three primary components: a secure document format; a secure protocol; and a trusted computing base.", "num_citations": "3\n", "authors": ["348"]}
{"title": "When Agile Security Meets 5G\n", "abstract": " 5G is a critical infrastructure that will connect the whole society and bridge other critical infrastructure systems. Thus, cybersecurity emerges as crucial tenet within the 5G pathway. In this article, we discuss the concept of agile security within a 5G infrastructure taking into account two of its major technologies: Mobile Edge Computing (MEC) and Network Functions Virtualization (NFV). In this sense, we first discuss the 5G-driven MEC deployment from a NFV perspective. Secondly, we present the concept of agile security and how it can be embedded in the daily activities of mobile network operators (MNOs). Thirdly, we discuss risk management as a key element of the agile security framework. To illustrate its application, we propose the design of an agile security risk-aware edge server mechanism for 5G driven MEC deployment, which uses multiple thresholds and a load-balancing security control to mitigate the risks\u00a0\u2026", "num_citations": "2\n", "authors": ["348"]}
{"title": "Automated Event Prioritization for Security Operation Center using Deep Learning\n", "abstract": " Despite their popularity, Security Operation Centers (SOCs) are facing increasing challenges and pressure due to the growing volume, velocity and variety of the IT infrastructure and security data observed on a daily basis. Due to the mixed performance of current technological solutions, e.g. IDS and SIEM, there is an over-reliance on manual analysis of the events by human security analysts. This creates huge backlogs and slow down considerably the resolution of critical security events. Obvious solutions include increasing accuracy and efficiency in the automation of crucial aspects of the SOC workflow, such as the event classification and prioritization. In the current paper, we present a new approach for SOC event classification by identifying a set of new features using graphical analysis and classifying using a deep neural network model. Experimental evaluation using real SOC event log data yields very\u00a0\u2026", "num_citations": "2\n", "authors": ["348"]}
{"title": "Anonymous IoT Mutual Inter-Device Authentication Scheme Based on Incremental Counter (AIMIA-IC)\n", "abstract": " Cyber attackers are shifting their attention from traditional computers to IoT devices for malignant activities like exposing smart homeowner private information and/or to launch botnet attacks. Like for conventional networks, the security of IoT networks rests on how properly the authentication process is done. However, unlike conventional networks, IoT infrastructure faces an uphill battle in deploying and operating strong authentication schemes because of inherent limitations on the underlying storage and computation capability. In this paper, we propose a new anonymous mutual Inter-device authentication protocol based on transient identities, incremental counter and temporary secret keys for IoT. The proposed protocol is based on symmetric cryptography and somehow follows the ZigBee protocol. It allows IoT devices to anonymously and mutually authenticate in an unlinkable and untraceable manner, and\u00a0\u2026", "num_citations": "2\n", "authors": ["348"]}
{"title": "Facets and Promises of Gait Biometric Recognition\n", "abstract": " The emerging field of behavior biometrics has prompted a re-examination of many previously overlooked human characteristics. One such characteristic that has traditionally undergone analysis in the medical realm is the gait biometric. Gait biometrics refer to the unique aspects of human locomotion that can be captured and used for recognition purposes. These biometrics offer a number of potential advantages over other traditional biometrics in their abilities to be detected at a distance and with little-to-no obtrusion to the subject of the analysis. The gait biometric also offers another potential advantage over many traditional biometrics because it is inherently difficult to spoof the complicated set of actions that compose the human gait. This chapter discusses the various approaches that have been used to perform recognition via the gait biometric and examines the performance and implications that might be\u00a0\u2026", "num_citations": "2\n", "authors": ["348"]}
{"title": "Adaptive mobile keystroke dynamic authentication using ensemble classification methods\n", "abstract": " Mobile keystroke dynamic biometric authentication requires several biometric samples for enrolment. In some application context or scenario where the user scarcely uses the application, it could take quite a while to get enough samples for enrolment. This creates a window of vulnerability where the user cannot be authenticated using the keystroke dynamic biometric. We propose in this paper, an adaptive approach to derive initially the user profile online and passively with a minimum number of samples, and then progressively update the profile as more samples become available. The approach uses ensemble classification methods and the equal error rate as profile maturity metric. The approach was evaluated using an existing dataset involving 42 users yielding encouraging results. The best performance achieved was an EER of 5.29% using Random forest algorithm.", "num_citations": "2\n", "authors": ["348"]}
{"title": "Impact of base transceiver station selection mechanisms on a mobile botnet over a LTE network\n", "abstract": " This paper studies the impact of two base transceiver station selection mechanisms, namely, the distance-based eNodeB (DBM) and the signal power-based eNodeB (SPBM) mechanisms, on a mobile botnet launching a distributed denial of service (DDoS) attack on a Long Term Evolution (LTE) network. Simulation results using the Riverbed Modeller reveal that in comparison to DBM, using SPBM to enable the mobile devices' connections with the serving eNodeB stations can reduce the impact of the attack severity of the mobile botnet on the victim server, from 100% to 70%.", "num_citations": "2\n", "authors": ["348"]}
{"title": "Applications of gait biometrics\n", "abstract": " The gait biometric, having only relatively recently become technically feasible as a means to provide security, has to-this-date seen only limited applications in industry. Nevertheless, gait biometric recognition continues to be a growing area of interest due to its unobtrusive nature and an increasing number of technologies available for capturing information about the human gait. In this chapter, we explore a variety of applications for which gait biometrics may be deployed.", "num_citations": "2\n", "authors": ["348"]}
{"title": "Performance metrics and models for continuous authentication systems\n", "abstract": " Continuous Authentication (CA) systems represent a new class of security systems that are increasingly the focus of much attention in the research literature. CA departs from the traditional (static) authentication scheme by repeating several times the authentication process dynamically throughout the entire login session; the main objectives are to detect session hijacking and ensure session security. As the technology gains in maturity and becomes more diverse, it is essential to develop common and meaningful evaluation metrics that can be used to compare and contrast between existing and future schemes. So far, all the CA systems proposed in the literature were by default evaluated using the same accuracy metrics used for static authentication systems. As an alternative, we discuss in this chapter dynamic accuracy metrics that better capture the continuous nature of CA activity. Furthermore, we introduce and\u00a0\u2026", "num_citations": "2\n", "authors": ["348"]}
{"title": "Contract-based security monitors for service oriented software architecture\n", "abstract": " Monitors have been used for real-time systems to ensure proper behavior; however, most approaches do not allow for the addition of relevant fields required to identify and react to security vulnerabilities. Contracts can provide a useful mechanism for identifying and tracking vulnerabilities. Currently, contracts have been proposed for reliability and formal verification; yet, their use in security is limited. Static analysis methods are able to identify many known vulnerabilities; however, they suffer from a high rate of false-positives. The creation of a mechanism that can verify identified vulnerabilities is therefore warranted. We propose a contract-based security assertion monitoring framework (CB SAMF) for reducing the number of security vulnerabilities that are exploitable. CB SAMF will span multiple software layers and be used in an enhanced systems development life cycle (SDLC) including service-oriented analysis\u00a0\u2026", "num_citations": "2\n", "authors": ["348"]}
{"title": "Behavioral biometrics for online computer user monitoring\n", "abstract": " Traditional biometrics technologies such as fingerprints or iris recognition systems require special hardware devices for biometrics data collection. This makes them unsuitable for online computer user monitoring, which to be effective should be non-intrusive, and carried out passively. Behavioural biometrics based on human computer interaction devices such as mouse and keyboards do not carry such limitation, and as such are good candidates for online computer user monitoring. We present in this chapter artificial intelligence based techniques that can be used to analyze and process keystroke and mouse dynamics to achieve passive user monitoring.", "num_citations": "2\n", "authors": ["348"]}
{"title": "A statistical model for biometric verification\n", "abstract": " Biometrics can be defined as a set of distinctive, permanent and universal features recognized from human physiological or behavioral characteristics [17],[18]. As such, biometrics systems are commonly classified into two categories: physiological biometrics and behavioral biometrics. Physiological biometrics, which include finger-scan, iris-scan, retina-scan, hand-scan, and facial-scan use measurements from the human body. Behavioral biometrics such as signature or keystroke dynamics use measurements based on human actions [3],[4],[13],[14]. Due to their strong variability over time, so far, behavioral biometric systems have been less successful compared to physiological ones [3]. Despite such limitation, behavioral biometrics such as mouse dynamics and keystroke dynamics, carry the greatest promise in the particular field of online computer user monitoring [7]. For such application, passive or non-intrusive monitoring is essential. Unfortunately most biometrics systems require special hardware device for biometrics data collection, restricting their use to only networks segments where such devices are available. Behavioral biometrics such as mouse dynamics and keystroke dynamics are appropriate for such context because they only require traditional human-computer interaction devices. In this chapter, we present some techniques for extracting and analyzing mouse and keystroke dynamics data for online computer user monitoring. While the use of mouse dynamics for online monitoring is straightforward, the use of keystroke dynamics for such purpose faces the important challenges underlying the need for free-text detection.", "num_citations": "2\n", "authors": ["348"]}
{"title": "Classifier Calibration: with implications to threat scores in cybersecurity\n", "abstract": " This paper explores the calibration of a classifier output score in binary classification problems. A calibrator is a function that maps the arbitrary classifier score, of a testing observation, onto  to provide an estimate for the posterior probability of belonging to one of the two classes. Calibration is important for two reasons; first, it provides a meaningful score, that is the posterior probability; second, it puts the scores of different classifiers on the same scale for comparable interpretation. The paper presents three main contributions: (1) Introducing multi-score calibration, when more than one classifier provides a score for a single observation. (2) Introducing the idea that the classifier scores to a calibration process are nothing but features to a classifier, hence proposing extending the classifier scores to higher dimensions to boost the calibrator's performance. (3) Conducting a massive simulation study, in the order of 24,000 experiments, that incorporates different configurations, in addition to experimenting on two real datasets from the cybersecurity domain. The results show that there is no overall winner among the different calibrators and different configurations. However, general advices for practitioners include the following: the Platt's calibrator~\\citep{Platt1999ProbabilisticOutputsForSupport}, a version of the logistic regression that decreases bias for a small sample size, has a very stable and acceptable performance among all experiments; our suggested multi-score calibration provides better performance than single score calibration in the majority of experiments, including the two real datasets. In addition, extending the scores can help in some\u00a0\u2026", "num_citations": "1\n", "authors": ["348"]}
{"title": "Optimal security risk management mechanism for the 5G cloudified infrastructure\n", "abstract": " This work proposes an optimal security risk management mechanism to holistically minimize the risks of a Denial of Service (DoS) attack and Service Level Agreement (SLA) violations that might unfold at the 5G edge-cloud ecosystem. Using the Semi-Markov Decision Process framework, a cyber risk-aware controller is designed to optimally decide on the admission, placement, and migration of a service taking into consideration a user taxonomy and the service requirements. A new cost structure that balances the targeted security risks as well as the cost and the reward of a secure service provisioning is introduced to pave the way for a safe edge-cloud operation. To proactively restrict the population of untrusted users, we consider security controls in the form of a linear and an exponential cost functions and show that the former represents a more flexible and profitable pathway for a Mobile Network Operator to\u00a0\u2026", "num_citations": "1\n", "authors": ["348"]}
{"title": "Towards an Epidemic SMS-based Cellular Botnet.\n", "abstract": " Attacks and threats against cellular devices such as botnets are becoming more and more prominent. Focusing on short message services (SMS) phishing attacks, this paper proposes the design of a cellular botnet that initiates such attack and studies its epidemic behavior using three random graphs models, namely the Barabasi\u2013and-Albert topology (BAT), Erdos-and-Reyni topology (ERT), and Watts-and-Strogatz topology (WST). Simulation results show that:(1) Compared to BAT and WST, ERT is the best topology for enhancing the epidemic behavior of the proposed cellular botnet,(2) the BAT topology is less resilient to devices\u2019 failures compared to the ERT and WST topologies. In the end, an effective holistic multi-tier defense strategy against the proposed epidemic SMS-based cellular botnet is presented.", "num_citations": "1\n", "authors": ["348"]}
{"title": "Security-and Location-Aware Optimal Virtual Machine Management for 5G-Driven MEC Systems\n", "abstract": " Mobile Edge Computing (MEC) over a densified 5G wireless network deployment arises as an effective response to the skyrocketing demand for latency-driven mobile computing applications which can meet virtual computing, storage, and networking resources one-hop away from their locations. In this context, the design of virtual machine (VM) management mechanisms comes out as key issue in cloud orchestration process given the need to provide these applications with the nearest VMs resources. The design becomes even more challenging when security is taken into account in the resource allocation problem due to need to shield the computation task with additional VMs. In this paper, we propose an optimal security- and location-aware VMM mechanism that efficiently manages the placement of computation tasks in a multi-cloud environment considering MEC and the Back-up cloud. The proposed method\u00a0\u2026", "num_citations": "1\n", "authors": ["348"]}
{"title": "Arguments Against Using the 1998 DARPA Dataset for Cloud IDS Design and Evaluation and Some Alternative\n", "abstract": " Due to the lack of adequate public datasets, the proponents of many existing cloud intrusion detection systems (IDS) have relied on the DARPA dataset to design and evaluate their models. In the current paper, we show empirically that the DARPA dataset by failing to meet important statistical characteristics of real world cloud traffic data center is inadequate for evaluating cloud IDS. We present, as alternative, a new public dataset collected through a cooperation between our lab and a non-profit cloud service provider, which contains benign data and a wide variety of attack data. We present a new hypervisor-based cloud IDS using instance-oriented feature model and supervised machine learning techniques. We investigate 3 different classifiers: Logistic Regression (LR), Random Forest (RF), and Support Vector Machine (SVM) algorithms. Experimental evaluation on a diversified dataset yields a detection rate of\u00a0\u2026", "num_citations": "1\n", "authors": ["348"]}
{"title": "Intelligent, Secure, and Dependable Systems in Distributed and Cloud Environments: First International Conference, ISDDC 2017, Vancouver, BC, Canada, October 26-28, 2017\u00a0\u2026\n", "abstract": " This book constitutes the refereed proceedings of the First International Conference on Intelligent, Secure, and Dependable Systems in Distributed and Cloud Environments, ISDDC 2017, held in Vancouver, BC, Canada, in October 2017. The 12 full papers presented together with 1 short paper were carefully reviewed and selected from 43 submissions. This book also contains 3 keynote talks and 2 tutorials. The contributions included in this proceedings cover many aspects of theory and application of effective and efficient paradigms, approaches, and tools for building, maintaining, and managing secure and dependable systems and infrastructures, such as botnet detection, secure cloud computing and cryptosystems, IoT security, sensor and social network security, behavioral systems and data science, and mobile computing.", "num_citations": "1\n", "authors": ["348"]}
{"title": "Adaptive Communication in Wireless Networks\n", "abstract": " Wireless communication technologies are undergoing rapid advancements. The last few years have experienced a steep growth in research on wireless networks having attractive claims. Researchers are currently envisioning different attractive properties of wireless systems such as the ability to self-organize, self-configure, self-heal, self-manage and self-maintain. These systems are increasingly becoming dynamic and they are expected to perform many tasks autonomously by adapting to the dynamics of the networks. With the wide range of applications that need to be supported in these systems, there are increasing expectations about what the current and the future generation networks can do. Many of these requirements are pivoted in the ability of the networks to adapt to the network dynamism. Adaptation to changing environments, in turn, often leads to increased performance of the networks. In this Special\u00a0\u2026", "num_citations": "1\n", "authors": ["348"]}
{"title": "Unsupervised Identity Application Fraud Detection using Rule-based Decision Tree.\n", "abstract": " Identity fraud is becoming a growing concern for most government and private institutions. In the literature, identity fraud is categorized into two classes, namely application fraud and behavioral (or transactional) fraud. Most of the previous works in the area of identity fraud prevention and detection have focused primarily on credit transactional frauds. The work described in this paper is one of the very few works that focus on application fraud detection. We present an unsupervised framework to detect fraudulent applications for identity certificates by extracting identity patterns from the web, and crossing these patterns with information contained in the application forms in order to detect inconsistencies or anomalies. The outcome of this process is submitted to a decision tree classifier generated on the fly from a rule base which is derived from heuristics and expert knowledge, and updated as more information are\u00a0\u2026", "num_citations": "1\n", "authors": ["348"]}
{"title": "RBDT-1 method: Combining rules and Decision tree capabilities\n", "abstract": " Most of the methods that generate decision trees for a specific problem use examples of data instances in the decision tree generation process. This chapter proposes a method called \u201cRBDT-1\u201d - rule based decision tree - for learning a decision tree from a set of decision rules that cover the data instances rather than from the data instances themselves. RBDT-1 method uses a set of declarative rules as an input for generating a decision tree. The method\u2019s goal is to create on-demand a short and accurate decision tree from a stable or dynamically changing set of rules. We conduct a comparative study of RBDT-1 with existing decision tree methods based on different problems. The outcome of the study shows that in terms of tree complexity (number of nodes and leaves in the decision tree) RBDT-1 compares favorably to AQDT-1, AQDT-2 which are methods that create decision trees from rules. RBDT-1\u00a0\u2026", "num_citations": "1\n", "authors": ["348"]}
{"title": "E-means: an evolutionary clustering algorithm\n", "abstract": " In this paper we propose a new evolutionary clustering algorithm named E-means. E-means is an Evolutionary extension of k-means algorithm that is composed by a revised k-means algorithm and an evolutionary approach to Gaussian mixture model, which estimates automatically the number of clusters and the optimal mean for each cluster. More specifically, the proposed E-means algorithm defines an entropy-based fitness function, and three genetic operators for merging, mutation, and deletion components. We conduct two sets of experiments using a synthetic dataset and an existing benchmark to validate the proposed E-means algorithm. The results obtained in the first experiment show that the algorithm can estimate exactly the optimal number of clusters for a set of data. In the second experiment, we compute nine major clustering validity indices and compare the corresponding results with those\u00a0\u2026", "num_citations": "1\n", "authors": ["348"]}
{"title": "A genetic EM algorithm for learning the optimal number of components of mixture models.\n", "abstract": " Mixture models have been widely used in cluster analysis. Traditional mixture densities-based clustering algorithms usually predefine the number of clusters via random selection or contend based knowledge. An improper pre-selection of the number of clusters may easily lead to bad clustering outcome. Expectation-maximization (EM) algorithm is a common approach to estimate the parameters of mixture models. However, EM is prone to converge into local maximum after a limited number of iterations. Moreover, EM usually assumes that the number of mixing components is known in advance, which is not always the case in practice. In order to address these issues we propose in this paper a new genetic EM algorithm to learn the optimal number of components of mixture models. Specifically, the algorithm defines an entropy-based fitness function, and two genetic operators for splitting and merging components. We conducted two sets of experiments using a synthetic dataset and two existing benchmarks to validate our genetic EM algorithm. The results obtained in the first experiment show that the algorithm can estimate exactly the optimal number of clusters for a set of data. In the second experiment, we computed three major clustering validity indices and compared the corresponding results with those obtained using established clustering techniques, and found that our genetic EM algorithm achieves better clustering structures.", "num_citations": "1\n", "authors": ["348"]}
{"title": "Integration of Structured Review and Model-based Verification: a Case Study\n", "abstract": " Sammendrag/Abstract: In this report, we discuss how structured reviews and formal verification and validation (V&V) can be integrated into a single development framework to exploit the synergy between them. The integrated approach uses graphical modeling techniques and the supporting tools as a front-end to formal V&V in order to improve feasibility of the framework. This in turns increases acceptability of formal V&V techniques among software developers by hiding their esoteric features behind the graphical modeling techniques, which are popular among the software developers.", "num_citations": "1\n", "authors": ["348"]}
{"title": "A transition-based strategy for object-oriented software testing\n", "abstract": " Though time-to-market has become the primary criterion that drives most current software development projects, quality still remains the key concern of critical software development projects, for which the cost of a single bug may involve serious loss or damages. Meeting the higher quality level required for such kinds of systems may be achieved only by using sound and rigorous test practices. We present in this paper an integrated platform that uses a formalized version of UML statechart as the basis for rigorous testing of object-oriented programs. The platform adapts and integrates systematic test data generation strategies and associated tools for object-oriented program testing.", "num_citations": "1\n", "authors": ["348"]}
{"title": "Integrating formal methods in the development process of distributed systems\n", "abstract": " The importance of formal methods in software development process is motivated and discussed. A framework is proposed for the integration of semi-formal and formal notations in order to produce a formal specification of systems. The approach relies on two steps: the first step consists in using adequately statecharts and activity-charts to guide the analyst's understanding of the system and produce a preliminary document. The second step consists in generating a VDM specification from the preliminary document on the basis of predefined rules. The notion of control kernel is proposed as a mean to introduce control information in the obtained VDM specification. The approach is applied to a simple distributed critical system.", "num_citations": "1\n", "authors": ["348"]}
{"title": "Int\u00e9gration des sp\u00e9cifications partielles des calculateurs embarqu\u00e9s\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "1\n", "authors": ["348"]}
{"title": "Timing extensions in object analysis\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "1\n", "authors": ["348"]}