{"title": "A replicable comparison study of NER software: StanfordNLP, NLTK, OpenNLP, SpaCy, Gate\n", "abstract": " Named Entity Recognition (NER) is a key building block of any Natural Language Processing (NLP) system, making possible the detection and classification of entities (e.g., Person, Location) in any given text. While a large number of NER software exist today, it remains difficult for NLP and NER practitioners to clearly and objectively identify what software perform(s) the best. One of the reasons is the difference in results across the literature and the lack of information needed to be able to fully reproduce the experiment. To overcome this problem, this paper presents a comprehensive and replicable study to assess the performance of NER software, thus laying the groundwork for future benchmarking and meaningful comparison studies. As part of our experiments, the latest version of five well-known NER software were selected, along with two distinct corpora. We observe a discrepancy between the result we get\u00a0\u2026", "num_citations": "27\n", "authors": ["550"]}
{"title": "Test data generation techniques for mutation testing: A systematic mapping\n", "abstract": " Mutation testing is regarded as an effective testing criterion. However, its main downside is that it is an expensive and time consuming technique, which has hampered its widespread adoption in industrial settings. Automatic test data generation is an option to deal with this problem. The successful automation of this activity requires the generation of a small number of tests that can achieve good mutation score. In this paper, we describe the process, results and discussions of a systematic mapping conducted to gather and identify evidence with respect to the techniques and approaches for test data generation in mutation testing. We selected 19 primary studies that focus on techniques based in search, code coverage, restrictions, and hybrid techniques. Our results indicate that most of the reported approaches are not industry-ready, which underscores the importance of further research in the area so that automatic test data generation can reach an acceptable level of maturity and be used in realistic settings.", "num_citations": "24\n", "authors": ["550"]}
{"title": "Time to clean your test objectives\n", "abstract": " Testing is the primary approach for detecting software defects. A major challenge faced by testers lies in crafting efficient test suites, able to detect a maximum number of bugs with manageable effort. To do so, they rely on coverage criteria, which define some precise test objectives to be covered. However, many common criteria specify a significant number of objectives that occur to be infeasible or redundant in practice, like covering dead code or semantically equal mutants. Such objectives are well-known to be harmful to the design of test suites, impacting both the efficiency and precision of the tester's effort. This work introduces a sound and scalable technique to prune out a significant part of the infeasible and redundant objectives produced by a panel of white-box criteria. In a nutshell, we reduce this task to proving the validity of logical assertions in the code under test. The technique is implemented in a tool that\u00a0\u2026", "num_citations": "21\n", "authors": ["550"]}
{"title": "A Hybrid Algorithm for Multi-objective Test Case Selection in Regression Testing\n", "abstract": " Testing is crucial to ensure the quality of software systems\u2013but testing is an expensive process, so test managers try to minimise the set of tests to run to save computing resources and speed up the testing process and analysis. One problem is that there are different perspectives on what is a good test and it is usually not possible to compare these dimensions. This is a perfect example of a multi-objective optimisation problem, which is hard\u2014especially given the scale of the search space here. In this paper, we propose a novel hybrid algorithm to address this problem. Our method is composed of three steps: a greedy algorithm to find quickly some good solutions, a genetic algorithm to increase the search space covered and a local search algorithm to refine the solutions. We demonstrate through a large scale empirical evaluation that our method is more reliable (better whatever the time budget) and more robust (better whatever the number of dimensions considered)\u2013in the scenario with 4 objectives and a default execution time, we are 268% better in hypervolume on average than the state-of-the-art algorithms.", "num_citations": "14\n", "authors": ["550"]}
{"title": "Killing Stubborn Mutants with Symbolic Execution\n", "abstract": " Thorough testing is often required in order to assess the core logic and the \u2018critical\u2019parts of the programs under analysis. Unfortunately, performing thorough testing is hard, tedious and time consuming.To support thorough testing, mutation testing aims at guiding the design of test cases that are likely fault revealing. The key idea of mutation is to use artificially introduced defects, called mutations, to identify untested (or weakly tested) cases and to guide test generation. Thus, testers can improve their test suites by designing mutation-based test cases, ie, test that reveal the artificially introduced defects.", "num_citations": "13\n", "authors": ["550"]}
{"title": "Testing delegation policy enforcement via mutation analysis\n", "abstract": " Delegation is an important dimension of security that plays a crucial role in the administration mechanism of access control policies. Delegation may be viewed as an exception made to an access control policy in which a user gets right to act on behalf of other users. This meta-level characteristic together with the complexity of delegation itself make it crucial to ensure the correct enforcement and management of delegation policy in a system via testing. To this end, we adopt mutation analysis for delegation policies. In order to achieve this, a set of mutant operators specially designed for introducing mutants into the key components (features) of delegation is proposed. Our approach consists of analyzing the representation of the key components of delegation, based on which we derive the suggested set of mutant operators. These operators can then be used to introduce mutants into delegation policies and thus\u00a0\u2026", "num_citations": "13\n", "authors": ["550"]}
{"title": "Special issue on mutation testing\n", "abstract": " Special issue on Mutation Testing | Information and Software Technology ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Information and Software Technology Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsInformation and Software TechnologyVol. , No. CSpecial issue on Mutation Testing research-article Special issue on Mutation Testing Share on Authors: Mike Papadakis profile image Mike Papadakis Interdisciplinary Centre for Security, Reliability and Trust, Luxembourg University, Luxembourg Interdisciplinary Centre for Security, Reliability and Trust, Luxembourg University, Luxembourg View Profile , Ren\u00e9 Just profile image Ren\u00e9 Just \u2026", "num_citations": "5\n", "authors": ["550"]}
{"title": "Statistical Model Checking for Variability-Intensive Systems.\n", "abstract": " We propose a new Statistical Model Checking (SMC) method to discover bugs in variability-intensive systems (VIS). The state-space of such systems is exponential in the number of variants, which makes the verification problem harder than for classical systems. To reduce verification time, we sample executions from a featured transition system\u2013a model that represents jointly the state spaces of all variants. The combination of this compact representation and the inherent efficiency of SMC allows us to find bugs much faster (up to 16 times according to our experiments) than other methods. As any simulation-based approach, however, the risk of Type-1 error exists. We provide a lower bound and an upper bound for the number of simulations to perform to achieve the desired level of confidence. Our empirical study involving 59 properties over three case studies reveals that our method manages to discover all variants violating 41 of the properties. This indicates that SMC can act as a low-cost-high-reward method for verifying VIS.", "num_citations": "3\n", "authors": ["550"]}