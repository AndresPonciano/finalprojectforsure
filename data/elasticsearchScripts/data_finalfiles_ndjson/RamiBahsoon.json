{"title": "A decentralized self-adaptation mechanism for service-based applications in the cloud\n", "abstract": " Cloud computing, with its promise of (almost) unlimited computation, storage, and bandwidth, is increasingly becoming the infrastructure of choice for many organizations. As cloud offerings mature, service-based applications need to dynamically recompose themselves to self-adapt to changing QoS requirements. In this paper, we present a decentralized mechanism for such self-adaptation, using market-based heuristics. We use a continuous double-auction to allow applications to decide which services to choose, among the many on offer. We view an application as a multi-agent system and the cloud as a marketplace where many such applications self-adapt. We show through a simulation study that our mechanism is effective for the individual application as well as from the collective perspective of all applications adapting at the same time.", "num_citations": "125\n", "authors": ["559"]}
{"title": "Cloud adoption: a goal-oriented requirements engineering approach\n", "abstract": " We motivate the need for a new requirements engineering methodology for systematically helping businesses and users to adopt cloud services and for mitigating risks in such transition. The methodology is grounded in goal oriented approaches for requirements engineering. We argue that Goal Oriented Requirements Engineering (GORE) is a promising paradigm to adopt for goals that are generic and flexible statements of users' requirements, which could be refined, elaborated, negotiated, mitigated for risks and analysed for economics considerations. We describe the steps of the proposed process and exemplify the use of the methodology through an example. The methodology can be used by small to large scale organisations to inform crucial decisions related to cloud adoption.", "num_citations": "106\n", "authors": ["559"]}
{"title": "Microservices and their design trade-offs: A self-adaptive roadmap\n", "abstract": " Migrating to microservices (microservitization) enables optimising the autonomy, replaceability, decentralised governance and traceability of software architectures. Despite the hype for microservitization , the state of the art still lacks consensus on the definition of microservices, their properties and their modelling techniques. This paper summarises views of microservices from informal literature to reflect on the foundational context of this paradigm shift. A strong foundational context can advance our understanding of microservitization and help guide software architects in addressing its design problems. One such design problem is finalising the optimal level of granularity of a microservice architecture. Related design trade-offs include: balancing the size and number of microservices in an architecture and balancing the nonfunctional requirement satisfaction levels of the individual microservices as well as their\u00a0\u2026", "num_citations": "101\n", "authors": ["559"]}
{"title": "A systematic review of service level management in the cloud\n", "abstract": " Cloud computing make it possible to flexibly procure, scale, and release computational resources on demand in response to workload changes. Stakeholders in business and academia are increasingly exploring cloud deployment options for their critical applications. One open problem is that service level agreements (SLAs) in the cloud ecosystem are yet to mature to a state where critical applications can be reliably deployed in clouds. This article systematically surveys the landscape of SLA-based cloud research to understand the state of the art and identify open problems. The survey is particularly aimed at the resource allocation phase of the SLA life cycle while highlighting implications on other phases. Results indicate that (i) minimal number of SLA parameters are accounted for in most studies; (ii) heuristics, policies, and optimisation are the most commonly used techniques for resource allocation; and (iii) the\u00a0\u2026", "num_citations": "65\n", "authors": ["559"]}
{"title": "Evaluating software architectures: Development stability and evolution\n", "abstract": " We survey seminal work on software architecture evaluation methods. We then look at an emerging class of methods that explicates evaluating software architectures for stability and evolution. We define architectural stability and formulate the problem of evaluating software architectures for stability and evolution. We draw the attention on the use of Architectures Description Languages (ADLs) for supporting the evaluation of software architectures in general and for architectural stability in specific.", "num_citations": "63\n", "authors": ["559"]}
{"title": "Self-adaptive and sensitivity-aware QoS modeling for the cloud\n", "abstract": " Given the elasticity, dynamicity and on-demand nature of the cloud, cloud-based applications require dynamic models for Quality of Service (QoS), especially when the sensitivity of QoS tends to fluctuate at runtime. These models can be autonomically used by the cloud-based application to correctly self-adapt its QoS provision. We present a novel dynamic and self-adaptive sensitivity-aware QoS modeling approach, which is fine-grained and grounded on sound machine learning techniques. In particular, we combine symmetric uncertainty with two training techniques: Auto-Regressive Moving Average with eXogenous inputs model (ARMAX) and Artificial Neural Network (ANN) to reach two formulations of the model. We describe a middleware for implementing the approach. We experimentally evaluate the effectiveness of our models using the RUBiS benchmark and the FIFA 1998 workload trends. The results\u00a0\u2026", "num_citations": "59\n", "authors": ["559"]}
{"title": "EPiCS: Engineering proprioception in computing systems\n", "abstract": " Modern compute systems continue to evolve towards increasingly complex, heterogeneous and distributed architectures. At the same time, functionality and performance are no longer the only aspects when developing applications for such systems, and additional concerns such as flexibility, power efficiency, resource usage, reliability and cost are becoming increasingly important. This does not only raise the question of how to efficiently develop applications for such systems, but also how to cope with dynamic changes in the application behaviour or the system environment. The EPiCS Project aims to address these aspects through exploring self-awareness and self-expression. Self-awareness allows systems and applications to gather and maintain information about their current state and environment, and reason about their behaviour. Self-expression enables systems to adapt their behaviour autonomously to\u00a0\u2026", "num_citations": "59\n", "authors": ["559"]}
{"title": "Measuring performance of virtual learning environment system in higher education\n", "abstract": " Purpose \u2013 The purpose of this paper is to measure the performance of commercial virtual learning environment (VLE) systems, which helps the decision makers to select the appropriate system for their institutions.Design/methodology/approach \u2013 This paper develops an integrated multiple criteria decision making approach, which combines the analytic hierarchy process (AHP) and quality function deployment (QFD), to evaluate and select the best system. The evaluating criteria are derived from the requirements of those who use the system. A case study is provided to demonstrate how the integrated approach works.Findings \u2013 The major advantage of the integrated approach is that the evaluating criteria are of interest to the stakeholders. This ensures that the selected system will achieve the requirements and satisfy the stakeholders most. Another advantage is that the approach can guarantee the benchmarking to\u00a0\u2026", "num_citations": "53\n", "authors": ["559"]}
{"title": "Performance modelling and verification of cloud-based auto-scaling policies\n", "abstract": " Auto-scaling, a key property of cloud computing, allows application owners to acquire and release resources on demand. However, the shared environment, along with the exponentially large configuration space of available parameters, makes the configuration of auto-scaling policies a challenging task. In particular, it is difficult to quantify, a priori, the impact of a policy on Quality of Service (QoS) provision. To address this problem, we propose a novel approach based on performance modelling and formal verification to produce performance guarantees on particular rule-based auto-scaling policies. We demonstrate the usefulness and efficiency of our techniques through a detailed validation process on two public cloud providers, Amazon EC2 and Microsoft Azure, targeting two cloud computing models, Infrastructure as a Service (IaaS) and Platform as a Service (PaaS), respectively. Our experimental results show\u00a0\u2026", "num_citations": "50\n", "authors": ["559"]}
{"title": "Self-adaptive and online qos modeling for cloud-based software services\n", "abstract": " In the presence of scale, dynamism, uncertainty and elasticity, cloud software engineers faces several challenges when modeling Quality of Service (QoS) for cloud-based software services. These challenges can be best managed through self-adaptivity because engineers' intervention is difficult, if not impossible, given the dynamic and uncertain QoS sensitivity to the environment and control knobs in the cloud. This is especially true for the shared infrastructure of cloud, where unexpected interference can be caused by co-located software services running on the same virtual machine; and co-hosted virtual machines within the same physical machine. In this paper, we describe the related challenges and present a fully dynamic, self-adaptive and online QoS modeling approach, which grounds on sound information theory and machine learning algorithms, to create QoS model that is capable to predict the QoS\u00a0\u2026", "num_citations": "50\n", "authors": ["559"]}
{"title": "Empirical comparison of regression test selection algorithms\n", "abstract": " In the maintenance phase, the regression test selection problem refers to selecting test cases from the initial suite of test cases used in the development phase. In this paper, we empirically compare five representative regression test selection algorithms, which include: Simulated Annealing, Reduction, Slicing, Dataflow, and Firewall algorithms. The comparison is based on eight quantitative and qualitative criteria. These criteria are: number of selected test cases, execution time, precision, inclusiveness, preprocessing requirements, type of maintenance, level of testing, and type of approach. The empirical results show that the five algorithms can be used for different requirements of regression testing. For example the Simulated Annealing algorithm can be used for emergency non-safety-critical maintenance situations with a large number of small modifications.", "num_citations": "48\n", "authors": ["559"]}
{"title": "Evaluating architectural stability with real options theory\n", "abstract": " Architectural stability refers to the extent to which a software architecture is flexible enough to respond to changes in stakeholders' requirements and the environment. We contribute to a model that exploits options theory to evaluate architectural stability. We describe how we have derived the model: the analogy and assumptions made; its formulation and possible interpretations. We use a refactoring case study to empirically evaluate the model. The results show that the model can provide insights into architectural stability and investment decisions related to the evolution of software systems.", "num_citations": "47\n", "authors": ["559"]}
{"title": "Using real options to select stable middleware-induced software architectures\n", "abstract": " The requirements that force decisions towards building distributed system architectures are usually of a non-functional nature. Scalability, openness, heterogeneity, and fault-tolerance are examples of such non-functional requirements. The current trend is to build distributed systems with middleware, which provide the application developer with primitives for managing the complexity of distribution, system resources, and for realising many of the non-functional requirements. As non-functional requirements evolve, the 'coupling' between the middleware and architecture becomes the focal point for understanding the stability of the distributed software system architecture in the face of change. It is hypothesised that the choice of a stable distributed software architecture depends on the choice of the underlying middleware and its flexibility in responding to future changes in non-functional requirements. Drawing on a\u00a0\u2026", "num_citations": "43\n", "authors": ["559"]}
{"title": "Self-adaptive trade-off decision making for autoscaling cloud-based services\n", "abstract": " Elasticity in the cloud is often achieved by on-demand autoscaling. In such context, the goal is to optimize the Quality of Service (QoS) and cost objectives for the cloud-based services. However, the difficulty lies in the facts that these objectives, e.g., throughput and cost, can be naturally conflicted; and the QoS of cloud-based services often interfere due to the shared infrastructure in cloud. Consequently, dynamic and effective trade-off decision making of autoscaling in the cloud is necessary, yet challenging. In particular, it is even harder to achieve well-compromised trade-offs, where the decision largely improves the majority of the objectives; while causing relatively small degradations to others. In this paper, we present a self-adaptive decision making approach for autoscaling in the cloud. It is capable to adaptively produce autoscaling decisions that lead to well-compromised trade-offs without heavy human\u00a0\u2026", "num_citations": "42\n", "authors": ["559"]}
{"title": "Symbiotic and sensitivity-aware architecture for globally-optimal benefit in self-adaptive cloud\n", "abstract": " Due to the uncertain and dynamic demand for Quality of Service (QoS) in cloud-based systems, engineering self-adaptivity in cloud architectures require novel approaches to support on-demand elasticity. The architecture should dynamically select an elastic strategy, which optimizes the global benefit for QoS and cost objectives for all cloud-based services. The architecture shall also provide mechanisms for reaching the strategy with minimal overhead. However, the challenge in the cloud is that the nature of objectives (eg, throughput and the required cost) and QoS interference could cause overlapping sensitivity amongst intra-and inter-services objectives, which leads to objective-dependency (ie, conflicted or harmonic) during optimization. In this paper, we propose a symbiotic and sensitivity-aware architecture for optimizing global-benefit with reduced overhead in the cloud. The architecture dynamically\u00a0\u2026", "num_citations": "42\n", "authors": ["559"]}
{"title": "Archoptions: A real options-based model for predicting the stability of software architectures\n", "abstract": " Architectural stability refers to the extent an architecture is flexible to endure evolutionary changes in stakeholders\\' requirements and the environment. We assume that the primary goal of software architecture is to guide the system\\'s evolution. We contribute to a novel model that exploits options theory to predict architectural stability. The model is predictive: it provides \\\"insights\\\" on the evolution of the software system based on valuing the extent an architecture can endure a set of likely evolutionary changes. The model builds on Black and Scholes financial options theory (Noble Prize wining) to value such extent. We show how we have derived the model: the analogy and assumptions made to reach the model, its formulation, and possible interpretations. We refer to this model as ArchOptions.", "num_citations": "41\n", "authors": ["559"]}
{"title": "CloudMTD: Using real options to manage technical debt in cloud-based service selection\n", "abstract": " In cloud marketplace, cloud-based system architectures can be composed of web services, which are leased or bought off the cloud. These architectures can add value to its composition by switching and substituting its constituent services. The value-added can relate to improved Quality of Service (QoS), new revenue streams by enabling new business models, reduced operational cost and so forth. The selection and substitution decisions may introduce a technical debt, however. We specifically look at the debt of substitution decisions in support for scaling up scenarios. This debt may need to be managed, cleared and transformed to value-added. We take an option-based approach to inform the selection of candidate web services with varying debt. For every selection, we quantify the extent to which it can clear the debt and provide future options.", "num_citations": "36\n", "authors": ["559"]}
{"title": "Predicting and quantifying the technical debt in cloud software engineering\n", "abstract": " Identifying and managing effectively the Technical Debt has become an issue of great importance over recent years. In cloud marketplaces, where the cloud services can be leased, the difficulty to promptly predict and manage the Technical Debt has a significant impact. In this paper, we examine the Technical Debt, which stems from budget constraints during the software development process as well as the capacity of a cloud service. In this context, the budget and the cloud service selection decisions may introduce Technical Debt. Towards reaching a conclusion, two approaches are taken into consideration. Initially, a cost estimation approach is researched, which is related to implementing Software as a Service (SaaS) in the cloud for three scenarios aiming to predict the incurrence of the Technical Debt in the future. The Constructive Cost Model (COCOMO) is exploited, in order to estimate the implementation\u00a0\u2026", "num_citations": "31\n", "authors": ["559"]}
{"title": "A dynamic data-driven simulation approach for preventing service level agreement violations in cloud federation\n", "abstract": " The new possibility of accessing an infinite pool of computational resources at a drastically reduced price has made cloud computing popular. With the increase in its adoption and unpredictability of workload, cloud providers are faced with the problem of meeting their service level agreement (SLA) claims as demonstrated by large vendors such as Amazon and Google. Therefore, users of cloud resources are embracing the more promising cloud federation model to ensure service guarantees. Here, users have the option of selecting between multiple cloud providers and subsequently switching to a more reliable one in the event of a provider's inability to meet its SLA. In this paper, we propose a novel dynamic data-driven architecture capable of realising resource provision in a cloud federation with minimal SLA violations. We exemplify the approach with the aid of case studies to demonstrate its feasibility.", "num_citations": "31\n", "authors": ["559"]}
{"title": "Scalable service-oriented replication with flexible consistency guarantee in the cloud\n", "abstract": " Replication techniques are widely applied in and for cloud to improve scalability and availability. In such context, the well-understood problem is how to guarantee consistency amongst different replicas and govern the trade-off between consistency and scalability requirements. Such requirements are often related to specific services and can vary considerably in the cloud. However, a major drawback of existing service-oriented replication approaches is that they only allow either restricted consistency or none at all. Consequently, service-oriented systems based on such replication techniques may violate consistency requirements or not scale well. In this paper, we present a Scalable Service Oriented Replication (SSOR) solution, a middleware that is capable of satisfying applications\u2019 consistency requirements when replicating cloud-based services. We introduce new formalism for describing services in service\u00a0\u2026", "num_citations": "30\n", "authors": ["559"]}
{"title": "Design of a market-based mechanism for quality attribute tradeoff of services in the cloud\n", "abstract": " Cloud computing, with its promise of (almost) unlimited computation, storage and bandwidth, is increasingly becoming the infrastructure of choice for many organizations. As applications gain in popularity and mature, the quality attributes demanded of them change significantly. Applications that manage themselves and exhibit different quality attributes, based on demand, are the ideal that we would like to have. Creating self-managing applications for the cloud present significant problems, since the cloud infrastructure is not under the application architect's control. We propose an initial design of novel market-based mechanism to allow web-applications living on the cloud to self-manage with regard to their quality attributes. We use a scenario to exemplify and evaluate the approach.", "num_citations": "29\n", "authors": ["559"]}
{"title": "Dynamic QoS optimization architecture for cloud-based DDDAS\n", "abstract": " An emerging class of Dynamic Data Driven application systems heavily depends on cloud and Big Data. We refer to this class of DDDAS as cloud-based DDDAS. Despite the growing interest in marrying DDDAS with the cloud, there is a general lack for architectural frameworks explicating the cloud requirements, which can support cloud-based DDDAS. Given the unpredictable, dynamic and on-demand nature of the cloud, cloud-based DDDAS requires novel approaches for dynamic Quality of Service (QoS) optimization. This is important for providing timely and reliable predictions and for ensuring higher dependability in the solution, as it would be unrealistic to assume that optimal QoS can be achieved at design time. We propose a decentralized architectural style for cloud-based DDDAS, where dynamic QoS optimization is in the heart of the symbiotic adaptation. The architecture leverages on the classical\u00a0\u2026", "num_citations": "28\n", "authors": ["559"]}
{"title": "Using implied scenarios in security testing\n", "abstract": " Existing security testing techniques often fail to reveal critical security threats, partly because testers focus on testing known and expected behaviours, and consequently, ignore testing for unspecified behaviours that are frequently targeted by attackers. The novel contribution of this paper is an exploratory example of the use of Implied Scenarios detection to the problem of security testing. Implied scenarios arise when the desired global behaviour is implemented component-wise. These scenarios can have security consequences on the system, and thus provide useful feedback for the security posture of the system.", "num_citations": "26\n", "authors": ["559"]}
{"title": "Data allocation mechanism for Internet-of-Things systems with blockchain\n", "abstract": " The use of Internet of Things (IoT) has introduced genuine concerns regarding data security and its privacy when data are in collection, exchange, and use. Meanwhile, blockchain offers a distributed and encrypted ledger designed to allow the creation of immutable and tamper-proof records of data at different locations. While blockchain may enhance IoT with innate security, data integrity, and autonomous governance, IoT data management and its allocation in blockchain still remain an architectural concern. In this article, we propose a novel context-aware mechanism for on-chain data allocation in IoT-blockchain systems. Specifically, we design a data controller based on fuzzy logic to calculate the Rating of Allocation (RoA) value of each data request considering multiple context parameters, i.e., data, network, and quality and decide its on-chain allocation. Furthermore, we illustrate how the design and realization\u00a0\u2026", "num_citations": "25\n", "authors": ["559"]}
{"title": "Relating system quality and software architecture\n", "abstract": " System Quality and Software Architecture collects state-of-the-art knowledge on how to intertwine software quality requirements with software architecture and how quality attributes are exhibited by the architecture of the system. Contributions from leading researchers and industry evangelists detail the techniques required to achieve quality management in software architecting, and the best way to apply these techniques effectively in various application domains (especially in cloud, mobile and ultra-large-scale/internet-scale architecture) Taken together, these approaches show how to assess the value of total quality management in a software development process, with an emphasis on architecture. The book explains how to improve system quality with focus on attributes such as usability, maintainability, flexibility, reliability, reusability, agility, interoperability, performance, and more. It discusses the importance of clear requirements, describes patterns and tradeoffs that can influence quality, and metrics for quality assessment and overall system analysis. The last section of the book leverages practical experience and evidence to look ahead at the challenges faced by organizations in capturing and realizing quality requirements, and explores the basis of future work in this area. Explains how design decisions and method selection influence overall system quality, and lessons learned from theories and frameworks on architectural quality Shows how to align enterprise, system, and software architecture for total quality Includes case studies, experiments, empirical validation, and systematic comparisons with other approaches already in practice.", "num_citations": "24\n", "authors": ["559"]}
{"title": "Evaluating security properties of architectures in unpredictable environments: A case for cloud\n", "abstract": " The continuous evolution and unpredictability underlying service-based systems leads to difficulties in making exact QoS claims about the dependability of architectures interfacing with them. Hence, there is a growing need for new methods to evaluate the dependability of architectures interfacing with such environments. This paper presents a method for evaluating the security quality attribute of architectures in service-based systems. The proposed method combines some properties of the Architectural Tradeoff Analysis Method (ATAM) and security testing using Implied Scenario. In particular, the scenario elicitation process of ATAM is improved by utilising Implied Scenario technique to generate scenarios which may be undetected using plain ATAM. An industrial case study of a problem related to securing data at the Software-as-a-Service layer on Force.com Cloud platform is adopted to validate the new method\u00a0\u2026", "num_citations": "23\n", "authors": ["559"]}
{"title": "Microservice transition and its granularity problem: A systematic mapping study\n", "abstract": " Microservices have gained wide recognition and acceptance in software industries as an emerging architectural style for autonomic, scalable, and more reliable computing. The transition to microservices has been highly motivated by the need for better alignment of technical design decisions with improving value potentials of architectures. Despite microservices' popularity, research still lacks disciplined understanding of transition and consensus on the principles and activities underlying that transition. In this paper, we report on a systematic mapping study that consolidates various views, approaches and activities that commonly assist in the transition to microservices. The study aims to provide a better understanding of the transition; it also contributes a working definition of the transition and technical activities underlying it. We term the transition and technical activities leading to microservice architectures as\u00a0\u2026", "num_citations": "20\n", "authors": ["559"]}
{"title": "Multi-tenant cloud service composition using evolutionary optimization\n", "abstract": " In Software as a Service (SaaS)cloud marketplace, several functionally equivalent services tend to be available with different Quality of Service (QoS)values. For processing end-users multi-dimensional QoS and functional requirements, the application engineers are required to choose suitable services and optimize the service composition plans for each category of users. However, existing approaches for dynamic services composition tend to support execution plans that search for service provisions of equivalent functionalities with varying QoS or cost constraints to meet the tenants' QoS requirements or to dynamically respond to changes in QoS. These approaches tend to ignore the fact that multi-tenant execution plans need to provide variant execution plans, each offering a customized plan for a given tenant with its functionality, QoS and cost requirements. Henceforth, the dynamic selection and composition of\u00a0\u2026", "num_citations": "20\n", "authors": ["559"]}
{"title": "Self-adaptive resource management system in iaas clouds\n", "abstract": " Resource management in cloud infrastructures is one of the most challenging problems due to the heterogeneity of resources, variability of the workload and scale of data centers. Efficient management of physical and virtual resources can be achieved considering performance requirements of hosted applications and infrastructure costs. In this paper, we present a self-adaptive resource management system based on a hierarchical multi-agent based architecture. The system uses novel adaptive utilization threshold mechanism and benefits from reinforcement learning technique to dynamically adjust CPU and memory thresholds for each Physical Machine (PM). It periodically runs a Virtual Machine (VM) placement optimization algorithm to keep the total resource utilization of each PM within given thresholds for improving Service Level Agreement (SLA) compliance. More-over, the algorithm consolidates VMs into\u00a0\u2026", "num_citations": "20\n", "authors": ["559"]}
{"title": "Cloud adoption: Prioritizing obstacles and obstacles resolution tactics using AHP\n", "abstract": " The enormous potential of cloud computing for improved and cost-effective service has generated unprecedented interest in its adoption. However, a potential cloud user faces numerous risks regarding service requirements, cost implications of failure and uncertainty about cloud providers' ability to meet service level agreements. These risks hinder the adoption of cloud. We extend the work on goal-oriented requirements engineering (GORE) and obstacles for informing the adoption process. We argue that obstacles prioritisation and their resolution is core to mitigating risks in the adoption process. We propose a novel systematic method for prioritising obstacles and their resolution tactics using Analytical Hierarchy Process (AHP). We provide an example to demonstrate the applicability and effectiveness of the approach. To assess the AHP choice of the resolution tactics we support the method by stability and\u00a0\u2026", "num_citations": "20\n", "authors": ["559"]}
{"title": "A framework for dynamic self-optimization of power and dependability requirements in green cloud architectures\n", "abstract": " I report on the activities and research challenges, their rationales, and the work in progress related to the ongoing EPSRC/UoB Bridging the Gap Fellowship project on Green Cloud Architectures. The initiative is aimed at a framework for dynamic self-optimization of cloud architectures taking into account the tradeoffs involved in maintaining acceptable dependability requirements/ Quality of Service (QoS) with minimal power at runtime. I argue that linkage between dependability requirements and power should be explicit. I motivate the need for new meters for Power-per-QoS value (and sacrifices) for cloud architectures. I motivate the need for an economics-inspired approach for dynamic self-optimization of cloud architectures. I discuss the role of Data Driven Simulation Systems in implementing such framework.", "num_citations": "20\n", "authors": ["559"]}
{"title": "Minimizing nasty surprises with better informed decision-making in self-adaptive systems\n", "abstract": " Designers of self-adaptive systems often formulate adaptive design decisions, making unrealistic or myopic assumptions about the system's requirements and environment. The decisions taken during this formulation are crucial for satisfying requirements. In environments which are characterized by uncertainty and dynamism, deviation from these assumptions is the norm and may trigger \"surprises\". Our method allows designers to make explicit links between the possible emergence of surprises, risks and design trade-offs. The method can be used to explore the design decisions for self-adaptive systems and choose among decisions that better fulfil (or rather partially fulfil) non-functional requirements and address their trade-offs. The analysis can also provide designers with valuable input for refining the adaptation decisions to balance, for example, resilience (i.e. Satisfiability of non-functional requirements and\u00a0\u2026", "num_citations": "19\n", "authors": ["559"]}
{"title": "Evaluating technical debt in cloud-based architectures using real options\n", "abstract": " A Cloud-based Service-Oriented Architecture (CBSOA) is typically composed of web services, which are offered off the cloud marketplace. CB-SOA can improve its utility and add value to its composition by switching among its constituent services. We look at the option to defer the decision of substitution under uncertainty. We exploit Binomial Options to the formulation. We quantify the time-value of the architecture decisions of switching web services and technical debt they can imply on the structure. As CB-SOA are market-sensitive, dynamic and \"volatile\", the decision of deferral tends to be sensitive to these dynamics. Henceforth, the structural complexity of a CB-SOAcan change over time and so the technical debt as its constituent web services are modified, replaced, upgraded, etc. The method builds on Design Structure Matrix (DSM) and introduces time and complexity aware propagation cost metrics to assess\u00a0\u2026", "num_citations": "18\n", "authors": ["559"]}
{"title": "Secarch: Architecture-level evaluation and testing for security\n", "abstract": " We propose a novel approach that merges implied scenarios and race condition analysis techniques, to systematically detect and analyse security-related vulnerabilities at the architectural level. We apply our approach to an industrial case related to architecting systems interfacing the cloud. The application demonstrates an effective use of the approach, where the approach has detected securityrelated vulnerabilities in the architecture due to unexpected modes of interactions in such environment. Our approach was able to guide testers to detect critical security scenarios, which were not perceived during the inception phases or not captured using either of implied scenarios or race conditions detection techniques alone. We reflect on its applicability and scalability. We look into possible usage scenarios related to architectural-level testing for security and incremental refinements of the architecture following the\u00a0\u2026", "num_citations": "18\n", "authors": ["559"]}
{"title": "Evaluating software architectures for stability: A real options approach\n", "abstract": " Architectural stability refers to the extent an architecture is flexible to endure evolutionary changes in stakeholders\u2019 requirements and the environment, while leaving the architecture intact. In an evolutionary context, there is a pressing need for stable software architectures. In this context, requirements are generally volatile; they are likely to change and evolve over time. The change is inevitable as it reflects changes in stakeholders\u2019 needs and the environment in which the software system works. The tension between an unstable architecture and the volatile requirements may entail large and disruptive changes for the requirements to be accommodated. The change may \u201cbreak\u201d the architecture necessitating changes to the architectural structure (eg changes to components and interfaces), architectural topology (eg architectural style, where a style is a generic description of a software architecture), or even changes to the underlying architectural infrastructure (eg middleware). It may be expensive and difficult to change the architecture as requirements evolve [6]. Consequently, failing to accommodate the change leads ultimately to the degradation of the usefulness and the value of the system. From an economic perspective, the volatility of requirements is a source of uncertainty that places the long-term investment in a particular architecture at risk. If the business goal that the system should be long-lived, should evolve to accommodate future changes, and should create future value, stability becomes an important architectural quality to evaluate an architecture for. The evaluation is necessary to cope with the incomplete knowledge in an\u00a0\u2026", "num_citations": "18\n", "authors": ["559"]}
{"title": "Toward a smarter cloud: Self-aware autoscaling of cloud configurations and resources\n", "abstract": " Promoting self-aware autoscaling to intelligently handle the dynamics and uncertainty of changing workloads, configurations, and demands on resources at runtime can facilitate more scalable, elastic, and dependable cloud-based services.", "num_citations": "17\n", "authors": ["559"]}
{"title": "Systematic elaboration of compliance requirements using compliance debt and portfolio theory\n", "abstract": " [Context and motivation] Eliciting compliance requirements often results in requirements, which might not be satisfied due to uncertainty and unavailability of resources. The lack of anticipation of these factors may increase the cost of achieving compliance. [Question/problem] Managing compliance is an investment activity that requires making decisions about selecting the right compliance goals under uncertainty, handling the obstacles to those goals and minimising risks. [Principal ideas/results] (1) We define the concept of technical debt for managing compliance and we explore its link with obstacles to compliance goals. (2) We propose goal-oriented method and obstacles handling with a portfolio-based thinking for systematically managing obstacles and refining compliance goals. [Contribution]We use an exemplar to illustrate and evaluate the approach. The results show that our approach can\u00a0\u2026", "num_citations": "17\n", "authors": ["559"]}
{"title": "Conceptual framework for dynamic trust monitoring and prediction\n", "abstract": " The dynamic and collaborative nature of mobile and sensor networks raises the issue of how connected mobile devices can be trusted. Despite the existing security paradigms such as cryptographic mechanisms, and reputation and trust models, the assurance of security remains a problem of such environments. These networks have been plagued with internal security issues such as the presence of untrusted nodes that misbehave. Depending on the proportion of misbehaving nodes and their strategies, attacks such as collusions may occur. By covering up malicious behaviour of one another from the remaining part of the network, two or more malicious nodes may collaborate to cause damage to or disrupt the network. The concept of the Dynamic Data-Driven Application Systems paradigm has been suggested for use in diverse fields. This paper proposes a novel framework that utilises the paradigm in the area of\u00a0\u2026", "num_citations": "17\n", "authors": ["559"]}
{"title": "Interschema correspondence establishment in a cooperative OWL-based multi-information server grid environment\n", "abstract": " Establishing interschema semantic knowledge between corresponding elements in a cooperating OWL-based multi-information server grid environment requires deep knowledge, not only about the structure of the data represented in each server, but also about the commonly occurring differences in the intended semantics of this data. The same information could be represented in various incompatible structures, and more importantly the same structure could be used to represent data with many diverse and incompatible semantics. In a grid environment interschema semantic knowledge can only be detected if both the structural and semantic properties of the schemas of the cooperating servers are made explicit and formally represented in a way that a computer system can process. Unfortunately, very often there is lack of such knowledge and the underlying grid information servers (ISs) schemas, being\u00a0\u2026", "num_citations": "17\n", "authors": ["559"]}
{"title": "Applying ArchOptions to value the payoff of refactoring\n", "abstract": " ArchOptions is a real-options based model that we have proposed [R. Bahsoon et al. (2003)] to value the flexibility of software architectures in response to future changes in requirements. We build on ArchOptions to devise an options-based model, which values the architectural flexibility that results from a refactoring exercise. This value assists in understanding the payoff of investing in refactoring: if the refactored system results in an architecture that is more flexible, such that the expected added value (in the form of options) due to the enhanced flexibility outweighs the cost of investing in this exercise, then refactoring is said to payoff. We apply our model to a refactoring case study from the literature.", "num_citations": "17\n", "authors": ["559"]}
{"title": "Engineering proprioception in SLA management for cloud architectures\n", "abstract": " With the wide adoption of the Cloud, there remains an open challenge to provide more dependable, transparent, and trustworthy provision of services. Service terms are typically defined in the Service Level Agreement (SLA) binding both service providers and users. For the service user, there is a need to ensure that s/he is enjoying the agreed level of service and any violations are reported accordingly. For the service provider, there is a need to manage a resilient infrastructure capable of meeting SLA terms and inform strategies for maximising profit and resource utilisation. The massive size, dynamism and unpredictability of Cloud architectures makes these goals difficult to accomplish using classic Service Level Management (SLM) approaches. In this paper, we motivate the need for novel dynamic and decentralised approaches for the design of SLM. Requirements and key design decisions for the new SLM are\u00a0\u2026", "num_citations": "16\n", "authors": ["559"]}
{"title": "Reduction-based methods and metrics for selective regression testing\n", "abstract": " In corrective maintenance, modified software is regression tested using selected test cases in order to ensure that the modifications have not caused adverse effects. This activity of selective regression testing involves regression test selection, which refers to selecting test cases from the previously run test suite, and test-coverage identification. In this paper, we propose three test-selection methods and two coverage identification metrics. The three methods aim to reduce the number of selected test cases for retesting the modified software. The first method, referred to as modification-based reduction version 1 (MBR1), selects a reduced number of test cases based on the modification made and its effects in the software. The second method, referred to as modification-based reduction version 2 (MBR2) improves MBR1 by further omitting tests that do not cover the modification. The third method, referred to as precise\u00a0\u2026", "num_citations": "16\n", "authors": ["559"]}
{"title": "Managing trade-offs in self-adaptive software architectures: A systematic mapping study\n", "abstract": " Self-adaptation has been driven by the need to achieve and maintain quality attributes in the face of the continuously changing requirements, as well as the uncertain demand during run-time. Designing architectures that exhibit a good trade-off between multiple quality attributes is challenging, especially in the case of self-adaptive software systems, due to the complexity, heterogeneity, and ultra-large scale of modern software systems. This challenge increases with the dynamic, open, and uncertain operating environment, as well as the need for complying to environmental, regulatory, and sustainability requirements; such as energy consumption regulations. This study aims at analyzing the research landscape that have explicitly addressed trade-offs management for self-adaptive software architectures, to obtain a comprehensive overview on the current state of research on this specialized area.A systematic\u00a0\u2026", "num_citations": "15\n", "authors": ["559"]}
{"title": "Trust dynamics: a data-driven simulation approach\n", "abstract": " Reputation and trust-based models have gained popularity recently because they have been shown to be promising in the area of trust management. Despite this fact, building reliable systems still remains a challenge. Proposed models focus on historical and online information to determine the reputation of domain members. However, the dynamic nature of reputation and trust requires an equally dynamic approach to computing and resolving trust related issues in any domain. This paper proposes a reliable and novel dynamic framework that utilises a data-driven approach for trust management. The framework uses past interactions, recent and anticipated future trust values of every identity in the domain. The proposed framework is critically evaluated and compared with existing work through experiments. The advantage of this proactive framework compared to other approaches is that informed\u00a0\u2026", "num_citations": "15\n", "authors": ["559"]}
{"title": "An economics-driven approach for valuing scalability in distributed architectures\n", "abstract": " Drawing on a case study that adequately represents a medium-size component-based distributed architecture, the contribution of this paper shows how existing performance repositories could be mined to value the ranges in which a given software architecture can scale to support likely changes in load. The mining is based on a financial analogy, where we utilize the concept of twin asset in financial engineering to justify mining relevant repositories. The mining process in then complemented with real options analysis for predicting the values resulted from the ranges in which an architecture can scale under uncertainty, where uncertainty is attributed to the unpredicted change in load. As the exact method for analyzing scalability is subject to debate, we focus the analysis on throughput as a way for measuring scalability. Using options analysis, we report on how ranges in which an architecture can scale, can inform\u00a0\u2026", "num_citations": "15\n", "authors": ["559"]}
{"title": "ThermoSim: Deep learning based framework for modeling and simulation of thermal-aware resource management for cloud computing environments\n", "abstract": " Current cloud computing frameworks host millions of physical servers that utilize cloud computing resources in the form of different virtual machines. Cloud Data Center (CDC) infrastructures require significant amounts of energy to deliver large scale computational services. Moreover, computing nodes generate large volumes of heat, requiring cooling units in turn to eliminate the effect of this heat. Thus, overall energy consumption of the CDC increases tremendously for servers as well as for cooling units. However, current workload allocation policies do not take into account effect on temperature and it is challenging to simulate the thermal behavior of CDCs. There is a need for a thermal-aware framework to simulate and model the behavior of nodes and measure the important performance parameters which can be affected by its temperature. In this paper, we propose a lightweight framework, ThermoSim, for\u00a0\u2026", "num_citations": "14\n", "authors": ["559"]}
{"title": "Analysing and modelling runtime architectural stability for self-adaptive software\n", "abstract": " With the increased dependence on software, there is a pressing need for engineering long-lived software. As architectures have a profound effect on the life-span of the software and the provisioned quality of service, stable architectures are significant assets. Architectural stability tends to reflect the success of the system in supporting continuous changes without phasing-out. For self-adaptive architectures, the behavioural aspect of stability is essential for seamless operation, to continuously keep the provision of quality requirements stable and prevent unnecessary adaptations that will risk degrading the system. In this paper, we introduce a systematic approach for analysing and modelling architectural stability. Specifically, we leverage architectural concerns and viewpoints to explicitly analyse stability attributes of the intended behaviour. Due to the probabilistic nature of systems\u2019 behaviour, stability modelling is\u00a0\u2026", "num_citations": "13\n", "authors": ["559"]}
{"title": "Economics-driven approach for managing technical debt in cloud-based architectures\n", "abstract": " Cloud-based Service-Oriented Architectures are composed of web services, offered via the cloud. The substitution decision may introduce technical debt, which needs to be managed, cleared and transformed to value-added. We define the concept of technical debt for Cloud-based SOA. We formulate the problem of web service substitution and its technical debt valuation as an option problem (option-to-switch between services). We use options analysis to manage and clear technical debt. We report on the formulation, which exploits Binomial Options Analysis. We evaluate the approach using an example.", "num_citations": "13\n", "authors": ["559"]}
{"title": "Self-managing SLA compliance in cloud architectures: A market-based approach\n", "abstract": " Service providers often use service level agreements (SLAs) to assure potential users of their services about the QoS to expect when they subscribe. In the cloud computing model, providers are required to continuously meet their SLA claims in the face of unanticipated failure of cloud resources. The dynamics of the cloud environment as attributed to its unpredictable mode of use and elasticity of its resources make human-driven solutions inefficient or sometimes infeasible. On the other hand, self-managed architectures have increasingly matured in their capacity to coordinate environments predominated by uncertainties. Thus making them a right fit for managing cloud-based systems. However, given the massive resource pool of the cloud, state-of-the-art centralised self-managed architectures are not scalable and are inherently brittle. Therefore, we propose a decentralised resource control mechanism which\u00a0\u2026", "num_citations": "13\n", "authors": ["559"]}
{"title": "Database design debts through examining schema evolution\n", "abstract": " Causes of the database debt can stem from ill-conceptual, logical, and/or physical database design decisions, violations to key design databases principles, use of anti-patterns etc. In this paper, we explore the problem of relational database design debt and define the problem. We develop a taxonomy, which classifies various types of debts that can relate to conceptual, logical and physical design of a database. We define the concept of Database Design Debt, discuss their origin, causes and preventive mechanisms. We draw on MediaWiki case study and examine its database schema evolution to support our work. The contribution hopes to make database designers and application developers aware of these debts so they can minimize/avoid their consequences on a given system.", "num_citations": "12\n", "authors": ["559"]}
{"title": "Quality-driven architectural patterns for self-aware cloud-based software\n", "abstract": " Architecture-based self-adaptation has been recognised as one of the prominent ways to design autonomic systems, where self-manageable architectures tend to achieve the required level of dynamicity and compliance with the continual changing in QoS requirements during run-time. Self-awareness and self-expression have recently emerged as promising architectural concepts in the field of self-adaptive software. Self-aware architecture patterns are envisioned as enabler for self-adaptation, but they tend to provide limited support for the QoS run-time requirements. While the research community has developed in architecture quality management, patterns and tactics, addressing quality attributes in self-aware architectures has not been tackled yet. In this paper, we aim to provide quality-driven architectural patterns for emerging class of architecture enabled by the principles of self-awareness. We report on the\u00a0\u2026", "num_citations": "12\n", "authors": ["559"]}
{"title": "Prioritizing technical debt in database normalization using portfolio theory and data quality metrics\n", "abstract": " Database normalization is the one of main principles for designing relational databases. The benefits of normalization can be observed through improving data quality and performance, among the other qualities. We explore a new context of technical debt manifestation, which is linked to ill-normalized databases. This debt can have long-term impact causing systematic degradation of database qualities. Such degradation can be liken to accumulated interest on a debt. We claim that debts are likely to materialize for tables below the fourth normal form. Practically, achieving fourth normal form for all the tables in the database is a costly and idealistic exercise. Therefore, we propose a pragmatic approach to prioritize tables that should be normalized to the fourth normal form based on the metaphoric debt and interest of the ill-normalized tables, observed on data quality and performance. For data quality, tables are\u00a0\u2026", "num_citations": "11\n", "authors": ["559"]}
{"title": "A debt-aware learning approach for resource adaptations in cloud elasticity management\n", "abstract": " Elasticity is a cloud property that enables applications and their execution systems to dynamically acquire and release shared computational resources on demand. Moreover, it unfolds the advantage of economies of scale in the cloud through a drop in the average costs of these shared resources. However, it is still an open challenge to achieve a perfect match between resource demand and provision in autonomous elasticity management. Resource adaptation decisions essentially involve a trade-off between economics and performance, which produces a gap between the ideal and actual resource provisioning. This gap, if not properly managed, can negatively impact the aggregate utility of a cloud customer in the long run. To address this limitation, we propose a technical debt-aware learning approach for autonomous elasticity management based on a reinforcement learning of debts in resource\u00a0\u2026", "num_citations": "11\n", "authors": ["559"]}
{"title": "The technical debt in cloud software engineering: a prediction-based and quantification approach\n", "abstract": " Predicting and quantifying promptly the Technical Debt has turned into an issue of significant importance over recent years. In the cloud marketplace, where cloud services can be leased, the difficulty to identify the Technical Debt effectively can have a significant impact. In this chapter, the probability of introducing the Technical Debt due to budget and cloud service selection decisions is investigated. A cost estimation approach for implementing Software as a Service (SaaS) in the cloud is examined, indicating three scenarios for predicting the incurrence of Technical Debt in the future. The Constructive Cost Model (COCOMO) is used in order to estimate the cost of the implementation and define a range of secureness by adopting a tolerance value for prediction. Furthermore, a Technical Debt quantification approach is researched for leasing a cloud Software as a Service (SaaS) in order to provide insights about the\u00a0\u2026", "num_citations": "11\n", "authors": ["559"]}
{"title": "Architectural stability\n", "abstract": " One of the major indicators of the success (failure) of software evolution is the extent to which the software system can endure changes in requirements, while leaving the architecture of the software system intact. The presence of this \u201cintuitive\u201d phenomenon is referred to as architectural stability. The concept is still far from being understood and many architectural stability related questions are remained unanswered. Reflecting on our extensive research into the problem, we explore perspectives in handling the problem. We review existing research effort and discuss their limitations. We outline research challenges and opportunities.", "num_citations": "11\n", "authors": ["559"]}
{"title": "Using obstacles for systematically modeling, analysing, and mitigating risks in cloud adoption\n", "abstract": " In this chapter, the authors motivate the need for a systematic approach to cloud adoption from the risk perspective. The enormous potential of cloud computing for improved and cost-effective service delivery for commercial and academic purposes has generated unprecedented interest in its adoption. However, a potential cloud user faces numerous risks regarding service requirements, cost implications of failure, and uncertainty about cloud providers\u2019 ability to meet service level agreements. Hence, the authors consider two perspectives of a case study to identify risks associated with cloud adoption. They propose a risk management framework based on the principle of GORE (Goal-Oriented Requirements Engineering). In this approach, they liken risks to obstacles encountered while realising cloud user goals, therefore proposing cloud-specific obstacle resolution tactics for mitigating identified risks. The proposed\u00a0\u2026", "num_citations": "10\n", "authors": ["559"]}
{"title": "Self-awareness in software engineering: A systematic literature review\n", "abstract": " Background: Self-awareness has been recently receiving attention in computing systems for enriching autonomous software systems operating in dynamic environments. Objective: We aim to investigate the adoption of computational self-awareness concepts in autonomic software systems and motivate future research directions on self-awareness and related problems. Method: We conducted a systemic literature review to compile the studies related to the adoption of self-awareness in software engineering and explore how self-awareness is engineered and incorporated in software systems. From 865 studies, 74 studies have been selected as primary studies. We have analysed the studies from multiple perspectives, such as motivation, inspiration, and engineering approaches, among others. Results: Results have shown that self-awareness has been used to enable self-adaptation in systems that exhibit\u00a0\u2026", "num_citations": "9\n", "authors": ["559"]}
{"title": "Self-adaptive volunteered services composition through stimulus-and time-awareness\n", "abstract": " Volunteered Service Composition (VSC) refers to the process of composing volunteered services and resources. These services are typically published to a pool of voluntary resources. Selection and composition decisions tend to encounter numerous uncertainties: service consumers and applications have little control of these services and tend to be uncertain about their level of support for the desired functionalities and non-functionalities. In this paper, we contribute to a self-awareness framework that implements two levels of awareness, Stimulus-awareness and Time-awareness. The former responds to basic changes in the environment while the latter takes into consideration the historical performance of the services. We have used volunteer service computing as an example to demonstrate the benefits that self-awareness can introduce to self-adaptation. We have compared the Stimulus- and Time-awareness\u00a0\u2026", "num_citations": "9\n", "authors": ["559"]}
{"title": "Economics-Driven Software Mining\n", "abstract": " Economics-driven software mining (EDSM) sifts through the repository data to extract information that could be useful for reasoning about not only the technical aspects but also the economics properties related to the development and/or evolution of software systems, and in relation to the environments in which they are procured, developed, evolved and used. The objective is to provide the analyst with insights into investment decisions related to the development, maintenance, and evolution of software systems, EDSM can also assist the analyst in resource planning and utilization. In this position paper, we define EDSM, describe possible scenarios for realizing EDSM and highlight some challenges.", "num_citations": "9\n", "authors": ["559"]}
{"title": "Elasticity debt: a debt-aware approach to reason about elasticity decisions in the cloud\n", "abstract": " Cloud elasticity provides the underlying primitives to dynamically acquire and release shared computational resources on demand. Therefore, elasticity constantly takes adaptation decisions to adjust the resource provisioning constrained by quality of service and operating costs minimization. However, dynamic trade-offs for resource provisioning rarely consider the value of the adaptation decisions under uncertainty. Part of the problem stems from the lack of a utility-driven model to reason about it. In this paper, we introduce the concept of elasticity debt as an approach to reason about elasticity decisions from a utility-driven perspective, where we apply the technical debt metaphor in the context of cloud elasticity. Moreover, we extended CloudSim as a proof of concept to show that a debt-aware elasticity decision-making can achieve a higher utility over time. We provide an elasticity conceptual model that links the\u00a0\u2026", "num_citations": "8\n", "authors": ["559"]}
{"title": "Towards self-aware service composition\n", "abstract": " Service-based applications are typically composedof web services, which are selected from a pool of servicesand/or cloud market. Selection and composition decisions tendto encounter numerous uncertainties: service consumers andapplications have little control of these services and tend to beuncertain about their level of support for the desired functionalitiesand non-functionalities. We contribute to an \"intelligent\"framework for selecting and composing services. The frameworkis ground on the premise of computationally self-awareness toinform decisions of selecting and composing the services to meetboth behavioral and functional requirements. The frameworkprovides the primitives for fine grained representation of knowledgeand levels of self-awareness for time, goal, interaction andstimuli. We have used volunteer service computing as an exampleto demonstrate the benefits that self-awareness can\u00a0\u2026", "num_citations": "8\n", "authors": ["559"]}
{"title": "Scalable service oriented replication in the cloud\n", "abstract": " Replication techniques are widely applied in and for cloud to enable elastically scalable and highly available service. Consistency and scalability requirements need to be ensured for the applications deploy in cloud. However, a major lack of existing service oriented replication approaches is that they only allow either rather restricted consistency or none at all, consequently the system may violates consistency requirements or does not scale well. In this paper, we present Scalable Service Oriented Replication (SSOR), a middleware solution that satisfies application's requirements in service replication. We propose the notions of region and the relevant service oriented requirements policies, by which trading between consistency and scalability can be handled. We solve atomic broadcast as a sub-problem by demonstrating Multi-fixed Sequencers Protocol (MSP). We also apply a Region based Election Protocol\u00a0\u2026", "num_citations": "8\n", "authors": ["559"]}
{"title": "Sustainability debt: a portfolio-based approach for evaluating sustainability requirements in architectures\n", "abstract": " Architectural Sustainability refers to the ability of an architecture to achieve its goals while sustaining its value on dimensions related to environmental, social, economic, individual and/or technical during its operation and evolution. While the process of architectural design implies a fit between the requirements, system conditions and constraints; incomplete information and uncertainty may increase the cost of the architecture, introduce risks, alter its value and influence the extent to which it can evolve and sustain. We propose an economics-driven architectural evaluation method which extends the Cost Benefits Analysis Method (CBAM) and integrates principles of modern portfolio theory to control the risks when linking sustainability concern to architectural design decisions. The method aims at identifying portfolio (s) of architecture design decisions which are more promising for adding/delivering value while\u00a0\u2026", "num_citations": "7\n", "authors": ["559"]}
{"title": "A utility model for volunteered service composition\n", "abstract": " Volunteered Service Composition (VSC) refers to the process of composing volunteered services and resources. These services are typically published to a pool of voluntary resources. The composition aims at satisfying some objectives (e.g. Utilizing storage and eliminating waste, sharing space and optimizing for energy, reducing computational cost etc.). In cases when a single volunteered service does not satisfy a request, VSC will be required. In this paper, we contribute to three approaches for composing volunteered services: these are exhaustive, na\u00efve and utility-based search approach to VSC. The proposed new utility-based approach, for instance, is based on measuring the utility that each volunteered service can provide to each request and systematically selects the one with the highest utility. We found that the utility-based approach tend to be more effective and efficient when selecting services, while\u00a0\u2026", "num_citations": "7\n", "authors": ["559"]}
{"title": "Risk-aware web service allocation in the cloud using portfolio theory\n", "abstract": " In this paper, we view the cloud as market place for trading instances of web services, which can be bought or leased by web applications. Applications can buy diversity by selecting web services from multiple cloud sellers in a cloud-based market. We argue that by diversifying the selection, we can improve the dependability of the application and reduce risks associated with service level agreements violations. We propose a novel dynamic adaptive search based software engineering approach, which uses portfolio theory to construct a diversify portfolio of web service instances, traded from multiple cloud providers. The approach systematically evaluates the Quality of Service and risks of the portfolio, compare it to the optimal traded portfolio at a given time. It can then dynamically decide on a new portfolio and adapt the application accordingly. We use a hypothetical scenario to demonstrate the effective use of the\u00a0\u2026", "num_citations": "7\n", "authors": ["559"]}
{"title": "Green software architectures: A market-based approach\n", "abstract": " Software systems architects are continually faced with the challenge of scaling up software systems architectures to sup-port constantly growing load of users\u2019 processing needs and data. Scaling up the architectures to meet these needs does certainly introduce additional energy cost. For example, to meet the scalability requirements, additional hardware and software resources may need to be deployed. Reducing the energy demands in such architectures while meeting the scalability requirements, are always challenging. We explicate the attention to power as an architectural constraint/property that need to be analyzed in relation with scalability. Current research and practice to distributed software architecture approaches are green-unaware. They don\u2019t provide the primitives for reasoning and managing power consumption. We argue that the software engineering should be green aware, where the software engineering and design activities should not only be judged by their technical merits, but also by their contributions to energy savings. In particular, the software system architecture appears to be the appropriate level of abstraction to address green-aware concerns. Software architectures should be green-aware, providing power management mechanisms as part of the architecture primitives. Furthermore, it looks plausible to leverage on advances in selfmanagement software architectures [2], where self-managing power could be separated from the core system functionalities. We argue that there is a pragmatic need for new software architectural layer, which could be easily integrated with existing styles for self-managing the trade-offs\u00a0\u2026", "num_citations": "7\n", "authors": ["559"]}
{"title": "Semi-automated detection of architectural threats for security testing\n", "abstract": " The ability to deliver reliable software systems of higher quality within budget and schedule continues to challenge most IT organizations. As with the current growth of software, applications are becoming too bloated to be tested effectively. Furthermore, testing is often performed under immense time pressure. In particular, testing for security has become one of the difficult challenges in software engineering. This is due to many factors, mainly:1. lack of security expertise amongst software engineers resulting in a software design with no security consideration. Software developers are generally never provided with the information on how to develop secure applications [4].2. conducting effective security testing is time consuming, as testers look for unspecified features in the system, with no guarantee of finding a vulnerability.3. security testing cannot be performed in a random fashion since parts of systems are more\u00a0\u2026", "num_citations": "7\n", "authors": ["559"]}
{"title": "Methods and metrics for selective regression testing\n", "abstract": " In corrective software maintenance, selective regression testing includes test selection from previously-run test suites and test coverage identification. We propose three reduction-based regression test selection methods and two McCabe-based coverage identification metrics (T. McCabe, 1976). We empirically compare these methods with three other reduction- and precision-oriented methods, using 60 test problems. The comparison shows that our proposed methods yield favourable results.", "num_citations": "7\n", "authors": ["559"]}
{"title": "BioSec: A Biometric Authentication Framework for Secure and Private Communication among Edge Devices in IoT and Industry 4.0\n", "abstract": " With the rapid increase in the usage areas of Internet of Things (IoT) devices, it brings challenges such as security and privacy. One way to ensure these in IoT-based systems is user authentication. Until today, user authentication is provided by traditional methods such as pin and token based. But traditional methods have challenges such as forgotten, stolen, and shared with another user who is unauthorized. To address these challenges, we proposed a biometric method called BioSec to provide authentication in IoT integrated with edge consumer electronics using fingerprint authentication. Further, we ensured the security of biometric data both in the transmission channel and database with the standard encryption method. BioSec ensures secure and private communication among edge devices in IoT and Industry 4.0. Finally, we have compared three encryption methods used to protect biometric templates in\u00a0\u2026", "num_citations": "6\n", "authors": ["559"]}
{"title": "DATESSO: Self-Adapting Service Composition with Debt-Aware Two Levels Constraint Reasoning\n", "abstract": " The rapidly changing workload of service-based systems can easily cause under-/over-utilization on the component services, which can consequently affect the overall Quality of Service (QoS), such as latency. Self-adaptive services composition rectifies this problem, but poses several challenges:(i) the effectiveness of adaptation can deteriorate due to over-optimistic assumptions on the latency and utilization constraints, at both local and global levels; and (ii) the benefits brought by each composition plan is often short term and is not often designed for long-term benefits---a natural prerequisite for sustaining the system. To tackle these issues, we propose a two levels constraint reasoning framework for sustainable self-adaptive services composition, called DATESSO. In particular, DATESSO consists of a refined formulation that differentiates thestrictness' for latency/utilization constraints in two levels. To strive for\u00a0\u2026", "num_citations": "6\n", "authors": ["559"]}
{"title": "Cloud instance selection using parallel k-means and ahp\n", "abstract": " Managing cloud spend and qualities when selecting cloud instances is cited as one of the timely research challenges in cloud computing. Cloud service consumers are often confronted by too many options and selection is challenging. This is because instance provision can be difficult to comprehend for an average technical user and tactics of cloud provider are far from being transparent biasing the selection. This paper proposes a novel cloud instance selection framework for finding the optimal IaaS purchase strategy for a VARD application in Amazon EC2. Analytical Hierarchy Process (AHP) and parallel K-Means Clustering algorithm are used and combined in Cloud Instance Selection environments. It allows cloud users to get the recommendation about cloud instance types and job submission periods based on requirements such as CPU, RAM, and resource utilisation. The system leverages AHP to select\u00a0\u2026", "num_citations": "6\n", "authors": ["559"]}
{"title": "Asset-centric security-aware service selection\n", "abstract": " Catering for the runtime security of users and their assets (e.g. files, accounts, etc.) in service oriented environments is a challenging problem. We motivate the need for an adaptive framework that selects online services according to the runtime security requirements and cost constraints of assets. We report on a market-inspired approach (i.e. reversed Posted-Offer auction) that satisfies multiple, heterogeneous requests for online services in environments with shared and scarce resources. The solution is tested on the specific area of Cloud storage services.", "num_citations": "6\n", "authors": ["559"]}
{"title": "Agent-based trust management and prediction using D3-FRT\n", "abstract": " Reputation and trust management systems have been useful in domains that rely on the cooperation of members to function correctly and to fulfil their purposes. Despite the advent of these systems, having trusted communications remains a challenge. This is as a result of relying on the domain members for reputation information. These systems lack well analysed approaches for determining the bias of the members. A semi-distributed framework D3-FRT, which is inspired by the Dynamic Data-Driven Simulation paradigm, is presented in this paper. The framework adopts an agent-based modelling approach to make predictions about domain members. The D3-FRT framework is novel as it uses past, online and predicted data to identify misbehaving members. In this paper, the accuracy of the prediction is tested and a report on the framework's performance in different network scenarios is also presented. The\u00a0\u2026", "num_citations": "6\n", "authors": ["559"]}
{"title": "A data-driven framework for dynamic trust management\n", "abstract": " Reputation and trust-based models have been used extensively in different application domains. These include large online communities such as eBay, Amazon, YouTube and ad-hoc and wireless sensor networks. Recently, the use of the models has gained popularity due to their effectiveness in providing trusted systems or networks. Thesemodels focus on online and historical data to determine the reputation of domain members. In this paper, we propose a novel approach for obtaining trust values by focusing not only on online and historical data but also possible future scenarios to anticipate events in the next time intervals. The data-driven framework is able to dynamically obtain and inject data to predict the future trust value of every identity in the system. The advantage of this proactive approach compared to other approaches is that informed decisions about the domain can be made before a compromise\u00a0\u2026", "num_citations": "6\n", "authors": ["559"]}
{"title": "Evaluating the stability of software architectures with real options theory\n", "abstract": " Architectural stability refers to the extent a software architecture can respond to changes in stakeholders\u2019 requirements and the environment, while adding a value. We report a result in the economic-driven software engineering research. We present a novel approach for evaluating architectural stability using a synergy of real options theory and viewpoints. Specifically, we contribute to a model that exploits Black and Scholes options theory (Nobel Prize winning) to predict architectural stability. We describe how we have derived the model: the analogy and assumptions made; its formulation; possible interpretations; and its sensitivity to estimates. The valuation using the model necessarily requires a comprehensive solution that incorporates multiple valuation techniques, some with subjective estimates and others based on market data, when available. To introduce discipline into this setting and capture the value from\u00a0\u2026", "num_citations": "6\n", "authors": ["559"]}
{"title": "Identifying and estimating technical debt for service composition in SaaS cloud\n", "abstract": " A composite service in multi-tenant SaaS cloud would inevitably operate under dynamic changes on the workload from the tenants, and thus it is not uncommon for the composition to encounter under-utilization and over-utilization on the component services. However, both of those cases could be good or bad: the former implies that although there is under-utilization, the pay-off afterwards are more significant; the latter, in contrast, refers to the over-utilization that leads to trivial pay-off, or nothing at all. Such a notion perfectly matches with the Technical Debt (TD) metaphor in Software Engineering. As a result, it is necessary to identify the root causes of the debts and where the debt can be manifested in the service composition, which, in turn, would offer great helps on the decision making process of service composition. In this paper, we propose a novel approach for identifying the technical debt in service\u00a0\u2026", "num_citations": "5\n", "authors": ["559"]}
{"title": "Green-as-a-service (gaas) for cloud service provision operation\n", "abstract": " We introduce the concept of green-as-a-service that provides a cost-effective and specialized on-demand monitoring, analysis, and continuous feeds for energy use and savings which can be exploited by both providers and consumers to meet energy targets. We describe a decentralized architecture model for implementing GaaS and discuss its constituent components. The architecture leverages on SOA and publish-subscribe model to provide an effective solution for wider adoption of the vision and to render an inherently scalable solution. The service has the promise to provide transparency in the way energy and long-term sustainability are linked to the business objectives along with its cost and revenues.", "num_citations": "5\n", "authors": ["559"]}
{"title": "Evaluating identity management architectures\n", "abstract": " Developments in the area of identity management have been subject to very little critique. Many implementations have gathered little general following, and larger scale adoption, such as OpenID, has been limited to internal systems and large identity providers.", "num_citations": "5\n", "authors": ["559"]}
{"title": "An architecture for dynamic trust monitoring in mobile networks\n", "abstract": " Collusion attacks remain a major problem of reputation and trust models, in mobile ad hoc networks. By covering up malicious behaviour of one another from the remaining part of the network, two or more malicious nodes may collaborate to cause damage to or disrupt the network. A number of models exist, which have been proposed to address this issue. Despite these however, the assurance of trusted communication still remains a challenge in these networks. We present a dynamic trust model that detects malicious behaviour at runtime and prevents collusion attacks. Our proposed model employs a novel approach that has the advantage of predicting the future trustworthiness of nodes, based on historical and online behaviour of nodes. This is achieved by an architecture that applies the paradigm of Dynamic Data Driven Application Systems, in solving the problem of collusion attacks in mobile networks.", "num_citations": "5\n", "authors": ["559"]}
{"title": "Requirements for evaluating architectural stability\n", "abstract": " In previous papers, we have proposed the in-transit buffer mechanism (ITB) to improve network performance in COWs with irregular topology and source routing. This mechanism allows the use of minimal paths among all hosts, breaking cyclic dependences between channels by storing and later re-injecting packets at some intermediate hosts. However, it also has two additional features that can improve even more network performance. First, the ITB mechanism reduces network contention because some messages are ejected from the network freeing network links. Second, the ITB mechanism allows the use of any path between each source-destination pair, improving traffic balance. In this paper, we present a new routing algorithm that takes advantage of ITB by exploiting both issues: traffic balance and network contention reduction. The evaluation results show that network throughput can be considerably\u00a0\u2026", "num_citations": "5\n", "authors": ["559"]}
{"title": "Architectural stability and middleware: An architecture-centric evolution perspective\n", "abstract": " Architecture stability refers to the extent to which a software system can endure changes in requirements, while leaving the architecture of the software system intact. We argue that changes in non-functional requirements are critical to threat the stability of a software architecture over its projected lifetime. We claim that focusing the analysis on the \u201ccoupling\u201d of middleware and software architectures is a step towards understanding the ramifications of the change in the so called middleware-induced architectures. Middleware-induced architectures follow an architecture-centric evolution approach, as the emphasis is placed on the induced architecture and the provided middleware primitives to simplify the construction of distributed systems, realize many of the non-functional requirements (eg, scalability, fault tolerance, etc.) and facilitate their evolution over time. To support the claim, we use a case study and we observe how a software architecture, when induced by distinct middleware, differs in coping with changes in nonfunctional requirements. We conclude by hinting on future research directions in the area.", "num_citations": "5\n", "authors": ["559"]}
{"title": "Self-awareness for dynamic knowledge management in self-adaptive volunteer services\n", "abstract": " Engineering volunteer services calls for novel self-adaptive approaches for dynamically managing the process of selecting volunteer services. As these services tend to be published and withdrawn without restrictions, uncertainties, dynamisms and 'dilution of control' related to the decisions of selection and composition are complex problems. These services tend to exhibit periodic performance patterns, which are often repeated over a certain time period. Consequently, the awareness of such periodic patterns enables the prediction of the services performance leading to better adaptation. In this paper, we contribute to a self-adaptive approach, namely time-awareness, which combines self-aware principles with dynamic histograms to dynamically manage the periodic trends of services performance and their evolution trends. Such knowledge can inform the adaptation decisions, leading to increase in the precision\u00a0\u2026", "num_citations": "4\n", "authors": ["559"]}
{"title": "A taxonomy for architectural stability\n", "abstract": " With the increase dependence on software, there is a pressing need for engineering long-lived stable software. As architectures have a profound effect on the life-span of the software and the provisioned quality of the service, a stable architecture is a significant asset of the software. Yet, there is lack of consensus on the concept of stability as an architectural quality attribute. This paper proposes a taxonomy for defining, characterising and analysing architectural stability. The aim is to provide a better understanding and characterisation of this strategic quality attribute within the domain of software architecture, and to explicate a set of general concepts across a wide range of architectures. Such framework would significantly ease understanding the concept in the shed of modern and complex software architectures, and, therefore, allow more systematic guidance in designing and operating architectures. We apply the\u00a0\u2026", "num_citations": "4\n", "authors": ["559"]}
{"title": "Design patterns and primitives: Introduction of components and patterns for SACS\n", "abstract": " When faced with the task of designing and implementing self-aware and self-expressive computing systems, researchers and practitioners need guidelines on how to use the concepts and foundations of self-awareness. This chapter provides such guidelines on how to design self-aware and self-expressive computing systems in a principled way.We have documented different levels of self-awareness and proposed architectural patterns. We have also discussed common architectural primitives and attributes for architecting self-aware and self-expressive systems. Drawing on the knowledge obtained from the previous investigations, we discuss how the proposed patterns and primitives can be used in real software system projects.", "num_citations": "4\n", "authors": ["559"]}
{"title": "Relating System Quality and Software Architecture: Foundations and Approaches\n", "abstract": " The field of software architecture has gone through significant evolution over the past two decades. Early research in software architecture focused on technological contributions such as the modeling of structural and behavioral properties of software systems. Automated analysis of these models resulted in the development of tools and approaches aimed at ensuring a system\u2019s functional and nonfunctional properties such as performance, interoperability, and schedulability. More recently, however, software architecture research has shifted in fundamental ways. The emphasis on capturing design decisions and their relationship to both a software system\u2019s requirements and its implementation is predominant. The synergy between the design decisions captured in the software architecture and system quality is the primary motivation behind this book.", "num_citations": "4\n", "authors": ["559"]}
{"title": "Self-adapting applications based on qa requirements in the cloud using market-based heuristics\n", "abstract": " There are several situations where applications in the cloud need to self-manage their quality attributes (QA). We posit that self-adaptation can be achieved through a market-based approach and describe a marketplace for web-services. We simulate agents trading web-services on behalf of self-managing applications and demonstrate that such a mechanism leads to a good allocation of web-services to applications, even when applications dynamically change their QA requirements. We conclude with a discussion on evaluating this mechanism of self-adaptation, with regards to scalability in the cloud.", "num_citations": "4\n", "authors": ["559"]}
{"title": "Secure storage and communication in J2ME based lightweight multi-agent systems\n", "abstract": " Securing data and applications is critical in the wireless era. The successive increase in wireless communication opens vulnerabilities to confidential information. This paper aims at investigating the issues related to security when the Java 2 Micro Edition (J2ME) based multi-agent system applications are run on different handheld devices. Agent\u2019s information must be protected on the local device as well as on other devices during communication. J2ME MIDP security model does not provide secure data storage and communication mechanism for applications running on different mobile devices. This paper proposes a mechanism for secure storage of agent\u2019s information and also securing communication between agents in J2ME based lightweight multi-agent system. We present a new solution to this problem by providing a security framework that can be used to provide agent\u2019s secure storage and\u00a0\u2026", "num_citations": "4\n", "authors": ["559"]}
{"title": "Evaluating software architectures for stability and evolution\n", "abstract": " Architectural stability refers to the extent an architecture is flexible to endure evolutionary changes in stakeholders\u2019 requirements and the environment, while leaving the architecture intact. We report an early result in an emerging discipline of software engineering, the economic-driven software engineering research. We propose a novel approach for evaluating the stability of software architectures using a synergy of real options theory and viewpoints. Specifically, we contribute to a novel model that exploits options theory to predict architectural stability. The model is predictive: it provides \u201cinsights\u201d on the evolution of the software system based on valuing the extent an architecture can endure a set of likely evolutionary changes. The model builds on Black and Scholes financial options theory (Noble Prize wining) to value such extent. We show how we have derived the model: the analogy and assumptions made to reach the model, its formulation, and possible interpretations. We refer to this model as ArchOptions. ArchOptions requires the estimation of several parameters. The estimation necessarily involves many parties-each with their own perspective on the system defined by their valuation objectives, assessment \u201cregime\u201d, skills, responsibilities, knowledge, and expertise. The problem associated with how to guide the estimation in this setting, we term as a multiple perspectives valuation problem. We describe the problem from a value-based software engineering perspective. We suggest a viewpoints-oriented framework as a solution. The framework appears to promote flexibility in implementing the model through aligning the estimation needs\u00a0\u2026", "num_citations": "4\n", "authors": ["559"]}
{"title": "Towards Engineering Cognitive Digital Twins with Self-Awareness\n", "abstract": " There has been a recent explosion of interest in digital twins, namely data driven virtual replicas that can provide insights about a physical system and support decision making. This paper deals with cognitive digital twins, namely twins that can exhibit a high level of intelligence that can replicate human cognitive processes and execute conscious actions autonomously. The paper brings together the concepts of digital twins and self-awareness and discusses how the different levels of self-awareness can be harnessed for the design of cognitive-digital twins. A discussion of digital twins in relation to the Dynamic Data Driven Application Systems (DDDAS) paradigm and a classification of digital twins based on their analytics capability are also provided.", "num_citations": "3\n", "authors": ["559"]}
{"title": "A reference architecture and modelling principles for architectural stability based on self-awareness: Case of cloud architectures\n", "abstract": " With the increased dependence on software, there is a pressing need for engineering long-lived software. As architectures have a profound effect on the life-span of the software and the provisioned quality of service, stable architectures are significant assets. Architectural stability tends to reflect the success of the system in supporting continuous changes without phasing-out. The \\textit{behavioural} aspect of stability is essential for seamless operation, to continuously keep the provision of quality requirements stable and prevent architecture's drifting and phasing-out. In this paper, we introduce a reference architecture and model for stability. Specifically, we leverage on the self-awareness principles and runtime goals modelling to explicitly support architectural stability. To illustrate the applicability and evaluate the proposed approach, we consider the case of cloud architectures. The experimental results show that our approach increases the efficiency of the architecture in keeping the expected behaviour stable during runtime operation.", "num_citations": "3\n", "authors": ["559"]}
{"title": "A multi-agent elasticity management based on multi-tenant debt exchanges\n", "abstract": " A multi-tenant Software as a Service (SaaS) application is a highly configurable software that allows its owner to serve multiple tenants, each with their own workflows, workloads and Service Level Objectives (SLOs). Tenants are usually organizations that serve several users and the application appears to be a different one for each tenant. However, in practice, multi-tenant SaaS applications limit the diversity of tenants by clustering them in a few categories (e.g. premium, standard) with predefined SLOs. Additionally, this coarse-grained clustering reduces the advantage of these multi-tenant ecosystems over single tenant architectures to share dynamically virtual resources between tenants based on their own workload profile and elasticity adaptation decisions. To address this limitation, we propose a multi-agent elasticity management where each tenant is represented by a reinforcement learning agent that\u00a0\u2026", "num_citations": "3\n", "authors": ["559"]}
{"title": "Bridging ecology and cloud: transposing ecological perspective to enable better cloud autoscaling\n", "abstract": " Elastic autoscaling is the fundamental mechanism that enables the cloud-based services to continually evolve themselves \u2013 through changing the related software configurations and hardware resource provisions \u2013 under time-varying workloads. However, given the increasingly complex dynamic, uncertainty and trade-offs related to the runtime QoS and cost/energy of services, cloud autoscaling system is becoming one of the most complex artifacts constructed by human and thus its effectiveness is difficult to be preserved. In this article, we present novel ideas for facilitating cloud autoscaling. Our hypothesis is that cloud ecosystem, represented by a collection of cloud-based services, bears many similarities with the natural ecosystem. As such, we intend to investigate how ecological view can be adopted to better explain how the cloud-based services evolve, and to explore what are the key factors that drive stable\u00a0\u2026", "num_citations": "3\n", "authors": ["559"]}
{"title": "Dynamic modelling of tactics impact on the stability of self-aware cloud architectures\n", "abstract": " Given the elasticity, on-demand nature, and runtime dynamics of the cloud, a stable self-adaptive architecture should keep the fulfilment of Quality of Service objectives stable, while performing stable adaptations that converge towards these objectives. The dynamic management and selection of architectural tactics, as adaptation mechanisms, shall be in the heart of the adaptation process, as being essential for effective and stable adaptations. This calls for measuring the impact of tactics on the stability of inter-related quality attributes during run-time. In this paper, we introduce a Markovian-based analytical model for dynamically assessing the impact of tactics on the stability behaviour of self-adaptive cloud architectures. The model also employs self-awareness capabilities for betterinforming the selection of optimal tactics configurations leading to stability. Experimental evaluations have shown the accuracy and\u00a0\u2026", "num_citations": "3\n", "authors": ["559"]}
{"title": "Securing cloud users at runtime via a market mechanism: A case for federated identity\n", "abstract": " Securing users in the federated cloud environment is a challenging problem. We motivate the need for a dynamic and adaptive framework for securing identities at runtime. The solution explores the link between Identity Security Goals, the features they require (e.g. Anonymity, Integrity) and the provisioned underlying computational resources (e.g. Memory, CPU) in federated environments. We report on an economics inspired approach, which utilizes an auction procedure for dynamic allocation of resources for adaptively securing identities at runtime. The solution is realized as a simulation and tested on the cloud specific area of federated identity management.", "num_citations": "3\n", "authors": ["559"]}
{"title": "Economics-driven software architecting for cloud\n", "abstract": " Many of the problems facing providers and users of Cloud-based systems, in terms of maximizing Quality-of-Service (QoS) satisfaction, can be studied using theories in microeconomics. Specifically, the concept of market-based control provides tools that can be used to design economically and computationally efficient Cloud software architectures. This chapter surveys both domains and presents some of the underlying problems and opportunities in the interesting crossbreed of economics and Cloud computing. The dynamic resource allocation problem is used as an example to demonstrate the added value of this approach. Observations from simulation studies reveal the usefulness of the posted offer market model as a viable mechanism for orchestrating the interaction of components in a Cloud software architecture. The chapter concludes with a reflection on open problems that need to be addressed to move\u00a0\u2026", "num_citations": "3\n", "authors": ["559"]}
{"title": "Economics-Driven Architecting for Non Functional Requirements in the Presence of Middleware\n", "abstract": " The current trend is to build distributed software architectures with middleware, which provides the application developer with primitives for managing the complexity of distribution and for realizing many of the non-functional requirements like scalability, openness, heterogeneity, availability, reliability and fault-tolerance. In this chapter, we discuss the problem of evolving non-functional requirements, their stability implications and economics ramifications on the software architectures induced by middleware. We look at the role of middleware in architecting for non-functional requirements and their evolution trends. We advocate adjusting requirements elicitation and management techniques to elicit not just the current non-functional requirements, but also to assess the way in which they will develop over the lifetime of the architecture and their economics ramifications. These ranges of requirements may then\u00a0\u2026", "num_citations": "3\n", "authors": ["559"]}
{"title": "Fine-grained recommendation systems for service attribute exchange\n", "abstract": " The effectiveness of service oriented computing relies on the trustworthiness of sharing of data between services. We advocate a semi-automated approach for information distribution and sharing, assisted by a reputation system. Unlike current recommendation systems which provide a user with a general trust value for a service, we propose a reputation model which calculates trust neighbourhoods through fine-grained multi-attribute analysis. Such a model allows a recommendation relevance to improve whilst maintaining a large user group, propagating and evolving trust perceptions between users. The approach is demonstrated on a small example.", "num_citations": "3\n", "authors": ["559"]}
{"title": "The first international workshop on unified data mining engine: addressing challenges (UDME 2007)\n", "abstract": " Building a Unified Data Mining Engine (UDME) is not an easy exercise, specifically, when several factors can undermine their quality success, such as cost, time, and lack of systematic approaches. We would like to architect and develop a UDME, that has the some or all of the following properties: 1. Ease of use, 2. No Need of Expert to run the tool 3. Easy to add new functionality 4. Easy to interface 6. Multiple algorithms 7. Fewer resources 8. Stable 9. Isolation of Application logic 10. Minimum Maintenance Cost The workshop will address the unified data mining engine'challenges, and also debate several issues that are related to the architecture and development of the UDME.", "num_citations": "3\n", "authors": ["559"]}
{"title": "Defining Dependable Dynamic Data-Driven Software Architectures\n", "abstract": " The thesis of this vision paper is that the dynamic data driven applications systems (DDDAS) is a promising paradigm to adopt for assisting architectures to self-maintain their dependability properties, as the software architecture tends to evolve in response to changes in the operating environment, changes in contexts, and dynamic usages of the application. In this perspective, the architecture becomes an integrated computational and measurement artifact aimed at measuring, simulating, and controlling the runtime evolution of dependable software systems. This perspective is novel and has the promise to form a built-in support for the runtime dependability analyses, reasoning, and evaluation for many architecture-centric approaches such as product-line, service oriented, and model-driven paradigms. The contribution of this position paper is a definition of Dependable Dynamic Data-Driven Software Architectures\u00a0\u2026", "num_citations": "3\n", "authors": ["559"]}
{"title": "Interaction-awareness for self-adaptive volunteer computing\n", "abstract": " In this paper, we contribute to a self-adaptive approach, namely interaction-awareness which adopts self-aware principles to dynamically manage and maintain the knowledge on the interactions between volunteer services in the volunteer computing paradigm. Such knowledge can inform the adaptation decisions, leading to increase in the precision of selecting and composing services. We evaluate the approaches using a volunteer storage composition scenario. The evaluation results show the advantages of dynamic knowledge management in self-adaptive VC in selecting dependable services and satisfying higher number of requests.", "num_citations": "2\n", "authors": ["559"]}
{"title": "Stabilising performance in cloud services composition using portfolio theory\n", "abstract": " The increasing number of services available in the cloud market make them plausible and attractive for building Cloud Service Compositions (CSC). However, performance instability is common in the cloud environment due to changes in supply and demand of shared computational infrastructure and resources. Candidate compositions are vulnerable to such instability. We propose a novel approach to improve performance stability by leveraging on the principles of design diversity in service composition(s). The approach uses portfolio theory to construct a diversified composition of candidate services that share lowest possible correlation for their performances. We use an exemplar to illustrate the applicability of the approach. Controlled experiments are used to test the approach effectiveness in improving the performance stability of CSC. While the scalability of our approach is evaluated, we report on its sensitivity\u00a0\u2026", "num_citations": "2\n", "authors": ["559"]}
{"title": "Implementing design diversity using portfolio thinking to dynamically and adaptively manage the allocation of Web services in the cloud\n", "abstract": " We view the cloud as a marketplace for trading instances of web services, which can be \u201cleased\u201d by web applications. We argue that applications can \u201cbuy\u201d diversity by selecting instances of web services from multiple cloud sellers in this market. By diversifying the selection and allocation of web service instances, an application can potentially improve its dependability and reduce risks associated with service level agreement (SLA) violations. We propose a novel, dynamic and adaptive approach for implementing design diversity in the cloud market. The approach uses portfolio theory to construct a diversified portfolio of web service instances, which are traded from multiple cloud providers. We illustrate the applicability of the approach. Controlled experiments are also used to (i) test the approach effectiveness in minimizing the risk of SLA violation; (ii) simulate the dynamic and adaptive behaviour of the approach in\u00a0\u2026", "num_citations": "2\n", "authors": ["559"]}
{"title": "A risk-aware framework for compliance goal-obstacle analysis\n", "abstract": " Engineering regulatory compliance requirements is valuable during the software development process as they are necessary to reduce risk, improve security and help systems achieve their business goals. Existing methods for assessing compliance requirements are inadequate as they fail to consider the important aspects such as interdependency between goals, obstacles and agents. Poor goal and risk analysis during the requirement engineering phase often result in incomplete requirements and wrong estimation of risks. This paper presents a goal-oriented quantitative compliance analysis framework that considers these issues during the requirement analysis phase.", "num_citations": "2\n", "authors": ["559"]}
{"title": "Architecture-centric testing for security: An agile perspective\n", "abstract": " Verifying the security posture as a system evolves is indispensable for building deployable software systems. Traditional security testing lacks flexibility in (1) providing early feedback to the architect on the ability of the software to predict security threats so that changes are made before the system is built, (2) responding to changes in user and behavior requirements that could affect the security of software, and (3) offering real design fixes that do not merely hide the symptoms of the problem (i.e., patching).We motivate the need for an architecture-level testing for security grounded on incremental and continuous refinements to support agile principles. We use architecture as an artifact for initiating the testing process for security through subsequent and iterative refinements. We extend the use of implied scenario to reveal undesirable behavior caused by ambiguities in users\u2019 requirements and we analyze detection\u00a0\u2026", "num_citations": "2\n", "authors": ["559"]}
{"title": "Aligning Enterprise, System, and Software Architectures\n", "abstract": " Although enterprise, system, and software architectures have many common features and often overlap in practice, the presence of each architecture is required in the planning and design of a system. The alignment of these architectures in the design processes is important in the development of software-intensive complex systems. Aligning Enterprise, System, and Software Architectures covers both theoretical approaches and practical solutions in the processes for aligning enterprise, systems, and software architectures. This book aims to provide architects and researchers with a clear understanding of all three types of architectures.", "num_citations": "2\n", "authors": ["559"]}
{"title": "Portable Secure Identity Management\n", "abstract": " The area of identity management has developed from the desperation of all parties involved becoming overwhelmed with authentication and profile management. Traditional service-centric distributed systems provide no consistency and password fatigue causes security nightmares. The move toward user-centric centralised systems aims to relieve this problem, but in turn adds privacy concerns. Furthermore, the transition between the two methods is slow and resembles the age old chicken-and-egg problem. In order to determine the requirements of services and users from their identity architecture, my work provides an analytical framework for visualising the changes between architectures. Through the use of this framework it is possible to see the areas of identity architectures which may be improved upon and which architecture suits a particular situation. By evolving identity architectures around a single model\u00a0\u2026", "num_citations": "2\n", "authors": ["559"]}
{"title": "Selecting Miners within Blockchain-based Systems Using Evolutionary Algorithms for Energy Optimisation\n", "abstract": " In this paper, we represent the problem of selecting miners within a blockchain-based system as a subset selection problem. We formulate the problem of minimising blockchain energy consumption as an optimisation problem with two conflicting objectives: energy consumption and trust. The proposed model is compared across different algorithms to demonstrate its performance.", "num_citations": "1\n", "authors": ["559"]}
{"title": "Architecting Internet of Things Systems with Blockchain: A Catalog of Tactics\n", "abstract": " Blockchain offers a distributed ledger to record data collected from Internet of Thing (IoT) devices as immutable and tamper-proof transactions and securely shared among authorized participants in a Peer-to-Peer (P2P) network. Despite the growing interest in using blockchain for securing IoT systems, there is a general lack of systematic research and comprehensive review of the design issues on the integration of blockchain and IoT from the software architecture perspective. This article presents a catalog of architectural tactics for the design of IoT systems supported by blockchain as a result of a Systematic Literature Review (SLR) on IoT and blockchain to extract the commonly reported quality attributes, design decisions, and relevant architectural tactics for the architectural design of this category of systems. Our findings are threefold:<?brk?> (i) identification of security, scalability, performance, and\u00a0\u2026", "num_citations": "1\n", "authors": ["559"]}
{"title": "Assessing Smart Contracts Security Technical Debts\n", "abstract": " Smart contracts are self-enforcing agreements that are employed to exchange assets without the approval of trusted third parties. This feature has encouraged various sectors to make use of smart contracts when transacting. Experience shows that many deployed contracts are vulnerable to exploitation due to their poor design, which allows attackers to steal valuable assets from the involved parties. Therefore, an assessment approach that allows developers to recognise the consequences of deploying vulnerable contracts is needed. In this paper, we propose a debt-aware approach for assessing security design vulnerabilities in smart contracts. Our assessment approach involves two main steps: (i) identification of design vulnerabilities using security analysis techniques and (ii) an estimation of the ramifications of the identified vulnerabilities leveraging the technical debt metaphor, its principal and interest. We use examples of vulnerable contracts to demonstrate the applicability of our approach. The results show that our assessment approach increases the visibility of security design issues. It also allows developers to concentrate on resolving smart contract vulnerabilities through technical debt impact analysis and prioritisation. Developers can use our approach to inform the design of more secure contracts and for reducing unintentional debts caused by a lack of awareness of security issues.", "num_citations": "1\n", "authors": ["559"]}
{"title": "Architectural stability reasoning using self-awareness principles: Case of self-adaptive cloud architectures\n", "abstract": " With the increased dependence on software, there is a pressing need for engineering long-lived software. As architectures have a profound effect on the life-span of the software and the provisioned quality of service, stable architectures are significant assets. Architectural stability tends to reflect the success of the system in supporting continuous changes without phasing-out. The \\textit{behavioural} aspect of stability is essential for seamless operation, to continuously keep the provision of quality requirements stable and prevent architecture's drifting and phasing-out. In this paper, we present a framework for reasoning about stability during runtime, leveraging on self-awareness principles. Specifically, we employ runtime goals for managing stability goals, online learning for reasoning about stability on the long-run, and stochastic games for managing associated trade-offs. We evaluate the proposed work using the case of cloud architectures for its highly dynamics during runtime. The experimental results have shown the efficiency of self-awareness techniques in realising the expected behaviour stable during runtime operation.", "num_citations": "1\n", "authors": ["559"]}
{"title": "Modelling and simulation environment for self-adaptive and self-aware cloud architectures\n", "abstract": " Cloud-based software systems are increasingly becoming complex and operating in highly dynamic environments. Self-adaptivity and self-awareness have recently emerged to cope with such level of dynamicity and scalability. Meanwhile, designing and testing such systems have poven to be a challenging task, as well as research benchmarking. Despite the influx of research in both self-adaptivity and cloud computing, as well as the various simulations environments proposed so far, there is a general lack of modelling and simulation environments of self-adaptive and self-aware cloud architectures. To aid researchers and practioners in overcoming such challenges, this paper presents a novel modelling and simulation environment for self-adaptive and self-aware cloud architectures. The environment provides significant benefits for designing self-adaptive and self-aware cloud architectures, as well as testing adaptation and awareness mechanisms. The toolkit is also beneficial as a symbiotic simulator during runtime to support adaptation decisions. We experimentally validated and evaluated the implementation using benchmarks and evaluation use cases.", "num_citations": "1\n", "authors": ["559"]}
{"title": "Identifying Technical Debt in Database Normalization Using Association Rule Mining\n", "abstract": " In previous work, we explored a new context of technical debt that relates to database normalization design decisions. We claimed that database normalization debts are likely to be incurred for tables below the fourth normal form. We proposed a method to prioritize the tables that should be normalized based on their impact on data quality and performance. In this study, we propose a framework to identify normalization debt items (i.e. tables below the fourth normal form) by mining the data stored in each table. Our framework makes use of association rule mining to discover functional dependencies between attributes in a table, which will help determine the current normal form of that table and reveal debt tables. To illustrate our method, we use a case study from Microsoft, AdventureWorks database. The results revealed the applicability of our framework to identify debt tables.", "num_citations": "1\n", "authors": ["559"]}
{"title": "A Market-Based Approach for Detecting Malware in the Cloud via Introspection\n", "abstract": " Traditional anti-virus (AV) solutions are known for their considerable consumption of resources, limiting their usefulness on the cloud. In contrast, cloud-based lightweight malware monitoring approaches consume fewer resources than a full malware scan would normally require, however, they are often prone to false alarms; limiting their effectiveness. In this paper, such a trade-off is addressed by proposing a prioritisation approach, consisting of two protection layers (i.e. lightweight and full malware scanning) to conduct a scalable and effective malware inspection of the cloud Virtual Machines (VMs). The novel contribution of this paper is a market-inspired mechanism that utilises lightweight scanners to prioritise the AV scanning process, by deciding which VM should be thoroughly scanned and when; it will trigger then a full malware scan on a pre-defined percentage of the most critical VMs. The\u00a0\u2026", "num_citations": "1\n", "authors": ["559"]}
{"title": "Thwarting Market Specific Attacks In Cloud\n", "abstract": " Market oriented methodologies have been extensively used for solving dynamic allocation problems in online systems including the Cloud. Despite their extensive use, very little has been known about their security against market specific security threats (e.g. monopoly, shill bidding, etc.). This work follows an experimental driven approach for: (i) promoting the development of threat-aware, market-oriented Clouds, (ii) exposing existing market specific security vulnerabilities and (iii) developing security mechanisms for online markets. We show that the designs of existing market-oriented Clouds are limited when facing market specific attacks and when thwarting malicious bidders and sellers from manipulating auction mechanisms for personal gains. Furthermore, we show that our solutions can effectively resolve market specific attacks and secure bidders, sellers and auctioning mechanisms in the context of Cloud.", "num_citations": "1\n", "authors": ["559"]}
{"title": "An Economics-Driven Approach for Automated SLA Negotiation for Cloud Services Adoption: Aspoc2\n", "abstract": " With the growing number of cloud providers offering a variety of on-demand services, the process of adopting cloud and selecting a cloud provider is becoming laborious and time consuming involving complex and lengthy negotiations to mediate user requirements with that of cloud Service Level Agreement (SLA) provision. To make the method more efficient, there is a need for an effective, dynamic, and flexible automated approach on negotiation for resolving conflicts and mediating user requirements in SLAs. We contribute to a novel method for automated negotiation, which draws inspiration from two economic concepts - Pareto optimality and Bayesian updating. We describe a model which implements bilateral and multiple attribute negotiations. We exemplify the effectiveness of the approach using scenarios.", "num_citations": "1\n", "authors": ["559"]}
{"title": "Evaluating Software Products\n", "abstract": " \u2022 Observational Method\u2022 Focus is on a specific goal while with Project Monitoring data was collected without particular goal in mind\u2022 Project that is undertaken anyway\u2022 Data collection of a few specific attributes\u2022 If they are performed on real projects, they are already \u201cscaled-up\u201d to life size", "num_citations": "1\n", "authors": ["559"]}
{"title": "Special Issue on Software Architecture and Mobility\n", "abstract": " E-businesses are increasingly facing the need for porting the provision of their eservices to mobile customers. Evolving requirements, such as reliability, security, scalability, performance and privacy, from fixed to mobile settings, has revealed new and important challenges. This is due to the behavioural constraints that mobility poses, and that were not faced in traditional distributed settings. Examples include: dynamic network topology, changes in location, constrained resource availability, communication protocols heterogeneity, unstable connectivity, and so forth. Industrial practice is demonstrating that such transition is not straightforward and tends to be costly. In particular, the evolution may break the architecture of the software system, thus calling for substantial and expensive changes. Even when the system is (re) built from scratch, it is unclear if and how the state of the art in software architectures relates to the requirements and concerns brought forward by mobile software systems. Likewise, there is still a lack of systematic software engineering methods and techniques, which can assist in developing and evolving mobile software systems.This Special Issue on Software Architectures and Mobility is commissioned to address these gaps by strengthening the cross fertilization of advances from requirements and domain engineering, software architectures, and middleware to systematically develop and evolve dependable software architectures supporting mobility. The objective is to address challenges and share novel results in developing and evolving dependable mobile software systems.", "num_citations": "1\n", "authors": ["559"]}