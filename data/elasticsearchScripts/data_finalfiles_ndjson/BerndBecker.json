{"title": "A definition and classification of timing anomalies\n", "abstract": " Timing Anomalies are characterized by counterintuitive timing behaviour. A locally faster execution leads to an increase of the execution time of the whole program. The presence of such behaviour makes WCET analysis more difficult: It is not safe to assume local worst-case behaviour wherever the analysis encounters uncertainty. Existing definitions of Timing Anomalies are rather imprecise and intuitive in nature. Some do not cover all kinds of known Timing Anomalies. After giving an overview of related work, we give a concise formal definition of Timing Anomalies. We then begin to identify different classes of anomalies. One of these classes, coined Scheduling Timing Anomalies, coincides with previous restricted definitions.", "num_citations": "257\n", "authors": ["1879"]}
{"title": "How robust is the n-cube?\n", "abstract": " The n-cube network is called faulty if it contains any faulty processor or any faulty link. For any number k we want to compute the minimum number f(n, k) of faults which is necessary for an adversary to make every (n \u2212 k)-dimensional subcube faulty. Reversely formulated: The existence of an (n \u2212 k)-dimensional non-faulty subcube can be guaranteed, if there are less than f(n, k) faults in the n-cube. In this paper several lower and upper bounds for f(n, k) are derived such that the resulting gaps are \u201csmall.\u201d For instance if k \u2265 2 is constant, then f(n, k) = \u03b8(logn). Especially for k = 2 and large n: f(n, 2) \u2208 [[\u03b1n\u2309]: [\u03b1n]\u2309 + 2], where \u03b1n =logn + \u00bd log log n + \u00bd. Or if k = \u03c9(log log n) then 2k < f(n, k) < 2(1 + \u025b)k, with \u025b chosen arbitrarily small. The aforementioned upper bounds are obtained by analysing the behaviour of an adversary who makes \u201cworst-case\u201d distributions of a given number of faulty processors. For k = 2 the \u201cworst\u00a0\u2026", "num_citations": "198\n", "authors": ["1879"]}
{"title": "A family of logical fault models for reversible circuits\n", "abstract": " Reversibility is of interest in achieving extremely low power dissipation; it is also an inherent design requirement of quantum computation. Logical fault models for conventional circuits such as stuck-at models are not wellsuited to quantum circuits. We derive a family of logical fault models for reversible circuits composed of k- CNOT (k-input controlled-NOT) gates and implementable by many technologies. The models are extensions of the previously proposed single missing-gate fault (MGF) model, and include multiple and partial MGFs. We study the basic detection requirements of the new fault types and derive bounds on the size of their test sets. We also present optimal test sets computed via integer linear programming for various benchmark circuits. These results indicate that, although the test sets are generally very small, partial MGFs may need significantly larger test sets than single MGFs.", "num_citations": "141\n", "authors": ["1879"]}
{"title": "Testing for missing-gate faults in reversible circuits\n", "abstract": " Logical reversibility occurs in low-power applications and is an essential feature of quantum circuits. Of special interest are reversible circuits constructed from a class of reversible elements called k-CNOT (controllable NOT) gates. We review the characteristics of k-CNOT circuits and observe that traditional fault models like the stuck-at model may not accurately represent their faulty behavior or test requirements. A new fault model, the missing gate fault (MGF) model, is proposed to better represent the physical failure modes of quantum technologies. It is shown that MGFs are highly testable, and that all MGFs in an N-gate k-CNOT circuit can be detected with from one to [N/2] test vectors. A design-for-test (DFT) method to make an arbitrary circuit fully testable for MGFs using a single test vector is described. Finally, we present simulation results to determine (near) optimal test sets and DFT configurations for some\u00a0\u2026", "num_citations": "127\n", "authors": ["1879"]}
{"title": "Multithreaded SAT solving\n", "abstract": " This paper describes the multithreaded MiraXT SAT solver which was designed to take advantage of current and future shared memory multiprocessor systems. The paper highlights design and implementation details that allow the multiple threads to run and cooperate efficiently. Results show that in single threaded mode, MiraXT compares well to other state of the art solvers on industrial problems. In threaded mode, it provides cutting edge performance, as speedup is obtained on both SAT and UNSAT instances.", "num_citations": "124\n", "authors": ["1879"]}
{"title": "Checking equivalence for partial implementations\n", "abstract": " In this chapter we address the problem of Black Box Equivalence Checking, which occurs when the specification is known, but only parts of the implementation are finished or known. For an example, see Figure 7.1 a and Figure 7.1 b. The latter one shows a partial implementation of the specification given in Figure 7.1 a. It contains two black boxes, BB1 and BB2. Clearly, after a suitable implementation of the two black boxes the final implementation fulfills its specification.Black Box Equivalence Checking enables the use of verification techniques in early stages of the design. Design errors can be already detected when only a partial implementation is at hand\u2013for example, due to a distribution of the implementation task to several groups of designers. Parts of the implementation, which are not yet finished, are combined intoblack boxes. If the implementation differs from the specification for all possible substitutions of\u00a0\u2026", "num_citations": "119\n", "authors": ["1879"]}
{"title": "K* BMDs: A new data structure for verification\n", "abstract": " Recently, two new dates structures have been proposed in the area of Computer Aided Design (CAD), i.e. Ordered Kronecker Functional Decision Diagrams (OKFDDs) and Multiplicative Binary Moment Diagrams (*BMDs). OKFDDs are the most general ordered data structure for representing Boolean functions at the bit-level. *BMDs are especially applicable to integer valued functions. In this paper we propose a new data structure, called Kronecker Multiplicative BMDs (K*BMDs), that is a generalization of OKFDDs to the word-level. Using K*BMDs it is possible to represent functions efficiently, that have a good word-level description, since K*BMDs are a generalization of *BMDs. On the other hand they are also applicable to verification problems at the bit-level. We present experimental results to demonstrate the efficiency of our approach including a comparison of K*BMDs to several other data structures, like\u00a0\u2026", "num_citations": "108\n", "authors": ["1879"]}
{"title": "Simulating resistive-bridging and stuck-at faults\n", "abstract": " The authors present a simulator for resistive-bridging and stuck-at faults. In contrast to earlier work, it is based on electrical equations rather than table look up, thus, exposing more flexibility. For the first time, simulation of sequential circuits is dealt with; interaction of fault effects in current time frame and earlier time frames is elaborated on for different bridge resistances. Experimental results are given for resistive-bridging and stuck-at faults in combinational and sequential circuits. Different definitions of fault coverage are listed, and quantitative results with respect to all these definitions are given for the first time", "num_citations": "99\n", "authors": ["1879"]}
{"title": "On the relation between BDDs and FDDs\n", "abstract": " Data structures for Boolean functions form an essential component of design automation tools, especially in the area of logic synthesis. The slate of the art data structure is the ordered binary decision diagram (OBDD), which results from general binary decision diagrams (BDDs), also called branching programs, by the application of ordering restrictions. In the context of EXOR-based logic synthesis another type of decision diagram (DD), called (ordered) functional decision diagram ((O)FDD), becomes important. We study the relation between (ordered, free) BDDs and FDDs. Both BDDs and FDDs result from DDs by defining the represented function in different ways. If the underlying DD is complete, the relation between these two types of interpretation can be described by a Boolean transformation \u03c4. This allows us to relate the FDD-size of \u0192 and the BDD-size of \u03c4(\u0192) also in the case where the corresponding DDs are\u00a0\u2026", "num_citations": "90\n", "authors": ["1879"]}
{"title": "PaMiraXT: Parallel SAT solving with threads and message passing\n", "abstract": " This article describes PaMiraXT, a powerful parallel SAT algorithm. PaMiraXT follows a master/client model based on message passing, making it suitable for any kind of workstation cluster. For the clients, MiraXT is used, which itself is thread-based parallel solver designed to take advantage of current and future shared memory multiprocessor systems. We highlight design and implementation details that allow the threads/clients to run and cooperate efficiently. Experimental results show that MiraXT compares well to other state-of-the-art SAT algorithms. In single-threaded mode, it outperforms MiniSat2, PicoSAT 535, and RSat 2.01, while in multi-threaded mode, MiraXT provides cutting edge performance, as it solves significantly more instances within the given time limit. A case study, using three copies of MiraXT with a total of 8 threads as clients, underlines the potential of PaMiraXT, resulting in a speedup of 5.62\u00a0\u2026", "num_citations": "82\n", "authors": ["1879"]}
{"title": "An analysis framework for transient-error tolerance\n", "abstract": " Transient or soft errors are an increasing problem in mainstream microelectronics. We propose a framework for modeling transient-error tolerance (TET) in logic circuits. We classify transient errors as critical or non-critical according to their impact on circuit behavior, such as their ability to disturb the internal state for specified periods of time. We introduce a metric called the critical soft-error rate (CSER) as an alternative to conventional SER, and present some analysis strategies based on CSER. This approach employs a new single transient fault (STF) model, which is defined in terms of a temporary stuck-at fault and its associated circuit state. Although basically technology-independent, STFs can be extended with low-level physical attributes. With STFs, we can estimate the transient error probability p err  of a circuit's nodes, as well as various measures of error susceptibility and TET. We demonstrate the use of\u00a0\u2026", "num_citations": "78\n", "authors": ["1879"]}
{"title": "The K* BMD: A verification data structure\n", "abstract": " Circuit designers can efficiently verify designs at the bit and word levels in one graph-based data structure. The authors present the representation technique, manipulation algorithms for K*BMDs, and experimental results other data structures.", "num_citations": "75\n", "authors": ["1879"]}
{"title": "How many decomposition types do we need?[decision diagrams]\n", "abstract": " Decision Diagrams (DDs) are used in many applications in CAD. Various types of DDs, e.g. BDDs, FDDs, KFDDs, differ by their decomposition types. In this paper we investigate the different decomposition types and prove that there are only three that really help to reduce the size of DDs.< >", "num_citations": "74\n", "authors": ["1879"]}
{"title": "Power droop testing\n", "abstract": " Circuit activity is a function of input patterns. When circuit activity changes abruptly, it can cause sudden drop or rise in power supply voltage. This change is known as power droop and is an instance of power supply noise. Although power droop may cause an IC to fail, such failures cannot currently be screened during testing as it is not covered by conventional fault models. In this paper we present a technique for screening such failures. We propose a heuristic method to generate test sequences which create worst-case power drop by accumulating the high-frequency and low-frequency effects. The generated patterns need to be sequential even for scan designs. We employ a dynamically constrained version of the classical D-algorithm for test generation, i.e., the algorithm generates new constraints on-the-fly depending on previous assignments. The obtained patterns can be used for manufacturing testing as\u00a0\u2026", "num_citations": "70\n", "authors": ["1879"]}
{"title": "Ordered Kronecker functional decision diagrams-a data structure for representation and manipulation of Boolean functions\n", "abstract": " Ordered Kronecker functional decision diagrams (OKFDD's) are a data structure for efficient representation and manipulation of Boolean functions. OKFDD's are a generalization of ordered binary decision diagrams (OBDD)s) and ordered functional decision diagrams and thus combine the advantages of both. In this paper, basic properties of OKFDD's and their efficient representation and manipulation are given. Starting with elementary manipulation algorithms, we present methods for the construction of small OKFDD's. Our approach is based on dynamic variable ordering and decomposition-type choice. For changing the decomposition type, we use an efficient reordering-based method. We briefly discuss the implementation of PUMA, an OKFDD package, which was used in all our experiments. These experiments demonstrate the quality of our methods in comparison to sifting and interleaving for OBDD's.", "num_citations": "65\n", "authors": ["1879"]}
{"title": "A simulator of small-delay faults caused by resistive-open defects\n", "abstract": " We present a simulator which determines the coverage of small-delay faults, i.e., delay faults with a size below one clock cycle, caused by resistive-open defects. These defects are likely to escape detection by stuck-at or transition fault patterns. For the first time, we couple the calculation of the critical size of a small-delay fault with the computation of the resistance range of the corresponding resistive-open defect for which this size is exceeded. By doing so, we are able to extend probabilistic fault coverage metrics initially developed for static resistive bridging faults to small-delay defects.", "num_citations": "63\n", "authors": ["1879"]}
{"title": "Small-delay-fault ATPG with waveform accuracy\n", "abstract": " The detection of small-delay faults is traditionally performed by sensitizing transitions on a path of sufficient length from an input to an output of the circuit going through the fault site. While this approach allows efficient test generation algorithms, it may result in false positives and false negatives as well, i.e. undetected faults are classified as detected or detectable faults are classified as undetectable. We present an automatic test pattern generation algorithm which considers waveforms and their propagation on each relevant line of the circuit. The model incorporates individual delays for each gate and filtering of small glitches. The algorithm is based on an optimized encoding of the test generation problem by a Boolean satisfiability (SAT) instance and is implemented in the tool WaveSAT. Experimental results for ISCAS-85, ITC-99 and industrial circuits show that no known definition of path sensitization can eliminate\u00a0\u2026", "num_citations": "61\n", "authors": ["1879"]}
{"title": "Synthesis for testability: Binary decision diagrams\n", "abstract": " We investigate the testability properties of Boolean circuits derived from (Reduced Ordered) Binary Decision Diagrams. It is shown that BDD-cirucits (or at least) BDD-like circuits are easily testable with respect to different fault models (cellular, stuck-at and path delay fault model). Furthermore the circuits and the test sets can be constructed efficiently.", "num_citations": "60\n", "authors": ["1879"]}
{"title": "Sympathy: fast exact minimization of fixed polarity Reed-Muller expressions for symmetric functions\n", "abstract": " In this paper a polynomial time algorithm for the minimization of Fixed Polarity Reed-Muller Expressions (FPRMs) for totally symmetric functions based on Ordered Functional Decision Diagrams (OFDDs) is presented. A generalization to partially symmetric functions is investigated. The algorithm has been implemented as the program Sympathy. Experimental results in comparison to previously published methods are given to show the efficiency of the approach.< >", "num_citations": "59\n", "authors": ["1879"]}
{"title": "MORE: an alternative implementation of BDD packages by multi-operand synthesis\n", "abstract": " In this paper we present a new approach for the realization of a BDD package. This approach does not depend on recursive synthesis operations, i.e. the ternary If-Then-Else-operator (ITE), to perform manipulations of Boolean functions; instead our basic operation MORE is based on exchanges of neighbouring variables and existential quantification. It is capable of combining an arbitrary number of Boolean functions in parallel. We discuss the difference between MORE and ITE and give experimental results to show the advantages of our implementation approach with respect to size and runtime.", "num_citations": "58\n", "authors": ["1879"]}
{"title": "A genetic algorithm for minimization of fixed polarity Reed-Muller expressions\n", "abstract": " A Genetic Algorithm (GA) is developed to find small or minimal Fixed Polarity Reed-Muller expressions (FPRMs) for large functions. We combine the GA with greedy heuristics, i.e. we use Hybrid GAs (HGAs). We show by experiments that results superior to all other approaches for large functions can be obtained using GAs.", "num_citations": "58\n", "authors": ["1879"]}
{"title": "Towards Verification of Artificial Neural Networks.\n", "abstract": " We consider the safety verification of controllers obtained via machine learning. This is an important problem as the employed machine learning techniques work well in practice, but cannot guarantee safety of the produced controller, which is typically represented as an artificial neural network. Nevertheless, such methods are used in safety-critical environments. In this paper we take a typical control problem, namely the Cart Pole System (aka inverted pendulum), and a model of its physical environment and study safety verification of this system. To do so, we use bounded model checking (BMC). The created formulas are solved with the SMT-solver iSAT3. We examine the problems that occur during solving these formulas and show that extending the solver by special deduction routines can reduce both memory consumption and computation time on such instances significantly. This constitutes a first step towards verification of machine-learned controllers, but a lot of challenges remain.", "num_citations": "57\n", "authors": ["1879"]}
{"title": "Automatic test pattern generation for interconnect open defects\n", "abstract": " We present a fully automated flow to generate test patterns for interconnect open defects. Both inter-layer opens (open- via defects) and arbitrary intra-layer opens can be targeted. An aggressor-victim model used in industry is employed to describe the electrical behavior of the open defect. The flow is implemented using standard commercial tools for parameter extraction (PEX) and test generation (ATPG). A highly optimized branch-and bound algorithm to determine the values to be assigned to the aggressor lines is used to reduce both the ATPG efforts and the number of aborts. The resulting test sets are smaller and achieve a higher defect coverage than stuck-at n-detection test sets, and are robust against process variations.", "num_citations": "57\n", "authors": ["1879"]}
{"title": "Resistive bridge fault model evolution from conventional to ultra deep submicron\n", "abstract": " We present three resistive bridging fault models valid for different CMOS technologies. The models are partitioned into a general framework (which is shared by all three models) and a technology-specific part. The first model is based on Shockley equations and is valid for conventional but not deep submicron CMOS. The second model is obtained by fitting SPICE data. The third resistive bridging fault model uses Berkeley predictive technology model and BSIM4; it is valid for CMOS technologies with feature sizes of 90nm and below, accurately describing non-trivial electrical behavior in that technologies. Experimental results for ISCAS circuits show that the test patterns obtained for the Shockley model are still valid for the fitted model, but lead to coverage loss under the predictive model.", "num_citations": "56\n", "authors": ["1879"]}
{"title": "On the optimal layout of planar graphs with fixed boundary\n", "abstract": " The optimal planar layout of planar graphs with respect to the - or -metric leads to NP-hard problems, if one assumes the nodes of the graph to be fixed in the plane (see [FiPa], [Be]).In this paper we consider the (optimal) layout of graphs with fixed boundary (i.e., graphs, where only the nodes of a given cycle of the graph have fixed positions in the plane). The investigated layouts are straight line embeddings in a continuous part of the plane; the cost of a layout is calculated with help of very general cost functions including the pth power of the usual Euclidean distance metric for  (for short, -metric).For a large class of graphs, which, for example, occur in chip layout problems as the abstract structure of switching circuits, we show the existence and uniqueness of the optimal layout.The main part of the paper is concerned with planar graphs. We get an interesting characterization of nonplanar layouts of\u00a0\u2026", "num_citations": "54\n", "authors": ["1879"]}
{"title": "Learning heuristics for OBDD minimization by evolutionary algorithms\n", "abstract": " Ordered Binary Decision Diagrams (OBDDs) are the state-of-the-art data structure in CAD for ICs. OBDDs are very sensitive to the chosen variable ordering, i.e. the size may vary from linear to exponential.             In this paper we present an Evolutionary Algorithm (EA) that learns good heuristics for OBDD minimization starting from a given set of basic operations. The difference to other previous approaches to OBDD minimization is that the EA does not solve the problem directly. Rather, it developes strategies for solving the problem.             To demonstrate the efficiency of our approach experimental results are given. The newly developed heuristics are more efficient than other previously presented methods.", "num_citations": "53\n", "authors": ["1879"]}
{"title": "A BDD-based algorithm for computation of exact fault detection probabilities\n", "abstract": " Signal and fault detection probabilities are widely used in the area of testing. Due to the computational complexity, in most cases only approximated values are computed. A system called PLATO which allows the computation of the exact values for many combinational circuits is described. The implemented algorithms use the recently developed BDD packages as data structure. Besides the description of the algorithms, attention is given to general problems arising with the use of BDDs as data structure. Some new heuristics are presented to deal with these problems.", "num_citations": "53\n", "authors": ["1879"]}
{"title": "Technische Informatik\n", "abstract": " Das vorliegende Buch ist eine \u00dcberarbeitung des Buches \u201eTechnische Informatik. Eine Einf\u00fchrung \u201c, das vor drei Jahren bei Pearson Studium erschienen ist. Wenn auch die Entwicklung von Rechnern und die Bedeutung integrierter Schaltungen und eingebetteter Systeme in diesen drei Jahren weiter rasant voran geschritten ist, die f\u00fcr das Basisverst\u00e4ndnis notwendigen Grundlagen haben sich nicht wesentlich ver\u00e4ndert.", "num_citations": "51\n", "authors": ["1879"]}
{"title": "On the generation of multiplexer circuits for pass transistor logic\n", "abstract": " Pass Transistor Logic (PTL) has attracted more and more interest during recent years, since it has proved to be an attractive alternative to static CMOS designs with respect to area, performance and power consumption. Existing automatic PTL synthesis tools use a direct mapping of (decomposed) BDDs to pass transistors. Thereby, structural properties of BDDs like the ordering restriction and the fact that the select signals of the multiplexers (corresponding to BDD nodes) directly depend on input variables, are imposed on PTL circuits although they are not necessary for PTL synthesis. General multiplexer circuits can be used instead and should provide a much higher potential for optimization compared to a pure BDD approach. Nevertheless-to the best of our knowledge-an optimization of general Multiplexer Circuits (MCs) for PTL synthesis has not been tried so far due to a lack of suitable optimization approaches\u00a0\u2026", "num_citations": "50\n", "authors": ["1879"]}
{"title": "On the representational power of bit-level and word-level decision diagrams\n", "abstract": " Several types of Decision Diagrams (DDs) have have been proposed in the area of Computer Aided Design (CAD), among them being bit-level DDs like OBDDs, OFDDs and OKFDDs. While the aforementioned types of DDs are suitable for representing Boolean functions at the bit-level and have proved useful for a lot of applications in CAD, recently DDs to represent integer-valued functions, like MTBDDs (=ADDs), EVBDDs, FEVBDDs, (*)BMDs, HDDs (=KBMDs), and K*BMDs, attract more and more interest, e.g., using *BMDs it was for the first time possible to verify multipliers of bit length up to n=256. In this paper we clarify the representational power of these DD classes. Several (inclusion) relations and (exponential) gaps between specific classes differing in the availability of additive and/or multiplicative edge weights and in the choice of decomposition types are shown. It turns out for example, that K(*)BMDs, a\u00a0\u2026", "num_citations": "50\n", "authors": ["1879"]}
{"title": "Dynamic minimization of OKFDDs\n", "abstract": " We present methods for the construction of small Ordered Kronecker Functional Decision Diagrams (OKFDDs). OKFDDs are a generalization of Ordered Binary Decision Diagrams (OBDDs) and Ordered Functional Decision Diagrams (OFDDs) as well. Our approach is based on dynamic variable ordering and decomposition type choice. For changing the decomposition type we use a new method. We briefly discuss the implementation of PUMA, our OKFDD package. The quality of our methods in comparison with sifting and interleaving for OBDDs is demonstrated based on experiments performed with PUMA.", "num_citations": "49\n", "authors": ["1879"]}
{"title": "Modeling and mitigating transient errors in logic circuits\n", "abstract": " Transient or soft errors caused by various environmental effects are a growing concern in micro and nanoelectronics. We present a general framework for modeling and mitigating the logical effects of such errors in digital circuits. We observe that some errors have time-bounded effects; the system's output is corrupted for a few clock cycles, after which it recovers automatically. Since such erroneous behavior can be tolerated by some applications, i.e., it is noncritical at the system level, we define the critical soft error rate (CSER) as a more realistic alternative to the conventional SER measure. A simplified technology-independent fault model, the single transient fault (STF), is proposed for efficiently estimating the error probabilities associated with individual nodes in both combinational and sequential logic. STFs can be used to compute various other useful metrics for the faults and errors of interest, and the required\u00a0\u2026", "num_citations": "48\n", "authors": ["1879"]}
{"title": "Antom\u2014solver description\n", "abstract": " This note briefly describes our first prototype of antom, a DPLL-like parallel SAT solver based on the algorithm portfolio principle. Up to eight copies of antom\u2019s sequential SAT solving unit are running in parallel, each of them having an individual set of parameters. The following parts of the core engine were used to differentiate between the threads:", "num_citations": "48\n", "authors": ["1879"]}
{"title": "Compositional performability evaluation for statemate\n", "abstract": " This paper reports on our efforts to link an industrial state-of-the-art modelling tool to academic state-of-the-art analysis algorithms. In a nutshell, we enable timed reachability analysis of uniform continuous-time Markov decision processes, which are generated from STATEMATE models. We give a detailed explanation of several construction, transformation, reduction, and analysis steps required to make this possible. The entire tool flow has been implemented, and it is applied to a nontrivial example", "num_citations": "48\n", "authors": ["1879"]}
{"title": "Orthogonal Hypergraph Drawing for Improved Visibility.\n", "abstract": " Visualization of circuits is an important research area in electronic design automation. One commonly accepted method to visualize a circuit aligns the gates to layers and uses orthogonal lines to connect the gates. In our model we assume that between two consecutive layers every net is allowed to occupy only one track. This avoids unnecessary bends in the wires and helps to improve the clarity of the drawing. Then a crossing reduction step is applied to further improve the readability of the circuit schematics.First we assume that the nodes have already been fixed on a layered hypergraph structure. We consider the problem of assigning the hyperedges between two layers to tracks. The idea is to minimize the total number of hyperedge crossings. We prove that finding the best solution is NP-hard. Then, in contrast to many other approaches which route all the wiring after placing all nodes we focus on a new approach which dynamically reorders the nodes within the layers to further reduce the number of hyperedge crossings. An efficient algorithm is presented that minimizes the hyperedge crossings. Experimental results are provided which show that the drawings can be improved significantly while the running time remains moderate.", "num_citations": "48\n", "authors": ["1879"]}
{"title": "Optimizing bounded model checking for linear hybrid systems\n", "abstract": " Bounded model checking (BMC) is an automatic verification method that is based on finitely unfolding the system\u2019s transition relation. BMC has been successfully applied, in particular, for discovering bugs in digital system design. Its success is based on the effectiveness of satisfiability solvers that are used to check for a finite unfolding whether a violating state is reachable. In this paper we improve the BMC approach for linear hybrid systems. Our improvements are tailored to lazy satisfiability solving and follow two complementary directions. First, we optimize the formula representation of the finite unfoldings of the transition relations of linear hybrid systems, and second, we accelerate the satisfiability checks by accumulating and generalizing data that is generated during earlier satisfiability checks. Experimental results show that the presented techniques accelerate the satisfiability checks significantly.", "num_citations": "47\n", "authors": ["1879"]}
{"title": "Functional simulation using binary decision diagrams\n", "abstract": " In many verification techniques, fast functional evaluation of a Boolean network is needed. We investigate the idea of using binary decision diagrams (BDDs) for functional simulation. The area-time trade-off that results from different minimization techniques of the BDD is discussed. We propose new minimization methods based on dynamic reordering that allow smaller representations with (nearly) no runtime penalty.", "num_citations": "47\n", "authors": ["1879"]}
{"title": "A study of cognitive resilience in a JPEG compressor\n", "abstract": " Many classes of applications are inherently tolerant to errors. One such class are applications designed for a human end user, where the capabilities of the human cognitive system (cognitive resilience) may compensate some of the errors produced by the application. We present a methodology to automatically distinguish between tolerable errors in imaging applications which can be handled by the human cognitive system and severe errors which are perceptible to a human end user. We also introduce an approach to identify non-critical spots in a hardware circuit which should not be hardened against soft errors because errors that occur on these spots are tolerable. We demonstrate that over 50% of flip-flops in a JPEG compressor chip are non-critical and require no hardening.", "num_citations": "46\n", "authors": ["1879"]}
{"title": "The pros and cons of very-low-voltage testing: an analysis based on resistive bridging faults\n", "abstract": " Test application at reduced power supply voltage (or VLV testing) is a cost-effective way to increase the defect coverage of a test set. Resistive short defects are a major contributor to this coverage increase. Using a probabilistic model of these defects, we quantify the coverage impact of VLV testing for different voltages. When considering the coverage increase, we differentiate between defects missed by the test set at nominal voltage and undetectable defects (flaws) detected by VLV testing. In our analysis, the performance degradation of the device caused by lower power supply voltage is accounted for. Furthermore, we describe a situation in which defects detected by conventional testing are missed by VLV testing and quantify the resulting coverage loss. We report the numbers on the increased defect coverage, flaw coverage, and coverage loss for ISCAS circuits.", "num_citations": "45\n", "authors": ["1879"]}
{"title": "Automatic test pattern generation for resistive bridging faults\n", "abstract": " An ATPG for resistive bridging faults is proposed that combines the advantages of section-based generation and interval-based simulation. In contrast to the solutions introduced so far, it can handle arbitrary non-feedback bridges between two nodes, including ones detectable at higher resistance and undetectable at lower resistance, and faults requiring more than one vector for detection.", "num_citations": "45\n", "authors": ["1879"]}
{"title": "Efficient testing of optimal time adders\n", "abstract": " Considers the design of two well-known optimal time adders: the carry look-ahead adder and the conditional sum adder. It is shown that 6 log/sub 2/(n)-4 and 6 log/sub 2/(n)+2 test patterns suffice to completely test the n-bit carry look-ahead adder and the n-bit conditional sum adder with respect to the single stuck-at fault model (for a given set of basic cells). The results are considered pertinent to establishing the correct behavior of a given VLSI chip.< >", "num_citations": "45\n", "authors": ["1879"]}
{"title": "Equivalence checking of partial designs using dependency quantified Boolean formulae\n", "abstract": " We consider the partial equivalence checking problem (PEC), i. e., checking whether a given partial implementation of a combinational circuit can (still) be extended to a complete design that is equivalent to a given full specification. To solve PEC, we give a linear transformation from PEC to the question whether a dependency quantified Boolean formula (DQBF) is satisfied. Our novel algorithm to solve DQBF based on quantifier elimination can therefore be applied to solve PEC.We also present first experimental results showing the feasibility of our approach and the inaccuracy of QBF approximations, which are usually used for deciding the PEC so far.", "num_citations": "44\n", "authors": ["1879"]}
{"title": "Minimal critical subsystems for discrete-time Markov models\n", "abstract": " We propose a new approach to compute counterexamples for violated \u03c9-regular properties of discrete-time Markov chains and Markov decision processes. Whereas most approaches compute a set of system paths as a counterexample, we determine a critical subsystem that already violates the given property. In earlier work we introduced methods to compute such subsystems based on a search for shortest paths. In this paper we use SMT solvers and mixed integer linear programming to determine minimal critical subsystems.", "num_citations": "44\n", "authors": ["1879"]}
{"title": "Counterexample generation for discrete-time Markov chains using bounded model checking\n", "abstract": " Since its introduction in 1999, bounded model checking has gained industrial relevance for detecting errors in digital and hybrid systems. One of the main reasons for this is that it always provides a counterexample when an erroneous execution trace is found. Such a counterexample can guide the designer while debugging the system.               In this paper we are investigating how bounded model checking can be applied to generate counterexamples for a different kind of model\u2014namely discrete-time Markov chains. Since in this case counterexamples in general do not consist of a single path to a safety-critical state, but of a potentially large set of paths, novel optimization techniques like loop-detection are applied not only to speed-up the counterexample computation, but also to reduce the size of the counterexamples significantly. We report on some experiments which demonstrate the practical\u00a0\u2026", "num_citations": "44\n", "authors": ["1879"]}
{"title": "Intelligent CAD process\n", "abstract": " An adaptive CAD system, comprising:(a) gathering data consisting of at least one of (i) human generated information and techniques, and (ii) machine generated information and rules;(b) processing the gathered data by instructions to produce processed knowledge containing script without a product or part design;(c) recursively editing the processed knowledge to continuously improve the script to form an executable part design, such processing being carried out by inputting into the editing process at least one of (i) recently learned data,(ii) associative techniques, relations and features, and (iii) knowledge-based rules and instructions and (d) inputting the history of step (c) into processed knowledge, such inputting creating captured improvement criteria, that is iteratively and recursively feeding back into either the recursive editing process or into processing of step (b) to effect evolvement of an executable design\u00a0\u2026", "num_citations": "44\n", "authors": ["1879"]}
{"title": "Recent Improvements in the SMT Solver iSAT.\n", "abstract": " Over the past decades embedded systems have become more and more complex. Furthermore, besides digital components they now often contain additional analog parts\u2013making them to embedded hybrid systems. If such systems are used in safety critical environments, a formal correctness proof is highly desirable. The SMT solver iSAT aims at solving boolean combinations of linear and non-linear constraint formulas (including transcendental functions), and thus is suitable to verify safety properties of systems consisting of both, linear and nonlinear behaviour. To keep up with the ever increasing complexity of these systems we present recent improvements in various parts of iSAT. Experiments demonstrate that iSAT with all the presented improvements integrated typically gains a speedup between one and two orders of magnitude.", "num_citations": "43\n", "authors": ["1879"]}
{"title": "BDDs in a branch and cut framework\n", "abstract": " Branch & Cut is today\u2019s state-of-the-art method to solve 0/1-integer linear programs. Important for the success of this method is the generation of strong valid inequalities, which tighten the linear programming relaxation of 0/1-IPs and thus allow for early pruning of parts of the search tree.               In this paper we present a novel approach to generate valid inequalities for 0/1-IPs which is based on Binary Decision Diagrams (BDDs). BDDs are a datastructure which represents 0/1-vectors as paths of a certain acyclic graph. They have been successfully applied in computational logic, hardware verification and synthesis.               We implemented our BDD cutting plane generator in a branch-and-cut framework and tested it on several instances of the MAX-ONES problem and randomly generated 0/1-IPs. Our computational results show that we have developed competitive code for these problems, on which state\u00a0\u2026", "num_citations": "43\n", "authors": ["1879"]}
{"title": "Automatic identification of timing anomalies for cycle-accurate worst-case execution time analysis\n", "abstract": " Hard real-time systems need methods to determine upper bounds for their execution times, usually called worst-case execution times. Timing anomalies are counterintuitive conditions in which a local speed-up of an instruction results in a global slow-down. Modern efficient timing analysis tools may yield inaccurate results when applied to processors with timing anomalies while methods which are suited for timing-anomalous systems are computationally expensive. Timing anomaly identification is key in choosing the right analysis technique for a given processor. In this paper, for the first time, an automated timing anomaly identification approach based on formal methods is presented. We validate the method by applying it to a simplified microprocessor using a commercial model checking tool", "num_citations": "42\n", "authors": ["1879"]}
{"title": "A unified fault model and test generation procedure for interconnect opens and bridges\n", "abstract": " A unified gate-level fault model for interconnect opens and bridges is proposed. Defects are modeled as constrained multiple line stuck-at faults. A novel feature of the proposed fault model is its flexibility to accommodate increasing levels of accuracy. Additionally the model does not require accurate device level circuit models to achieve desired accuracy. Efficient methods for fault simulation and test generation are discussed and experimental results on benchmark circuits and industrial designs are presented. The experimental results presented show that the tests generated using simpler versions of the proposed fault model achieve higher defect coverage than the tests using two currently popular methods to derive high defect coverage tests.", "num_citations": "42\n", "authors": ["1879"]}
{"title": "Thread-parallel integrated test pattern generator utilizing satisfiability analysis\n", "abstract": " Efficient utilization of the inherent parallelism of multi-core architectures is a grand challenge in the field of electronic design automation (EDA). One EDA algorithm associated with a high computational cost is automatic test pattern generation (ATPG). We present the ATPG tool TIGUAN based on a thread-parallel SAT solver. Due to a tight integration of the SAT engine into the ATPG algorithm and a carefully chosen mix of various optimization techniques, multi-million-gate industrial circuits are handled without aborts. TIGUAN supports both conventional single-stuck-at faults and sophisticated conditional multiple stuck-at faults which allows to generate patterns for non-standard fault models. We demonstrate how TIGUAN can be combined with conventional structural ATPG to extract full benefit of the intrinsic strengths of both approaches.", "num_citations": "41\n", "authors": ["1879"]}
{"title": "Testability of 2-level AND/EXOR circuits\n", "abstract": " It is often stated that AND/EXOR circuits are much easier to test than AND/OR circuits. This statement, however, only holds true for circuits derived from restricted classes of AND/EXOR expressions, like positive polarity Reed-Muller and fixed polarity Reed-Muller expressions. For these two classes of expressions, circuits with good deterministic testability properties are known. In this paper we show that these circuits also have good random pattern testability attributes. An input probability distribution is given that yields a short expected test length for biased random patterns. This is the first time theoretical results on random pattern testability are presented for 2-level AND/EXOR circuit realizations of arbitrary Boolean functions. It turns out that analogous results cannot be expected for less restricted classes of 2-level AND/EXOR circuits. We present experiments demonstrating that generally minimized 2-level\u00a0\u2026", "num_citations": "41\n", "authors": ["1879"]}
{"title": "LIRA: Handling constraints of linear arithmetics over the integers and the reals\n", "abstract": " The mechanization of many verification tasks relies on efficient implementations of decision procedures for fragments of first-order logic. Interactive theorem provers like pvs also make use of such decision procedures to increase the level of automation. Our tool lira implements decision procedures based on automata-theoretic techniques for first-order logics with linear arithmetic, namely, for FO(\u2115, +), FO(\u2124,+,<), and FO(\u211d, \u2124,+,<).", "num_citations": "40\n", "authors": ["1879"]}
{"title": "TIGUAN: Thread-parallel integrated test pattern generator utilizing satisfiability analysis\n", "abstract": " We present the automatic test pattern generator TIGUAN based on a thread-parallel SAT solver. Due to a tight integration of the SAT engine into the ATPG algorithm and a carefully chosen mix of various optimization techniques, multi-million-gate industrial circuits are handled without aborts. TIGUAN supports both conventional single-stuck-at faults and sophisticated conditional multiple stuck-at faults which allows to generate patterns for non-standard fault models.", "num_citations": "39\n", "authors": ["1879"]}
{"title": "Pamira-a parallel sat solver with knowledge sharing\n", "abstract": " In this paper we describe PaMira, a powerful distributed SAT solver. PaMira is based on the highly optimized, sequential SAT engine Mira, incorporating all essential optimization techniques modern algorithms utilize to maximize performance. For the distributed execution an efficient work stealing method has been implemented. PaMira also employs the exchange of conflict clauses between the processes to guide the search more efficiently. We provide experimental results showing linear speedup on a multiprocessor environment with four AMD Opteron processors", "num_citations": "39\n", "authors": ["1879"]}
{"title": "HQSpre\u2013an effective preprocessor for QBF and DQBF\n", "abstract": " We present our new preprocessor HQSpre, a state-of-the-art tool for simplifying quantified Boolean formulas (QBFs) and the first available preprocessor for dependency quantified Boolean formulas\u00a0(DQBFs). The latter are a generalization of QBFs, resulting from adding so-called Henkin-quantifiers to QBFs. HQSpre\u00a0applies most of the preprocessing techniques that have been proposed in the literature. It can be used both as a standalone tool and as a library. It is possible to tailor it towards different solver back-ends, e.\u00a0g., to preserve the circuit structure of the formula when a non-CNF solver back-end is used. Extensive experiments show that HQSpre\u00a0allows QBF solvers to solve more benchmark instances and is able to decide more instances on its own than state-of-the-art tools. The same impact can be observed in the DQBF domain as well.", "num_citations": "38\n", "authors": ["1879"]}
{"title": "Extraction, simulation and test generation for interconnect open defects based on enhanced aggressor-victim model\n", "abstract": " We present a flow to extract, simulate and generate test patterns for interconnect open defects. In contrast to previous work, the accuracy of defect modeling is improved by taking the thresholds of logic gates as well as noise margins into account. Efficient fault simulation is enabled by employing an aggressive fault collapsing strategy and an optimized fault list ordering heuristic which allows to combine the advantages of event-driven simulation with bit parallelism. Test generation complexity is kept in check by generating patterns for technology-independent segment-stuck-at faults first, thus reducing (though not completely eliminating) the need for sophisticated technology-aware test generation. Moreover, a comprehensive untestability analysis identifies new classes of untestable faults. Experimental results demonstrate high efficiency of the new flow, outperforming earlier work by two orders of magnitude.", "num_citations": "38\n", "authors": ["1879"]}
{"title": "Hierarchical design based on a calculus of nets\n", "abstract": " We present an algebraic approach to hierarchical design of integrated circuits. This approach is based on a \u201ccalculus of nets\u201d which includes topological as well as behavioural aspects of integrated circuits. We have developed a hierarchical design system called CADIC which is build around this calculus in much the same way as eg Algol is build around numerics. An example for the design of a family of fast adders will demonstrate the power of this calculus. Finally we will give a summary outline on the structure of procedures which automatically transform the design into lower design levels.", "num_citations": "38\n", "authors": ["1879"]}
{"title": "Solving DQBF through quantifier elimination\n", "abstract": " We show how to solve dependency quantified Boolean formulas (DQBF) using a quantifier elimination strategy which yields an equivalent QBF that can be decided using any standard QBF solver. The elimination is accompanied by a number of optimizations which help reduce memory consumption and computation time. We apply our solver HQS to problems from the domain of verification of incomplete combinational circuits to demonstrate the effectiveness of the proposed algorithm. The results show enormous improvements both in the number of solved instances and in the computation times compared to existing work on validating DQBF.", "num_citations": "37\n", "authors": ["1879"]}
{"title": "Speedup techniques utilized in modern SAT solvers\n", "abstract": " This paper describes and compares features and techniques modern SAT solvers utilize to maximize performance. Here we focus on: Implication Queue Sorting (IQS) combined with Early Conflict Detection Based BCP (ECDB); and a modified decision heuristic based on the combination of Variable State Independent Decaying Sum (VSIDS), Berkmin, and Siege\u2019s Variable Move to Front (VMTF). These features were implemented and compared within the framework of the MIRA SAT solver. The efficient implementation and analysis of these features are presented and the speedup and robustness each feature provides is demonstrated. Finally, with everything enabled (ECDB with IQS and advanced decision heuristics), MIRA was able to consistently outperform zChaff and even Forklift on the benchmarks provided, solving 37 out of 111 industrial benchmarks compared to zChaff\u2019s 21 and Forklift\u2019s 28.", "num_citations": "37\n", "authors": ["1879"]}
{"title": "Incremental preprocessing methods for use in BMC\n", "abstract": " Traditional incremental SAT solvers have achieved great success in the domain of Bounded Model Checking (BMC). Recently, modern solvers have introduced advanced preprocessing procedures that have allowed them to obtain high levels of performance. Unfortunately, many preprocessing techniques such as variable and (blocked) clause elimination cannot be directly used in an incremental manner. This work focuses on extending these techniques and Craig interpolation so that they can be used effectively together in incremental SAT solving (in the context of BMC). The techniques introduced here doubled the performance of our BMC solver on both SAT and UNSAT problems. For UNSAT problems, preprocessing had the added advantage that Craig interpolation was able to find the fixed point sooner, reducing the number of incremental SAT iterations. Furthermore, our ideas seem to perform better\u00a0\u2026", "num_citations": "36\n", "authors": ["1879"]}
{"title": "Transient fault characterization in dynamic noisy environments\n", "abstract": " Technology trends are increasing the frequency of serious transient (soft) faults in digital systems. For example, ICs are becoming more susceptible to cosmic radiation, and are being embedded in applications with dynamic noisy environments. We propose a generic framework for representing such faults and characterizing them on-line. We formally define the impact of a transient fault in terms of three basic parameters: frequency, observability and severity. We distinguish fault modes in systems whose noise environment changes dynamically. Based on these ideas, the problem of designing on-line architectures for transient fault characterization is formulated and analyzed for several optimization goals. Finally, experiments are described that determine transient fault impact and the corresponding tests for various simulated fault modes of the ISCAS-89 benchmark circuits", "num_citations": "36\n", "authors": ["1879"]}
{"title": "High-level counterexamples for probabilistic automata\n", "abstract": " Providing compact and understandable counterexamples for violated system properties is an essential task in model checking. Existing works on counterexamples for probabilistic systems so far computed either a large set of system runs or a subset of the system's states, both of which are of limited use in manual debugging. Many probabilistic systems are described in a guarded command language like the one used by the popular model checker PRISM. In this paper we describe how a smallest possible subset of the commands can be identified which together make the system erroneous. We additionally show how the selected commands can be further simplified to obtain a well-understandable counterexample.", "num_citations": "35\n", "authors": ["1879"]}
{"title": "Graphenbasierte Funktionsdarstellung: Boolesche und Pseudo-Boolesche Funktionen\n", "abstract": " Kompakte Darstellung und effiziente Manipulation Boolescher Funktionen sind in vielen Bereichen, insbesondere des computergest\u00fctzten Schaltkreisentwurfes, zentrale Aufgaben. Im Hinblick auf Anwendungen ist es dabei von gro\u00dfem Interesse, einen guten Kompromi\u00df zwischen den oben angesprochenen, sich \u201cwidersprechenden\" Zielen, Kompaktheit und Effizienz, zu finden. Besonderer Beliebtheit erfreuen sich in diesem Zusammenhang die von Bryant 1986 eingef\u00fchrten Ordered Binary Decision Diagrams (OBDDs): Sie werden ins-besondere in den Bereichen Verifikation und Logiksynthese auch industriellerfolgreich eingesetzt.Mit wachsender Zahl von Anwendungen sind auch inh\u00e4rente Nachteile sichtbar geworden und haben vor allem in den letzten drei Jahren zu Weiterentwicklungen des Basiskonzeptes gef\u00fchrt. Dabei hat sich eine ganze Familie von graphenbasierten Funktionsdarstellungen entwickelt, die je nach Anwendungsgebiet Vorteile gegen\u00fcber den klassischen OBDDs bieten.", "num_citations": "35\n", "authors": ["1879"]}
{"title": "Efficient graph based representation of multi-valued functions with an application to genetic algorithms\n", "abstract": " We present a new general data structure for representation of multi-valued input, multi-valued output functions, called function graphs (FG). Ordered FGs are shown to be a canonical form. We investigate read-once FGs and show that type-restricted FGs are also canonical. We use FGs for multi-valued set representation and manipulation. They allow efficient manipulation algorithms for set operations, e.g. union and intersection. An application to genetic algorithms (GAs) is presented in more detail. A population is represented by a multi-rooted FG. It is shown by experimental results that this new representation is very efficient and superior to other data structures for GAs.< >", "num_citations": "35\n", "authors": ["1879"]}
{"title": "Efficient SAT-based search for longest sensitisable paths\n", "abstract": " We present a versatile method that enumerates all or a user-specified number of longest sensitisable paths in the whole circuit or through specific components. The path information can be used for design and test of circuits affected by statistical process variations. The algorithm encodes all aspects of the path search as an instance of the Boolean Satisfiability Problem (SAT), which allows the method not only to benefit from recent advances in SAT-solving technology, but also to avoid some of the drawbacks of previous structural approaches. Experimental results for academic and industrial benchmark circuits demonstrate the method's accuracy and scalability.", "num_citations": "34\n", "authors": ["1879"]}
{"title": "Advanced SAT-techniques for bounded model checking of blackbox designs\n", "abstract": " In this paper we will present an optimized structural 01X-SAT-solver for bounded model checking of blackbox designs that exploits semantical knowledge regarding the node selection during SAT search. Experimental results show that exploiting the problem structure in this way speeds up the 01X-SAT-solver considerably. Additionally, we give a concise first-order formulation that is more expressive than using 01X-logic. This formulation leads to hard-to-solve QBF formulas for which experimental results from the QBF Evaluation 2006 are presented.", "num_citations": "34\n", "authors": ["1879"]}
{"title": "OKFDDs versus OBDDs and OFDDs\n", "abstract": " Ordered Decision Diagrams (ODDs) as a means for the representation of Boolean functions are used in many applications in CAD. Depending on the decomposition type, various classes of ODDs have been defined, the most important being the Ordered Binary Decision Diagrams (OBDDs), the Ordered Functional Decision Diagrams (OFDDs) and the Ordered Kronecker Functional Decision Diagrams (OKFDDs). In this paper we clarify the computational power of OKFDDs versus OBDDs and OFDDs from a (more) theoretical point of view. We prove several exponential gaps between specific types of ODDs. Combining these results it follows that a restriction of the OKFDD concept to subclasses, such as OBDDs and OFDDs as well, results in families of functions which lose their efficient representation.", "num_citations": "34\n", "authors": ["1879"]}
{"title": "Synthesis for testability: Circuits derived from ordered kronecker functional decision diagrams\n", "abstract": " Summary form only given. Testability properties of circuits derived from Ordered Kronecker Functional Decision Diagrams (OKFDDs) are studied with respect to the Stuck-At Fault Model (SAFM) and the Cellular Fault Model (CFM). The computation of complete test sets and of all occurring redundancies can be done easily and efficiently and circuits with high testability can be obtained.< >", "num_citations": "34\n", "authors": ["1879"]}
{"title": "Polynomial formal verification of of multipliers\n", "abstract": " Until recently verifying multipliers with formal methods was not feasible, even for small input word sizes. About two years ago, a new data structure, called Multiplicative Binary Moment Diagram (*BMD), was introduced for representing arithmetic functions over Boolean variables. Based on this data structure, methods were proposed by which verification of multipliers with input word sizes of up to 256 bits became feasible. Only experimental data has been provided for these verification methods until now. In this paper we give a formal proof that logic verification using *BMDs is polynomially bounded in both space and time when applied to the class of Wallace-tree like multipliers.", "num_citations": "32\n", "authors": ["1879"]}
{"title": "OFDD based minimization of fixed polarity Reed-Muller expressions using hybrid genetic algorithms\n", "abstract": " We present an ordered functional decision diagram (OFDD) based method to minimize fixed polarity Reed-Muller expressions (FPRMs) for very large functions using genetic algorithms (GAs). R. Dreschsler et al. (1994) presented fast heuristic methods for FPRM minimization and compared them to several other approaches. We show that better results for large functions can be obtained if these heuristics are combined with GAs, i.e. we use hybrid GAs (HGAs). Experimental results are given to show the efficiency of the approach.< >", "num_citations": "32\n", "authors": ["1879"]}
{"title": "The COMICS Tool \u2013 Computing Minimal Counterexamples for DTMCs\n", "abstract": " This paper presents the tool COMICS\u00a01.0, which performs model checking and generates counterexamples for DTMCs. For an input DTMC, COMICS computes an abstract system that carries the model checking information and uses this result to compute a critical subsystem, which induces a counterexample. This abstract subsystem can be refined and concretized hierarchically. The tool comes with a command line version as well as a graphical user interface that allows the user to interactively influence the refinement process of the counterexample.", "num_citations": "31\n", "authors": ["1879"]}
{"title": "Multi-objective optimization in evolutionary algorithms using satisfiability classes\n", "abstract": " Many optimization problems consist of several mutually dependent subproblems, where the resulting solutions must satisfy all requirements.               We propose a new model for Multi-Objective Optimization (MOO) in Evolutionary Algorithms (EAs). The search space is partitioned into so-called Satisfiability Classes (SC), where each region represents the quality of the optimization criteria. Applying the SCs to individuals in a population a fitness can be assigned during the EA run. The model also allows the handling of infeasible regions and restrictions in the search space. Additionally, different priorities for optimization objectives can be modeled. Advantages of the model over previous approaches are discussed and an application is given that shows the superiority of the method for modeling MOO problems.", "num_citations": "31\n", "authors": ["1879"]}
{"title": "On variable ordering and decomposition type choice in OKFDDs\n", "abstract": " We present methods for the construction of small ordered Kronecker Functional Decision Diagrams (OKFDDs). OKFDDs are a generalization of ordered binary decision diagrams (OBDDs) and ordered functional decision diagrams (OFDDs) as well. Starting with an upper bound for the size of an OKFDD representing a tree-like circuit, we develop different heuristics to find good variable orderings and decomposition types for OKFDDs representing two-level and multilevel circuits, respectively. Experimental results are presented to show the efficiency of our approaches.", "num_citations": "31\n", "authors": ["1879"]}
{"title": "Hierarchical counterexamples for discrete-time Markov chains\n", "abstract": " This paper introduces a novel counterexample generation approach for the verification of discrete-time Markov chains (DTMCs) with two main advantages: (1) We generate abstract counterexamples which can be refined in a hierarchical manner. (2) We aim at minimizing the number of states involved in the counterexamples, and compute a critical subsystem of the DTMC whose paths form a counterexample. Experiments show that with our approach we can reduce the size of counterexamples and the number of computation steps by several orders of magnitude.", "num_citations": "30\n", "authors": ["1879"]}
{"title": "Dynamic compaction in SAT-based ATPG\n", "abstract": " SAT-based automatic test pattern generation has several advantages compared to conventional structural procedures, yet often yields too large test sets. We present a dynamic compaction procedure for SAT-based ATPG which utilizes internal data structures of the SAT solver to extract essential fault detection conditions and to generate patterns which cover multiple faults. We complement this technique by a state-of-the-art forward-looking reverse-order simulation procedure. Experimental results obtained for an industrial benchmark circuit suite show that the new method outperforms earlier static approaches by approximately 23%.", "num_citations": "30\n", "authors": ["1879"]}
{"title": "On combining 01X-logic and QBF\n", "abstract": " We discuss how to combine 01X-logic and quantified boolean formulas (QBF) within a homogeneous SAT/QBF-framework in the context of bounded model checking of blackbox designs. The proposed combination allows a flexible handling of blackboxes w.r.t.\u00a0computational resources. Preliminary results show the scalability of the approach.", "num_citations": "30\n", "authors": ["1879"]}
{"title": "Laissez-faire caching for parallel# SAT solving\n", "abstract": " The problem of counting the number of satisfying assignments of a propositional formula (#SAT) can be considered to be the big brother of the well known SAT problem. However, the higher computational complexity and a lack of fast solvers currently limit its usability for real world problems.               Similar to SAT, utilizing the parallel computation power of modern CPUs could greatly increase the solving speed in the realm of #SAT. However, in comparison to SAT there is an additional obstacle for the parallelization of #SAT that is caused by the usage of conflict learning together with the #SAT specific techniques of component caching and sub-formula decomposition. The combination can result in an incorrect final result being computed due to incorrect values in the formula cache. This problem is easily resolvable in a sequential solver with a depth-first node order but requires additional care and handling\u00a0\u2026", "num_citations": "29\n", "authors": ["1879"]}
{"title": "ATPG-Based grading of strong fault-secureness\n", "abstract": " Robust circuit design has become a major concern for nanoscale technologies. As a consequence, for design validation, not only the functionality of a circuit has to be considered, but also its robustness properties have to be analyzed. In this work we propose a method to verify the strong fault-secureness by use of constrained SAT-based ATPG. Strongly fault-secure circuits can be seen as the widest class of circuits achieving the totally self-checking (TSC) goal, which requires that every fault be detected the first time it manifests itself as an error at the outputs. As the strongly fault-secure property guarantees to achieve the TSC goal even in the case of fault accumulation, the effects of all possible fault sequences have to be taken into consideration to verify this property. To speed up the complex analysis of multiple faults we develop rules to derive detectability or redundancy information for multiple faults from the\u00a0\u2026", "num_citations": "29\n", "authors": ["1879"]}
{"title": "Scalable calculation of logical masking effects for selective hardening against soft errors\n", "abstract": " Selective hardening aims at achieving maximal soft error rate reduction at reasonable cost by applying hardening techniques to most susceptible circuit nodes only. Logical, electrical and latching-window masking effects must all be considered when calculating the susceptibility of circuit nodes to soft errors. We introduce a scalable selective hardening method based on an approximate calculation of fault detection probabilities at the nodes. Error probability reduction comparable to that obtained by the exact BDD-based algorithm (which is not scalable) can be achieved by setting an over-ambitious optimization target. The run times are negligible even for industrial multiple-million-gates circuits. Existing approaches for calculating electrical and latching-window masking can be readily incorporated into the framework.", "num_citations": "29\n", "authors": ["1879"]}
{"title": "Testing with decision diagrams\n", "abstract": " Decision diagrams (DDs) are the state-of-the-art data structure in VLSI CAD. They are widely used and in the mean time have also been integrated in commercial tools. In the following special interest is devoted to the use of DDs in the area of testing. We give a brief review of test algorithms successfully using the capabilities of DDs as a data structure for tasks like fault detection, synchronization and built-in-self-test. In the main part of the paper we concentrate on synthesis for testability approaches where circuits are derived from DD representations. Depending on the type of the DD and its structural properties differing classes of DD-circuits result. Their testability properties with respect to static and dynamic fault models are analysed. In summary, the computation of complete test sets and of all occurring redundancies can be done easily and efficiently based on DD manipulation algorithms. Circuits with high\u00a0\u2026", "num_citations": "28\n", "authors": ["1879"]}
{"title": "On the (non-) resetability of synchronous sequential circuits\n", "abstract": " We present a tool to compute a synchronizing sequence for synchronous sequential circuits. It consists of three parts. One part is an OBDD-based approach combined with a heuristic algorithm for preventing a memory overflow. This approach potentially finds a minimum length reset sequence. The second part is an improved three-valued based greedy algorithm. Its synchronizing sequence is not minimal in all cases, but experiments show that it is actually very good. The third part of the tool (and the focus of this paper) is a routine to quickly decide the non-resetability of a design. In contrast to previous approaches this routine is based on sufficient functional conditions to prove the non-resetability of certain memory elements. For the first time results about the resetability of the largest ISCAS'89 benchmark circuits are presented.", "num_citations": "28\n", "authors": ["1879"]}
{"title": "Preprocessing for DQBF\n", "abstract": " For SAT and QBF formulas many techniques are applied in order to reduce/modify the number of variables and clauses of the formula, before the formula is passed to the actual solving algorithm. It is well known that these preprocessing techniques often reduce the computation time of the solver by orders of magnitude. In this paper we generalize different preprocessing techniques for SAT and QBF problems to dependency quantified Boolean formulas (DQBF) and describe how they need to be adapted to work with a DQBF solver core. We demonstrate their effectiveness both for CNF- and non-CNF-based DQBF algorithms.", "num_citations": "27\n", "authors": ["1879"]}
{"title": "Ordnungen, Verb\u00e4nde und Relationen mit Anwendungen\n", "abstract": " In dieser Ausarbeitung von Vorlesungen, welche in den letzten Jahren an der Christian-Albrechts-Universitat zu Kiel abgehalten wurden, wird versucht, eine Einfiihrung in die Ordnungs-und Verbandstheorie und den damit eng verbundenen algebraischen Kalkiil der binaren Relationen zu geben und Anwendungen insbesondere in der Informatik zu demonstrieren. Die eben erwahnten Gebiete spielen heute in vielen Bereichen der reinen und angewandten Mathematik und der Informatik eine groBe Rolle. Etwa haben sehr viele Satze der Mathematik fiber auf-und absteigende Ketten, wie sie etwa bei auflosbaren Gruppen oder Noetherschen Ringen auftreten, einen ordnungstheoretischen Hintergrund. Gleiches gilt fiir die Methoden der Informatik zum Beweis von Terminierungen von Deduktionen und Programmen. Ein weiteres Beispiel ist die Boolesche Algebra, ein spezieller Zweig der Verbandstheorie. Durch\u00a0\u2026", "num_citations": "27\n", "authors": ["1879"]}
{"title": "On detection of resistive bridging defects by low-temperature and low-voltage testing\n", "abstract": " Test application at reduced power supply voltage (low-voltage testing) or reduced temperature (low-temperature testing) can improve the defect coverage of a test set, particularly of resistive short defects. Using a probabilistic model of two-line nonfeedback short defects, we quantify the coverage impact of low-voltage and low-temperature testing for different voltages and temperatures. Effects of statistical process variations are not considered in the model. When quantifying the coverage increase, we differentiate between defects missed by the test set at nominal conditions and undetectable defects (flaws) detected at non nominal conditions. In our analysis, the performance degradation of the device caused by lower power supply voltage is accounted for. Furthermore, we describe a situation in which defects detected by conventional testing are missed by low-voltage testing and quantify the resulting coverage loss\u00a0\u2026", "num_citations": "27\n", "authors": ["1879"]}
{"title": "Challenges in the development of hydrate phases as active pharmaceutical ingredients\u2013An example\n", "abstract": " The challenges during pilot plant scale-up of the SAR474832 API (active pharmaceutical ingredient) production in view of crystallization, isolation, drying and micronization are reported. A variety of different solid-state analytical and spectroscopic techniques (also coupled methods) were applied in order to understand the complex phase transition behaviour of the crystallographic phase (form 1) chosen for development: a partially non-stoichiometric channel-hydrate (x (1\u00a0+\u00a01.25) H2O) crystallizing from pure water in the crystal habit of fine needles, which tend to agglomerate upon isolation and drying. Processes have been developed for drying, sieving and micronization by jetmilling to avoid non-desired phase transitions (overdrying effects) into other hydrate forms. Special methods have been established to minimize, monitor and control the formation of amorphous content during the particle size reduction steps. By\u00a0\u2026", "num_citations": "26\n", "authors": ["1879"]}
{"title": "Modeling feedback bridging faults with non-zero resistance\n", "abstract": " We study the behavior of feedback bridging faults with non-zero bridge resistance in both combinational and sequential circuits. We demonstrate that a test vector may detect the fault, not detect the fault or lead to oscillation, depending on bridge resistance. Moreover, the resistance intervals in which a particular behavior is observed are not necessarily contiguous. We demonstrate non-trivial behavior for situations in which a detection seems impossible, namely disabled loops going through a gate with controlling values on its side inputs.               We outline the multiple strengths problem which arises due to the fact that a critical bridge resistance depends on the strengths of the signals driving the bridge, which in turn are functions of the number of the on-transistors, these again depending on the bridge resistance, making such a fault very hard to resolve. For sequential circuits, we describe additional\u00a0\u2026", "num_citations": "26\n", "authors": ["1879"]}
{"title": "Combining GAs and symbolic methods for high quality tests of sequential circuits\n", "abstract": " A symbolic fault simulator is integrated in a Genetic Algorithm (GA) environment to perform Automatic Test Pattern Generation (ATPG) for synchronous sequential circuits. In a two phase algorithm test length and fault coverage as well are optimized. Furthermore, not only the Single Observation Time Test Strategy is supported, but also test patterns with respect to the Multiple Observation Time Test Strategy are generated. However, there are circuits that are hard to test using random pattern sequences, even if these sequences are genetically optimized. Thus, deterministic aspects are included in the GA environment to improve fault coverage. Experiments demonstrate that both a priori time consuming strategies, the symbolic simulation approach and the GA, can be combined at reasonable costs: Tests with higher fault coverages and considerably shorter test sequences than previously presented approaches\u00a0\u2026", "num_citations": "26\n", "authors": ["1879"]}
{"title": "Functional test of small-delay faults using SAT and Craig interpolation\n", "abstract": " We present SATSEQ, a timing-aware ATPG system for small-delay faults in non-scan circuits. The tool identifies the longest paths suitable for functional fault propagation and generates the shortest possible sub-sequences per fault. Based on advanced model-checking techniques, SATSEQ provides detection of small-delay faults through the longest functional paths. All test sequences start at the circuit's initial state; therefore, overtesting is avoided. Moreover, potential invalidation of the fault detection is taken into account. Experimental results show high detection and better performance than scan testing in terms of test application time and overtesting-avoidance.", "num_citations": "25\n", "authors": ["1879"]}
{"title": "Low-cost hardening of image processing applications against soft errors\n", "abstract": " Image processing systems are increasingly used in safety-critical applications, and their hardening against soft errors becomes an issue. The authors propose a methodology to identify soft errors as uncritical based on their impact on the system's functionality. The authors call a soft error uncritical if its impact is provably limited to image perturbations during a very short period of time (number of cycles) and the system is guaranteed to recover thereafter. Uncritical errors do not require hardening as their effects are unperceivable for the human user of the system. The authors focus on soft errors in the motion estimation subsystem of MPEG-2 and introduce different definitions of uncritical soft errors in that subsystem. A method is proposed to automatically determine uncritical errors and provide experimental results for various parameters. The concept can be adapted to further systems and enhance existing methods", "num_citations": "25\n", "authors": ["1879"]}
{"title": "Parallel SAT solving in bounded model checking\n", "abstract": " Bounded Model Checking (BMC) is an incremental refutation technique to search for counterexamples of increasing length. The existence of a counterexample of a fixed length is expressed by a first-order logic formula that is checked for satisfiability using a suitable solver.               We apply communicating parallel solvers to check satisfiability of the BMC formulae. In contrast to other parallel solving techniques, our method does not parallelize the satisfiability check of a single formula, but the parallel solvers work on formulae for different counterexample lengths. We adapt the method of constraint sharing and replication of Shtrichman, originally developed for sequential BMC, to the parallel setting. Since the learning mechanism is now parallelized, it is not obvious whether there is a benefit from the concepts of Shtrichman in the parallel setting. We demonstrate on a number of benchmarks that adequate\u00a0\u2026", "num_citations": "25\n", "authors": ["1879"]}
{"title": "A hybrid genetic algorithm for the channel routing problem\n", "abstract": " We present a Hybrid Genetic Algorithm (HGA) for the Channel Routing Problem (CRP). To do so we combine a Genetic Algorithm (GA) with domain specific knowledge, i.e. the genetic operators make use of the rip-up and reroute technique. Thereby the execution time of our method is faster than previously presented evolutionary based approaches. Furthermore, concerning space complexity we show by experiments that our HGA can handle large channels (with more than 100 columns).", "num_citations": "25\n", "authors": ["1879"]}
{"title": "Learning heuristics by genetic algorithms\n", "abstract": " In many applications of Computer Aided Design (CAD) of Integrated Circuits (ICs) the problems that have to be solved are NP-hard. Thus, exact algorithms are only applicable to small problem instances and many authors have presented heuristics to obtain solutions (non-optimal in general) for larger instances of these hard problems. In this paper we present a model for Genetic Algorithms (GA) to learn heuristics starting from a given set of basic operations. The difference to other previous applications of GAs in CAD of ICs is that the GA does not solve the problem directly. Rather, it develops strategies for solving the problem. To demonstrate the efficiency of our approach experimental results for a specific problem are presented.", "num_citations": "25\n", "authors": ["1879"]}
{"title": "Verification of partial designs using incremental QBF solving\n", "abstract": " SAT solving is an indispensable core component of numerous formal verification tools and has found widespread use in industry, in particular when using it in an incremental fashion, e.g. in Bounded Model Checking (BMC). On the other hand, there are applications, in particular in the area of partial design verification, where SAT formulas are not expressive enough and a description via Quantified Boolean Formulas (QBF) is much more adequate. In this paper we introduce incremental QBF solving and thereby make it usable as a core component of BMC. To do so, we realized an incremental version of the state-of-the-art QBF solver QuBE, allowing for the reuse of learnt information e.g. in the form of conflict clauses and solution cubes. As an application we consider BMC for partial designs (i.e. designs containing so-called blackboxes) and thereby disprove realizability, that is, we prove that an unsafe state is\u00a0\u2026", "num_citations": "24\n", "authors": ["1879"]}
{"title": "Craig interpolation in the presence of non-linear constraints\n", "abstract": " An increasing number of applications in particular in the verification area leverages Craig interpolation. Craig interpolants (CIs) can be computed for many different theories such as: propositional logic, linear inequalities over the reals, and the combination of the preceding theories with uninterpreted function symbols. To the best of our knowledge all previous tools that provide CIs are addressing decidable theories. With this paper we make Craig interpolation available for an in general undecidable theory that contains Boolean combinations of linear and non-linear constraints including transcendental functions like sin(\u00b7) and cos(\u00b7). Such formulae arise e.g.\u00a0during the verification of hybrid systems. We show how the construction rules for CIs can be extended to handle non-linear constraints. To do so, an existing SMT solver based on a close integration of SAT and Interval Constraint Propagation is enhanced\u00a0\u2026", "num_citations": "24\n", "authors": ["1879"]}
{"title": "SUPERB: Simulator utilizing parallel evaluation of resistive bridges\n", "abstract": " A high-performance resistive bridging fault simulator SUPERB (Simulator Utilizing Parallel Evaluation of Resistive Bridges) is proposed. It is based on fault sectioning in combination with parallel-pattern or parallel-fault multiple-stuck-at simulation. It outperforms a conventional interval-based resistive bridging fault simulator by three orders of magnitude while delivering identical results. Further competing tools are outperformed by several orders of magnitude. Industrial-size circuits, including a multi-million-gates design, could be simulated with runtimes within an order of magnitude of the runtimes for pattern-parallel stuck-at fault simulation.", "num_citations": "24\n", "authors": ["1879"]}
{"title": "QmiraXT-A Multithreaded QBF Solver.\n", "abstract": " This paper introduces the state-of-the-art multithreaded QBF solver QMiraXT. QMiraXT is the first parallel QBF Solver that supports advanced features such as: conflict/solution analysis with non-chronological backtracking; knowledge sharing between threads; and novel preprocessing and decision heuristics. By utilizing these features, QMiraXT is significantly faster on industrial and formal verification problems than other solvers. In summary, with 4 threads, QMiraXT solved 22 more benchmarks, providing a speedup of 3.82 compared to the next best sequential solver.", "num_citations": "24\n", "authors": ["1879"]}
{"title": "Computation of minimal counterexamples by using black box techniques and symbolic methods\n", "abstract": " Computing counterexamples is a crucial task for error diagnosis and debugging of sequential systems. If an implementation does not fulfill its specification, counterexamples are used to explain the error effect to the designer. In order to be understood by the designer, counterexamples should be simple, i.e. they should be as general as possible and assign values to a minimal number of input signals. Here we use the concept of  Black Boxes  - parts of the design with unknown behavior - to mask out components for counterexample computation. By doing so, the resulting counterexample will argue about a reduced number of components in the system to facilitate the task of understanding and correcting the error. We introduce the notion of 'uniform counterexamples' to provide an exact formalization of simplified counterexamples arguing only about components which were not masked out. Our computation of\u00a0\u2026", "num_citations": "24\n", "authors": ["1879"]}
{"title": "Steady and unsteady numerical investigation of transitional shock-boundary-layer-interactions on a fan blade\n", "abstract": " The present numerical study was performed to investigate the impact of both the Reynolds number variation and the used turbulence model to capture the boundary layer development on the characteristic of a BR710 fan blade. A one-equation model of Spalart Allmaras with an optional semi-empirical transition model of Abu-Ghanam Shaw has been applied. The transition model allows the boundary layer development from a laminar to a turbulent behaviour to be taken into account. This is of particular importance at low Reynolds numbers and thus high operating altitudes of airplanes when the transition location moves further downstream to the trailing edge. Therefore the interaction between the shock waves of the transonic fan blade row and the boundary layer leads to a significant change of the characteristic. The steady numerical studies of the 3-D blade passage have been carried out with the commercial 3-D\u00a0\u2026", "num_citations": "24\n", "authors": ["1879"]}
{"title": "Look-up table FPGA synthesis from minimized multi-valued pseudo kronecker expressions\n", "abstract": " In this paper we outline a method for Look-up Table-FPGA (LUT-FPGA) synthesis from minimized Multi-Valued Pseudo Kronecker Expressions (MV PSDKROs). By restricting logic minimization to consider only easily mappable expressions, a regular Cellular Architecture (CA) layout without routing overhead is obtained. In this way our method combines logic minimization, mapping and routing. The transformation into the MV domain reduces the area as the number of products in the PSDKRO expression can be further minimized. Deriving the exact minimum MV PSDKRO is known to be hard or even intractable. We address this by applying pruning techniques based on cost estimation and dynamic methods to find suitable variable orderings. Results on a set of MCNC benchmarks show the advantages of the proposed minimization methods.", "num_citations": "24\n", "authors": ["1879"]}
{"title": "On the expressive power of OKFDDs\n", "abstract": " Ordered Decision Diagrams (ODDs) as a means for the representation of Boolean functions are used in many applications in CAD. Depending on the decomposition type, various classes of ODDs have been defined, among them being the Ordered Binary Decision Diagrams (OBDDs), the Ordered Functional Decision Diagrams (OFDDs) and the Ordered Kronecker Functional Decision Diagrams (OKFDDs).               Based on a formalization of the concept decomposition type we first investigate all possible decomposition types and prove that already OKFDDs, which result from the application of only three decomposition types, result in the most general class of ODDs. We then show from a (more) theoretical point of view that the generality of OKFDDs is really needed. We prove several exponential gaps between specific classes of ODDs, e.g. between OKFDDs on the one side and OBDDs, OFDDs on the\u00a0\u2026", "num_citations": "24\n", "authors": ["1879"]}
{"title": "A hierarchical approach to fault collapsing\n", "abstract": " One central point of testing is the choice of the fault model and the faults which have to be considered to ensure the correct behaviour of a circuit. The number of faults has a strong influence on the costs which must be paid for in the generation of a test set. For logical fault models this number can be reduced using equivalence relations between faults. Since the complexity of digital circuits is increasing, hierarchical design is becoming more and more important. In this paper, we show that in the case of a hierarchical circuit description often more equivalence relations between faults can be recognized efficiently than in the case of a nonhierarchical description. With respect to the stuck-at fault model, our experiments show that the computation of these equivalence relations can be performed in negligible time and that the number of faults can be reduced considerably.< >", "num_citations": "24\n", "authors": ["1879"]}
{"title": "On the optimality of K longest path generation algorithm under memory constraints\n", "abstract": " Adequate coverage of small-delay defects in circuits affected by statistical process variations requires identification and sensitization of multiple paths through potential defect sites. Existing K longest path generation (KLPG) algorithms use a data structure called path store to prune the search space by restricting the number of sub-paths considered at the same time. While this restriction speeds up the KLPG process, the algorithms lose their optimality and do not guarantee that the K longest sensitizable paths are indeed found. We investigate, for the first time, the effects of missing some of the longest paths on the defect coverage. We systematically quantify how setting different limits on the path-store size affects the numbers and relative lengths of identified paths, as well as the run-times of the algorithm. We also introduce a new optimal KLPG algorithm that works iteratively and pinpointedly addresses defect\u00a0\u2026", "num_citations": "23\n", "authors": ["1879"]}
{"title": "SAT-based analysis of sensitisable paths\n", "abstract": " Manufacturing defects in nanoscale technologies have highly complex timing behaviour that is also affected by process variations. While conventional wisdom suggests that it is optimal to detect a delay defect through the longest sensitisable path, non-trivial defect behaviour along with modelling inaccuracies necessitate consideration of paths of well-controlled length during test generation. We present a generic methodology that yields tests through all sensitisable paths of user-specified length. The resulting tests can be employed within the framework of adaptive testing. The methodology is based on encoding the problem as a Boolean-satisfiability (SAT) instance and thereby leverages recent advances in SAT-solving technology.", "num_citations": "23\n", "authors": ["1879"]}
{"title": "A symbiosis of interval constraint propagation and cylindrical algebraic decomposition\n", "abstract": " We present a novel decision procedure for non-linear real arithmetic: a combination of iSAT, an incomplete SMT solver based on interval constraint propagation (ICP), and an implementation of the complete cylindrical algebraic decomposition (CAD) method in the library GiNaCRA . While iSAT is efficient in finding unsatisfiability, on satisfiable instances it often terminates with an interval box whose satisfiability status is unknown to iSAT. The CAD method, in turn, always terminates with a satisfiability result. However, it has to traverse a double-exponentially large search space.             A symbiosis of iSAT and CAD combines the advantages of both methods resulting in a fast and complete solver. In particular, the interval box determined by iSAT provides precious extra information to guide the CAD-method search routine: We use the interval box to prune the CAD search space in both phases, the projection and\u00a0\u2026", "num_citations": "22\n", "authors": ["1879"]}
{"title": "Priorities in multi-objective optimization for genetic programming\n", "abstract": " A new technique for multi-objective optimization is presented that allows to include priorities. But in contrast to previous techniques they can be included very easily and do not require much user interaction. The new approach is studied from a theoretical and practical point of view. The main differences to existing methods, like relation dominate and favor, are discussed. An experimental study of applying priorities in heuristics learning based on Genetic Programming (GP) is described. The experiments confirm the advantages presented in comparison to several other techniques.", "num_citations": "22\n", "authors": ["1879"]}
{"title": "Word-level decision diagrams, WLCDs and division\n", "abstract": " Several types of Decision Diagrams (DDs) have been proposed for the verijcation of Integrated Circuits. Recently word-level DDs lib BblDs,* BhfDs, HDDs, K* BhiDs and* PHDDs have been attracting more and more interest, eg, by using* BMDsand* PHDDsit wasfor thejrst timepossible toformally verifi integermultipliers and Joating point multipliers of \u201csigni&ant\u201d bitlengths, respectively.On the other hat~ it has been unhewn, whether division, the operation inverse to multiplication, can be efiiently represented by some ppe of word-level DDs. In this paper we show that the representational power of any word-level DD is too weak to efficiently represent integer divisiok Thus, neither a clever choice of the variable orderins, the decomposition type or the edse weights, can lead to a polynotnial DD sizefor divisio~", "num_citations": "22\n", "authors": ["1879"]}
{"title": "Overview of decision diagrams\n", "abstract": " An overview on decision diagrams (DDs) is given. DDs are the state-of-the-art data structure in verification and logic synthesis. They are widely used, and are integrated into commercial tools. The overview is incomplete in the sense that not all DDs are considered, but the authors mention the most important DDs, with practical relevance. DDs with special emphasis on the aspect of function representation at bit-level and word-level are considered.", "num_citations": "22\n", "authors": ["1879"]}
{"title": "A graphical system for hierarchical specifications and checkups of VLSI circuits\n", "abstract": " The most important frontend components of the VLSI design system CADIC are presented. The first one allows graphical specification of recursively defined circuits. The other one allows the designer to navigate the synthesized layout following the hierarchical specification to check eg CADIC's hierarchical optimisations or to control the outcome of test generation algorithms.<>", "num_citations": "22\n", "authors": ["1879"]}
{"title": "PHAETON: A SAT-based framework for timing-aware path sensitization\n", "abstract": " Knowledge about sensitizable paths through combinational logic is essential for numerous design tasks. We present the framework PHAETON which identifies sensitizable paths and generates test pairs to exercise these paths using Boolean satisfiability (SAT). PHAETON supports a large number of models and sensitization conditions and provides a generic interface that can be used by applications. It incorporates a novel application-specific unary representation of integer numbers to integrate timing information with logical conditions within the same monolithic SAT formula. Due to a number of further elaborate speed-up techniques, PHAETON scales to industrial circuits. Experimental results show the performance of PHAETON in classical K longest path generation tasks and in new post-silicon validation and characterization scenarios.", "num_citations": "21\n", "authors": ["1879"]}
{"title": "Multi-cycle circuit parameter independent ATPG for interconnect open defects\n", "abstract": " Interconnect opens are known to be one of the predominant defects in nanoscale technologies. Generating tests to detect such defects is challenging due to the need to accurately determine the coupling capacitances between the open net and its aggressors and fix the state of these aggressors during test. Process variations cause deviations from assumed values of circuit parameters thus potentially invalidating tests generated with assumed circuit parameters. Additionally, recent investigation using test chips showed that the steady state voltage on open nets may drift slowly with the application of circuit inputs and can be different at different nets.", "num_citations": "21\n", "authors": ["1879"]}
{"title": "Resistive bridging fault simulation of industrial circuits\n", "abstract": " We report the successful application of a resistive bridging fault (RBF) simulator to industrial benchmark circuits. Despite the slowdown due to the consideration of the sophisticated RBF model, the run times of the simulator were within an order of magnitude of the run times for pattern-parallel complete-circuit stuck-at fault simulation. Industrial-size circuits, including a multi-million-gates design, could be simulated in reasonable time despite a significantly higher number of faults to be simulated compared with stuck-at fault simulation.", "num_citations": "21\n", "authors": ["1879"]}
{"title": "Polynomial formal verification of multipliers\n", "abstract": " Not long ago, completely automatical formal verification of multipliers was not feasible, even for small input word sizes. However, with Multiplicative Binary Moment Diagrams (*BMD), which is a new data structure for representing arithmetic functions over Boolean variables, methods were proposed by which verification of multipliers with input word sizes of up to 256 Bits is now feasible. Unfortunately, only experimental data has been provided for these verification methods until now.               In this paper, we give a formal proof that logic verification with *BMDs is polynomially bounded in both, space and time, when applied to the class of Wallace-tree like multipliers. Using this knowledge online detection of design errors becomes feasible during a verification run.", "num_citations": "21\n", "authors": ["1879"]}
{"title": "Crossing reduction by windows optimization\n", "abstract": " The number of edge crossings is a commonly accepted measure to judge the \u201creadability\u201d of graph drawings. In this paper we present a new algorithm for high quality multi-layer straight-line crossing minimization. The proposed method uses a local optimization technique where subsets of nodes and edges are processed exactly. The algorithm uses optimization on a window applied in a manner, similar to those used in the area of formal verification of logic circuits. In contrast to most existing heuristics, more than two layers are considered simultaneously. The algorithm tries to reduce the total number of crossings based on an initial placement of the nodes and can thus also be used in a post- processing step. Experiments are given to demonstrate the efficacy of the proposed technique on benchmarks from the area of circuit design.", "num_citations": "21\n", "authors": ["1879"]}
{"title": "Synthesis of pseudo kronecker lattice diagrams\n", "abstract": " The design process of digital circuits is often carried out in individual steps, like logic minimization, mapping and routing. This leads to quality loss, e.g. in cases where highly optimized netlists fit badly onto the target architecture. Lattice diagrams have been proposed as one possible solution. They offer a regular two dimensional structure, thus overcoming the routing problem. However elegant, presented methods have only been shown to find practical lattice representations for small functions. We present heuristic synthesis methods for Pseudo-Symmetric Pseudo Kronecker Decision Diagrams (PSP-KDDs) applicable to incompletely specified multiple output functions. The lattice structure maps directly to both ASICs and fine grain FPGAs. Our method (combining logic minimization, mapping and routing) seeks to minimize area and delay by heuristic methods. Experimental results on a set of MCNC benchmarks\u00a0\u2026", "num_citations": "21\n", "authors": ["1879"]}
{"title": "A hybrid fault simulator for synchronous sequential circuits\n", "abstract": " Fault simulation for synchronous sequential circuits is a very time-consuming task. The complexity of the task increases if there is no information available about the initial state of the circuit. In this case, an unknown initial state is assumed which is usually handled by introducing a three-valued logic. It is known that fault simulation based upon this logic only determines a lower bound for the fault coverage achieved by a test sequence. Therefore, we developed a hybrid fault simulator H-FS combining the advantages of a fault simulator using the three-valued logic and of an exact symbolic fault simulator based upon binary decision diagrams. H-FS is able to handle even the largest benchmark circuits and thereby determines fault coverages much more accurately than previous algorithms using the three-valued logic.", "num_citations": "21\n", "authors": ["1879"]}
{"title": "Symbolic counterexample generation for large discrete-time Markov chains\n", "abstract": " This paper presents several symbolic counterexample generation algorithms for discrete-time Markov chains (DTMCs) violating a PCTL formula. A counterexample is (a symbolic representation of) a sub-DTMC that is incrementally generated. The crux to this incremental approach is the symbolic generation of paths that belong to the counterexample. We consider two approaches. First, we extend bounded model checking and develop a simple heuristic to generate highly probable paths first. We then complement the SAT-based approach by a fully (multi-terminal) BDD-based technique. All symbolic approaches are implemented, and our experimental results show a substantially better scalability than existing explicit techniques. In particular, our BDD-based approach using a method called fragment search allows for counterexample generation for DTMCs with billions of states (up to 1015).", "num_citations": "20\n", "authors": ["1879"]}
{"title": "Efficient Solving of Large Arithmetic Constraint Systems with Complex Boolean Structure\n", "abstract": " Due to the increasing use of more and more complex computerized systems in safetycritical applications, formal verification of such systems is of growing importance. Among the most successful methods in formal verification of finite-state systems is bounded model checking (BMC), a technique for checking whether an unsafe system state is reachable within a fixed number of steps. BMC belongs to a class of verification algorithms having in common that the verification task is reduced to the problem of checking the satisfiability of a propositional formula or a series thereof. Though originally formulated for discrete transition systems only, BMC is in principle also applicable to hybrid discrete-continuous systems, which naturally arise eg in the field of embedded systems where digital (discrete) controllers are coupled with analog (continuous) physical plants. The BMC formulae arising from such systems are, however\u00a0\u2026", "num_citations": "20\n", "authors": ["1879"]}
{"title": "An easily testable optimal-time VLSI-multiplier\n", "abstract": " We consider the design of a \u2018tree-multiplier\u2019, which is a modified version of a Wallace tree-multiplier [16] made suitable for VLSI design by Luk and Vuillemin [12]. It is shown that 4 log(n) + 3 test patterns suffice to exhaustively test the multiplier with respect to the \u2018cellular fault model\u2019 (which includes tests for all single stuck at faults). Some slight modifications of the multiplier prove, that these tests can be applied without increasing the number of input ports substantially.", "num_citations": "20\n", "authors": ["1879"]}
{"title": "Accurate ICP-based floating-point reasoning\n", "abstract": " In scientific and technical software, floating-point arithmetic is often used to approximate arithmetic on physical quantities natively modeled as reals. Checking properties for such programs (e.g. proving unreachability of code fragments) requires accurate reasoning over floating-point arithmetic. Currently, most of the SMT-solvers addressing this problem class rely on bit-blasting. Recently, methods based on reasoning in interval lattices have been lifted from the reals (where they traditionally have been successful) to the floating-point numbers. The approach presented in this paper follows the latter line of interval-based reasoning, but extends it by including bitwise integer operations and cast operations between integer and floating-point arithmetic. Such operations have hitherto been omitted, as they tend to define sets not concisely representable in interval lattices, and were consequently considered the domain of\u00a0\u2026", "num_citations": "19\n", "authors": ["1879"]}
{"title": "Efficient SAT-based dynamic compaction and relaxation for longest sensitizable paths\n", "abstract": " Comprehensive coverage of small-delay faults under massive process variations is achieved when multiple paths through the fault locations are sensitized by the test pair set. Using one test pair per path may lead to impractical test set sizes and test application times due to the large number of near-critical paths in state-of-the-art circuits.", "num_citations": "19\n", "authors": ["1879"]}
{"title": "SAT-ATPG using preferences for improved detection of complex defect mechanisms\n", "abstract": " Failures caused by phenomena such as crosstalk or power-supply noise are gaining in importance in advanced nanoscale technologies. The detection of such complex defects benefits from the satisfaction of certain constraints, for instance justifying specific transitions on neighbouring lines of the defect location. We present a SAT-based ATPG-tool that supports the enhanced conditional multiple-stuck-at fault model (ECMS@). This model can specify multiple fault locations along with a set of hard conditions imposed on arbitrary lines; hard conditions must hold in order for the fault effect to become active. Additionally, optimisation constraints that may be required for best coverage can be specified via a set of soft conditions. The introduced tool justifies as many of these conditions as possible, using a mechanism known as SAT with preferences. Several applications are discussed and evaluated by extensive\u00a0\u2026", "num_citations": "19\n", "authors": ["1879"]}
{"title": "Encoding techniques, Craig interpolants and bounded model checking for incomplete designs\n", "abstract": " This paper focuses on bounded invariant checking for partially specified circuits \u2013 designs containing so-called blackboxes \u2013 using the well known 01X- and QBF-encoding techniques. For detecting counterexamples, modeling the behavior of a blackbox using 01X-encoding is fast, but rather coarse as it limits what problems can be verified. We introduce the idea of 01X-hardness, mainly the classification of problems for which this encoding technique does not provide any useful information about the existence of a counterexample. Furthermore, we provide a proof for 01X-hardness based on Craig interpolation, and show how the information contained within the Craig interpolant or unsat-core can be used to determine heuristically which blackbox outputs to model in a more precise way. We then compare 01X, QBF and multiple hybrid modeling methods. Finally, our total workflow along with multiple state-of\u00a0\u2026", "num_citations": "19\n", "authors": ["1879"]}
{"title": "A scalable BIST architecture for delay faults\n", "abstract": " We present a scalable BIST (Built-In Self Test) architecture that provides a tunable trade-off between on-chip area demand and test execution time for delay fault testing. So, the architecture can meet test execution time requirements, area requirements, or any target in between. Experiments show the scalability of our approach, e.g., that considerably shorter test execution time can be achieved by storing only a few additional input vectors of the BIST architecture. The gain of test execution time possible with the proposed method ranges from a factor of 2 up to a factor of more than 800000.", "num_citations": "19\n", "authors": ["1879"]}
{"title": "On the generation of area-time optimal testable adders\n", "abstract": " We present a performance driven generator for integer adders which has the following interesting feature: The generator is parametrized in the operands' bitlength n, the delay of the addition t/sub n/, and the fault model FM. FM may in particular be chosen as the classical stuck-at fault model, the cellular fault model or the robust path delay fault model. The output of the generator is a performance oriented conditional sum type adder, i.e., an area-minimal n-bit adder of the \"conditional sum type\" with delay /spl les/t/sub n/ (if it exists) together with a small complete test set with respect to the chosen fault model FM.< >", "num_citations": "19\n", "authors": ["1879"]}
{"title": "State space modeling of high frequency multiwinding transformers\n", "abstract": " State space models of high frequency multiwinding transformers are presented, suitable for circuit simulation with all kinds of excitation and loads. The elements of these state space models are calculated based on a field and network theoretical analysis. A simulation of a switched mode power supply and a comparison with measurements demonstrates the accuracy of the analysis.< >", "num_citations": "19\n", "authors": ["1879"]}
{"title": "Layouts with wires of balanced length\n", "abstract": " For any graph G with fixed boundary there exists a layout in the plane, which minimizes the maximum Euclidean distance of any node to its neighbors. This layout balances the length of the graph edges and is therefore called a (length-) balanced layout of G. Furthermore the existence of a unique optimal balanced layout L with the following properties is proved: (i) L is the minimal element of an order defined on the set of layouts of a graph with fixed boundary. (ii) L may be constructed as the limit of the lp-optimal layouts Lp of G. (iii) If G is a planar graph with fixed boundary, then the optimal balanced layout L of G is quasi-planar.", "num_citations": "19\n", "authors": ["1879"]}
{"title": "Provably optimal test cube generation using quantified Boolean formula solving\n", "abstract": " Circuits that employ test pattern compression rely on test cubes to achieve high compression ratios. The less inputs of a test pattern are specified, the better it can be compacted and hence the lower the test application time. Although there exist previous approaches to generate such test cubes, none of them are optimal. We present for the first time a framework that yields provably optimal test cubes by using the theory of quantified Boolean formulas (QBF). Extensive comparisons with previous methods demonstrate the quality gain of the proposed method.", "num_citations": "18\n", "authors": ["1879"]}
{"title": "Exact routing with search space reduction\n", "abstract": " The layout problem in VLSI-design can be broken up into the subtasks partitioning, floorplanning, placement, and routing. In the routing phase, a large number of connections between the blocks and cells have to be established, while intersections lead to short circuits and, therefore, have to be avoided. We present an approach for exact routing of multiterminal nets that complements traditional routing techniques. It is particularly well suited for an application to dense problem instances and the completion of routing in subregions, which turn out to be difficult for routing tools based on heuristic methods. The exact router proposed uses symbolic methods, i.e., MDDs (multivalued decision diagrams) for representation of the routing space. For the necessary computations of routing solutions, we profit considerably from the efficient basic operations on MDDs. All possible solutions to the routing problem are represented\u00a0\u2026", "num_citations": "18\n", "authors": ["1879"]}
{"title": "Testability properties of local circuit transformations with respect to the robust path-delay-fault model\n", "abstract": " We present a new approach to show that local circuit transformations which improve the area of a circuit preserve or improve robust path-delay-fault testability. In contrast to previously published methods which had to consider the whole circuit we examine only the subcircuits to be transformed. Furthermore, we present some new transformations which preserve or improve robust path-delay-fault testability.< >", "num_citations": "18\n", "authors": ["1879"]}
{"title": "Small scale AES toolbox: algebraic and propositional formulas, circuit-implementations and fault equations\n", "abstract": " Cryptography is one of the key technologies ensuring security in the digital domain. As such, its primitives and implementations have been extensively analyzed both from a theoretical, cryptoanalytical perspective, as well as regarding their capabilities to remain secure in the face of various attacks. One of the most common ciphers, the Advanced Encryption Standard (AES) (thus far) appears to be secure in the absence of an active attacker. To allow for the testing and development of new attacks or countermeasures a small scale version of the AES with a variable number of rounds, number of rows, number of columns and data word size, and a complexity ranging from trivial up to the original AES was developed. In this paper we present a collection of various implementations of the relevant small scale AES versions based on hardware (VHDL and gate-level), algebraic representations (Sage and CoCoA) and their translations into propositional formulas (in CNF). Additionally, we present fault attack equations for each version. Having all these resources available in a single and well structured package allows researchers to combine these different sources of information which might reveal new patterns or solving strategies. Additionally, the fine granularity of difficulty between the different small scale AES versions allows for the assessment of new attacks or the comparison of different attacks.", "num_citations": "17\n", "authors": ["1879"]}
{"title": "Early-life-failure detection using SAT-based ATPG\n", "abstract": " Early-life failures (ELF) result from weak chips that may pass manufacturing tests but fail early in the field, much earlier than expected product lifetime. Recent experimental studies over a range of technologies have demonstrated that ELF defects result in changes in delays over time inside internal nodes of a logic circuit before functional failure occurs. Such changes in delays are distinct from delay degradation caused by circuit aging mechanisms such as Bias Temperature Instability. Traditional transition fault or robust path delay fault test patterns are inadequate for detecting such ELF-induced changes in delays because they do not model the demanding detection conditions precisely. In this paper, we present an automatic test pattern generation (ATPG) technique based on Boolean Satisfiability (SAT) for detecting ELF-induced delay changes at all gates in a given circuit. Our simulation results, using various\u00a0\u2026", "num_citations": "17\n", "authors": ["1879"]}
{"title": "Numerical and experimental investigations of a compressor cascade flow with secondary air removal\n", "abstract": " The paper presents numerical and experimental results for a low speed compressor cascade with bleed air removal at the endwall. The aerofoil design is representative for a stator blade in a modern high pressure compressor near the casing wall. Secondary air is commonly supplied by simple bleed geometries downstream of stator rows. The focus of the present investigation was the systematic development of a passage integrated bleed configuration. With the assumption of an invariable bleed mass flow rate it should be designed to provide an advantageous effect on the main flow. Furthermore, a high pressure recovery in the bleed flow was aspired. Steady 3D RANS simulations were performed using the Spalart-Allmaras turbulence model. In both numerical simulations and experiments, an improved performance was found. Beside reduced losses and increased pressure rise, the wake flow downstream of the\u00a0\u2026", "num_citations": "17\n", "authors": ["1879"]}
{"title": "Verification of designs containing black boxes\n", "abstract": " Often modern designs contain regions where the implementation of certain components is not (fully) known. These regions are called black boxes in the following. They occur e.g. if different designers work on a project in parallel or if IP cores are used. An approach based on a symbolic representation of characteristic functions for verifying circuits with black boxes is presented. We show that by this method more faults can be detected than with pure binary simulation and symbolic simulation using BDDs, respectively, only. This results from the formulation of our algorithm that allows implications over the black box. Experimental results are given to show what parts of a design can be proven to be correct, if black boxes are assumed. Of course, the probability for the detection of a fault in general depends on the size of the unknown regions. But fault injection experiments on benchmarks show that for many circuits, even\u00a0\u2026", "num_citations": "17\n", "authors": ["1879"]}
{"title": "On local transformations and path delay fault testability\n", "abstract": " Several synthesis for path delay fault (PDF) testability approaches are based on local transformations of digital circuits. Different methods were used to show that transformations preserve or improve PDF testability. In this paper we present a new unifying approach to show that local transformations preserve or improve PDF testability. This approach can be applied to every local transformation and in contrast to previously published methods only the subcircuits to be transformed have to be considered.               Using our new approach we are able to show in a very convenient way that the transformations which are already used in synthesis tools preserve or improve PDF testability. We present further transformations which preserve or improve testability. We show that a transformation, claimed to preserve PDF testability, in fact, does not do so. Moreover, the testability improving factor which is a unit of\u00a0\u2026", "num_citations": "17\n", "authors": ["1879"]}
{"title": "ALLQBF solving by computational learning\n", "abstract": " In the last years, search-based QBF solvers have become essential for many applications in the formal methods domain. The exploitation of their reasoning efficiency has however been restricted to applications in which a \u201csatisfiable/unsatisfiable\u201d answer or one model of an open quantified Boolean formula suffices as an outcome, whereas applications in which a compact representation of all models is required could not be tackled with QBF solvers so far.               In this paper, we describe how computational learning provides a remedy to this problem. Our algorithms employ a search-based QBF solver and learn the set of all models of a given open QBF problem in a CNF (conjunctive normal form), DNF (disjunctive normal form), or CDNF (conjunction of DNFs) representation. We evaluate our approach experimentally using benchmarks from synthesis of finite-state systems from temporal logic and monitor\u00a0\u2026", "num_citations": "16\n", "authors": ["1879"]}
{"title": "PaQuBE: Distributed QBF solving with advanced knowledge sharing\n", "abstract": " In this paper we present the parallel QBF Solver PaQuBE. This new solver leverages the additional computational power that can be exploited from modern computer architectures, from pervasive multicore boxes to clusters and grids, to solve more relevant instances and faster than previous generation solvers. PaQuBE extends QuBE, its sequential core, by providing a Master/Slave Message Passing Interface (MPI) based design that allows it to split the problem up over an arbitrary number of distributed processes. Furthermore, PaQuBE\u2019s progressive parallel framework is the first to support advanced knowledge sharing in which solution cubes as well as conflict clauses can be shared. According to the last QBF Evaluation, QuBE is the most powerful state-of-the-art QBF Solver. It was able to solve more than twice as many benchmarks as the next best independent solver. Our results here, show that PaQuBE\u00a0\u2026", "num_citations": "16\n", "authors": ["1879"]}
{"title": "Efficient bridging fault simulation of sequential circuits based on multi-valued logics\n", "abstract": " We present the concept of a multi-valued logic simulator for bridging faults in sequential circuits. Different models for the handling of intermediate values in flip flops on the digital design level can be integrated and result in an expected realistic behavior area for bridging faults. Several experimental results are given to underline properties and advantages of the simulation technique.", "num_citations": "16\n", "authors": ["1879"]}
{"title": "The multiple variable order problem for binary decision diagrams: theory and practical application\n", "abstract": " Reduced Ordered Binary Decision Diagrams (ROBDDs) gained widespread use in logic design verification, test generation, fault simulation, and logic synthesis [17, 7]. Since the size of an ROBDD heavily depends on the variable order used, there is a strong need to find variable orders that minimize the number of nodes in an ROBDD. In certain applications we have to cope with ROBDDs with different variable orders, whereas further manipulations of these ROBDDs require common variable orders. In this paper we give a theoretical background for this\" Multiple Variable Order problem\". Moreover, we solve the problem to transform ROBDDs with different variable orders into a good common variable order using dynamic variable ordering techniques.", "num_citations": "16\n", "authors": ["1879"]}
{"title": "A multi-layer detailed routing approach based on evolutionary algorithms\n", "abstract": " We present an evolutionary algorithm (EA) for detailed routing problems (DRPs), like the channel routing problem and the switchbox routing problem. We combine EAs with domain specific knowledge, i.e. the genetic operators make use of the rip-up and reroute technique. The algorithm can work with two layer and multilayer problem instances. The efficiency of our algorithm is demonstrated by application to multilayer channel routing benchmarks. Instances with up to five layers, 130 columns, and more than 60 nets are considered.", "num_citations": "16\n", "authors": ["1879"]}
{"title": "Ein logisch-topologischer Kalk\u00fcl zur Konstruktion von integrierten Schaltkreisen\n", "abstract": " Es wird ein CAD-System ICAD-IC vorgestellt, das den Entwurf integrierter Schaltungen unterst\u00fctzen soll. Der Kern des Systems besteht in einem Netzkalk\u00fcl, der es erlaubt, neben der logischen Information auch geometrische Informationen zu handhaben. Dieser Kalk\u00fcl besitzt verschiedene Auspr\u00e4gungen, die den Entwurf auf verschiedenen Entwurfsebenen unterst\u00fctzen. Das System ist um den Kalk\u00fcl herum entwickelt, wie etwa ALGOL um die Numerik. Soweit das System bis jetzt entwickelt ist, betrifft es die logisch-topologische Entwurfsebene und den \u00dcbergang zur topographischen Entwurfsebene. Wir stellen hier das Konzept des Kalk\u00fcls vor und erl\u00e4utern an Beispielen einige Grundlagenuntersuchungen zu diesem Thema.", "num_citations": "16\n", "authors": ["1879"]}
{"title": "Counterexample-guided strategy improvement for pomdps using recurrent neural networks\n", "abstract": " We study strategy synthesis for partially observable Markov decision processes (POMDPs). The particular problem is to determine strategies that provably adhere to (probabilistic) temporal logic constraints. This problem is computationally intractable and theoretically hard. We propose a novel method that combines techniques from machine learning and formal verification. First, we train a recurrent neural network (RNN) to encode POMDP strategies. The RNN accounts for memory-based decisions without the need to expand the full belief space of a POMDP. Secondly, we restrict the RNN-based strategy to represent a finite-memory strategy and implement it on a specific POMDP. For the resulting finite Markov chain, efficient formal verification techniques provide provable guarantees against temporal logic specifications. If the specification is not satisfied, counterexamples supply diagnostic information. We use this information to improve the strategy by iteratively training the RNN. Numerical experiments show that the proposed method elevates the state of the art in POMDP solving by up to three orders of magnitude in terms of solving times and model sizes.", "num_citations": "15\n", "authors": ["1879"]}
{"title": "Efficient SMT-based ATPG for interconnect open defects\n", "abstract": " Interconnect opens are known to be one of the predominant defects in nanoscale technologies. However, automatic test pattern generation for open faults is challenging, because of their rather unstable behaviour and the numerous electric parameters which need to be considered. Thus, most approaches try to avoid accurate modeling of all constraints and use simplified fault models in order to detect as many faults as possible or make assumptions which decrease both complexity and accuracy. This paper presents a new SMT-based approach which for the first time supports the Robust Enhanced Aggressor Victim model without restrictions and handles oscillations. It is combined with the first open fault simulator fully supporting the Robust Enhanced Aggressor Victim model and thereby accurately considering unknown values. Experimental results show the high efficiency of the new method outperforming previous\u00a0\u2026", "num_citations": "15\n", "authors": ["1879"]}
{"title": "# SAT-based vulnerability analysis of security components\u2014A case study\n", "abstract": " In this paper we describe a new approach to assess a circuit's vulnerability to fault attacks. This is achieved through analysis of the circuit's design specification, making use of modern SAT solving techniques. For each injectable fault, a corresponding SAT instance is generated. Every satisfying solution for such an instance is equivalent to a circuit state and an input assignment for which the fault affects the circuit's outputs such that the error is not detected by the embedded fault detection. The number of solutions is precisely calculated by a #SAT solver and can be translated into an exact vulnerability measure. We demonstrate the applicability of this method for design space exploration by giving detailed results for various implementations of a deterministic random bit generator.", "num_citations": "15\n", "authors": ["1879"]}
{"title": "Multi-conditional SAT-ATPG for power-droop testing\n", "abstract": " Power droop is a non-trivial signal-integrity-related effect triggered by specific power-supply conditions. High-frequency and low-frequency power droop may lead to failure of an IC during application time, but they usually remain undetected by state-of-the-art manufacturing test methods, as the fault excitation imposes particular conditions on global switching activity over several time frames. Hence, ATPG for power-droop test (PD-ATPG) is an extremely hard problem that has not yet been solved optimally. In this paper, we use a SAT-based ATPG engine that employs a mechanism known as SAT-solving with qualitative preferences to generate a solution guaranteed to be optimal for a given set of optimisation criteria, however at the expense of high SAT-solving times. Therefore, a well-balanced set of criteria has to be chosen for the SAT-formulation in order to get as good solutions as possible without rendering the\u00a0\u2026", "num_citations": "15\n", "authors": ["1879"]}
{"title": "Counterexample generation for Markov chains using SMT-based bounded model checking\n", "abstract": " Generation of counterexamples is a highly important task in the model checking process. In contrast to, e.,g., digital circuits where counterexamples typically consist of a single path leading to a critical state of the system, in the probabilistic setting counterexamples may consist of a large number of paths. In order to be able to handle large systems and to use the capabilities of modern SAT-solvers, bounded model checking (BMC) for discrete-time Markov chains was established.             In this paper we introduce the usage of SMT-solving over linear real arithmetic for the BMC procedure. SMT-solving, extending SAT with theories in this context on the one hand leads to a convenient way to express conditions on the probability of certain paths and on the other hand allows to handle Markov reward models. We use the former to find paths with high probability first. This leads to more compact counterexamples. We\u00a0\u2026", "num_citations": "15\n", "authors": ["1879"]}
{"title": "Conflict-based selection of branching rules\n", "abstract": " We propose an adaptive framework for branching rule selection that is based on a set of branching rules. Each branching rule is attached a preference value that is dynamically adapted with respect to conflict analysis. Thus, our approach brings together two essential features of modern SAT algorithms which were traditionally independent from each other. Experimental results show the feasibility of our approach.", "num_citations": "15\n", "authors": ["1879"]}
{"title": "Crossing reduction for orthogonal circuit visualization\n", "abstract": " ABSTRACT\u00a2\u00a1\u00a4\u00a3\u00a6\u00a5 \u00a7 \u00a9\u00a4\u00a1\u00a4 \u00a7 \u00a1!#\" $\u00a1 &%\" $\u00a5'\u00a1 &\u00a3(\u00a1\u00a4\u00a3) \u00a7 0\u00a1\u00a4 1324!%\u00a6 5 \u00a7 6 7% 89\u00a3\u00a6 8 \u00a7 !%\" 5@ \u00a7 % 8 \u00a7 A\u00a1 89\u00a9 89\" 9\u00a6% B'\u00a1\" D CE8 $\u00a3\u00a6\u00a1\u00a4 FB (\u00a7 \u00a5'1G \u00a7 !\u00a1\u00a4 B IHQ PR 6\" \u00a7 \u00a1\u00a4 SF# 8T%\u00a6%%\u00a3 U\u00a1\u00a4(\u00a7 V\u00a9 W \u00a7 % FB8X CE89Y\u00a3\u00a6\u00a1\u00a4 F1G \u00a7 $ aX% 8 b6\u00a5 S\u00a1 &% 8c \u00a7 \u00a2@'\u00a1\u00a4 FB@'Ydb6\u00a5 \u00a7 !\u00a9\u00a4\u00a1\u00a4 daV F% 5 \u00a7 2'@ S\u00a1\u00a4\" \u00a7 !\u00a9 E% 8 $2 E% 8$\u00a3\u00a6 8 $6 5 \u00a7 !\u00a1\u00a4\u00a7 \" 9\u00a1\u00a4%\" 9\u00a5 S\u00a1 & c@ \u00a7 U \u00a7 \u00a9\u00a4\u00a9\u00a4 eU\u00a3 f@ g\u00a5'1G \u00a7 S\u00a3 Q h\u00a5'CE89%\u00a3 i 5 \u00a7 SCG\u00a1 & Hq p\u00a2\u00a3\u00a6\u00a5 \u00a7 \u00a9\u00a4\u00a9 &a6r'CE% 5 \u00a7 $ ecY\u00a1\u00a4'Fs \u00a7 t\" $\u00a1 &%\" $\u00a5 S\u00a1 &#\u00a1\u00a3# \u00fc \u00a7 \u00a3\u00a6 8$ Cv w \u00a7 t F% 5 \u00a7 ! 2S@ A%@ gaE2489% F!% 5 \u00a7 2'@ x\u00a3 i\u00a6%\u00a5 S\" 9\u00a5 E% 8 eU@'89% 8V S gC'89\u00a3 y \u00a7 % 8h\" $ S'8$\" 9 8 C (u6a7\u00a3 i\u00a6% 5 \u00a7 \u00a1\u00a4 FB@ 6 y\u00a9\u00a1\u00a4'8$\u00a3 $ r \u00a7 SC S gCE8 $\u00a3 y \u00a7 % 8\u00a9\u00a4 6\" \u00a7 8 C7\u00a1\u00a4 7 \u00a7 D e \u00a7 $ a3@ \u00a7 ! 13\u00a1'\u00a1\u00a4 13\u00a1 98$\u00a3@'8\u00a2\" 9%\u00a3\u00a6\u00a3\u00a6\u00a1\u00a4 SFB\u00a3 U!@ S89\u00a3\u00a6 8y\u00a9\u00a4\u00a1\u00a4 S8 $\u00a3 $ H d X@ S\u00a1\u00a4\u00a3 2S \u00a7 2489% re 8 \u00a7 BC'CE% 8$\u00a3\u00a6\u00a3@'8 2E% Bu'\u00a9 891!'% 89Y\u00a6% 5 \u00a7 ! S\u00a3 i!% 13\u00a1\u00a4 SFU@ S\u00a1\u00a4\u00a3 F!% 5 \u00a7 2'@ D% 892'% 8$\u00a3\u00a6 8 $6 5 \u00a7 \u00a1 D \u00fc \u00a7 \" 5 yf \u00a7 X!%\u00a6@ S FB BS \u00a7 \u00a9 g\" $\u00a1 &%\" $\u00a5'\u00a1\u00a4\u00a3 i\u00a6%\u00a5 S\" 9\u00a5 E% 8Br\u00a1 H8BH% 892S\u00a9 \u00a7 \" $\u00a1\u00a4'F@ S8\u00a3 i\u00a6% 5 \u00a7 !\u00a1 F@ 6 (\u00a9\u00a4\u00a1\u00a4 S8 $\u00a3 u6av@ S%\u00a1\u00a4 $6 5 \u00a7 \u00a9 \u00a7 ! C B89%\u00a6\u00a1\u00a4\" \u00a7 \u00a9\u00a9\u00a4\u00a1\u00a4 S89\u00a3 $ HQ\u00a2 3 89 3\" 9\u00a1 89 g \u00a7 \u00a9\u00a4 F%\u00a1 &@ S1\u00a1\u00a3 Q 2'% 89\u00a3\u00a6 8 $6 8 C#@ \u00a7 13\u00a1\u00a4 S\u00a1\u00a4 13\u00a1\u00a4 $8 $\u00a3 d@'8\" T% B\u00a3\u00a6\u00a3\u00a6\u00a1\u00a4 SF\u00a2 FB\u00a1\u00a4 e8 $ D@ S\u00a1\u00a4\u00a3 fd S89ex\" T%\u00a1\u00a4 8T%\u00a1 SgE Hq hqiE2489%\u00a1\u00a4 138 $6 5 \u00a7 !\u00a9 B% 8$\u00a3\u00a6\u00a5 S\u00a9 &\u00a3 d \u00a7 % 8 2E% E\u00a1 CE8 C@ S \u00a7 !\u00a2 C'8 $13 S\u00a3 i\u00a6% 5 \u00a7 8y@ S8 8T 3\" $\u00a1\u00a4 8$ S\" Ta (! j@ S8X \u00a7 ! 2S2E% e \u00a7 \" 5@ RH", "num_citations": "15\n", "authors": ["1879"]}
{"title": "On optimizing bist-architecture by using OBDD-based approaches and genetic algorithms\n", "abstract": " We introduce a two-staged Genetic Algorithm for optimizing weighted random pattern testing in a Built-in-Self-Test (BIST) environment. The first stage includes the OBDD-based optimization of input probabilities with regard to the expected test length. The optimization itself is constrained to discrete weight values which can directly be integrated in a BIST environment. During the second stage, the hardware-design of the actual BIST-structure is optimized. Experimental results are given to demonstrate the quality of our approach.", "num_citations": "15\n", "authors": ["1879"]}
{"title": "Satisfiability problems for OFDDs\n", "abstract": " We investigate the complexity of problems on Ordered Functional Decision Diagrams (OFDDs) related to satisfiability, i.e. SAT-ONE, SAT-ALL, and SAT-COUNT. We prove that SAT-ALL has a running time linear in the product of the number of satisfying assignments and the size of the given OFDD. Counting the satisfying assignments in an OFDD is proved to be #P-complete, and thus not possible in polynomial time unless P=NP.", "num_citations": "15\n", "authors": ["1879"]}
{"title": "OKFDDs\u2014Algorithms, Applications and Extensions\n", "abstract": " We present Ordered Kronecker Functional Decision Diagrams (OKFDDs), a graph-based data structure for the representation and manipulation of Boolean functions. OKFDDs are a generalization of Ordered Binary Decision Diagrams and Ordered Functional Decision Diagrams and as such provide a more compact representation of the functions than either of the two decision diagrams. We review basic properties of OKFDDs and study methods for their efficient representation and manipulation. These algorithms are integrated in our OKFDD package PUMA whose implementation is briefly discussed. Finally we point out some applications of OKFDDs, demonstrate the efficiency of our approach by some experiments and discuss a promising extension of the concept to also allow representation and manipulation of word-level functions.", "num_citations": "15\n", "authors": ["1879"]}
{"title": "Genetic Alogrithms in Computer Aided Design of Integrated Circuits\n", "abstract": " An increasing number of successful applications of Genetic Algorithms (GAs) within Computer Aided Design (CAD) of Integrated Circuits (ICs) is reported in the literature. The problems dealt with in this eld consist of sequences of sub-problems, which are characterized by being NP-hard, large and mutually dependent. This very high level of complexity should make the GA a well suited approach, at least in principle. However, the GA is of practical interest to the CAD community if and only if it is competitive to the existing approaches with respect to performance. With this fact as the starting point, the purpose of this paper is to discuss how to develop high-performance GAs for CAD of ICs.After reviewing a number of recent, performance competitive GAs for key problems in CAD of ICs, the common characteristics of these algorithms are discussed. They all exploit problem speci c knowledge in various ways or are integrated with other heuristics. The paper also discusses performance evaluation principles. To make an impact, it is crucial that performance is evaluated using the measures commonly applied in the CAD eld. The practical implications hereof for GA-based applications are addressed.", "num_citations": "15\n", "authors": ["1879"]}
{"title": "Towards the formal verification of security properties of a Network-on-Chip router\n", "abstract": " Vulnerabilities and design flaws in Network-on-Chip (NoC) routers can be exploited in order to spy, modify and constraint the sensitive communication inside the Multi-Processors Systems-on-Chip (MPSoCs). Although previous works address the NoC threat, finding secure and efficient solutions to verify the security is still a challenge. In this work, we propose for the first time a method to formally verify the correctness and the security properties of a NoC router in order to provide the proper communication functionality and to avoid NoC attacks. We present a generalized verification flow that proves a wide set of implementation-independent security-related properties to hold. We employ unbounded model checking techniques to account for the highly-sequential behaviour of the NoC systems. The evaluation results demonstrate the feasibility of our approach by presenting verification results of six different NoC routing\u00a0\u2026", "num_citations": "14\n", "authors": ["1879"]}
{"title": "Autofault: towards automatic construction of algebraic fault attacks\n", "abstract": " A prototype of the framework AutoFault, which automatically constructs fault-injection attacks for hardware realizations of ciphers, is presented. AutoFault can be used to quickly evaluate the resistance of security-critical hardware blocks to fault attacks and the adequacy of implemented countermeasures. The framework takes as inputs solely the circuit description of the cipher and the fault(s) and produces an algebraic formula that can be handed over to an external solver. In contrast to previous work, attacks constructed by AutoFault do not incorporate any cipher-specific cryptoanalytic derivations, making the framework accessible to users without cryptographic background. We report successful application of AutoFault in combination with a state-of-the-art SAT solver to LED-64 and to small-scale AES. To the best of our knowledge, this is the first time that a state-of-the-art cipher (LED-64) was broken by a fault attack\u00a0\u2026", "num_citations": "14\n", "authors": ["1879"]}
{"title": "From DQBF to QBF by dependency elimination\n", "abstract": " In this paper, we propose the elimination of dependencies to convert a given dependency quantified Boolean formula (DQBF) to an equisatisfiable QBF. We show how to select a set of dependencies to eliminate such that we arrive at a smallest equisatisfiable QBF in terms of existential variables that is achievable using dependency elimination. This approach is improved by taking so-called don\u2019t-care dependencies into account, which result from the application of dependency schemes to the formula and can be added to or removed from the formula at no cost. We have implemented this new method in the state-of-the-art DQBF solver HQS. Experiments show that dependency elimination is clearly superior to the previous method using variable elimination.", "num_citations": "14\n", "authors": ["1879"]}
{"title": "Systemic frequency biases in ring oscillator pufs on fpgas\n", "abstract": " Physically unclonable functions (PUFs) are an emerging primitive in hardware security, enabling the identification of computer-chips. A promising type particularly for FPGA implementations is the Ring Oscillator (RO) PUF, where signal delays-stemming from uncontrollable variations in the manufacturing process-are used as device-specific characteristics. Based on experimental results gathered with 38 identical Altera FPGAs, we show the existence of non-device-specific i.e., systemic RO frequency biases, traced back to (1) the internal routing within the RO's look-up tables, (2) the RO locations on the FPGAs, or (3) the non-PUF payload activity. As these biases are the same for all devices, the result is poor inter-device uniqueness and unreliable signatures under changing payloads. After characterizing these biases with a newly developed set of metrics, we suggest a method to overcome them: Using only a small\u00a0\u2026", "num_citations": "14\n", "authors": ["1879"]}
{"title": "Identification of high power consuming areas with gate type and logic level information\n", "abstract": " Power-related problems in at-speed scan testing have become more and more serious, since excessive IR-drop caused by excessive power consumption results in overtesting. There are two important factors in low-power testing: one is power estimation, the other is power reduction. Several estimation methods have been proposed based on the analysis of switching activity characteristics. In order to estimate the impact of IR-drop, it is more important to consider the area containing many cells which consume excessive power than to consider the total number of switching activity in a circuit. In this paper, we propose a novel method for identifying areas where excessive IR-drop likely occurs without using test vectors. Visualized experimental results for IWLS 2005 benchmark circuits demonstrate that the proposed method can effectively identify areas containing many cells which consume higher power than others\u00a0\u2026", "num_citations": "14\n", "authors": ["1879"]}
{"title": "Probabilistic model checking and reliability of results\n", "abstract": " In formal verification, reliable results are of utmost importance. In model checking of digital systems, mainly incorrect implementations of the model checking algorithms due to logical errors are the source of wrong results. In probabilistic model checking, however, numerical instabilities are an additional source for inconsistent results. We motivate our investigations with an example, for which several state-of-the-art probabilistic model checking tools give completely wrong results due to inexact computations. We then analyze, at which points inaccuracies are introduced during the model checking process. We discuss first ideas how, in spite of these inaccuracies, reliable results can be obtained or at least the user be warned about potential correctness problems: (1) usage of exact (rational) arithmetic, (2) usage of interval arithmetic to obtain safe approximations of the actual probabilities, (3) provision of certificates\u00a0\u2026", "num_citations": "14\n", "authors": ["1879"]}
{"title": "Simulating open-via defects\n", "abstract": " Open-via defects are a major systematic failure mechanism in nanoscale manufacturing processes. We present a flow for simulating open-via defects. Electrical parameters are extracted from the layout and technology data and represented in a way which allows efficient simulation on gate level. The simulator takes oscillation caused by open-via defects into account and quantifies its impact on defect coverage. The flow can be employed for manufacturing test as well as for defect diagnosis.", "num_citations": "14\n", "authors": ["1879"]}
{"title": "Identification of critical errors in imaging applications\n", "abstract": " Practical on-line test methods do not cover all possible faults of a system. We propose a method to identify critical faults and distinguish them from non-critical ones. Low-cost on-line fault detection can focus on the critical faults. Alternatively, the circuit sites associated with critical faults could be selectively hardened to improve the overall reliability of a system. This is done in a cost- effective way because no hardening against non-critical faults is required. In this work, we concentrate on faults in imaging applications such as video. We classify faults based on their impact on the system behavior, i.e., the visibility of their effects by a human end-user. The psycho- visual model from the JPEG compression method is used for fault effect classification.", "num_citations": "14\n", "authors": ["1879"]}
{"title": "On SAT-based bounded invariant checking of blackbox designs\n", "abstract": " Design verification by property checking is a mandatory task during circuit design. In this context, bounded model checking (BMC) has become popular for falsifying erroneous designs. Additionally, the analysis of partial designs, i.e., circuits that are not fully specified, has recently gained attraction. In this work we analyze how BMC can be applied to such partial designs. Our experiments show that even with the most simple modelling scheme, namely 01X-simulation, a relevant number of errors can be detected. Additionally, we propose a SAT-solver that directly can handle 01X-logic", "num_citations": "14\n", "authors": ["1879"]}
{"title": "Exact computation of maximally dominating faults and its application to n-detection tests\n", "abstract": " n-detection test sets for stuck-at faults have been shown to be useful in detecting unmodeled defects. It was also shown that a set of faults, called maximally dominating faults, can play an important role in controlling the increase in the size of an n-detection test set as n is increased. In an earlier work, a superset of the maximally dominating fault set was used. In this work, we propose a method to determine exact sets of maximally dominating faults. We also define a new type of n-detection test sets based on the exact set of maximally dominating faults. We present experimental results to demonstrate the usefulness of this exact set in producing high-quality n-detection test sets.", "num_citations": "14\n", "authors": ["1879"]}
{"title": "Hybrid fault simulation for synchronous sequential circuits\n", "abstract": " We present a fault simulator for synchronous sequential circuits that combines the efficiency of three-valued logic simulation with the exactness of a symbolic approach. The simulator is hybrid in the sense that three different modes of operation\u2014three-valued, symbolic and mixed\u2014are supported. We demonstrate how an automatic switching between the modes depending on the computational resources and the properties of the circuit under test can be realized, thus trading off time/space for accuracy of the computation. Furthermore, besides the usual Single Observation Time Test Strategy (SOT) for the evaluation of the fault coverage, the simulator supports evaluation according to the more general Multiple Observation Time Test Strategy (MOT). Numerous experiments are given to demonstrate the feasibility and efficiency of our approach. In particular, it is shown that, at the expense of a reasonable time\u00a0\u2026", "num_citations": "14\n", "authors": ["1879"]}
{"title": "Improved minimization methods of pseudo kronecker expressions for multiple output functions\n", "abstract": " Pseudo Kronecker expressions (PSDKROs) are a class of AND/EXOR expressions. For a Boolean function with a given variable order the minimal PSDKRO can be derived efficiently using decision diagram (DD) techniques. The quality, i.e., the number of products in the expression, of the result is known to be dependent on the variable ordering. This paper proposes several improvements and enhancements to previous minimization methods. A pruning technique that can be tuned to tradeoff quality for computational resources is presented. By applying dynamic ordering methods, significant improvements to many previously reported results are obtained. Furthermore, a new method for the minimization of multiple output functions is outlined. Experiments on a set of MCNC benchmarks confirm the advantages of the presented algorithms.", "num_citations": "14\n", "authors": ["1879"]}
{"title": "Fault simulation in sequential multi-valued logic networks\n", "abstract": " In this paper we present a fault simulator for Sequential Multi-Valued Logic Networks (SMVLN). With this tool we investigate their random pattern testability (RPT). We discuss a unified approach for fault models in SMVLNs and show that it is possible to describe all static fault models with a global formalism. A large set of experimental results is given that demonstrates the efficiency of our approach. For the first time fault coverages for the Stuck-At Fault Model (SAFM) and Skew Fault Model (SKFM) for large sequential circuits are reported.", "num_citations": "14\n", "authors": ["1879"]}
{"title": "On the construction of optimal time adders\n", "abstract": " In this paper we present the design of a novel optimal time adder: the conditional carry adder. In order to perform addition a tree-like combination of multiplexer cells is used in the carry computation part. We show that, for the complete conditional carry adder, this results in an overall computation time which seems to be substantially shorter than for any other known (optimal time) adder (eg carry look ahead adders ([5]) or conditional sum adders ([12])). The second part of this paper contains a uniform approach to the computation of the carry function resulting in seven different classes of optimal time adders. It is shown that the conditional carry adder and the carry look ahead adder are representatives of two different classes. While section 1 defines the conditional carry adder and proposes a realization which is very time efficient, section 2 provides the possibility to compare this choice with other possible realizations\u00a0\u2026", "num_citations": "14\n", "authors": ["1879"]}
{"title": "Semi-automatic generation and labeling of training data for non-intrusive load monitoring\n", "abstract": " User awareness is one of the main drivers to reduce unnecessary energy consumption in our homes. This awareness, however, requires individual energy data of the devices we own. A retrofittable way to get this data is to use Non-Intrusive Load Monitoring methods. Most of these methods are supervised and require to collect labeled ground truth data in advance. Labeling on-phases of devices is already a tedious process, but if further information about internal device states are required (eg intensity of an HVAC), manual labeling methods are infeasible. We propose a novel data collection and labeling method for Non-Intrusive Load Monitoring. This method uses intrusive sensors directly connected to the monitored devices. A post-processing step classifies the connected devices into four categories and exposes internal state sequences in a semi-automatic way. We evaluated our labeling method with a sample\u00a0\u2026", "num_citations": "13\n", "authors": ["1879"]}
{"title": "Motion planning under partial observability using game-based abstraction\n", "abstract": " We study motion planning problems where agents move inside environments that are not fully observable and subject to uncertainties. The goal is to compute a strategy for an agent that is guaranteed to satisfy certain safety and performance specifications. Such problems are naturally modeled by partially observable Markov decision processes (POMDPs). Because of the potentially huge or even infinite belief space of POMDPs, verification and strategy synthesis is in general computationally intractable. We tackle this difficulty by exploiting typical structural properties of such scenarios; for instance, we assume that agents have the ability to observe their own positions inside an environment. Ambiguity in the state of the environment is abstracted into non-deterministic choices over the possible states of the environment. Technically, this abstraction transforms POMDPs into probabilistic two-player games (PGs). For\u00a0\u2026", "num_citations": "13\n", "authors": ["1879"]}
{"title": "Difference in the working principle of axial slot and tip blowing casing treatments\n", "abstract": " Tip blowing and axial slot casing treatments have shown their ability to enhance the stability of a transonic axial compressor with different effects on efficiency. For an effective application of these casing treatments, a good knowledge of the influence of the casing treatment on the rotor flow field is important. There is still a need for more detailed investigations, in order to understand the interaction between the treatment and the near casing 3D flow field. For transonic compressor rotors this interaction is more complex, as super- and subsonic flow regions alternate while interacting with the casing treatment.         In the present study, an axial slot and a tip blowing casing treatment, which have been developed and optimized for the same tip critical transonic axial compressor rotor (reference rotor) by Streit et al. [1] and Guinet et al. [2], are subject of the investigation. Both casing treatment types showed their capabilities to\u00a0\u2026", "num_citations": "13\n", "authors": ["1879"]}
{"title": "The potential of rotor and stator clocking in a 2.5-stage low-speed axial compressor\n", "abstract": " Detailed experimental investigations have been conducted to gain profound knowledge of airfoil clocking mechanisms in axial compressors. Clocking, the circumferential indexing of adjacent rotor or stator rows with equal blade counts, is known as a potential means to modify the flow field in multistage turbo-machinery and increase overall efficiencies of both turbines and compressors. These beneficial effects on turbomachine performance are due to wake-airfoil interactions and primarily depend on the alignment of a downstream blade or vane row with upstream wake trajectories that are generated in the same frame of reference. The present survey describes and discusses the experimental research on Rotor and Stator Clocking effects in a low-speed 2.5-stage axial flow compressor. For both Rotor and Stator Clocking, variations of Stage 2 performance have been found that are sinusoidal in trend over the\u00a0\u2026", "num_citations": "13\n", "authors": ["1879"]}
{"title": "On the quality of test vectors for post-silicon characterization\n", "abstract": " Post-silicon validation, i.e., physical characterization of a small number of fabricated circuit instances before start of high-volume manufacturing, has become an essential step in integrated circuit production. Post-silicon validation is required to identify intricate logic or electrical bugs which could not be found during pre-silicon verification. In addition, physical characterization is useful to determine the performance distribution of the manufactured circuit instances and to derive performance yield. Test vectors used for this step are subject to different requirements compared to vectors for simulation-based verification or for manufacturing test. In particular, they must sensitize a very comprehensive set of paths in the circuit, assuming massive variations and possible modeling deficiencies. An inadequate test vector set may result in overly optimistic yield estimates and wrong manufacturing decisions. On the other hand, the\u00a0\u2026", "num_citations": "13\n", "authors": ["1879"]}
{"title": "Hyper-graph based partitioning to reduce DFT cost for pre-bond 3D-IC testing\n", "abstract": " 3D IC technology has demonstrated significant performance and power gains over 2D. However, for technology to be viable yield should be increased. Testing a complete 3D IC after stacking leads to an exponential decay in yield. Pre-bond tests are required to insure correct functionality of the die. In this work we propose a hypergraph based biased netlist partitioning scheme scheme for pre-bond testing of individual dies to reduce extra-hardware (flip-flops) required. Further reduction in hardware is achieved by a logic cone based flip-flop sharing scheme. Simulation results on ISCAS89 benchmark circuits and several industrial benchmarks demonstrate the effectiveness of the proposed approach.", "num_citations": "13\n", "authors": ["1879"]}
{"title": "An experimental investigation of stator clocking effects in a two-stage low-speed axial compressor\n", "abstract": " The impact of stator clocking on performance and flow of a 2.5-stage axial compressor has been investigated. Stator clocking, the circumferential indexing of adjacent stator rows with equal blade counts, is known as a potential means to modify the flow field in multistage turbomachinery and increase overall efficiencies of both turbines and compressors. These potential effects on turbomachine performance are due to wake-airfoil interactions and primarily depend on the alignment of the downstream stator row with the upstream stator wake path. The present survey describes and discusses the experimental research on stator clocking effects in a low-speed 2.5-stage axial flow compressor, using front loaded CDA blade sections and cantilevered stator rows with identical blade counts. Conventional static pressure tappings were used to locate global peaks in compressor performance for varying Stator 2 clocking\u00a0\u2026", "num_citations": "13\n", "authors": ["1879"]}
{"title": "A soft error emulation system for logic circuits\n", "abstract": " In nanometer technologies, soft errors in logic circuits are increasingly important. Since the failure in time (FIT) rates for these circuits are very low, millions of test vectors are required for a realistic analysis of soft errors. This exceeds the capabilities of software simulation tools. We propose an FPGA emulation architecture that can apply millions of vectors within seconds. Comprehensive soft error profiling was done for ISCAS 89 circuits. Soft errors were assigned to four different classes, and their latency and recovery time were obtained. This information is useful for understanding the vulnerability of the system to soft errors and hardening it against such errors.", "num_citations": "13\n", "authors": ["1879"]}
{"title": "Checking equivalence for circuits containing incompletely specified boxes\n", "abstract": " We consider the problem of checking whether an implementation which contains parts with incomplete information is equivalent to a given full specification. We study implementations which are not completely specified, but contain boxes which are associated with incompletely specified functions (called Incompletely Specified Boxes or IS-Boxes). After motivating the use of implementations with Incompletely Specified Boxes we define our notion of equivalence for this kind of implementations and present a method to solve the problem. A series of experimental results demonstrates the effectiveness and feasibility of the methods presented.", "num_citations": "13\n", "authors": ["1879"]}
{"title": "Fast and efficient construction of BDDs by reordering based synthesis\n", "abstract": " We present a new approach to symbolic simulation with BDDs. Our method uses Reordering Based Synthesis (RBS) which allows the integration of dynamic variable ordering (even) within a single synthesis operation (e.g. an AND-operation). Thus, huge peak sizes during the construction can often be avoided, and we obtain a method that, with no penalty in runtime, is more memory efficient than traditional ITE operator based symbolic simulation. The results are confirmed by experiments on a large set of benchmarks: We give a comparison to previously published approaches and also consider some industrial benchmarks which are known to be hard to handle.", "num_citations": "13\n", "authors": ["1879"]}
{"title": "Decision diagrams in synthesis-algorithms, applications and extensions\n", "abstract": " An overview on Decision Diagrams (DDs), the state-of-the-art data structure in computer aided design of integrated circuits, is given. The overview is not complete in the sense that all DDs are considered, but we mention the most important with practical relevance. DDs are widely used and in the meantime have also been integrated in commercial tools. In the following special interest is devoted to the use of DDs in the area of synthesis. We also discuss the influence of DDs in other fields and outline future trends.", "num_citations": "13\n", "authors": ["1879"]}
{"title": "A genetic algorithm for RKRO minimization\n", "abstract": " We show that there is a close relation between Ordered Kronecker Functional Decision Diagrams (OKFDDs) and two-level AND/EXOR expressions. This relation, together with efficient OKFDD algorithms, can be utilized for exact and heuristic minimization of these AND/EXOR expressions, called Reduced Kronecker Expressions (RKROs).RKROs depend on the Variable Ordering (VO) and Decomposition Type List (DTL) of the corresponding OKFDD. We propose several (exact and heuristical) minimization algorithms for fixed VO and perform experimental results. A Genetic Algorithm (GA) is applied to minimize RKROs with respect to VO and DTL in parallel. We applied our GA to a large set of benchmark functions to show the efficiency of our approach.", "num_citations": "13\n", "authors": ["1879"]}
{"title": "OBDD-based optimization of input probabilities for weighted random pattern generation\n", "abstract": " Numerous methods have been devised to compute and to optimize fault detection probabilities for combinational circuits. The methods range from topological to algebraic. In combination with OBDDs, algebraic methods have received more and more attention. Recently, an OBDD based method has been presented which allows the computation of exact fault detection probabilities for many combinational circuits. We combine this method with strategies making use of necessary assignments (computed by an implication procedure). The experimental results show that the resulting method leads to a decrease of the time and space requirements for computing fault detection probabilities of the hard faults by a factor of 4 on average compared to the original algorithm. By this means it is now possible to efficiently use the OBDD based approach also for the optimization of input probabilities for weighted random pattern\u00a0\u2026", "num_citations": "13\n", "authors": ["1879"]}
{"title": "Computations over finite monoids and their test complexity\n", "abstract": " We consider the test pattern generation problem for circuits, which compute expressions over some algebraic structure. The relation between algebraic properties of this structure and test complexity (i.e. the best possible test size) is analyzed.Here, this relation is looked at in detail for the family of all finite monoids. The test complexity of a monoid with respect to a problem is measured by the number of tests needed to check the best testable circuit (in a certain computational model) solving the problem. Two important computations over finite monoids namely expression evaluation and parallel prefix computation are considered. The relation between algebraic properties of a monoid and its test complexity (with respect to these problems) is studied. In both cases it can be shown that the set of all finite monoids partitions into exactly three classes with constant, logarithmic and linear test complexity, respectively. These\u00a0\u2026", "num_citations": "13\n", "authors": ["1879"]}
{"title": "Optimal-time multipliers and c-testability\n", "abstract": " After a brief review on testability aspects of parallel arithmetical units we focus on n-bit multipliers and especially consider a class of Wallace tree multipliers made suitable for VLSI design by Vuillemin and Luk [VULU].It is shown that for these circuits both optimal running time and optimal test complexity can be obtained. A complete test set according to the single cellular fault model is presented.(In this case, the single cellular fault model is superior to the classical single stuck-at model.) The proposed test only consists of 17 pattern8 for all n. Hence, the multiplier is C-testable, ie it can be tested by a number of input combination8 which is independent of the number of cells in the circuit. The extra test hardware is very small. Only two additional ports and n-2 internal connections are necessary.", "num_citations": "13\n", "authors": ["1879"]}
{"title": "Computer simulation of an inverse problem for electric current computed tomography using a uniform triangular discretization\n", "abstract": " For the inverse problem of electric current computed tomography, discretization is achieved using a uniform mesh composed of triangular elements. The simulation presented utilizes network analysis, linearization, and iteration to obtain a solution. The network analysis algorithm for the direct as well as the inverse problem is described. It is shown how the matrices used to define the inverse problem can be generated automatically, given only a few parameters that describe the size of the mesh. A way to visualize the result graphically is presented.< >", "num_citations": "13\n", "authors": ["1879"]}
{"title": "On the construction of optimal time adders\n", "abstract": " In this paper we present the design of a novel optimal time adder: the conditional carry adder. In order to perform addition a tree-like combination of multiplexer cells is used in the carry computation part. We show that, for the complete conditional carry adder, this results in an overall computation time which seems to be substantially shorter than for any other known (optimal time) adder (e.g. carry look ahead adders ([BrKu]) or conditional sum adders ([Sk])).             The second part of this paper contains a uniform approach to the computation of the carry function resulting in seven different classes of optimal time adders. It is shown that the conditional carry adder and the carry look ahead adder are representatives of two different classes. While section 1 defines the conditional carry adder and proposes a realization which is very time efficient, section 2 provides the possibility to compare this choice with other\u00a0\u2026", "num_citations": "13\n", "authors": ["1879"]}
{"title": "An easily testable optimal-time VLSI-Multiplier\n", "abstract": " An easily testable optimal-time VLSI-multiplier - OpenGrey fra | eng OpenGrey Open System for Information on Grey literature in Europe Home Search Subjects Partners Export Help Search XML To cite or link to this reference: http://hdl.handle.net/10068/148486 Title : An easily testable optimal-time VLSI-multiplier Author : Becker, B. ; Corporate author : Saarland Univ., Saarbruecken (Germany). Sonderforschungsbereich 124 VLSI Entwurfsmethoden und Parallelitaet ; Kaiserslautern Univ. (Germany). Sonderforschungsbereich 124 VLSI Entwurfsmethoden und Parallelitaet ; Saarland Univ., Saarbruecken (Germany). Fachbereich 10 - Angewandte Mathematik und Informatik ; Deutsche Forschungsgemeinschaft (DFG), Bonn (Germany) ; Publication year : 1985 Language : English ; Pagination/Size : 22 p. ; SIGLE classification : 09J - Information theory, coding theory, signal processing ; 09A - Components ; Document \u2026", "num_citations": "13\n", "authors": ["1879"]}
{"title": "Dynamic polynomial watchdog encoding for solving weighted MaxSAT\n", "abstract": " In this paper we present a novel pseudo-Boolean (PB) constraint encoding for solving the weighted MaxSAT problem with iterative SAT-based methods based on the Polynomial Watchdog (PW) CNF encoding. The watchdog of the PW encoding indicates whether the bound of the PB constraint holds. In our approach, we lift this static watchdog concept to a dynamic one allowing an incremental convergence to the optimal result. Consequently, we formulate and implement a SAT-based algorithm for our new Dynamic Polynomial Watchdog (DPW) encoding which can be applied for solving the MaxSAT problem. Furthermore, we introduce three fundamental optimizations of the PW encoding also suited for the original version leading to significantly less encoding size. Our experimental results show that our encoding and algorithm is competitive with state-of-the-art encodings as utilized in QMaxSAT (2nd\u00a0\u2026", "num_citations": "12\n", "authors": ["1879"]}
{"title": "Das Debat-O-Meter: ein neues Instrument zur Analyse von TV-Duellen\n", "abstract": " Die Wirkung von TV-Duellen verbindet sich mit mehreren Aspekten3: Zun\u00e4chst erreicht kein anderes Wahlkampfereignis derart viele W\u00e4hler; so sahen beispiels weise zwischen 14 und 21 Millionen Zuschauer die bisherigen Duelle auf Bundes ebene. 4 Zum zweiten deckt kein anderes Format eine derart breite Palette an The men ab und erlaubt es W\u00e4hlern, nicht nur die Kandidaten und ihre Positionen kennen zu lernen, sondern diese auch direkt zu vergleichen. Und drittens sprechen TV-Duelle in besonderem Ma\u00dfe auch politisch weniger interessierte und daher oft nur schwer zu erreichende W\u00e4hler an5, sodass sie die Besch\u00e4ftigung mit Politik ansto\u00dfen und den Boden f\u00fcr politisches Engagement bereiten k\u00f6nnen. Faas und Maier sprechen deshalb zurecht von,, Wahlk\u00e4mpfe [n] im Miniaturformat\". 6", "num_citations": "12\n", "authors": ["1879"]}
{"title": "A lazy SMT-solver for a non-linear subset of real algebra\n", "abstract": " There are several methods for the synthesis and analysis of hybrid systems that require efficient algorithms and tools for satisfiability checking. For analysis, eg, bounded model checking describes counterexamples of a fixed length by logical formulas, whose satisfiability corresponds to the existence of such a counterexample. As an example for parameter synthesis, we can state the correctness of a parameterized system by a logical formula; the solution set of the formula gives us possible safe instances of the parameters. For discrete systems, which can be described by propositional logic formulas, SAT-solvers can be used for the satisfiability checks. For hybrid systems, having mixed discrete-continuous behavior, SMT-solvers are needed. SMT-solving extends SAT with theories, and has its main focus on linear arithmetic, which is sufficient to handle, eg, linear hybrid systems. However, there are only few solvers for more expressive but still decidable logics like the first-order theory of the reals with addition and multiplication--real algebra. Since the synthesis and analysis of non-linear hybrid systems requires such a powerful logic, we need efficient SMT-solvers for real algebra. Our goal is to develop such an SMT-solver for the real algebra, which is both complete and efficient.", "num_citations": "12\n", "authors": ["1879"]}
{"title": "Early Conflict Detection Based BCP for SAT Solving.\n", "abstract": " This paper describes a new BCP algorithm that improves the performance of Chaff class solvers by reducing the total number of clauses the BCP procedure must evaluate. This is done by: detecting conflicts earlier; evaluating clauses better; and by increasing the controllability of the conflicts which the BCP procedure finds. Solvers like Limmat [10] include a simple Early Conflict Detection BCP (ECDB), however we introduce a new aggressive ECDB procedure and the MIRA solver that efficiently incorporates it while easily facilitating comparisons between ECDB modes. With the full ECDB procedure enabled, MIRA was able to reduce the number of evaluated clauses by 59% on average compared to the disabled ECDB version. This new procedure and other speedup techniques discussed here allow MIRA to solve problems 3.7 times faster on average than zChaff. Lastly, this paper shows how significant speedup can be attained relatively easily by incorporating a certain level of ECDB into other solvers.", "num_citations": "12\n", "authors": ["1879"]}
{"title": "Exact channel routing using symbolic representation\n", "abstract": " The layout problem in VLSI-design can be broken up into the subtasks partitioning, placement and routing. As well as the others of these tasks, the routing problem is NP-complete and so in general it is impossible to find an optimal solution to it in an efficient way. However for problem instances of small size, it may be possible not only to generate the best routing with respect to a certain cost function, but even to determine all legal solutions to the problem. We consider the channel routing problem and show how to solve it exactly using symbolic methods i.e. MDDs (Multi-valued Decision Diagrams). The basic operations on MDDs can be carried out very efficiently and thus the necessary time-consuming computations can be speeded up considerably. In our approach, wires in the channel are described as functions of multi-valued variables, and so the grid points and also the set of legal solutions can be represented\u00a0\u2026", "num_citations": "12\n", "authors": ["1879"]}
{"title": "Manipulation algorithms for K*BMDs\n", "abstract": " Bit-level and word-level based Decision Diagrams (DDs) have led to significant advances in the area of Computer Aided Design (CAD). Recently, a new data structure for the word-level, called Kronecker Multiplicative BMDs (K*BMDs), has been presented.             We study manipulation algorithms for K*BMDs: Using K*BMDs it is possible to represent functions efficiently, that have a good word-level description (like multipliers). On the the other hand K*BMDs are also applicable to verification problems at the bit-level. We clarify the relation between bit- and word-level representation which is of importance in particular in the context of verification. Experiments show that *BMDs are not wellsuited for the bit-level. On the other hand OBDDs are not applicable on the word-level. We present algorithms that allow to dynamically switch between bit-level and word-level. We discuss a method for changing the\u00a0\u2026", "num_citations": "12\n", "authors": ["1879"]}
{"title": "AND/EXOR-based synthesis of testable KFDD-circuits with small depth\n", "abstract": " Decision Diagrams are used in design automation for efficient representation of Boolean functions. It is also possible to directly derive circuits from Decision Diagrams. In this paper we present an approach to synthesize circuits from a very general class of Decision Diagrams, the ordered Kronecker Functional Decision Diagrams. These Decision Diagrams make use of Davio decompositions which are based on exclusive-or operations and therefore allow the use of EXOR gates in the synthesized circuits. We investigate area, depth, and testability of these circuits and compare them to circuit designs generated by other synthesis tools. Experimental results show that the presented approach is suitable to overcome the trade-off between depth and testability at the price of reasonable area overhead.", "num_citations": "12\n", "authors": ["1879"]}
{"title": "Computer aided design and modeling of high frequency magnetic components\n", "abstract": " A new computer-aided design program is presented suitable for design, optimization and modeling of high frequency multiwinding transformers and inductors in any power electronics applications (converters and inverters). Depending on the arrangement of the windings and the ambient temperature on one hand the winding losses and the core losses can be calculated if the voltage and current waveforms at the terminals are known in principle. On the other hand state space models or equivalent circuits of different accuracy can be determined and implemented easily into simulators like SABER. An optimization routine allows the interactive optimization of high frequency magnetic components regarding losses, weight or height.< >", "num_citations": "12\n", "authors": ["1879"]}
{"title": "Fast fault simulation in combinational circuits: an efficient data structure, dynamic dominators and refined check-up\n", "abstract": " Several methods accelerating fault simulation for combinational circuits using parallel pattern evaluation are presented. All methods make use of a very efficient data structure which allows the easy recognition of special situations that can be used to avoid a lot of gate evaluations during explicit fault simulation. An implementation of the concepts shows that the resulting fault simulation algorithm is very fast. The proposals and the improved data structure considerably enhance the performance of the standard algorithm.<>", "num_citations": "12\n", "authors": ["1879"]}
{"title": "A uniform test approach for RCC-Adders\n", "abstract": " In this paper testability aspects of Recursive Carry Computation adders are considered. The class of RCC-adders has been introduced in [5] and contains a wide range of different adder realizations (eg, optimal time adders such as the the carry look-ahead adder of [8] and the conditional carry adder of [5]).", "num_citations": "12\n", "authors": ["1879"]}
{"title": "Dependency schemes for DQBF\n", "abstract": " Dependency schemes allow to identify variable independencies in QBFs or DQBFs. For QBF, several dependency schemes have been proposed, which differ in the number of independencies they are able to identify. In this paper, we analyze the spectrum of dependency schemes that were proposed for QBF. It turns out that only some of them are sound for DQBF. For the sound ones, we provide a correctness proof, for the others counter examples. Experiments show that a significant number of dependencies can either be added to or removed from a formula without changing its truth value, but with significantly increasing the flexibility for modifying the representation.", "num_citations": "11\n", "authors": ["1879"]}
{"title": "Accurate CEGAR-based ATPG in presence of unknown values for large industrial designs\n", "abstract": " Unknown values emerge during the design and test generation process as well as during later test application and system operation. They adversely affect the test quality by reducing the controllability and observability of internal circuit structures - resulting in a loss of fault coverage. To handle unknown values, conventional test generation algorithms as used in state-of-the-art commercial tools, rely on n-valued algebras. However, n-valued algebras introduce pessimism as soon as X-values reconverge. Consequently, these algorithms fail to compute the accurate result. This paper focuses on a new highly incremental CEGAR-based algorithm that overcomes these limitations and hence is completely accurate in presence of unknown values. It relies on a modified SAT-solver tailored for this specific problem. The experimental results for circuits with up to 2 400 000 gates show that this combination allows high\u00a0\u2026", "num_citations": "11\n", "authors": ["1879"]}
{"title": "Compressor map computation based on 3D CFD analysis\n", "abstract": " The focus of the paper is on procedures and strategies to compute high-fidelity compressor maps for aero engines based on 3D CFD. The developed automatic process starts with an operation point analysis where a convergence checker terminates the running 3D flow analysis as soon as physical quantities such as mass flow or aerodynamic blade row loss have converged. Subsequently, the corresponding compressor speed line is determined, where operation limits like surge and choke are detected by solving optimization and root search problems, respectively. Such speed lines also have to be calculated for various other shaft speeds to obtain the whole performance map. This is achieved by adjusting shaft speed and boundary conditions, where the mesh for variable stator vanes and the amount of bleed mass flow are adapted automatically according to given schedules. Finally, the developed\u00a0\u2026", "num_citations": "11\n", "authors": ["1879"]}
{"title": "Recent advances in SAT-based ATPG: Non-standard fault models, multi constraints and optimization\n", "abstract": " It is well-known that in principle automatic test pattern generation (ATPG) can be solved by transforming the circuit and the fault considered into a Boolean satisfiability (SAT) instance and then calling a so-called SAT solver to compute a test. More recently, the potential of SAT-based ATPG has been significantly extended. In this paper, we first provide introductory knowledge on SAT-based ATPG and then report on latest developments enabling applications far beyond classical ATPG.", "num_citations": "11\n", "authors": ["1879"]}
{"title": "SMILE: Smartphones in der Lehre\u2013ein R\u00fcck-und \u00dcberblick\n", "abstract": " Bei SMILE handelt es sich um ein Projekt, das im Wintersemester 2010 gestartet wurde. Sein fortlaufendes Ziel ist die Erforschung von M\u00f6glichkeiten, die universit\u00e4re Lehre - insbesondere Vorlesungen mit \u00fcber hundert Studierenden - durch den Einsatz von IT zu bereichern. Hierf\u00fcr wurden Apps f\u00fcr Studierende und Dozierenden entwickelt, die auf allen g\u00e4ngigen Ger\u00e4ten laufen. Die konzeptionelle Planung liegt bei einem interdisziplin\u00e4ren Team aus Informatikern und Instructional Designern; f\u00fcr die Implementierung wird eng mit einem studentischen Entwicklerteam zusammen gearbeitet. Zwei Preisauszeichnungen zeigen die positive Resonanz, die SMILE bisher hervor gerufen hat. Im Sommersemester 2013 wird SMILE zum vierten Mal in einer gr\u00f6\u00dferen Vorlesung eingesetzt. In diesem Workshop-Paper beschreiben wir den bisherigen Verlauf des Projekts und die Kernfunktionalit\u00e4ten der Software.", "num_citations": "11\n", "authors": ["1879"]}
{"title": "Analysis of ring oscillator pufs on 60nm fpgas\n", "abstract": " In hardware security and trusted computing it is often desired to uniquely and unambiguously identify a device among several others of the same brand. Physically unclonable functions (PUFs) take advantage of subtle variations in the devices\u2019 production process to achieve this. A ring oscillator (RO) PUF exploits differing time delays of circuits to yield a unique response from each device. The implementation of RO PUFs on FPGAs has been widely discussed but most experiments have been conducted on Xilinx FPGAs. In this paper we are reporting statistical results from an analysis spanning 20 equivalent Altera FPGAs. The presented results include the PUF quality\u2019s dependency on different parameters like RO length and placement on the FPGA. We identify the optimal RO length of 16 Logic Elements (LE) and show some specific placement cases for which the otherwise very good PUF quality decreases drastically.", "num_citations": "11\n", "authors": ["1879"]}
{"title": "Symbolic counterexample generation for discrete-time Markov chains\n", "abstract": " In this paper we investigate the generation of counterexamples for discrete-time Markov chains (DTMCs) and PCTL properties. Whereas most available methods use explicit representations for at least some intermediate results, our aim is to develop fully symbolic algorithms. As in most related work, our counterexample computations are based on path search. We first adapt bounded model checking as a path search algorithm and extend it with a novel SAT-solving heuristics to prefer paths with higher probabilities. As a second approach, we use symbolic graph algorithms to find counterexamples. Experiments show that our approaches, in contrast to other existing techniques, are applicable to very large systems with millions of states.", "num_citations": "11\n", "authors": ["1879"]}
{"title": "Bounded model checking of incomplete networks of timed automata\n", "abstract": " Verification of real-time systems - e.g. communication protocols or embedded controllers - is an important task. One method to detect errors is called bounded model checking (BMC). In BMC the system is iteratively unfolded and then transformed into a satisfiability problem. If an appropriate solver finds the k-th instance to be satisfiable a counterexample for a given safety property has been found. In this paper we present a first approach to apply BMC to networks of timed automata (that is a system of several interacting subautomata) where parts of the network are unspecified (so called blackboxes). Here, we would like to answer the question of unrealizability, that is, is there a path of a certain length violating a safety property regardless of the implementation of the blackboxes. We provide solutions to this problem for two timed automata communication models. For the simple synchronization model, a BMC approach\u00a0\u2026", "num_citations": "11\n", "authors": ["1879"]}
{"title": "Minimization of large state spaces using symbolic branching bisimulation\n", "abstract": " Bisimulations in general are a powerful concept to minimize large finite state systems regarding some well-defined observational behavior. In contrast to strong bisimulation, for branching bisimulation there are only tools available that work on an explicit state space representation. In this work, we present for the first time a symbolic approach for branching bisimulation that uses BDDs as basic data structure and that is based on the concept of signature refinement. First experimental results for problem instances derived from process algebraic system descriptions show the feasibility and the robustness of our approach", "num_citations": "11\n", "authors": ["1879"]}
{"title": "On detection of resistive bridging defects by low-temperature and low-voltage testing\n", "abstract": " Resistive defects are gaining importance in very-deepsubmicron technologies, but their detection conditions are not trivial. Test application can be performed under reduced temperature and/or voltage in order to improve detection of these defects. This is the first analytical study of resistive bridge defect coverage of CMOS ICs under low-temperature and mixed low-temperature, low-voltage conditions. We extend a resistive bridging fault model in order to account for temperature-induced changes in detection conditions. We account for changes in both the parameters of transistors involved in the bridge and the resistance of the short defect itself. Using a resistive bridging fault simulator, we determine fault coverage for low-temperature testing and compare it to the numbers obtained at nominal conditions. We also quantify the coverage of flaws, i.e. defects that are redundant at nominal conditions but could deteriorate\u00a0\u2026", "num_citations": "11\n", "authors": ["1879"]}
{"title": "Evolutionary optimization of Markov sources for pseudo random scan BIST\n", "abstract": " Recent work by Basturkmen et al. (2002) showed that Markov sources lead to scan BIST designs of lower cost compared to earlier proposed methods in scan BIST. However the method presented by Basturkmen et al. utilizes tests generated using a deterministic test generator for target faults in synthesizing the Markov source to generate the tests. The requirement of a deterministic test generator may hinder the use of this procedure in industrial settings since the BIST tool must also include a deterministic ATPG tool that may add to the cost of the BIST tool. In this paper we investigate a procedure to synthesize BIST controllers with Markov sources for test generation using Evolutionary Algorithms (EAs). This allows us to avoid using the deterministic ATPG needed previously. Additionally we do not employ inversion logic used in by Basturkmen et al., thereby potentially reducing the hardware in the BIST controller\u00a0\u2026", "num_citations": "11\n", "authors": ["1879"]}
{"title": "Minimization of OKFDDs by genetic algorithms\n", "abstract": " A Genetic Algorithm (GA) is applied to minimize the size of Ordered Kronecker Functional Decision Diagrams (OKFDDs). Our approach chooses a good variable ordering and decomposition type list in parallel. We apply our minimization algorithm to technology mapping for FPGAs. Experimental results are given to show the efficiency of our approach. 1 Introduction Genetic Algorithms (GAs) are often used in optimization and machine learning [14, 6]. In many applications they are superior to the classical optimization techniques, eg gradient-descent. Recently, GAs have succesfully been applied to several hard problems in Computer Aided Design (CAD), like routing, placement, test pattern generation and logic synthesis (see eg [11, 20, 9]). Decision Diagrams (DDs) are often used in CAD systems for efficient representation and manipulation of Boolean functions [5, 8, 7]. Ordered Kronecker Functional Decision Diagrams (OKFDD), the most general ordered DD, have been presented in [10]. OKFDDs a...", "num_citations": "11\n", "authors": ["1879"]}
{"title": "Random pattern fault simulation in multi-valued circuits\n", "abstract": " We present a fault simulator for Multi-Valued Logic Networks (MVLN). With this tool we investigate their Random Pattern Testability (RPT). We show for a restricted class of multi-valued circuits that the RPT is better than for two-valued circuits. We point out the relation between redundancies in two- and multi-valued logic networks. Moreover we show that the role of fault simulation for MVLNs is more important than in the binary case. A set of experimental results for large circuits emphasizes the efficiency of our approach.", "num_citations": "11\n", "authors": ["1879"]}
{"title": "Computer aided optimization of multi-winding transformers for SMPS considering HF-effects\n", "abstract": " Physical models of multi-winding transformers for SMPS with modern standard or variable core geometries and solenoidal windings arranged side by side or planar spiral windings are presented, suitable for computer aided optimization under consideration of skin and proximity effects. The winding layers are composable to interleaved or arbitrary composited windings to reduce losses. The height of ferrite cores for planar transformers in power modules can be assigned, while core losses are approximately accounted for. The selection of an objective function, the initial values and algorithms are guided by the aim to integrate the nonlinear optimization program into a CAE package for SMPS, run on PCs.< >", "num_citations": "11\n", "authors": ["1879"]}
{"title": "FIRED: A Fully-labeled hIgh-fRequency Electricity Disaggregation Dataset\n", "abstract": " As more and more homes are equipped with smart electricity meters, home owners gain the ability to monitor their total electricity consumption on a daily or hourly basis. Techniques such as load forecasting, load disaggregation, and activity recognition try to provide even better insights into our electricity consumption, highlight saving potential or improve our daily living. To develop and evaluate these techniques, publicly available datasets are used. We identified a lack of high frequency fully labeled electricity datasets in the residential domain and present the FIRED dataset. It contains 52 days of 8 kHz aggregated current and voltage readings of the 3-phase supply of a typical residential apartment in Germany. The dataset also contains synchronized ground truth data as 2 kHz readings of 21 individual appliances, as well as room temperature readings and fully labeled state changes of the lighting system, resulting\u00a0\u2026", "num_citations": "10\n", "authors": ["1879"]}
{"title": "Hardware-oriented algebraic fault attack framework with multiple fault injection support\n", "abstract": " The evaluation of fault attacks on security-critical hardware implementations of cryptographic primitives is an important concern. In such regards, we have created a framework for automated construction of fault attacks on hardware realization of ciphers. The framework can be used to quickly evaluate any cipher implementations, including any optimisations. It takes the circuit description of the cipher and the fault model as input. The output of the framework is a set of algebraic equations, such as conjunctive normal form (CNF) clauses, which is then fed to a SAT solver. We consider both attacking an actual implementation of a cipher on an field-programmable gate array (FPGA) platform using a fault injector and the evaluation of an early design of the cipher using idealized fault models. We report the successful application of our hardware-oriented framework to a collection of ciphers, including the advanced\u00a0\u2026", "num_citations": "10\n", "authors": ["1879"]}
{"title": "Sensitized path PUF: A lightweight embedded physical unclonable function\n", "abstract": " Physical unclonable functions (PUFs) can be used for a number of security applications, including secure on-chip generation of secret keys. We introduce an embedded PUF concept called sensitized path PUF (SP-PUF) that is based on extracting entropy out of inherent timing variability of modules already present in the circuit. The new PUF sensitizes paths of nearly identical lengths and generates response bits by racing transitions through different paths against each other. SP-PUF has lower area overhead and higher speed than earlier embedded PUFs and requires no helper data stored in non-volatile memory beyond standard error-correction information for fuzzy extraction. Compared with standalone PUFs, the new solution intrinsically and inseparably intertwines PUF behavior with functional circuitry, thus complicating invasive attacks or simplifying their detection. We present a systematic design flow to turn\u00a0\u2026", "num_citations": "10\n", "authors": ["1879"]}
{"title": "Skolem functions for DQBF\n", "abstract": " We consider the problem of computing Skolem functions for satisfied dependency quantified Boolean formulas (DQBFs). We show how Skolem functions can be obtained from an elimination-based DQBF solver and how to take preprocessing steps into account. The size of the Skolem functions is optimized by don\u2019t-care minimization using Craig interpolants and rewriting techniques. Experiments with our DQBF solver HQS show that we are able to effectively compute Skolem functions with very little overhead compared to the mere solution of the formula.", "num_citations": "10\n", "authors": ["1879"]}
{"title": "Formal vulnerability analysis of security components\n", "abstract": " Vulnerability to malicious fault attacks is an emerging concern for hardware circuits that are employed in mobile and embedded systems and process sensitive data. We describe a new methodology to assess the vulnerability of a circuit to such attacks, taking into account built-in protection mechanisms. Our method is based on accurate modeling of fault effects and detection status expressed by Boolean satisfiability (SAT) formulas. Vulnerability is quantified based on the number of solutions of these formulas, which are determined by an efficient #SAT solver. We demonstrate the applicability of this method for design space exploration of a pseudo random number generator and for calculating the attack success rate in a multiplier circuit protected by robust error-detecting codes.", "num_citations": "10\n", "authors": ["1879"]}
{"title": "Improving diagnosis resolution of a fault detection test set\n", "abstract": " Manufactured VLSI circuits using a new technology typically suffer from systematic defects that are process-dependent and at sub-nanometer feature sizes such defects may be even design-dependent. The root causes for systematic defects must be determined to ramp up yields. Volume diagnosis is becoming popular to identify root causes for systematic defects. Volume diagnosis uses logic diagnosis based on failing circuit responses to production tests of a large number of failing devices, followed by statistical analysis methods to determine the root cause(s) for yield limiters. Typically production tests use fault detection tests and hence may have limited diagnosis resolution. To improve diagnosis resolution diagnostic ATPGs can be used to generate test sets to distinguish all pairs of distinguishable faults in one or more fault models. The sizes of such tests tend to be considerably higher than fault detection test sets\u00a0\u2026", "num_citations": "10\n", "authors": ["1879"]}
{"title": "Estimation of component criticality in early design steps\n", "abstract": " Nanoscale integrated circuits suffer both from high defect densities and increased parameter variations possibly affecting the overall timing behaviour. Components with a higher vulnerability to process variations are not just critical during test design and test application, but also during normal operation. In particular, ageing effects and changes in the operation environment including supply voltage, temperature and radiation, can easily aggravate the effects of parameter variations inherent to the manufacturing process. Online and offline techniques that attempt to cope with such effects, like online error detection and correction, online diagnosis and hardening, have high cost and therefore cannot be applied to the whole circuit. Making a good selection of components to apply these techniques to, requires accurate metrics for gate criticality under process variations. This paper presents a SAT-based approach to\u00a0\u2026", "num_citations": "10\n", "authors": ["1879"]}
{"title": "Parallel QBF solving with advanced knowledge sharing\n", "abstract": " In this paper we present the parallel QBF Solver PaQuBE. This new solver leverages the additional computational power that can be exploited from modern computer architectures, from pervasive multi-core boxes to clusters and grids, to solve more relevant instances faster than previous generation solvers. Furthermore, PaQuBE's progressive MPI based parallel framework is the first to support advanced knowledge sharing in which solution cubes as well as conflict clauses can be exchanged between solvers. Knowledge sharing plays a critical role in the performance of PaQuBE. However, due to the overhead associated with sending and receiving MPI messages, and the restricted communication/network bandwidth available between solvers, it is essential to optimize not only what information is shared, but the way in which it is shared. In this context, we compare multiple conflict clause and solution cube sharing\u00a0\u2026", "num_citations": "10\n", "authors": ["1879"]}
{"title": "Correctness issues of symbolic bisimulation computation for Markov chains\n", "abstract": " Bisimulation reduction is a classical means to fight the infamous state space explosion problem, which limits the applicability of automated methods for verification like model checking. A signature-based method, originally developed by Blom and Orzan for labeled transition systems and adapted for Markov chains by Derisavi, has proved to be very efficient. It is possible to implement it symbolically using binary decision diagrams such that it is able to handle very large state spaces efficiently. We will show, however, that for Markov chains this algorithm suffers from numerical instabilities, which often result in too large quotient systems. We will present and experimentally evaluate two different approaches to avoid these problems: first the usage of rational arithmetic, and second an approach not only to represent the system structure but also the transition rates symbolically. In addition, this allows us to modify\u00a0\u2026", "num_citations": "10\n", "authors": ["1879"]}
{"title": "Diagnosis of realistic defects based on the X-fault model\n", "abstract": " Defects not described by conventional fault models are a challenge for state-of-the-art fault diagnosis techniques. The X-fault model has been introduced recently as a modeling technique for complex defect mechanisms. We analyze the performance of the X-fault diagnosis for a number of defect classes leading to highly complex circuit behavior on electrical level. Experiments performed using accurate resistive- bridge and interconnect-open simulators demonstrate the superiority of X-fault diagnosis over traditional methods.", "num_citations": "10\n", "authors": ["1879"]}
{"title": "Experiences with error handling in critical systems\n", "abstract": " Over the past several years, we have analyzed the error-handling designs of a variety of critical applications and have discovered serious defects even in well-tested and mature systems. In this paper, we will describe specific recurring patterns of error handling defects we have observed in critical systems. It seems clear that the design, implementation, and testing of error handling are often not given adequate attention and resources.", "num_citations": "10\n", "authors": ["1879"]}
{"title": "Evolutionary algorithms in computer-aided design of integrated circuits\n", "abstract": " An increasing number of successful applications of Evolutionary Algorithms (EAs) within Computer Aided Design (CAD) of Integrated Circuits (ICs) is reported in the literature. The problems dealt with in this eld consist of sequences of sub-problems, which are characterized by being NP-hard, large and mutually dependent. This very high level of complexity should make the EA a well suited approach, at least in principle.However, the EA is of practical interest to the CAD community if and only if it is competitive to the existing approaches with respect to performance. With this fact as the starting point, the purpose of this paper is to discuss how to develop high-performance EAs for CAD of ICs.", "num_citations": "10\n", "authors": ["1879"]}
{"title": "A genetic algorithm for the construction of small and highly testable OKFDD-circuits\n", "abstract": " A Genetic Algorithm (GA) is applied to derive circuits that combine area efficiency and testability. These circuits are obtained from Ordered Kronecker Functional Decision Diagrams (OKFDDs). In\" Becker and Drechsler (1995)\" a heuristic approach has been presented. In this paper we show how these results can further be improved by GAs. Finally, we apply our minimization algorithm to technology mapping for FPGAs. We present experimental results to show the efficiency of our approach.", "num_citations": "10\n", "authors": ["1879"]}
{"title": "The (D) QBF preprocessor HQSpre\u2013Underlying theory and its implementation\n", "abstract": " Preprocessing turned out to be an essential step for SAT, QBF, and DQBF solvers to reduce/modify the number of variables and clauses of the formula, before the formula is passed to the actual solving algorithm. These preprocessing techniques often reduce the computation time of the solver by orders of magnitude. In this paper, we present the preprocessor HQSpre that was developed for Dependency Quantified Boolean Formulas (DQBFs) and that generalizes different preprocessing techniques for SAT and QBF problems to DQBF. We give a presentation of the underlying theory together with detailed proofs as well as implementation details contributing to the efficiency of the preprocessor. HQSpre has been used with obvious success by the winners of the DQBF track, and, even more interestingly, the QBF tracks of QBFEVAL\u201918.", "num_citations": "9\n", "authors": ["1879"]}
{"title": "QBF with soft variables\n", "abstract": " QBF formulae are usually considered in prenex form, ie the quantifierblock is completely separated from the propositional part of the QBF. Among others, the semantics of the QBF is defined by the sequence ofthe variables within the prefix, where existentially quantifiedvariables depend on all universally quantified variables stated to theleft.", "num_citations": "9\n", "authors": ["1879"]}
{"title": "Implementation and analysis of ring oscillator PUFs on 60 nm Altera Cyclone FPGAs\n", "abstract": " Ring Oscillator (RO) physically unclonable functions (PUFs) on field programmable gate arrays (FPGAs) have drawn much attention in recent years. Making each FPGA uniquely identifiable, they allow for protection of intellectual property (IP) or generation of secret encryption keys. Their implementation has been widely discussed, but most experiments have been conducted on Xilinx platforms. In this paper, we report the statistical results from an analysis spanning 20 Cyclone IV FPGAs with 60 nm technology. We parameterize the RO length, placement, ambient temperature, and non-PUF switching activity and discuss the observed effects on PUF quality.", "num_citations": "9\n", "authors": ["1879"]}
{"title": "Equivalence Checking for Partial Implementations Revisited.\n", "abstract": " In this paper we consider the problem of checking whether a partial implementation can (still) be extended to a complete design which is equivalent to a given full specification. In particular, we investigate the relationship between the equivalence checking problem for partial implementations (PEC) and the validity problem for quantified Boolean formulae (QBF) with so-called Henkin quantifiers. Our analysis leads us to a sound and complete algorithmic solution to the PEC problem as well as to an exact complexity theoretical classification of the problem.", "num_citations": "9\n", "authors": ["1879"]}
{"title": "Incremental QBF preprocessing for partial design verification\n", "abstract": " Bounded Model Checking (BMC) is a major verification method for finding errors in sequential circuits. BMC accomplishes this by iteratively unfolding a circuit k times, adding the negated property, and finally converting the BMC instance into a sequence of satisfiability (SAT) problems. When considering incomplete designs (i.e. those containing so-called blackboxes), we rather need the logic of Quantified Boolean Formulas (QBF) to obtain a more precise modeling of the unknown behavior of the blackbox. Here, we answer the question of unrealizability of a property, where finding a path of length k proves that the property is violated regardless of the implementation of the blackbox. To boost this task, solving blackbox BMC problems incrementally has been shown to be feasible [3], although the restrictions required in the preprocessing phase reduce its effectiveness. In this paper we enhance the verification\u00a0\u2026", "num_citations": "9\n", "authors": ["1879"]}
{"title": "Minimal Critical Subsystems as Counterexamples for omega-Regular DTMC Properties.\n", "abstract": " We propose a new approach to compute counterexamples for violated \u03c9-regular properties of discrete-time Markov chains. Whereas most approaches compute a set of system paths as a counterexample, we determine a critical subsystem that already violates the given property. In earlier work methods have been introduced to compute such subsystems for safety properties, based on a search for shortest paths. In this paper we use mixed integer linear programming to determine minimal critical subsystems for arbitrary \u03c9-regular properties.", "num_citations": "9\n", "authors": ["1879"]}
{"title": "Proof certificates and non-linear arithmetic constraints\n", "abstract": " Symbolic methods in computer-aided verification rely heavily on constraint solvers. The correctness and reliability of these solvers are of vital importance in the analysis of safety-critical systems, e.g., in the automotive context. Satisfiability results of a solver can usually be checked by probing the computed solution. This is in general not the case for un-satisfiability results. In this paper, we propose a certification method for unsatisfiability results for mixed Boolean and non-linear arithmetic constraint formulae. Such formulae arise in the analysis of hybrid discrete/continuous systems. Furthermore, we test our approach by enhancing the iSAT constraint solver to generate unsatisfiability proofs, and implemented a tool that can efficiently validate such proofs. Finally, some experimental results showing the effectiveness of our techniques are given.", "num_citations": "9\n", "authors": ["1879"]}
{"title": "Picoso-A Parallel Interval Constraint Solver.\n", "abstract": " This paper describes the parallel interval constraint solver Picoso, which can decide (a subclass of) boolean combinations of linear and non-linear constraints. Picoso follows a master/client model based on message passing, making it suitable for any kind of workstation cluster as well as for multi-processor machines. To run several clients in parallel, an efficient work stealing mechanism has been integrated, dividing the overall search space into disjoint parts. Additionally, to prevent the clients from running into identical conflicts, information about conflicts in form of conflict clauses is exchanged among the clients. Performance measurements, using four clients to solve a number of benchmark problems, show that Picoso yields (almost) linear speedup compared to the sequential interval constraint solver iSAT, on which the clients of Picoso are based.", "num_citations": "9\n", "authors": ["1879"]}
{"title": "Optimization techniques for BDD-based bisimulation computation\n", "abstract": " In this paper we report on optimizations for a BDD-based algorithm for the computation of bisimulations. The underlying algorithmic principle is an iterative refinement of a partition of the state space. The proposed optimizations demonstrate that both, taking into account the algorithmic structure of theproblem and the exploitation of the BDD-based representation, are essential to finally obtain an efficient symbolic algorithm for real-world problems. The contributions of this paper are (1) block forwarding to update block refinement as soon as possible,(2) split-driven refinement that over-approximates the set of blocks that must definitely be refined, and (3) block ordering to fix the order of the blocks for the refinement in a clever way. We provide substantial experimental results on examples from different applications and compare them to alternative approaches when possible. The experiments clearly show that the\u00a0\u2026", "num_citations": "9\n", "authors": ["1879"]}
{"title": "Orthogonal circuit visualization improved by merging the placement and routing phases\n", "abstract": " Visualization of circuits is an important research area in electronic design automation. Locating errors in a large design may require a high-quality graphical representation of a circuit that allows humans to understand it. Usually, drawing a circuit is based on visualizing the corresponding graph or hypergraph structure where nodes are connected by straight lines, and nodes are located in a way that minimizes the crossings of these lines. Then the algorithms re-transform this graph representation back to an orthogonal circuit structure, i. e. it replaces the straight lines by horizontal and vertical lines. In contrast to many other approaches which route all the wiring after placing all nodes we focus on a new approach which dynamically reorders the nodes within the layers to further reduce the number of hyperedge crossings. An efficient algorithm is presented that minimizes the hyperedge crossings. Experimental results\u00a0\u2026", "num_citations": "9\n", "authors": ["1879"]}
{"title": "K-layer straightline crossing minimization by speeding up sifting\n", "abstract": " Recently, a technique called sifting has been proposed for k-layer straightline crossing minimization. This approach outperforms the traditional layer by layer sweep based heuristics by far when applied to k-layered graphs with k\u22653. In this paper, we present two methods to speed up sifting. First, it is shown how the crossing matrix can be computed and updated efficiently. Then, we study lower bounds which can be incorporated in the sifting algorithm, allowing to prune large parts of the search space. Experimental results show that it is possible to speed up sifting by more than a factor of 20 using the new methods.", "num_citations": "9\n", "authors": ["1879"]}
{"title": "Grouping heuristics for word-level decision diagrams\n", "abstract": " Word-level decision diagrams (WLDDs), like EVBDDs, *BMDs, HDDs, K*BMDs, are powerful tools in circuit verification. For some arithmetic circuits, like multipliers, formal verification was possible for the first time using WLDDs. Besides a good variable ordering and the decomposition types the size of a WLDD essentially depends on the grouping of the outputs. In this paper we study output grouping in more detail. We give examples showing that an exponential reduction or an exponential blow-up can be obtained dependent on grouping. We describe efficient heuristics for output grouping given a circuit description in the form of a netlist. Experimental results are given to demonstrate the efficiency of our approach.", "num_citations": "9\n", "authors": ["1879"]}
{"title": "Memory controller for providing a plurality of defined areas of a mass storage medium as independent mass memories to a master operating system core for exclusive provision to\u00a0\u2026\n", "abstract": " A computer system includes at least one processor, a first mass memory and a second mass memory. The computer system implements a master operating system core, a first operating system core and at least one second operating system core on the processor under control of the master operating system core. The memory controller provides the master operating system core with defined areas of a mass storage medium as a first mass memory and at least one second mass memory, each independent of one another, and controls mapping of the first mass memory and of the at least one second mass memory to the defined areas of the mass storage medium. The master operating system core allows the first operating system core and the at least one second operating system core to have exclusive access to at least one of the mass memories.", "num_citations": "8\n", "authors": ["1879"]}
{"title": "Pacose: an iterative SAT-based MaxSAT solver\n", "abstract": " Pacose is a SAT-based MaxSAT solver, using two incremental CNF encodings, a binary adder [1] and the Dynamic Polynomial Watchdog (DPW)[2], for Pseudo-Boolean (PB) constraints. It is an extension of QMaxSAT 2017 [3], based on Glucose 4.2. 1 [4] SAT solver. It uses a Boolean Multilevel Optimization (BMO) pre-/inprocessing method to simplify the instances. Additionally a trimming method is applied to cut off unsatisfiable soft clauses and find a good initial satisfiable weight to reduce the size of the encoding.", "num_citations": "8\n", "authors": ["1879"]}
{"title": "Distributed parallel# SAT solving\n", "abstract": " The #SAT problem, that is counting the number of solutions of a propositional formula, extends the well-known SAT problem into the realm of probabilistic reasoning. However, the higher computational complexity and lack of fast solvers still limits its applicability for real world problems. In this work we present our distributed parallel #SAT solver dCountAntom which utilizes both local, shared-memory parallelism as well as distributed (cluster computing) parallelism. Although highly parallel solvers are known in SAT solving, such techniques have never been applied to the #SAT problem. Furthermore we introduce a solve progress indicator which helps the user to assess whether the presented problem is likely solvable within a reasonable time. Our analysis shows a high accuracy of the estimated progress. Our experiments with up to 256 CPU cores working in parallel yield large speedups across different\u00a0\u2026", "num_citations": "8\n", "authors": ["1879"]}
{"title": "Using interval constraint propagation for pseudo-boolean constraint solving\n", "abstract": " This work is motivated by (1) a practical application which automatically generates test patterns for integrated circuits and (2) the observation that off-the-shelf state-of-the-art pseudo-Boolean solvers have difficulties in solving instances with huge pseudo-Boolean constraints as created by our application. Derived from the SMT solver iSAT3 we present the solver iSAT3p that on the one hand allows the efficient handling of huge pseudo-Boolean constraints with several thousand summands and large integer coefficients. On the other hand, experimental results demonstrate that at the same time iSAT3p is competitive or even superior to other solvers on standard pseudo-Boolean benchmark families.", "num_citations": "8\n", "authors": ["1879"]}
{"title": "Implication Graph Compression inside the SMT Solver iSAT3.\n", "abstract": " The iSAT algorithm aims at solving boolean combinations of linear and non-linear arithmetic constraint formulas (including transcendental functions), and thus is suitable to verify safety properties of systems consisting of both, linear and non-linear behaviour. The iSAT algorithm tightly integrates interval constraint propagation into the conflict-driven clauselearning framework. During the solving process, this may result in a huge implication graph. This paper presents a method to compress the implication graph on-the-fly. Experiments demonstrate that this method is able to reduce the overall memory footprint up to an order of magnitude.", "num_citations": "8\n", "authors": ["1879"]}
{"title": "Proving QBF-hardness in bounded model checking for incomplete designs\n", "abstract": " Bounded Model Checking (BMC) is a major verification technique for finding errors in sequential circuits by unfolding the design iteratively and converting the BMC instances into Boolean satisfiability (SAT) formulas. Here, we consider incomplete designs (i.e. those containing so-called black boxes) where the verification task is to prove unrealizability of a property. A property is called unrealizable by an incomplete design, if there is an error which can not be compensated by any implementation of the black boxes. While 01X-modeling of the unknown behavior of the black boxes yields easy-to-solve SAT problems, the logic of quantified Boolean formulas (QBF) is needed for 01X-hard problems to obtain a more precise modeling. However, QBF-modeling does not guarantee success in proving unrealizability. To this purpose, we introduce the concept of QBF-hardness in this paper, a classification of problems for\u00a0\u2026", "num_citations": "8\n", "authors": ["1879"]}
{"title": "Identification of critical variables using an FPGA-based fault injection framework\n", "abstract": " The shrinking nanometer technologies of modern microprocessors and the aggressive supply voltage down-scaling drastically increase the risk of soft errors. In order to cope with this risk efficiently, selective hardware and software protection schemes are applied. In this paper, we propose an FPGA-based fault injection framework which is able to identify the most critical registers of an entire microprocessor. Further-more, our framework identifies critical variables in the source code of an arbitrary application running in its native environment. We verify the feasibility and relevance of our approach by implementing a lightweight and efficient error correction mechanism protecting only the most critical parts of the system. Experimental results with state estimation applications demonstrate a significantly reduced number of critical calculation errors caused by faults injected into the processor.", "num_citations": "8\n", "authors": ["1879"]}
{"title": "Delta-IDDQ testing of resistive short defects\n", "abstract": " This paper addresses the efficiency of I DDQ  and more specifically Delta- I DDQ  testing when using a realistic short defect model that properly considers the relation between the resistance of the short and its detectability. The results clearly show that the Delta-I DDQ  approach covers a large number of resistive shorts missed by conventional logic testing, requiring only a relatively small vector set. In addition a significant number of defects which are proven to be undetectable by logic testing but may deteriorate and result in reliability failures are detected. The Delta- I DDQ  threshold and thus the equipment sensitivity is shown to be critical for the test quality. Furthermore, the validity of the traditional I DDQ  fault models when considering resistive short defects is found to be limited. For instance, the use of the fault-free next-state function for sequential I DDQ  fault simulation is shown to result in a wrong classification\u00a0\u2026", "num_citations": "8\n", "authors": ["1879"]}
{"title": "A model for transient faults in logic circuits\n", "abstract": " Transient (soft) faults due to particle strikes and other environmental and manufacturing effects are a frequent cause of failure in ICs. We propose a general, technology-independent model called single transient fault (STF) model to represent transient faults and errors in logic circuits. It is defined in terms of a temporary stuck-at fault and its associated circuit state. STFs can be used to estimate the transient error probability perr of a circuit\u2019s nodes, as well as various measures of reliability and error tolerance. We demonstrate the use of STFs with combinational and sequential logic circuits, including several types of adders. Some other applications of STFs are also briefly considered.", "num_citations": "8\n", "authors": ["1879"]}
{"title": "Analyzing the memory effect of resistive open in CMOS random logic\n", "abstract": " This paper analyzes the electrical behaviour of resistive opens as a function of its unpredictable resistance. It is demonstrated that the electrical behaviour depends on the value of the open resistance. It is also shown that, due to the memory effect detection of the open by a given vector Ti depends on all the vectors that have been applied to the circuit before Ti. An electrical analysis of this memory effect is presented", "num_citations": "8\n", "authors": ["1879"]}
{"title": "Exact computation of maximally dominating faults and its application to n-detection tests for full-scan circuits\n", "abstract": " The size of an n-detection test set increases approximately linearly with n. This increase in size may be too fast when an upper bound on test set size must be satisfied. A test generation method is proposed for obtaining a more gradual increase in the sizes of n-detection test sets, while still ensuring that every additional test would be useful in improving the test set quality. The method is based on the use of fault-dominance relations to identify a small subset of faults (called maximally dominating faults) whose numbers of detections are likely to have a high impact on the defect coverage of the test set. Structural analysis obtains a superset of the maximally dominating fault set. A method is proposed for determining exact sets of maximally dominating faults. New types of n-detection test sets are based on the approximate and exact sets of maximally dominating faults. The test sets are called (n,n2)-detection test sets and\u00a0\u2026", "num_citations": "8\n", "authors": ["1879"]}
{"title": "ERMM: An Engineering Requirements Management Method\n", "abstract": " Automotive product development is a lengthy and complex process. There exists a large body of various requirements, standards, and regulations, which need to be followed by all engineering activities throughout the entire vehicle development process. The underlying relationships between these requirements are very complicated. Although most of engineering requirements can be found in various engineering databases, it is the lack of the underlying relationship between the requirements and their association with the design that makes it extremely difficult for even experienced engineers to follow the requirements in their dayto-day work. This paper introduces an Engineering Requirements Management Method (ERMM) that captures these interrelationships and associations using a matrix-based representation. A case study with a real automotive component is also presented.", "num_citations": "8\n", "authors": ["1879"]}
{"title": "Application of linearly transformed BDDs in sequential verification\n", "abstract": " The computation of the set of reachable states is the key problem of many applications in sequential verification. Binary Decision Diagrams (BDDs) are extensively used in this domain, but tend to blow up for larger instances. To increase the computational power of BDDs, linearly transformed BDDS (LTBDDs) have been proposed. In this paper we show how this concept can be incorporated into the sequential verification domain by restricting dynamic reordering in a way that the relational product can still be carried out efficiently. Experimental results are given to show the efficiency of our approach.", "num_citations": "8\n", "authors": ["1879"]}
{"title": "PEDSS: A Product Engineering Decision Support System\n", "abstract": " Automotive vehicle body structure design is a long and complex design process. It involves iterations of design modifications, analysis, validation, and confirmation. It is time consuming and costly. In order to bring better and more affordable vehicles to the consumers, the auto-industry is seeking ways to reduce the vehicle cycle time and, at the same time, improve vehicle quality. One approach is to maximize the reuse of the engineering knowledge and make smart engineering decisions early. To assist engineers making decisions in the early design cycle, a Ford team has been working on the development of an intelligent vehicle Product Engineering Decision Support System called PEDSS. PEDSS is a knowledge based design tool that performs trade-off studies among various performance requirements, design specifications, package and manufacturing constraints, serviceability, and cost. It is developed using\u00a0\u2026", "num_citations": "8\n", "authors": ["1879"]}
{"title": "Specialized hardware for implementation of evolutionary algorithms\n", "abstract": " Evolutionary Algorithms (EAs) are getting more and more popular and many successful applications of these principles have been reported. One of the major drawbacks of these approaches in general is that they are often not competitive with respect to runtime in comparison to other methods. A natural way to speed up these algorithms and to handle large problem instances are parallel implementations of EAs on parallel hardware.We present a dynamically reconfigurable Multiprocessor System (MPS). Small RISC type CPUs, the so called Processor Nodes (PNs), are the basic computing units of the system. The communication channels between the PNs can dynamically be switched by a Field Programmable Interconnection Device (FPID), realizing a crosspoint switch. The FPID is controlled by a seperated Communication Processor (CP). Up to 9 PNs fit onto one carrier board, which is a long PC ISA card. A\u00a0\u2026", "num_citations": "8\n", "authors": ["1879"]}
{"title": "Distance driven finite state machine traversal\n", "abstract": " Symbolic techniques have revolutionized reachability analysis in the last years. Extending their applicability to handle large, industrial designs is a key issue, involving the need to focus on memory consumption for BDD representation as well as time consumption to perform symbolic traversals of Finite State Machines (FSMs). We address the problem of reachability analysis for large FSMs, introducing a novel technique that performs reachability analysis using a sequence of \u201cdistance driven\u201d partial traversals based on dynamically chosen prunings of the transition relation. Experiments are given to demonstrate the efficiency and robustness of our approach: We succeed in completing reachability problems with significantly smaller memory requirements and improved time performance.", "num_citations": "8\n", "authors": ["1879"]}
{"title": "Exact minimisation of Kronecker expressions for symmetric functions\n", "abstract": " In the paper, an algorithm for the exact minimisation of Kronecker expressions (KROs) for totally symmetric functions is presented. KROs are a class of AND/EXOR forms closely related to ordered Kronecker functional decision diagrams (OKFDDs). This close relation is used to obtain a polynomial time minimisation algorithm. A generalisation to partially symmetric functions is investigated. Experimental results in comparison to previously published methods are given to show the efficiency of the approach.", "num_citations": "8\n", "authors": ["1879"]}