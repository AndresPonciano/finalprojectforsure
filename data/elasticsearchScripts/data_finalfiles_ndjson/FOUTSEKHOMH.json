{"title": "Why do automated builds break? an empirical study\n", "abstract": " To detect integration errors as quickly as possible, organizations use automated build systems. Such systems ensure that (1) the developers are able to integrate their parts into an executable whole, (2) the testers are able to test the built system, (3) and the release engineers are able to leverage the generated build to produce the upcoming release. The flipside of automated builds is that any incorrect change can break the build, and hence testing and releasing, and (even worse) block other developers from continuing their work, delaying the project even further. To measure the impact of such build breakage, this empirical study analyzes 3,214 builds produced in a large software company over a period of 6 months. We found a high ratio of build breakage (17.9%), and also quantified the cost of such build breakage as more than 336.18 man-hours. Interviews with 28 software engineers from the company helped to\u00a0\u2026", "num_citations": "74\n", "authors": ["191"]}
{"title": "Stack overflow: a code laundering platform?\n", "abstract": " Developers use Question and Answer (Q&A) websites to exchange knowledge and expertise. Stack Overflow is a popular Q&A website where developers discuss coding problems and share code examples. Although all Stack Overflow posts are free to access, code examples on Stack Overflow are governed by the Creative Commons Attribute-ShareAlike 3.0 Unported license that developers should obey when reusing code from Stack Overflow or posting code to Stack Overflow. In this paper, we conduct a case study with 399 Android apps, to investigate whether developers respect license terms when reusing code from Stack Overflow posts (and the other way around). We found 232 code snippets in 62 Android apps from our dataset that were potentially reused from Stack Overflow, and 1,226 Stack Overflow posts containing code examples that are clones of code released in 68 Android apps, suggesting that\u00a0\u2026", "num_citations": "61\n", "authors": ["191"]}
{"title": "On testing machine learning programs\n", "abstract": " Nowadays, we are witnessing a wide adoption of Machine learning (ML) models in many software systems. They are even being tested in safety-critical systems, thanks to recent breakthroughs in deep learning and reinforcement learning. Many people are now interacting with systems based on ML every day, e.g., voice recognition systems used by virtual personal assistants like Amazon Alexa or Google Home. As the field of ML continues to grow, we are likely to witness transformative advances in a wide range of areas, from finance, energy, to health and transportation. Given this growing importance of ML-based systems in our daily life, it is becoming utterly important to ensure their reliability. Recently, software researchers have started adapting concepts from the software testing domain (e.g., code coverage, mutation testing, or property-based testing) to help ML engineers detect and correct faults in ML\u00a0\u2026", "num_citations": "52\n", "authors": ["191"]}
{"title": "Enforcing security in Internet of Things frameworks: A systematic literature review\n", "abstract": " With the rise of the Internet of Things (IoT) technology, the number of IoT devices/sensors has increased significantly. It is anticipated that large-scale sensor-based systems will prevail in our societies, calling for novel methodologies to design and operate those new systems. To support the computational demand of real-time delay-sensitive applications of largely distributed IoT devices/sensors, the Cloud is migrating to the edge of the network where resources such as routers, switches, and gateways are being virtualized.The open structural design of IoT architecture and the extensive usage of the paradigm itself cause to encounter conventional security issues for the existing networking technologies. Moreover, cooperation generates challenges as new security challenges can disrupt the systems\u2019 regular functionalities and operations. Furthermore, the commercialization of the IoT has led to several public security\u00a0\u2026", "num_citations": "49\n", "authors": ["191"]}
{"title": "An empirical study of code smells in javascript projects\n", "abstract": " JavaScript is a powerful scripting programming language that has gained a lot of attention this past decade. Initially used exclusively for client-side web development, it has evolved to become one of the most popular programming languages, with developers now using it for both client-side and server-side application development. Similar to applications written in other programming languages, JavaScript applications contain code smells, which are poor design choices that can negatively impact the quality of an application. In this paper, we investigate code smells in JavaScript server-side applications with the aim to understand how they impact the fault-proneness of applications. We detect 12 types of code smells in 537 releases of five popular JavaScript applications (i.e., express, grunt, bower, less.js, and request) and perform survival analysis, comparing the time until a fault occurrence, in files containing code\u00a0\u2026", "num_citations": "46\n", "authors": ["191"]}
{"title": "Task scheduling in big data platforms: a systematic literature review\n", "abstract": " Context: Hadoop, Spark, Storm, and Mesos are very well known frameworks in both research and industrial communities that allow expressing and processing distributed computations on massive amounts of data. Multiple scheduling algorithms have been proposed to ensure that short interactive jobs, large batch jobs, and guaranteed-capacity production jobs running on these frameworks can deliver results quickly while maintaining a high throughput. However, only a few works have examined the effectiveness of these algorithms.Objective: The Evidence-based Software Engineering (EBSE) paradigm and its core tool, i.e., the Systematic Literature Review (SLR), have been introduced to the Software Engineering community in 2004 to help researchers systematically and objectively gather and aggregate research evidences about different topics. In this paper, we conduct a SLR of task scheduling algorithms that\u00a0\u2026", "num_citations": "36\n", "authors": ["191"]}
{"title": "Supplementary bug fixes vs. re-opened bugs\n", "abstract": " A typical bug fixing cycle involves the reporting of a bug, the triaging of the report, the production and verification of a fix, and the closing of the bug. However, previous work has studied two phenomena where more than one fix are associated with the same bug report. The first one is the case where developers re-open a previously fixed bug in the bug repository (sometimes even multiple times) to provide a new bug fix that replace a previous fix, whereas the second one is the case where multiple commits in the version control system contribute to the same bug report (\"supplementary bug fixes\"). Even though both phenomena seem related, they have never been studied together, i.e., are supplementary fixes a subset of re-opened bugs or the other way around? This paper investigates the interplay between both phenomena in five open source software projects: Mozilla, Net beans, Eclipse JDT Core, Eclipse\u00a0\u2026", "num_citations": "32\n", "authors": ["191"]}
{"title": "Predicting scheduling failures in the cloud: A case study with google clusters and hadoop on amazon EMR\n", "abstract": " Cloud Computing has emerged as a key technology to deliver and manage computing, platform, and software services over the Internet. Task scheduling algorithms play an important role in the efficiency of cloud computing services as they aim to reduce the turnaround time of tasks and improve resource utilization. Several task scheduling algorithms have been proposed in the literature for cloud computing systems, the majority relying on the computational complexity of tasks and the distribution of resources. However, several tasks scheduled following these algorithms still fail because of unforeseen changes in the cloud environments. In this paper, using tasks execution and resource utilization data extracted from the execution traces of real world applications at Google, we explore the possibility of predicting the scheduling outcome of a task using statistical models. If we can successfully predict tasks failures, we\u00a0\u2026", "num_citations": "23\n", "authors": ["191"]}
{"title": "On the detection of licenses violations in the android ecosystem\n", "abstract": " Mobile applications (apps) developers often reuse code from existing libraries and frameworks in order to reduce development costs. However, these libraries and frameworks are governed by licenses to which developers must comply. A failure to comply with a license is likely to result in penalties and fines. In this paper, we analyse the licenses of 857 mobile apps from the F-droid market with the aim to understand the types of licenses that are mostly used by developers of open-source mobile apps and how these licenses evolve over time. We also investigate licenses violations and the evolution of these violations over time. Results show that developers of open-source mobile apps mostly use GPL and Apache licenses. We found licenses violations in 17 out of 857 apps, and 7 apps still had violations in their latest release at the time of this study. We also observed that many files are not licensed in their first\u00a0\u2026", "num_citations": "19\n", "authors": ["191"]}
{"title": "A dynamic and failure-aware task scheduling framework for hadoop\n", "abstract": " Hadoop has become a popular framework for processing data-intensive applications in cloud environments. A core constituent of Hadoop is the scheduler, which is responsible for scheduling and monitoring the jobs and tasks, and rescheduling them in case of failures. Although fault-tolerance mechanisms have been proposed for Hadoop, the performance of Hadoop can be significantly impacted by unforeseen events in the cloud environment. In this paper, we introduce a dynamic and failure-aware framework that can be integrated within Hadoop scheduler and adjust the scheduling decisions based on collected information about the cloud environment. Our framework relies on predictions made by machine learning algorithms and scheduling policies generated by a Markovian Decision Process (MDP), to adjust its scheduling decisions on the fly. Instead of the fixed heartbeat-based failure detection commonly\u00a0\u2026", "num_citations": "16\n", "authors": ["191"]}
{"title": "Factors impacting rapid releases: an industrial case study\n", "abstract": " Context: Software release teams try to reduce the time needed for the transit of features or bug fixes from the development environment to the production, crossing all the quality gates. However, little is known about the factors that influence the time-to-production and how they might be controlled in order to speed up the release cycles.Goal: This paper examines step by step the release process of an industrial software organization aiming to identify factors that have a significant impact on the lead time and outcomes of the software releases.Method: Over 14 months of release data have been analyzed (246 releases from the isolated source code branches to the production environment).Results: We discuss three dimensions under which a series of factors could be addressed: technical, organizational, and interactional. We present our findings in terms of implications for release process improvements.Conclusions\u00a0\u2026", "num_citations": "16\n", "authors": ["191"]}
{"title": "The open-closed principle of modern machine learning frameworks\n", "abstract": " Recent advances in computing technologies and the availability of huge volumes of data have sparked a new machine learning (ML) revolution, where almost every day a new headline touts the demise of human experts by ML models on some task. Open source software development is rumoured to play a significant role in this revolution, with both academics and large corporations such as Google and Microsoft releasing their ML frameworks under an open source license. This paper takes a step back to examine and understand the role of open source development in modern ML, by examining the growth of the open source ML ecosystem on GitHub, its actors, and the adoption of frameworks over time. By mining LinkedIn and Google Scholar profiles, we also examine driving factors behind this growth (paid vs. voluntary contributors), as well as the major players who promote its democratization (companies vs\u00a0\u2026", "num_citations": "15\n", "authors": ["191"]}
{"title": "Broadcast vs. unicast review technology: Does it matter?\n", "abstract": " Code review is the process of having other team members examine changes to a software system in order to evaluate their technical content and quality. Over the years, multiple tools have been proposed to help software developers conduct and manage code reviews. Some software organizations have been migrating from broadcast review technology to a more advanced unicast review approach such as Jira, but it is unclear if these unicast review technology leads to better code reviews. This paper empirically studies review data of five Apache projects that switched from broadcast based code review to unicast based, to understand the impact of review technology on review effectiveness and quality. Results suggest that broadcast based review is twice faster than review done with unicast based review technology. However, unicast's review quality seems to be better than that of the broadcast based. Our findings\u00a0\u2026", "num_citations": "15\n", "authors": ["191"]}
{"title": "A large-scale empirical study of code smells in JavaScript projects\n", "abstract": " JavaScript is a powerful scripting programming language that has gained a lot of attention this past decade. Initially used exclusively for client-side web development, it has evolved to become one of the most popular programming languages, with developers now using it for both client-side and server-side application development. Similar to applications written in other programming languages, JavaScript applications contain code smells, which are poor design choices that can negatively impact the quality of an application. In this paper, we perform a large-scale study of JavaScript code smells in server-side and client-side applications, with the aim to understand how they impact the fault-proneness of applications, and how they are evolved by the developers of the applications. We detect 12 types of code smells in 1807 releases of 15 popular JavaScript applications (i.e., express, grunt, bower, less.js\u00a0\u2026", "num_citations": "14\n", "authors": ["191"]}
{"title": "An empirical study of the impact of cloud patterns on quality of service (qos)\n", "abstract": " Cloud patterns are described as good solutions to recurring design problems in a cloud context. These patterns are often inherited from Service Oriented Architectures or Object Oriented Architectures where they are considered good practices. However, there is a lack of studies that assess the benefits of these patterns for cloud applications. In this paper, we conduct an empirical study on a Restful application deployed in the cloud, to investigate the individual and the combined impact of three cloud patterns (i.e., Local Database proxy, Local Sharding-Based Router and Priority Queue Patterns) on Quality of Service (QoS). We measure the QoS using the application's response time, average, and maximum number of requests processed per seconds. Results show that cloud patterns doesn't always improve the response time of an application. In the case of the Local Database proxy pattern, the choice of algorithm\u00a0\u2026", "num_citations": "14\n", "authors": ["191"]}
{"title": "Experience report: An empirical study of API failures in OpenStack cloud environments\n", "abstract": " Stories about service outages in cloud environments have been making the headlines recently. In many cases, the reliability of cloud infrastructure Application Programming Interfaces (APIs) were at fault. Hence, understanding the factors affecting the reliability of these APIs is important to improve the availability of cloud services. In this study, we mined bugs of 25 modules within the 5 most important OpenStack APIs to understand API failures and characteristics. Our results show that in OpenStack, only one third of all API-related changes are due to fixing failures, with 7% of all fixes even changing the API interface, potentially breaking clients. Through qualitative analysis of 230 sampled API failures we observed that the majority of API related failures are due to small programming faults. Fortunately, the subject, message and stack trace as well as reply lag between comments included in these failures' bug reports\u00a0\u2026", "num_citations": "13\n", "authors": ["191"]}
{"title": "Why reinventing the wheels? An empirical study on library reuse and re-implementation\n", "abstract": " Nowadays, with the rapid growth of open source software (OSS), library reuse becomes more and more popular since a large amount of third- party libraries are available to download and reuse. A deeper understanding on why developers reuse a library (i.e., replacing self-implemented code with an external library) or re-implement a library (i.e., replacing an imported external library with self-implemented code) could help researchers better understand the factors that developers are concerned with when reusing code. This understanding can then be used to improve existing libraries and API recommendation tools for researchers and practitioners by using the developers concerns identified in this study as design criteria. In this work, we investigated the reasons behind library reuse and re-implementation. To achieve this goal, we first crawled data from two popular sources, F-Droid and GitHub. Then\u00a0\u2026", "num_citations": "12\n", "authors": ["191"]}
{"title": "ATLAS: An adaptive failure-aware scheduler for hadoop\n", "abstract": " Hadoop has become the de facto standard for processing large data in today's cloud environment. The performance of Hadoop in the cloud has a direct impact on many important applications ranging from web analytic, web indexing, image and document processing to high-performance scientific computing. However, because of the scale, complexity and dynamic nature of the cloud, failures are common and these failures often impact the performance of jobs running in Hadoop. Although Hadoop possesses built-in failure detection and recovery mechanisms, several scheduled jobs still fail because of unforeseen events in the cloud environment. A single task failure can cause the failure of the whole job and unpredictable job running times. In this paper, we propose ATLAS (AdapTive faiLure-Aware Scheduler), a new scheduler for Hadoop that can adapt its scheduling decisions to events occurring in the cloud\u00a0\u2026", "num_citations": "12\n", "authors": ["191"]}
{"title": "An empirical study of patch uplift in rapid release development pipelines\n", "abstract": " In rapid release development processes, patches that fix critical issues, or implement high-value features are often promoted directly from the development channel to a stabilization channel, potentially skipping one or more stabilization channels. This practice is called patch uplift. Patch uplift is risky, because patches that are rushed through the stabilization phase can end up introducing regressions in the code. This paper examines patch uplift operations at Mozilla, with the aim to identify the characteristics of the uplifted patches that did not effectively fix the targeted problem and that introduced regressions. Through statistical and manual analyses, a series of problems were investigated, including the reasons behind patch uplift decisions, the root causes of ineffective uplifts, the characteristics of uplifted patches that introduced regressions, and whether these regressions can be prevented. Additionally, three\u00a0\u2026", "num_citations": "11\n", "authors": ["191"]}
{"title": "DeepEvolution: A Search-Based Testing Approach for Deep Neural Networks\n", "abstract": " The increasing inclusion of Deep Learning (DL) models in safety-critical systems such as autonomous vehicles have led to the development of multiple model-based DL testing techniques. One common denominator of these testing techniques is the automated generation of test cases, e.g., new inputs transformed from the original training data with the aim to optimize some test adequacy criteria. So far, the effectiveness of these approaches has been hindered by their reliance on random fuzzing or transformations that do not always produce test cases with a good diversity. To overcome these limitations, we propose, DeepEvolution, a novel search-based approach for testing DL models that relies on metaheuristics to ensure a maximum diversity in generated test cases. We assess the effectiveness of DeepEvolution in testing computer-vision DL models and found that it significantly increases the neuronal coverage\u00a0\u2026", "num_citations": "11\n", "authors": ["191"]}
{"title": "Squad: Software quality understanding through the analysis of design\n", "abstract": " Object-oriented software quality models usually use metrics of classes and of relationships among classes to assess the quality of systems. However, software quality does not depend on classes solely: it also depends on the organization of classes, i.e., their design. Our thesis is that it is possible to understand how the design of systems affects their quality and to build quality models that take into account various design styles, in particular design patterns, antipatterns, and code smells. To demonstrate our thesis, we first analyze how playing roles in design patterns, antipatterns, and code smells impacts quality; specifically change-proneness, fault-proneness, and maintenance costs. Second, we build quality models and apply and validate them on open-source and industrial object-oriented systems to show that they allow a more precise evaluation of the quality than traditional models,like Bansiya et al.'s QMOOD.", "num_citations": "11\n", "authors": ["191"]}
{"title": "The state of practice on virtual reality (vr) applications: An exploratory study on github and stack overflow\n", "abstract": " Virtual Reality (VR) is a computer technology that holds the promise of revolutionizing the way we live. The release in 2016 of new-generation headsets from Facebook-owned Oculus and HTC has renewed the interest in that technology. Thousands of VR applications have been developed over the past years, but most software developers lack formal training on this technology. In this paper, we propose descriptive information on the state of practice of VR applications' development to understand the level of maturity of this new technology from the perspective of Software Engineering (SE). To do so, we focused on the analysis of 320 VR open source projects from Github to determine which are the most popular languages and engines used in VR projects, and evaluate the quality of the projects from a software metric perspective. To get further insights on VR development, we also manually analyzed nearly 300\u00a0\u2026", "num_citations": "10\n", "authors": ["191"]}
{"title": "Understanding the impact of cloud patterns on performance and energy consumption\n", "abstract": " Cloud patterns are abstract solutions to recurrent design problems in the cloud. Previous work has shown that these patterns can improve the Quality of Service (QoS) of cloud applications but their impact on energy consumption is still unknown. In this work, we conduct an empirical study on two multi-processing and multi-threaded applications deployed in the cloud, to investigate the individual and the combined impact of six cloud patterns (Local Database Proxy, Local Sharding Based Router, Priority Queue, Competing Consumers, Gatekeeper and Pipes and Filters) on the energy consumption. We measure the energy consumption using Power-API; an application programming interface (API) written in Java to monitor the energy consumed at the process-level. Results show that cloud patterns can effectively reduce the energy consumption of a cloud-based application, but not in all cases. In general, there appear\u00a0\u2026", "num_citations": "10\n", "authors": ["191"]}
{"title": "On improving the dependability of cloud applications with fault-tolerance\n", "abstract": " Cloud computing is an increasingly popular paradigm that allows individuals and enterprises to provision and deploy software applications over the Internet. Customers can lease services provided by these\" cloud\" applications (aka cloud apps), ramping up or down the capacity as they need and paying only for what they use. Cloud apps are used in about every industry today; from financial, retail, education, and communications, to manufacturing, utilities and transportation. Forrester Research predicts that cloud apps sales will account for more than 16% of the total software market by 2016. However, cloud apps dependability is still a major issue for both providers and users. Failures of cloud apps generally result in big economic losses as core business activities now rely on them. In this position paper we discuss the current state of the dependability of cloud apps and advocate for the use of fault-tolerance\u00a0\u2026", "num_citations": "9\n", "authors": ["191"]}
{"title": "Kubernetes or openShift? Which technology best suits eclipse hono IoT deployments\n", "abstract": " New verticals within the Internet of Things paradigm, i.e., smart cities, industrie 4.0, etc., require specific platform(s) to allow different components to communicate. The value of the IoT systems often correlates directly with the ability of those platforms to connect different devices efficiently and integrate them into higher-level solutions. Eclipse Hono allows the provisioning of remote service interfaces for connecting devices to a back-end and interacts with them uniformly regardless of their types and communication protocols. Currently, there is a variety of possibilities for using Hono in production; it can be deployed on Kubernetes, OpenShift or Docker Swarms. However, these deployments decisions have important performance implications that the developers are not often aware of. In this paper, we step up loads in Kubernetes and OpenShift to clear out the performance costs of their deployment scenarios, with the\u00a0\u2026", "num_citations": "8\n", "authors": ["191"]}
{"title": "Infrastructure fault detection and prediction in edge cloud environments\n", "abstract": " As an emerging 5G system component, edge cloud becomes one of the key enablers to provide services such us mission critical, IoT and content delivery applications. However, because of limited fail-over mechanisms in edge clouds, faults (eg, CPU or HDD faults) are highly undesirable. When infrastructure faults occur in edge clouds, they can accumulate and propagate; leading to severe degradation of system and application performance. It is therefore crucial to identify these faults early on and mitigate them. In this paper, we propose a framework to detect and predict several faults at infrastructure-level of edge clouds using supervised machine learning and statistical techniques. The proposed framework is composed of three main components responsible for:(1) data pre-processing,(2) fault detection, and (3) fault prediction. The results show that the framework allows to timely detect and predict several faults\u00a0\u2026", "num_citations": "7\n", "authors": ["191"]}
{"title": "Behind the scenes: developers' perception of multi-language practices\n", "abstract": " Nowadays, it is common to see software development teams combine multiple programming languages when developing a new software system. Most non-trivial software systems are developed using components written in different languages and technologies. This mixed-language programming approach allows developers to reuse existing code and libraries instead of implementing the code from scratch. It also allows them to leverage the strengths and benefits of each language. However, poor integration of different components of multi-language systems can lead to inconsistencies, dependency issues, and even bugs. To help developers make proper use of components and libraries written in different programming languages, researchers and practitioners have formulated multiple catalogs of design practices for multi-language systems. However, there is no evidence that these design practices are\u00a0\u2026", "num_citations": "7\n", "authors": ["191"]}
{"title": "1st international workshop on release engineering (releng 2013)\n", "abstract": " Release engineering deals with all activities in between regular development and actual usage of a software product by the end user, i.e., integration, build, test execution, packaging and delivery of software. Although research on this topic goes back for decades, the increasing heterogeneity and variability of software products along with the recent trend to reduce the release cycle to days or even hours starts to question some of the common beliefs and practices of the field. For example, a project like Mozilla Firefox releases every 6 weeks, generating updates for dozens of existing Firefox versions on 5 desktop, 2 mobile and 3 mobile desktop platforms, each of which for more than 80 locales. In this context, the International Workshop on Release Engineering (RELENG) aims to provide a highly interactive forum for researchers and practitioners to address the challenges of, find solutions for and share experiences\u00a0\u2026", "num_citations": "7\n", "authors": ["191"]}
{"title": "Practitioners\u2019 insights on machine-learning software engineering design patterns: a preliminary study\n", "abstract": " Machine-learning (ML) software engineering design patterns encapsulate reusable solutions to commonly occurring problems within the given contexts of ML systems and software design. These ML patterns should help develop and maintain ML systems and software from the design perspective. However, to the best of our knowledge, there is no study on the practitioners\u2019 insights on the use of ML patterns for design of their ML systems and software. Herein we report the preliminary results of a literature review and a questionnaire-based survey on ML system developers\u2019 state-of-practices with concrete ML patterns.", "num_citations": "6\n", "authors": ["191"]}
{"title": "TFCheck: A TensorFlow Library for Detecting Training Issues in Neural Network Programs\n", "abstract": " The increasing inclusion of Machine Learning (ML) models in safety-critical systems like autonomous cars have led to the development of multiple model-based ML testing techniques. One common denominator of these testing techniques is their assumption that training programs are adequate and bug-free. These techniques only focus on assessing the performance of the constructed model using manually labeled data or automatically generated data. However, their assumptions about the training program are not always true as training programs can contain inconsistencies and bugs. In this paper, we examine training issues in ML programs and propose a catalog of verification routines that can be used to detect the identified issues, automatically. We implemented the routines in a Tensorflow-based library named TFCheck. Using TFCheck, practitioners can detect the aforementioned issues automatically. To\u00a0\u2026", "num_citations": "6\n", "authors": ["191"]}
{"title": "Challenges and issues of mining crash reports\n", "abstract": " Automatic crash reporting tools built in many software systems allow software practitioners to understand the origin of field crashes and help them prioritise field crashes or bugs, locate erroneous files, and/or predict bugs and crash occurrences in subsequent versions of the software systems. In this paper, after illustrating the structure of crash reports in Mozilla, we discuss some techniques for mining information from crash reports, and highlight the challenges and issues of these techniques. Our aim is to raise the awareness of the research community about issues that may bias research results obtained from crash reports and provide some guidelines to address certain challenges related to mining crash reports.", "num_citations": "6\n", "authors": ["191"]}
{"title": "Machine Learning Architecture and Design Patterns\n", "abstract": " Researchers and practitioners studying best practices strive to design Machine Learning (ML) application systems and software that address software complexity and quality issues. Such design practices are often formalized as architecture and design patterns by encapsulating reusable solutions to common problems within given contexts. In this paper, software-engineering architecture and design (anti-) patterns for ML application systems are analyzed to bridge the gap between traditional software systems and ML application systems with respect to architecture and design. Specifically, a systematic literature review confirms that ML application systems are popular due to the promotion of artificial intelligence. We identified 32 scholarly documents and 48 gray documents out of which 38 documents discuss 33 patterns: 12 architecture patterns, 13 design patterns, and 8 anti-patterns. Additionally, a survey of developers reveals that there are 7 major architecture patterns and 5 major design patterns. Then the relationships among patterns are identified in a pattern map.", "num_citations": "5\n", "authors": ["191"]}
{"title": "How green are cloud patterns?\n", "abstract": " Cloud Patterns are abstract solutions to recurrent design problems in the cloud. Previous work has shown that these patterns can improve the Quality of Service (QoS) of cloud applications but their impact on energy consumption is still unknown. Yet, energy consumption is the biggest challenge that cloud computing systems (the backbone of today's high-tech economy) face today. In fact, 10% of the world's electricity is now being consumed by servers, laptops, tablets and smartphones. Energy consumption has complex dependencies on the hardware platform, and the multiple software layers. The hardware, its firmware, the operating system, and the various software components used by a cloud application, all contribute to determining the energy footprint. Hence, even though increasing a data center efficiency will eventually improve energy efficiency, the internal design of cloud-based applications can be\u00a0\u2026", "num_citations": "5\n", "authors": ["191"]}
{"title": "An Empirical Study of Highly Impactful Bugs in Mozilla Projects\n", "abstract": " Bug triaging is the process that consists in screening and prioritising bugs to allow a software organisation to focus its limited resources on bugs with high impact on software quality. In a previous work, we proposed an entropy-based crash triaging approach that can help software organisations identify crash-types that affect a large user base with high frequency. We refer to bugs associated to these crash-types as highly-impactful bugs. The proposed triaging approach can identify highly-impactful bugs only after they have led to crashes in the field for a certain period of time. Therefore, to reduce the impact of highly-impactful bugs on user perceived quality, an early identification of these bugs is necessary. In this paper, we examine the characteristics of highly-impactful bugs in Mozilla Firefox and Fennec for Android, and propose statistical models to help software organisations predict them early on before they\u00a0\u2026", "num_citations": "5\n", "authors": ["191"]}
{"title": "Patterns and quality of object-oriented software systems\n", "abstract": " Maintenance costs during the past decades have reached more than 70% of the overall costs of object-oriented systems, because of many factors, such as changing software environments, changing users' requirements, and the overall quality of systems. One factor on which we have a control is the quality of systems. Many object-oriented software quality models have been introduced in the literature to help assess and control quality. However, these models usually use metrics of classes (such as number of methods) or of relationships between classes (for example coupling) to measure internal attributes of systems. Yet, the quality of object-oriented systems does not depend on classes' metrics solely: it also depends on the organisation of classes, i.e. the system design that concretely manifests itself through design styles, such as design patterns and antipatterns.  In this dissertation, we propose the method DEQUALITE to systematically build quality models that take into account the internal attributes of the systems (through metrics) but also their design (through design patterns and antipatterns). This method uses a machine learning approach based on Bayesian Belief Networks and builds on the results of a series of experiments aimed at evaluating the impact of design patterns and antipatterns on the quality of systems. These experiments, performed on 9 large object-oriented open source systems enable us to draw the following conclusions:  \u2022 Counter-intuitively, design patterns do not always improve the quality of systems; tangled implementations of design patterns for example significantly affect the structure of classes and negatively\u00a0\u2026", "num_citations": "5\n", "authors": ["191"]}
{"title": "A large scale empirical study of the impact of spaghetti code and blob anti-patterns on program comprehension\n", "abstract": " ContextSeveral studies investigated the impact of anti-patterns (i.e., \u201cpoor\u201d solutions to recurring design problems) during maintenance activities and reported that anti-patterns significantly affect the developers\u2019 effort required to edit files. However, before developers edit files, they must understand the source code of the systems. This source code must be easy to understand by developers.ObjectiveIn this work, we provide a complete assessment of the impact of two instances of two anti-patterns, Blob or Spaghetti Code, on program comprehension.MethodWe analyze the impact of these two anti-patterns through three empirical studies conducted at Polytechnique Montr\u00e9 al (Canada) with 24 participants; at Carlton University (Canada) with 30 participants; and at University Basilicata (Italy) with 79 participants.ResultsWe collect data from 372 tasks obtained thanks to 133 different participants from the three\u00a0\u2026", "num_citations": "4\n", "authors": ["191"]}
{"title": "SIGMA: Strengthening IDS with GAN and Metaheuristics Attacks\n", "abstract": " An Intrusion Detection System (IDS) is a key cybersecurity tool for network administrators as it identifies malicious traffic and cyberattacks. With the recent successes of machine learning techniques such as deep learning, more and more IDS are now using machine learning algorithms to detect attacks faster. However, these systems lack robustness when facing previously unseen types of attacks. With the increasing number of new attacks, especially against Internet of Things devices, having a robust IDS able to spot unusual and new attacks becomes necessary. This work explores the possibility of leveraging generative adversarial models to improve the robustness of machine learning based IDS. More specifically, we propose a new method named SIGMA, that leverages adversarial examples to strengthen IDS against new types of attacks. Using Generative Adversarial Networks (GAN) and metaheuristics, SIGMA %Our method consists in generates adversarial examples, iteratively, and uses it to retrain a machine learning-based IDS, until a convergence of the detection rate (i.e. until the detection system is not improving anymore). A round of improvement consists of a generative phase, in which we use GANs and metaheuristics to generate instances ; an evaluation phase in which we calculate the detection rate of those newly generated attacks ; and a training phase, in which we train the IDS with those attacks. We have evaluated the SIGMA method for four standard machine learning classification algorithms acting as IDS, with a combination of GAN and a hybrid local-search and genetic algorithm, to generate new datasets of attacks. Our\u00a0\u2026", "num_citations": "4\n", "authors": ["191"]}
{"title": "State of practices of java native interface\n", "abstract": " The use of the Java Native Interface (JNI) allows taking advantage of the existing libraries written in different programming languages for code reuse, performance, and security. Despite the importance of JNI in development, practices on its usages are not well studied yet. In this paper, we investigated the usage of JNI in 100 open source systems collected from OpenHub and Github, around 8k of source code files combined between Java and C/C++, including the Java class libraries part of the JDK v9. We identified the state of the practice in JNI systems by semi-automatically and manually analyzing the source code.", "num_citations": "4\n", "authors": ["191"]}
{"title": "What Do Practitioners Discuss about IoT and Industry 4.0 Related Technologies? Characterization and Identification of IoT and Industry 4.0 Categories in Stack Overflow Discussions\n", "abstract": " Internet of Things and Industry 4.0\u2013related discussions have become increasingly prevalent on several online Q&A websites in recent years. Analyzing and understanding such discussions could provide practitioners with more insights into various trends in the evolution of topics of interest and help different research communities, including software development and industrial sectors, better understand the needs and challenges facing practitioners as they operate in these fields. We conduct an exploratory study to capture and compare the popularity as well as the effect of the discussion topics on the domain across such communities. We use extracted data from popular online Q&A websites, such as Stack Exchange, and investigate 176,819 posts to investigate what practitioners are asking and looking for. We also use Machine Learning for Language Toolkit (MALLET) based\u2013Latent Dirichlet Allocation (LDA) topic\u00a0\u2026", "num_citations": "3\n", "authors": ["191"]}
{"title": "Are multi-language design smells fault-prone? An empirical study\n", "abstract": " Nowadays, modern applications are developed using components written in different programming languages and technologies. The cost benefits of reuse and the advantages of each programming language are two main incentives behind the proliferation of such systems. However, as the number of languages increases, so do the challenges related to the development and maintenance of these systems. In such situations, developers may introduce design smells (i.e., anti-patterns and code smells) which are symptoms of poor design and implementation choices. Design smells are defined as poor design and coding choices that can negatively impact the quality of a software program despite satisfying functional requirements. Studies on mono-language systems suggest that the presence of design smells may indicate a higher risk of future bugs and affects code comprehension, thus making systems harder to\u00a0\u2026", "num_citations": "3\n", "authors": ["191"]}
{"title": "Analysis of Modern Release Engineering Topics:\u2013A Large-Scale Study using StackOverflow\u2013\n", "abstract": " Release engineers are continuously required to de-liver high-quality software products to the end-user. As a result, modern software companies are proposing new changes in their delivery process that adapt to new technologies such as continuous deployment and Infrastructure-as-Code. However, developers and release engineers still find these practices challenging, and resort to question and answer websites such as StackOverflow to find answers. This paper presents the results of our empirical study on release engineering questions in StackOverflow, to understand the modern release engineering topics of interest and their difficulty. Using topic modeling techniques, we find that (i) developers discuss on a broader range of 38 release engineering topics covering all the six phases of modern release engineering, (ii) the topics Merge Conflict, Branching & Remote Upstream are more popular, while topics Code\u00a0\u2026", "num_citations": "3\n", "authors": ["191"]}
{"title": "The Scent of Deep Learning Code: An Empirical Study\n", "abstract": " Deep learning practitioners are often interested in improving their model accuracy rather than the interpretability of their models. As a result, deep learning applications are inherently complex in their structures. They also need to continuously evolve in terms of code changes and model updates. Given these confounding factors, there is a great chance of violating the recommended programming practices by the developers in their deep learning applications. In particular, the code quality might be negatively affected due to their drive for the higher model performance. Unfortunately, the code quality of deep learning applications has rarely been studied to date. In this paper, we conduct an empirical study to investigate the distribution of code smells in deep learning applications. To this end, we perform a comparative analysis between deep learning and traditional open-source applications collected from GitHub. We\u00a0\u2026", "num_citations": "3\n", "authors": ["191"]}
{"title": "Software Release Patterns When is it a good time to update a software component?\n", "abstract": " Over the past decade the industry 4.0 witnessed a trend towards an increasing number of software components, dependencies towards third party software components, and software component release cycles. Industry 4.0 teams building software products are more frequently impacted by third party software component updates. Due to this dependency, updating a single third party software component can break an entire software product. Reasons include parallel conflicting updates of third party software components, updating to an unstable version, or updating to a major stable version without an impact analysis. The objective of this paper is to reduce the risk of breaking updates by reviewing software release patterns and proposing update scheduling recommendations.", "num_citations": "3\n", "authors": ["191"]}
{"title": "An empirical study of DLL injection bugs in the Firefox ecosystem\n", "abstract": " DLL injection is a technique used for executing code within the address space of another process by forcing the load of a dynamic-link library. In a software ecosystem, the interactions between the host and third-party software increase the maintenance challenges of the system and may lead to bugs. In this work, we empirically investigate bugs that were caused by third-party DLL injections into the Mozilla Firefox browser. Among the 103 studied DLL injection bugs, we found that 93 bugs (90.3%) led to crashes and 57 bugs (55.3%) were caused by antivirus software. Through a survey with third-party software vendors, we observed that some vendors did not perform any QA with pre-release versions nor intend to use a public API (WebExtensions) but insist on using DLL injection. To reduce DLL injection bugs, host software vendors may strengthen the collaboration with third-party vendors, e.g., build a\u00a0\u2026", "num_citations": "3\n", "authors": ["191"]}
{"title": "Is it Safe to Uplift this Patch?: An Empirical Study on Mozilla Firefox\n", "abstract": " In rapid release development processes, patches that fix critical issues, or implement high-value features are often promoted directly from the development channel to a stabilization channel, potentially skipping one or more stabilization channels. This practice is called patch uplift. Patch uplift is risky, because patches that are rushed through the stabilization phase can end up introducing regressions in the code. This paper examines patch uplift operations at Mozilla, with the aim to identify the characteristics of uplifted patches that introduce regressions. Through statistical and manual analyses, we quantitatively and qualitatively investigate the reasons behind patch uplift decisions and the characteristics of uplifted patches that introduced regressions. Additionally, we interviewed three Mozilla release managers to understand organizational factors that affect patch uplift decisions and outcomes. Results show that\u00a0\u2026", "num_citations": "3\n", "authors": ["191"]}
{"title": "Helping Android Users to Find the Most Efficient Apps\n", "abstract": " Helping Android Users to Find the Most Efficient Apps Page 1 Motivation Initiated Research Solving the App Selection Problem Conclusion Helping Android Users to Find the Most Efficient Apps Rub\u00e9n Saborido, Foutse Khomh SWAT Labs., DGIGL, Polytechnique Montr\u00e9al, Canada Ottawa (Canada), 2017 1 / 32 Page 2 Motivation Initiated Research Solving the App Selection Problem Conclusion Available information in current marketplaces Performance metrics Availability of performance metrics Mobile device marketplaces A category in a marketplace contains many apps, often implementing very similar features. 2 / 32 Page 3 Motivation Initiated Research Solving the App Selection Problem Conclusion Available information in current marketplaces Performance metrics Availability of performance metrics Rating to evaluate the quality of mobile apps 3 / 32 Page 4 Motivation Initiated Research Solving the App in of , , (\u2026", "num_citations": "2\n", "authors": ["191"]}
{"title": "A study of the energy consumption of databases and cloud patterns\n", "abstract": " Nowadays databases have become the backbone of cloud-based applications. Cloud-based applications are used in about every industry today. Despite their popularity and wide adoption, little is still known about the energy footprint of these applications and, in particular, of their databases. Yet, reducing the energy consumption of applications is a major objective for society and will continue to be so in the near to far future. In this paper, we study the energy consumption of three databases used by cloud-based applications: MySQL, PostgreSQL, and MongoDB, through a series of experiments with three cloud-based applications (a RESTful multi-threaded application, DVD Store, and JPetStore). We also study the impact of cloud patterns on the energy consumption because databases in cloud-based applications are often implemented in conjunction with patterns. We measure the energy consumption\u00a0\u2026", "num_citations": "2\n", "authors": ["191"]}
{"title": "Factors impacting software release engineering: A longitudinal study\n", "abstract": " Software release teams try to reduce the time needed for the transit of features or bug fixes from the development environment to the production, crossing all the quality gates. However, little is known about the factors that influence the timeto-production and how they might be controlled in order to speed up the release cycles. This paper examines step by step the release process of an industrial software organization aiming to identify factors that have a significant impact on the Lead Time and outcomes of the software releases. Over 14 months of release data have been analyzed (246 releases from the isolated source code branches to the production environment). We discuss three dimensions under which a series of factors could be addressed: Technical, Organizational, and Interactional. We present our finding in terms of implications for release process improvements.", "num_citations": "2\n", "authors": ["191"]}
{"title": "Short Biography\n", "abstract": " Background I was born in Cameroon. Prior to my Ph. D studies, I received:\u25b6 a Master\u2019s degree in Software Engineering from the National Advanced School of Engineering (Cameroon),\u25b6 a Master\u2019s degree (DEA) in Mathematics from the University of Yaounde I (Cameroon).", "num_citations": "2\n", "authors": ["191"]}
{"title": "Reverse-engineering the literature on design patterns and reverse-engineering\n", "abstract": " Since their inception in 1994, design patterns have been the subject of many papers. In the reverse-engineering community, several authors have proposed approaches to consider design patterns during reverse- and re-engineering. However, it has been recently put forward in the community that it is difficult to compare previous approaches due to the diversity of vocabulary and the lack of a general framework to map and relate these approaches. Consequently, we study 59 papers related to design patterns in the software engineering community at large (1) to identify and define common terms related to design patterns, (2) to identify recurring themes in the papers, and (3) to further characterise approaches for design pattern detection along several categories. Recurring themes allow us to provide the portrait of the \\typical\" paper on design patterns while categories draw the portrait of the \\typical\" approach in design pattern detection. We propose to the community to use a \u00afx vocabulary, to diversify the approaches, and to build a common benchmark to assess the reverse engineering of design patterns.", "num_citations": "2\n", "authors": ["191"]}
{"title": "How to Certify Machine Learning Based Safety-critical Systems? A Systematic Literature Review\n", "abstract": " Context: Machine Learning (ML) has been at the heart of many innovations over the past years. However, including it in so-called 'safety-critical' systems such as automotive or aeronautic has proven to be very challenging, since the shift in paradigm that ML brings completely changes traditional certification approaches. Objective: This paper aims to elucidate challenges related to the certification of ML-based safety-critical systems, as well as the solutions that are proposed in the literature to tackle them, answering the question 'How to Certify Machine Learning Based Safety-critical Systems?'. Method: We conduct a Systematic Literature Review (SLR) of research papers published between 2015 to 2020, covering topics related to the certification of ML systems. In total, we identified 217 papers covering topics considered to be the main pillars of ML certification: Robustness, Uncertainty, Explainability, Verification, Safe Reinforcement Learning, and Direct Certification. We analyzed the main trends and problems of each sub-field and provided summaries of the papers extracted. Results: The SLR results highlighted the enthusiasm of the community for this subject, as well as the lack of diversity in terms of datasets and type of models. It also emphasized the need to further develop connections between academia and industries to deepen the domain study. Finally, it also illustrated the necessity to build connections between the above mention main pillars that are for now mainly studied separately. Conclusion: We highlighted current efforts deployed to enable the certification of ML based software systems, and discuss some future research directions.", "num_citations": "1\n", "authors": ["191"]}
{"title": "Faults in Deep Reinforcement Learning Programs: A Taxonomy and A Detection Approach\n", "abstract": " A growing demand is witnessed in both industry and academia for employing Deep Learning (DL) in various domains to solve real-world problems. Deep Reinforcement Learning (DRL) is the application of DL in the domain of Reinforcement Learning (RL). Like any software systems, DRL applications can fail because of faults in their programs. In this paper, we present the first attempt to categorize faults occurring in DRL programs. We manually analyzed 761 artifacts of DRL programs (from Stack Overflow posts and GitHub issues) developed using well-known DRL frameworks (OpenAI Gym, Dopamine, Keras-rl, Tensorforce) and identified faults reported by developers/users. We labeled and taxonomized the identified faults through several rounds of discussions. The resulting taxonomy is validated using an online survey with 19 developers/researchers. To allow for the automatic detection of faults in DRL programs, we have defined a meta-model of DRL programs and developed DRLinter, a model-based fault detection approach that leverages static analysis and graph transformations. The execution flow of DRLinter consists in parsing a DRL program to generate a model conforming to our meta-model and applying detection rules on the model to identify faults occurrences. The effectiveness of DRLinter is evaluated using 15 synthetic DRLprograms in which we injected faults observed in the analyzed artifacts of the taxonomy. The results show that DRLinter can successfully detect faults in all synthetic faulty programs.", "num_citations": "1\n", "authors": ["191"]}
{"title": "Why are Some Bugs Non-Reproducible?:\u2013An Empirical Investigation using Data Fusion\u2013\n", "abstract": " Software developers attempt to reproduce software bugs to understand their erroneous behaviours and to fix them. Unfortunately, they often fail to reproduce (or fix) them, which leads to faulty, unreliable software systems. However, to date, only a little research has been done to better understand what makes the software bugs non-reproducible. In this paper, we conduct a multimodal study to better understand the non-reproducibility of software bugs. First, we perform an empirical study using 576 non-reproducible bug reports from two popular software systems (Firefox, Eclipse) and identify 11 key factors that might lead a reported bug to non-reproducibility. Second, we conduct a user study involving 13 professional developers where we investigate how the developers cope with non-reproducible bugs. We found that they either close these bugs or solicit for further information, which involves long deliberations and\u00a0\u2026", "num_citations": "1\n", "authors": ["191"]}
{"title": "The Diversity Crisis of Software Engineering for Artificial Intelligence\n", "abstract": " Artificial Intelligence (AI) is experiencing a \"diversity crisis.\"1 Several reports1-3 have shown how the breakthrough of modern AI has not yet been able to improve on existing diversity challenges regarding gender, race, geography, and other factors, neither for the end users of those products nor the companies and organizations building them. Plenty of examples have surfaced in which biased data engineering practices or existing data sets led to incorrect, painful, or sometimes even harmful consequences for unassuming end users.4 The problem is that ruling out such biases is not straightforward due to the sheer number of different bias types.5 To have a chance to eliminate as many biases as possible, most of the experts agree that the teams and organizations building AI products should be made more diverse.1-3 This harkens back to Linus' law6 for open source development (\"given enough eyeballs, all bugs\u00a0\u2026", "num_citations": "1\n", "authors": ["191"]}
{"title": "Multi-language design smells: A backstage perspective\n", "abstract": " Context: Multi-language systems became prevalent with technological advances. Developers opt for the combination of programming languages to build an application. Problem: Software quality is achieved by following good practices and avoiding bad ones. However, most of the practices in the literature are applied to a single programming language and do not consider the interaction between programming languages. Objective: We previously defined a catalog of bad practices ie, design smells related to multi-language systems. This paper aims to provide empirical evidence on the relevance of our catalog and its impact on software quality. Method: We analysed 262 snapshots of nine open source projects to detect occurrences of multi-language design smells. We also extracted information about the developers that contributed to those systems. We plan to perform an open and a closed survey targeting\u00a0\u2026", "num_citations": "1\n", "authors": ["191"]}
{"title": "Just-in-time detection of protection-impacting changes on WordPress and MediaWiki\n", "abstract": " Access control mechanisms based on roles and privileges restrict the access of users to security sensitive resources in a multi-user software system. Unintentional privilege protection changes may occur during the evolution of a system, which may introduce security vulnerabilities, threatening user\u2019s confidential data, and causing other severe problems. In this thesis, we use the Pattern Traversal Flow Analysis technique to identify definite protection differences in WordPress and MediaWiki systems. We analyse the evolution of privilege protections across 211 and 193 releases from respectively WordPress and Mediawiki, and observe that around 60% of commits affect privileges protections in both projects. We refer to these commits as protection-impacting change (PIC) commits. To help developers identify PIC commits justin-time, ie, as soon as they are introduced in the code base, we extract a series of metrics\u00a0\u2026", "num_citations": "1\n", "authors": ["191"]}
{"title": "Patterns for program reverse engineering from the viewpoint of metamodel\n", "abstract": " Reverse engineering tools often define their own metamodels according to their purposes and intended features. These tools and metamodels have advantages that may benefit other metamodels as well as limitations that other metamodels may solve. To guide practitioners (and researchers) in selecting, integrating, and using appropriate tools, we propose a preliminary pattern catalog for program reverse engineering from the program metamodel viewpoint based on our conceptual framework in consideration of both grammarware and modelware approaches. The catalog consists of one metapattern, Transformation to higher abstraction levels, and three concrete patterns, Integrated program reverse engineering, Fact extraction, and Architecture recovery. The intended audience of these patterns is practitioners (and researchers) such as software maintainers who desire to comprehend a program. In addition, these patterns may be helpful for tool developers (and researchers) creating reverse engineering tools.", "num_citations": "1\n", "authors": ["191"]}
{"title": "3rd international workshop on release engineering (RELENG 2015)\n", "abstract": " Release engineering deals with all activities inbetween regular development and actual usage of asoftware product by the end user, i.e., integration, build, testexecution, packaging and delivery of software. Although re-search on this topic goes back for decades, the increasing heterogeneity and variability of software products along withthe recent trend to reduce the release cycle to days or even hoursstarts to question some of the common beliefs and practicesof the field. For example, a project like Mozilla Firefox releasesevery 6 weeks, generating updates for dozens of existing Fire-fox versions on 5 desktop, 2 mobile and 3 mobile desktopplatforms, each of which for more than 80 locales. In this con-text, the International Workshop on Release Engineering(RELENG) aims to provide a highly interactive forum for re-searchers and practitioners to address the challenges of, findsolutions for and share experiences with\u00a0\u2026", "num_citations": "1\n", "authors": ["191"]}
{"title": "DEQUALITE: m\u00e9thode de construction de mod\u00e8les de qualit\u00e9 prenant en compte la conception des syst\u00e8mes\n", "abstract": " La plupart des mod\u00e8les de qualit\u00e9 pr\u00e9sent\u00e9s dans la litt\u00e9rature ou utilis\u00e9s dans l\u2019industrie pour \u00e9valuer les syst\u00e8mes par objets utilisent des m\u00e9triques de classes (nombre de m\u00e9thodes d\u2019une classe par exemple) ou des m\u00e9triques de relations entre classes (couplage entre deux classes par exemple) pour mesurer les attributs internes des syst\u00e8mes. Cependant, la qualit\u00e9 des syst\u00e8mes par objets ne d\u00e9pend pas uniquement de la structure de leurs classes mais aussi de la fa\u00e7on dont celles-ci sont organis\u00e9es, c\u2019est-\u00e0-dire de leur conception. Nous proposons DEQUALITE, une m\u00e9thode de construction de mod\u00e8les de qualit\u00e9 permettant de mesurer la qualit\u00e9 des syst\u00e8mes par objets en prenant en compte non seulement les attributs internes du syst\u00e8me mais aussi sa conception. Notre m\u00e9thode utilise une approche par apprentissage. Elle s\u2019appuie sur une \u00e9tude des patrons de conception pour prendre en compte la conception des syst\u00e8mes. Notre m\u00e9thode permet aussi de combiner des mod\u00e8les de qualit\u00e9 afin d\u2019augmenter la capacit\u00e9 de pr\u00e9diction. Nous illustrons notre m\u00e9thode sur un ensemble de syst\u00e8mes implantant des patrons de conception et sur le mod\u00e8le de qualit\u00e9 QMOOD de Bansiya. Nous discutons les avantages et les inconv\u00e9nients de cette m\u00e9thode et proc\u00e9dons \u00e0 la validation d\u2019un mod\u00e8le de qualit\u00e9 r\u00e9sultant sur un ensemble de syst\u00e8mes. Nous terminons par une discussion sur les avantages et limitations de l\u2019utilisation des patrons de conception pour la construction de mod\u00e8les de qualit\u00e9.----------Abstract: Object-oriented software quality models usually use metrics of classes (such as number of methods) or of relationships between\u00a0\u2026", "num_citations": "1\n", "authors": ["191"]}