{"title": "Feature selection using gravitational search algorithm for biomedical data\n", "abstract": " Analysis of medical data for disease prediction requires efficient feature selection techniques, as the data contains a large number of features. Researchers have used evolutionary computation (EC) techniques like genetic algorithms, particle swarm optimization etc. for FS and have found them to be faster than traditional techniques. We have explored a relatively new EC technique called gravitational search algorithm (GSA) for feature selection in medical datasets. This wrapper based method, that we have employed, using GSA and k-nearest neighbors reduces the number of features by an average of 66% and considerably improves the accuracy of prediction.", "num_citations": "40\n", "authors": ["1232"]}
{"title": "Quality metrics for conceptual models for data warehouse focusing on dimension hierarchies\n", "abstract": " Multidimensional conceptual models have been accepted as the foundation for data warehouse designs. The quality of these models have significant effect on the quality of data warehouse and hence, in turn on the information quality. Few researchers have defined quality attributes for the conceptual models for data warehouse and have also proposed metrics to assess the quality attributes of these models objectively. The objective of this work is to propose candidate metrics to compute the structural complexity of multidimensional model. The main emphasis of this paper will be on the dimension hierarchies in multidimensional model. Though, these hierarchies play very significant role in analysing data at various granularity levels, their use enhances structural complexities of multidimensional model which can affect their understandability and modifiability and in turn maintainability.", "num_citations": "24\n", "authors": ["1232"]}
{"title": "Computer-aided segmentation of liver lesions in CT scans using cascaded convolutional neural networks and genetically optimised classifier\n", "abstract": " Abdominal CT scans have been widely studied and researched by medical professionals in recent years. CT scans have proved effective for the task of detection of liver abnormalities in patients. Computer-aided automatic segmentation of the liver can serve as an elementary step for radiologists to trace anomalies in the liver. In this paper, we have explored deep learning techniques first and foremost for the extraction of liver from the abdominal CT scan and then, consequently, to segment the lesions from a tumour-ridden liver. A cascaded model of convolutional neural networks is used to segment lesions once tumour has been detected in the liver by GA-ANN which has been fed textural liver features using LTEM for its classification procedure. A high DICE index has been obtained of 0.9557 for liver segmentation and 0.6976 for lesion segmentation.", "num_citations": "23\n", "authors": ["1232"]}
{"title": "Validating dimension hierarchy metrics for the understandability of multidimensional models for data warehouse\n", "abstract": " Structural properties including hierarchies have been recognised as important factors influencing quality of a software product. Metrics based on structural properties (structural complexity metrics) have been popularly used to assess the quality attributes like understandability, maintainability, fault-proneness etc. of a software artefact. Although few researchers have considered metrics based on dimension hierarchies to assess the quality of multidimensional models for data warehouse, there are certain aspects of dimension hierarchies like those related to multiple hierarchies, shared dimension hierarchies among various dimensions etc. which have not been considered in the earlier works. In the authors' previous work, they identified the metrics based on these aspects which may contribute towards the structural complexity and in turn the quality of multidimensional models for data warehouse. However, the work\u00a0\u2026", "num_citations": "21\n", "authors": ["1232"]}
{"title": "Complexity metric for multidimensional models for data warehouse\n", "abstract": " Quality of data models for data warehouse has significant effect on the quality of data warehouse. Complexity metrics play significant role in predicting quality attributes of a software artifact. Few researchers have proposed structural complexity metrics for the multidimensional data models for data warehouse which may act as objective indicators of the quality of these models. However, the metrics proposed earlier have not considered the structural complexity due to relationships among various elements present in these models. This paper proposes a complexity metric which considers structural complexity due to relationships among elements present in multidimensional models for data warehouse. The metric is proposed on the basis of Goal Question Metric approach. The practical usefulness of the proposed metric is proved by validating the metric using a practical framework proposed by Kaner. This preliminary\u00a0\u2026", "num_citations": "18\n", "authors": ["1232"]}
{"title": "Trust Aware Recommender Systems: A Survey on Implicit Trust Generation Techniques\n", "abstract": " Development of Web 2.0 enabled users to share information online, which results into an exponential growth of world wide web data. This leads to the so-called information overload problem. Recommender Systems (RS) are intelligent systems, helping on-line users to overcome information overload by providing customized recommendations on various items. In real world, people are willing to take advice and recommendation from their trustworthy friends only. Trust plays a key role in the decision-making process of a person. Incorporation of trust information in RS, results in a new class of recommender systems called trust aware recommender systems (TARS). This paper presents a survey on various implicit trust generation techniques in context of TARS. We have analyzed eight different implicit trust metrics, with respect to various properties of trust proposed by researchers in regard to TARS.", "num_citations": "17\n", "authors": ["1232"]}
{"title": "Trust aware recommender system using swarm intelligence\n", "abstract": " Due to limitations and challenges faced by traditional collaborative filtering-based recommender systems, researchers have been shifting their attention towards using trust information among users while generating recommendations. It is observed that one trust metric may work better for some user and fails to do so in the case of another user. This paper proposes to favor that metric which provides high-quality recommendations for a particular user. For this purpose, weights have been assigned to various trust metrics for each pair of users and optimized iteratively to generate more accurate and personalized recommendations. We have used swarm intelligent techniques namely Bat algorithm and Particle Swarm Optimization for the same. The performance of the approach proposed in this work is evaluated using MovieLens, Epinions, CiaoDVD, and Filmtrust data sets and compared to earlier works generating\u00a0\u2026", "num_citations": "15\n", "authors": ["1232"]}
{"title": "Theoretical and empirical validation of comprehensive complexity metric for multidimensional models for data warehouse\n", "abstract": " Structural complexity metrics have been widely used to assess quality of an artefact. Researchers in past have defined complexity metrics to assess the quality of multidimensional models for data warehouse. These metrics have been defined considering various elements like facts, dimensions, dimension hierarchies etc., but have not taken into account the relationships among these elements of the models. In our previous work, a comprehensive complexity metric for multidimensional models for data warehouse has been proposed which not only considered complexity due to the elements but also structural complexity due to relationships among these elements. However, the proposal lacks theoretical and empirical validation of the metric. Hence, practical utility of the metric could not be established. This paper validates the proposed metric theoretically as well as empirically. The theoretical validation\u00a0\u2026", "num_citations": "15\n", "authors": ["1232"]}
{"title": "Plant Leaf Disease Detection and Classification Using Particle Swarm Optimization\n", "abstract": " The loss of crops due to diseases is a major danger to food security. It is important to develop the requisite infrastructure and tools for the detection of diseases in crops. The opportunity to detect diseases in crops has increased manifolds with the rise in the number of smartphone users and improved network connectivity. In this paper, we provide an approach to detect and classify plant leaf diseases. The methodology involves image acquisition, pre-processing of the images, feature extraction followed by feature selection and finally the classification of plant diseases. A deep convolutional neural network was trained to extract features from the input image. An optimal set of features is selected using Particle Swarm Optimization (PSO) and are classified into 23 different classes, including both healthy and diseased categories. Apropos, by employing this technique, the plant leaf images are classified with an\u00a0\u2026", "num_citations": "13\n", "authors": ["1232"]}
{"title": "An improved collaborative filtering based recommender system using bat algorithm\n", "abstract": " Recommender Systems have proven to be of great aid in dealing with the issue of Information Overload by improving the user experience through quality recommendations. In recent times, heuristic techniques have been employed by researchers in recommender systems along with traditional methods of collaborative and content based filtering. On the same account, in this work a Bat algorithm based heuristic technique has been used to compute the weights of items (features) so as to find better neighbourhood for the active user. We argue and also prove using the results that this technique of giving weights to items using heuristic methods helps in achieving better personalized recommendations. The performance of this system was also compared to that of Artificial Bee Colony based system (ABC). The results indicated that BA performed 6.9% better than ABC in terms of Mean Absolute Error and F1 Score\u00a0\u2026", "num_citations": "13\n", "authors": ["1232"]}
{"title": "Assessment of quality of data warehouse multidimensional model\n", "abstract": " Data warehouses are large repositories designed to enable the knowledge workers to take better and faster decisions. Due to its significance in strategic decisions, there is a need to assure data warehouse quality. One of the factors affecting the data warehouse quality is multidimensional model quality. Although there are some useful guidelines for designing good multidimensional data models, but objective indicators, i.e., metrics are needed to help designers to develop quality multidimensional models. Few researchers have proposed quality metrics for multidimensional models for data warehouse. These metrics need to be theoretically as well as empirically validated in order to prove their practical utility. In this paper, empirical validation using controlled experiment is carried out. We not only evaluate the effect of individual metric but also evaluate the effect of various combinations of metrics on data warehouse\u00a0\u2026", "num_citations": "12\n", "authors": ["1232"]}
{"title": "Gravitational search algorithm in recommendation systems\n", "abstract": " Recommendation Systems have found extensive use in today\u2019s web environment as they improve the overall user experience by providing users with personalized suggestions. Along with the traditional techniques like Collaborative and Content-based filtering, researchers have explored computational intelligence techniques to improve the performance of recommendation systems. In this paper, a similar approach has been taken in the form of applying a heuristic based technique on recommendation systems. The paper proposes a recommendation system based on a less explored nature-inspired technique called Gravitational Search Algorithm. The performance of this system is compared with that of a system using Particle Swarm Optimisation, which is a similar optimisation technique. The results show that Gravitational Search Algorithm excels in improving the accuracy of the recommendation model\u00a0\u2026", "num_citations": "9\n", "authors": ["1232"]}
{"title": "Neural network approach to predict quality of data warehouse multidimensional model\n", "abstract": " Estimating the quality of data warehouse at an early stage is an important task. The quality of data warehouse depends on the data quality and data warehouse multidimensional model. Very little work is done to assess the quality of multidimensional model objectively using metrics. Some statistical techniques like correlation analysis, univariate and multivariate regression techniques, etc. have been used which indicated that these metrics are significantly related to the quality of multidimensional models for data warehouse. However, in context of data warehouse, very little work has been done to predict the multidimensional model quality using machine learning techniques. In this paper, we have used artificial neural network to predict the quality of multidimensional schemas. Here it is shown that ANN is able to successfully model the complex and non linear relationships between the quality metrics and understandability which is one of the quality factors of maintainability of data warehouse multidimensional model.", "num_citations": "8\n", "authors": ["1232"]}
{"title": "Theoretical and empirical validation of coupling metrics for object-oriented data warehouse design\n", "abstract": " The conceptual model of a data warehouse can be used to determine its quality during the early stages of design. Metrics have been proposed in the past to quantify the structural complexity of these models. A majority of these metrics focus on the internal quality attributes of size and complexity. Unfortunately, not many measures have been proposed to assess the magnitude of coupling in the data warehouse multidimensional models. Coupling has a significant impact on the complexity and, in turn, quality of these models. In our previous work, we had put forward measures to determine the scope of inheritance and aggregation coupling between classes present in the object-oriented conceptual model of the data warehouse. The proposed measures take conformed dimensions into account, which is a notable feature of the data warehouse. However, the proposed metrics had not been validated. Therefore\u00a0\u2026", "num_citations": "7\n", "authors": ["1232"]}
{"title": "Using Strong, acquaintance and weak tie strengths for modeling relationships in facebook network\n", "abstract": " Predicting strength of a relationship (also known as Tie Strength Problem) has been a trivial research area amongst sociologists for decades. However, considering the recent trends in internet behavior of people along with the development of so called social web, makes it popular amongst web scientists to work on this as a potential research topic with new perspectives. Real life is a complex social dynamic system comprising individuals starting of either as strong acquaintances or weak acquaintances and move towards strong or weak ties with passage of time. In this paper we validate the existence of varying degree of relationship individuals have on Facebook using unsupervised machine learning techniques like divisive hierarchical clustering and statistical techniques like SSE ; analyzing strength of the boundaries that distinguish them. We have realized this on a feature rich dataset of more than 100\u00a0\u2026", "num_citations": "7\n", "authors": ["1232"]}
{"title": "Real-time geo influence in social networks\n", "abstract": " Exponential burst of real-time information generated through Social Media Networks in recent years, creates a hot ubiquitous platform for research among data scientists. Main area under spotlight in Social Networks Analysis (SNA) is friendship networks, user influence and computation of how deep and how fast the information diffuses. Amidst recent upsurge in Smartphone usage statistics, there is spectacular rise in tagging of feeds and post them with locations due to GPS localizations (Geo-tags and location coordinates of images and news feeds). For the local advertisers and social campaigners, it is vital to carve out phase based user reach models in a particular city/location. In this paper, an algorithm to calculate real-time geo influence of twitter users pertaining to location and time constraints is proposed and necessitate its requirement to meet the vital requisite to find out how fast information is spread by a\u00a0\u2026", "num_citations": "7\n", "authors": ["1232"]}
{"title": "Predicting quality of data warehouse using fuzzy logic\n", "abstract": " Due to strategic importance of data warehouse (DW) as decision support systems, it has become crucial to guarantee that these repositories should provide quality information to the decision makers. Quality of data warehouse multidimensional model has significant effect on data warehouse quality and in turn on the information quality. Few authors have suggested metrics to assess the quality of data warehouse multidimensional models. Empirical validation using statistical techniques like correlation analysis, univariate and multivariate regression techniques, etc., indicated that these metrics are significantly related to the quality of multidimensional models for data warehouse. But these techniques are not able to model non-linear relationship between the metrics and quality of multidimensional model. In this paper, model based on fuzzy logic approach is proposed to approximate non-linear relationship between\u00a0\u2026", "num_citations": "6\n", "authors": ["1232"]}
{"title": "An empirical analysis of implicit trust metrics in recommender systems\n", "abstract": " Recommender system is an intelligent solution to information overload problem. Classical collaborative filtering based recommender system suffers from cold start and data sparsity problems. Incorporation of trust in classical recommender systems has potential to improve the overall performance of recommender system. Trust has been enormously researched and its influence is manifested in recommender systems. Because of unavailability of explicit trust information, various implicit trust metrics are developed to deduce trust from user's online behavior. In this paper, we have conducted an empirical study of six implicit trust metrics on two different real world datasets. A comparative analysis of these metrics with classical user based collaborative filtering is performed.", "num_citations": "5\n", "authors": ["1232"]}
{"title": "Empirical validation of object oriented data warehouse design quality metrics\n", "abstract": " Data warehouses have been developed that stores information enabling the knowledge worker to make better and faster decisions. As a decision support information system, a data warehouse must provide high level quality of data and quality of service. Various metrics have been defined and theoretical validated to measure the quality of the data warehouse in a consistent and objective manner and if quality measured, it can be managed and improved. Now, in this paper we will use these design quality metrics and empirically validated these metrics by conducting an experiment using regression analysis and deriving the conclusions according to the analysis so that they can be used by researchers and users.", "num_citations": "4\n", "authors": ["1232"]}
{"title": "Project Portfolio Management (PPM) in Education Domain Using Skill Matcher Model\n", "abstract": " Project Portfolio Management has spurred significant research due to its importance in systematic management of corporate, government and academic projects. In this paper, we propose a skill matcher model for PPM which optimally matches students with various skills to a set of projects with specific skills requirements. We extract the skills required to execute a project from its description. We then generate a concept lattice of projects-skills by applying Formal Concept Analysis. The concepts so generated are assigned to students in an optimal manner by invoking the Stable Marriages Algorithm, keeping in view certain matching criteria. The experimental results show that the project teams so formed consists of all the skills required for completion of the project.", "num_citations": "3\n", "authors": ["1232"]}
{"title": "Empirical analysis of metrics for object oriented multidimensional model of data warehouse using unsupervised machine learning techniques\n", "abstract": " Data Warehouse provides the foundation for businesses to take informed decisions for day to day operations and making future strategy. Since the role is so pivotal to the growth and success of the business, its quality is very critical. Conceptual models of data warehouses give us a great insight into the quality of the developed system during the early stages of the design process. Researchers have proposed a number of metrics to evaluate the quality of these object oriented multidimensional models. Further, for these metrics to be used in practice, empirical evaluation is crucial. There are a number of propositions in literature that work towards empirical validation of metrics. But most of them are either restricted to statistical techniques or supervised machine learning techniques. In order to empirically validate the metrics, we need to get user responses for a number of schemas and take down observations\u00a0\u2026", "num_citations": "3\n", "authors": ["1232"]}
{"title": "Coupling metrics for object-oriented data warehouse design\n", "abstract": " Coupling is one of the most important factors influencing complexity and inturn quality of any software artifact. Researchers in the past have proposed different metrics to quantify the structural complexity of data warehouse design. The properties of complexity and size have obtained vast recognition by researchers. Unfortunately, there is little research on metrics to determine the extent of coupling in multidimensional models. None have worked to determine the degree to which the fact and dimension classes are coupled in an object-oriented multidimensional model. This paper puts forward a proposal to determine the extent of aggregation and inheritance coupling among classes in the early artifacts of data warehouse. The proposed coupling metrics take into consideration conformed dimensions which is a significant feature in a data warehouse. Preliminary corroboration of the proposed metrics using a practical\u00a0\u2026", "num_citations": "3\n", "authors": ["1232"]}
{"title": "Clickbait Detection Using Swarm Intelligence\n", "abstract": " Clickbaits are the articles containing catchy headlines which lure the reader to explore full content, but do not have any useful information. Detecting clickbaits solely by the headline without opening the link, can serve as a utility for users over internet. This can prevent their time from useless surfing caused by exploring clickbaits. In this paper Ant Colony Optimization, a Swarm Intelligence (SI) based technique has been used to detect clickbaits. In comparison with algorithms used in the past, this SI based technique provided a better accuracy and a human interpretable set of rules to classify clickbaits. A maximum accuracy of 96.93% with a set of 20 classification rules was obtained using the algorithm.", "num_citations": "2\n", "authors": ["1232"]}
{"title": "Automatic liver segmentation in CT images using improvised techniques\n", "abstract": " Computer aided automatic segmentation of liver can serve as an elementary step for radiologists to trace anomalies in the liver. In this paper, we have explored two techniques for liver segmentation - Region growing technique of Morphological Snake and a graph-based technique called Felzenszwalb. The aforementioned techniques have been modified by incorporating Artificial Neural Network (ANN) for automatic seed generation eliminating any user intervention. It has been tested on an open-source dataset of Liver CT Scans. Compared to the algorithms that have been used in past, the algorithms discussed in this paper are computationally much efficient in terms of time. Both algorithms were able to segment liver with high accuracy but Morphological Snake outperformed Felzenszwalb in terms of segmentation by achieving a dice index of 0.88 and a very high accuracy of 98.11%. However\u00a0\u2026", "num_citations": "2\n", "authors": ["1232"]}
{"title": "Analysis of Feature Ranking Techniques for Defect Prediction in Software Systems\n", "abstract": " Software quality is an important parameter, and it plays a crucial role in software development. One of the most important software quality attributes is fault proneness. It evaluates the quality of the final product. Fault proneness prediction models must be built in order to enhance software quality. There are various software metrics which help in software modeling, but it is a cumbersome and time-consuming process to use all of them. So, there is always a need to select those set of software metrics which help in determining fault proneness. Careful selection of software metrics is a major concern, and it becomes crucial if the search space is too large. This study focuses on the ranking of software metrics for building defect prediction models. Hybrid approach is applied in which feature ranking techniques are used to reduce the search space along with the feature subset selection methods. Classification\u00a0\u2026", "num_citations": "2\n", "authors": ["1232"]}
{"title": "Clinical utility of PCR in the diagnosis and management of latent tubercular endometritis\n", "abstract": " ObjectiveIt is estimated that 5% of females presenting themselves in infertility clinics worldwide are affected with genital tuberculosis. Genital tuberculosis remains undiagnosed and untreated. PCR test has been reported to have a high sensitivity but low specificity varying from 60\u201370%. Our aim was to evaluate the PCR (utilizing the target IS6110) in enhancing the diagnostic certainty for genital latent tuberculosis bacillus infection (LTBI) and the reproductive outcomes in women treated with antituberculosis therapy.DesignRetrospective review. of patients with either primary or secondary unexplained infertility or recurrent IVF failure.Materials and methodsThe records of 500 patients were reviewed. Of these 200 were recurrent aborters and 300 had ART failures. The age of the patients varied from 21\u201347 yrs, with an average age of 34 yrs. 41%(124/300) amongst the ART failures and 43%(86/200) of the recurrent\u00a0\u2026", "num_citations": "2\n", "authors": ["1232"]}
{"title": "Fuzzy Gravitational Search Approach to a Hybrid Data Model Based Recommender System\n", "abstract": " In recent times, when the Internet is flooded with information, users get overwhelmed with the large amount of data and need some system to narrow down their choices. Recommender systems provide personalized suggestions to the users, giving them a better experience. Data Filtering methods along with many Computational Intelligence (CI) techniques have been used to build and optimize these systems. Here, we introduce a new Recommender System, based on Fuzzy Gravitational Search Algorithm using Hybrid Data Model (FGSA-HDM). FGSA-HDM uses a nature inspired heuristic technique, Gravitational Search Algorithm (GSA), to learn a user\u2019s preference and optimize weightage given to different features which define the user profile. Also, to incorporate the fuzziness of human nature, these features have been represented by Fuzzy sets. The proposed technique, FGSA-HDM, has shown better\u00a0\u2026", "num_citations": "1\n", "authors": ["1232"]}
{"title": "Empirical investigation of metrics for multidimensional model of data warehouse using support vector machine\n", "abstract": " Data Warehouse is the backbone of all analytics oriented organizations where business decisions need to be taken. Due to its role as a decision support system, its quality becomes crucial. Data warehouse conceptual models can be used to determine its quality during the early stages of design. Several metrics have been proposed to estimate the quality of these models. In order to corroborate the practical applicability of these metrics, it is important to validate them empirically. A number of propositions have been made in the past for the empirical validation of these metrics largely using statistical techniques of correlation and regression. However, statistical techniques are unable to model complex and non-linear relationships between the metrics and quality of the data warehouse models. In this paper, we have made an attempt to assess the non-linear relationship between the data warehouse structural metrics\u00a0\u2026", "num_citations": "1\n", "authors": ["1232"]}