{"title": "Towards automatic model synchronization from model transformations\n", "abstract": " The metamodel techniques and model transformation techniques provide a standard way to represent and transform data, especially the software artifacts in software development. However, after a transformation is applied, the source model and the target model usually co-exist and evolve independently. How to propagate modifications across models in different formats still remains as an open problem.", "num_citations": "218\n", "authors": ["1704"]}
{"title": "From state-to delta-based bidirectional model transformations: the symmetric case\n", "abstract": " A bidirectional transformation (BX) keeps a pair of interrelated models synchronized. Symmetric BXs are those for which neither model in the pair fully determines the other. We build two algebraic frameworks for symmetric BXs, with one correctly implementing the other, and both being delta-based generalizations of known state-based frameworks. We identify two new algebraic laws-weak undoability and weak invertibility, which capture important semantics of BX and are useful for both state- and delta-based settings. Our approach also provides a flexible tool architecture adaptable to different user\u2019s needs.", "num_citations": "192\n", "authors": ["1704"]}
{"title": "Model synchronization based on triple graph grammars: correctness, completeness and invertibility\n", "abstract": " Triple graph grammars (TGGs) have been used successfully to analyze correctness and completeness of bidirectional model transformations, but a corresponding formal approach to model synchronization has been missing. This paper closes this gap by providing a formal synchronization framework with bidirectional update propagation operations. They are generated from a given TGG, which specifies the language of all consistently integrated source and target models. As our main result, we show that the generated synchronization framework is correct and complete, provided that forward and backward propagation operations are deterministic. Correctness essentially means that the propagation operations preserve and establish consistency while completeness ensures that the operations are defined for all possible inputs. Moreover, we analyze the conditions under which the operations are inverse to\u00a0\u2026", "num_citations": "137\n", "authors": ["1704"]}
{"title": "Supporting automatic model inconsistency fixing\n", "abstract": " Modern development environments often involve models with complex consistency relations. Some of the relations can be automatically established through\" fixing procedures\". When users update some parts of the model and cause inconsistency, a fixing procedure dynamically propagates the update to other parts to fix the inconsistency. Existing fixing procedures are manually implemented, which requires a lot of efforts and the correctness of a fixing procedure is not guaranteed.", "num_citations": "127\n", "authors": ["1704"]}
{"title": "Supporting runtime software architecture: A bidirectional-transformation-based approach\n", "abstract": " Runtime software architectures (RSA) are architecture-level, dynamic representations of running software systems, which help monitor and adapt the systems at a high abstraction level. The key issue to support RSA is to maintain the causal connection between the architecture and the system, ensuring that the architecture represents the current system, and the modifications on the architecture cause proper system changes. The main challenge here is the abstraction gap between the architecture and the system. In this paper, we investigate the synchronization mechanism between architecture configurations and system states for maintaining the causal connections. We identify four required properties for such synchronization, and provide a generic solution satisfying these properties. Specifically, we utilize bidirectional transformation to bridge the abstraction gap between architecture and system, and design an\u00a0\u2026", "num_citations": "93\n", "authors": ["1704"]}
{"title": "Synchronizing concurrent model updates based on bidirectional transformation\n", "abstract": " Model-driven software development often involves several related models. When models are updated, the updates need to be propagated across all models to make them consistent. A bidirectional model transformation keeps two models consistent by updating one model in accordance with the other. However, it does not work when the two models are modified at the same time. In this paper we first examine the requirements for synchronizing concurrent updates. We view a synchronizer for concurrent updates as a function taking the two original models and the two updated models as input, and producing two new models where the updates are synchronized. We argue that the synchronizer should satisfy three properties that we define to ensure a reasonable synchronization behavior. We then propose a new algorithm to wrap any bidirectional transformation into a synchronizer with the help of model\u00a0\u2026", "num_citations": "89\n", "authors": ["1704"]}
{"title": "A user survey of configuration challenges in Linux and eCos\n", "abstract": " Operating systems expose sophisticated configurability to handle variability in hardware platforms like mobile devices, desktops, and servers. The variability model of an operating system kernel like Linux contains thousands of options guarded by hundreds of complex constraints. To guide users throughout the configuration and ensure the validity of their decisions, specialized tools known as configurators have been developed. Despite these tools, configuration still remains a difficult and challenging process. To better understand the challenges faced by users during configuration, we conducted two surveys, one among Linux users and another among eCos users. This paper presents the results of the surveys along three dimensions: configuration practice; user guidance; and language expressiveness. We hope that these results will help researchers and tool builders focus their efforts to improve tool support for\u00a0\u2026", "num_citations": "82\n", "authors": ["1704"]}
{"title": "Generating synchronization engines between running systems and their model-based views\n", "abstract": " The key point to leverage model-based techniques on runtime system management is to ensure the correct synchronization between the running system and its model-based view. In this paper, we present a generative approach, and the supporting tool, to make systematic the development of synchronization engines between running systems and models. We require developers to specify \u201cwhat kinds of elements to manage\u201d as a MOF meta-model and \u201chow to manipulate those elements using the system\u2019s management API\u201d as a so-called access model. From these two specifications, our SM@RT tool automatically generates the synchronization engine to reflect the running system as a MOF-compliant model. We have applied this approach on several practical systems, including the JOnAS JEE server.", "num_citations": "68\n", "authors": ["1704"]}
{"title": "A case study on consistency management of business and IT process models in banking\n", "abstract": " Organizations that adopt process modeling often maintain several co-existing models of the same business process. These models target different abstraction levels and stakeholder perspectives. Maintaining consistency among these models has become a major challenge for such organizations. Although several academic works have discussed this challenge, little empirical investigation exists on how people perform process model consistency management in practice. This paper aims to address this lack by presenting an in-depth empirical study of a business-driven engineering process deployed at a large company in the banking sector. We analyzed more than 70 business process models developed by the company, including their change history, with over 1,000 change requests. We also interviewed 9 business and IT practitioners and surveyed 23 such practitioners to understand concrete\u00a0\u2026", "num_citations": "40\n", "authors": ["1704"]}
{"title": "Inferring meta-models for runtime system data from the clients of management APIs\n", "abstract": " A new trend in runtime system monitoring is to utilize MOF-based techniques in analyzing the runtime system data. Approaches and tools have been proposed to automatically reflect the system data as MOF compliant models, but they all require users to manually build the meta-models that define the types and relations of the system data. To do this, users have to understand the different management APIs provided by different systems, and find out what kinds of data can be obtained from them. In this paper, we present an automated approach to inferring such meta-models by analyzing client code that accesses management APIs. A set of experiments show that the approach is useful for realizing runtime models and applicable to a wide range of systems, and the inferred meta-models are close to the reference ones.", "num_citations": "37\n", "authors": ["1704"]}
{"title": "Programming situational mobile web applications with cloud-mobile convergence: An internetware-oriented approach\n", "abstract": " Mobile Web applications (a.k.a., Web apps) stand for an important trend for next-generation Internet-based software. Currently popular mobile Web apps need to be adapted to various and ever-changing contexts and personalized user requirements. Based on our over-decade research experiences and practice on the Internetware paradigm, this position article describes an Internetware-oriented approach to designing, developing, and deploying situational mobile Web apps, by synthesizing the resources and services of mobile and cloud. Guided by a novel Service-Model-View-Controller (SMVC) software model, a mobile Web app is organized into a well-defined structure that facilitates adaptation including online/offline data access, computation offloading, user interface optimization, hybrid composition, etc. We provide efficient runtime support spanning mobile and cloud to make mobile Web apps more flexibly\u00a0\u2026", "num_citations": "34\n", "authors": ["1704"]}
{"title": "Interactive inconsistency fixing in feature modeling\n", "abstract": " Feature models have been widely adopted to reuse the requirements of a set of similar products in a domain. In feature models\u2019 construction, one basic task is to ensure the consistency of feature models, which often involves detecting and fixing of inconsistencies in feature models. While many approaches have been proposed, most of them focus on detecting inconsistencies rather than fixing inconsistencies. In this paper, we propose a novel dynamic-priority based approach to interactively fixing inconsistencies in feature models, and report an implementation of a system that not only automatically recommends a solution to fixing inconsistencies but also supports domain analysts to gradually reach the desirable solution by dynamically adjusting priorities of constraints. The key technical contribution is, as far as we are aware, the first application of the constraint hierarchy theory to feature modeling, where\u00a0\u2026", "num_citations": "29\n", "authors": ["1704"]}
{"title": "Enforcing a security pattern in stakeholder goal models\n", "abstract": " Patterns are useful knowledge about recurring problems and solutions. Detecting a security problem using patterns in requirements models may lead to its early solution. In order to facilitate early detection and resolution of security problems, in this paper, we formally describe a role-based access control (RBAC) as a pattern that may occur in stakeholder requirements models. We also implemented in our goal-oriented modeling tool the formally described pattern using model-driven queries and transformations. Applied to a number of requirements models published in literature, the tool automates the detection and resolution of the security pattern in several goal-oriented stakeholder requirements.", "num_citations": "29\n", "authors": ["1704"]}
{"title": "Inferring program transformations from singular examples via big code\n", "abstract": " Inferring program transformations from concrete program changes has many potential uses, such as applying systematic program edits, refactoring, and automated program repair. Existing work for inferring program transformations usually rely on statistical information over a potentially large set of program-change examples. However, in many practical scenarios we do not have such a large set of program-change examples. In this paper, we address the challenge of inferring a program transformation from one single example. Our core insight is that \"big code\" can provide effective guide for the generalization of a concrete change into a program transformation, i.e., code elements appearing in many files are general and should not be abstracted away. We first propose a framework for transformation inference, where programs are represented as hypergraphs to enable fine-grained generalization of transformations\u00a0\u2026", "num_citations": "28\n", "authors": ["1704"]}
{"title": "Smartfixer: Fixing software configurations based on dynamic priorities\n", "abstract": " Large modern software systems are often organized as product lines, requiring specialists to configure variability models before delivering a product. Variability models capture both the commonality and variability of different products, and help detect the configurations errors. Existing approaches can recommend fixes for the errors automatically. However, the recommended fixes are sometimes large and complex, and existing approaches lack guidance to help users identify a desirable fix. This paper proposes an approach to provide such guidance using dynamic priorities. The basic idea is to first generate one fix, and then gradually reach the desirable fix based on user feedback. To this end, our approach (1) automatically translates user feedback into a set of implicit priority levels on configuration variables, using five priority assignment and adjustment strategies and (2) efficiently generates potential desirable\u00a0\u2026", "num_citations": "21\n", "authors": ["1704"]}
{"title": "Automatic clone recommendation for refactoring based on the present and the past\n", "abstract": " When many clones are detected in software programs, not all clones are equally important to developers. To help developers refactor code and improve software quality, various tools were built to recommend clone-removal refactorings based on the past and the present information, such as the cohesion degree of individual clones or the co-evolution relations of clone peers. The existence of these tools inspired us to build an approach that considers as many factors as possible to more accurately recommend clones. This paper introduces CREC, a learning-based approach that recommends clones by extracting features from the current status and past history of software projects. Given a set of software repositories, CREC first automatically extracts the clone groups historically refactored (R-clones) and those not refactored (NR-clones) to construct the training set. CREC extracts 34 features to characterize the\u00a0\u2026", "num_citations": "19\n", "authors": ["1704"]}
{"title": "Swin: Towards type-safe java program adaptation between apis\n", "abstract": " Java program adaptation between different APIs is a common task in software development. When an old API is upgraded to an incompatible new version, or when we want to migrate an application from one platform to another platform, we need to adapt programs between different APIs. Although different program transformation tools have been developed to automate the program adaptation task, no tool ensures type safety in transforming Java programs: given a transformation program and any well-typed Java program, the transformed result is still well-typed. As a matter of fact, it is often observed that a dedicated adaptation tool turns a working application into a set of incompatible programs. We address this problem by providing a type-safe transformation language, SWIN, for Java program adaptation between different APIs. SWIN is based on Twinning, a modern transformation language for Java programs\u00a0\u2026", "num_citations": "19\n", "authors": ["1704"]}
{"title": "How do Python framework APIs evolve? an exploratory study\n", "abstract": " Python is a popular dynamic programming language. In recent years, many frameworks implemented in Python have been widely used for data science and web development. Similar to frameworks in other languages, the APIs provided by Python frameworks often evolve, which would inevitably induce compatibility issues in client applications. While existing work has studied the evolution of frameworks in static programming languages such as Java, little is known on how Python framework APIs evolve and the characteristics of the compatibility issues induced by such evolution. To bridge this gap, we take a first look at the evolution of Python framework APIs and the resulting compatibility issues in client applications. We analyzed 288 releases of six popular Python frameworks from three different domains and 5,538 open-source projects built on these frameworks. We investigated the evolution patterns of Python\u00a0\u2026", "num_citations": "11\n", "authors": ["1704"]}
{"title": "Learning to synthesize\n", "abstract": " In many scenarios we need to find the most likely program under a local context, where the local context can be an incomplete program, a partial specification, natural language description, etc. We call such problem program estimations. In this paper we propose an abstract framework, learning to synthesis, or L2S in short, to address this problem. L2S combines four tools to achieve this: rewriting rules are used to define the search space and search steps, constraint solving is used to prune off invalid candidates at each search step, machine learning is used to estimate conditional probabilities for the candidates at each search step, and search algorithms are used to find the best possible solution. The main goal of L2S is to lay out the design space to motivate the research on program estimation.", "num_citations": "8\n", "authors": ["1704"]}
{"title": "Guiding dynamic programing via structural probability for accelerating programming by example\n", "abstract": " Programming by example (PBE) is an important subproblem of program synthesis, and PBE techniques have been applied to many domains. Though many techniques for accelerating PBE systems have been explored, the scalability remains one of the main challenges: There is still a gap between the performances of state-of-the-art synthesizers and the industrial requirement. To further speed up solving PBE tasks, in this paper, we propose a novel PBE framework MaxFlash. MaxFlash uses a model based on structural probability, named topdown prediction models, to guide a search based on dynamic programming, such that the search will focus on subproblems that form probable programs, and avoid improbable programs. Our evaluation shows that MaxFlash achieves \u00d7 4.107\u2212 \u00d7 2080 speed-ups against state-of-the-art solvers on 244 real-world tasks.", "num_citations": "7\n", "authors": ["1704"]}
{"title": "Goal modelling for security problem matching and pattern enforcement\n", "abstract": " This article describes how earlier detection of security problems and the implementation of solutions would be a cost-effective approach for developing secure software systems. Developing, gathering and sharing similar repeatable programming knowledge and solutions has led to the introduction of Patterns in the 90's. The same concept has been adopted to realise reoccurring security knowledge and hence security patterns. Detecting a security problem using the patterns in requirements models may lead to its early prevention. In this article, the authors have provided an overview of security patterns in the past two decades, followed by a summary of i*/Tropos goal modelling framework. Section 2 outlines model-driven development, meta-models and model transformation, within the context of requirements engineering. They have summarised security access control types, and formally described role-based\u00a0\u2026", "num_citations": "7\n", "authors": ["1704"]}
{"title": "Supporting feature model refinement with updatable view\n", "abstract": " In the research of software reuse, feature models have been widely adopted to capture, organize and reuse the requirements of a set of similar applications in a software domain. However, the construction, especially the refinement, of feature models is a labor-intensive process, and there lacks an effective way to aid domain engineers in refining feature models. In this paper, we propose a new approach to support interactive refinement of feature models based on the view updating technique. The basic idea of our approach is to first extract features and relationships of interest from a possibly large and complicated feature model, then organize them into a comprehensible view, and finally refine the feature model through modifications on the view. The main characteristics of this approach are twofold: a set of powerful rules (as the slicing criterion) to slice the feature model into a view automatically, and a\u00a0\u2026", "num_citations": "6\n", "authors": ["1704"]}
{"title": "Tolerating Inconsistency in Feature Models.\n", "abstract": " Feature models have been widely adopted to reuse the requirements of a set of similar products in a domain. When constructing feature models, it is difficult to always ensure the consistency of feature models. Therefore, tolerating inconsistencies is important during the construction of feature models. The usual way of tolerating inconsistencies is to find the minimal unsatisfiable core. However, identifying the minimal unsatisfiable core is time-consuming, which decreases itself the practicability. In this paper, we propose a priority based approach to tolerating inconsistencies in feature models efficiently. The basic idea of our approach is to find the weaker unsatisfied constraints, while keeping the rest of the feature model consistent. Our approach tolerates inconsistencies with the help of priority based operations while building feature models. To this end, we adopt the constraint hierarchy theory to express the degree of domain analysts\u2019 confidence on constraints (ie the priorities of constraints) and tolerate inconsistencies in feature models. Experiments have been conducted to demonstrate that our system can scale up to large feature models.", "num_citations": "6\n", "authors": ["1704"]}
{"title": "Configurator semantics of the CDL language\n", "abstract": " This paper presents formal semantics of the Component Description Language (CDL) language. Compared to the CDL semantics proposed by Berger and She [BS10], this version focuses more on the behavior of configurator and is more close to the implementation of a configurator.", "num_citations": "4\n", "authors": ["1704"]}
{"title": "Can defects be fixed with weak test suites? An analysis of 50 defects from defects4j\n", "abstract": " Automated program repair techniques, which target to generating correct patches for real world defects automatically, have gained a lot of attention in the last decade. Many different techniques and tools have been proposed and developed. However, even the most sophisticated program repair techniques can only repair a small portion of defects while producing a lot of incorrect patches. A possible reason for this low performance is that the test suites of real world programs are usually too weak to guarantee the behavior of the program. To understand to what extent defects can be fixed with weak test suites, we analyzed 50 real world defects from Defects4J, in which we found that up to 84% of them could be correctly fixed. This result suggests that there is plenty of space for current automated program repair techniques to improve. Furthermore, we summarized seven fault localization strategies and seven patch generation strategies that were useful in localizing and fixing these defects, and compared those strategies with current repair techniques. The results indicate potential directions to improve automatic program repair in the future research.", "num_citations": "3\n", "authors": ["1704"]}
{"title": "A compositional approach to bidirectional model transformation\n", "abstract": " A Compositional Approach to Bidirectional Model Transformation - Bidirectional Computation for Software Engineering Page 1 Bidirectional Computation Bidirectional Computation is WANTED in SE BiX: A Bidirectional Tree Transformation Language Bidirectional Model Transformation: A Compositional Approach Conclusion A Compositional Approach to Bidirectional Model Transformation Bidirectional Computation for Software Engineering Zhenjiang Hu GRACE Center National Institute of Informatics March 6, 2009 Joint Work with Soichiro Hidaka, Hiroyuki Kato and Keisuke Nakano Zhenjiang Hu A Compositional Approach to Bidirectional Model Transformation Page 2 Bidirectional Computation Bidirectional Computation is WANTED in SE BiX: A Bidirectional Tree Transformation Language Bidirectional Model Transformation: A Compositional Approach Conclusion How do you synchronize your calenders? \u2026", "num_citations": "3\n", "authors": ["1704"]}
{"title": "Interactive Patch Filtering as Debugging Aid\n", "abstract": " It is widely recognized that program repair tools need to have a high precision to be useful, i.e., the generated patches need to have a high probability to be correct. However, it is fundamentally difficult to ensure the correctness of the patches, and many tools compromise other aspects of repair performance such as recall for an acceptable precision. In this paper we ask a question: can a repair tool with a low precision be still useful? To explore this question, we propose an interactive filtering approach to patch review, which filters out incorrect patches by asking questions to the developers. Our intuition is that incorrect patches can still help understand the bug. With proper tool support, the benefit outweighs the cost even if there are many incorrect patches. We implemented the approach as an Eclipse plugin tool, InPaFer, and evaluated it with a simulated experiment and a user study with 30 developers. The results show that our approach improve the repair performance of developers, with 62.5% more successfully repaired bugs and 25.3% less debugging time in average. In particular, even if the generated patches are all incorrect, the performance of the developers would not be significantly reduced, and could be improved when some patches provide useful information for repairing, such as the faulty location and a partial fix.", "num_citations": "2\n", "authors": ["1704"]}
{"title": "Scaling static taint analysis to industrial SOA applications: a case study at Alibaba\n", "abstract": " In Alibaba, we have seen a growing demand for tracing data flow for scenarios such as data leak detection, change governance, and data consistency checking. Static taint analysis is a technique for such problems, and many approaches are proposed for high scalability and precision. This paper shares our experience in applying taint analysis in Alibaba. In particular, we find that the state-of-the-art taint analysis tool, FlowDroid, does not work well in our cases because our applications make heavy use of libraries, native methods and enterprise-specific frameworks, which impose two major challenges, scalability and implicit dependency, to FlowDroid. This paper presents ANTaint to address these problems. ANTaint improves scalability by expanding the call graph and applying taint propagation on demand for libraries, which account for majority of the program execution but only a small fraction propagates taints\u00a0\u2026", "num_citations": "1\n", "authors": ["1704"]}
{"title": "How to Explain a Patch: An Empirical Study of Patch Explanations in Open Source Projects\n", "abstract": " Bugs are inevitable in software development and maintenance processes. Recently a lot of research efforts have been devoted to automatic program repair, aiming to reduce the efforts of debugging. However, since it is difficult to ensure that the generated patches meet all quality requirements such as correctness, developers still need to review the patch. In addition, current techniques produce only patches without explanation, making it difficult for the developers to understand the patch. Therefore, we believe a more desirable approach should generate not only the patch but also an explanation of the patch. To generate a patch explanation, it is important to first understand how patches were explained. In this paper, we explored how developers explain their patches by manually analyzing 300 merged bug-fixing pull requests from six projects on GitHub. Our contribution is twofold. First, we build a patch\u00a0\u2026", "num_citations": "1\n", "authors": ["1704"]}
{"title": "Inferring the data access from the clients of generic APIs\n", "abstract": " Many programs access external data sources through generic APIs. The class hierarchy of such a generic API does not reflect the schema of any particular data source, and thus it is hard to clarify what data an API client accesses and how it obtains them. This makes it difficult to maintain the API clients. In this paper, we show that the data access of an API client can be recovered through static analysis on the client's source code. We provide a formal and intuitive way to represent the data access, as a graph of so-called summoning snippets. Each snippet stands for a type of data accessed by the client, and carries the code slice from the client about how to obtain the data via the API. We provide an automated approach to inferring a complete and well-simplified set of summoning snippets from the client source code, based on points-to analysis and code slicing. We implement this approach as a development\u00a0\u2026", "num_citations": "1\n", "authors": ["1704"]}