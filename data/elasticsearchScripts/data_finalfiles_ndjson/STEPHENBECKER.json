{"title": "Crime and punishment: An economic approach\n", "abstract": " Since the turn of the twentieth century, legislation in Western countries has expanded rapidly to reverse the brief dominance of laissez faire during the nineteenth century. The state no longer merely protects against violations of person and property through murder, rape, or burglary but also restricts \u0393\u00c7\u00ffdiscrimination\u0393\u00c7\u00d6 against certain minorities, collusive business arrangements, \u0393\u00c7\u00ffjaywalking\u0393\u00c7\u00d6, travel, the materials used in construction, and thousands of other activities. The activities restricted not only are numerous but also range widely, affecting persons in very different pursuits and of diverse social backgrounds, education levels, ages, races, etc. Moreover, the likelihood that an offender will be discovered and convicted and the nature and extent of punishments differ greatly from person to person and activity to activity. Yet, in spite of such diversity, some common properties are shared by practically all legislation\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "22262\n", "authors": ["44"]}
{"title": "The Palladio component model for model-driven performance prediction\n", "abstract": " One aim of component-based software engineering (CBSE) is to enable the prediction of extra-functional properties, such as performance and reliability, utilising a well-defined composition theory. Nowadays, such theories and their accompanying prediction methods are still in a maturation stage. Several factors influencing extra-functional properties need additional research to be understood. A special problem in CBSE stems from its specific development process: Software components should be specified and implemented independently from their later context to enable reuse. Thus, extra-functional properties of components need to be specified in a parametric way to take different influencing factors like the hardware platform or the usage profile into account. Our approach uses the Palladio component model (PCM) to specify component-based software architectures in a parametric way. This model offers direct\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "903\n", "authors": ["44"]}
{"title": "Model-based performance prediction with the palladio component model\n", "abstract": " One aim of component-based software engineering (CBSE) is to enable the prediction of extra-functional properties, such as performance and reliability, utilising a well-defined composition theory. Nowadays, such theories and their accompanying prediction methods are still in a maturation stage. Several factors influencing extra-functional properties need additional research to be understood. A special problem in CBSE stems from its specific development process: Software components should be specified and implemented independent from their later context to enable reuse. Thus, extra-functional properties of components need to be specified in a parametric way to take different influence factors like the hardware platform or the usage profile into account. In our approach, we use the Palladio Component Model (PCM) to specify component-based software architectures in a parametric way. This model offers direct\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "267\n", "authors": ["44"]}
{"title": "Automatically improve software architecture models for performance, reliability, and cost using evolutionary algorithms\n", "abstract": " Quantitative prediction of quality properties (ie extra-functional properties such as performance, reliability, and cost) of software architectures during design supports a systematic software engineering approach. Designing architectures that exhibit a good trade-off between multiple quality criteria is hard, because even after a functional design has been created, many remaining degrees of freedom in the software architecture span a large, discontinuous design space. In current practice, software architects try to find solutions manually, which is time-consuming, can be error-prone and can lead to suboptimal designs. We propose an automated approach to search the design space for good solutions. Starting with a given initial architectural model, the approach iteratively modifies and evaluates architectural models. Our approach applies a multi-criteria genetic algorithm to software architectures modelled with the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "232\n", "authors": ["44"]}
{"title": "Modeling and simulating software architectures: The Palladio approach\n", "abstract": " A new, quantitative architecture simulation approach to software design that circumvents costly testing cycles by modeling quality of service in early design states. Too often, software designers lack an understanding of the effect of design decisions on such quality attributes as performance and reliability. This necessitates costly trial-and-error testing cycles, delaying or complicating rollout. This book presents a new, quantitative architecture simulation approach to software design, which allows software engineers to model quality of service in early design stages. It presents the first simulator for software architectures, Palladio, and shows students and professionals how to model reusable, parametrized components and configured, deployed systems in order to analyze service attributes. The text details the key concepts of Palladio's domain-specific modeling language for software architecture quality and presents the corresponding development stage. It describes how quality information can be used to calibrate architecture models from which detailed simulation models are automatically derived for quality predictions. Readers will learn how to approach systematically questions about scalability, hardware resources, and efficiency. The text features a running example to illustrate tasks and methods as well as three case studies from industry. Each chapter ends with exercises, suggestions for further reading, and \u0393\u00c7\u00a3takeaways\u0393\u00c7\u00a5 that summarize the key points of the chapter. The simulator can be downloaded from a companion website, which offers additional material. The book can be used in graduate courses on software architecture, quality\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "163\n", "authors": ["44"]}
{"title": "The Palladio component model\n", "abstract": " This report introduces the Palladio Component Model (PCM), a novel software component model for business information systems, which is specifically tuned to enable model-driven quality-of-service (QoS, ie, performance and reliability) predictions (based on work previously published in [1, 2, 3, 4, 5]). The PCM\u0393\u00c7\u00d6s goal is to assess the expected response times, throughput, and resource utilization of component-based software architectures during early development stages. This shall avoid costly redesigns, which might occur after a poorly designed architecture has been implemented. Software architects should be enabled to analyse different architectural design alternatives and to support their design decisions with quantitative results from performance or reliability analysis tools. Component-based software engineering (CBSE)[6] promises many advantages over object-oriented or procedural development approaches. Besides increased reusability, better preparation for evolution, higher quality due to increased testing, and shorter time-to-market, CBSE potentially offers better predictability for the properties of architectures, because individual components should be provided with more detailed specifications. A large number of component models has been designed for different purposes. Component models used in the industry today (COM+/.NET, J2EE/EJB, CCM, etc.) do not offer capabilities for predicting QoS attributes. Component models from academia [7] have been designed to support purposes like runtime configuration, protocol checking, mobile device assessment etc. Some of them deal with QoS predictions (eg, ROBOCOP, KLAPER\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "151\n", "authors": ["44"]}
{"title": "Visual evidence: A Seventh Man, the specified generalization, and the work of the reader\n", "abstract": " How do photographs provide evidence for social science arguments? Analysis of A Seventh Man , a book about migrant labor in Europe, by John Berger and Jean Mohr, suggests that they do this by providing specified generalizations, which state a general idea embodied in images of specific people, places, and events.", "num_citations": "150\n", "authors": ["44"]}
{"title": "Performance prediction of component-based systems\n", "abstract": " Performance predictions of component assemblies and the ability of obtaining system-level performance properties from these predictions are a crucial success factor when building trustworthy component-based systems. In order to achieve this goal, a collection of methods and tools to capture and analyze the performance of software systems has been developed. These methods and tools aim at helping software engineers by providing them with the capability to understand design trade-offs, optimize their design by identifying performance inhibitors, or predict a system\u0393\u00c7\u00d6s performance within a specified deployment environment. In this paper, we analyze the applicability of various performance prediction methods for the development of component-based systems and contrast their inherent strengths and weaknesses in different engineering problem scenarios. In so doing, we establish a basis to select an\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "124\n", "authors": ["44"]}
{"title": "Scalability, elasticity, and efficiency in cloud computing: A systematic literature review of definitions and metrics\n", "abstract": " Context: In cloud computing, there is a multitude of definitions and metrics for scalability, elasticity, and efficiency. However, stakeholders have little guidance for choosing fitting definitions and metrics for these quality properties, thus leading to potential misunderstandings. For example, cloud consumers and providers cannot negotiate reliable and quantitative service level objectives directly understood by each stakeholder. Objectives: Therefore, we examine existing definitions and metrics for these quality properties from the viewpoint of cloud consumers, cloud providers, and software architects with regard to commonly used concepts. Methods: We execute a systematic literature review (SLR), reproducibly collecting common concepts in definitions and metrics for scalability, elasticity, and efficiency. As quality selection criteria, we assess whether existing literature differentiates the three properties, exemplifies\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "109\n", "authors": ["44"]}
{"title": "Coupled model transformations for QoS enabled component-based software design\n", "abstract": " Component-based software engineering aims at developing software systems by assembling pre-existing components to build applications. One advantage gained from this is an increased predictability of the system's performance based on its constituting components. As models are used during software design but performance is a run-time attribute, the necessary abstraction in models from implementation details might remove performance-relevant aspects resulting in a loss of prediction accuracy. The solution presented in this thesis introduces the Palladio Component Model for component-based software design with predictable performance attributes. Transformations map instances of this model into implementations resulting in a deterministic relationship between the model and its implementation. The introduced Coupled Transformations method uses this relationship to automatically include implementation details which increases their prediction accuracy. The approach is validated in several case studies showing the increased accuracy as well as the applicability of the overall approach by third parties.", "num_citations": "93\n", "authors": ["44"]}
{"title": "Quantitative evaluation of model-driven performance analysis and simulation of component-based architectures\n", "abstract": " During the last decade, researchers have proposed a number of model transformations enabling performance predictions. These transformations map performance-annotated software architecture models into stochastic models solved by analytical means or by simulation. However, so far, a detailed quantitative evaluation of the accuracy and efficiency of different transformations is missing, making it hard to select an adequate transformation for a given context. This paper provides an in-depth comparison and quantitative evaluation of representative model transformations to, e.g., queueing petri nets and layered queueing networks. The semantic gaps between typical source model abstractions and the different analysis techniques are revealed. The accuracy and efficiency of each transformation are evaluated by considering four case studies representing systems of different size and complexity. The presented\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "88\n", "authors": ["44"]}
{"title": "Metrics and benchmarks for self-aware computing systems\n", "abstract": " In this chapter, we propose a list of metrics grouped by the MAPE-K paradigm for quantifying properties of self-aware computing systems. This set of metrics can be seen as a starting point toward benchmarking and comparing self-aware computing systems on a level-playing field. We discuss state-of-the art approaches in the related fields of self-adaptation and self-protection to identify commonalities in metrics for self-aware computing. We illustrate the need for benchmarking self-aware computing systems with the help of an approach that uncovers real-time characteristics of operating systems. Gained insights of this approach can be seen as a way of enhancing self-awareness by a measurement methodology on an ongoing basis. At the end of this chapter, we address new challenges in reference workload definition for benchmarking self-aware computing systems, namely load intensity patterns and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "83\n", "authors": ["44"]}
{"title": "Classification of concrete textual syntax mapping approaches\n", "abstract": " Textual concrete syntaxes for models are beneficial for many reasons. They foster usability and productivity because of their fast editing style, their usage of error markers, autocompletion and quick fixes. Furthermore, they can easily be integrated into existing tools such as diff/merge or information interchange through e-mail, wikis or blogs. Several frameworks and tools from different communities for creating concrete textual syntaxes for models emerged during recent years. However, these approaches failed to provide a solution in general. Open issues are incremental parsing and model updating as well as partial and federated views. To determine the capabilities of existing approaches, we provide a classification schema, apply it to these approaches, and identify their deficiencies.", "num_citations": "64\n", "authors": ["44"]}
{"title": "Parametric performance completions for model-driven performance prediction\n", "abstract": " Performance prediction methods can help software architects to identify potential performance problems, such as bottlenecks, in their software systems during the design phase. In such early stages of the software life-cycle, only a little information is available about the system\u0393\u00c7\u00d6s implementation and execution environment. However, these details are crucial for accurate performance predictions. Performance completions close the gap between available high-level models and required low-level details. Using model-driven technologies, transformations can include details of the implementation and execution environment into abstract performance models. However, existing approaches do not consider the relation of actual implementations and performance models used for prediction. Furthermore, they neglect the broad variety of possible implementations and middleware platforms, possible configurations, and\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "59\n", "authors": ["44"]}
{"title": "Evaluating maintainability with code metrics for model-to-model transformations\n", "abstract": " Using model-to-model transformations to generate analysis models or code from architecture models is sought to promote compliance and reuse of components. The maintainability of transformations is influenced by various characteristics - as with every programming language artifact. Code metrics are often used to estimate code maintainability. However, most of the established metrics do not apply to declarative transformation languages (such as QVT Relations) since they focus on imperative (e.g. object-oriented) coding styles. One way to characterize the maintainability of programs are code metrics. However, the vast majority of these metrics focus on imperative (e.g., object-oriented) coding styles and thus cannot be reused as-is for transformations written in declarative languages. In this paper we propose an initial set of quality metrics to evaluate transformations written in the declarative QVT\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "58\n", "authors": ["44"]}
{"title": "Performance analysis of self-adaptive systems for requirements validation at design-time\n", "abstract": " Self-adaptation allows continuously running software systems to operate in changing and uncertain contexts while meeting their requirements in a broad range of contexts, eg, from low to high load situations. As a consequence, requirements for self-adaptive systems are more complex than requirements for static systems as they have to explicitly address properties of the self-adaptation layer. While approaches exist in the literature to capture this new type of requirements formally, their achievement cannot be analyzed in early design phases yet. In this paper, we apply RELAX to formally specify non-functional requirements for self-adaptive systems. We then apply our model-based SimuLizar approach for a semi-automatic analysis to test whether the self-adaptation layer ensures that these non-functional requirements are met. We evaluate our approach on the design of a proof-of-concept load balancer system. As\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "57\n", "authors": ["44"]}
{"title": "Simulizar: Design-time modeling and performance analysis of self-adaptive systems\n", "abstract": " Modern software systems adapt themselves to changing environments in order to meet quality-of-service requirements, such as response time limits. The engineering of the system's self-adaptation logic does not only require new modeling methods, but also new analysis of transient phases. Model-driven software performance engineering methods already allow design-time analysis of steady states of nonadaptive system models. In order to validate requirements for transient phases, new modeling and analysis methods are needed. In this paper, we present SimuLizar, our initial model-driven approach to model self-adaptive systems and to analyze the performance of their transient phases. Our evaluation of a proof of concept load balancer system shows the applicability of our modeling approach. In addition, a comparison of our performance analysis with a prototypical implementation of our example system provides evidence that the prediction accuracy is sufficient to identify unsatisfactory self-adaptations.", "num_citations": "55\n", "authors": ["44"]}
{"title": "Performance modeling in industry: a case study on storage virtualization\n", "abstract": " In software engineering, performance and the integration of performance analysis methodologies gain increasing importance, especially for complex systems. Well-developed methods and tools can predict non-functional performance properties like response time or resource utilization in early design stages, thus promising time and cost savings. However, as performance modeling and performance prediction is still a young research area, the methods are not yet well-established and in wide-spread industrial use. This work is a case study of the applicability of the Palladio Component Model as a performance prediction method in an industrial environment. We model and analyze different design alternatives for storage virtualization on an IBM* system. The model calibration, validation and evaluation is based on data measured on a System z9* as a proof of concept. The results show that performance predictions\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "54\n", "authors": ["44"]}
{"title": "A pattern-based performance completion for message-oriented middleware\n", "abstract": " Details about the underlying Message-oriented Middleware (MOM) are essential for accurate performance predictions of software systems using message-based communication. The MOM's configuration and usage strongly influence its throughput, resource utilisation and timing behaviour. Prediction models need to reflect these effects and allow software architects to evaluate the performance influence of MOM configured for their needs. Performance completions [31, 32] provide the general concept to include low-level details of execution environments in abstract performance models. In this paper, we extend the Palladio Component Model (PCM)[4] by a performance completion for Message-oriented Middleware. With our extension to the model, software architects can specify and configure message-based communication using a language based on messaging patterns. For performance evaluation, a model-to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "48\n", "authors": ["44"]}
{"title": "Classifying software component interoperability errors to support component adaption\n", "abstract": " This paper discusses various classifications of component interoperability errors. These classifications aim at supporting the automation of component adaptation. The use of software components will only demonstrate beneficial, if the costs for component deployment (i.e., acquisition and composition) are considerably lower than those for custom component development. One of the main reasons for the moderate progress in component-based software engineering are the high costs for component deployment. These costs are mainly caused by adapting components to bridge interoperability errors between unfitting components. One way to lower the costs of component deployment is to support component adaptation by tools, i.e., for interoperability checks of (semi-)automated adaptor generation. This automation of component adaptation requires a deep understanding of component interoperability errors\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "45\n", "authors": ["44"]}
{"title": "Model-driven performance engineering of self-adaptive systems: a survey\n", "abstract": " To meet quality-of-service requirements in changing environments, modern software systems adapt themselves. The structure, and correspondingly the behavior, of these systems undergoes continuous change. Model-driven performance engineering, however, assumes static system structures, behavior, and deployment. Hence, self-adaptive systems pose new challenges to model-driven performance engineering. There are a few surveys on self-adaptive systems, performance engineering, and the combination of both in the literature. In contrast to existing work, here we focus on model-driven performance analysis approaches. Based on a systematic literature review, we present a classification, identify open issues, and outline further research.", "num_citations": "44\n", "authors": ["44"]}
{"title": "Reverse engineering component models for quality predictions\n", "abstract": " Legacy applications are still widely spread. If a need to change deployment or update its functionality arises, it becomes difficult to estimate the performance impact of such modifications due to absence of corresponding models. In this paper, we present an extendable integrated environment based on Eclipse developed in the scope of the Q-Impress project for reverse engineering of legacy applications (in C/C++/Java). The Q-Impress project aims at modeling quality attributes (performance, reliability, maintainability) at an architectural level and allows for choosing the most suitable variant for implementation of a desired modification. The main contributions of the project include i) a high integration of all steps of the entire process into a single tool, a beta version of which has been already successfully tested on a case study, ii) integration of multiple research approaches to performance modeling, and iii) an\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "41\n", "authors": ["44"]}
{"title": "Towards a tool-oriented taxonomy of view-based modelling\n", "abstract": " The separation of view and model is one of the key concepts of Model- Driven Engineering (MDE). Having different views on a central model helps modellers to focus on specific aspects. Approaches for the creation of Domain-Specific Modelling Languages (DSML) allow language engineers to define languages tailored for specific problems. To be able to build DSMLs that also benefit from view-based modelling a common understanding of the properties of both paradigms is required. However, research has not yet considered the combination of both paradigms, namely view-based domain specific modelling to a larger extent. Especially, a comprehensive analysis of a view's properties (e.g., partial, overlapping, editable, persistent, etc.) has not been conducted. Thus, it is also still unclear to which extent view-based modelling is understood by current DSML approaches and what a common understanding if this paradigm is. In this paper, we explore view-based modelling in a tool-oriented way. Furthermore, we analyse the properties of the view-based domain-specific modelling concept and provide a feature-based classification of these properties.", "num_citations": "40\n", "authors": ["44"]}
{"title": "Model-driven generation of performance prototypes\n", "abstract": " Early, model-based performance predictions help to understand the consequences of design decisions on the performance of the resulting system before the system\u0393\u00c7\u00d6s implementation becomes available. While this helps reducing the costs for redesigning systems not meeting their extra-functional requirements, performance prediction models have to abstract from the full complexity of modern hard- and software environments potentially leading to imprecise predictions. As a solution, the construction and execution of prototypes on the target execution environment gives early insights in the behaviour of the system under realistic conditions. In literature several approaches exist to generate prototypes from models which either generate code skeletons or require detailed models for the prototype. In this paper, we present an approach which aims at automated generation of a performance prototype based\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "40\n", "authors": ["44"]}
{"title": "Combining clustering and pattern detection for the reengineering of component-based software systems\n", "abstract": " During the software lifecycle, software systems have to be continuously maintained to counteract architectural deterioration and retain their software quality. In order to maintain a software it has to be understood first which can be supported by (semi-) automatic reverse engineering approaches. Reverse engineering is the analysis of software for the purpose of recovering its design documentation, eg, in form of the conceptual architecture. Today, the most prevalent reverse engineering approaches are (1) the clustering based approach which groups the elements of a given software system based on metric values in order to provide an overview of the system and (2) the pattern-based approach which tries to detect pre-defined patterns in the software which can give insight about the original developers' intentions. In this paper, we present an approach towards combining these techniques: we show how the detection\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "39\n", "authors": ["44"]}
{"title": "Parametric performance contracts for QML-specified software components\n", "abstract": " The performance of a software component heavily depends on the environment of the component. As a software component only justifies its investment when deployed in several environments, one can not specify the performance of a component as a constant (e.g., as a single value or distribution of values in its interface). Hence, classical component contracts allowing to state the component's performance as a post-condition, if the environment realises a specific performance stated in the precondition, do not help. This fixed pair of pre- and postcondition do not model that a component can have very different performance figures depending on its context. Instead of that, parametric contracts are needed for specifying the environmental dependency of the component's provided performance. In this paper we discuss the specification of dependencies of external calls for the performance metric response time. We\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "38\n", "authors": ["44"]}
{"title": "A case study on model-driven and conventional software development: The palladio editor\n", "abstract": " The actual benefits of model-driven approaches compared to code-centric development have not been systematically investigated. This paper presents a case study in which functional identical software was once developed in a code-centric, conventional style and once using Eclipse-based model-driven development tools. In our specific case, the model-driven approach could be carried in 11% of the time of the conventional approach, while simultaneously improving code quality.", "num_citations": "37\n", "authors": ["44"]}
{"title": "The MechatronicUML design method-process and language for platform-independent modeling\n", "abstract": " Nowadays, software drives all kinds of systems that interact with their physical environment [GRS14]. Examples for such systems are autonomously driving cars or trains, self-coordinating robots, or production systems in smart factories. These systems are referred to as mechatronic systems or cyber-physical systems (CPS)[aca11]. The number of such mechatronic systems in our world is growing rapidly [Pal08]. Mechatronic systems are developed in a joint effort by mechanical engineers, electrical engineers, control engineers, and software engineers [VDI04a]. Innovation in mechatronic systems is largely driven by embedded software. For example, it has been estimated that the current generation of upper class cars will contain about one gigabyte of software [PBKS07]. Mechatronic systems pose a challenge for software development as their software has to execute in a safety-critical, real-time environment, ie, human life may be harmed if the software does not always produce correct results on time. As a consequence, the software must be correct in its first release. Therefore, incremental testing-based development approaches are not applicable to such software. Instead, a software engineering method for mechatronic systems has to provide effective and efficient means to develop the software and prove its correctness.", "num_citations": "36\n", "authors": ["44"]}
{"title": "An industrial case study on quality impact prediction for evolving service-oriented software\n", "abstract": " Systematic decision support for architectural design decisions is a major concern for software architects of evolving service-oriented systems. In practice, architects often analyse the expected performance and reliability of design alternatives based on prototypes or former experience. Model-driven prediction methods claim to uncover the tradeoffs between different alternatives quantitatively while being more cost-effective and less error-prone. However, they often suffer from weak tool support and focus on single quality attributes. Furthermore, there is limited evidence on their effectiveness based on documented industrial case studies. Thus, we have applied a novel, model-driven prediction method called Q-ImPrESS on a large-scale process control system consisting of several million lines of code from the automation domain to evaluate its evolution scenarios. This paper reports our experiences with the method\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "36\n", "authors": ["44"]}
{"title": "Executing reconfigurations in hierarchical component architectures\n", "abstract": " Mechatronic systems reconfigure the structure of their software architecture, eg, to avoid hazardous situations or to optimize operational conditions like minimizing their energy consumption. As software architectures are typically build on components, reconfiguration actions need to respect the component structure. This structure should be hierarchical to enable encapsulated components. While many reconfiguration approaches for embedded real-time systems allow the use of hierarchically embedded components, ie, horizontal composition, none of them offers a modeling and verification solution to take hierarchical composition, ie, encapsulation, into account. In this paper, we present an extension to our existing modeling language, muml, to enable safe hierarchical reconfigurations. The two main extensions are (a) an adapted variant of the two-phase commit protocol to initiate reconfigurations which maintain\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "35\n", "authors": ["44"]}
{"title": "Parameter dependent performance specifications of software components\n", "abstract": " Performance predictions based on design documents aim at improving the quality of software architectures. In component-based architectures, it is difficult to specify the performance of individual components, because it depends on the deployment context of a component, which may be unknown to its developers. The way components are used influences the perceived performance, but most performance prediction approaches neglect this influence. In this paper, we present a specification notation based on annotated UML diagrams to explicitly model the influence of parameters on the performance of a software component. The UML specifications are transformed into a stochastical model that allows the prediction of response times as distribution functions. Furthermore, we report on a case study performed on an online store. The results indicate that more accurate predictions could be obtained with the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "34\n", "authors": ["44"]}
{"title": "Coupled model transformations\n", "abstract": " Model-driven performance prediction methods use abstract design models to predict the performance of the modelled system during early development stages. However, performance is an attribute of the running system and not its model. The system contains many implementation details not part of its model but still affecting the performance at run-time. Existing approaches neglect details of the implementation due to the abstraction underlying the design model. Completion components [26] deal with this problem, however, they have to be added manually to the prediction model. In this work, we assume that the system's implementation is generated by a chain of model transformations. In this scenario, the transformation rules determine the transformation result. By analysing these transformation rules, a second transformation can be derived which automatically adds details to the prediction model according to the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "33\n", "authors": ["44"]}
{"title": "The social bases of drug-induced experiences.\n", "abstract": " The social bases of drug-induced experiences. - Abstract - Europe PMC Sign in or create an account https://orcid.org Europe PMC Menu About About Europe PMC Preprints in Europe PMC Funders Joining Europe PMC Governance Roadmap Outreach Tools Tools overview ORCID article claiming Journal list Grant finder External links service RSS feeds Annotations Annotations submission service Developers Developer resources Articles RESTful API Grants RESTful API API use cases SOAP web service Annotations API OAI service Bulk downloads Developers Forum Help Help using Europe PMC Search syntax reference Contact us Contact us Helpdesk Feedback Twitter Blog Tech blog Developer Forum Europe PMC plus Search worldwide, life-sciences literature Search Advanced Search Recent history Saved searches Abstract The social bases of drug-induced experiences. Becker HS NIDA Research , 01 Mar , \u0393\u00c7\u00aa", "num_citations": "33\n", "authors": ["44"]}
{"title": "The mechatronicuml method: Model-driven software engineering of self-adaptive mechatronic systems\n", "abstract": " The software of mechatronic systems interacts with the system's physical environment. In such systems, an incorrect software may cause harm to human life. As a consequence, software engineering methods for developing such software need to enable developers to effectively and efficiently proof their correctness. This is further complicated by additional characteristics of mechatronic systems as self-adaptation and coordination with other systems. In this poster, we present MechatronicUML which is a model-driven software engineering method that especially considers these characteristics of self-adaptive mechatronic systems.", "num_citations": "32\n", "authors": ["44"]}
{"title": "A survey of fuzzy service matching approaches in the context of on-the-fly computing\n", "abstract": " In the last decades, development turned from monolithic software products towards more flexible software components that can be provided on world-wide markets in form of services. Customers request such services or compositions of several services. However, in many cases, discovering the best services to address a given request is a tough challenge and requires expressive, gradual matching results, considering different aspects of a service description, eg, inputs/ouputs, protocols, or quality properties. Furthermore, in situations in which no service exactly satisfies the request, approximate matching which can deal with a certain amount of fuzziness becomes necessary. There is a wealth of service matching approaches, but it is not clear whether there is a comprehensive, fuzzy matching approach which addresses all these challenges. Although there are a few service matching surveys, none of them is able to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "32\n", "authors": ["44"]}
{"title": "What do they really learn at college?\n", "abstract": " SELECTION 8 What Do They Really Learn at College?* Howard S. Becker W hen we talk of education, we ordinarily refer to the conventional institutions in which it is carried on: elementary schools, secondary schools, colleges and universities, graduateand professional schools. W hen we talk of what students learn at school, we usually refer to the things adults wantthemto learn there. W hatdo people learn as they grow up in our society? W heredo they learn it? It maybethat the important things that happen to students in college do not happen in the library, the laboratory, or in the classroom. Most middle-class boys and girls graduate from high school and go on to college. M any, perhapsmost, college-goers learn in college precisely what they need to knowto get along as adults in a middle-class world. T he middle-class worlds of business and the professions demandanumber of specific skills and abilities and the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "29\n", "authors": ["44"]}
{"title": "Consciousness, power and drug effects\n", "abstract": " Scientists no longer believe that a drug has a simple physiological action, essentially the same in all humans. Experimcntal, anthropological and sociological evidence have convinced most observers that drug effects vary greatly, depending on variations in the physiology and psychology of the persons taking them, on the state the person is in when he ingests the drug, and on the social situation in which drug ingestion occurs. We can understand the social context of drug experiences better by showing how their character depends on the amount and kind of knowledge available to the person taking the drug. Since distribution of knowledge is a function of the social organization of the groups in which drugs are used, drug experiences vary with variations in social organization. I explore that possibility in three quite different settings of drug use: the illegal use of drugs for pleasure, the use of medically prescribed\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "26\n", "authors": ["44"]}
{"title": "Parametric performance contracts for software components and their compositionality\n", "abstract": " The performance of a software component heavily depends on the environment of the component. As a software component only justifies its investment when deployed in several environments, one can not specify the performance of a component as a constant (eg, as a single value or distribution of values in its interface). Hence, classical component contracts allowing to state the component\u0393\u00c7\u00d6s performance as a post-condition, if the environment realises a specific performance stated in the precondition, do not help. This fixed pair of pre-and postcondition do not model that a component can have very different performance figures depending on its context. Instead of that, parametric contracts are needed for specifying the environmental dependency of the component\u0393\u00c7\u00d6s provided performance. In this paper we discuss the specification of such dependencies for the performance metric response time. We model the statistical distribution of response time in dependency of the distribution of response times of environmental services.", "num_citations": "25\n", "authors": ["44"]}
{"title": "Workload-aware system monitoring using performance predictions applied to a large-scale e-mail system\n", "abstract": " Offering services in the internet requires a dependable operation of the underlying software systems with guaranteed quality of service. The workload of such systems typically significantly varies throughout a day and thus leads to changing resource utilisations. Existing system monitoring tools often use fixed threshold values to determine if a system is in an unexpected state. Especially in low load situations, deviations from the system's expected behaviour are detected too late if fixed value thresholds (leveled for peak loads) are used. In this paper, we present our approach of a workload-aware performance monitoring process based on performance prediction techniques. This approach allows early detections of performance problems before they become critical. We applied our approach to the e-mail system operated by Germany's largest e-mail provider, the 1&1 Internet AG. This case study demonstrates the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "22\n", "authors": ["44"]}
{"title": "Engineering Scalable, Elastic, and Cost-Efficient Cloud Computing Applications: The CloudScale Method\n", "abstract": " This book provides an overview of the problems involved in engineering scalable, elastic, and cost-efficient cloud computing services and describes the CloudScale method\u0393\u00c7\u00f6a description of rescuing tools and the required steps to exploit these tools. It allows readers to analyze the scalability problem in detail and identify scalability anti-patterns and bottlenecks within an application. With the CloudScale method, software architects can analyze both existing and planned IT services.", "num_citations": "20\n", "authors": ["44"]}
{"title": "Transforming operational profiles of software components for quality of service predictions\n", "abstract": " Current Quality-of-Service (QoS) predictions methods for component-based software systems disregard the influence of the operational profile for anticipating an architecture\u0393\u00c7\u00d6s performance, reliability, security or safety. The operational profile captures the set of inputs and outputs to a software components. We argue, that a detailed operational profile especially for software components is necessary for accurate QoS-predictions and that a standardised form of it is needed. We demonstrate that components act as transformers to an operational profile and discuss that this transformation has to be described, so that QoS prediction methods are able to deliver appropriate results for component-based architectures.", "num_citations": "19\n", "authors": ["44"]}
{"title": "CAUS: an elasticity controller for a containerized microservice\n", "abstract": " Recent trends towards microservice architectures and containers as a deployment unit raise the need for novel adaptation processes to enable elasticity for containerized microservices. Microservices facing unpredictable workloads need to react fast and match the supply as closely as possible to the demand in order to guarantee quality objectives and to keep costs at a minimum. Current state-of-the-art approaches, that react on conditions which reflect the need to scale, are either slow or lack precision in supplying the demand with the adequate capacity. Therefore, we propose a novel heuristic adaptation process which enables elasticity for a particular containerized microservice. The proposed method consists of two mechanisms that complement each other. One part reacts to changes in load intensity by scaling container instances depending on their processing capability. The other mechanism manages\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "18\n", "authors": ["44"]}
{"title": "Towards modeling reconfiguration in hierarchical component architectures\n", "abstract": " Today's real-time embedded systems operate in frequently changing environments on which they react by self-adaptations. Such an approach needs adequate modeling support of these reconfigurations to enable verification of safety properties, eg, by timed model checking. Component-based development of such systems realizes these self-adaptations by structural reconfigurations of components and their connectors. However, component models proposed in literature do not support reconfigurable components in real-time embedded context but focus on other domains like business information systems. In this paper, we present an extension of our modeling language MechatronicUML to support structural reconfigurations taking the specific requirements of our domain into account. Based on the proposed extension we outline our research roadmap to achieve verification and realization of systems modeled in\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "18\n", "authors": ["44"]}
{"title": "Archimetrix: Improved software architecture recovery in the presence of design deficiencies\n", "abstract": " Maintaining software systems requires up-to-date models of these systems to systematically plan, analyse and execute the necessary reengineering steps. Often, no or only outdated models of such systems exist. Thus, a reverse engineering step is needed that recovers the system's components, subsystems and connectors. However, reverse engineering methods are severely impacted by design deficiencies in the system's code base, e.g., they lead to wrong component structures. Several approaches exist today for the reverse engineering of component-based systems, however, none of them explicitly integrates a systematic design deficiency removal into the process to improve the quality of the reverse engineered architecture. Therefore, in our Archimetrix approach, we propose to regard the most relevant deficiencies with respect to the reverse engineered component-based architecture and support\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "18\n", "authors": ["44"]}
{"title": "Predicting Software Component Performance: On the Relevance of Parameters for Benchmarking Bytecode and APIs\n", "abstract": " Performance prediction of component-based software systems is needed for systematic evaluation of design decisions, but also when an application\u0393\u00c7\u00d6s execution system is changed. Often, the entire application cannot be benchmarked in advance on its new execution system due to high costs or because some required services cannot be provided there. In this case, performance of bytecode instructions or other atomic building blocks of components can be used for performance prediction. However, the performance of bytecode instructions depends not only on the execution system they use, but also on their parameters, which are not considered by most existing research. In this paper, we demonstrate that parameters cannot be ignored when considering Java bytecode. Consequently, we outline a suitable benchmarking approach and the accompanying challenges.", "num_citations": "18\n", "authors": ["44"]}
{"title": "Reengineering component-based software systems with archimetrix\n", "abstract": " Many software development, planning, or analysis tasks require an up-to-date software architecture documentation. However, this documentation is often outdated, unavailable, or at least not available as a formal model which analysis tools could use. Reverse engineering methods try to fill this gap. However, as they process the system\u0393\u00c7\u00d6s source code, they are easily misled by design deficiencies (e.g., violations of component encapsulation) which leaked into the code during the system\u0393\u00c7\u00d6s evolution. Despite the high impact of design deficiencies on the quality of the resulting software architecture models, none of the surveyed related works is able to cope with them during the reverse engineering process. Therefore, we have developed the Archimetrix approach which semiautomatically recovers the system\u0393\u00c7\u00d6s concrete architecture in a formal model while simultaneously detecting and removing design\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "17\n", "authors": ["44"]}
{"title": "Evaluating performance of software architecture models with the Palladio component model\n", "abstract": " Techniques from model-driven software development are useful to analyse the performance of a software architecture during early development stages. Design models of software models can be transformed into analytical or simulation models, which enable analyzing the response times, throughput, and resource utilization of a system before starting the implementation. This chapter provides an overview of the Palladio Component Model (PCM), a special modeling language targeted at model-driven performance predictions. The PCM is accompanied by several model transformations, which derive stochastic process algebra, queuing network models, or Java source code from a software design model. Software architects can use the results of the analytical models to evaluate the feasibility of performance requirements, identify performance bottlenecks, and support architectural design decisions quantitatively\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "17\n", "authors": ["44"]}
{"title": "An empirical investigation of the effort of creating reusable, component-based models for performance prediction\n", "abstract": " Model-based performance prediction methods aim at evaluating the expected response time, throughput, and resource utilisation of a software system at design time, before implementation. Existing performance prediction methods use monolithic, throw-away prediction models or component-based, reusable prediction models. While it is intuitively clear that the development of reusable models requires more effort, the actual higher amount of effort has not been quantified or analysed systematically yet. To study the effort, we conducted a controlled experiment with 19 computer science students who predicted the performance of two example systems applying an established, monolithic method (Software Performance Engineering) as well as our own component-based method (Palladio). The results show that the effort of model creation with Palladio is approximately 1.25 times higher than with SPE in our\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "16\n", "authors": ["44"]}
{"title": "Transactional execution of hierarchical reconfigurations in cyber-physical systems\n", "abstract": " Cyber-physical systems reconfigure the structure of their software architecture, e.g., to avoid hazardous situations and to optimize operational conditions like their energy consumption. These reconfigurations have to be safe so that the systems protect their users or environment against harmful conditions or events while changing their structure. As software architectures are typically built on components, reconfiguration actions need to take into account the component structure. This structure should support vertical composition to enable hierarchically encapsulated components. While many reconfiguration approaches for cyber-physical and embedded real-time systems allow the use of hierarchically embedded components, i.e., vertical composition, none of them offers a modeling and verification solution to take hierarchical composition, i.e., encapsulation, into account thus limiting reuse and compositional\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "14\n", "authors": ["44"]}
{"title": "A tool suite for the model-driven software engineering of cyber-physical systems\n", "abstract": " Cyber-physical systems, eg, autonomous cars or trains, interact with their physical environment. As a consequence, they commonly have to coordinate with other systems via complex message communication while realizing safety-critical and real-time tasks. As a result, those systems should be correct by construction. Software architects can achieve this by using the MechatronicUML process and language. This paper presents the MechatronicUML Tool Suite that offers unique features to support the MechatronicUML modeling and analyses tasks.", "num_citations": "14\n", "authors": ["44"]}
{"title": "Apps against the spread: Privacy implications and user acceptance of COVID-19-related smartphone apps on three continents\n", "abstract": " The COVID-19 pandemic has fueled the development of smartphone applications to assist disease management. Many \u0393\u00c7\u00a3corona apps\u0393\u00c7\u00a5 require widespread adoption to be effective, which has sparked public debates about the privacy, security, and societal implications of government-backed health applications. We conducted a representative online study in Germany (n= 1003), the US (n= 1003), and China (n= 1019) to investigate user acceptance of corona apps, using a vignette design based on the contextual integrity framework. We explored apps for contact tracing, symptom checks, quarantine enforcement, health certificates, and mere information. Our results provide insights into data processing practices that foster adoption and reveal significant differences between countries, with user acceptance being highest in China and lowest in the US. Chinese participants prefer the collection of personalized data, while\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "12\n", "authors": ["44"]}
{"title": "Mechatronicuml-syntax and semantics\n", "abstract": " Innovation in today\u0393\u00c7\u00d6s technical systems is largely driven by embedded software. For example, it has been estimated that the current generation of upper class cars will contain about one gigabyte of software [PBKS07]. Technical systems pose a challenge for software development as they are often employed in a safety-critical context and they operate under tight resource constraints.The trend of software integration accelerates as more and more embedded devices are not working in isolation but heavily interact and coordinate with other parts of the technical system. This requires discrete state-based software in addition to the previously used continuous controllers [Kil05] for controlling the dynamic behavior of the physical part of the system. This leads to complex hybrid embedded software. This is even more the case in systems of systems. There, autonomous systems coordinate and communicate in an ad-hoc fashion [SW07]. In this case, the network topology is not fixed at design time but rather adapts itself at run time. Finally, the integration of self-X behavior [CdLG+ 09], like self-adaptation, selfoptimization, self-organizing, and self-healing, is another trend in innovative systems. Again, software plays an important part in realizing this behavior. All these trends lead to complex technical systems whose structure and behavior cannot be fully determined a priori. The key issue for the successful development of such systems is handling the inherent complexity. Therefore appropriate development methods and languages as well as supporting tools are required.", "num_citations": "12\n", "authors": ["44"]}
{"title": "An empirical investigation of the applicability of a component-based performance prediction method\n", "abstract": " Component-based software performance engineering (CBSPE) methods shall enable software architects to assess the expected response times, throughputs, and resource utilization of their systems already during design. This avoids the violation of performance requirements. Existing approaches for CBSPE either lack tool support or rely on prototypical tools, who have only been applied by their authors. Therefore, industrial applicability of these methods is unknown. On this behalf, we have conducted a controlled experiment involving 19 computer science students, who analysed the performance of two component-based designs using our Palladio performance prediction approach, as an example for a CBSPE method. Our study is the first of its type in this area and shall help to mature CBSPE to industrial applicability. In this paper, we report on results concerning the prediction accuracy achieved by the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "12\n", "authors": ["44"]}
{"title": "Textual views in model driven engineering\n", "abstract": " Building views on abstract models is one of the key concepts of model-driven engineering. Different views help to present concepts behind a model in a way that they can be understood and edited by different stakeholders or developers in different roles. Within graphical modelling several approaches exist allowing the definition of explicit holistic, partial or combined graphical views for models.On the other hand several frameworks that provide textual editing support for models have been presented over recent years. However, the combination of both principals, meaning textual, editable and decorating views is lacking in all of these approaches. In this paper, we introduce a textual decorator approach that allows to separately store and manage the textual concrete syntax from the actual abstract model elements. Thereby we allow to define textual views on models that may be partial and/or overlapping concerning\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "11\n", "authors": ["44"]}
{"title": "Quality of service modeling language\n", "abstract": " This chapter gives an overview over the the Quality of Service Modeling Language (QML), a language which can be used to describe QoS offerings or needs of specified services.", "num_citations": "11\n", "authors": ["44"]}
{"title": "Performance-related metrics in the ISO 9126 standard\n", "abstract": " ISO 9126 [243, 244, 245] is a standard which can be used to describe the quality of software systems. It is based on a quality model that is illustrated in part one of the standard [243]. This model distinguishes quality attributes into internal and external attributes. Internal metrics depend on knowledge on the internal details of the respective software. External metrics can be measured without knowing internal details. Furthermore, the quality model introduces characteristics and sub-characteristics which are abstractions of the actual attributes. For example, Usability is an abstraction of Learnability, Understandability, and Operability which each itself again abstracts from the different attributes.", "num_citations": "10\n", "authors": ["44"]}
{"title": "The architectural template method: templating architectural knowledge to efficiently conduct quality\u0393\u00c7\u00c9of\u0393\u00c7\u00c9service analyses\n", "abstract": " Software architects plan the realization of software systems by assessing design decisions on the basis of architectural models. Using these models as input, architectural analyses assess the impact of architects' decisions on quality\u0393\u00c7\u00c9of\u0393\u00c7\u00c9service properties. While the creation of suitable architectural models requires software architects to apply complex architectural knowledge, for example, in the form of established architectural styles and patterns, current architectural analyses lack support for directly reusing such knowledge. This lack points to an unused potential to make the work of software architects more effective and efficient. To use this potential, we introduce the architectural template (AT) method, an engineering method that makes design\u0393\u00c7\u00c9time analyses of quality\u0393\u00c7\u00c9of\u0393\u00c7\u00c9service properties of software systems more efficient. The AT method allows to quantify quality\u0393\u00c7\u00c9of\u0393\u00c7\u00c9service properties on the basis of reusable\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["44"]}
{"title": "Parallelization, modeling, and performance prediction in the multi-/many core area: A systematic literature review\n", "abstract": " Context: Software developers face complex, connected, and large software projects. The development of such systems involves design decisions that directly impact the quality of the software. For an early decision making, software developers can use model-based prediction approaches for (non-)functional quality properties. Unfortunately, the accuracy of these approaches is challenged by newly introduced hardware features like multiple cores within a single CPU (multicores) and their dependence on shared memory and other shared resources. Objectives: Our goal is to understand whether and how existing model-based performance prediction approaches face this challenge. We plan to use gained insights as foundation for enriching existing prediction approaches with capabilities to predict systems running on multicores. Methods: We perform a Systematic Literature Review (SLR) to identify current model\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["44"]}
{"title": "Market-optimized service specification and matching\n", "abstract": " Various approaches in service engineering are based on service markets where brokers use service matching in order to perform service discovery. For matching, a broker translates the specifications of providers\u0393\u00c7\u00d6 services and requesters\u0393\u00c7\u00d6 requirements into her own specification language, in order to check their compliance using a matcher. The broker\u0393\u00c7\u00d6s success depends on the configuration of her language and its matcher because they influence important properties like the effort for providers and requesters to create suitable specifications as well as accuracy and runtime of matching. However, neither existing service specification languages, nor existing matching approaches are optimized in such way. Our approach automatically provides brokers with an optimal configuration of a language and its matcher to improve her success in a given market with respect to her strategy. The approach is based on\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "9\n", "authors": ["44"]}
{"title": "The mechatronicuml design method\u0393\u00c7\u00f4process, syntax, and semantics\n", "abstract": " Innovation in today\u0393\u00c7\u00d6s technical systems is largely driven by embedded software. For example, it has been estimated that the current generation of upper class cars will contain about one gigabyte of software [PBKS07]. Technical systems pose a challenge for software development as they are often employed in a safety-critical context and they operate under tight resource constraints.The trend of software integration accelerates as more and more embedded devices are not working in isolation but heavily interact and coordinate with other parts of the technical system. This requires discrete state-based software in addition to the previously used continuous controllers [Kil05] for controlling the dynamic behavior of the physical part of the system. This leads to complex hybrid embedded software. This is even more the case in systems of systems. There, autonomous systems coordinate and communicate in an ad-hoc fashion [SW07]. In this case, the network topology is not fixed at design time but rather adapts itself at run time. Finally, the integration of self-X behavior [CdLG+ 09], like self-adaptation, selfoptimization, self-organizing, and self-healing, is another trend in innovative systems. Again, software plays an important part in realizing this behavior. All these trends lead to complex technical systems whose structure and behavior cannot be fully determined a priori. The key issue for the successful development of such systems is handling the inherent complexity. Therefore appropriate development methods and languages as well as supporting tools are required.", "num_citations": "8\n", "authors": ["44"]}
{"title": "Evidencia visual: un s\u251c\u2310ptimo hombre, la generalizaci\u251c\u2502n especificada y el trabajo del lector\n", "abstract": " \u252c\u2510Qu\u251c\u2310 tipo de pruebas nos dan las im\u251c\u00edgenes fotogr\u251c\u00edficas? Una an\u251c\u2310cdota de un cr\u251c\u00a1tico de fotograf\u251c\u00a1a burlado en los a\u251c\u2592os 60 explicita las dificultades de establecer \u0393\u00c7\u00a3la verdad\u0393\u00c7\u00a5 de las fotograf\u251c\u00a1as. La obra cl\u251c\u00edsica de John Berger y Jean Mohr, Un s\u251c\u2310ptimo hombre (1974), proporciona una s\u251c\u2502lida y ejemplar evidencia textual y fotogr\u251c\u00edfica sobre un fen\u251c\u2502meno social importante: las migraciones contempor\u251c\u00edneas de los trabajadores emigrantes del sur europeo en el industrializado norte de la misma Europa, all\u251c\u00ed por la d\u251c\u2310cada de los 60 y principios de los 70 del siglo pasado.  Palabras clave: fotograf\u251c\u00a1a, evidencia visual, Jean Mohr, John Berger, trabajadores emigrantes, relaci\u251c\u2502n texto/imagen  Abstract  What kind of evidence do photographic images give us? A small story of a deceived photographic critic from the 1960s explains the difficulties of establishing", "num_citations": "8\n", "authors": ["44"]}
{"title": "Systematic refinement of performance models for concurrent component-based systems\n", "abstract": " Model-driven performance prediction methods require detailed design models to evaluate the performance of software systems during early development stages. However, the complexity of detailed prediction models and the semantic gap between modelled performance concerns and functional concerns prevents many developers to address performance. As a solution to this problem, systematic model refinements, called completions, hide low-level details from developers. Completions automatically integrate performance-relevant details into component-based architectures using model-to-model transformations. In such scenarios, conflicts between different completions are likely. Therefore, the application order of completions must be determined unambiguously in order to reduce such conflicts. Many existing approaches employ the concept of performance completions to include performance-relevant details to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "8\n", "authors": ["44"]}
{"title": "Ending campus drug incidents\n", "abstract": " The use of drugs-primarily marijuana and LSD-has become an increasingly important and time-consuming problem on college campuses. Much of the thinking and writing (that done by adults, anyway) focuses on the drug use itself, asking why so many students take drugs and what can be done to prevent them, or lessen the impact of their use of drugs.But instead of asking why students use drugs, let us ask how a campus comes to have a drug incident-thus suggesting that we ought to be concerned with a problem somewhat different from the one we conventionally are. I propose this, first, because it is very likely impossible, given our resources and our will, to stop students from using drugs. No college administration has the personnel to root out drug use by itself.(It may try, however, to achieve the same end by opening the college to undercover agents of offcampus police forces, or it may-as in the recent action at\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "8\n", "authors": ["44"]}
{"title": "History, Culture and Subjective Experience: An Exploration of the Social Bases of Drug-Induced Experiences\n", "abstract": " The physiological effects of drugs can be ascertained by standard techniques of physiological and pharmacological research. Even if physiologically observable effects are substantially the same in all members of the species, individuals can vary widely in those to which they choose to pay attention. A user suffering from drug-induced anxiety may also come into contact with non-users who will offer him definitions, depending on their own perspectives and experiences, that may validate the diagnosis of\" going crazy\" and thus prolong the episode, possibly producing relatively permanent disability. These non-users include family members and police, but most important among them are psychiatrists and psychiatrically oriented physicians. Physicians, confronted with a case of drug-induced anxiety and lacking specific knowledge of its character or proper treatment, rely on a kind of generalized diagnosis. A number of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["44"]}
{"title": "PBlaman: performance blame analysis based on Palladio contracts\n", "abstract": " In performance\u0393\u00c7\u00c9driven software engineering, the performance of a system is evaluated through models before the system is assembled. After assembly, the performance is then validated using performance tests. When a component\u0393\u00c7\u00c9based system fails certain performance requirements during the tests, it is important to find out whether individual components yield performance errors or whether the composition of components is faulty. This task is called performance blame analysis. Existing performance blame analysis approaches and also alternative error analysis approaches are restricted, because they either do not employ expected values, use expected values from regression testing, or use static developer\u0393\u00c7\u00c9set limits. In contrast, this paper describes the new performance blame analysis approach PBlaman that builds upon our previous work and that employs the context\u0393\u00c7\u00c9portable performance contracts of\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["44"]}
{"title": "Decision support via automated metric comparison for the palladio-based performance blame analysis\n", "abstract": " When developing component-based systems, we incorporate third-party black-box components. For each component, performance contracts have been specified by their developers. If errors occur when testing the system built from these components, it is very important to find out whether components violate their performance contracts or whether the composition itself is faulty. This task is called performance blame analysis. In our previous work we presented a performance blame analysis approach that blames components based on a comparison of response time values from the failed test case to expected values derived from the performance contract. In that approach, the system architect needs to manually assess if the test data series shows faster or slower response times than the data derived from the contract. This is laborious as the system architect has to do this for each component operation. In this paper\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["44"]}
{"title": "The palladio component model\n", "abstract": " The Palladio Component Model (PCM) has been developed over the last 5 years. Today it is a mature modeling language for modeling component-based or service-oriented software systems with a special focus on predicting extrafunctional properties of the system based on its constituting components. The PCM highly relies on model-driven software development techniques for this and uses automated transformations into well-known prediction models or simulation systems. It is supported by a mature, industry proven tool set based on the Eclipse platform. The tutorial presents the PCM\u0393\u00c7\u00d6s foundational ideas from the area of component-based or service-oriented software development, its analysis capabilities, its tooling support, and possible extension points. In the component-based foundations, the tutorial defines the term component and presents components in different phases of their life-cycle. The discussion\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "7\n", "authors": ["44"]}
{"title": "Experience of pragmatically combining RE methods for performance requirements in industry\n", "abstract": " To meet end-user performance expectations, precise performance requirements are needed during development and testing, e.g., to conduct detailed performance and load tests. However, in practice, several factors complicate performance requirements elicitation: lacking skills in performance requirements engineering, outdated or unavailable functional specifications and architecture models, the specification of the system's context, lack of experience to collect good performance requirements in an industrial setting with very limited time, etc. From the small set of available non-functional requirements engineering methods, no method exists that alone leads to precise and complete performance requirements with feasible effort and which has been reported to work in an industrial setting. In this paper, we present our experiences in combining existing requirements engineering methods into a performance\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "6\n", "authors": ["44"]}
{"title": "Incremental Updates for Textual Modelling of Large Scale Models\n", "abstract": " Model-Driven Engineering (MDE) aims at improving the development of complex computer systems. Within this context textual concrete syntaxes for models are beneficial for many reasons. They foster usability and productivity because of their fast editing style, their usage of error markers, autocompletion and quick fixes. Several frameworks and tools from different communities for creating concrete textual syntaxes for models emerged during recent years. However, open issues are incremental parsing and model updating as well as the handling and synchronisation of partial and federated views with the underlying model. In this paper we present an approach for concrete textual syntaxes that makes use of incremental parsing and transformation techniques.", "num_citations": "6\n", "authors": ["44"]}
{"title": "Empirische Bewertung von Performanz-Vorhersageverfahren f\u251c\u255dr Software Architekturen\n", "abstract": " Die Architektur eines Software-Systems beeinflusst ma\u251c\u0192geblich seine Qualit\u251c\u00f1tseigenschaften wie Performanz oder Zuverl\u251c\u00f1ssigkeit. Daher sind Architektur\u251c\u00f1nderungen oft die einzige M\u251c\u2562glichkeit, M\u251c\u00f1ngel bei diesen Qualit\u251c\u00f1tseigenschaften zu beheben. Je sp\u251c\u00f1ter diese \u251c\u00e4nderungen an der Architektur w\u251c\u00f1hrend des Software-Entwicklungsprozesses vorgenommen werden, desto teurer und riskanter sind sie. Aus diesem Grund ist eine fr\u251c\u255dhzeitige Analyse verschiedener Architektur-Entwurfsalternativen bez\u251c\u255dglich ihrer Auswirkungen auf Qualit\u251c\u00f1tseigenschaften vorteilhaft. Dieser Artikel beschreibt die Evaluation dreier verschiedener Performanz-Vorhersageverfahren f\u251c\u255dr Software-Architekturen hinsichtlich ihrer Eignung, korrekte Empfehlungen f\u251c\u255dr fr\u251c\u255dhzeitige Entwurfsentscheidungen zu geben. Zus\u251c\u00f1tzlich sollen diese Vorhersageverfahren pr\u251c\u255dfen, ob extern vorgegebene Performanz-Anforderungen realisierbar sind. Die Performanz-Vorhersageverfahren SPE\u0393\u00c7\u00a3, Capacity Planning\u0393\u00c7\u00a3 und \u0393\u00c7\u20a7umlPSI\u0393\u00c7\u00a3 wurden empirisch durch 31 Teilnehmer untersucht, die eine Menge vorgegebener Alternativen beim Entwurf der Architektur eines Webservers zu bewerten hatten. Die Ergebnisse zeigen, dass Entwurfsalternativen mit allen Verfahren richtig bewertet wurden, sofern deutliche Auswirkungen auf die Performanz vorhanden waren. Ohne den Einsatz der Performanz-Vorhersageverfahren wurden h\u251c\u00f1ufiger weniger performante Entwurfsalternativen vorgeschlagen. Dar\u251c\u255dber hinaus konnte das Verfahren Capacity Planning die absoluten Werte bei den meisten Entwurfsalternativen relativ genau vorhersagen.", "num_citations": "6\n", "authors": ["44"]}
{"title": "Gropius\u0393\u00c7\u00f6A Tool for Managing Cross-component Issues\n", "abstract": " Modern software systems often are structured as distributed component-based architectures, such as microservice architectures. However, such systems come with significant challenges in cross-component issue management. Each component usually manages its issues in an independent issue management system, and conventional issue management systems only have a project-specific scope. Therefore, issues that affect multiple components or propagate across various components cannot be displayed. Furthermore, issues cannot be linked semantically to issues in other components. Instead, emergency solutions, such as a URL to the other issue, must be used. This makes it challenging to recognize cross-component dependency information. This paper presents Gropius, a tool for integrated management of cross-component issues. Gropius graphically models such cross-component issues together with\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["44"]}
{"title": "An exploratory study of hardware reverse engineering\u0393\u00c7\u00f6technical and cognitive processes\n", "abstract": " Understanding the internals of Integrated Circuits (ICs), referred to as Hardware Reverse Engineering (HRE), is of interest to both legitimate and malicious parties. HRE is a complex process in which semi-automated steps are interwoven with human sense-making processes. Currently, little is known about the technical and cognitive processes which determine the success of HRE. This paper performs an initial investigation on how reverse engineers solve problems, how manual and automated analysis methods interact, and which cognitive factors play a role. We present the results of an exploratory behavioral study with eight participants that was conducted after they had completed a 14-week training. We explored the validity of our findings by comparing them with the behavior (stategies applied and solution time) of an HRE expert. The participants were observed while solving a realistic HRE task. We tested cognitive abilities of our participants and collected large sets of behavioral data from log files. By comparing the least and most efficient reverse engineers, we were able to observe successful strategies. Moreover, our analyses suggest a phase model for reverse engineering, consisting of three phases. Our results further indicate that the cognitive factor Working Memory (WM) plays a role in efficiently solving HRE problems. Our exploratory study builds the foundation for future research in this topic and outlines ideas for designing cognitively difficult countermeasures (\u0393\u00c7\u00a3cognitive obfuscation\u0393\u00c7\u00a5) against HRE.", "num_citations": "5\n", "authors": ["44"]}
{"title": "Integrating service matchers into a service market architecture\n", "abstract": " Service markets provide software components in the form of services. In order to enable a service discovery that satisfies service requesters and providers best, markets need automatic service matching: approaches for comparing whether a provided service satisfies a service request. Current markets, e.g., app markets, are limited to basic keyword-based search although many better suitable matching approaches are described in literature. However, necessary architectural decisions for the integration of matchers have a huge impact on quality properties like performance or security.               Architectural decisions wrt. service matchers have rarely been discussed, yet, and systematic approaches for their integration into service markets are missing. In this paper, we present a systematic integration approach including the definition of requirements and a discussion on architectural tactics. As a benefit, the\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "5\n", "authors": ["44"]}
{"title": "Towards the combination of clustering-based and pattern-based reverse engineering approaches\n", "abstract": " Reverse Engineering, i.e. the analysis of software for the purpose of recovering its design documentation, e.g. in form of the conceptual architecture, is an important area of software engineering. Today, two prevalent reverse engineering approaches have emerged: (1) the clustering-based approach which tries to analyze a given software system by grouping its elements based on metric values to provide the reverse engineer with an overview of the system and (2) the pattern-based approach which tries to detect predefined structural patterns in the software which can give insight about the original developers' intentions. These approaches operate on different levels of abstraction and have specific strengths and weaknesses. In this paper, we sketch an approach towards combining these techniques which can remove some of the specific shortcomings.", "num_citations": "5\n", "authors": ["44"]}
{"title": "Exploring the Mysteries of System-Level Test\n", "abstract": " System-level test, or SLT, is an increasingly important process step in today\u0393\u00c7\u00d6s integrated circuit testing flows. Broadly speaking, SLT aims at executing functional workloads in operational modes. In this paper, we consolidate available knowledge about what SLT is precisely and why it is used despite its considerable costs and complexities. We discuss the types or failures covered by SLT, and outline approaches to quality assessment, test generation and root-cause diagnosis in the context of SLT. Observing that the theoretical understanding for all these questions has not yet reached the level of maturity of the more conventional structural and functional test methods, we outline new and promising directions for methodical developments leveraging on recent findings from software engineering.", "num_citations": "4\n", "authors": ["44"]}
{"title": "Using performance models for planning the redeployment to infrastructure-as-a-service environments: a case study\n", "abstract": " Context: Performance models allow software architects to conduct what-if analyses, e.g., to assess deployment scenarios regarding performance. While a typical scenario is the redeployment to Infrastructure-as-a-Service (IaaS) environments, there is currently no empirical evidence that architects can apply performance models in such scenarios for accurate performance analyses and how much effort is required. Objectives: Therefore, we explore the applicability of software performance engineering for planning the redeployment of existing software applications to IaaS environments. Methods: We conduct a case study in which we apply performance engineering to redeploy a realistic existing application to IaaS environments. We select an online book shop implementation (CloudStore) as existing application and engineer a corresponding Palladio performance model. Subsequently, we compare analysis results\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["44"]}
{"title": "Towards a secure cloud usage for financial IT\n", "abstract": " Cloud Computing and Big Data are the current hot topics in research and industry. Based on the enormous amount of preliminary work, ranging from grid and distributed computing to data mining and clustering, to name only a few approaches, cloud computing has become a defacto standard for computing in general and data-intensive industry tasks in particular. Thus, a lot of questions about how to develop and implement such systems are already answered, but nonetheless, there is reservation to adopt such techniques in some business areas. Most of the reservations are due to security reasons, as in certain areas, like in the banking sector or in the health industry, high levels of security standards have been met for decades and those standards must not be weakened. This is the reason why we investigate-closely together with partners from the industry-how to overcome security concerns in the adoption of cloud computing in the financial industry. An introduction to our strategies is given with this paper.", "num_citations": "4\n", "authors": ["44"]}
{"title": "The MechatronicUML Method\u0393\u00c7\u00f4Process, Syntax, and Semantics\n", "abstract": " Innovation in today\u0393\u00c7\u00d6s technical systems is largely driven by embedded software. For example, it has been estimated that the current generation of upper class cars will contain about one gigabyte of software [PBKS07]. Technical systems pose a challenge for software development as they are often employed in a safety-critical context and they operate under tight resource constraints.The trend of software integration accelerates as more and more embedded devices are not working in isolation but heavily interact and coordinate with other parts of the technical system. This requires discrete state-based software in addition to the previously used continuous controllers [Kil05] for controlling the dynamic behavior of the physical part of the system. This leads to complex hybrid embedded software. This is even more the case in systems of systems. There, autonomous systems coordinate and communicate in an ad-hoc fashion [SW07]. In this case, the network topology is not fixed at design time but rather adapts itself at run time. Finally, the integration of self-X behavior [CdLG+ 09], like self-adaptation, selfoptimization, self-organizing, and self-healing, is another trend in innovative systems. Again, software plays an important part in realizing this behavior. All these trends lead to complex technical systems whose structure and behavior cannot be fully determined a priori. The key issue for the successful development of such systems is handling the inherent complexity. Therefore appropriate development methods and languages as well as supporting tools are required.", "num_citations": "4\n", "authors": ["44"]}
{"title": "Towards System Viewpoints to Specify Adaptation Models at Runtime\n", "abstract": " Current research focuses on the specification, analysis, and realisation of systems with self-* properties. Such systems are characterised by the fact that they react on changes in their environment by altering their own structure in order to maintain their non-functional properties. However, there is no standard engineering method to model such systems. In this paper, we propose a set of new system viewpoints and their views. Additionally we describe initial ideas of the properties we want to check based on the new system views.", "num_citations": "4\n", "authors": ["44"]}
{"title": "Service Architecture Meta Model\n", "abstract": " Service Architecture Meta Model | D3S D3S homepage For Students Research People Projects Software Publications Seminar Contact Service Architecture Meta Model Technical report Title: Service Architecture Meta Model Authors: S. Becker, L. Bulej, T. Bure\u253c\u00ed, P. Hn\u2500\u00a2tynka, L. Kapova, J. Kofro\u253c\u00ea, H. Koziolek, J. Kraft, R. Mirandola, J. Stammel, G. Tamburrelli, M. Trifu Publication: Technical report, Year: 2008 BibTeX: @techreport{becker_service_report_2008, title = {{Service Architecture Meta Model}}, author = {Becker, Steffen and Bulej, Lubom\u2500\u2592r and Bures, T. and Hnetynka, Petr and Kapova, Lucia and Kofron, Jan and Koziolek, Heiko and Kraft, Johan and Mirandola, Raffaella and Stammel, Johannes and Tamburrelli, Giordano and Trifu, Mircea}, year = {2008}, } \u252c\u2310 D3S Edit this page Department of Distributed and Dependable Systems Faculty of Mathematics and Physics Charles University Malostransk\u251c\u2310 n\u251c\u00edm\u2500\u00a2st\u251c\u00a1 25 1 \u0393\u00c7\u00aa", "num_citations": "4\n", "authors": ["44"]}
{"title": "Towards performance evaluation of component based software architectures\n", "abstract": " This paper reviews different approaches for predicting the performance of software architectures while keeping component based systems in mind. For these approaches we present classifying properties. We investigate formal analytical prediction models and execution based simulation models. In particular, we discuss network queuing models. As a result, we show the benefits and limitations of these models for predicting performance with respect to component based software architectures. Finally, we sketch future work on a mixed approach for component based performance evaluation, utilising both, simulations and predictions.", "num_citations": "4\n", "authors": ["44"]}
{"title": "St\u251c\u255dcklistenbasiertes Komponenten-Konfigurationsmanagement\n", "abstract": " In diesem Beitrag wird ein Konzept f\u251c\u255dr das Konfigurationsmanagement komponentenorientierter Anwendungen dargestellt. Dabei wird zun\u251c\u00f1chst der Begriff \u0393\u00c7\u20a7Konfigurationsmanagement \u0393\u00c7\u00a3n\u251c\u00f1her erl\u251c\u00f1utert und anschlie\u251c\u0192end die St\u251c\u255dcklistenorganisation als eine geeignete Methode f\u251c\u255dr das Konfigurationsmanagement beschrieben. Der Beitrag konzentriert sich auf die Entwicklung einer Vorgehensweise zur (automatisierten) Unterst\u251c\u255dtzung der Komponentenauswahl, die auf St\u251c\u255dcklisten, einem einheitlichen Spezifikationsrahmen und einer multiattributiven Entscheidungsfindung basiert. Abschlie\u251c\u0192end wird das \u251c\u00e4nderungsmanagement beschrieben, das ebenfalls zum Konfigurationsmanagement zu z\u251c\u00f1hlen ist.", "num_citations": "4\n", "authors": ["44"]}
{"title": "The applicability of palladio for assessing the quality of cloud-based microservice architectures\n", "abstract": " When adopting microservices, software architects have to make several design decisions which impact the quality of the application in terms of scalability, elasticity and cost-efficiency. A prominent model-driven architectural simulator that aids software architects in analysing and predicting the quality of their architecture is Palladio. There is active work on extending Palladio to support new needs, however, there is lack of evidence for its applicability in the context of microservice architectures. Therefore, we conduct a case study at a partner company where we apply Palladio to analyse the performance as well as to assess scalability, elasticity and cost-efficiency aspects of a cloud-based microservice application. In this work, we highlight some of the results which show that Palladio is able to predict the application performance with a sufficient accuracy. However, when assessing scalability, elasticity and cost\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["44"]}
{"title": "Towards performance engineering of model transformation\n", "abstract": " Model transformations are an essential operation on models which is applied at design time and even at run time. For this, the performance of transformations is an important aspect, which needs to be considered. The current research takes only the improvement of transformation engines into account but there is no method or tool support to help engineers to identify performance bottlenecks in their transformation definition. In this paper we present our proposed approach to develop a method for performance engineering of model transformations. This method should support engineers to improve the performance of their defined transformations by providing visualizations of reasons for performance problems and offering possible refactorings for a transformation which can improve its performance.", "num_citations": "3\n", "authors": ["44"]}
{"title": "Challenges in Multicore Performance Predictions\n", "abstract": " Software performance predictions are an established part of an engineering like software development process and therefore relevant to enable high quality and to ensure requirement fulfillment. Software Performance Engineers use for that model-based performance predictions approaches. However, current predictions approaches are based on the assumption of single core CPU systems. To enable Software Performance Engineers to further give accurate predictions also for multicore systems, which are by now state of the art, we need to adapt our current prediction models. On the poster, we discuss the upcoming challenges to be tackled to increase the accuracy of the performance predictions models.", "num_citations": "3\n", "authors": ["44"]}
{"title": "Cloud computing applications\n", "abstract": " Cloud computing focuses on elasticity, i.e., providing constant quality of service independent of workload. For achieving elasticity, cloud computing applications utilize virtualized infrastructures, distributed platforms, and other software-as-a-service offerings. The surge of cloud computing applications responds to the ability of cloud computing environments to only pay for utilized resources while saving upfront costs (e.g., buying and setting up infrastructure) and allowing for dynamic allocation of resources even in public-private hybrid scenarios.This chapter investigates the shift from classical three-tier web applications to such elastic cloud computing applications. After characterizing web applications, we describe cloud computing characteristics and derive how web applications can exploit these characteristics.Our results motivate novel requirements that have to be engineered and modeled, as further\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["44"]}
{"title": "The CloudScale Method for Managers\n", "abstract": " Having described the CloudScale method for engineering scalable cloud computing applications in the previous chapters, we explicitly address managers of software development processes in this chapter. It answers questions managers have in mind when considering the CloudScale method: Is it worth implementing the CloudScale method in my organization? What does it take? What are the benefits? What will be the costs? How should I get started? This chapter addresses all these questions and provides answers based on our own experience that we gained when introducing and applying the CloudScale method in practice. In the course of the chapter, we distinguish two types of managers: project managers, who are concerned with managing project teams that implement the business requirements, and technical managers, who manage the actual development efforts and take technical decisions\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["44"]}
{"title": "Model transformations in non-functional analysis\n", "abstract": " The quality assessment of software design models in early development phases can prevent wrong design decisions on the architectural level. As such wrong decisions are usually very cost-intensive to revert in late testing phases, model-driven quality predictions offer early quality estimates to prevent such erroneous decisions. By model-driven quality predictions we refer to analyses which run fully automated based on model-driven methods and tools. In this paper, we give an overview on the process of model-driven quality analyses used today with a special focus on issues that arise in fully automated approaches.", "num_citations": "3\n", "authors": ["44"]}
{"title": "Towards model-driven evolution of performance critical business information systems to cloud computing architectures\n", "abstract": " Migrating legacy applications to todays emerging cloud infrastructures is still challenging. In this paper, we sketch an approach, that combines reverse engineering and performance analyses for applications evolving to the cloud.", "num_citations": "3\n", "authors": ["44"]}
{"title": "Palladio-based performance blame analysis\n", "abstract": " Performance is an important quality attribute for business information systems. When a tester has spotted a performance error, the error is passed to the software developers to fix it. However, in component-based software development the tester has to do blame analysis first, ie the tester has to decide, which party is responsible to fix the error. If the error is a design or deployment issue, it can be assigned to the software architect or the system deployer. If the error is specific to a component, it needs to be assigned to the corresponding component developer. An accurate blame analysis is important, because wrong assignments of errors will cause a loss of time and money.", "num_citations": "3\n", "authors": ["44"]}
{"title": "Structuring complex story diagrams by polymorphic calls\n", "abstract": " In model-driven software engineering, model transformations occur frequently, eg, to transform platform independent models into platform specific models. Hybrid languages using imperative and declarative elements seem to be a promising approach as they integrate explicit control-flow with efficient matching. Story diagrams are such a hybrid model transformation language that combines UML activity diagrams and graph transformations in a graphical transformation language. Hitherto, story diagrams do not support structuring complex transformations into several independent story diagrams which can be called in a welldefined manner. This prevents rule reuse and hence significantly reduces the maintainability of the transformations. In this paper, we therefore extend story diagrams by explicit call activities that invoke other story diagrams and support polymorphic dispatching. We evaluate the benefits of such calls by revisiting an already implemented model transformation and discussing improvements due to our new call concept.", "num_citations": "3\n", "authors": ["44"]}
{"title": "Quality of Software Architectures Models and Architectures: 4th International Conference on the Quality of Software Architectures, QoSA 2008, Karlsruhe, Germany, October 14-17\u252c\u00e1\u0393\u00c7\u00aa\n", "abstract": " Models are used in all kinds of engineering disciplines to abstract from the various details of the modelled entity in order to focus on a specific aspect. Like a blueprint in civil engineering, a software architecture provides an abstraction from the full software system\u0393\u00c7\u00d6s complexity. It allows software designers to get an overview on the system under development and to analyze its properties. In this sense, models are the foundation needed for software development to become a true engineering discipline. Especially when reasoning on a software system\u0393\u00c7\u00d6s extra-functional properties, its software architecture carries the necessary information for early, design-time analyses. These analyses take the software architecture as input and can be used to direct the design process by allowing a systematic evaluation of different design alternatives. For example, they can be used to cancel out decisions which would lead to\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["44"]}
{"title": "Zur Soziologie abweichenden Verhaltens\n", "abstract": " \u0393\u00c7\u20a7Der Mensch mit abweichendem Verhalten ist ein Mensch, auf den diese Bezeichnung erfolgreich angewandt worden ist; abweichendes Verhalten ist Verhalten, das Menschen als solches bezeichnen \u0393\u00c7\u00a3: Es ist einer der klassischen S\u251c\u00f1tze der Devianzsoziologie in einem der Klassiker des Feldes. Howard S. Becker betont fernab von alten und simplistischen Fragen danach,\u0393\u00c7\u20a7warum Menschen Regeln brechen \u0393\u00c7\u00a3, welche Situationen und welche Prozesse dazu f\u251c\u255dhren, dass Menschen in Positionen geraten, in denen sie als \u0393\u00c7\u20a7Regelbrecher \u0393\u00c7\u00a3betitelt werden, wie sie mit diesen Positionen umgehen und sich auch gegen diese wehren.\" Au\u251c\u0192enseiter\" erschien erstmals 1963 in New York und wurde 1981 bei S. Fischer in deutscher \u251c\u00a3bersetzung publiziert. Seit den fr\u251c\u255dhen neunziger Jahren vergriffen, liegt seit 2014 eine von Michael Dellwing \u251c\u255dberarbeitete Version vor. In der nun neuesten Auflage enth\u251c\u00f1lt der Band zudem zwei\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "3\n", "authors": ["44"]}
{"title": "An exploratory study on performance engineering in model transformations\n", "abstract": " Model-Driven Software Engineering (MDSE) is a widely used approach to deal with the increasing complexity of software. This increasing complexity also leads to the fact that the models used and the model transformations applied become larger and more complex as well. This means that the execution performance of model transformations is gaining in importance. While improving the performance of model transformation execution engines has been a focus of the MDSE-community in the past, there does not exist any empirical study on how developers of model transformation deal with performance issues. Consequently, we conducted an exploratory mixed method study consisting of a quantitative online survey and a qualitative interview study. We used a questionnaire to investigate whether the performance of a transformation is actually important for transformation developers and whether they have already\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["44"]}
{"title": "An Exploratory Study on Performance Engineering in Model Transformations: Data of the mixed method study\n", "abstract": " Model-Driven Software Engineering is one way to deal with the increasing complexity of software being developed. The size and complexity of the software is also visible in the models, which are becoming larger and more complex as a result. This trend also affects the performance of model transformations, which are an important operation on these models. In the past, research has mainly focused on improving the performance of transformation engines, so there are currently no studies on how transformation developers deal with performance issues. Consequently, we conducted an exploratory mixed method study consisting of a quantitative online survey and a qualitative interview study to further investigate how developers deal with performance issues. The data set published here was generated during our study and consists of an interview guide, a code book, 13 transcribed and coded interviews and the data from the questionnaire that we collected on the interviewees.", "num_citations": "2\n", "authors": ["44"]}
{"title": "Akzeptanz von Corona-Apps in Deutschland vor der Einf\u251c\u255dhrung der Corona-Warn-App\n", "abstract": " Dieses Dokument pr\u251c\u00f1sentiert erste Ergebnisse einer Studie \u251c\u255dber die Wahrnehmung und Akzeptanz von Smartphone-Apps zur Bek\u251c\u00f1mpfung der Corona-Pandemie (\u0393\u00c7\u20a7Corona-Apps \u0393\u00c7\u00a3) in Deutschland. Die Studie wurde mittels eines repr\u251c\u00f1sentativen Online-Panels im Zeitraum vom 9. bis zum 15. Juni 2020 durchgef\u251c\u255dhrt und somit kurz vor dem Erscheinen der deutschen Corona-Warn-App. Die Ergebnisse zeigen, dass die Akzeptanz f\u251c\u255dr Kontaktverfolgungs-Apps innerhalb der deutschen Bev\u251c\u2562lkerung signifikant h\u251c\u2562her ist als f\u251c\u255dr andersartige Corona-Apps. Au\u251c\u0192erdem wurde festgestellt, dass pers\u251c\u2562nliche Erfahrungen mit dem Coronavirus sowohl die Nutzungsbereitschaft als auch die wahrgenommene N\u251c\u255dtzlichkeit von Corona-Apps erh\u251c\u2562hen. Diese Studie bildet den Auftakt zu einer Reihe von Studien, mit denen die pers\u251c\u2562nliche Einstellung zu Corona-Apps in verschiedenen L\u251c\u00f1ndern untersucht werden soll. Durch die Wiederholung zu verschiedenen Zeitpunkten im Verlauf der globalen Pandemie sollen au\u251c\u0192erdem Langzeiteffekte und \u251c\u00e4nderungen im zeitlichen Verlauf erforscht werden.", "num_citations": "2\n", "authors": ["44"]}
{"title": "Introduction: the struggle for power on the campus\n", "abstract": " So many colleges and universities have had their confrontation, so many unlikely ones, that administrators can now take it that whatever school has not been so favored soon will be. The causes and character of campus disorder consists of a change in the distribution of power among the people who act together to make up the college community. At the same time, colleges differ in the way power has been allocated and exercised in them. Any new accommodation will doubtless include some fundamental revisions of the status differences symbolized by the current violations of civility. Students will probably not get to tell professors what to do. More likely professors will simply stop telling students what to do, leaving much more freedom of choice for everyone. The battle cry is\" Student Power\", but the result that is expected and hoped for is a freer system of Less Power.ABSTRACT", "num_citations": "2\n", "authors": ["44"]}
{"title": "Software architecture design assistants need controlled efficiency experiments: Lessons learned from a survey\n", "abstract": " Software architects use so-called software architecture design assistants to get tool-based, (semi-)automated support in engineering software systems. Compared to manual engineering, the main promise of such a support is that architects can create high-quality architectural designs more efficiently. Yet, current practice in evaluating whether this promise is kept is based on case studies conducted by the original authors of respective design assistants. The downside of such evaluations is that they are neither generalizable to thirdparty software architects nor can be used for quantitative efficiency comparisons between competing design assistants. To tackle this problem, we investigate how researchers can apply controlled experiments for evaluating the impact of software architecture design assistants on the efficiency of architects. For our investigation, we survey related controlled experiments. Based on this\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["44"]}
{"title": "Proceedings of the 2014 Symposium on Software Performance (SOSP'14): Joint Descartes/Kieker/Palladio Days\n", "abstract": " Performance is one of the most relevant quality attributes of any IT system. While good performance leads to high user satisfaction, poor performance lead to loss of users, perceivable unavailability of the system, or unnecessarily high costs of network or compute resources. Therefore, various techniques to evaluate, control, and improve the performance of IT systems have been developed, ranging from online monitoring and benchmarking to modeling and prediction. Experience shows, that for system design or later optimization, such techniques need to be applied in smart combination.Therefore, the Symposium on Software Performance brings together researchers and practitioners interested in all facets of software performance, ranging from modeling and prediction to monitoring and runtime management. The symposium is organized by three already established research groups, namely Descartes, Kieker, and Palladio, who use this symposium also as a joint developer and community meeting. Descartes\u0393\u00c7\u00d6 focus are techniques and tools for engineering self-aware computing systems designed for maximum dependability and efficiency. Kieker is a well-established tool and approach for monitoring software performance of complex, large, and distributed IT systems. Palladio is a likewise-established tool and approach for modeling software architectures of IT systems and for simulating their performance.", "num_citations": "2\n", "authors": ["44"]}
{"title": "Specifying Intra-Component Dependencies for Synthesizing Component Behaviors.\n", "abstract": " Cyber-physical systems, eg, cars, interact with their physical environment, underlie real-time constraints, and exchange messages with each other. An engineer can define their software using a componentbased architecture. An approach to manage the complexity of this task is to separate concerns by specifying the behavior of each component\u0393\u00c7\u00d6s port independently and, afterwards, synthesizing the component behavior based on the port\u0393\u00c7\u00d6s behaviors and their dependencies. Though, such a synthesis requires to specify the intra-component dependencies formally. However, for several dependencies that are commonly used, no formal language exists. In this paper, we present a language that enables the specification of all commonly used dependencies in the domain of cyber-physical systems. Moreover, we define the requirements for an intra-component dependency language, provide an extended synthesis process, and introduce the dependency kinds the language shall support.", "num_citations": "2\n", "authors": ["44"]}
{"title": "Modellgetriebene Software-Entwicklung\n", "abstract": " Modellgetriebene Software-Entwicklung - Research Portal, King's College, London King's College London King's main site Research portal Home Researchers Research Groups Research Outputs Research Funding Internal Research Outputs Theses . Journals Publishers Modellgetriebene Software-Entwicklung Research output: Chapter in Book/Report/Conference proceeding \u0393\u00c7\u2551 Chapter A Baier, S Becker, M Jung, K Krogmann, C Rottgers, N Streekmann, K Thoms, S Zschaler Overview Citation formats Original language English Title of host publication Handbuch der Software-Architektur. Editors R Reussner , W Hasselbring Publisher Dpunkt Verlag Pages 93 - 122 Number of pages 30 Published 2008 King's Authors S Zschaler (Informatics, Software Modelling and Applied Logic) Post to Twitter Post to FaceBook Post to Digg View graph of relations By the same authors Finding Subgraphs with Side Constraints Akg\u251c\u255dn\u0393\u00c7\u00aa", "num_citations": "2\n", "authors": ["44"]}
{"title": "A Survey on the Relevance of the Performance of Model Transformations: Data of the Participant Search and the Questionnaire\n", "abstract": " There are a number of techniques for analyzing and improving the performance of programs written in a general-purpose language. For model transformation languages such techniques are still unknown. These are domain-specific languages, which, simply said, are used to update models or create new models. Thus, these languages realize important operations in the context of Model-Driven Development. Current research about the performance of transformations is strongly focused on the transformation engine, which executes the transformations. Consequently, we conducted an online survey to examine whether techniques for analyzing and improving the performance of transformations are needed. Overall, our data set consists the results of the online survey and the information necessary to repeat the survey. The questionnaire was fully answered by 84 participants. Our data set includes the processed answers and the anonymized raw data. Additionally, we have performed hypothesis tests. Their results and the variables used for them are also part of our data set. In order to support the repeatability of our study, our data set contains not only our questionnaire, but also the results of the snowballing we used for the design of the questions Q9 and Q15. Furthermore, we have conducted a Systematic Literature Review (SLR) about the transformation languages Atlas Transformation Language (ATL), Henshin, QVTo and Viatra, to find suitable participants for our study. Therefore, our data set also contains information about the execution of this SLR and its results.", "num_citations": "1\n", "authors": ["44"]}
{"title": "Cross-Component Issue Metamodel and Modelling Language.\n", "abstract": " Software systems are often built out of distributed components developed by independent teams. As a result, issues of these components, such as bugs or feature requests, are typically managed in separate, isolated issue management systems. As a result, it is hard to keep an overview of issues affecting issues of other components. Managing issues in a component-specific scope comes with significant problems in the development process since managing such cross-component issues is error-prone and time-consuming. Therefore, the crosscomponent issue management system Gropius was developed in previous work, which is a tool for integrated cross-component issue management that acts as a wrapper across the independent components\u0393\u00c7\u00d6 issue management systems. This paper introduces the underlying metamodel of Gropius in detail and presents the graphical modelling language implemented by Gropius.", "num_citations": "1\n", "authors": ["44"]}
{"title": "Towards a parallel template catalogue for software performance predictions\n", "abstract": " Software Performance Engineers evaluate quality attributes (like response time) of software rich systems based on architectural models during early design time. Thereby, they use model-based approaches to analyze the software's behaviour and resource consumption. One prominent approach is the Palladio Component Model (PCM) which has been researched for over a decade. However, when it comes to multicore support or massive parallel execution the approaches still suffer from major drawbacks. Drawbacks include inaccurate prediction models, insufficient modelling languages, and missing tool support, to name just some of them.", "num_citations": "1\n", "authors": ["44"]}
{"title": "Highway to HAL\n", "abstract": " Since hardware oftentimes serves as the root of trust in our modern interconnected world, malicious hardware manipulations constitute a ubiquitous threat in the context of the Internet of Things (IoT). Hardware reverse engineering is a prevalent technique to detect such manipulations. Over the last years, an active research community has significantly advanced the field of hardware reverse engineering. Notably, many open research questions regarding the extraction of functionally correct netlists from Field Programmable Gate Arrays (FPGAs) or Application Specific Integrated Circuits (ASICs) have been tackled. In order to facilitate further analysis of recovered netlists, a software framework is required, serving as the foundation for specialized algorithms. Currently, no such framework is publicly available. Therefore, we provide the first open-source gate-library agnostic framework for gate-level netlist analysis. In this positional paper, we demonstrate the workflow of our modular framework HAL on the basis of two case studies and provide profound insights on its technical foundations.", "num_citations": "1\n", "authors": ["44"]}
{"title": "Campus Power Struggle: Transaction/Society Book Series\u0393\u00c7\u00f61\n", "abstract": " Campus Power Struggle traces the explosive evolution of the student political movement from the Berkeley Free Speech Movement of 1964 to armed confrontation at Cornell in 1969. From campus conflict as a microcosm of larger political struggles for self-determination, to student concern about infringements upon personal liberties, the studies in this book provide authoritative insight into unrest on American campuses. This volume represents sociology as the\"\" big news\"\" in its most impressive and involved style. No. l in the series. Contents: Introduction-The Struggle for Power on the Campus (Howard S. Becker). Beyond Berkeley (Joseph Gusfleld). Columbia: The Dynamics of a Student Revolution (Ellen Kay Tnmberger). The Crisis at San Francisco State (James McEvoy and Abraham Miller). Confrontation at Cornell (William H. Fried/and and Harry Edwards'). The Phantom Racist (Rita James Simon and James\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["44"]}
{"title": "7th Symposium on Software Performance (SSP)\n", "abstract": " More than fifty participants attended the 7th Symposium on Software Performance in Kiel. This occasion was also used to celebrate the tenth birthday of the Kieker monitoring framework. Performance is one of the most relevant quality attributes of any IT system. While good performance leads to high user satisfaction, weak response times lead to loss of users, perceived unavailability of the system, or unnecessarily high costs of network or computing resources. Therefore, various techniques to evaluate, control, and improve the performance of IT systems have been developed, ranging from online monitoring and benchmarking to modeling and prediction. Experience shows, that for system design or later optimization, such techniques should be applied in smart combination.Therefore, the \u0393\u00c7\u00a3Symposium on Software Performance\u0393\u00c7\u00a5 brings together researchers and practitioners interested in all facets of software performance, ranging from modeling and prediction to monitoring and runtime management. The symposium is organized by the three established research groups Descartes [1], Kieker [2], and Palladio [3]; thus this symposium also serves as a joint community meeting. Descartes\u0393\u00c7\u00d6 focus are techniques and tools for engineering self-aware computing systems designed for maximum dependability and efficiency. Kieker is a well-established tool and approach for monitoring software performance of", "num_citations": "1\n", "authors": ["44"]}
{"title": "Kooperative methoden-und werkzeugentwicklung zur cloudmigration von propriet\u251c\u00f1renanwendungskomponenten\n", "abstract": " Die cloudbasierte Bereitstellung von Funktionen als Software-as-a-Service (SaaS) erm\u251c\u2562glicht die Erschlie\u251c\u0192ung neuer Kundenpotenziale bei kleinen und mittelgro\u251c\u0192en Unternehmen. Um bestehende Anwendungskomponenten als SaaS anzubieten, muss eine entsprechende Migration durchgef\u251c\u255dhrt werden. Das Projekt AACC besch\u251c\u00f1ftigt sich mit der modellgetriebenen \u251c\u00a3berf\u251c\u255dhrung von Anwendungskomponenten in Cloud-Computing-Umgebungen. Der hierbei durchgef\u251c\u255dhrte Wissenstransfer beinhaltet softwaretechnische Kompetenzen zur Methodendefinition, Konzepte der modellgetriebenen Softwareentwicklung und technische Kenntnisse zur Implementierung einer integrierten Werkzeugunterst\u251c\u255dtzung. In diesem Beitrag beschreiben wir die In- halte des Wissenstransfers, die erarbeiteten L\u251c\u2562sungen und unsere Erfahrungen aus dem Projekt.", "num_citations": "1\n", "authors": ["44"]}
{"title": "Cloud Computing Reduces Uncertainties in Quality-of-Service Matching!\n", "abstract": " Cloud computing resulted in a continuously growing number of provided software services to be used by consumers. Brokers discover services that fit best to consumers\u0393\u00c7\u00d6 requirements by matching Quality-of-Service (QoS) properties. In order to negotiate Service-Level Agreements (SLAs), a provider has to determine the provided QoS based on QoS analyses. However, the risk for the provider to violate the SLA is high as the service\u0393\u00c7\u00d6s actual quality can deviate from the specified QoS due to uncertainties that occur during the provider\u0393\u00c7\u00d6s quality analysis. In this paper, we discuss current software engineering paradigms like cloud computing and service-oriented computing with respect to the amount of uncertainty they induce into service matching and SLA negotiations. As a result, we explain, why cloud computing reduces such uncertainties.", "num_citations": "1\n", "authors": ["44"]}
{"title": "Modellbasierte und Modellgetriebene Softwaremodernisierung\n", "abstract": " Die Notwendigkeit der Software-Architekturevolution motivierte Uwe Zdun aus den bekannten Ph\u251c\u00f1nomenen des Abdriftens (Architecture Drift) und der Erosion. Als entscheidende Gegenma\u251c\u0192nahme schlug er die Rekonstruktion der Softwarearchitektur vor, wobei architektonische Abstraktionen und Sichten wesentliche Bestandteile der Rekonstruktion sind. Er diskutierte die Vor-und Nachteile existierender Bottom-up-, Topdown-und hybrider Rekonstruktionsverfahren und leitete hieraus drei wesentliche Herausforderungen ab:(A) Abstraktionen auf verschiedenen Granularit\u251c\u00f1tsebenen,(B) Traceability zwischen Architekturmodellen und Code sowie (C) Schritthalten mit der fortschreitenden Evolution der Software. Als L\u251c\u2562sung stellte Zdun einen modellgetriebenen Ansatz vor. Mit einer Domain-Specific Language (DSL) werden Abbildungen zwischen Architektursichten spezifiziert, so dass zB aus Klassenmodellen automatisch Komponentenmodelle generiert und ebenfalls mittels automatischer Modelltransformationen Traceability-Links erstellt werden k\u251c\u2562nnen. Mithilfe von Modellvergleichen k\u251c\u2562nnen dann Unterschiede zwischen Versionen des Komponentenmodells, dh dem rekonstruierten und dem existierenden oder vorherigen Architekturmodell, identifiziert werden. Durch einfache Filter, die die Abstraktion unterst\u251c\u255dtzen, und die Pr\u251c\u255dfung von Design Constraints k\u251c\u2562nnen effektiv Abweichungen zwischen Architekturmodell und Code im Transformationsprozess entdeckt werden. In empirischen Untersuchungen konnte gezeigt werden, dass Traceability-Links eine wichtige Rolle f\u251c\u255dr das Verstehen der architektonischen Abstraktionen spielen.", "num_citations": "1\n", "authors": ["44"]}
{"title": "Configuration of Specification Language and Matching for Services in On-The-Fly Computing\n", "abstract": " In order to buy and use software services, service requesters have to discover services which satisfy their requirements and are available on service markets. Various approaches introduce service brokers, who serve as intermediaries between requesters and providers [ACKM10]. For the discovery, a broker matches the requesters\u0393\u00c7\u00d6 requirements specification to specifications of the provided services. For this, brokers use a matcher that determines the extent, to which a provider\u0393\u00c7\u00d6s service complies to the requesters\u0393\u00c7\u00d6 requirements. Furthermore, providers and requesters often use different specification languages. Thus, the broker has to translate their specifications into her own language supported by a corresponding matcher. This translation is out of the scope of this report as it can be done automatically based on existing approaches [KLR+ 12].In the market, different brokers compete with each other for customers [CJ03]. We assume that customers prefer a broker who delivers most suitable services fast and with the least possible effort. Thus, in order to succeed in this competition, brokers can distinguish themselves by providing a fast and accurate service discovery with low effort for their customers. Therefore, brokers have to develop their own business strategies, which they adjust to the given market. A main part of this strategy is to find a configuration of a language and a matcher, which is optimal wrt. the service discovery and the customer\u0393\u00c7\u00d6s effort. Depending on the broker\u0393\u00c7\u00d6s strategy and the market characteristics, different configurations can be optimal because they are subject to multiple trade-offs. For example, a comprehensive specification\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["44"]}
{"title": "An Empirical Investigation of the Component-Based Performance Prediction Method Palladio\n", "abstract": " Model-based performance prediction methods aim at evaluating the expected response time, throughput, and resource utilization of a software system at design time, before implementation, to achieve predictability of the system\u0393\u00c7\u00d6s performance characteristics. Existing performance prediction methods use monolithic, throw-away prediction models or component-based, reusable prediction models. While it is intuitively clear that the development of reusable models requires more effort, the actual higher amount of effort had not been quantified or analyzed systematically yet. Furthermore, the achieved prediction accuracy of the methods when applied by developers had not yet been compared. To study this effort, we conducted a controlled experiment with 19 computer science students who predicted the performance of two example systems applying an established, monolithic method (Software Performance\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["44"]}
{"title": "Investment in Human Capital: A Theoretical Analysis', Journal of Political Economy, 70 (5, Part 2), October, 9-49\n", "abstract": " I. INTRODUCTION prove the physical and mental abilities of OME activities primarily affect fu-people and thereby raise real income ture well-being, while others have prospects. their main impact in the present. People differ substantially in their Dining is an example of the latter, while economic well-being, both among counpurchase of a car exemplifies the former. tries and among families within a given Both earnings and consumption can be country. For a while economists were re-affected: on-the-job training primarily lating these differences primarily to dif-affects earnings, a new sail boat primari-ferences in the amount of physical capital ly affects consumption, and a college since richer people had more physical education is said to affect both. The ef-capital than others. It has become in-fects may operate either through physical creasingly evident, however, from studies resources, such as a sail boat, or through of income growth\u0393\u00c7\u00a5 that factors other human resources, such as a college edu-than physical resources play a larger cation. This paper is concerned with role than formerly believed, thus focusactivities that influence future real in-ing attention on less tangible resources, come through the imbedding of resources like the knowledge possessed. A concern in people. This is called investing in with investment in human capital, human capital. therefore, ties in closely with the newThe many ways to invest include emphasis on intangible resources and schooling, on-the-job training, medical may be useful in attempts to understand care, vitamin consumption, and acquir-the inequality in income among people. ing information about the economic\u252c\u00e1\u0393\u00c7\u00aa", "num_citations": "1\n", "authors": ["44"]}
{"title": "Nickel processing\n", "abstract": " A method of processing intermediate Ni-bearing products is disclosed. The method comprises subjecting the intermediate Ni-bearing products to an acid leach in order to dissolve substantially all of the acid soluble magnesium-bearing minerals contained therein to provide an upgraded Ni-bearing residue and a leach solution. The method is particularly suitable where the intermediate Ni-bearing products are nickel sulphide concentrates or nickel iron oxide calcine.", "num_citations": "1\n", "authors": ["44"]}