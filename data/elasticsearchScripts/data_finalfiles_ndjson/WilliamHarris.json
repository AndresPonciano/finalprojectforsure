{"title": "Enforcing Kernel Security Invariants with Data Flow Integrity.\n", "abstract": " The operation system kernel is the foundation of the whole system and is often the de facto trusted computing base for many higher level security mechanisms. Unfortunately, kernel vulnerabilities are not rare and are continuously being introduced with new kernel features. Once the kernel is compromised, attackers can bypass any access control checks, escalate their privileges, and hide the evidence of attacks. Many protection mechanisms have been proposed and deployed to prevent kernel exploits. However, a majority of these techniques only focus on preventing control-flow hijacking attacks; techniques that can mitigate noncontrol-data attacks either only apply to drivers/modules or impose too much overhead. The goal of our research is to develop a principled defense mechanism against memory-corruption-based privilege escalation attacks. Toward this end, we leverage dataflow integrity to enforce security invariants of the kernel access control system. In order for our protection mechanism to be practical, we develop two new techniques: one for automatically inferring data that are critical to the access control system without manual annotation, and the other for efficient DFI enforcement over the inference results. We have implemented a prototype of our technology for the ARM64 Linux kernel on an Android device. The evaluation results of our prototype implementation show that our technology can mitigate a majority of privilege escalation attacks, while imposing a moderate amount of performance overhead.", "num_citations": "112\n", "authors": ["1723"]}
{"title": "Enforcing unique code target property for control-flow integrity\n", "abstract": " The goal of control-flow integrity (CFI) is to stop control-hijacking attacks by ensuring that each indirect control-flow transfer (ICT) jumps to its legitimate target. However, existing implementations of CFI have fallen short of this goal because their approaches are inaccurate and as a result, the set of allowable targets for an ICT instruction is too large, making illegal jumps possible. In this paper, we propose the Unique Code Target (UCT) property for CFI. Namely, for each invocation of an ICT instruction, there should be one and only one valid target. We develop a prototype called uCFI to enforce this new property. During compilation, uCFI identifies the sensitive instructions that influence ICT and instruments the program to record necessary execution context. At runtime, uCFI monitors the program execution in a different process, and performs points-to analysis by interpreting sensitive instructions using the recorded\u00a0\u2026", "num_citations": "78\n", "authors": ["1723"]}
{"title": "Flexjava: Language support for safe and modular approximate programming\n", "abstract": " Energy efficiency is a primary constraint in modern systems. Approximate computing is a promising approach that trades quality of result for gains in efficiency and performance. State-of-the-art approximate programming models require extensive manual annotations on program data and operations to guarantee safe execution of approximate programs. The need for extensive manual annotations hinders the practical use of approximation techniques. This paper describes FlexJava, a small set of language extensions, that significantly reduces the annotation effort, paving the way for practical approximate programming. These extensions enable programmers to annotate approximation-tolerant method outputs. The FlexJava compiler, which is equipped with an approximation safety analysis, automatically infers the operations and data that affect these outputs and selectively marks them approximable while giving\u00a0\u2026", "num_citations": "66\n", "authors": ["1723"]}
{"title": "Complexity verification using guided theorem enumeration\n", "abstract": " Determining if a given program satisfies a given bound on the amount of resources that it may use is a fundamental problem with critical practical applications. Conventional automatic verifiers for safety properties cannot be applied to address this problem directly because such verifiers target properties expressed in decidable theories; however, many practical bounds are expressed in nonlinear theories, which are undecidable.   In this work, we introduce an automatic verification algorithm, CAMPY, that determines if a given program P satisfies a given resource bound B, which may be expressed using polynomial, exponential, and logarithmic terms. The key technical contribution behind our verifier is an interpolating theorem prover for non-linear theories that lazily learns a sufficiently accurate approximation of non-linear theories by selectively grounding theorems of the nonlinear theory that are relevant to proving\u00a0\u2026", "num_citations": "27\n", "authors": ["1723"]}
{"title": "Determination of organic carbon and carbonates in soils\n", "abstract": " Procedure and apparatus for determining organic and inorganic carbon in soils are described. The digestion acids used differ from those used in common practice in containing no H2SO4. Sulfate interference was shown to prevent complete digestion of carbonates in a system containing H2SO4. The procedure described is accurate for carbonates and for organic compounds as difficult to oxidize as benzoic acid. The time required for one determination of organic carbon is 30 min; that for inorganic carbon is 22 min.", "num_citations": "17\n", "authors": ["1723"]}
{"title": "Automated verification of query equivalence using satisfiability modulo theories\n", "abstract": " Database-as-a-service offerings enable users to quickly create and deploy complex data processing pipelines. In practice, these pipelines often exhibit significant overlap of computation due to redundant execution of certain sub-queries. It is challenging for developers and database administrators to manually detect overlap across queries since they may be distributed across teams, organization roles, and geographic locations. Thus, we require automated cloud-scale tools for identifying equivalent queries to minimize computation overlap. State-of-the-art algebraic approaches to automated verification of query equivalence suffer from two limitations. First, they are unable to model the semantics of widely-used SQL features, such as complex query predicates and three-valued logic. Second, they have a computationally intensive verification procedure. These limitations restrict their efficacy and efficiency in cloud\u00a0\u2026", "num_citations": "14\n", "authors": ["1723"]}
{"title": "UNIVERSITY OF WISCONSIN\u2013MADISON\n", "abstract": " iDedicated to my mother and father ii Acknowledgments Lately it occurs to me what a long, strange trip it\u2019s been.\u2014Robert Hunter It does, as they say, take a village to raise a graduate student. The work presented in this thesis owes its existence largely to the work and guidance of my advisors, Somesh Jha and Thomas Reps; their unique mixture of dedication to the field and rigorous irreverence will be forever unmatched. It has also been aided directly by the hard work and keen insights of", "num_citations": "9\n", "authors": ["1723"]}
{"title": "Proving flow security of sequential logic via automatically-synthesized relational invariants\n", "abstract": " Due to the proliferation of reprogrammable hardware, core designs built from modules drawn from a variety of sources execute with direct access to critical system resources. Expressing guarantees that such modules satisfy, in particular the dynamic conditions under which they release information about their unbounded streams of inputs, and automatically proving that they satisfy such guarantees, is an open and critical problem.,,To address these challenges, we propose a domain-specific language, named STREAMS, for expressing information-flow policies with declassification over unbounded input streams. We also introduce a novel algorithm, named SIMAREL, that given a core design C and STREAMS policy P, automatically proves or falsifies that C satisfies P. The key technical insight behind the design of SIMAREL is a novel algorithm for efficiently synthesizing relational invariants over pairs of circuit\u00a0\u2026", "num_citations": "7\n", "authors": ["1723"]}
{"title": "Completely automated equivalence proofs\n", "abstract": " Verifying partial (i.e., termination-insensitive) equivalence of programs has significant practical applications in software development and education. Conventional equivalence verifiers typically rely on a combination of given relational summaries and suggested synchronization points; such information can be extremely difficult for programmers without a background in formal methods to provide for pairs of programs with dissimilar logic. In this work, we propose a completely automated verifier for determining partial equivalence, named Pequod. Pequod automatically synthesizes expressive proofs of equivalence conventionally only achievable via careful, manual constructions of product programs To do so, Pequod syntheses relational proofs for selected pairs of program paths and combines the per-path relational proofs to synthesize relational program invariants. To evaluate Pequod, we implemented it as a tool that targets Java Virtual Machine bytecode and applied it to verify the equivalence of hundreds of pairs of solutions submitted by students for problems hosted on popular online coding platforms, most of which could not be verified by existing techniques.", "num_citations": "3\n", "authors": ["1723"]}
{"title": "Icarus: Understanding de facto formats by way of feathers and wax\n", "abstract": " When    data format achieves a significant level of adoption, the presence of multiple format implementations expands the original specification in often-unforeseen ways. This results in an implicitly defined, de facto format, which can create vulnerabilities in programs handling the associated data files. In this paper we present our initial work on ICARUS: a toolchain for dealing with the problem of understanding and hardening de facto file formats. We show the results of our work in progress in the following areas: labeling and categorizing a corpora of data format samples to understand accepted variations of a format; the detection of sublanguages within the de facto format using both entropy- and taint-tracking-based methods, as a means of breaking down the larger problem of learning how the grammar has evolved; grammar inference via reinforcement learning, as a means of tying together the learned\u00a0\u2026", "num_citations": "2\n", "authors": ["1723"]}
{"title": "SIA: Optimizing Queries using Learned Predicates\n", "abstract": " Predicate-centric rules for rewriting queries is a key technique in optimizing queries. These include pushing down the predicate below the join and aggregation operators, or optimizing the order of evaluating predicates. However, many of these rules are only applicable when the predicate uses a certain set of columns. For example, to move the predicate below the join operator, the predicate must only use columns from one of the joined tables. By generating a predicate that satisfies these column constraints and preserves the semantics of the original query, the optimizer may leverage additional predicate-centric rules that were not applicable before. Researchers have proposed syntax-driven rewrite rules and machine learning algorithms for inferring such predicates. However, these techniques suffer from two limitations. First, they do not let the optimizer constrain the set of columns that may be used in the learned\u00a0\u2026", "num_citations": "1\n", "authors": ["1723"]}
{"title": "\u03bb-Symphony: A concise language model for MPC\n", "abstract": " Secure multi-party computation (MPC) allows mutually distrusting parties to cooperatively compute, using a cryptographic protocol, a function over their private data. This paper presents \u03bb-Symphony, an expressive yet concise domain-specific language for expressing MPCs. \u03bb-Symphony starts with the standard, simply-typed \u03bb calculus extended with integers, sums, products, recursive types, and references. It layers on two additional elements:(1) A datatype representing secret shares, which are the basis of multiparty computation, and (2) a simple mechanism called par blocks to express which scopes are to be executed by which parties, and which determine to whom various data values are visible at any given time. The meaning of a \u03bb-Symphony program can be expressed using a single-threaded semantics even though in actuality the program will be run by multiple communicating parties in parallel. Our distributed semantics is expressed naturally as piecewise, single-threaded steps of slices of the program among its parties. We prove that these two semantic interpretations of a program coincide, and we prove a standard type soundness result. To demonstrate \u03bb-Symphony\u2019s expressiveness, we have built an interpreter for it (with some extensions) and used it to implement a number of realistic MPC applications, including sorting, statistical and numeric computations, and private information retrieval.", "num_citations": "1\n", "authors": ["1723"]}
{"title": "SPES: A Two-Stage Query Equivalence Verifier\n", "abstract": " In database-as-a-service platforms, automated verification of query equivalence helps eliminate redundant computation across queries (ie, overlapping sub-queries). State-of-the-art tools for automated detection of query equivalence adopt two different approaches. The first technique is based on reducing queries to algebraic expressions and proving their equivalence using an algebraic theory. The limitations of this approach are threefold. It cannot prove the equivalence of queries with significant differences in the attributes of their relational operators (eg, predicates in the filter operator). It does not support certain widely-used SQL features (eg, NULL values). Its verification procedure is computationally intensive. The second technique is based on deriving the symbolic representation of the queries and proving their equivalence using the satisfiability modulo theory. The limitations of this approach are twofold. It only proves the equivalence of queries under set semantics. It cannot prove the equivalence of queries with significant structural differences in their abstract syntax trees.In this paper, we present a novel two-stage approach to automated verification of query equivalence that addresses the limitations of these individual techniques. The first stage consists of reducing queries to a novel algebraic representation and then normalizing the resulting algebraic expressions to minimize structural differences. The second stage consists of applying a verification algorithm to convert the normalized algebraic expressions to a novel query pair symbolic representation and proving their equivalence under bag semantics using satisfiability modulo theory\u00a0\u2026", "num_citations": "1\n", "authors": ["1723"]}
{"title": "Relational Verification via Invariant-Guided Synchronization\n", "abstract": " Relational properties describe relationships that hold over multiple executions of one or more programs, such as functional equivalence. Conventional approaches for automatically verifying such properties typically rely on syntax-based, heuristic strategies for finding synchronization points among the input programs. These synchronization points are then annotated with appropriate relational invariants to complete the proof. However, when suboptimal synchronization points are chosen the required invariants can be complicated or even inexpressible in the target theory. In this work, we propose a novel approach to verifying relational properties. This approach searches for synchronization points and synthesizes relational invariants simultaneously. Specifically, the approach uses synthesized invariants as a guide for finding proper synchronization points that lead to a complete proof. We implemented our approach as a tool named PEQUOD, which targets Java Virtual Machine (JVM) bytecode. We evaluated PEQUOD by using it to solve verification challenges drawn from the from the research literature and by verifying properties of student-submitted solutions to online challenge problems. The results show that PEQUOD solve verification problems that cannot be addressed by current techniques.", "num_citations": "1\n", "authors": ["1723"]}
{"title": "Solving Constrained Horn Clauses Using Dependence-Disjoint Expansions\n", "abstract": " Recursion-free Constrained Horn Clauses (CHCs) are logic-programming problems that can model safety properties of programs with bounded iteration and recursion. In addition, many CHC solvers reduce recursive systems to a series of recursion-free CHC systems that can each be solved efficiently. In this paper, we define a novel class of recursion-free systems, named Clause-Dependence Disjoint (CDD), that generalizes classes defined in previous work. The advantage of this class is that many CDD systems are smaller than systems which express the same constraints but are part of a different class. This advantage in size allows CDD systems to be solved more efficiently than their counterparts in other classes. We implemented a CHC solver named Shara. Shara solves arbitrary CHC systems by reducing the input to a series of CDD systems. Our evaluation indicates that Shara outperforms state-of-the-art implementations in many practical cases.", "num_citations": "1\n", "authors": ["1723"]}
{"title": "Secure programming via game-based synthesis\n", "abstract": " Interactive security systems provide powerful security primitives (i.e., security-oriented system calls) that an application can invoke at various moments during execution to control accesses to its sensitive information. Prior to the work described in this thesis, an application developer was forced to explicitly write imperative code that executes security primitives. Moreover, a developer could only reason informally about whether the code satisfied the developers intuitive notions of security and correctness.  This dissertation describes the design of policy weavers for interactive-security systems. A policy weaver allows a programmer to specify desired functionality and security guarantees of an application, and automatically obtain a modified application that satisfies such guarantees when executed on an interactive-security system. Each policy weaver consists of (i) a policy language in which the developer expresses desired guarantees, and (ii) a program instrumenter that takes as input an uninstrumented program and a policy in the language, and outputs a program that satisfies the specified policy.  We have designed and evaluated policy weavers for the Capsicum capability system and the HiStar decentralized information-flow control (DIFC) system by designing and applying a policy-weaver generator, which takes as input the semantics of the primitives of each system and outputs a weaver for the system.", "num_citations": "1\n", "authors": ["1723"]}