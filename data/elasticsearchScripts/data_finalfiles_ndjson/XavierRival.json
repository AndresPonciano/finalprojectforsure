{"title": "Trace partitioning in abstract interpretation based static analyzers\n", "abstract": " When designing a tractable static analysis, one usually needs to approximate the trace semantics. This paper proposes a systematic way of regaining some knowledge about the traces by performing the abstraction over a partition of the set of traces instead of the set itself. This systematic refinement is not only theoretical but tractable: we give automatic procedures to build pertinent partitions of the traces and show the efficiency on an implementation integrated in the Astr\u00e9e static analyzer, a tool capable of dealing with industrial-size software.", "num_citations": "278\n", "authors": ["1749"]}
{"title": "The trace partitioning abstract domain\n", "abstract": " In order to achieve better precision of abstract interpretation-based static analysis, we introduce a new generic abstract domain, the trace partitioning abstract domain. We develop a theoretical framework allowing a wide range of instantiations of the domain, proving that all these instantiations give correct results. From this theoretical framework, we go into implementation details of a particular instance developed in the Astr\u00e9e static analyzer. We show how the domain is automatically configured in Astr\u00e9e and the gain and cost in terms of performance and precision.", "num_citations": "199\n", "authors": ["1749"]}
{"title": "Relational inductive shape analysis\n", "abstract": " Shape analyses are concerned with precise abstractions of the heap to capture detailed structural properties. To do so, they need to build and decompose summaries of disjoint memory regions. Unfortunately, many data structure invariants require relations be tracked across disjoint regions, such as intricate numerical data invariants or structural invariants concerning back and cross pointers. In this paper, we identify issues inherent to analyzing relational structures and design an abstract domain that is parameterized both by an abstract domain for pure data properties and by user-supplied specifications of the data structure invariants to check. Particularly, it supports hybrid invariants about shape and data and features a generic mechanism for materializing summaries at the beginning, middle, or end of inductive structures. Around this domain, we build a shape analysis whose interesting components include a pre\u00a0\u2026", "num_citations": "193\n", "authors": ["1749"]}
{"title": "Understanding the origin of alarms in Astr\u00e9e\n", "abstract": " Static analyzers like Astr\u00e9e are incomplete, hence, may produce false alarms. We propose a framework for the investigation of the alarms produced by Astr\u00e9e , so as to help classifying them as true errors or false alarms that are due to the approximation inherent in the static analysis. Our approach is based on the computation of an approximation of a set of traces specified by an initial and a (set of) final state(s). Moreover, we allow for finer analyses to focus on some execution patterns or on some possible inputs. The underlying algorithms were implemented inside Astr\u00e9e and used successfully to track alarms in large, critical embedded applications.", "num_citations": "108\n", "authors": ["1749"]}
{"title": "Symbolic transfer function-based approaches to certified compilation\n", "abstract": " We present a framework for the certification of compilation and of compiled programs. Our approach uses a symbolic transfer functions-based representation of programs, so as to check that source and compiled programs present similar behaviors. This checking can be done either for a concrete semantic interpretation (Translation Validation) or for an abstract semantic interpretation (Invariant Translation) of the symbolic transfer functions. We propose to design a checking procedure at the concrete level in order to validate both the transformation and the translation of abstract invariants. The use of symbolic transfer functions makes possible a better treatment of compiler optimizations and is adapted to the checking of precise invariants at the assembly level. The approach proved successful in the implementation point of view, since it rendered the translation of very precise invariants on very large assembly\u00a0\u2026", "num_citations": "90\n", "authors": ["1749"]}
{"title": "Shape analysis with structural invariant checkers\n", "abstract": " Developer-supplied data structure specifications are important to shape analyses, as they tell the analysis what information should be tracked in order to obtain the desired shape invariants. We observe that data structure checking code (eg, used in testing or dynamic analysis) provides shape information that can also be used in static analysis. In this paper, we propose a lightweight, automatic shape analysis based on these developer-supplied structural invariant checkers. In particular, we set up a parametric abstract domain, which is instantiated with such checker specifications to summarize memory regions using both notions of complete and partial checker evaluations. The analysis then automatically derives a strategy for canonicalizing or weakening shape invariants.", "num_citations": "86\n", "authors": ["1749"]}
{"title": "Abstract interpretation-based certification of assembly code\n", "abstract": " We present a method for analyzing assembly programs based on source program analysis and invariant translation. It is generic in the choice of an abstract domain for representing stores. This method is adapted to the design of certification tools for assembly programs generated by compiling programs written in an imperative language, without writing a specific compiler or modifying an existing one since invariant translation only uses standard debugging information. A prototype was developed for a procedural subset of the C language.", "num_citations": "39\n", "authors": ["1749"]}
{"title": "Abstract dependences for alarm diagnosis\n", "abstract": " We propose a framework for dependence analyses, adapted \u2013among others\u2013 to the understanding of static analyzers outputs. Static analyzers like Astr\u00e9e are sound but not complete; hence, they may yield false alarms, that is report not being able to prove part of the properties of interest. Helping the user in the alarm inspection task is a major challenge for current static analyzers. Semantic slicing, i.e. the computation of precise abstract invariants for a set of erroneous traces, provides a useful characterization of a possible error context. We propose to enhance semantic slicing with information about abstract dependences. Abstract dependences should be more informative than mere dependences: first, we propose to restrict to the dependences that can be observed in a slice; second, we define dependences among abstract properties, so as to isolate abnormal behaviors as source of errors. Last, stronger\u00a0\u2026", "num_citations": "35\n", "authors": ["1749"]}
{"title": "Automatic analysis of open objects in dynamic language programs\n", "abstract": " In dynamic languages, objects are open\u2013they support iteration over and dynamic addition/deletion of their attributes. Open objects, because they have an unbounded number of attributes, are difficult to abstract without a priori knowledge of all or nearly all of the attributes and thus pose a significant challenge for precise static analysis. To address this challenge, we present the HOO (Heap with Open Objects) abstraction that can precisely represent and infer properties about open-object-manipulating programs without any knowledge of specific attributes. It achieves this by building upon a relational abstract domain for sets that is used to reason about partitions of object attributes. An implementation of the resulting static analysis is used to verify specifications for dynamic language framework code that makes extensive use of open objects, thus demonstrating the effectiveness of this approach.", "num_citations": "33\n", "authors": ["1749"]}
{"title": "Calling context abstraction with shapes\n", "abstract": " Interprocedural program analysis is often performed by computing procedure summaries. While possible, computing adequate summaries is difficult, particularly in the presence of recursive procedures. In this paper, we propose a complementary framework for interprocedural analysis based on a direct abstraction of the calling context. Specifically, our approach exploits the inductive structure of a calling context by treating it directly as a stack of activation records. We then build an abstraction based on separation logic with inductive definitions. A key element of this abstract domain is the use of parameters to refine the meaning of such call stack summaries and thus express relations across activation records and with the heap. In essence, we define an abstract interpretation-based analysis framework for recursive programs that permits a fluid per call site abstraction of the call stack--much like how shape analyzers\u00a0\u2026", "num_citations": "31\n", "authors": ["1749"]}
{"title": "Reduced product combination of abstract domains for shapes\n", "abstract": " Real-world data structures are often enhanced with additional pointers capturing alternative paths through a basic inductive skeleton (e.g., back pointers, head pointers). From the static analysis point of view, we must obtain several interlocking shape invariants. At the same time, it is well understood in abstract interpretation design that supporting a separation of concerns is critically important to designing powerful static analyses. Such a separation of concerns is often obtained via a reduced product on a case-by-case basis. In this paper, we lift this idea to abstract domains for shape analyses, introducing a domain combination operator for memory abstractions. As an example, we present simultaneous separating shape graphs, a product construction that combines instances of separation logic-based shape domains. The key enabler for this construction is a static analysis on inductive data structure\u00a0\u2026", "num_citations": "29\n", "authors": ["1749"]}
{"title": "Modular construction of shape-numeric analyzers\n", "abstract": " The aim of static analysis is to infer invariants about programs that are precise enough to establish semantic properties, such as the absence of run-time errors. Broadly speaking, there are two major branches of static analysis for imperative programs. Pointer and shape analyses focus on inferring properties of pointers, dynamically-allocated memory, and recursive data structures, while numeric analyses seek to derive invariants on numeric values. Although simultaneous inference of shape-numeric invariants is often needed, this case is especially challenging and is not particularly well explored. Notably, simultaneous shape-numeric inference raises complex issues in the design of the static analyzer itself. In this paper, we study the construction of such shape-numeric, static analyzers. We set up an abstract interpretation framework that allows us to reason about simultaneous shape-numeric properties by combining shape and numeric abstractions into a modular, expressive abstract domain. Such a modular structure is highly desirable to make its formalization and implementation easier to do and get correct. To achieve this, we choose a concrete semantics that can be abstracted step-by-step, while preserving a high level of expressiveness. The structure of abstract operations (i.e., transfer, join, and comparison) follows the structure of this semantics. The advantage of this construction is to divide the analyzer in modules and functors that implement abstractions of distinct features.", "num_citations": "26\n", "authors": ["1749"]}
{"title": "Abstraction of arrays based on non contiguous partitions\n", "abstract": " Array partitioning analyses split arrays into contiguous partitions to infer properties of cell sets. Such analyses cannot group together non contiguous cells, even when they have similar properties. In this paper, we propose an abstract domain which utilizes semantic properties to split array cells into groups. Cells with similar properties will be packed into groups and abstracted together. Additionally, groups are not necessarily contiguous. This abstract domain allows to infer complex array invariants in a fully automatic way. Experiments on examples from the Minix 1.1 memory management demonstrate its effectiveness.", "num_citations": "23\n", "authors": ["1749"]}
{"title": "Separating shape graphs\n", "abstract": " Detailed memory models that expose individual fields are necessary to precisely analyze code that makes use of low-level aspects such as, pointers to fields and untagged unions. Yet, higher-level representations that collect fields into records are often used because they are typically more convenient and efficient in modeling the program heap. In this paper, we present a shape graph representation of memory that exposes individual fields while largely retaining the convenience of an object-level model. This representation has a close connection to particular kinds of formulas in separation logic. Then, with this representation, we show how to extend the Xisa shape analyzer for low-level aspects, including pointers to fields, C-style nested structures and unions, malloc and free, and array values, with minimal changes to the core algorithms (e.g., materialization and summarization).", "num_citations": "22\n", "authors": ["1749"]}
{"title": "Experiments with finite tree automata in Coq\n", "abstract": " Tree automata are a fundamental tool in computer science. We report on experiments to integrate tree automata in Coq using shallow and deep reflection techniques. While shallow reflection seems more natural in this context, it turns out to give disappointing results. Deep reflection is more difficult to apply, but is more promising.", "num_citations": "17\n", "authors": ["1749"]}
{"title": "Static analysis of spreadsheet applications for type-unsafe operations detection\n", "abstract": " Spreadsheets are widely used, yet are error-prone. In particular, they use a weak type system, which allows certain operations that will silently return unexpected results, like comparisons of integer values with string values. However, discovering these issues is hard, since data and formulas can be dynamically set, read or modified. We propose a static analysis that detects all run-time type-unsafe operations in spreadsheets. It is based on an abstract interpretation of spreadsheet applications, including spreadsheet tables, global re-evaluation and associated programs. Our implementation supports the features commonly found in real-world spreadsheets. We ran our analyzer on the EUSES Spreadsheet Corpus. This evaluation shows that our tool is able to automatically verify a large number of real spreadsheets, runs in a reasonable time and discovers complex bugs that are difficult to detect by code\u00a0\u2026", "num_citations": "12\n", "authors": ["1749"]}
{"title": "Hierarchical shape abstraction of dynamic structures in static blocks\n", "abstract": " We propose a hierarchical shape abstract domain, so as to infer structural invariants of dynamic structures such as lists living inside static structures, such as arrays. This programming pattern is often used in safety critical embedded software as an alternative to dynamic memory allocation. Our abstract domain precisely describes such hierarchies of structures. It combines several instances of simple shape abstract domains, dedicated to the representation of elementary shape properties, and also embeds a numerical abstract domain. This modular construction greatly simplifies the design and the implementation of the abstract domain. We provide an implementation, and show the effectiveness of our approach on a problem taken from a real code.", "num_citations": "12\n", "authors": ["1749"]}
{"title": "An abstract domain to infer types over zones in spreadsheets\n", "abstract": " Spreadsheet languages are very commonly used, by large user bases, yet they are error prone. However, many semantic issues and errors could be avoided by enforcing a stricter type discipline. As declaring and specifying type information would represent a prohibitive amount of work for users, we propose an abstract interpretation based static analysis for spreadsheet programs that infers type constraints over zones of spreadsheets, viewed as two-dimensional arrays. Our abstract domain consists in a cardinal power from a numerical abstraction describing zones in a spreadsheet to an abstraction of cell values, including type properties. We formalize this abstract domain and its operators (transfer functions, join, widening and reduction) as well as a static analysis for a simplified spreadsheet language. Last, we propose a representation for abstract values and present an implementation of our analysis.", "num_citations": "11\n", "authors": ["1749"]}
{"title": "Concrete memory models for shape analysis\n", "abstract": " This paper discusses four store-based concrete memory models. We characterize memory models by the class of pointers they support and whether they use numerical or symbolic offsets to address values in a block. We give the semantics of a C-like language within each of these memory models to illustrate their differences. The language we consider is a fragment of Leroy's Clight, including arrays, pointer arithmetics but excluding casts. All along the paper, we link these concrete memory models with existing shape analyses.", "num_citations": "11\n", "authors": ["1749"]}
{"title": "A relational shape abstract domain\n", "abstract": " Static analyses aim at inferring semantic properties of programs. We distinguish two important classes of static analyses: state analyses and relational analyses. While state analyses aim at computing an over-approximation of reachable states of programs, relational analyses aim at computing functional properties over the input\u2013output states of programs. Several advantages of relational analyses are their ability to analyze incomplete programs, such as libraries or classes, but also to make the analysis modular, using input\u2013output relations as composable summaries for procedures. In the case of numerical programs, several analyses have been proposed that utilize relational numerical abstract domains to describe relations. On the other hand, designing abstractions for relations over input\u2013output memory states and taking shapes into account is challenging. In this paper, we propose a set of novel logical\u00a0\u2026", "num_citations": "10\n", "authors": ["1749"]}
{"title": "Semantic-directed clumping of disjunctive abstract states\n", "abstract": " To infer complex structural invariants, shape analyses rely on expressive families of logical properties. Many such analyses manipulate abstract memory states that consist of separating conjunctions of basic predicates describing atomic blocks or summaries. Moreover, they use finite disjunctions of abstract memory states in order to account for dissimilar shapes. Disjunctions should be kept small for the sake of scalability, though precision often requires to keep additional case splits. In this context, deciding when and how to merge case splits and to replace them with summaries is critical both for the precision and for the efficiency. Existing techniques use sets of syntactic rules, which are tedious to design and prone to failure. In this paper, we design a semantic criterion to clump abstract states based on their silhouette which applies not only to the conservative union of disjuncts, but also to the weakening of\u00a0\u2026", "num_citations": "10\n", "authors": ["1749"]}
{"title": "Shape analysis for unstructured sharing\n", "abstract": " Shape analysis aims to infer precise structural properties of imperative memory states and has been applied heavily to verify safety properties on imperative code over pointer-based data structures. Recent advances in shape analysis based on separation logic has leveraged summarization predicates that describe unbounded heap regions like lists or trees using inductive definitions. Unfortunately, data structures with unstructured sharing, such as graphs, are challenging to describe and reason about in such frameworks. In particular, when the sharing is unstructured, it cannot be described inductively in a local manner. In this paper, we propose a global abstraction of sharing based on set-valued variables that when integrated with inductive definitions enables the specification and shape analysis of structures with unstructured sharing.", "num_citations": "9\n", "authors": ["1749"]}
{"title": "Weakly sensitive analysis for unbounded iteration over JavaScript objects\n", "abstract": " JavaScript framework libraries like jQuery are widely used, but complicate program analyses. Indeed, they encode clean high-level constructions such as class inheritance via dynamic object copies and transformations that are harder to reason about. One common pattern used in them consists of loops that copy or transform part or all of the fields of an object. Such loops are challenging to analyze precisely, due to weak updates and as unrolling techniques do not always apply. In this paper, we observe that precise field correspondence relations are required for client analyses (e.g., for call-graph construction), and propose abstractions of objects and program executions that allow to reason separately about the effect of distinct iterations without resorting to full unrolling. We formalize and implement an analysis based on this technique. We assess the performance and precision on the computation of call\u00a0\u2026", "num_citations": "8\n", "authors": ["1749"]}
{"title": "Construction of abstract domains for heterogeneous properties (position paper)\n", "abstract": " The aim of static analysis is to infer invariants about programs that are tight enough to establish semantic properties, like the absence of run-time errors. In the last decades, several branches of the static analysis of imperative programs have made significant progress, such as in the inference of numeric invariants or the computation of data structures properties (using pointer abstractions or shape analyzers). Although simultaneous inference of shape-numeric invariants is often needed, this case is especially challenging and less well explored. Notably, simultaneous shape-numeric inference raises complex issues in the design of the static analyzer itself. We study the modular construction of static analyzers, based on combinations of atomic abstract domains to describe several kinds of memory properties and value properties.", "num_citations": "8\n", "authors": ["1749"]}
{"title": "Proofnets and context semantics for the additives\n", "abstract": " We provide a context semantics for Multiplicative-Additive Linear Logic (MALL), together with proofnets whose reduction preserves semantics, where proofnet reduction is equated with cut-elimination on MALL sequents. The results extend the program of Gonthier, Abadi, and L\u00e9vy, who provided a \u201cgeometry of optimal \u03bb-reduction\u201d (context semantics) for \u03bb-calculus and Multiplicative-Exponential Linear Logic (MELL). We integrate three features: a semantics that uses buses to implement slicing; a proofnet technology that allows multidimensional boxes and generalized garbage, preserving the linearity of additive reduction; and finally, a read-back procedure that computes a cut-free proof from the semantics, a constructive companion to full abstraction theorems.", "num_citations": "8\n", "authors": ["1749"]}
{"title": "Weakly sensitive analysis for JavaScript object\u2010manipulating programs\n", "abstract": " While JavaScript programs have become pervasive in web applications, they remain hard to reason about. In this context, most static analyses for JavaScript programs require precise call graph information, since the presence of large numbers of spurious callees significantly deteriorates precision. One of the most challenging JavaScript features that complicate the inference of precise static call graph information is read/write accesses to object fields, the names of which are computed at runtime. JavaScript framework libraries often exploit this facility to build objects from other objects, as a way to simulate sophisticated high\u2010level programming constructions. Such code patterns are difficult to analyze precisely, due to weak updates and limitations of unrolling techniques. In this paper, we observe that precise field origination relations can be inferred by locally reasoning about object copies, both regarding to the\u00a0\u2026", "num_citations": "6\n", "authors": ["1749"]}
{"title": "Revisiting recency abstraction for JavaScript: towards an intuitive, compositional, and efficient heap abstraction\n", "abstract": " JavaScript is one of the most widely used programming languages. To understand the behaviors of JavaScript programs and to detect possible errors in them, researchers have developed several static analyzers based on the abstract interpretation framework. However, JavaScript provides various language features that are difficult to analyze statically and precisely such as dynamic addition and removal of object properties, first-class property names, and higher-order functions. To alleviate the problem, JavaScript static analyzers often use recency abstraction, which refines address abstraction by distinguishing recent objects from summaries of old objects. We observed that while recency abstraction enables more precise analysis results by allowing strong updates on recent objects, it is not monotone in the sense that it does not preserve the precision relationship between the underlying address abstraction\u00a0\u2026", "num_citations": "6\n", "authors": ["1749"]}
{"title": "An array content static analysis based on non-contiguous partitions\n", "abstract": " Conventional array partitioning analyses split arrays into contiguous partitions to infer properties of sets of cells. Such analyses cannot group together non-contiguous cells, even when they have similar properties. In this paper, we propose an abstract domain which utilizes semantic properties to split array cells into groups. Cells with similar properties will be packed into groups and abstracted together. Additionally, groups are not necessarily contiguous. This abstract domain allows us to infer complex array invariants in a fully automatic way. Experiments on examples from the Minix 1.1 memory management and a tiny industrial operating system demonstrate the effectiveness of the analysis.", "num_citations": "6\n", "authors": ["1749"]}
{"title": "An abstract domain combinator for separately conjoining memory abstractions\n", "abstract": " The breadth and depth of heap properties that can be inferred by the union of today\u2019s shape analyses is quite astounding. Yet, achieving scalability while supporting a wide range of complex data structures in a generic way remains a long-standing challenge. In this paper, we propose a way to side-step this issue by defining a generic abstract domain combinator for combining memory abstractions on disjoint regions. In essence, our abstract domain construction is to the separating conjunction in separation logic as the reduced product construction is to classical, non-separating conjunction. This approach eases the design of the analysis as memory abstract domains can be re-used by applying our separating conjunction domain combinator. And more importantly, this combinator enables an analysis designer to easily create a combined domain that applies computationally-expensive abstract domains only\u00a0\u2026", "num_citations": "6\n", "authors": ["1749"]}
{"title": "A theoretical foundation of sensitivity in an abstract interpretation framework\n", "abstract": " Program analyses often utilize various forms of sensitivity such as context sensitivity, call-site sensitivity, and object sensitivity. These techniques all allow for more precise program analyses, that are able to compute more precise program invariants, and to verify stronger properties. Despite the fact that sensitivity techniques are now part of the standard toolkit of static analyses designers and implementers, no comprehensive frameworks allow the description of all common forms of sensitivity. As a consequence, the soundness proofs of static analysis tools involving sensitivity often rely on ad hoc formalization, which are not always carried out in an abstract interpretation framework. Moreover, this also means that opportunities to identify similarities between analysis techniques to better improve abstractions or to tune static analysis tools can easily be missed. In this article, we present and formalize a framework for the\u00a0\u2026", "num_citations": "5\n", "authors": ["1749"]}
{"title": "Abstraction of optional numerical values\n", "abstract": " We propose a technique to describe properties of numerical stores with optional values, that is, where some variables may have no value. Properties of interest include numerical equalities and inequalities. Our approach lifts common linear inequality based numerical abstract domains into abstract domains describing stores with optional values. This abstraction can be used in order to analyze languages with some form of option scalar type. It can also be applied to the construction of abstract domains to describe complex memory properties that introduce symbolic variables, e.g., in order to summarize unbounded sets of program variables, and where these symbolic variables may be undefined, as in some array or shape analyses. We describe the general form of abstract states, and propose sound and automatic static analysis algorithms. We evaluate our construction in the case of an array abstract domain.", "num_citations": "5\n", "authors": ["1749"]}
{"title": "Desynchronized multi-state abstractions for open programs in dynamic languages\n", "abstract": " Dynamic language library developers face a challenging problem: ensuring that their libraries will behave correctly for a wide variety of client programs without having access to those client programs. This problem stems from the common use of two defining features for dynamic languages: callbacks into client code and complex manipulation of attribute names within objects. To remedy this problem, we introduce two state-spanning abstractions. To analyze callbacks, the first abstraction desynchronizes a heap, allowing partitions of the heap that may be affected by a callback to an unknown function to be frozen in the state prior to the call. To analyze object attribute manipulation, building upon an abstraction for dynamic language heaps, the second abstraction tracks attribute name/value pairs across the execution of a library. We implement these abstractions and use them to verify modular specifications of\u00a0\u2026", "num_citations": "5\n", "authors": ["1749"]}
{"title": "Certification of compiled assembly code by invariant translation\n", "abstract": " We present a method for analyzing assembly programs obtained by compilation and checking safety properties on compiled programs. It proceeds by analyzing the source program, translating the invariant obtained at the source level, and then checking the soundness of the translated invariant with respect to the assembly program. This process is especially adapted to the certification of assembly or other machine-level kinds of programs. Furthermore, the success of invariant checking enhances the level of confidence in the results of both the compilation and the static analysis. From a practical point of view, our method is generic in the choice of an abstract domain for representing sets of stores, and the process does not interact with the compilation itself. Hence a certification tool can be interfaced with an existing analyzer and designed so as to work with a class of compilers that do not need to be modified\u00a0\u2026", "num_citations": "4\n", "authors": ["1749"]}
{"title": "Abstract domains and solvers for sets reasoning\n", "abstract": " When constructing complex program analyses, it is often useful to reason about not just individual values, but collections of values. Symbolic set abstractions provide building blocks that can be used to partition elements, relate partitions to other partitions, and determine the provenance of multiple values, all without knowing any concrete values. To address the simultaneous challenges of scalability and precision, we formalize and implement an interface for symbolic set abstractions and construct multiple abstract domains relying on both specialized data structures and off-the-shelf theorem provers. We develop techniques for lifting existing domains to improve performance and precision. We evaluate these domains on real-world data structure analysis problems.", "num_citations": "3\n", "authors": ["1749"]}
{"title": "Verification, Model Checking, and Abstract Interpretation: 15th International Conference, VMCAI 2014, San Diego, CA, USA, January 19-21, 2014, Proceedings\n", "abstract": " This book constitutes the refereed proceedings of the 15th International Conference on Verification, Model Checking and Abstract Interpretation, VMCAI 2014, held in San Diego, CA, USA, in January 2013. The 25 revised full papers presented were carefully reviewed and selected from 64 submissions. The papers cover a wide range of topics including program verification, model checking, abstract interpretation and abstract domains, program synthesis, static analysis, type systems, deductive methods, program certification, debugging techniques, program transformation, optimization, hybrid and cyber-physical systems.", "num_citations": "3\n", "authors": ["1749"]}
{"title": "No Crash, No Exploit: Automated Verification of Embedded Kernels\n", "abstract": " The kernel is the most safety- and security-critical component of many computer systems, as the most severe bugs lead to complete system crash or exploit. It is thus desirable to guarantee that a kernel is free from these bugs using formal methods, but the high cost and expertise required to do so are deterrent to wide applicability. We propose a method that can verify both absence of runtime errors (i.e. crashes) and absence of privilege escalation (i.e. exploits) in embedded kernels from their binary executables. The method can verify the kernel runtime independently from the application, at the expense of only a few lines of simple annotations. When given a specific application, the method can verify simple kernels without any human intervention. We demonstrate our method on two different use cases: we use our tool to help the development of a new embedded realtime kernel, and we verify an existing industrial\u00a0\u2026", "num_citations": "2\n", "authors": ["1749"]}
{"title": "Analyse statique par interpr\u00e9tation abstraite\n", "abstract": " L\u2019interpr\u00e9tation abstraite a \u00e9t\u00e9 propos\u00e9e comme un cadre g\u00e9n\u00e9rique permettant de formaliser, d\u00e9river et prouver des analyses statiques par approximation conservative, c\u2019est \u00e0 dire capables de d\u00e9montrer une propri\u00e9t\u00e9 donn\u00e9e pour un sous-ensemble des programmes v\u00e9rifiant celle-ci. Tout d\u2019abord, nous d\u00e9crivons pas \u00e0 pas les principales \u00e9tapes dans la conception de telles analyses, du choix d\u2019un mod\u00e8le des programmes \u00e0 \u00e9tudier \u00e0 la formalisation des algorithmes d\u2019analyse, en passant par le choix d\u2019une ensemble de pr\u00e9dicats \u00e0 utiliser. Ensuite, nous pr\u00e9sentons quelques applications r\u00e9centes de ces techniques, dans divers domaines de l\u2019informatiqueABSTRACT. Abstract interpretation was introduced as a generic framework, which allows to formalize, derive and prove static analyses, which are based on conservative approximation, that is, which are able to establish a fixed property for a subset of the programs which actually satisfy it. First, we provide a step by step description of the main steps in the design of such analyses, from the choice of a model for the programs to study, to the formalization of the analysis algorithm, including the choice of a set of predicates to use for the analysis. Then, we present a panel of recent applications of these techniques to various areas of computer science.", "num_citations": "2\n", "authors": ["1749"]}
{"title": "Binsec/Codex, an abstract interpreter to verify safety and security properties of systems code\n", "abstract": " This document describes the internals of Binsec/Codex, an analyzer able to verify safety and security properties on machine code, notably used to verify absence of runtime errors and privilege escalation in embedded kernels. After stating our assumptions on the hardware, we give a detailed overview of the abstract domains used in the analysis, and give examples of why each domain is needed.", "num_citations": "1\n", "authors": ["1749"]}
{"title": "Parametric abstract domains for shape analysis\n", "abstract": " Parametric Abstract Domains for Shape Analysis Page 1 Parametric Abstract Domains for Shape Analysis Xavier RIVAL (INRIA & \u00c9cole Normale Sup\u00e9rieure) Joint work with Bor-Yuh Evan CHANG (University of Maryland U University of Colorado) and George NECULA (University of California at Berkeley) Page 2 Purpose of Shape Analysis \u2022 Infer precise information about memory layout: \u2666 pointers \u2666 dynamic, unbounded data-structures \u25b6 eg, lists, queues, stacks, trees \u25b6 complex composite structures: eg, in device drivers \u2022 Wide range of applications: \u2666 proving memory safety absence of memory leaks, null/dangling pointer dereference \u2666 proving the preservation of shapes eg, no cycle is introduced in what should be a tree \u2666 establishing stronger properties eg, correctness of a sorting algorithm \u2666 allow other analyses to support manipulation of complex structures Parametric Abstract Domains for Shape Analysis \u2013 p.2/\u2026", "num_citations": "1\n", "authors": ["1749"]}