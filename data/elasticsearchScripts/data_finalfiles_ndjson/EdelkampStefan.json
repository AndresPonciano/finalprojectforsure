{"title": "Planning with pattern databases\n", "abstract": " Heuristic search planning effectively finds solutions for large planning problems, but since the estimates are either not admissible or too weak, optimal solutions are found in rare cases only. In contrast, heuristic pattern databases are known to significantly improve lower bound estimates for optimally solving challenging single-agent problems like the 24-Puzzle or Rubik\u2019s Cube. This paper studies the effect of pattern databases in the context of deterministic planning. Given a fixed state description based on instantiated predicates, we provide a general abstraction scheme to automatically create admissible domain-independent memory-based heuristics for planning problems, where abstractions are found in factorizing the planning space. We evaluate the impact of pattern database heuristics in A* and hill climbing algorithms for a collection of benchmark domains.", "num_citations": "381\n", "authors": ["1628"]}
{"title": "PDDL2. 2: The language for the classical part of the 4th international planning competition\n", "abstract": " This document defines the language to be used in the classical part of the 4th International Planning Competition, IPC-4. The language comprises all of PDDL2. 1 levels 1, 2, and 3, as defined by Maria Fox and Derek Long in 1] parts of this document have been copied from that source. On top of this language, for IPC-4 derived predicates are re-introduced, and timed initial literals are (newly) introduced into the competition language. We give the syntax and semantics of these constructs.", "num_citations": "310\n", "authors": ["1628"]}
{"title": "Heuristic search: theory and applications\n", "abstract": " Search has been vital to artificial intelligence from the very beginning as a core technique in problem solving. The authors present a thorough overview of heuristic search with a balance of discussion between theoretical analysis and efficient implementation and application to real-world problems. Current developments in search such as pattern databases and search with efficient use of external memory and parallel processing units on main boards and graphics cards are detailed. Heuristic search as a problem solving tool is demonstrated in applications for puzzle solving, game playing, constraint satisfaction and machine learning. While no previous familiarity with heuristic search is necessary the reader should have a basic knowledge of algorithms, data structures, and calculus. Real-world case studies and chapter ending exercises help to create a full and realized picture of how search fits into the world of artificial intelligence and the one around us. Provides real-world success stories and case studies for heuristic search algorithms Includes many AI developments not yet covered in textbooks such as pattern databases, symbolic search, and parallel processing units", "num_citations": "286\n", "authors": ["1628"]}
{"title": "Directed explicit model checking with HSF-SPIN\n", "abstract": " We present the explicit state model checker HSF-SPIN which is based on the model checker SPIN and its Promela modeling language. HSF-SPIN incorporates directed search algorithms for checking safety and a large class of LTL-specified liveness properties. We start off from the A* algorithm and define heuristics to accelerate the search into the direction of a specified failure situation. Next we propose an improved nested depth-first search algorithm that exploits the structure of Promela Never-Claims. As a result of both improvements, counterexamples will be shorter and the explored part of the state space will be smaller than with classical approaches, allowing to analyze larger state spaces. We evaluate the impact of the new heuristics and algorithms on a set of protocol models, some of which are real-world industrial protocols.", "num_citations": "241\n", "authors": ["1628"]}
{"title": "Route planning and map inference with global positioning traces\n", "abstract": " Navigation systems assist almost any kind of motion in the physical world including sailing, flying, hiking, driving and cycling. On the other hand, traces supplied by global positioning systems (GPS) can track actual time and absolute coordinates of the moving objects.             Consequently, this paper addresses efficient algorithms and data structures for the route planning problem based on GPS data; given a set of traces and a current location, infer a short(est) path to the destination.             The algorithm of Bentley and Ottmann is shown to transform geometric GPS information directly into a combinatorial weighted and directed graph structure, which in turn can be queried by applying classical and refined graph traversal algorithms like Dijkstras\u2019 single-source shortest path algorithm or A*.             For high-precision map inference especially in car navigation, algorithms for road segmentation, map matching\u00a0\u2026", "num_citations": "240\n", "authors": ["1628"]}
{"title": "Directed explicit-state model checking in the validation of communication protocols\n", "abstract": " The success of model checking is largely based on its ability to efficiently locate errors in software designs. If an error is found, a model checker produces a trail that shows how the error state can be reached, which greatly facilitates debugging. However, while current model checkers find error states efficiently, the counterexamples are often unnecessarily lengthy, which hampers error explanation. This is due to the use of \u201cnaive\u201d search algorithms in the state space exploration.               In this paper we present approaches to the use of heuristic search algorithms in explicit-state model checking. We present the class of A* directed search algorithms and propose heuristics together with bitstate compression techniques for the search of safety property violations. We achieve great reductions in the length of the error trails, and in some instances render problems analyzable by exploring a much smaller number of\u00a0\u2026", "num_citations": "221\n", "authors": ["1628"]}
{"title": "Time complexity of iterative-deepening-A\u2217\n", "abstract": " We analyze the time complexity of iterative-deepening-A\u2217(IDA\u2217). We first show how to calculate the exact number of nodes at a given depth of a regular search tree, and the asymptotic brute-force branching factor. We then use this result to analyze IDA\u2217 with a consistent, admissible heuristic function. Previous analyses relied on an abstract analytic model, and characterized the heuristic function in terms of its accuracy, but do not apply to concrete problems. In contrast, our analysis allows us to accurately predict the performance of IDA\u2217 on actual problems such as the sliding-tile puzzles and Rubik's Cube. The heuristic function is characterized by the distribution of heuristic values over the problem space. Contrary to conventional wisdom, our analysis shows that the asymptotic heuristic branching factor is the same as the brute-force branching factor. Thus, the effect of a heuristic function is to reduce the effective\u00a0\u2026", "num_citations": "192\n", "authors": ["1628"]}
{"title": "The deterministic part of IPC-4: An overview\n", "abstract": " We provide an overview of the organization and results of the deterministic part of the 4th International Planning Competition, ie, of the part concerned with evaluating systems doing deterministic planning. IPC-4 attracted even more competing systems than its already large predecessors, and the competition event was revised in several important respects. After giving an introduction to the IPC, we briefly explain the main differences between the deterministic part of IPC-4 and its predecessors. We then introduce formally the language used, called PDDL2. 2 that extends PDDL2. 1 by derived predicates and timed initial literals. We list the competing systems and overview the results of the competition. The entire set of data is far too large to be presented in full. We provide a detailed summary; the complete data is available in an online appendix. We explain how we awarded the competition prizes.", "num_citations": "175\n", "authors": ["1628"]}
{"title": "Incremental map generation with GPS traces\n", "abstract": " This paper provides a generic approach for map generation based on Global Positioning System (GPS) traces especially for unknown terrains. The system uses AI algorithms to infer the road geometry. Given a set of GPS traces, this input is refined by filtering and partitioning algorithms. For constructing the graph, clustering algorithms are applied that allow to incrementally generate a road map, annotated with travel time information. The processing of the input data relies on a subdivision of the world into tiles. A flexible map viewer is provided to navigate through the hierarchically organized content of the database. The system provides the export of maps to serve e.g. as the input for a routing server, which in turn can be queried via TCP/IP for shortest and quickest routes.", "num_citations": "156\n", "authors": ["1628"]}
{"title": "MIPS: The model-checking integrated planning system\n", "abstract": " Mips is a planning system that applies binary decision diagrams (BDDs) to compactly represent world states in a planning problem and efficiently explore the underlying state space. It was the first general planning system based on model-checking methods. It can handle the strips subset of the pddl language and some additional features from adl, namely, negative preconditions and (universal) conditional effects. At the Fifth International Conference on Artificial Intelligence Planning and Scheduling (AIPS'00), mips was one of five planning systems to be awarded for distinguished performance in the fully automated track. This article gives a brief introduction to, and explains the basic planning algorithm used by, mips, using a simple logistics problem as an example.", "num_citations": "139\n", "authors": ["1628"]}
{"title": "Exhibiting knowledge in planning problems to minimize state encoding length\n", "abstract": " In this paper we present a general-purposed algorithm for transforming a planning problem specified in Strips into a concise state description for single state or symbolic exploration.             The process of finding a state description consists of four phases. In the first phase we symbolically analyze the domain specification to determine constant and one-way predicates, i.e. predicates that remain unchanged by all operators or toggle in only one direction, respectively.             In the second phase we symbolically merge predicates invariants which lead to a drastic reduction of state encoding size, while in the third phase we constrain the domains of the predicates to be considered by enumerating the operators of the planning problem. The fourth phase combines the result of the previous phases.", "num_citations": "131\n", "authors": ["1628"]}
{"title": "Symbolic Pattern Databases in Heuristic Search Planning.\n", "abstract": " This paper invents symbolic pattern databases (SPDB) to combine two influencing aspects for recent progress in domain-independent action planning, namely heuristic search and model checking. SPDBs are off-line computed dictionaries, generated in symbolic backward traversals of automatically inferred planning space abstractions. The entries of SPDBs serve as heuristic estimates to accelerate explicit and symbolic, approximate and optimal heuristic search planners. Selected experiments highlight that the symbolic representation yields much larger and more accurate pattern databases than the ones generated with explicit methods.", "num_citations": "125\n", "authors": ["1628"]}
{"title": "OBDDs in heuristic search\n", "abstract": " The use of a lower bound estimate in the search has a tremendous impact on the size of the resulting search trees, whereas OBDDs can be used to efficiently describe sets of states based on their binary encoding. This paper combines these two ideas into a new algorithm BDDA               *. It challenges both the breadth-first search using OBDDs and the traditional A               * algorithm. The problem with A               * is that in many application areas the set of states is too huge to be kept in main memory. In contrast, brute-force breadth-first search using OBDDs unnecessarily expands several nodes. Therefore, we exhibit a new trade-off between time and space requirements and tackle the most important problem in heuristic search, the overcoming of space limitations while avoiding a strong penalty in time. We evaluate our approach in the (n               2\u22121)-Puzzle and within Sokoban.", "num_citations": "125\n", "authors": ["1628"]}
{"title": "Taming numbers and durations in the model checking integrated planning system\n", "abstract": " The Model Checking Integrated Planning System (MIPS) is a temporal least commitment heuristic search planner based on a flexible object-oriented workbench architecture. Its design clearly separates explicit and symbolic directed exploration algorithms from the set of on-line and off-line computed estimates and associated data structures.", "num_citations": "109\n", "authors": ["1628"]}
{"title": "Engineering benchmarks for planning: the domains used in the deterministic part of IPC-4\n", "abstract": " In a field of research about general reasoning mechanisms, it is essential to have appropriate benchmarks. Ideally, the benchmarks should reflect possible applications of the developed technology. In AI Planning, researchers more and more tend to draw their testing examples from the benchmark collections used in the International Planning Competition (IPC). In the organization of (the deterministic part of) the fourth IPC, IPC-4, the authors therefore invested significant effort to create a useful set of benchmarks. They come from five different (potential) real-world applications of planning: airport ground traffic control, oil derivative transportation in pipeline networks, model-checking safety properties, power supply restoration, and UMTS call setup. Adapting and preparing such an application for use as a benchmark in the IPC involves, at the time, inevitable (often drastic) simplifications, as well as careful choice between, and engineering of, domain encodings. For the first time in the IPC, we used compilations to formulate complex domain features in simple languages such as STRIPS, rather than just dropping the more interesting problem constraints in the simpler language subsets. The article explains and discusses the five application domains and their adaptation to form the PDDL test suites used in IPC-4. We summarize known theoretical results on structural properties of the domains, regarding their computational complexity and provable properties of their topology under the h+ function (an idealized version of the relaxed plan heuristic). We present new (empirical) results illuminating properties such as the quality of the most wide-spread\u00a0\u2026", "num_citations": "75\n", "authors": ["1628"]}
{"title": "Large-scale optimal PDDL3 planning with MIPS-XXL\n", "abstract": " State trajectory and preference constraints are the two language features introduced in PDDL3 (Gerevini & Long 2005) for describing benchmarks of the 5th international planning competition. State trajectory constraints provide an important step of the agreed fragment of PDDL towards the description of temporal control knowledge and temporally extended goals They assert conditions that must be met during the execution of a plan and are often expressed using quantification over domain objects.We suggest to compile the state trajectory and preference constraints into PDDL2 (Edelkamp 2006). Trajectory constraints are compiled into B\u00fcchi automata that are synchronized with the exploration of the planning problem, while preference constraints are transformed into numerical fluents that are changed upon violation. An internal weighted best-first search is invoked that tries to find a solution. Once a solution is found, the solution quality is inserted in the problem description and a new search is started using earlier solution cost as the minimization parameter. If the internal search fails to terminate with in a specified amount of time, we switch to a cost-optimal external breadth-first search procedure that utilizes harddisk to store the generated states.", "num_citations": "70\n", "authors": ["1628"]}
{"title": "Partial order reduction in directed model checking\n", "abstract": " Partial order reduction is a very succesful technique for avoiding the state explosion problem that is inherent to explicit state model checking of asynchronous concurrent systems. It exploits the commutativity of concurrently executed transitions in interleaved system runs in order to reduce the size of the explored state space. Directed model checking on the other hand addresses the state explosion problem by using guided search techniques during state space exploration. As a consequence, shorter errors trails are found and less search effort is required than when using standard depth-first or breadth-first search. We analyze how to combine directed model checking with partial order reduction methods and give experimental results on how the combination of both techniques performs.", "num_citations": "68\n", "authors": ["1628"]}
{"title": "Large-scale directed model checking LTL\n", "abstract": " To analyze larger models for explicit-state model checking, directed model checking applies error-guided search, external model checking uses secondary storage media, and distributed model checking exploits parallel exploration on multiple processors.               In this paper we propose an external, distributed and directed on-the-fly model checking algorithm to check general LTL properties in the model checker SPIN. Previous attempts are restricted to checking safety properties. The worst-case I/O complexity is bounded by $O(\\mbox{\\em sort}(|{\\cal F}||{\\cal R}|)/p+ l \\cdot \\mbox{\\em scan}(|{\\cal F}||{\\cal S}|))$, where  and  are the sets of visited states and transitions in the synchronized product of the B\u00fcchi automata for the model and the property specification,  is the number of accepting states, l is the length of the shortest counterexample, and p is the number of processors. The algorithm we propose\u00a0\u2026", "num_citations": "65\n", "authors": ["1628"]}
{"title": "On the implementation of MIPS\n", "abstract": " Planning is a central topic of AI and provides solutions to problems given in a problem independent formalism. Recent successes in the exploration of model checking and single-agent search problems have led to a generalization of the symbolic exploration method with binary decision diagrams (BDDs).", "num_citations": "63\n", "authors": ["1628"]}
{"title": "On the Compilation of Plan Constraints and Preferences.\n", "abstract": " State trajectory and preference constraints are the two language features introduced in PDDL3 (Gerevini & Long 2005) for describing benchmarks of the 5th international planning competition. In this work we make existing solver technology applicable to planning with PDDL3 domains by compiling the new constructs back to PDDL2 (Fox & Long 2003). State trajectory constraints are translated into LTL formulae and further to B\u00fcchi automata, one for each constraint. These automata are compiled to grounded PDDL and the results are merged with the grounded representation of the original problem. Preference constraints are compiled away using numerical state variables. We provide encouraging experimental results in heuristic search planning.", "num_citations": "62\n", "authors": ["1628"]}
{"title": "Optimal symbolic planning with action costs and preferences\n", "abstract": " This paper studies the solving of finite-domain action planning problems with discrete action costs and soft constraints. For sequential optimal planning, a symbolic perimeter database heuristic is addressed in a bucket implementation of A*. For computing net-benefits, we propose symbolic branch-and-bound search together with some search refinements. The net-benefit we optimize is the total benefit of satisfying the goals, minus the total action cost to achieve them. This results in an objective function to be minimized that is a linear expression over the violation of the preferences added to the action cost total.", "num_citations": "60\n", "authors": ["1628"]}
{"title": "Protocol verification with heuristic search\n", "abstract": " We present an approach to reconcile explicit state model checking and heuristic directed search and provide experimental evidence that the model checking problem for concurrent systems, such as communications protocols, can be solved more efficiently, since finding a state violating a property can be understood as a directed search problem. In our work we combine the expressive power and implementation efficiency of the SPIN model checker with the HSF heuristic search workbench, yielding the HSF-SPIN tool that we have implemented. We start off from the A* algorithm and some of its derivatives and define heuristics for various system properties that guide the search so that it finds error states faster. In this paper we focus on safety properties and provide heuristics for invariant and assertion violation and deadlock detection. We provide experimental results for applying HSF-SPIN to two toy protocols and one real world protocol, the CORBA GIOP protocol.", "num_citations": "60\n", "authors": ["1628"]}
{"title": "SymBA*: A symbolic bidirectional A* planner\n", "abstract": " Lately, several important advancements have been obtained in symbolic search. First, bidirectional blind search has obtained good results on many domains. Second, perimeter-based abstraction heuristics have been proposed as an important improvement over regular abstraction heuristics. Motivated by the synergy between bidirectional search and perimeter-based abstraction heuristics, here we present SymBA*, which performs bidirectional A* using the frontiers of the opposite search to infer informed perimeter-based abstraction heuristics.", "num_citations": "57\n", "authors": ["1628"]}
{"title": "Automated creation of pattern database search heuristics\n", "abstract": " Pattern databases are dictionaries for heuristic estimates storing state-to-goal distances in state space abstractions. Their effectiveness is sensitive to the selection of the underlying patterns. Especially for multiple and additive pattern databases, the manual selection of patterns that leads to good exploration results is involved.             For automating the selection process, greedy bin-packing has been suggested. This paper proposes genetic algorithms to optimize its output. Patterns are encoded as binary strings and optimized using an objective function that predicts the heuristic search tree size based on the distribution of heuristic values in abstract space.             To reduce the memory requirements we construct the pattern databases symbolically. Experiments in heuristic search planning indicate that the total search efforts can be reduced significantly.", "num_citations": "55\n", "authors": ["1628"]}
{"title": "External A*\n", "abstract": " In this paper we study External A*, a variant of the conventional (internal) A* algorithm that makes use of external memory, e.g., a hard disk. The approach applies to implicit, undirected, unweighted state space problem graphs with consistent estimates. It combines all three aspects of best-first search, frontier search and delayed duplicate detection and can still operate on very small internal memory. The complexity of the external algorithm is almost linear in external sorting time and accumulates to $O(\\mbox{\\em sort}(|E|) + \\mbox{\\em scan}(|V|))$ I/O operations, where V and E are the set of nodes and edges in the explored portion of the state space graph. Given that delayed duplicate elimination has to be performed, the established bound is I/O optimal. In contrast to the internal algorithm, we exploit memory locality to allow blockwise rather than random access. The algorithmic design refers to external\u00a0\u2026", "num_citations": "54\n", "authors": ["1628"]}
{"title": "Survey on directed model checking\n", "abstract": " This article surveys and gives historical accounts to the algorithmic essentials of directed model checking, a promising bug-hunting technique to mitigate the state explosion problem. In the enumeration process, successor selection is prioritized. We discuss existing guidance and methods to automatically generate them by exploiting system abstractions. We extend the algorithms to feature partial-order reduction and show how liveness problems can be adapted by lifting the search space. For deterministic, finite domains we instantiate the algorithms to directed symbolic, external and distributed search. For real-time domains we discuss the adaption of the algorithms to timed automata and for probabilistic domains we show the application to counterexample generation. Last but not least, we explain how directed model checking helps to accelerate finding solutions to scheduling problems.", "num_citations": "51\n", "authors": ["1628"]}
{"title": "Parallel external directed model checking with linear I/O\n", "abstract": " In this paper we present Parallel External A*, a parallel variant of external memory directed model checking. As a model scales up, its successors generation becomes complex and, in turn, starts to impact the running time of the model checker. Probings of our external memory model checker IO-HSF-SPIN revealed that in some of the cases about 70% of the whole running time was consumed in the internal processing. Employing a multiprocessor machine or a cluster of workstations, we can distribute the internal working load of the algorithm on multiple processors.             Moreover, assuming a sufficient number of processors and number of open file pointers per process, the I/O complexity is reduced to linear by exploiting a hash-function based state space partition scheme.", "num_citations": "51\n", "authors": ["1628"]}
{"title": "Promela planning\n", "abstract": " The paper presents a structured translation from a static (bounded) subset of PROMELA/SPIN to the planning description language PDDL2.1. It exploits the representation of protocols as communicating finite state machines.             First, the state-space representation is defined to handle processes, queues, and shared variables. Second, each basic statement (assignment, input, etc.) is translated into a couple of predicates.             The deadlock detection problem is reformulated as an action planning problem and SPIN is compared to two action planners Metric-FF and MIPS on several benchmarks (e.g. leader election, dining philosophers, optical telegraph).             The difference to existing approaches is the direct use of planning tools. As a byproduct this introduces refined estimates for improved error detection in directed protocol validation.", "num_citations": "51\n", "authors": ["1628"]}
{"title": "Error detection with directed symbolic model checking\n", "abstract": " In practice due to entailed memory limitations the most important problem in model checking is state space explosion. Therefore, to prove the correctness of a given design binary decision diagrams (BDDs) are widely used as a concise and symbolic state space representation. Nevertheless, BDDs are not able to avoid an exponential blow-up in general. If we restrict ourselves to find an error of a design which violates a safety property, in many cases a complete state space exploration is not necessary and the introduction of a heuristic to guide the search can help to keep both the explored part and the associated BDD representation smaller than with the classical approach.               In this paper we will show that this idea can be extended with an automatically generated heuristic and that it is applicable to a large class of designs. Since the proposed algorithm can be expressed in terms of BDDs it is even\u00a0\u2026", "num_citations": "50\n", "authors": ["1628"]}
{"title": "Trail-directed model checking\n", "abstract": " HSF-SPIN is a Promela model checker based on heuristic search strategies. It utilizes heuristic estimates in order to direct the search for finding software bugs in concurrent systems. As a consequence, HSF-SPIN is able to find shorter trails than blind depth-first search.This paper contributes an extension to the paradigm of directed model checking to shorten already established unacceptable long error trails. This approach has been implemented in HSF-SPIN. For selected benchmark and industrial communication protocols experimental evidence is given that trail-directed model-checking effectively shortcuts existing witness paths.", "num_citations": "48\n", "authors": ["1628"]}
{"title": "Geometric travel planning\n", "abstract": " This paper provides a novel approach for optimal route planning by making efficient use of the underlying geometrical structure. It combines classical artificial intelligence exploration with computational geometry. Given a set of global positioning system (GPS) trajectories, the input is refined by geometric filtering and rounding algorithms. For constructing the graph and the according point-localization structure, fast scan line and divide-and-conquer algorithms are applied. For speeding up the optimal online search algorithms, the geometrical structure of the inferred weighted graph is exploited in two ways; it is compressed while retaining the original information for unfolding resulting shortest paths and is then annotated by lower bounds and refined topographic information (for example, by the bounding boxes of all shortest paths that start with a given edge). Traffic disturbances can result in an increase in travel time\u00a0\u2026", "num_citations": "47\n", "authors": ["1628"]}
{"title": "Directed error detection in C++ with the assembly-level model checker StEAM\n", "abstract": " Most approaches for model checking software are based on the generation of abstract models from source code, which may greatly reduce the search space, but may also introduce errors that are not present in the actual program.               In this paper, we propose a new model checker for the verification of native c++-programs. To allow platform independent model checking of the object code for concurrent programs, we have extended an existing virtual machine for c++ to include multi-threading and different exploration algorithms on a dynamic state description.               The error reporting capabilities and the lengths of counter-examples are improved by using heuristic estimator functions and state space compaction techniques that additionally reduce the exploration efforts.               The evaluation of four scalable simple example problems shows that our system StEAM can successfully enhance the\u00a0\u2026", "num_citations": "44\n", "authors": ["1628"]}
{"title": "Symbolic classification of general two-player games\n", "abstract": " In this paper we present a new symbolic algorithm for the classification, i. e. the calculation of the rewards for both players in case of optimal play, of two-player games with general rewards according to the Game Description Language. We will show that it classifies all states using a linear number of images concerning the depth of the game graph. We also present an extension that uses this algorithm to create symbolic endgame databases and then performs UCT to find an estimate for the classification of the game.", "num_citations": "43\n", "authors": ["1628"]}
{"title": "Algorithm and knowledge engineering for the TSPTW problem\n", "abstract": " The well-known traveling salesman problem (TSP) is concerned with determining the shortest route for a vehicle while visiting a set of cities exactly once. We consider knowledge and algorithm engineering in combinatorial optimization for improved solving of complex TSPs with Time Windows (TSPTW). To speed-up the exploration of the applied Nested Monte-Carlo Search with Policy Adaption, we perform beam search for an improved compromise of search breadth and depth as well as automated knowledge elicitation to seed the distribution for the exploration. To evaluate our approach, we use established TSPTW benchmarks with promising results. Furthermore, we indicate improvements for real-world logistics by its use in a multiagent system. Thereby, each agent computes individual TSPTW solutions and starts negotiation processes on this basis.", "num_citations": "41\n", "authors": ["1628"]}
{"title": "Efficient probabilistic model checking on general purpose graphics processors\n", "abstract": " We present algorithms for parallel probabilistic model checking on general purpose graphic processing units (GPGPUs). For this purpose we exploit the fact that some of the basic algorithms for probabilistic model checking rely on matrix vector multiplication. Since this kind of linear algebraic operations are implemented very efficiently on GPGPUs, the new parallel algorithms can achieve considerable runtime improvements compared to their counterparts on standard architectures. We implemented our parallel algorithms on top of the probabilistic model checker PRISM. The prototype implementation was evaluated on several case studies in which we observed significant speedup over the standard CPU implementation of the tool.", "num_citations": "41\n", "authors": ["1628"]}
{"title": "On the Performance of WEAK-HEAPSORT\n", "abstract": " Dutton (1993) presents a further HEAPSORT variant called WEAK-HEAPSORT, which also contains a new data structure for priority queues. The sorting algorithm and the underlying data structure are analyzed showing that WEAK-HEAPSORT is the best HEAPSORT variant and that it has a lot of nice properties.             It is shown that the worst case number of comparisons is n\u2308log n\u2309 \u2014 2\u2308log n\u2309 + n \u2212 \u2308log n\u2309 \u2264 n log n + 0.1n and weak heaps can be generated with n \u2212 1 comparisons. A double-ended priority queue based on weakheaps can be generated in n + \u2308n/2\u2309 \u2212 2 comparisons.             Moreover, examples for the worst and the best case of WEAK-HEAP-SORT are presented, the number of Weak-Heaps on 1, ... , n is determined, and experiments on the average case are reported.", "num_citations": "39\n", "authors": ["1628"]}
{"title": "The branching factor of regular search spaces\n", "abstract": " Many problems, such as the sliding-tile puzzles, generate search trees where different nodes have different numbers of children, in this case depending on the position of the blank. We show how to calculate the asymptotic branching factors of such problems, and how to efficiently compute the exact numbers of nodes at a given depth. This information is important for determining the complexity of various search algorithms on these problems. In addition to the sliding-tile puzzles, we also apply our technique to Rubik\u2019s Cube. While our techniques are fairly straightforward, the literature is full of incorrect branching factors for these problems, and the errors in several incorrect methods are fairly subtle.", "num_citations": "39\n", "authors": ["1628"]}
{"title": "Efficient symbolic search for cost-optimal planning\n", "abstract": " In cost-optimal planning we aim to find a sequence of operators that achieve a set of goals with minimum cost. Symbolic search with Binary Decision Diagrams (BDDs) performs efficient state space exploration in terms of time and memory. This is crucial in optimal settings, in which large parts of the state space must be explored in order to prove optimality. However, the development of accurate heuristics for explicit-state search in recent years have left symbolic search techniques in a secondary place. In this article we propose two orthogonal improvements for symbolic search planning. On the one hand, we analyze and compare different methods for image computation in order to efficiently perform the successor generation on symbolic search. Image computation is the main bottleneck of symbolic search algorithms so an efficient computation is paramount for efficient symbolic search planning. On the other hand\u00a0\u2026", "num_citations": "38\n", "authors": ["1628"]}
{"title": "Improving cost-optimal domain-independent symbolic planning\n", "abstract": " Symbolic search with BDDs has shown remarkable performance for cost-optimal deterministic planning by exploiting a succinct representation and exploration of state sets. In this paper we enhance BDD-based planning by applying a combination of domain-independent search techniques: the optimization of the variable ordering in the BDD by approximating the linear arrangement problem, pattern selection for improved construction of search heuristics in form of symbolic partial pattern databases, and a decision procedure for the amount of bidirection in the symbolic search process.", "num_citations": "38\n", "authors": ["1628"]}
{"title": "Parallel probabilistic model checking on general purpose graphics processors\n", "abstract": " We present algorithms for parallel probabilistic model checking on general purpose graphic processing units (GPGPUs). Our improvements target the numerical components of the traditional sequential algorithms. In particular, we capitalize on the fact that in most of them operations like matrix\u2013vector multiplication and solving systems of linear equations are the main complexity bottlenecks. Since linear algebraic operations can be implemented very efficiently on GPGPUs, the new parallel algorithms show considerable runtime improvements compared to their counterparts on standard architectures. We implemented our parallel algorithms on top of the probabilistic model checker PRISM. The prototype implementation was evaluated on several case studies in which we observed significant speedup over the standard CPU implementation of the tool.", "num_citations": "38\n", "authors": ["1628"]}
{"title": "Action planning for directed model checking of Petri nets\n", "abstract": " Petri nets are fundamental to the analysis of distributed systems especially infinite-state systems. Finding a particular marking corresponding to a property violation in Petri nets can be reduced to exploring a state space induced by the set of reachable markings. Typical exploration(reachability analysis) approaches are undirected and do not take into account any knowledge about the structure of the Petri net. This paper proposes heuristic search for enhanced exploration to accelerate the search. For different needs in the system development process, we distinguish between different sorts of estimates.Treating the firing of a transition as an action applied to a set of predicates induced by the Petri net structure and markings, the reachability analysis can be reduced to finding a plan to an AI planning problem. Having such a reduction broadens the horizons for the application of AI heuristic search planning technology\u00a0\u2026", "num_citations": "36\n", "authors": ["1628"]}
{"title": "Partial-order reduction and trail improvement in directed model checking\n", "abstract": " In this paper we present work on trail improvement and partial-order reduction in the context of directed explicit-state model checking. Directed explicit-state model checking employs directed heuristic search algorithms such as A* or best-first search to improve the error-detection capabilities of explicit-state model checking. We first present the use of directed explicit-state model checking to improve the length of already established error trails. Second, we show that partial-order reduction, which aims at reducing the size of the state space by exploiting the commutativity of concurrent transitions in asynchronous systems, can coexist well with directed explicit-state model checking. Finally, we illustrate how to mitigate the excessive length of error trails produced by partial-order reduction in explicit-state model checking. In this context we also propose a combination of heuristic search and partial-order reduction\u00a0\u2026", "num_citations": "35\n", "authors": ["1628"]}
{"title": "Semi-external LTL model checking\n", "abstract": " In this paper we establish c-bit semi-external graph algorithms, \u2013 i.e., algorithms which need only a constant number c of bits per vertex in the internal memory. In this setting, we obtain new trade-offs between time and space for I/O efficient LTL model checking. First, we design a c-bit semi-external algorithm for depth-first search. To achieve a low internal memory consumption, we construct a RAM-efficient perfect hash function from the vertex set stored on disk. We give a similar algorithm for double depth-first search, which checks for presence of accepting cycles and thus solves the LTL model checking problem. The I/O complexity of the search itself is proportional to the time for scanning the search space. For on-the-fly model checking we apply iterative-deepening strategy known from bounded model checking.", "num_citations": "34\n", "authors": ["1628"]}
{"title": "Mixed Propositional and Numeric Planning in the Model Checking Integrated Planning System.\n", "abstract": " The paper considers the extensions to the domainindependent Model Checking Integrated Planning System (MIPS) to pre-processes and solve mixed propositional and numerical planning problems in PDDL+ syntax for the 3rd international planning competition. The static analyzer grounds all predicates and functors, distinguishes constant from fluent atoms and numerical constants from variables. It further approximates the bounding intervals for the resource variables, and encodes their possible finite domain. Pre-compilation also establishes symmetries within the object set and dependencies among the set of operators. Based on the inferred information, the directed search exploration algorithm applies critical path scheduling to parallelize sequential plans and to refine a relaxed plan graph heuristic, while different pruning approaches effectively reduce the branching factor.", "num_citations": "34\n", "authors": ["1628"]}
{"title": "Localizing A*\n", "abstract": " Heuristic search in large problem spaces inherently calls for algorithms capable of running under restricted memory. This question has been investigated in a number of articles. However, in general the efficient usage of two-layered storage systems is not further discussed. Even if hard-disk capacity is sufficient for the problem instance at hand, the limitation of main memory may still represent the bottleneck for their practical applications. Since breadth-first and best-first strategies do not exhibit any locality of expansion, standard virtual memory management can soon result in thrashing due to excessive page faults.In this paper we propose a new search algorithm and suitable data structures in order to minimize page faults by a local reordering of the sequence of expansions. We prove its correctness and completeness and evaluate it in a real-world scenario of searching a large road map in a commercial route planning system.", "num_citations": "33\n", "authors": ["1628"]}
{"title": "Solving fully-observable non-deterministic planning problems via translation into a general game\n", "abstract": " In this paper, we propose a symbolic planner based on BDDs, which calculates strong and strong cyclic plans for a given non-deterministic input. The efficiency of the planning approach is based on a translation of the non-deterministic planning problems into a two-player turn-taking game, with a set of actions selected by the solver and a set of actions taken by the environment.               The formalism we use is a PDDL-like planning domain definition language that has been derived to parse and instantiate general games. This conversion allows to derive a concise description of planning domains with a minimized state vector, thereby exploiting existing static analysis tools for deterministic planning.", "num_citations": "32\n", "authors": ["1628"]}
{"title": "Monte-Carlo tree search for logistics\n", "abstract": " In this paper we review recent advances of randomized AI search in solving industrially relevant optimization problems. The method we focus on is a sampling-based solution mechanism called Monte-Carlo Tree Search (MCTS), which is extended by the concepts of nestedness and policy adaptation to establish a better trade-off between exploitation and exploration. This method, originating in game playing research, is a general heuristic search technique, for which often less problem-specific knowledge has to be added than in comparable approaches.", "num_citations": "30\n", "authors": ["1628"]}
{"title": "External Symbolic Heuristic Search with Pattern Databases.\n", "abstract": " In this paper we propose refinements for optimal search with symbolic pattern databases in deterministic statespace planning. As main memory is limited, external heuristic search is combined with the power of symbolic representation. We start with an external version of symbolic breadth-first search. Then an alternative and external implementation for BDDA* to include different heuristic evaluation functions into the symbolic search process is presented. We evaluate the approach in benchmarks taken from the 4th international planning competition.", "num_citations": "30\n", "authors": ["1628"]}
{"title": "Efficient explicit-state model checking on general purpose graphics processors\n", "abstract": " We accelerate state space exploration for explicit-state model checking by executing complex operations on the graphics processing unit (GPU). In contrast to existing approaches enhancing model checking through performing parallel matrix operations on the GPU, we parallelize the breadth-first layered construction of the state space graph. For efficient processing, the input model is translated to the reverse Polish notation, resulting in a representation as an integer vector. The proposed GPU exploration algorithm then divides into two parallel stages. In the first stage, each state is replaced with a Boolean vector to denote which transitions are enabled. In the second stage, pairs consisting of replicated states and enabled transition IDs are copied to the GPU then all transitions are applied in parallel to produce the successors. Bitstate hashing is used as a Bloom filter to remove duplicates from the set of\u00a0\u2026", "num_citations": "29\n", "authors": ["1628"]}
{"title": "Heuristic search for the analysis of graph transition systems\n", "abstract": " Graphs are suitable modeling formalisms for software and hardware systems involving aspects such as communication, object orientation, concurrency, mobility and distribution. State spaces of such systems can be represented by graph transition systems, which are basically transition systems whose states and transitions represent graphs and graph morphisms. Heuristic search is a successful Artificial Intelligence technique for solving exploration problems implicitly present in games, planning, and formal verification. Heuristic search exploits information about the problem being solved to guide the exploration process. The main benefits are significant reductions in the search effort and the size of solutions. We propose the application of heuristic search for the analysis of graph transition systems. We define algorithms and heuristics and present experimental results.", "num_citations": "29\n", "authors": ["1628"]}
{"title": "Byte code distance heuristics and trail direction for model checking Java programs\n", "abstract": " The integration of AI search methods in model checking applications has shown considerable success to accelerate hard-and software verification tasks. Unfortunately, in order to be analyzed the implemented system has to be modeled in checker specification languages. To the contrary, the automated verification of source-code, known as program verification, is an in-situ validation process that directly processes the compiled code. In this work, Java programs and their corresponding byte codes are chosen. To tackle the state explosion problem that arises due to the different forms of non-deterministic execution branches such as multi-threading, this paper introduces byte code distance heuristics to guide the exploration. Consequently, we extend the Java software verifier JPF. The application scenario is trail-directed program verification, where the main purpose is to shorten an already established error trail, so\u00a0\u2026", "num_citations": "28\n", "authors": ["1628"]}
{"title": "Implementing HEAPSORT with (n logn - 0.9n) and QUICKSORT with (n logn + 0.2n) comparisons\n", "abstract": " With refinements to the WEAK-HEAPSORT algorithm we establish the general and practical relevant sequential sorting algorithm INDEX-WEAK-HEAPSORT with exactly n\u2308log n\u2309 - 2\u2308log n\u2309 + 1 \u2264 n log n-0.9n comparisons and at most n log n + 0.1n transpositions on any given input. It comprises an integer array of size n and is best used to generate an index for the data set. With RELAXED-WEAK-HEAPSORT and GREEDY-WEAK-HEAPSORT we discuss modifications for a smaller set of pending element transpositions.If extra space to create an index is not available, with QUICK-WEAK-HEAPSORT we propose an efficient QUICKSORT variant with n log n + 0.2n + o(n) comparisons on the average. Furthermore, we present data showing that WEAK-HEAPSORT, INDEX-WEAK-HEAPSORT and QUICK-WEAK-HEAPSORT compete with other performant QUICKSORT and HEAPSORT variants.", "num_citations": "28\n", "authors": ["1628"]}
{"title": "Gamer, a general game playing agent\n", "abstract": " This work is concerned with our general game playing agent Gamer. In contrast to many other players, we do not only use a Prolog-like mechanism to infer knowledge about the current state and the available moves but instantiate the games to reduce the inference time in parallel UCT game tree search. Furthermore, we use the generated output to try to solve the games using symbolic search methods and thus play optimally.", "num_citations": "27\n", "authors": ["1628"]}
{"title": "Finding optimal solutions to Atomix\n", "abstract": " We present solutions of benchmark instances to the solitaire computer game Atomix found with different heuristic search methods. The problem is PSPACE-complete. An implementation of the heuristic algorithm A* is presented that needs no priority queue, thereby having very low memory overhead. The limited memory algorithm IDA* is handicapped by the fact that, due to move transpositions, duplicates appear very frequently in the problem space; several schemes of using memory to mitigate this weakness are explored, among those, \u201cpartial\u201d schemes which trade memory savings for a small probability of not finding an optimal solution. Even though the underlying search graph is directed, backward search is shown to be viable, since the branching factor can be proven to be the same as for forward search.", "num_citations": "27\n", "authors": ["1628"]}
{"title": "Symbolic A* Search with Pattern Databases and the Merge-and-Shrink Abstraction.\n", "abstract": " The efficiency of heuristic search planning crucially depends on the quality of the search heuristic, while succinct representations of state sets in decision diagrams can save large amounts of memory in the exploration. BDDA*\u2013a symbolic version of A* search\u2013combines the two approaches into one algorithm. This paper compares two of the leading heuristics for sequential-optimal planning: the merge-and-shrink and the pattern databases heuristic, both of which can be compiled into a vector of BDDs and be used in BDDA*. The impact of optimizing the variable ordering is highlighted and experiments on benchmark domains are reported.", "num_citations": "25\n", "authors": ["1628"]}
{"title": "Instantiating general games using prolog or dependency graphs\n", "abstract": " This paper proposes two ways to instantiate general games specified in the game description language GDL to enhance exploration efficiencies of existing players. One uses Prolog\u2019s inference mechanism to find supersets of reachable atoms and moves; the other one utilizes dependency graphs, a datastructure that can calculate the dependencies of the arguments of predicates by evaluating the various formulas from the game\u2019s description.", "num_citations": "25\n", "authors": ["1628"]}
{"title": "Exploiting the computational power of the graphics card: Optimal state space planning on the GPU\n", "abstract": " In this paper optimal state space planning is parallelized by exploiting the processing power of a graphics card. The two exploration steps, namely selecting the actions to be applied and generating the successors, are performed on a graphics processing unit. Duplicate detection, however, is delayed to be executed on the central processing unit. Multiple cores are employed to bypass main memory latency. To increase processing speed for exact duplicate detection, the hash tables are lock-free. Moreover, a bucket-based representation enhances the concurrent distribution of frontier states. The planner supports cost-first exploration and is able to deal with a considerable fraction of current PDDL, including numerical state variables, complex objective functions, and goal preferences. It can maximize the net-benefit. Experimental findings show visible performance gains especially for larger benchmark problems.", "num_citations": "24\n", "authors": ["1628"]}
{"title": "Limits and possibilities of BDDs in state space search\n", "abstract": " This paper investigates the impact of symbolic search for solving domain-independent action planning problems with binary decision diagrams (BDDs). Polynomial upper and exponential lower bounds on the number of BDD nodes for characteristic benchmark problems are derived and validated. In order to optimize the variable ordering, causal graph dependencies are exploited.", "num_citations": "24\n", "authors": ["1628"]}
{"title": "Optimal symbolic PDDL3 planning with MIPS-BDD\n", "abstract": " State trajectory and plan preference constraints are the two language features introduced in PDDL3 (Gerevini & Long 2005) for describing benchmarks of the 5th international planning competition. State trajectory constraints provide an important step of the agreed fragment of PDDL towards the description of temporal control knowledge (Bacchus & Kabanza 2000) and temporally extended goals (DeGiacomo & Vardi 1999). They assert conditions that must be met during the execution of a plan and are often expressed using using quantification over domain objects. Annotating goal conditions and state trajectory constraints with preferences models soft constraints. For planning with preferences, the objective function scales the violation of the constraints. Symbolic exploration based on BDDs (Bryant 1985) acts on sets of states rather than on singular ones and exploit redundancies in the joint state representation. BDDs are directed acyclic automata for the bitvector representation of a state. The unique representation of a state set as a BDD is much more memory-efficient than an explicit representation for the state set. In MIPS-BDD we make optimal BDD solver technology applicable to planning with PDDL3 domains. We compile state trajectory expressions to PDDL2 (Fox & Long 2003). The grounded representation is annotated with propositions that maintain the truth of preferences and operators that model that the synchronized execution or an associated property automaton. We contribute Cost-Optimal Breadth-First-Search and adapt it to the search with preference constraints.", "num_citations": "24\n", "authors": ["1628"]}
{"title": "Knowledge acquisition and knowledge engineering in the modplan workbench\n", "abstract": " In this paper we present the architecture and the abilities of the ModPlan Workbench; an interacive knowledge acquisition and engineering tool for AI planning. It provides automated domain analysis tools together with PDDL learning capabilities. Integrated optimal and suboptimal planning technology extends state-of-the-art technology.With the tool, domain experts assist solving hard combinatorial problems. Approximate or incremental solutions provided by the system are supervised. Intermediate results are accessible to improve domain modeling and to tune exploration in generating enhanced plans, which, in turn, can be bootstrapped for domain description inference.", "num_citations": "24\n", "authors": ["1628"]}
{"title": "Cost-algebraic heuristic search\n", "abstract": " Heuristic search is used to efficiently solve the single-node shortest path problem in weighted graphs. In practice, however, one is not only interested in finding a short path, but an optimal path, according to a certain cost notion. We propose an algebraic formalism that captures many cost notions, like typical Quality of Service attributes. We thus generalize A*, the popular heuristic search algorithm, for solving optimal-path problem. The paper provides an answer to a fundamental question for AI search, namely to which general notion of cost, heuristic search algorithms can be applied. We proof correctness of the algorithms and provide experimental results that validate the feasibility of the approach.", "num_citations": "24\n", "authors": ["1628"]}
{"title": "GPU-PRISM: An extension of PRISM for general purpose graphics processing units\n", "abstract": " We present an extension of the model checker PRISM for (general purpose) graphics processing units (GPUs). The extension is based on parallel algorithms for probabilistic model checking which are tuned for GPUs. In particular, we parallelize the parts of the algorithms that boil down to linear algebraic operations, like solving systems of linear equations and matrix vector multiplication. These computations are performed very efficiently on GPGPUs which results inconsiderable runtime improvements compared to the standard versions of PRISM. We evaluated the extension of PRISM on several case studies in which we observed significant speedup over the standard CPU implementation of the tool.", "num_citations": "23\n", "authors": ["1628"]}
{"title": "Model checking via delayed duplicate detection on the GPU\n", "abstract": " In this paper we improve large-scale disk-based model checking by shifting complex numerical operations to the graphic card, enjoying that during the last decade graphics processing units (GPUs) have become very powerful. For disk-based graph search, the delayed elimination of duplicates is the performance bottleneck as it amounts to sorting large state vector sets. We perform parallel processing on the GPU to improve the sorting speed significantly. Since existing GPU sorting solutions like Bitonic Sort and Quicksort do not obey any speed-up on state vectors, we propose a refined GPU-based Bucket Sort algorithm. Alternatively, we study sorting a compressed state vector and obtain speed-ups for delayed duplicate detection of more than one order of magnitude with a single GPU, located on an ordinary graphic card.", "num_citations": "23\n", "authors": ["1628"]}
{"title": "I/O efficient directed model checking\n", "abstract": " Directed model checking has proved itself to be a useful technique in reducing the state space of the problem graph. But still, its potential is limited by the available memory. This problem can be circumvented by the use of secondary storage devices to store the state space. This paper discusses directed best-first search to enhance error detection capabilities of model checkers like SPIN by using a streamed access to secondary storage. We explain, how to extend SPIN to allow external state access, and how to adapt heuristic search algorithms to ease error detection for this case. We call our derivate IO-HSF-SPIN. In the theoretical part of the paper, we extend the heuristic-based external searching algorithm to general weighted and directed graphs. We conduct experiments with some challenging protocols in Promela syntax like GIOP and dining philosophers and have succeeded in solving some hard\u00a0\u2026", "num_citations": "23\n", "authors": ["1628"]}
{"title": "Symbolic exploration in two-player games: Preliminary results\n", "abstract": " In this paper symbolic exploration with binary decision diagrams (BDDs) is applied to two-player games to improve main memory consumption for reachability analysis and game-theoretical classification, since BDDs provide a compact representation for large set of game positions. A number of examples are evaluated: Tic-Tac-Toe, Nim, Hex, and FourConnect. In Chess we restrict the considerations to the creation of endgame databases. The results are preliminary, but the study puts forth the idea that BDDs are widely applicable in game playing and provides a universal tool for people interested in quickly solving practical problems.", "num_citations": "23\n", "authors": ["1628"]}
{"title": "Monte-Carlo tree search for 3D packing with object orientation\n", "abstract": " In this paper we look at packing problems that naturally arise in container loading. Given a set of 3D iso-oriented objects and a container, the task is to find a packing sequence of the input objects consisting of the ID, location, and orientation that minimizes the space wasted by the packing. Instead of the decision problem, we look at the packing optimization problem, minimizing the total height of a packing. Our solutions uses extreme points and applies Monte-Carlo tree search with policy adaptation, a randomized search technique that has been shown to be effective for solving single-agent games and, more recently, complex traveling salesman and vehicle routing problems. The implementation is considerably simple and conceptually different from mathematical programming branch-and-bound and local search approaches. Nonetheless, the results in solving 2D and 3D packing problems are promising.", "num_citations": "22\n", "authors": ["1628"]}
{"title": "On the complexity of BDDs for state space search: A case study in Connect Four\n", "abstract": " Symbolic search using BDDs usually saves huge amounts of memory, while in some domains its savings are moderate at best. It is an open problem to determine if BDDs work well for a certain domain. Motivated by finding evidences for BDD growths for state space search, in this paper we are concerned with symbolic search in the domain of Connect Four. We prove that there is a variable ordering for which the set of all possible states\u2013when continuing after a terminal state has been reached\u2013can be represented by polynomial sized BDDs, whereas the termination criterion leads to an exponential number of nodes in the BDD given any variable ordering.", "num_citations": "22\n", "authors": ["1628"]}
{"title": "Parallel state space search on the GPU\n", "abstract": " This paper exploits parallel computing power of the graphics card for the enhanced enumeration of state spaces. We illustrate that modern graphics processing units (GPUs) have the potential to speed up state space search significantly. For an bitvector representation of the search frontier, GPU algorithms with one and two bits per state are presented. For enhanced compression efficient perfect hash functions and their inverse are studied. We establish maximal speed-ups of up to factor 30 and more wrt. single core computation.", "num_citations": "22\n", "authors": ["1628"]}
{"title": "Updating Shortest Paths.\n", "abstract": " Moving target search is a state space approach for finding non-stationary goals. The plot is given by a realtime situation in which the target has to be captured by a so-called problem solver. The model chosen in the trailblazer search allows the problem solver to maintain a map of the explored graph and to move faster than the target. Within this map the shortest paths to a current position are calculated after every move that a competitor commits. The trailblazer search does not use information about former maps. Thus, the main problem tackled in this paper is the incremental calculation of the shortest path tree. We proof the correctness of our approach, reason about its efficiency and show that it is empirically good in the average case.", "num_citations": "22\n", "authors": ["1628"]}
{"title": "Solving physical traveling salesman problems with policy adaptation\n", "abstract": " The Physical Traveling Salesman Problem (PTSP) is a current research problem which adds a model of velocity to the classic TSP. In this paper we propose algorithms for solving the PTSP which avoid the fragmented allocation of memory and precompute cell-precise single-source shortest paths for each waypoint by using an engineered implementation of Dijkstra's algorithm. To determine an initial tour, we solve ordinary and general TSPs. For moderately sized problems, we apply an optimal depth-first branch-and-bound TSP solver which warrants constant-time per search tree node. For larger problems, we apply randomized search with policy adaptation to learn from good tours. We evaluate our solution with a series of benchmark experiments and compare the results to the winner of the PTSP competition at CIG 2013. In comparison, our approach shows similar results but also provides a graph search with\u00a0\u2026", "num_citations": "21\n", "authors": ["1628"]}
{"title": "Searching with partial belief states in general games with incomplete information\n", "abstract": " In this paper we present a full-fledged player for general games with incomplete information specified in the game description language GDL-II. To deal with uncertainty we introduce a method that operates on partial belief states, which correspond to a subset of the set of states building a full belief state. To search for a partial belief state we present depth-first and Monte-Carlo methods. All can be combined with any traditional general game player, e.g., using minimax or UCT search.               Our general game player is shown to be effective in a number of benchmarks and the UCT variant compares positively with the one-and-only winner of an incomplete information track at an international general game playing competition.", "num_citations": "21\n", "authors": ["1628"]}
{"title": "Perfect hashing for state space exploration on the GPU\n", "abstract": " This paper exploits parallel computing power of graphics cards to accelerate state space search. We illustrate that modern graphics processing units (GPUs) have the potential to speed up breadth-first search significantly. For a bitvector representation of the search frontier, GPU algorithms with one and two bits per state are presented. Efficient perfect hash functions and their inverse are explored in order to achieve enhanced compression. We report maximal speed-ups of up to a factor of 27 wrt. single core CPU computation.", "num_citations": "21\n", "authors": ["1628"]}
{"title": "Cost-optimal external planning\n", "abstract": " This paper considers strategies for external memory based optimal planning. An external breadth-first search exploration algorithm is devised that is guaranteed to find the costoptimal solution. We contribute a procedure for finding the upper bound on the locality of the search in planning graphs that dictates the number of layers that have to be kept to avoid re-openings.We also discuss an external variant of Enforced Hill Climbing. Using relaxed-plan heuristic without helpful-action pruning we have been able to perform large explorations on metric planning problems, providing better plan lengths than have been reported earlier. A novel approach to plan reconstruction in external setting with linear I/O complexity is proposed. We provide external exploration results on some recently proposed planning domains.", "num_citations": "21\n", "authors": ["1628"]}
{"title": "Deterministic state space planning with BDDs\n", "abstract": " This short paper (cf.[5]) proposes a planner that uses BDDs to compactly represent sets of propositionally represented states. Using this representation, accurate reachability analysis and backward chaining can apparently be carried out without necessarily encountering exponential representation explosion. The main objectives are the interest in optimal solutions, the generality and the conciseness of the approach. The algorithms are tested against the AIPS'98 planning competition problems and lead to substantial improvements to existing solutions.The project Mips abbreviates intelligent model checking and planning system and encapsulates algorithms and data structures for model checking and planning with binary decision diagrams (BDDs)[2]. BDDs have the expressive power to efficiently encode and manipulate large sets of bit-strings. Therefore, BDDs are capable of symbolically representing both the states within the planning space and the operators applied.", "num_citations": "21\n", "authors": ["1628"]}
{"title": "Monte-carlo tree search for the multiple sequence alignment problem\n", "abstract": " The paper considers solving the multiple sequence alignment, a combinatorial challenge in computational biology, where several DNA RNA, or protein sequences are to be arranged for high similarity. The proposal applies randomized Monte-Carlo tree search with nested rollouts and is able to improve the solution quality over time. Instead of learning the position of the letters, the approach learns a policy for the position of the gaps. The Monte-Carlo beam search algorithm we have implemented has a low memory overhead and can be invoked with constructed or known initial solutions. Experiments in the BAliBASE benchmark show promising results in improving state-of-the-art alignments.", "num_citations": "20\n", "authors": ["1628"]}
{"title": "BDDs strike back (in AI planning)\n", "abstract": " The cost-optimal track of the international planning competition in 2014 has seen an unexpected outcome. Different to the precursing competition in 2011, where explicit-state heuristic search planning scored best, advances in the state-set exploration with BDDs showed a significant lead. In this paper we review the outcome of the competition, briefly looking into the internals of the competing systems.", "num_citations": "19\n", "authors": ["1628"]}
{"title": "Flash-efficient LTL model checking with minimal counterexamples\n", "abstract": " Solid state disks based on flash memory are an apparent alternative to hard disks for external memory search. Random reads are much faster, while random writes are generally not. In this paper, we illustrate how this influences the time-space trade-offs for scaling semi-external LTL model checking algorithms that request a constant number of bits per state in internal, and full state vectors on external memory. We invent a complexity model to analyze the effect of outsourcing the perfect hash function from random access to flash memory. In this model a 1-bit semi-external I/O efficient LTL model checking algorithm is proposed that generates minimal counterexamples.", "num_citations": "19\n", "authors": ["1628"]}
{"title": "Solving \u03bc-Calculus Parity Games by Symbolic Planning\n", "abstract": " This paper applies symbolic planning to solve parity games equivalent to \u03bc-calculus model checking problems. Compared to explicit algorithms, state sets are compacted during the analysis. Given that $\\mbox{\\it diam}(G)$ is the diameter of the parity game graph G with node set V, for the alternation-free model checking problem with at most one fixpoint operator, the algorithm computes at most $O(\\mbox{\\it diam}(G))$ partitioned images. For d alternating fixpoint operators, $O(d \\cdot \\mbox{\\it diam}(G) \\cdot (\\frac{|V|+(d-1)}{d-1})^{d-1})$ partitioned images are required in the worst case.             Practical models and properties stem from data-flow analysis, with problems transformed to parity game graphs, which are then compiled to a general game playing planner input.", "num_citations": "18\n", "authors": ["1628"]}
{"title": "New strategies in learning real time heuristic search\n", "abstract": " In contrast to off-line search algorithms such as Aand IDA\u2019, in real-time heuristic search we have to commit a move within a limited search horizon or time. One well known algorithm in this class is RTA\u2019. An algorithm is said to learn if it improves its performance over successive problem trials. In RTA\" the heuristic estimation is in general not admissible. Thus RTA has to be modified to a variant LRTA\" that is capable of learning. The aim of the strategies proposed in this paper is to improve the estimations found in LRTA\u2019. First, we examine two new schemas forward updating and backward updating for LRTA*.Then we propose CRTA\" which works similar to RTA* but terminates with admissible heuristic values. It is shown that the strategy used in CRTA* can be made efficiently. Combined with lazy evaluation updating CRTA* leads to an improved real time learning algorithm called SLRTA\u2019. Experimentally we show that CRTA* expands significantly less nodes than LRTA\" and thus converges faster to the optimal values.", "num_citations": "18\n", "authors": ["1628"]}
{"title": "The weak-heap data structure: Variants and applications\n", "abstract": " The weak heap is a priority queue that was introduced as a competitive structure for sorting. Its array-based form supports the operations find-min in O (1) worst-case time, and insert and delete-min in O (lg n) worst-case time using at most\u2308 lg n\u2309 element comparisons. Additionally, its pointer-based form supports delete and decrease in O (lg n) worst-case time using at most\u2308 lg n\u2309 element comparisons. In this paper we enhance this data structure as follows: 1. We improve the array-based form to support insert in O (1) amortized time. The main idea is to temporarily store the inserted elements in a buffer, and, once the buffer is full, to move its elements to the heap using an efficient bulk-insertion procedure. As an application, we use this variant in the implementation of adaptive heapsort. Accordingly, we guarantee, for several measures of disorder, that the formula expressing the number of element comparisons\u00a0\u2026", "num_citations": "17\n", "authors": ["1628"]}
{"title": "Partial symbolic pattern databases for optimal sequential planning\n", "abstract": " This paper investigates symbolic heuristic search with BDDs for solving domain-independent action planning problems cost-optimally. By distributing the impact of operators that take part in several abstractions, multiple partial symbolic pattern databases are added for an admissible heuristic, even if the selected patterns are not disjoint. As a trade-off between symbolic bidirectional and heuristic search with BDDs on rather small pattern sets, partial symbolic pattern databases are applied.", "num_citations": "17\n", "authors": ["1628"]}
{"title": "Costoptimal planning with constraints and preferences in large state spaces\n", "abstract": " This paper deals with planning in the presence of constraints and preferences as proposed for the 5th International Planning Competition. State trajectory constraints are translated into LTL formulae and are compiled into B\u00fcchi automata in PDDL format. Preference constraints are compiled into numerical fluents. Values of these fluents are changed by grounded operator effects upon violation.We propose two exploration strategies for optimal planning in PDDL3 domains:(i) a best-first branchand-bound weighted heuristic search;(ii) an external breadth-first search exploration algorithm that exploits secondary memory, such as harddisk, to save the open and closed lists. We prove an upper bound on the locality of the search in planning graphs that dictates the number of layers that have to be kept to avoid re-openings. For non-optimal planning, we present an external variant of enforced hill climbing.", "num_citations": "17\n", "authors": ["1628"]}
{"title": "Solving Single Vehicle Pickup and Delivery Problems with Time Windows and Capacity Constraints using Nested Monte-Carlo Search.\n", "abstract": " Transporting goods by courier and express services increases the service quality through short transit times and satisfies individual demands of customers. Determining the optimal route for a vehicle to satisfy transport requests while minimizing the total cost refers to the Single Vehicle Pickup and Delivery Problem. Beside time and distance objectives, in real world operations it is mandatory to consider further constraints such as time windows and the capacity of the vehicle. This paper presents a novel approach to solve Single Vehicle Pickup and Delivery Problems with time windows and capacity constraints by applying Nested Monte-Carlo Search (NMCS). NMCS is a randomized exploration technique which has successfully solved complex combinatorial search problems. To evaluate the approach, we apply benchmarks instances with up to 400 cities which have to be visited. The effects of varying the number of iterations and the search level are investigated. The results reveal, that the algorithm computes state-of-the-art solutions and is competitive with other approaches.", "num_citations": "16\n", "authors": ["1628"]}
{"title": "Agent-based multimodal transport planning in dynamic environments\n", "abstract": " The development and maintenance of traffic concepts in urban districts is expensive and leads to high investments for altering transport infrastructures or for the acquisition of new resources. We present an agent-based approach for modeling, simulation, evaluation, and optimization of public transport systems by introducing a dynamic microscopic model. Actors of varying stakeholders are represented by intelligent agents. While describing the inter-agent communication and their individual behaviors, the focus is on the implementation of information systems for traveler agents as well as on the matching between open source geographic information systems, and standardized transport schedules provided by the Association of German Transport Companies. The performance, efficiency, and limitations of the system are evaluated within the public transport infrastructure of Bremen. We discuss the effects of\u00a0\u2026", "num_citations": "16\n", "authors": ["1628"]}
{"title": "Transition trees for cost-optimal symbolic planning\n", "abstract": " Symbolic search with binary decision diagrams (BDDs) often saves huge amounts of memory and computation time. In this paper we propose two general techniques based on transition relation trees to advance BDD search by refining the image operator to compute the set of successors. First, the conjunction tree selects the set of applicable actions through filtering their precondition. Then, the disjunction tree combines each transition result. Transition trees are used to combine several transition relations, speeding up BDD search. Experiments with bidirectional symbolic blind and symbolic A* search on planning benchmarks are reported showing good performance on most IPC 2011 domains.", "num_citations": "16\n", "authors": ["1628"]}
{"title": "Abstraction in directed model checking\n", "abstract": " Abstraction is one of the most important issues to cope with large and infinite state spaces in model checking and to reduce the verification efforts. The abstract system is smaller than the original one and if the abstract system satisfies a correctness specification, so does the concrete one. However, abstractions may introduce a behavior violating the specification that is not present in the original system. This paper bypasses this problem by proposing the combination of abstraction with heuristic search to improve error detection. The abstract system is explored in order to create a database that stores the exact distances from abstract states to the set of abstract error states. To check, whether or not the abstract behavior is present in the original system, effcient exploration algorithms exploit the database as a guidance.", "num_citations": "16\n", "authors": ["1628"]}
{"title": "Directed symbolic exploration in AI-planning\n", "abstract": " In this paper we study traditional and enhanced BDD-based exploration procedures capable of handling large planning problems. On the one hand, reachability analysis and model checking have eventually approached AI-Planning. Unfortunately, they typically rely on uninformed blind search. On the other hand, heuristic search and especially lower bound techniques have matured in effectively directing the exploration even for large problem spaces. Therefore, with heuristic symbolic search we address the unexplored middle ground between single state and symbolic planning engines to establish algorithms that can gain from both sides. To this end we implement and evaluate heuristics found in state-of-theart heuristic single-state search planners.", "num_citations": "16\n", "authors": ["1628"]}
{"title": "Multi-goal motion planning with physics-based game engines\n", "abstract": " Toward enhancing automation in video games, this paper proposes an efficient approach for multi-goal motion planning, where a mobile agent needs to visit several regions in a complex environment containing numerous obstacles. The approach works in conjunction with differential equations and physics-based simulations of vehicle dynamics, efficiently planning collision-free, dynamically-feasible, and low-cost solution trajectories. We combine discrete search with sampling-based motion planning to map this challenging task to graph search. The approach imposes a discrete abstraction obtained by a workspace decomposition and then precomputes shortest paths to each goal. As the sampling-based motion planner expands a tree of collision-free and dynamically-feasible trajectories, it relies on a fast TSP solver to compute low-cost tours which can effectively guide the motion-tree expansion. The tours are\u00a0\u2026", "num_citations": "15\n", "authors": ["1628"]}
{"title": "Efficient automated generation of attack trees from vulnerability databases\n", "abstract": " In this paper we generate attack trees in form of unfolded attack graphs from vulnerability databases fully automatically. The inference algorithms merges this information with knowledge about the computer network, the software installed, and firewall logs to generate a vulnerability graph of the computer network.From this graph an attack tree is automatically extracted by applying a modified version of Dijkstra\u2019s shortest path algorithm that detects highly vulnerable attacks paths. The derived attack tree is extended to process firewall rules and can be labeled with additional information that is contained in the vulnerability database.", "num_citations": "15\n", "authors": ["1628"]}
{"title": "Can flash memory help in model checking?\n", "abstract": " As flash media become common and their capacities and speed grow, they are becoming a practical alternative for standard mechanical drives. So far, external memory model checking algorithms have been optimized for mechanical hard disks corresponding to the model of Aggarwal and Vitter\u00a0[1]. Since flash memories are essentially different, the model of Aggarwal and Vitter no longer describes their typical behavior. On such a different device, algorithms can have different complexity, which may lead to the design of completely new flash-memory-efficient algorithms. We provide a model for computation of I/O complexity on the model of Aggarwal and Vitter modified for flash memories. We discuss verification algorithms optimized for this model and compare the performance of these algorithms with approaches known from I/O efficient model checking on mechanical hard disks. We also give an answer\u00a0\u2026", "num_citations": "15\n", "authors": ["1628"]}
{"title": "External memory value iteration\n", "abstract": " We propose a unified approach to disk-based search for deterministic, non-deterministic, and probabilistic (MDP) settings. We provide the design of an external Value Iteration algorithm that performs at most O (lG\u00b7 scan (| E|)+ tmax\u00b7 sort (| E|)) I/Os, where lG is the length of the largest backedge in the breadth-first search graph G having| E| edges, tmax is the maximum number of iterations, and scan (n) and sort (n) are the I/O complexities for externally scanning and sorting n items. The new algorithm is evaluated over large instances of known benchmark problems. As shown, the proposed algorithm is able to solve very large problems that do not fit into the available RAM and thus out of reach for other exact algorithms.", "num_citations": "15\n", "authors": ["1628"]}
{"title": "Heuristic Search Planning with BDDs.\n", "abstract": " In this paper we study traditional and enhanced BDD-based exploration procedures capable of handling large planning problems. On the one hand, reachability analysis and model checking have eventually approached AI-Planning. Unfortunately, they typically rely on uninformed blind search. On the other hand, heuristic search and especially lower bound techniques have matured in effectively directing the exploration even for large problem spaces. Therefore, with heuristic symbolic search we address the unexplored middle ground between single state and symbolic planning engines to establish algorithms that can gain from both sides. To this end we implement and evaluate heuristics found in state-of-the-art heuristic single-state search planners.", "num_citations": "15\n", "authors": ["1628"]}
{"title": "QuickXsort: Efficient Sorting with n logn\u2009\u2212\u20091.399n\u2009+\u2009o(n) Comparisons on Average\n", "abstract": " In this paper we generalize the idea of QuickHeapsort leading to the notion of QuickXsort. Given some external sorting algorithm X, QuickXsort yields an internal sorting algorithm if X satisfies certain natural conditions. We show that up to o (n) terms the average number of comparisons incurred by QuickXsort is equal to the average number of comparisons of X. We also describe a new variant of WeakHeapsort. With QuickWeakHeapsort and QuickMergesort we present two examples for the QuickXsort construction. Both are efficient algorithms that perform approximately n log n\u2212 1.26 n+ o (n) comparisons on average. Moreover, we show that this bound also holds for a slight modification which guarantees an n\\logn+O(n) bound for the worst case number of comparisons. Finally, we describe an implementation of MergeInsertion and analyze its average case behavior. Taking MergeInsertion as a base case for\u00a0\u2026", "num_citations": "14\n", "authors": ["1628"]}
{"title": "Enhanced Shortest Path Computation for Multiagent-based Intermodal Transport Planning in Dynamic Environments.\n", "abstract": " This paper addresses improved urban mobility using multiagent simulation. We provide a description of the agent model and the routing infrastructure as a step towards a rich model of the interactions that happen in intermodal transport planning tasks. The multiagent model is generic in the sense that different public and individual transport agents and transportation agencies can be added and parameterized on-the-fly. It integrates planning with execution. We show that a sequence of calls to Dijkstra\u2019s single-source shortest-paths algorithm is crucial for planning and provide an efficient memory-less implementation with radix heaps in order to make this application feasible with respect to scalability. As a case study, we implement a scenario for Bangalore (India), starting on a higher level of abstraction and drilling down to a running program.", "num_citations": "14\n", "authors": ["1628"]}
{"title": "Generalizing the relaxed planning heuristic to non-linear tasks\n", "abstract": " The relaxed planning heuristic is a prominent state-to-goal estimator function for domain-independent forward-chaining heuristic search and local search planning. It enriches the state-space traversal of almost all currently available suboptimal state-of-the-art planning systems.               While current domain description languages allow general arithmetic expressions in precondition and effect lists, the heuristic has been devised for propositional, restricted, and linear tasks only. On the other hand, generalizations of the heuristic to non-linear tasks are of apparent need for modelling complex planning problems and a true necessity to validate software. Subsequently, this work proposes a solid extension to the estimate that can deal with non-linear preconditions and effects. It is derived based on an approximated plan construction with respect to intervals for variable assignments. For plan extraction, weakest\u00a0\u2026", "num_citations": "14\n", "authors": ["1628"]}
{"title": "Limits and possibilities of PDDL for model checking software\n", "abstract": " Automated validation of software systems with model checking technology either certifies that a given designs contain no specification error (like a deadlock or a failed assertion), or falsifies the desired property in form of a counterexample trace from the initial configuration to the error.Since counterexamples can be seen as goal establishing plans, this paper studies the appropriateness of problem domain description languages (PDDL) to specify software validation problems. The selected software application domain are communication protocols, for which a structured translation from a static subset of the protocol modeling language PROMELA to PDDL2. 1 is devised. It exploits the representation of protocols as communicating finite state machines.", "num_citations": "14\n", "authors": ["1628"]}
{"title": "Inferring flow of control in program synthesis by example\n", "abstract": " Abstract. We present a supervised, interactive learning technique that infers control structures of computer programs from user-demonstrated traces. A two-stage process is applied: first, a minimal deterministic finite automaton (DFA) M labeled by the instructions of the program is learned from a set of example traces and membership queries to the user. It accepts all preffixes of traces of the target program. The number of queries is bounded by O(k\u2022|M|), with k being the total number of instructions in the initial example traces. In the second step we parse this automaton into a high-level programming language in O(|M|2) steps, replacing jumps by conditional control structures.", "num_citations": "14\n", "authors": ["1628"]}
{"title": "Blockquicksort: Avoiding branch mispredictions in quicksort\n", "abstract": " It is well known that Quicksort\u00a0-- which is commonly considered as one of the fastest in-place sorting algorithms -- suffers in an essential way from branch mispredictions. We present a novel approach to addressing this problem by partially decoupling control from dataflow: in order to perform the partitioning, we split the input into blocks of constant size. Then, all elements in one block are compared with the pivot and the outcomes of the comparisons are stored in a buffer. In a second pass, the respective elements are rearranged. By doing so, we avoid conditional branches based on outcomes of comparisons (except for the final Insertionsort). Moreover, we prove that when sorting n elements, the average total number of branch mispredictions is at most \u03b5n log n + O(n) for some small \u03b5 depending on the block size. Our experimental results are promising: when sorting random-integer data, we achieve an increase in\u00a0\u2026", "num_citations": "13\n", "authors": ["1628"]}
{"title": "Integrating temporal reasoning and sampling-based motion planning for multigoal problems with dynamics and time windows\n", "abstract": " Robots used for inspection, package deliveries, moving of goods, and other logistics operations are often required to visit certain locations within specified time bounds. This gives rise to a challenging problem as it requires not only planning collision-free and dynamically feasible motions but also reasoning temporally about when and where the robot should be. While significant progress has been made in integrating task and motion planning, there are still no effective approaches for multigoal motion planning when both dynamics and time windows must be satisfied. To effectively solve this challenging problem, this paper develops an approach that couples temporal planning over a discrete abstraction with sampling-based motion planning over the continuous state space of feasible motions. The discrete abstraction is obtained by imposing a roadmap that captures the connectivity of the free space. At each\u00a0\u2026", "num_citations": "13\n", "authors": ["1628"]}
{"title": "Agent-based dispatching in groupage traffic\n", "abstract": " The complexity and dynamics in group age traffic requires flexible, efficient, and adaptive planning and controlling processes. While the general problem refers to the Vehicle Routing Problem (VRP), additional requirements have to be fulfilled in application. Individual properties and priorities of orders, a heterogeneous fleet of vehicles, dynamically incoming orders, unexpected events etc. require a proactive and reactive system behavior. To enable automated dispatching processes, we have implemented a multiagent system where the decision making is shifted from a central system to autonomous, interacting, intelligent agents. To evaluate the approach we used multi agent-based simulation and modeled several scenarios on real world infrastructures with orders provided by our industrial partner. The results reveal that agent-based dispatching meets the increasing requirements in groupage traffic while\u00a0\u2026", "num_citations": "13\n", "authors": ["1628"]}
{"title": "The weak-heap family of priority queues in theory and praxis\n", "abstract": " In typical applications, a priority queue is used to execute a sequence of n insert, m decrease, and n delete-min operations, starting with an empty structure. We study the performance of different priority queues for this type of operation sequences both theoretically and experimentally. In particular, we focus on weak heaps, weak queues, and their relaxed variants. We prove that for relaxed weak heaps the execution of any such sequence requires at most 2m+ 1.5 n lg n element comparisons. This improves over the best bound, at most 2m+ 2.89 n lg n element comparisons, known for the existing variants of Fibonacci heaps. We programmed six members of the weak-heap family of priority queues. For random data sets, experimental results show that non-relaxed versions are performing best and that rank-relaxed versions are slightly faster than run-relaxed versions. Compared to weak-heap variants, the corresponding weak-queue variants are slightly better in time but not in the number of element comparisons.", "num_citations": "13\n", "authors": ["1628"]}
{"title": "GPU exploration of two-player games with perfect hash functions\n", "abstract": " In this paper we improve solving two-player games by computing the game-theoretical value of every reachable state. A graphics processing unit located on the graphics card is used as a co-processor to accelerate the solution process. We exploit perfect hash functions to store the game states efficiently in memory and to transfer their ordinal representation between the host and the graphics card. As an application we validate Gasser's results that Nine-Men-Morris is a draw on a personal computer. Moreover, our solution is strong, while for the opening phase Gasser only provided a weak solution.", "num_citations": "13\n", "authors": ["1628"]}
{"title": "Policy-based benchmarking of weak heaps and their relatives\n", "abstract": " In this paper we describe an experimental study where we evaluated the practical efficiency of three worst-case efficient priority queues: 1) a weak heap that is a binary tree fulfilling half-heap ordering, 2) a weak queue that is a forest of perfect weak heaps, and 3) a run-relaxed weak queue that extends a weak queue by allowing some nodes to violate half-heap ordering. All these structures support Delete and Delete-min in logarithmic worst-case time. A weak heap supports Insert and Decrease in logarithmic worst-case time, whereas a weak queue reduces the worst-case running time of Insert to O(1), and a run-relaxed weak queue that of both Insert and Decrease to O(1). As competitors to these structures, we considered a binary heap, a Fibonacci heap, and a pairing heap. Generic programming techniques were heavily used in the code development. For benchmarking purposes we developed several\u00a0\u2026", "num_citations": "13\n", "authors": ["1628"]}
{"title": "On constructing a base map for collaborative map generation and its application in urban mobility planning\n", "abstract": " Urban mobility planning depends largely on the presence of good navigation data in the form of vectorized maps. Unfortunately, vector maps are not always available for many areas \u2013 especially for many of the third world countries. On the other hand, good paper maps collected by the city authorities are widely available. A solution is the  collaborative map generation  process that allows people to share the collected GPS traces. Nevertheless, the integration of these GPS traces is itself a challenge and requires a good  base map . This paper presents a method to extract calibrated road topology from raster maps to provide such a  base map  for collaborative map generation process. Our approach takes a bitmap and uses different graphics filters to infer the road geometry. We propose an aggregation algorithm that extracts the actual vectorized road fragments and construct a graph of road network. To evaluate the\u00a0\u2026", "num_citations": "13\n", "authors": ["1628"]}
{"title": "Optimizing last mile delivery using public transport with multi-agent based control\n", "abstract": " The majority of research work carried out in the field of Operations Research have relied on optimization algorithms to improve the pick-up and delivery problem. Most studies aim to solve the vehicle routing problem, to accommodate optimum delivery orders, vehicles etc. This paper focuses on developing a system model, which uses existing Public Transport facility of a city for the transportation of small and medium sized packaged goods, to avoid further aggravating the situation of urban congestion and also help reduce green house gas emissions. The research carried out investigates the feasibility of the proposed multi-agent based simulation model, for efficiency of cost, time and energy consumption. The Dijkstra Shortest Path algorithm and Nested Monte Carlo Search have been implemented to build a time based cost matrix which is used to generate a tour plan for intermodal delivery of goods. The quality of\u00a0\u2026", "num_citations": "12\n", "authors": ["1628"]}
{"title": "Model checking software: on some new waves and some evergreens\n", "abstract": " This paper introduces a special section of the STTT journal containing a selection of papers that were presented at the 13th International Workshop Model Checking Software SPIN 2007. We give a brief overview of the field of software model checking with emphasis on topics that are covered by the selected papers. In our focus are some emerging trends like multi-core model checking together with new high-quality model checking tools, as well as subjects that remain challenging virtually since the establishing of the discipline, like partial-order reduction and abstraction.", "num_citations": "12\n", "authors": ["1628"]}
{"title": "Symbolic exploration for general game playing in PDDL\n", "abstract": " This paper studies the application and extension of planning technology for general game playing. First, we study the transformation of the general game playing language GDL into PDDL with the help of domain constants and derived predicates (level 1 of PDDL2. 2) such that the PDDL input can be instantiated using existing static analysis tools. We discuss the differences in the conjunctive representation of the transition relation (in GDL) and its disjunctive form (in PDDL).Next, we present symbolic exploration algorithms for oneand two-player games to fully characterize optimal play. So far, the algorithms assume alternating moves by the players, but extend existing classification algorithms for zero-sum games to the more general cost model imposed in GDL. We evaluate the approach on a range of PDDL benchmarks matching the ones in the game playing community and show current limits and possibilities.", "num_citations": "12\n", "authors": ["1628"]}
{"title": "Theory and practice of time-space trade-offs in memory limited search\n", "abstract": " Having to cope with memory limitations is an ubiquitous issue in heuristic search. We present theoretical and practical results on new variants for exploring state-space with respect to memory limitations.               We establish O(log n) minimum-space algorithms that omit both the open and the closed list to determine the shortest path between every two nodes and study the gap in between full memorization in a hash table and the information-theoretic lower bound. The proposed structure of suffix-lists elaborates on a concise binary representation of states by applying bit-state hashing techniques. Significantly more states can be stored while searching and inserting n items into suffix lists is still available in O(n log n) time. Bit-state hashing leads to the new paradigm of partial iterative-deepening heuristic search, in which full exploration is sacrificed for a better detection of duplicates in large search depth.We\u00a0\u2026", "num_citations": "12\n", "authors": ["1628"]}
{"title": "First solutions to PDDL+ planning problems\n", "abstract": " In this paper we present the design and algorithmic details of a directed search planner to solve benchmark planning problems speci ed in PDDL+ syntax. The planner copes with durative actions, grounds and groups predicates and instantiates functions. The operators possibly span an in nite state space which is tackled by guided exploration. The heuristic estimates are inferred by plan relaxation, through pattern databases, or by state-to-goal di erences of numerical values and are incorporated in scalable heuristic search planning algorithms.", "num_citations": "12\n", "authors": ["1628"]}
{"title": "Autonomous and flexible multiagent systems enhance transport logistics\n", "abstract": " This paper presents an autonomous multiagent system which optimizes the planning and scheduling of industrial processes using the example of courier and express services. In order to handle the rising demands and to capitalize on the increasing optimization potential in transport logistics, which both result from the consequent integration of industrial processes into the Internet of Things and Services, the presented dispAgent solution ensures a flexible, adaptive, and proactive system behavior. Intelligent, selfishly acting agents represent logistic entities, which communicate and negotiate with each other to optimize the allocation of orders to transport facilities. The system has been developed in cooperation with our industrial partner tiramizoo, which is an expert in courier and express services. In order to determine the quality of the computed solutions, we evaluated the system using an established benchmark\u00a0\u2026", "num_citations": "11\n", "authors": ["1628"]}
{"title": "Early warning and intrusion detection based on combined ai methods\n", "abstract": " In this paper we survey the architecture and AI aspects in our project on early warning-and intrusion detection based on combined AI methods. We address the problem of alarm assessment in intrusion detection and use plan reconstruction based on hierarchically organised procedural knowledge that contains descriptions of adversary actions. Reconstructed plans are supposed to correlate events and alarms from a SIEM and provide explanations for a security expert. We also aim at predicting the next steps of multi-stage intrusion attacks in computer networks. Therefore a probabilistic relational reasoning over time method based on hidden Markov models is proposed.", "num_citations": "11\n", "authors": ["1628"]}
{"title": "Extended critical paths in temporal planning\n", "abstract": " Timed initial literals refer to a recently added feature to the problem domain description language PDDL. Besides the modelling perspective to express exogenous events, this language extension allows to impose deadlines to action execution and to select temporal plans of high quality. For efficiently solving problems with explicit timing requirements, the work in this paper extends a two-stage planning/scheduling system where the sequential plan is built followed by a critical path scheduling phase to find a parallel arrangement. Timed initial literals are included into the plan finding and scheduling process in form of time windows for action execution. Compared to earlier work, the temporal model is refined to include slack and to allow overlappings of dependent actions.The apparently simple scheduling phase is faster than other approaches to establish parallel plans, but expressive enough to cope with current benchmark problems. Through its efficiency, it applies not only to schedule complete plans, but also partial and relaxed plans. Correctness and optimality of the algorithms are shown, and limitations of the approach are discussed. Empirical evidence is given by providing plans for many temporal planning problems.", "num_citations": "11\n", "authors": ["1628"]}
{"title": "Suffix tree automata in state space search\n", "abstract": " An on-line learning algorithm for pruning state space search is described in this paper. The algorithm is based on a finite state machine which is both created and used in the search. The pruning technique is necessary when memory resources in searching huge problem spaces are restricted. A duplicate sequence is a generating path in the search tree that has a counterpart with smaller weight. The automaton provides the dictionary operations Insert and Delete for the duplicate sequences found in the search and Search for pruning the search tree.             The underlying data structure is a multi suffix tree. Given that the alphabet \u03a3 of state transitions is bounded by a constant an optimal worst case bound of O(|m|) for both insertion and deletion of a duplicate sequence m \u2208 \u03a3* is achieved. Using the structure as a finite state machine we can incrementally accept a given sequence x in time O(|x|).", "num_citations": "11\n", "authors": ["1628"]}
{"title": "Optimal Decision Making in Agent-based Autonomous Groupage Traffic.\n", "abstract": " The dynamics and complexity of planning and scheduling processes in groupage traffic require efficient, proactive, and reactive system behavior to improve the service quality while ensuring time and cost efficient transportation. We implemented a multiagent-system to emerge an adequate system behavior and focus on the decision making processes of agents that is based on the Traveling Salesman Problem (TSP) with aspects like contract time windows, individual restricted capacities of trucks, premium services and varying priorities of dynamically incoming orders. We present an optimal depth-first branch-and-bound asymmetric TSP solver with constraints on tour feasibility and depot reachability at any step of the process. To evaluate our approach, we use established benchmarks as well as its inclusion in a real-life multiagent-based simulation. Simulated scenarios are based on real customer orders of our industrial partner Hellmann Worldwide Logistics GmbH & Co. KG and are applied on real world infrastructures. The results reveal that efficient optimal decision making in multiagent systems increases the service quality and meets the requirements and challenges in logistics.", "num_citations": "10\n", "authors": ["1628"]}
{"title": "Stochastic gradient descent with gpgpu\n", "abstract": " We show how to optimize a Support Vector Machine and a predictor for Collaborative Filtering with Stochastic Gradient Descent on the GPU, achieving 1.66 to 6-times accelerations compared to a CPU-based implementation. The reference implementations are the Support Vector Machine by Bottou and the BRISMF predictor from the Netflix Prices winning team. Our main idea is to create a hash function of the input data and use it to execute threads in parallel that write on different elements of the parameter vector. We also compare the iterative optimization with a batch gradient descent and an alternating least squares optimization. The predictor is tested against over a hundred million data sets which demonstrates the increasing memory management capabilities of modern GPUs. We make use of matrix as well as float compression to alleviate the memory bottleneck.", "num_citations": "10\n", "authors": ["1628"]}
{"title": "External memory breadth-first search with delayed duplicate detection on the GPU\n", "abstract": " We accelerate breadth-first search by delegating complex operations to the graphics processing unit (GPU). The algorithm exploits external memory: if the state space becomes too large to be kept in main memory, it is maintained I/O-efficiently on disk.             As in many other approaches for external memory graph search, we apply delayed duplicate detection. The search proceeds in breadth-first layers with increasing minimum distance from the start state. For each layer stored on disk, we load chunks into the systems memory, which are forwarded to the memory on the graphics card. Here we test if outgoing transitions are enabled and generate all successors. Finally, we eliminate duplicates delayed by sorting on the GPU. Even facing the overhead of I/O access, noticeable overall speed-ups are obtained.", "num_citations": "10\n", "authors": ["1628"]}
{"title": "Finding the Needle in the Haystack with Heuristically Guided Swarm Tree Search.\n", "abstract": " In this paper we consider the search in large state spaces with high branching factors and an objective function to be maximized. Our method portfolio, which we refer to as heuristically guided swarm tree search, is randomized, as it consists of several Monte-Carlo runs, and guided, as it relies on fitness selection. We apply different search enhancement such as UCT, look-aheads, multiple runs, symmetry detection and parallel search to increase coverage and solution quality. Theoretically, we show that UCT, which trades exploration for exploitation, can be more successful on several runs than on only one. We look at two case studies. For the Same Game we devise efficient node evaluation functions and tabu color lists. For Morpion Solitaire the graph to be searched is reduced to a tree. We also adapt the search to the graphics processing unit.", "num_citations": "10\n", "authors": ["1628"]}
{"title": "Collaborative map generation\u2013survey and architecture proposal\n", "abstract": " The current widespread use and higher quality of GPS devices is drastically increasing the need for up\u2014to\u2014date digital maps to feed better and more reliable intelligent travelling assistance services.While on one hand the main industrial players can be seen to make large investments in order to satisfy this demand, on the other, a new trend is slowly emerging from the Internet social net\u2014working trend [sometimes referred to as' Web 2.0'] which should not be neglected. As in many other cases, the commercial approaches are superior in terms of quality and in coverage at the beginning, but the effect of a community working together is unexpectedly powerful. See, for example, the case of Wikipedia [as opposed to encyclopaedias such as Encarta or Britannica].", "num_citations": "10\n", "authors": ["1628"]}
{"title": "Cost-optimal symbolic planning with state trajectory and preference constraints\n", "abstract": " State trajectory and plan preference constraints are the two language features recently introduced to PDDL in the context of the 5th international planning competition. For planning with soft constraints, an objective function monitors their violation. This paper introduces a symbolic approach for finding cost-optimal plans. The set-based branch-and-bound algorithm exploits an efficient symbolic representation of the objective function. State trajectory constraints are compiled into automata, while ordinary preferences are evaluated on-line for the intersection of the search frontier with the goal.", "num_citations": "10\n", "authors": ["1628"]}
{"title": "QuickXsort: A fast sorting scheme in theory and practice\n", "abstract": " QuickXsort is a highly efficient in-place sequential sorting scheme that mixes Hoare\u2019s Quicksort algorithm with X, where X can be chosen from a wider range of other known sorting algorithms, like Heapsort, Insertionsort and Mergesort. Its major advantage is that QuickXsort can be in-place even if X is not. In this work we provide general transfer theorems expressing the number of comparisons of QuickXsort in terms of the number of comparisons of X. More specifically, if pivots are chosen as medians of (not too fast) growing size samples, the average number of comparisons of QuickXsort and X differ only by o(n)-terms. For median-of-k pivot selection for some constant k, the difference is a linear term whose coefficient we compute precisely. For instance, median-of-three QuickMergesort uses at most  comparisons. Furthermore, we examine the possibility of sorting base cases with some other algorithm\u00a0\u2026", "num_citations": "9\n", "authors": ["1628"]}
{"title": "Multiregion inspection by combining clustered traveling salesman tours with sampling-based motion planning\n", "abstract": " This paper develops an efficient approach to generate a collision-free and dynamically feasible trajectory that enables a robotic vehicle to inspect the entire workspace or a subset consisting of one or several regions. The approach makes it possible to specify constraints on the order in which the regions should be inspected by using colors to ensure that regions with the same color are inspected as a group. A key aspect is the transformation of the multiregion inspection into a clustered traveling salesman problem (CTSP). This is achieved by generating several inspection points on the medial axis of each region to increase the visibility and by grouping the inspection points into clusters. We also develop a fast branch-and-bound CTSP solver to find low-cost clustered tours. These tours guide sampling-based motion planning, as it expands a motion tree in search for a collision-free and dynamically feasible trajectory\u00a0\u2026", "num_citations": "9\n", "authors": ["1628"]}
{"title": "Improved diversity in nested rollout policy adaptation\n", "abstract": " For combinatorial search in single-player games nested Monte-Carlo search is an apparent alternative to algorithms like UCT that are applied in two-player and general games. To trade exploration with exploitation the randomized search procedure intensifies the search with increasing recursion depth. If a concise mapping from states to actions is available, the integration of policy learning yields nested rollout with policy adaptation (NRPA), while Beam-NRPA keeps a bounded number of solutions in each recursion level. In this paper we propose refinements for Beam-NRPA that improve the runtime and the solution diversity.", "num_citations": "9\n", "authors": ["1628"]}
{"title": "Weak heaps engineered\n", "abstract": " A weak heap is a priority queue that supports the operations construct, minimum, insert, and extract-min. To store n elements, it uses an array of n elements and an array of n bits. In this paper we study different possibilities for optimizing construct and insert such that minimum and extract-min are not made slower. We provide a catalogue of algorithms that optimize the standard algorithms in various ways. As the optimization criteria, we consider the worst-case running time, the number of instructions, branch mispredictions, cache misses, element comparisons, and element moves. Our contributions are summarized as follows: 1. The standard algorithm for construct runs in O (n) worst-case time and performs n\u2212 1 element comparisons. Our improved algorithms reduce the number of instructions, the number of branch mispredictions, the number of element moves, and the number of cache misses. 2 (a) Even though the\u00a0\u2026", "num_citations": "9\n", "authors": ["1628"]}
{"title": "Agent-based planning and control for groupage traffic\n", "abstract": " In this research and technology transfer project, the planning and control processes of the industrial partner Hellmann Worldwide Logistics GmbH & Co. KG are analyzed. An agent-based approach is presented to model current processes and to exploit the identified optimization potential. The developed system directly connects the information flow and the material flow as well as their interdependencies in order to optimize the planning and control in groupage traffic. The software system maps current processes to agents as system components and improves the efficiency by intelligent objects. To handle the high complexity and dynamics of logistics autonomous intelligent agents plan and control the way of represented objects through the logistic network by themselves and induce a flexible and reactive system behavior. We evaluate the implemented dispatching application by simulating the groupage traffic\u00a0\u2026", "num_citations": "9\n", "authors": ["1628"]}
{"title": "In-place heap construction with optimized comparisons, moves, and cache misses\n", "abstract": " We show how to build a binary heap in-place in linear time by performing ~ 1.625n element comparisons, at most ~ 2.125n element moves, and ~ n/B cache misses, where n is the size of the input array, B the capacity of the cache line, and ~ f(n) approaches f(n) as n grows. The same bound for element comparisons was derived and conjectured to be optimal by Gonnet and Munro; however, their procedure requires \u0398(n) pointers and does not have optimal cache behaviour. Our main idea is to mimic the Gonnet-Munro algorithm by converting a navigation pile into a binary heap. To construct a binary heap in-place, we use this algorithm to build bottom heaps of size  and adjust the heap order at the upper levels using Floyd\u2019s sift-down procedure. On another frontier, we compare different heap-construction alternatives in practice.", "num_citations": "9\n", "authors": ["1628"]}
{"title": "Real-time model checking on secondary storage\n", "abstract": " In this paper, we consider disk based exploration in priced timed automata for resource-optimal scheduling. State spaces for large problems can easily go beyond the main memory capacity. We propose the use of hard disk to store the generated state space induced by priced timed automata. We contribute three algorithms: External Breadth First Search for reachability analysis in ordinary timed automata, External Breadth First Branch-and-Bound for cost-optimal reachability analysis in priced timed automata, and Iterative Broadening External Breadth First Branch-and-Bound for a partial exploration in priced timed automata. The third algorithm achieves its completeness by trying to find an upper bound on the optimal solution in an incomplete search tree. Iteratively, the upper bound is made tighter and the coverage of the search space is widened. We present correctness and completeness proofs for the\u00a0\u2026", "num_citations": "9\n", "authors": ["1628"]}
{"title": "Action planning for graph transition systems\n", "abstract": " Graphs are suitable modeling formalisms for software and hardware systems involving aspects such as communication, object orientation, concurrency, mobility and distribution. State spaces of such systems can be represented by graph transition systems, which are basically transition systems whose states and transitions represent graphs and graph morphisms. In this paper, we propose the modeling of graph transition systems in PDDL and the application of heuristic search planning for their analysis. We consider different heuristics and present experimental results.", "num_citations": "9\n", "authors": ["1628"]}
{"title": "Abstraction databases in theory and model checking practice\n", "abstract": " Abstraction is one of the most important issues to cope with large and infinite state spaces in model checking and to reduce the verification efforts. The abstract system is smaller than the original one and if the abstract system satisfies a correctness specification, so does the concrete one. However, abstractions may introduce a behavior violating the specification that is not present in the original system.This paper bypasses this problem by proposing the combination of abstraction with heuristic search to improve error detection. The abstract system is explored in order to create a database that stores the exact distances from abstract states to the set of abstract error states. To check, whether or not the abstract behavior is present in the original system, efficient exploration algorithms exploit the database as a guidance.", "num_citations": "9\n", "authors": ["1628"]}
{"title": "Multi\u2010group motion planning in virtual environments\n", "abstract": " Toward enhancing automation, this paper proposes an efficient approach for multi\u2010group motion planning, where the set of goals is divided into k groups and the objective is to compute a collision\u2010free and dynamically feasible trajectory that enables a virtual vehicle to reach at least one goal from each group. The approach works with ground and aerial vehicles operating in complex environments containing numerous obstacles. In addition to modeling the vehicle dynamics by differential equations, the approach can use physics\u2010based game engines, which provide an increased level of realism. The approach is based on a hybrid search that uses generalized traveling salesman tours over a probabilistic roadmap to effectively guide the sampling\u2010based expansion of a motion tree. As the motion tree is expanded with collision\u2010free and dynamically feasible trajectories, tours are adjusted based on a partition of the\u00a0\u2026", "num_citations": "8\n", "authors": ["1628"]}
{"title": "Optimizing binary heaps\n", "abstract": " A priority queue\u2014a data structure supporting, inter alia, the operations minimum (top), insert (push), and extract-min (pop)\u2014is said to operate in-place if it uses O (1) extra space in addition to the n elements stored at the beginning of an array. Prior to this work, no in-place priority queue was known to provide worst-case guarantees on the number of element comparisons that are optimal up to additive constant terms for both insert and extract-min. In particular, for the standard implementation of binary heaps, insert and extract-min operate in logarithmic time while involving at most\u2308 lgn\u2309 and 2 lgn [could possibly be reduced to lg lgn+ O (1) and lgn+ log\u2217 n+ O (1)] element comparisons, respectively. In this paper we propose a variant of a binary heap that operates in-place, executes minimum and insert in O (1) worst-case time, and extract-min in O (lgn) worst-case time while involving at most lgn+ O (1) element\u00a0\u2026", "num_citations": "8\n", "authors": ["1628"]}
{"title": "BlockQuicksort: How Branch Mispredictions don't affect Quicksort\n", "abstract": " Since the work of Kaligosi and Sanders (2006), it is well-known that Quicksort -- which is commonly considered as one of the fastest in-place sorting algorithms -- suffers in an essential way from branch mispredictions. We present a novel approach to address this problem by partially decoupling control from data flow: in order to perform the partitioning, we split the input in blocks of constant size (we propose 128 data elements); then, all elements in one block are compared with the pivot and the outcomes of the comparisons are stored in a buffer. In a second pass, the respective elements are rearranged. By doing so, we avoid conditional branches based on outcomes of comparisons at all (except for the final Insertionsort). Moreover, we prove that for a static branch predictor the average total number of branch mispredictions is at most  for some small  depending on the block size when sorting  elements. Our experimental results are promising: when sorting random integer data, we achieve an increase in speed of 80% over the GCC implementation of C++ std::sort. Also for many other types of data and non-random inputs, there is still a significant speedup over std::sort. Only in few special cases like sorted or almost sorted inputs, std::sort can beat out implementation. Moreover, even on random input permutations, our implementation is even slightly faster than an implementation of the highly tuned Super Scalar Sample Sort, which uses a linear amount of additional space.", "num_citations": "8\n", "authors": ["1628"]}
{"title": "Symbolic discrete-time planning with continuous numeric action parameters for agent-controlled processes\n", "abstract": " In industrial domains such as manufacturing control, a trend away from centralized planning and scheduling towards more flexible distributed agent-based approaches could be observed over recent years. To be of practical relevance, the local control mechanisms of the autonomous agents must be able to dependably adhere and dynamically adjust to complex numeric goal systems like business key performance indicators in an economically beneficial way. However, planning with numeric state variables and objectives still poses a challenging task within the field of artificial intelligence (AI).In this article, a new general-purpose AI planning approach is presented that operates in two stages and extends existing domain-independent modeling formalisms like PDDL with continuous (i.e., infinite-domain) numeric action parameters, which are currently still unsupported by state-of-the-art AI planners. In doing so, it\u00a0\u2026", "num_citations": "8\n", "authors": ["1628"]}
{"title": "Externalizing the multiple sequence alignment problem with affine gap costs\n", "abstract": " Multiple sequence alignment (MSA) is a problem in computational biology with the goal to discover similarities between DNA or protein sequences. One problem in larger instances is that the search exhausts main memory. This paper applies disk-based heuristic search to solve MSA benchmarks. We extend iterative-deepening dynamic programming, a hybrid of dynamic programming and IDA*, for which optimal alignments with respect to similarity metrics and affine gap cost are computed. We achieve considerable savings of main memory with an acceptable time overhead. By scaling buffer sizes, the space-time trade-off can be adapted to existing resources.", "num_citations": "8\n", "authors": ["1628"]}
{"title": "Model Checking and Artificial Intelligence: 4th Workshop, MoChArt IV, Riva Del Garda, Italy, August 29, 2006, Revised Selected and Invited Papers\n", "abstract": " The refereed post-proceedings of the 4th Workshop on Model Checking and Artificial Intelligence are presented in this volume. Eight full workshop papers are presented along with three post-proceedings papers. Papers are organized into topical sections covering planning and model checking, heuristics for real-time model checking, verification of multi-agent systems, and logics for model checking and artificial intelligence.", "num_citations": "8\n", "authors": ["1628"]}
{"title": "Incremental hashing in state space search\n", "abstract": " State memorization is essential for state-space search to avoid redundant expansions and hashing serves as a method to, address store and retrieve states efficiently.In this paper we introduce incremental state hashing to compute hash values in constant time. The method will be most effective in guided depth-first search traversals of state space graphs, like in IDA*, where the computation of the set of successors and their heuristic estimates is extremely fast: heuristic values are often computed incrementally or retrieved from pre-computed pattern database tables, and backtracking keeps the changes in the state representation vector during the exploration small. The approach quickly decides if a given state is not present in a hash table, and accelerates successful search. It can further accelerate perfect hashing for pattern storage and look-up. If, for a better coverage of the state space, partial search methods without collision resolving is used, we establish another benefit for incremental state hashing. We exemplify our considerations in the (n2\u2212 1)-Puzzle, in action planning, and conduct experiments in Atomix.", "num_citations": "8\n", "authors": ["1628"]}
{"title": "Prediction of regular search tree growth by spectral analysis\n", "abstract": " The time complexity analysis of the IDA algorithm has shown that predicting the growth of the search tree essentially relies on only two criteria: The number of nodes in the brute-force search tree for a given depth and the equilibrium distribution of the heuristicestimate. Since the latter can be approximated by random sampling, we accurately predict the number of nodes in the brute-force search tree for large depth in closed form by analyzing the spectrum of the problem graph or one of its factorization.               We further derive that the asymptotic brute-force branching factor is in fact the spectral radius of the problem graph and exemplify our considerations in the domain of the (n2 - 1)-Puzzle", "num_citations": "8\n", "authors": ["1628"]}
{"title": "Representing and reducing uncertainty for enumerating the belief space to improve endgame play in Skat\n", "abstract": " In most fully observable board games, current AIs outperform expert play. For partially observable trick-taking card games, however, human experts still play consistently better. This paper proposes efficient knowledge representation and reasoning algorithms for the internationally played three-player card game Skat by representing, progressing, enumerating, evaluating and voting for the possible worlds, each player refers to as his/her knowledge about the other players\u2019 and the Skat cards. By using expert rules, elicited from statistical information in millions of games, this knowledge is accumulated in the first few tricks in order to reduce the uncertainty in the players\u2019 belief. In the so-called endgame, after five to six rounds of trick play, refined exploration algorithms suggest cards that lead to improved play. The proposed AIs have been tested both in reconsidering recorded human games, and in interactive play.", "num_citations": "7\n", "authors": ["1628"]}
{"title": "Worst-case efficient sorting with QuickMergesort\n", "abstract": " The two most prominent solutions for the sorting problem are Quicksort and Mergesort. While Quicksort is very fast on average, Mergesort additionally gives worst-case guarantees, but needs extra space for a linear number of elements. Worst-case efficient in-place sorting, however, remains a challenge: the standard solution, Heapsort, suffers from a bad cache behavior and is also not overly fast for in-cache instances. In this work we present median-of-medians QuickMergesort (MoMQuickMergesort), a new variant of QuickMergesort, which combines Quicksort with Mergesort allowing the latter to be implemented in place. Our new variant applies the median-of-medians algorithm for selecting pivots in order to circumvent the quadratic worst case. Indeed, we show that it uses at most n log n + 1.6n comparisons for n large enough. We experimentally confirm the theoretical estimates and show that the new algorithm\u00a0\u2026", "num_citations": "7\n", "authors": ["1628"]}
{"title": "Cyber-physical multiagent-simulation in production logistics\n", "abstract": " A growing network of technical systems, embedded and autonomous, influence our daily work. Among them, cyber-physical systems establish a close connection between the virtual and the real world. In this paper we show how an existing multiagent system that controls the physical production of goods on a monorail is virtualized by extracting the agents as black boxes and by integrating them into a multiagent simulation system. As a result, the exact same agents run in physical and cyber world. Towards this end, the physical environment has been mapped and visualized. Experiments show that the modeling and simulation error is small, such that scenarios can be varied, tested, debugged, and scaled, saving huge amounts of labor.", "num_citations": "7\n", "authors": ["1628"]}
{"title": "Perfect hashing for state spaces in BDD representation\n", "abstract": " In this paper we design minimum perfect hash functions on the basis of BDDs that represent all reachable states S\u2009\u2286\u2009{0,1}                   n                 . These functions are one-to-one on S and can be evaluated quite efficiently. Such hash functions are useful to perform search in a bitvector representation of the state space. The time to compute the hash value with standard operations on the BDD G is (n|G|), the time to compute the inverse is O(n                 2|G|). When investing O(n) bits per node, we arrive at O(|G|) preprocessing time and optimal time O(n) for ranking and unranking.", "num_citations": "7\n", "authors": ["1628"]}
{"title": "Scaling search with pattern databases\n", "abstract": " In this paper, we illustrate efforts to perform memory efficient large-scale search. We first generate sets of disjoint symbolic pattern databases on disk. These pattern databases are then used for heuristic guidance, while applying explicit-state external-memory heuristic search. Different options for parallelization to save time and memory are presented. The general techniques are mapped to the (n               2\u2009\u2212\u20091)-puzzle as a large-scale case study.", "num_citations": "7\n", "authors": ["1628"]}
{"title": "Dynamic incremental hashing in program model checking\n", "abstract": " Although computationaly neglegdible in other domains, the hashing of states can become one of the most expensive operations in software model checking. The reason lies in the potentially large state descriptions that programs expose. In this paper we introduce incremental hashing on large, dynamically changing state vectors that naturally arise during the verification of software in program model checkers. We exploit the fact that only small portions of the state description are changed by a single transition. Based on the changes in the predecessor state, the new state and its hash value can be computed efficiently.", "num_citations": "7\n", "authors": ["1628"]}
{"title": "Energy-Aware Multi-Goal Motion Planning Guided by Monte Carlo Search\n", "abstract": " Autonomous robots need a reliable way to preserve their energy level while performing a persistent task such as inspection or surveillance. Toward this objective, this paper considers the multi-goal motion-planning problem with multiple recharging stations where a robot operating in a complex environment has to reach each goal while reducing the travel distance and the number of times it recharges. This paper develops an integrated approach that couples samplingbased motion planning with Monte-Carlo Tree Search (MCTS). The proposed MCTS searches over a discrete abstraction, which is obtained via a probabilistic roadmap, and uses a reward function to calculate when, where, and whether it is beneficial to recharge. This results in short tours that also reduce the number of recharges. Such tours are used to guide sampling-based motion planning as it expands a tree of collision-free and dynamically\u00a0\u2026", "num_citations": "6\n", "authors": ["1628"]}
{"title": "Challenging human supremacy in Skat\n", "abstract": " After impressive successes in deterministic and fully-observable board games to significantly outclass humans, game playing research shifts towards non-deterministic and imperfect information card games, where humans are still persistently better. In this paper we devise a player that challenges human supremacy in Skat. We provide a complete player for playing selected variants of the game, with effective solutions for bidding and Skat putting, extracting knowledge from several million games. For trick play we combine expert rules with engineered tree exploration for optimal open card play. For dealing with uncertainty especially in Ouvert games we search the belief space.", "num_citations": "6\n", "authors": ["1628"]}
{"title": "Nested rollout policy adaptation for optimizing vehicle selection in complex VRPs\n", "abstract": " The goal of Vehicle Routing Problems (VRP) and their variations is to transport a set of orders with the minimum number of vehicles at least cost. Most approaches are designed to solve specific problem variations independently whereas in real world applications, those constraints are handled concurrently. This paper describes a novel approach to solve variants of Open VRP, Multi Depot VRP, Capacitated VRP as well as Pickup and Delivery with Time Windows applying Monte-Carlo Tree Search (MCTS) and in particular Nested Rollout Policy Adaptation. For evaluation, real data from the industry was obtained and tested on the developed approach.", "num_citations": "6\n", "authors": ["1628"]}
{"title": "Motion planning with rigid-body dynamics for generalized traveling salesman tours\n", "abstract": " This paper pursues multi-goal motion planning, where the overall set of goals is divided into k groups and the virtual agent needs to visit at least one goal per group. We have developed a combined task and motion-planning approach which can work with ground and aerial vehicles whose motions are simulated by differential equations or by physics-based game engines. The proposed approach is based on a hybrid search, where the expansion of a motion tree in the continuous state space is guided by heuristic costs and generalized traveling salesman tours computed over a discrete abstraction. The discrete abstraction is obtained via a probabilistic roadmap constructed over a low-dimensional configuration space resulting from a simplified problem setting. By capturing the connectivity of the free configuration space and connecting the goals, the roadmap provides generalized traveling salesman tours that\u00a0\u2026", "num_citations": "6\n", "authors": ["1628"]}
{"title": "Program model checking via action planning\n", "abstract": " In this paper we present steps towards a prototype implementation of a C++ software model checker based on AI\u00a0planning technology. It parses source code annotated with assertions and translates it into the planning domain description language to invoke recent planners. Lifted back to the source code level, computed plans then serve as counterexamples. As the approach can participate from efficient planner in-built search heuristics, the verification procedure is directed. For the translation process, different aspects like parsing, generation of a dependency graph, slicing, property conversion, and data abstraction are described. The program model checker has been embedded as a plugin in the Eclipse software development environment, resulting in an interactive debugging aid. First empirical findings compare the approach with an existing directed program model checker parses the same input and\u00a0\u2026", "num_citations": "6\n", "authors": ["1628"]}
{"title": "Rank-Relaxed Weak Queues: Faster than Pairing and Fibonacci Heaps?\n", "abstract": " A run-relaxed weak queue by Elmasry et al.(2005) is a priority queue data structure with insert and decrease-key in O (1) as well as delete and delete-min in O (log n) worst-case time. One further advantage is the small space consumption of 3n+ O (log n) pointers. In this paper we propose rank-relaxed weak queues, reducing the number of rank violations nodes for each level to a constant, while providing amortized constant time for decrease-key. Compared to run-relaxed weak queues, the new structure additionally gains one pointer per node. An empirical evaluation shows that the implementation can outperform Fibonacci and pairing heaps in practice even on rather simple data types.", "num_citations": "6\n", "authors": ["1628"]}
{"title": "External Memory Graph Search\n", "abstract": " Optimal solutions the RUBIK\u2019S CUBE, the (n\u00b2\u2212 1)-PUZZLE, and the TOWERS-OF-HANOI problem, all with state spaces of about or more than a quintillion (a billion times a billion) states. When processing a million states per second, looking at all states corresponds to hundreds of thousands of years. Even with search heuristics, time and space remain crucial resources: in extreme cases, weeks of computation time, gigabytes of main memory and terabytes of hard disk space have been invested to solve search challenges.", "num_citations": "6\n", "authors": ["1628"]}
{"title": "Planning in concurrent multiagent systems with the assembly model checker StEAM\n", "abstract": " The exploration of a programs state space has become a popular method lately. In most cases, the intention is to check the program against formal properties-such as the absence of deadlocks. The efforts in this field gave birth to a set of powerful tools-such as the Java model checker JPF (2) and the C++ model checker StEAM. However, the potential of those tools is not limited to the verification of formal properties.In this paper, we present a method, which uses StEAM as a planner in concurrent multiagent systems. In contrast to classical planning, we avoid the generation of an abstract model. The planner operates on the same compiled code that controls the actual system. The approach is evaluated in a case study using a C++-implementation of a multiagent manufacturing system.", "num_citations": "6\n", "authors": ["1628"]}
{"title": "Memory limitations in artificial intelligence\n", "abstract": " Artificial Intelligence (AI) deals with structuring large amounts of data. As a very first example of an expert system [424], take the oldest known scientific treatise surviving from the ancient world, the surgical papyrus [146] of about 3000 BC. It discusses cases of injured men for whom a surgeon had no hope of saving and lay many years unnoticed until it was rediscovered and published for the New York Historical Society. The papyrus summarizes surgical observations of head wounds disclosing an inductive method for inference [281], with observations that were stated with title, examination, diagnosis, treatment, prognosis and glosses much in the sense that if a patient has this symptom, then he has this injury with this prognosis if this treatment is applied.", "num_citations": "6\n", "authors": ["1628"]}
{"title": "QuickMergesort: Practically efficient constant-factor optimal sorting\n", "abstract": " We consider the fundamental problem of internally sorting a sequence of  elements. In its best theoretical setting QuickMergesort, a combination Quicksort with Mergesort with a Median-of- pivot selection, requires at most  element comparisons on the average. The questions addressed in this paper is how to make this algorithm practical. As refined pivot selection usually adds much overhead, we show that the Median-of-3 pivot selection of QuickMergesort leads to at most  element comparisons on average, while running fast on elementary data. The experiments show that QuickMergesort outperforms state-of-the-art library implementations, including C++'s Introsort and Java's Dual-Pivot Quicksort. Further trade-offs between a low running time and a low number of comparisons are studied. Moreover, we describe a practically efficient version with  comparisons in the worst case.", "num_citations": "5\n", "authors": ["1628"]}
{"title": "Automated planning and model checking (dagstuhl seminar 14482)\n", "abstract": " This report documents the program and the outcomes of Dagstuhl Seminar 14482\" Automated Planning and Model Checking\". There has been a lot of work on the exchanges between the areas of automated planning and model checking, based on the observation that a model-checking problem can be cast as a planning problem and vice-versa. The motivation for this seminar was to increase the synergy between the two research communities, and explore recent progress in the two areas in terms of techniques, tools and formalisms for describing planning and verification problems. The main outcomes were a greater common understanding of planning and model-checking issues and challenges, and greater appreciation of the cross-over between the modelling languages and methods. Different application domains were also explored, where planning and model-checking can be effectively integrated.", "num_citations": "5\n", "authors": ["1628"]}
{"title": "Two constant-factor-optimal realizations of adaptive heapsort\n", "abstract": " In this paper we introduce two efficient priority queues. For both, insert requires O(1) amortized time and extract-min                worst-case time including at most  element comparisons, where n is the number of elements stored. One priority queue is based on a weak heap (array-based) and the other on a weak queue (pointer-based). In both, the main idea is to temporarily store the inserted elements in a buffer, and once it is full to move its elements to the main queue using an efficient bulk-insertion procedure. By employing the new priority queues in adaptive heapsort, we guarantee, for several measures of disorder, that the formula expressing the number of element comparisons performed by the algorithm is optimal up to the constant factor of the high-order term. We denote such performance as constant-factor optimality. Unlike some previous constant-factor-optimal adaptive sorting\u00a0\u2026", "num_citations": "5\n", "authors": ["1628"]}
{"title": "Layer-abstraction for symbolically solving general two-player games\n", "abstract": " In this paper we propose a new algorithm for solving general two-player turn-taking games that performs symbolic search utilizing binary decision diagrams (BDDs). It consists of two stages: First, it determines all breadth-first search (BFS) layers using forward search and omitting duplicate detection, next, the solving process operates in backward direction only within these BFS layers thereby partitioning all BDDs according to the layers the states reside in. We provide experimental results for selected games and compare to a previous approach. This comparison shows that in most cases the new algorithm outperforms the existing one in terms of runtime and used memory so that it can solve games that could not be solved before with a general approach.", "num_citations": "5\n", "authors": ["1628"]}
{"title": "Distributed verification of multi-threaded C++ programs\n", "abstract": " Verification of multi-threaded C++ programs poses three major challenges: the large number of states, states with huge sizes, and time intensive expansions of states. This paper presents our efforts in addressing these issues by combining an efficient use of hard disk with the distribution of the state space on several computing nodes. The approach is applicable to clusters and multi-core machines with single or multiple hard disks. We exploit the concept of a signature of a state that allows the full state vector to stay on secondary memory. For a distributed exploration of the state space, we report the lessons learned from using different partitioning schemes, including Holzmann and Bosnacki's [G. Holzmann and D. Bosnacki. The design of a multi-core extension of the Spin Model Checker. IEEE Trans. on Software Engineering, 2007. To Appear] depth-slicing method, and their effects on blind and directed search\u00a0\u2026", "num_citations": "5\n", "authors": ["1628"]}
{"title": "Optimal Metric Planning with State Sets in Automata Representation.\n", "abstract": " This paper proposes an optimal approach to infinite-state action planning exploiting automata theory. State sets and actions are characterized by Presburger formulas and represented using minimized finite state machines. The exploration that contributes to the planning via model checking paradigm applies symbolic images in order to compute the deterministic finite automaton for the sets of successors. A large fraction of metric planning problems can be translated into Presburger arithmetic, while derived predicates are simply compiled away. We further propose three algorithms for computing optimal plans; one for uniform action costs, one for the additive cost model, and one for linear plan metrics. Furthermore, an extension for infinite state sets is discussed.", "num_citations": "5\n", "authors": ["1628"]}
{"title": "Incremental hashing for pattern databases\n", "abstract": " Hashing is essential for state-space search to avoid redundant work and to address abstract states in pattern databases. But in some domains hashing becomes a bottleneck of the exploration. This applies in particular to planning with pattern databases where both the actual and the abstract state need to be hashed, each requiring time linear in the number of atomic propositions. In this paper, we devise an incremental hashing scheme for planning with pattern databases, which reduces the time complexities for hashing to a constant. We exemplify our considerations in two established planning domains.", "num_citations": "5\n", "authors": ["1628"]}
{"title": "Directed automated theorem proving\n", "abstract": " This paper analyzes the effect of heuristic search algorithms like A* and IDA* to accelerate proof-state based theorem provers. A functional implementation of possibly weighted A* is proposed that extends Dijkstra\u2019s single-source shortest-path algorithm. Efficient implementation issues and possible flaws for both A* and IDA* are discussed in detail.             Initial results with first and higher order logic examples in Isabelle indicate that directed automated theorem proving is superior to other known general inference mechanisms and that it can enhance other proof techniques like model elimination.", "num_citations": "5\n", "authors": ["1628"]}
{"title": "Dynamic Play via Suit Factorization Search in Skat\n", "abstract": " In this paper we look at multi-player trick-taking card games that rely on obeying suits, which include Bridge, Hearts, Tarot, Skat, and many more. We propose mini-game solving in the suit factors of the game, and exemplify its application as a single-dummy or double-dummy analysis tool that restricts game play to either trump or non-trump suit cards. Such factored solvers are applicable to improve card selections of the declarer and the opponents, mainly in the middle game, and can be adjusted for optimizing the number of points or tricks to be made. While on the first glance projecting the game to one suit is an over-simplification, the partitioning approach into suit factors is a flexible and strong weapon, as it solves apparent problems arising in the phase transition of accessing static table information to dynamic play. Experimental results show that by using mini-game play, the strength of trick-taking Skat\u00a0\u2026", "num_citations": "4\n", "authors": ["1628"]}
{"title": "Monte-carlo search for prize-collecting robot motion planning with time windows, capacities, pickups, and deliveries\n", "abstract": " Logistics operations often require a robot to pickup and deliver objects from multiple locations within certain time frames. This is a challenging task-and-motion planning problem as it intertwines logical and temporal constraints about the operations with geometric and differential constraints related to obstacle avoidance and robot dynamics. To address these challenges, this paper couples vehicle routing over a discrete abstraction with sampling-based motion planning. On the one hand, vehicle routing provides plans to effectively guide sampling-based motion planning as it explores the vast space of feasible motions. On the other hand, motion planning provides feasibility estimates which vehicle routing uses to refine its plans. This coupling makes it possible to extend the state-of-the-art in multi-goal motion planning by also incorporating capacities, pickups, and deliveries in addition to time windows. When\u00a0\u2026", "num_citations": "4\n", "authors": ["1628"]}
{"title": "External-memory state space search\n", "abstract": " Many state spaces are so big that even in compressed form they fail to fit into main memory. As a result, during the execution of a search algorithm, only a part of the state space can be processed in main memory at a time; the remainder is stored on a disk.               In this paper we survey research efforts in external-memory search for solving state space problems, where the state space is generated by applying rules. We study different form of expressiveness and the effect of guiding the search into the direction of the goal. We consider outsourcing the search to disk as well as its additional parallelization to many-core processing units. We take the sliding-tile puzzle as a running example.", "num_citations": "4\n", "authors": ["1628"]}
{"title": "Planning with numeric key performance indicators over dynamic organizations of intelligent agents\n", "abstract": " In this paper we present a PDDL-based multi-agent planning system for reasoning about key performance indicators (KPIs) in an industrial production planning and control application scenario. On top of PDDL, numeric key figures and associated objectives are configured by the user at run-time and then processed automatically by the system in order to maximize overall goal satisfaction. The organizational structure of the system is a hierarchical multi-agent planning and simulation environment, with KPI objectives being propagated top-down and achievements being assessed bottom-up. KPIs can be automatically aggregated over dynamic groups of agents, with the ability of deliberately planning for reorganization. The planner supports continuous numeric action parameters, which it keeps lifted as sets of intervals before grounding them in delayed fashion with a mathematical optimizer. Plan generation\u00a0\u2026", "num_citations": "4\n", "authors": ["1628"]}
{"title": "cGamer: Constrained Gamer\n", "abstract": " Gamer is a symbolic planner that performs (in this case) bidirectional symbolic search. It already participated in 2008 and 2011, so in this paper we will focus on the improvements since then. The main improvements are: fixing some bugs and implementing basic improvements; a disjunctive partitioning of the transition relations; and the exploitation of state invariants both during the preprocessing phase and during search.", "num_citations": "4\n", "authors": ["1628"]}
{"title": "Combinatorial planning with numerical parameter optimization for local control in multi-agent systems\n", "abstract": " Planning with numeric state variables and goal systems today still poses a challenging task within the field of computational intelligence. In this paper a two-tier planning system is presented that enables the optimization of continuous numeric action parameters in combinatorially enumerated plans. It allows resorting to a \u201csatisficing\u201d strategy by means of partial execution and subsequent repair of infeasible plans in order to deal with certain difficulties concerning reliable and fast detection of action applicability that arise when planning with real-valued action parameters. The functioning of the system is evaluated in a multi-agent simulation of a shop floor control scenario with focus on the effects the possible problem cases and the satisficing approach have on attained plan quality.", "num_citations": "4\n", "authors": ["1628"]}
{"title": "The bitvector machine: a fast and robust machine learning algorithm for non-linear problems\n", "abstract": " In this paper we present and evaluate a simple but effective machine learning algorithm that we call Bitvector Machine: Feature vectors are partitioned along component-wise quantiles and converted into bitvectors that are learned. It is shown that the method is efficient in both training and classification. The effectiveness of the method is analysed theoretically for best and worst-case scenarios. Experiments on high-dimensional synthetic and real world data show a huge speed boost compared to Support Vector Machines with RBF kernel. By tabulating kernel functions, computing medians in linear-time, and exploiting modern processor technology for advanced bitvector operations, we achieve a speed-up of 32 for classification and 48 for kernel evaluation compared to the popular LIBSVM. Although the method does not generally outperform a SVM with RBF kernel it achieves a high classification accuracy\u00a0\u2026", "num_citations": "4\n", "authors": ["1628"]}
{"title": "A catalogue of algorithms for building weak heaps\n", "abstract": " An array-based weak heap is an efficient data structure for realizing an elementary priority queue. In this paper we focus on the construction of a weak heap. Starting from a straightforward algorithm, we end up with a catalogue of algorithms that optimize the standard algorithm in different ways. As the optimization criteria, we consider how to reduce the number of instructions, branch mispredictions, cache misses, and element moves. We also consider other approaches for building a weak heap: one based on repeated insertions and another relying on a non-standard memory layout. For most of the algorithms considered, we also study their effectiveness in practice.", "num_citations": "4\n", "authors": ["1628"]}
{"title": "A catalogue of weak-heap programs\n", "abstract": " This report is an electronic appendix to the paper \u201cA Catalogue of Algorithms for Building Weak Heaps\u201d presented at the 23nd International Workshop on Combinatorial Algorithms held in Tamil Nadu in July 2012, and to the journal version of this paper entitled \u201cWeak Heaps Engineered\u201d. This report together with an accompanying tar ball gives the source code used in the experiments reported in these papers.", "num_citations": "4\n", "authors": ["1628"]}
{"title": "Learning how to play Hex\n", "abstract": " In Hex two players try to connect opposing sides by placing pieces onto a rhombus-shaped board of hexagons. The game has a high strategic complexity and the number of possible board positions is larger than in Chess. There are already some Hex programs of recognizable strength, but which still play on a level below very strong human players. One of their major weaknesses is the time for evaluating a board. In this work we apply machine learning for the computer player to improve his play by generating an fast evaluation function and lookup procedure for pattern endgame databases. The data structures used are neural networks for the evaluation of a position and limited branching trees to determine if a position can be classified as won or lost.", "num_citations": "4\n", "authors": ["1628"]}
{"title": "Symbolic shortest path planning\n", "abstract": " This paper studies the impact of pattern databases for solving shortest path planning problems with limited memory. It contributes a bucket implementation of Dijkstra\u2019s algorithm for the construction of shortest path planning pattern databases and their use in symbolic A* search. For improved efficiency, the paper analyzes the locality for weighted problem graphs and show that it matches the duplicate detection scope in best-first search graphs. Cost-optimal plans for compiled competition benchmark domains are computed.", "num_citations": "4\n", "authors": ["1628"]}
{"title": "Accelerating external search with bitstate hashing\n", "abstract": " In this paper we refine external exploration for explicit state model checking by a fusion with internal bitstate hashing. External A* provides a method to cope up with large state spaces by efficiently utilizing secondary storage devices like harddisk to maintain the open and closed lists. Duplicates are removed by a two-level refinement scheme that involves sorting a subset of the open list externally and subtracting a small subset of closed list from the open list. The bottleneck in External A*[7] is the duplicates removal phase that dominates the I/O complexity of External A*. Bitstate hashing provides a solution to faster duplicates removal by utilizing only few bits for each state. But bitstate hashing is faced with the problem of having no support for large open list and for solution reconstruction. We present a strategy to accelerate external search by using bitstate hashing for duplicates removal. Case studies with our experimental external explicit state model checker IO-HSF-SPIN illustrate the effectiveness of the proposed algorithms.", "num_citations": "4\n", "authors": ["1628"]}
{"title": "PDDL2. 2 planning in the model checking integrated environment\n", "abstract": " This paper addresses recent advances in planning in order to cope with the recently extended expressiveness of the problem domain description language PDDL.Timed initial facts are included into the plan finding process in form of time intervals in which instantiated actions can take place. Beside the new modelling perspective for exogenous events this extension can impose sharp time bounds and select plans of high quality. In this paper the least-commitment temporal planning to enable and accelerate plan-finding is extended and the model for critical path scheduling is refined.", "num_citations": "4\n", "authors": ["1628"]}
{"title": "Pushing the limits in sequential sorting\n", "abstract": " With refinements to the WEAK-HEAPSORT algorithm we establish the general and practical relevant sequential sorting algorithm RELAXED-WEAK-HEAPSORT executing exactly n_log n_ 2_log n_ + 1 = n log n 0.9n comparisons on any given input. The number of transpositions is bounded by n plus the number of comparisons. Experiments show that RELAXED-WEAK-HEAPSORT only requires O(n) extra bits. Even if this space is not available, with QUICK-WEAK-HEAPSORT we propose an efficient QUICKSORT variant with n log n+0.2n+ o(n) comparisons on the average. Furthermore, we present data showing that WEAK-HEAPSORT, RELAXED-WEAK-HEAPSORT and QUICK-WEAK-HEAPSORT beat other performant QUICKSORT and HEAPSORT variants even for moderate values of n.", "num_citations": "4\n", "authors": ["1628"]}
{"title": "Using SPIN for the optimized scheduling of discrete event systems in manufacturing\n", "abstract": " A discrete event system (DES) is a dynamic system with discrete states the transitions of which are triggered by events. In this paper we propose the application of the Spin software model checker to a discrete event system that controls the industrial production of autonomous products. The flow of material is asynchronous and buffered. The aim of this work is to find concurrent plans that optimize the throughput of the system. In the mapping the discrete event system directly to the model checker, we model the production line as a set of communicating processes, with the movement of items modeled as channels. Experiments shows that the model checker is able to analyze the DES, subject to the partial ordering of the product parts. It derives valid and optimized plans with several thousands of steps using constraint branch-and-bound.", "num_citations": "3\n", "authors": ["1628"]}
{"title": "Branch-and-Bound Optimization of a Multiagent System for Flow Production using Model Checking.\n", "abstract": " In this paper we propose the application of a model checker to evaluate a multiagent system that controls the industrial production of autonomous products. As the flow of material is asynchronous at each station, queuing effects arise as long as buffers provide waiting room. Besides validating the design of the system, the core objective of this work is to find plans that optimize the throughput of the system. Instead of mapping the multiagent system directly to the model checker, we model the production line as a set of communicating processes, with the movement of items modeled as communication channels. Experiments shows that the model checker is able to analyze the movements of autonomous products for the model, subject to the partial ordering of the product parts. It derives valid and optimized plans with several thousands of steps using constraint branch-and-bound.", "num_citations": "3\n", "authors": ["1628"]}
{"title": "Autonomous, adaptive, and self-organized multiagent systems for the optimization of decentralized industrial processes\n", "abstract": " This chapter presents the concepts, an example implementation, and the evaluation of an autonomous, self-organized, and adaptive multiagent system to optimize industrial processes in dynamic environments. In order to satisfy the rising requirements which result from the Fourth Industrial Revolution and to benefit from the consequent integration of the Internet of Things and Services, the system is designed to link the data of highly decentralized entities to virtual representatives. The goal0 is to mesh complex information and material flows as well as their interdependencies in order to achieve an integrated optimization of production and logistic processes. Due to the high dynamics, the domain of courier and express services provides one of the most challenging environments, in which a high amount of decentralized data and information has to be considered, updated, and processed continuously during\u00a0\u2026", "num_citations": "3\n", "authors": ["1628"]}
{"title": "Packing irregular-shaped objects for 3D Printing\n", "abstract": " This paper considers solving a problem in combinatorial search: the automated arrangement of irregular-shaped objects for industrial 3D printing. The input is a set of triangulated models; the output is a set of location and orientation vectors for the objects. The proposed algorithm consists of three stages: (1) translation of the models into an octree; (2) design of an efficient test for pairwise intersection based on sphere trees; and (3) computation of an optimized placement of the objects using simulated annealing. We compare several sphere-tree construction methods and annealing parameter settings to derive valid packings.", "num_citations": "3\n", "authors": ["1628"]}
{"title": "An In-Place Priority Queue with O(1) Time for Push and lgn+ O(1) Comparisons for Pop\n", "abstract": " An in-place                 priority queue is a data structure that is stored in an array, uses constant extra space in addition to the array elements, and supports the operations $$ top $$                                                                     t                         o                         p                                                                ($$ find $$                                                                     f                         i                         n                         d                                                               -$$ min $$                                                                     m                         i                         n                                                               ), $$ push $$                                                                     p                         u                         s                         h                                                                ($$ insert $$                                                                     i                         n                         s                         e                         r                         t                                                               ), and $$ pop $$                                                                     p                         o                         p\u00a0\u2026", "num_citations": "3\n", "authors": ["1628"]}
{"title": "Symbolic and Explicit Search Hybrid through Perfect Hash Functions\u2014A Case Study in Connect Four\n", "abstract": " This work combines recent advances in AI planning under memory limitation, namely bitvector and symbolic search. Bitvector search assumes a bijective mapping between state and memory addresses, while symbolic search compactly represents state sets. The memory requirements vary with the structure of the problem to be solved. The integration of the two algorithms into one hybrid algorithm for strongly solving general games initiates a BDD-based solving algorithm, which consists of a forward computation of the reachable state set, possibly followed by a layered backward retrograde analysis. If the main memory becomes exhausted, it switches to explicit-state two-bit retrograde search. We use the classical game of Connect Four as a case study, and solve some instances of the problem space-efficiently with the proposed hybrid search algorithm.", "num_citations": "3\n", "authors": ["1628"]}
{"title": "Agent-based dispatching enables autonomous groupage traffic\n", "abstract": " The complexity and dynamics in groupage traffic require flexible, efficient, and adaptive planning and control processes. The general problem of allocating orders to vehicles can be mapped into the Vehicle Routing Problem (VRP). However, in practical applications additional requirements complicate the dispatching processes and require a proactive and reactive system behavior. To enable automated dispatching processes, this article presents a multiagent system where the decision making is shifted to autonomous, interacting, intelligent agents. Beside the communication protocols and the agent architecture, the focus is on the individual decision making of the agents which meets the specific requirements in groupage traffic. To evaluate the approach we apply multiagent-based simulation and model several scenarios of real world infrastructures with orders provided by our industrial partner. Moreover, a case study is conducted which covers the autonomous groupage traffic in the current processes of our industrial parter. The results reveal that agent-based dispatching meets the sophisticated requirements of groupage traffic. Furthermore, the decision making supports the combination of pickup and delivery tours efficiently while satisfying logistic request priorities, time windows, and capacity constraints.", "num_citations": "3\n", "authors": ["1628"]}
{"title": "Flash memory efficient LTL model checking\n", "abstract": " As the capacity and speed of flash memories in form of solid state disks grow, they are becoming a practical alternative for standard magnetic drives. Currently, most solid-state disks are based on NAND technology and much faster than magnetic disks in random reads, while in random writes they are generally not.So far, large-scale LTL model checking algorithms have been designed to employ external memory optimized for magnetic disks. We propose algorithms optimized for flash memory access. In contrast to approaches relying on the delayed detection of duplicate states, in this work, we design and exploit appropriate hash functions to re-invent immediate duplicate detection.For flash memory efficient on-the-fly LTL model checking, which aims at finding any counter-example to the specified LTL property, we study hash functions adapted to the two-level hierarchy of RAM and flash memory. For flash memory\u00a0\u2026", "num_citations": "3\n", "authors": ["1628"]}
{"title": "KI 2011: Advances in artificial intelligence\n", "abstract": " The yearly German Conference on Artificial Intelligence is the premier forum for German research in artificial intelligence, and attracts numerous international guests, too. KI 2011, the 34th event of the series, reflected a long-standing tradition, and continued to mirror the trends and developments of the science. The 2011 conference took place in Berlin during October 4\u20137, in co-location with INFORMATIK 2011, the 41st Annual Meeting of the Gesellschaft f\u00fcr Informatik, and MATES 2011, the 9th German Conference on Multi-Agent System Technologies.Since its inception, artificial intelligence has been at the vanguard of computer science, and today, its applications and methods have become so widespread and ubiquitous that most people simply take them for granted. Its contributions have so thoroughly permeated the fabric of our digital lives that they have become almost invisible. Artificial intelligence has become\u00a0\u2026", "num_citations": "3\n", "authors": ["1628"]}
{"title": "Knowledge engineering through simulation\n", "abstract": " The objectives of the International Knowledge Engineering Competition for Planning and Scheduling are to judge tools for knowledge acquisition and domain modeling, to accelerate knowledge engineering research in AI, and to encourage the development of software platforms that promise more rapid, accessible, and effective ways to construct reliable and efficient systems.The 2nd edition for the competition aimed at quantitative instead of only qualitative results. The evaluation infrastructure accomplishes this in three ways: 1) standardizing the application domains on which competitors used their KE tools, 2) representing those domains using simulations and documentation describing the domains, and 3) logging records of tool interactions. Client-server communication for the exchange of simulator states and computed plans was realized via a textual protocol.", "num_citations": "3\n", "authors": ["1628"]}
{"title": "Quo vadis, IPC-4?\u2014Proposals for the classical part of the 4th International Planning Competition\n", "abstract": " The 4th International Planning Competition, IPC-4, will take place alongside ICAPS'04 as a continuation of the previous competition events. The intention is to divide the competition into three separate parts, one for classical planning, one for probabilistic planning, and one for non-deterministic planning. As the co-chairs of the classical part, we give an outline of our proposals for that part's organization. Concerning further language extensions, our standpoint is that PDDL 2.1 still provides a lot of challenges, and no or at most moderate extensions are appropriate at this point in time. Concerning benchmark domains, we want to lay stress on a more careful choice of these, specifically we want to move towards real-world problems, and diverse problem structures. Concerning evaluation, we want to lay more emphasis on plan quality, in particular on optimality guarantees. Concerning organizational aspects, our main focus is to make the competition results more widely perceivable and understandable at conference-time.", "num_citations": "3\n", "authors": ["1628"]}
{"title": "Accelerating Heuristic Search in Spatial Domains.\n", "abstract": " This paper exploits the spatial representation of state space problem graphs to preprocess and enhance heuristic search engines. It combines classical AI exploration with computational geometry. Our case study considers trajectories in the plane. The application domain is general route planning, independent to the underlying vehicle model. The implemented target system is located on a server and answers client\u2019s shortest path queries with respect to a set of global positioning system traces. A graph is constructed from the traces and is compressed while retaining the original information for unfolding the resulting shortest paths. The search space is pruned by the database entries concisely representing all shortest paths that start with a given edge. The latter algorithm is suited for a server application that has to serve a large number of queries from several different clients. The sudden changes in the topology of graph can affect the pre-computed database entries. This paper discusses some models to incorporate the changes in the graph and possible solutions.", "num_citations": "3\n", "authors": ["1628"]}
{"title": "Simplifying automated pattern selection for planning with symbolic pattern databases\n", "abstract": " Pattern databases (PDBs) are memory-based abstraction heuristics that are constructed prior to the planning process which, if expressed symbolically, yield a very efficient representation. Recent work in the automatic generation of symbolic PDBs has established it as one of the most successful approaches for cost-optimal domain-independent planning. In this paper, we contribute two planners, both using bin-packing for its pattern selection. In the second one, we introduce a greedy selection algorithm called Partial-Gamer, which complements the heuristic given by bin-packing. We tested our approaches on the benchmarks of the last three International Planning Competitions, optimal track, getting very competitive results, with this simple and deterministic algorithm.", "num_citations": "2\n", "authors": ["1628"]}
{"title": "Multi-robot multi-goal motion planning with time and resources\n", "abstract": " This paper addresses multi-robot multi-goal motion planning with temporal and resources constraints. It solves the vehicle routing problem for mobile robots that operate according to their system dynamics, and which have to visit a number of waypoints scattered in a two-dimensional map environment with obstacles, while satisfying time window and capacity constraints. We compute the shortest path distances between each pair of waypoints in advance, and Monte-Carlo search plans the vehicles\u2019 tour through adaptation of a rollout policy, while adding the constraints to its optimization objective. Macro actions enable the vehicles to run in real-time with best actions being distributed to the individual controllers. We analyze how the simulation is affected by varying parameters such as the number of vehicles.", "num_citations": "2\n", "authors": ["1628"]}
{"title": "Challenging human supremacy in skat guided and complete and-or belief-space tree search for solving the nullspiel\n", "abstract": " After impressive successes in deterministic and fully-observable board games to significantly outclass humans, game playing research shifts towards nondeterministic and imperfect information games, where humans are persistently better. In this paper we devise a player that indicates computer supremacy for the Nullspiel, a misere variant of Skat, in which the declarer has to lose all tricks. We combine knowldege elicitation in several million games, together with expert rules, and engineered tree exploration that eventually leads to the Guided and Complete And-Or Belief-Space Search. We provide a complete player, with effective solutions for bidding, skat putting and for playing the different variants of the game.", "num_citations": "2\n", "authors": ["1628"]}
{"title": "3.5 BDDs for Minimal Perfect Hashing: Merging Two State-Space Compression Techniques\n", "abstract": " This talk will merge two different lines of research, namely a) state-space exploration with binary decision diagrams (BDDs), that was initially proposed for Model Checking and still is state-of-the-art in AI Planning. b) state-space compaction with (minimal) perfect hashing, which is used in the algorithm community as a memory-based index for big data (often residing on disk). I will show how BDDs can serve as the internal representation of a perfect hash function with linear-time ranking and unranking, and how it can be used as a static dictionary and an alternative to the recent compression schemes exploiting hypergraph theory. This will also result in a simple method to split a BDD in parts of equal number of satisfying assignments and to generate random inputs for any function represented as a BDD. As a surplus, the BDD hash function is monotone.In terms of applications, symbolic exploration with BDD constructs a succinct representation of the state space. For each layer of the search, a BDDs is generated and stored, and will later serve as an index to do extra work like the classification of game states. Based on this approach we will show, how to strongly solve Connect-Four in a combination of symbolic and explicit-state space exploration.", "num_citations": "2\n", "authors": ["1628"]}
{"title": "Improving the cache-efficiency of shortest path search\n", "abstract": " Flood-filling algorithms as used for coloring images and shadow casting show that improved locality greatly increases the cache performance and, in turn, reduces the running time of an algorithm. In this paper we look at Dijkstra\u2019s method to compute the shortest paths for example to generate pattern databases. As cache-improving contributions, we propose edge-cost factorization and flood-filling the memory layout of the graph. We conduct experiments in commercial game maps and compare the new priority queues with advanced heap implementations as well as and with alternative bucket implementations.", "num_citations": "2\n", "authors": ["1628"]}
{"title": "Surface inspection via hitting sets and multi-goal motion planning\n", "abstract": " This paper develops an approach that enables an aerial vehicle to carry out 3D surface inspections. Given a 3D environment with a set of objects that need to be inspected, and an inspection quality , the objective is to compute a set of waypoints whose joint visibility ratio is at least  and a dynamically-feasible and collision-free trajectory that enables the aerial vehicle to reach all the waypoints. The approach seeks to minimize the number of the waypoints and the overall distance traveled by the aerial vehicle.               A superset of the waypoints is first generated by using random sampling or approximations of the medial axis via skeletonization algorithms. To reduce the number of the waypoints, the approach applies a visibility filtering mechanism based on a computation of a hitting set via Monte-Carlo search over an axis-aligned bounding box obstacle tree. After generating the waypoints, a multi\u00a0\u2026", "num_citations": "2\n", "authors": ["1628"]}
{"title": "Strengthened lazy heaps: Surpassing the lower bounds for binary heaps\n", "abstract": " Let  denote the number of elements currently in a data structure. An in-place heap is stored in the first  locations of an array, uses  extra space, and supports the operations: minimum, insert, and extract-min. We introduce an in-place heap, for which minimum and insert take  worst-case time, and extract-min takes  worst-case time and involves at most  element comparisons. The achieved bounds are optimal to within additive constant terms for the number of element comparisons. In particular, these bounds for both insert and extract-min -and the time bound for insert- surpass the corresponding lower bounds known for binary heaps, though our data structure is similar. In a binary heap, when viewed as a nearly complete binary tree, every node other than the root obeys the heap property, i.e. the element at a node is not smaller than that at its parent. To surpass the lower bound for extract-min, we reinforce a stronger property at the bottom levels of the heap that the element at any right child is not smaller than that at its left sibling. To surpass the lower bound for insert, we buffer insertions and allow  nodes to violate heap order in relation to their parents.", "num_citations": "2\n", "authors": ["1628"]}
{"title": "Lex-partitioning: A new option for BDD search\n", "abstract": " For the exploration of large state spaces, symbolic search using binary decision diagrams (BDDs) can save huge amounts of memory and computation time. State sets are represented and modified by accessing and manipulating their characteristic functions. BDD partitioning is used to compute the image as the disjunction of smaller subimages. In this paper, we propose a novel BDD partitioning option. The partitioning is lexicographical in the binary representation of the states contained in the set that is represented by a BDD and uniform with respect to the number of states represented. The motivation of controlling the state set sizes in the partitioning is to eventually bridge the gap between explicit and symbolic search. Let n be the size of the binary state vector. We propose an O(n) ranking and unranking scheme that supports negated edges and operates on top of precomputed satcount values. For the uniform split of a BDD, we then use unranking to provide paths along which we partition the BDDs. In a shared BDD representation the efforts are O(n). The algorithms are fully integrated in the CUDD library and evaluated in strongly solving general game playing benchmarks.", "num_citations": "2\n", "authors": ["1628"]}
{"title": "Efficient Tolerant Pattern Matching with Constraint Abstractions in Description Logic.\n", "abstract": " In this paper we consider efficiently matching logical constraint compositions called patterns by introducing a degree of satisfaction. The major advantage of our approach to other soft pattern matching methods is to exploit existing domain knowledge represented in Description Logic to handle imprecision in the data and to overcome the problem of an insufficient number of patterns. The matching is defined in a probabilistic framework to support post-processing with probabilistic models. Additionally, we propose an efficient complete algorithm for this kind of pattern matching, which reduces the number of inference calls to the reasoner. We analyze its worst-case complexity and compare it to a simple and to a theoretical optimal algorithm.", "num_citations": "2\n", "authors": ["1628"]}
{"title": "Engineering benchmarks for planning: the domains used in the deterministic Part of IPC-4\n", "abstract": " In a field of research about general reasoning mechanisms, it is essential to have appropriate benchmarks. Ideally, the benchmarks should reflect possible applications of the developed technology. In AI Planning, researchers more and more tend to draw their testing examples from the benchmark collections used in the International Planning Competition (IPC). In the organization of (the deterministic part of) the fourth IPC, IPC-4, the authors therefore invested significant effort to create a useful set of benchmarks. They come from five different (potential) real-world applications of planning: airport ground traffic control, oil derivative transportation in pipeline networks, model-checking safety properties, power supply restoration, and UMTS call setup. Adapting and preparing such an application for use as a benchmark in the IPC involves, at the time, inevitable (often drastic) simplifications, as well as careful choice\u00a0\u2026", "num_citations": "2\n", "authors": ["1628"]}
{"title": "Reports of the AAAI 2010 conference workshops\n", "abstract": " The AAAI-10 Workshop program was held Sunday and Monday, July 11\u201312, 2010 at the Westin Peachtree Plaza in Atlanta, Georgia. The AAAI-10 workshop program included 13 workshops covering a wide range of topics in artificial intelligence. The titles of the workshops were AI and Fun, Bridging the Gap between Task and Motion Planning, Collaboratively-Built Knowledge Sources and Artificial Intelligence, Goal-Directed Autonomy, Intelligent Security, Interactive Decision Theory and Game Theory, Metacognition for Robust Social Systems, Model Checking and Artificial Intelligence, Neural-Symbolic Learning and Reasoning, Plan, Activity, and Intent Recognition, Statistical Relational AI, Visual Representations and Reasoning, and Abstraction, Reformulation, and Approximation. This article presents short summaries of those events.", "num_citations": "2\n", "authors": ["1628"]}
{"title": "Solving games in parallel with linear-time perfect hash functions\n", "abstract": " In this paper, we propose an efficient method of solving one-and two-player combinato-rial games by mapping each state to a unique bit in memory. In order to avoid collisions, a concise portfolio of perfect hash functions is provided. Such perfect hash functions then address tables that serve as a compressed representation of the search space and support the execution of exhaustive search algorithms like breadth-first search and retrograde analysis. Perfect hashing computes the rank of a state, while the inverse operation unrank re-constructs the state given its rank. Efficient algorithms are derived, studied in detail and generalized to a larger variety of games. We study rank and unrank functions for permu-tation games with distinguishable pieces, for selection games with indistinguishable pieces, and for general reachability sets. The running time for ranking and unranking in all three cases is linear in the size of the state vector. To overcome space and time limitations in solving previously unsolved games like Frogs-and-Toads and Fox-and-Geese, we utilize parallel computing power in form of multiple", "num_citations": "2\n", "authors": ["1628"]}
{"title": "Symbolic classification of general multi-player games\n", "abstract": " For general two-player turn-taking games, first solvers have been contributed. Algorithms for multi-player games like Max n, however, cannot classify general games robustly, and its extension Soft-Max n, which can play optimally against unknown and weak opponents, demands large amounts of memory. As RAM is a scarce resource, this paper proposes a memory-efficient implementation of the Soft-Max n algorithm, by exploiting the functional representation of state and evaluation sets with BDDs.", "num_citations": "2\n", "authors": ["1628"]}
{"title": "External Memory Search for Verification of Multi-threaded C++ Programs.\n", "abstract": " With the advent of multi-core processors, the need for development of multi-threaded softwares has become indispensable. Verification of multi-threaded programs, particularly those that involve sharing of memory resources, poses a greater challenge than their sequential counterparts. A certain class of software model checking problems can be transformed to AI search problems in graphs. Search algorithms, such as DFS, BFS, A*, etc. can then be applied to find an erroneous program location in a given program. Unfortunately, verification of softwares is very memory intensive. In this paper, we equip the search algorithms used in model checking a C++ program, with a controlled access to secondary memory such as hard disk. We exploit the concept of a signature of a state that allows the full state vector to stay on secondary memory. The extended search algorithms are now able to solve larger problems that were unsolvable due to the memory bottleneck.", "num_citations": "2\n", "authors": ["1628"]}
{"title": "Model Checking Software: 14th International SPIN Workshop, Berlin, Germany, July 1-3, 2007, Proceedings\n", "abstract": " This book presents the proceedings of the 14th International SPIN workshop on Model Checking Software, held in Berlin, Germany. Fourteen full papers are presented, together with four tool presentation papers and the abstracts of two invited talks. The papers are organized into topical sections covering directed model checking, partial order reduction, program analysis, exploration advances, modeling and case studies, and tool demonstrations.", "num_citations": "2\n", "authors": ["1628"]}
{"title": "Optimal Infinite State Planning with Presburger Automata\n", "abstract": " The paper proposes a new approach to infinite-state action planning with automata theory. State sets and actions are encoded as Presburger formulae and represented using minimized automata. The symbolic exploration that contributes to the planning via model checking paradigm repeatedly applies partitioned images on such automata to compute the automata for the successors of the current state set. The implementation adapts a library for automata manipulation.", "num_citations": "2\n", "authors": ["1628"]}
{"title": "External program model checking\n", "abstract": " To analyze larger models for model checking, external algorithms have shown considerable success in the verification of communication protocols. This paper applies external model checking to software executables. The state in such a verification approach itself is very large, such that main memory hinders the analysis of larger state spaces and calls for I/O efficient exploration algorithms. We propose a general state expanding algorithm based on a search tree skeleton with outsourced states. External collapse traded time for space. Additionally, heuristics accelerate the search process, guide it towards the error and shorten the length of the counterexample. Different caching and exploration strategies are evaluated. We found a counterexample in a C++-program for the Dining Philosophers\u2019 problem with 300 philosophers in a successful exploration lasting for over 100 hours while consuming 0.5 gigabytes RAM and 19 gigabytes hard disk.", "num_citations": "2\n", "authors": ["1628"]}
{"title": "Trail-directed Java program verification\n", "abstract": " This paper introduces the application of trail-based heuristics for software verification. Trail-directed program verification serves the purpose of shortening an error trail, so that it will be more comprehensible for the user. We explain the concept of two heuristics that are based on the Hamming-and FSM-distance between states of a Java program. We then utilize the Java software verifier JPF to implement and test the new heuristics and to compare them to the heuristics that are already provided by this tool.", "num_citations": "2\n", "authors": ["1628"]}
{"title": "Learning dead ends in sokoban\n", "abstract": " The main goal in Heuristic Search is to control huge (in general exponential sized) search spaces. Two di erent orthogonal approaches can be distinguished: First, to devise an heuristic that estimates the optimal solution length for every state in the space as accurate as possible. Second, in several domains there are one-way moves that can never be went back on (doors may shut if we go through, or handles might even be installed only on one side). Pruning is used to discard such dead ends, ie, branches that cannot possibly lead to a goal. In this talk we propose an extension of the well known A algorithm proposed by Hart, Nilsson and Raphael (1968) that allows to detect, memorize and generalize situations that are dead. Herein, generalization is done by restricting to relevant (partial) subpositions responsible for the failure. A data structure called Subposition Store is used for e cient storage and retrieval of these subposition.The algorithm is evaluated in the domain of the Sokoban puzzle, which is one of the remaining one-person games in which the human solution quality still outperforms all attempts to automatic solving strategies coded in a computer program. In Sokoban n balls are placed somewhere in a maze containing n goal elds which they must eventually reach. The player controls a man which can traverse the board and push the balls onto adjacent empty squares. Three problems can be distinguished: Decide, Pushes and Moves. Decide is just the task to solve the puzzle. Pushes additionally asks to minimize the number of ball pushes whereas Moves request an optimal number of man movements. Although all problems are\u00a0\u2026", "num_citations": "2\n", "authors": ["1628"]}
{"title": "Benchmarks Old and New: How to compare domain independence for costoptimal classical planning\n", "abstract": " Domain independence is one of the main features of automated planning. Planners, in the context of cost-optimal classical planning, are developed with the intent of solving any type of problem that can be formulated in PDDL. We then compare planners by the number of problem instances they solve on a set of benchmarks, one point for each problem solved. However, does solving the most problems automatically result in having the best domain-independent planner? In this paper, we compare the best performing, non-portfolio planners from the cost-optimal classical track of the International Planning Competition (IPC) 2018 on the complete set of benchmarks from the previous two competitions (2011 and 2014) and on a subset of the competitions from before 2011. Results show that, as the number of problems for each domain varies, current way of comparing planners (total coverage) can be biased towards the planners that perform the best in the domains with the most instances, but once we normalize those results, we can get a better picture for which technique is the most domain independent.", "num_citations": "1\n", "authors": ["1628"]}
{"title": "A case study of planning for smart factories\n", "abstract": " In this work, we propose the application of the SPIN software model checker to a multiagent system that controls the industrial production of goods. The flow of material is buffered on a production line with assembling stations. As the flow of material is asynchronous at each station, queuing is required as long as buffers provide waiting room. Besides validating the design of the system, the core objective of this work is to find concurrent plans that optimize the throughput of the system. In the mapping of the production system to the model checker, we model the production line as a set of communicating processes, with the movement of items modeled as channels. Experiments show that the model checker is able to analyze the system, subject to the partial ordering of the product parts. It derives valid and optimized plans with several thousands of steps using constraint branching in branch-and-bound search\u00a0\u2026", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Solving graph optimization problems in a framework for Monte-Carlo search\n", "abstract": " In this paper we solve fundamental graph optimization problems like Maximum Clique and Minimum Coloring with recent advances of Monte-Carlo Search. The optimization problems are implemented as single-agent games in a generic state-space search framework, roughly comparable to what is encoded in PDDL for an action planner.", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Heap Construction\u201450 Years Later\n", "abstract": " We study the problem of constructing a binary heap in an array using only a small amount of additional space. Let N denote the size of the input, M the capacity of the cache, and B the width of the cache lines of the underlying computer, all measured as numbers of elements. We show that there exists an in-place heap-construction algorithm that runs in \u0398(N) worst-case time and performs at most 1.625N+o(N) element comparisons, 1.5N+o(N) element moves, N/B+O(N/M\u00b7lgN) cache misses, and 1.375N+o(N) branch mispredictions. The same bound for the number of element comparisons was derived and conjectured to be optimal by Gonnet and Munro; however, their algorithm requires \u0398(N) pointers. For a tuning parameter S, the idea is to divide the input into a top tree of size  such that each of its leaves root a bottom tree of size \u0398(S). When S=\u0398(lgN/lglgN), we can convert the bottom trees into heaps\u00a0\u2026", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Solving the Physical Vehicle Routing Problem for Improved Multi-robot Freespace Navigation\n", "abstract": " Freespace navigation for autonomous robots is of growing industrial impact, especially in the logistics and warehousing domain. In this work, we describe a multiagent simulation solution to the physical vehicle routing problem, which extends the physical traveling salesman problem \u2014a recent benchmark used in robot motion planning research\u2014 by considering more than one concurrent vehicle.                 For the interaction of vehicles, we compute the collision of physical bodies and then apply the impact resulting from the elastic collision. A multi-threaded controller is implemented which forwards the proposed actions from each individual robot\u2019s controller to the environment real-time simulator. For computing an optimized assignment of the pickup and delivery tasks to the vehicles we apply nested Monte-Carlo tree search.                 In the experiments, we study the problem of robot navigation for\u00a0\u2026", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Proceedings of the Twenty-Sixth International Conference on Automated Planning and Scheduling\n", "abstract": " Proceedings of the Twenty-Sixth International Conference on Automated Planning and Scheduling - Research Portal, King's College, London King's College London King's main site Research portal Home Researchers Research Groups Research Outputs Research Funding Internal Research Outputs Theses . Journals Publishers Proceedings of the Twenty-Sixth International Conference on Automated Planning and Scheduling Research output: Book/Report \u203a Book \u203a peer-review Amanda Jane Coles (Editor), Andrew Ian Coles (Editor), Stefan Edelkamp (Editor), Daniele Magazzeni (Editor), Scott Sanner (Editor) Overview Citation formats Original language English Publisher AAAI Press ISBN (Print) 978-1-57735-757-5 Published 2016 Links http://www.aaai.org/Library/ICAPS/icaps16contents.php Final published version King's Authors Amanda Jane Coles (Editor) (Informatics, Planning, Reasoning and Planning) \u2026", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Heap-construction programs\n", "abstract": " This report together with an accompanying tar ball contains the source code of the programs described and benchmarked in the paper \u201cHeap Construction\u201450 Years Later\u201d. The programs in this package describe the state of the art in heap construction in 2016.", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Fractal Approximate Nearest Neighbour Search in Log-Log Time.\n", "abstract": " The power of fractal computation has been mainly exploited for image compression and halftoning. Here, we consider it for finding a fast approximate solution for the fundamental problem of nearest neighbour computation in the image plane. Traditional solutions use Delaunay triangulations or hierarchies (for the case of optimal solutions) or kd-trees for approximate ones. In contrast, we use a space-filling Hilbert curve which allows us to reduce the problem from 2D to 1D. The Hilbert curve has already been used to optimise high-dimensional nearest neighbour queries in the context of data base systems. In this paper, we propose a simplified solution that fits better to the computer vision context. We show that our algorithms solve two particular nearest neighbor problems efficiently. We provide practical results on the accuracy of the method and show that it is significantly faster than a kd-tree.", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Advances in BDD Search: Filtering, Partitioning, and Bidirectionally Blind\n", "abstract": " Symbolic search with BDDs often saves huge amounts of memory and computation time, but in the sequential-optimal track of the 2011 International Planning Competition (IPC) explicit-state heuristic search planners performed better. In this paper we present a set of improvements for blind and heuristic search with BDDs that indicate how to scale better. Besides some basic refinements this paper proposes two general techniques to advance BDD search by refining the image operator to compute the set of successors. First, a transition relation tree selects the set of applicable actions through filtering their precondition. Secondly, the state sets to be expanded are partitioned in equally-sized state subsets. Experiments on IPC 2011 planning benchmark domains are reported, with surprisingly good results for bidirectional blind search.", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Gamer: Fully-observable non-deterministic planning via pddl-translation into a game\n", "abstract": " This paper presents an optimal planner for the international probabilistic planning competition at ICAPS-08, IPPC-2008 for short. The planner solves non-deterministic action planning problems with binary decision diagrams. The efficiency of the planning approach is based on a translation of the non-deterministic planning problems into a twoplayer turn-taking game, with a set of actions selected by the solver and a set of actions taken by the environment. The formalism we use is a PDDL-like planning domain description language that has been derived to parse and instantiate general games. This conversion allows to derive a concise description of planning domains with a minimized state vector, thereby exploiting existing static analysis tools for deterministic planning.", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Optimal net-benefit with BDDs\n", "abstract": " This paper studies planning problems with discrete action costs and soft constraints. The net-benefit we optimize is the total benefit of satisfying the goals, minus the total action cost to achieve them. This results in a plan objective function to be minimized that is a linear expression over violation of the preferences added to the action cost total. If no goal preference is found, a BDD-based exploration that integrates a bucket implementation of Dijkstra\u2019s single source shortest path algorithm is presented. For computing netbenefits, we contribute a symbolic branch-and-bound search algorithm together with several search refinements.", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Pushing the Limits for Planning Pattern Databases\n", "abstract": " In this paper we illustrate efforts to perform memory efficient largescale planning. We first generate sets of disjoint pattern databases spaceefficiently using symbolic PDDL planning on disk. To improve the quality of the heuristic, temporal constraints are imposed. We then apply external memory heuristic search and propose its integration with IDA*. Different options for parallelization to save time and memory are presented. The general techniques are mapped to the (n2\u2212 1)-Puzzle as a running case study.", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Model Checking Software\n", "abstract": " The SPIN workshops focus on techniques for the validation and analysis of software systems based on explicit representations of state spaces, or combination of the latter with other representations. One of the main goals of the workshops is to encourage the interaction of researchers and practitioners in this area and the exchange of ideas with scientists working in related areas in software engineering. The evolution and success of the SPIN workshops reflects the maturing of model checking into a dominant technology for the formal verification of software systems. The first SPIN workshop was held in Montreal in 1995. In its first instances the workshop was intended as a forum for presenting extensions and applications of the model checker SPIN, to which the workshop owes its the name. As from the year 2000, the scope of the event clearly broadened to more general topics on software verification. To promote the\u00a0\u2026", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Automated pattern database design\n", "abstract": " Pattern databases are dictionaries for heuristic estimates based on state-to-goal distances in state space abstractions. Their effectiveness is sensitive to the selection of the underlying patterns. Especially for multiple and additive pattern databases, a manual selection of pattern sets that lead to good exploration results is involved.For automating the selection process, greedy bin-packing strategies have been suggested. This paper proposes genetic algorithms to optimize their output. Patterns are encoded as Boolean matrices and optimized using an objective function based on predicting the heuristic search tree size, given the distribution of heuristic values in the abstract state spaces. To reduce the memory requirements of the databases we apply a construction process based on BDDs. Experiments in heuristic search planning show that the search efforts are significantly reduced.", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Cost-optimal symbolic pattern database planning with state trajectory and preference constraints\n", "abstract": " This paper considers strategies for planning problems with state trajectory and plan preference constraints\u2013two recently added PDDL features that have been introduced in the context of the 5th international planning competition.A symbolic breadth-first search exploration algorithm is devised that is guaranteed to find the cost-optimal plan wrt. the preference conditions imposed. For untimed trajectory constraints we propose to run a synchronized property automata concurrent to the unconstrained state space, while timed trajectory constraints are checked during plan construction. Plan preferences are evaluated in the cost function after a successful plan has been generated. For deriving good search heuristics, we turn to the construction of symbolic pattern databases and the pattern selection problem.", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Dynamic Incremental Hashing and State Reconstruction in Program Model Checking\n", "abstract": " Concurrent systems exhibit a large number of identical states and hashing helps detecting duplicates and thus battling the state explosion problem. In this paper we introduce incremental hashing on large, dynamically changing state vectors, that naturally arise during the verification of software in program model checkers. We exploit the fact that only small portions of the state description are changed by a single transition. Based on the changes in the predecessor state, the new state and its hash value can be computed efficiently. In addition, we introduce state reconstruction, a method which exploits fast successor generation to trade time for space.", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Protocol Verification with Heuristic Search: First Results\n", "abstract": " In this paper we present the new protocol validator HSF-SPIN that incorporates directed search for checking safety properties. Promela speci cations are parsed into c++-code to serve as a general single-state problem with start, goal, expand and estimator function to be solved with di erent heuristic search algorithms. The basic idea is to accelerate the search process into the direction of a speci ed goal situation, which in the case of protocol veri cation is the set of errors. The explored part will be smaller than with classical approaches, allowing larger validations. If the estimate is a lower bound, optimal solutions will be found. The estimates exploit the representation of the protocol as communicating processes with queues and nite state machines. We evaluate the impact of various heuristics in reducing the search tree on scalable benchmark protocols. We also present a new search paradigm based on the combination of partial and heuristic search.", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Neue Wege in der Exploration\n", "abstract": " Exploration ist eine der fundamentalen Methoden in der Informatik allgemein und der K\u00fcnstlichen Intelligenz im speziellen. Wesentliche Erfolge reichen von der Bezwingung von Weltmeistern in nicht trivialen Spielen bis hin zu vielf\u00e4ltigen Handlungsablaufspl\u00e4nen. Allerdings ben\u00f6tigen die komplexen Anwendungen von heute und morgen mehr und mehr neue und ausgefeilte Methoden, um die inh\u00e4rente kombinatorische Explosion des zugrunde liegenden Zustandsraumes zu umgehen. In diesem Artikel stellen wir einige vielversprechende Ans\u00e4tze vor und diskutieren ihre praktische Anwendbarkeit.", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Dictionary automaton in optimal space\n", "abstract": " In this paper we describe the data structure of a time and space e cient string dictionary automaton, providing insertion and deletion of strings and nite state machine based substring searching. If the input alphabet is bounded and the pattern are mutually substring free an optimal worst case bound of O (jmj) for both insertion and deletion of a pattern m is achieved.The underlying structure is a multi su x tree. Let M be the set of strings stored in the dictionary resulting from an arbitrary sequence of Insert and Delete operations. One main result in this paper is that the space complexity of the augmented multi su x tree is O (d) with d=", "num_citations": "1\n", "authors": ["1628"]}
{"title": "Multi Suffix Tree Dictionary in Optimal Space\n", "abstract": " The talk is about a dictionary data structure D for matching multiple pat-tern. If the input alphabet \u03a3 is bounded and the pattern m in D are considered to be mutually substring free an optimal worst case bound of O (| m|) for both insertion and deletion of a pattern m\u2208 \u03a3\u2217 is achieved. Since the strings in D are not substrings of each other this is a special case of the dynamic dictionary matching problem (DDMP). The structure D is realised as a multi suffix tree. Let M be the set of strings stored in the dictionary D resulting from an arbitrary sequence of Insert and Delete operations. The main result is that the space complexity of the augmented multi suffix tree representing D is O (d) with d= m\u2208 M| m|. This bound is optimal if we assume that each pattern in the dictionary uses at least linear space and has not been achieved before. Further on, I present a new incremental Search operation to find one sub-string of x in time O (| x|). In the general case of the DDMP I will show that searching all tocc (total number of occurences) substrings in x can be performed in almost O ((| x|+ tocc) log d) time without destroying the linear efficiency re-sults of Insert and Delete. Last but not least, I will talk about the use of the multi suffix tree dictionary in state space search of huge problem spaces that do not fit in the memory. Thus we may assume that the problem space is described implicitely by a bounded number of transitions and that transition sequences can be regarded as strings. The set of strings M can be used as a set of forbidden words, so-called duplicates, in the search. Duplicates are transition sequences that are more expensive then their counterparts. When a\u00a0\u2026", "num_citations": "1\n", "authors": ["1628"]}