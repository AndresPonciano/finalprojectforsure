{"title": "Components of visual orienting\n", "abstract": " A peripheral visual cue produces an orienting of attention that facilitates detection of targets in the cued area. Following a shift of attention away from the cued area, targets at that location are handled less efficiently than at other places. We demonstrate this inhibitory effect, show that it arises from the sensory information present in the cue, and discuss its relationship to shifts in eye position and its functional significance in the process of orienting of attention. We indicate how the inhibitory effect accounts for the difficulty in demonstrating attentional orienting in situations where attended information arises from a single spatial position.'we believe that the components of visual orienting provide a model experimental system where important components of cognitive tasks can be linked to neural systems.", "num_citations": "4165\n", "authors": ["1039"]}
{"title": "Neural systems control of spatial orienting\n", "abstract": " A peripheral visual cue in an empty field (1) often summons head or eyes, or both, (2) improves efficiency at. the cued position while attention is directed to it, even without overt movements, and (3) reduces processing efficiency at the cued position once attention is withdrawn. We have studied the time course and the effects of mid-brain and cortical damage on these components of orienting. The facilitation arises from shifts in covert attention. In cases of mid-brain degeneration due to progressive supranuclear palsy, saccadic movements were abolished, while covert orienting still occurs. However, covert orienting was found to be delayed in directions in which eye movements were most affected, suggesting a role for mid-brain pathways in covert orienting. Parietal lesions can cause massive loss in detection contralateral to the lesion. This is especially true when attention has been directed to the opposite side\u00a0\u2026", "num_citations": "782\n", "authors": ["1039"]}
{"title": "14 Attention and the Control of Movements\n", "abstract": " During voluntary movements hand and eye are coordinated under the control of central attentional mechanisms. Several techniques are reviewed that serve to dissociate the usually coordinate activity of attention, eye and hand movements. Discrepancies between central expectancies and visual input produce errors that differentially affect hand and eye. Interference between directed eye movements and manual probes is used to trace both the capacity utilization and spatial distribution of attention during eye movements. Monocular bilateral stimulation is used to separate endogenous control of oculomotor responses from pathways subserving centrally controlled eye movements and consciousness. Taken as a whole, these techniques provide promising avenues for understanding the central control of coordinate movements.", "num_citations": "153\n", "authors": ["1039"]}
{"title": "HIPS: A Unix-based image processing system\n", "abstract": " A software system for image processing, HIPS, was developed for use in a UNIX environment. It includes a small set of subroutines which primarily deals with a standardized descriptive image sequence header, and an ever-growing library of image transformation tools in the form of UNIX \u201cfilters.\u201d Programs have been developed for simple image transformations, filtering, convolution, Fourier and other transform processing, edge detection and line drawing manipulation, simulation of digital compression and transmission, noise generation, and image statistics computation. The system has the useful feature that images are self-documenting to the extent that each image as stored in the system includes a history of the transformations that have been applied to that image. Although it has been used primarily with a Grinnell image processor, the bulk of the system is machine-independent. The system has proven itself a\u00a0\u2026", "num_citations": "142\n", "authors": ["1039"]}
{"title": "Conjunctive Continuous Performance Task (CCPT)\u2014A pure measure of sustained attention\n", "abstract": " Among the large variety of attentional tasks that have been used to study sustained attention, the Continuous Performance Task (CPT) is perhaps the most widely used. Despite substantial differences in task characteristics and demands, all CPT paradigms have been referred to as measures of sustained attention. In the present study we introduce a new variant of CPT, which minimizes perceptual and memory components while maximizing the sustained attention components of the task. In addition, we tested the contention that the ability to sustain attention should not be overly dependent on the specific stimuli and task-modality. To this end, we used a new visual Conjunctive CPT (CCPT) developed by Tsal, Shalev, & Mevorach (2005) and its auditory analogue. Using a Multi-Trait-Multi-Method (MTMM) analysis investigating reliability coefficients, convergent validity coefficients and divergent (discriminant) validity\u00a0\u2026", "num_citations": "96\n", "authors": ["1039"]}
{"title": "Intelligible encoding of ASL image sequences at extremely low information rates\n", "abstract": " American Sign Language (ASL) is a gestural language used by the hearing impaired. This paper describes experimental tests with deaf subjects that compared the most effective known methods of creating extremely compressed ASL images. The minimum requirements for intelligibility were determined for three basically different kinds of transformations: (1) gray-scale transformations that subsample the images in space and time; (2) two-level intensity quantization that converts the gray scale image into a black-and-white approximation; (3) transformations that convert the images into black and white outline drawings (cartoons). In Experiment 1, five subjects made quality ratings of 81 kinds of images that varied in spatial resolution, frame rate, and type of transformation. The most promising image size was 96 \u00d7 64 pixels (height \u00d7 width). The 17 most promising image transformations were selected for formal\u00a0\u2026", "num_citations": "95\n", "authors": ["1039"]}
{"title": "Hierarchical coding of binary images\n", "abstract": " Quadtrees are a compact hierarchical method of representation of images. In this paper, we explore a number of hierarchical image representations as applied to binary images, of which quadtrees are a single exemplar. We discuss quadtrees, binary trees, and an adaptive hierarchical method. Extending these methods into the third dimension of time results in several other methods. All of these methods are discussed in terms of time complexity, worst case and average compression of random images, and compression results on binary images derived from natural scenes. The results indicate that quadtrees are the most effective for two-dimensional images, but the adaptive algorithms are more effective for dynamic image sequences.", "num_citations": "94\n", "authors": ["1039"]}
{"title": "Sustained concentration: Passive filtering or active orienting?\n", "abstract": " This paper is concerned with the process by which one selects information from a sensory channel. Two possibilities are considered. In one the person sets a filter which then passively delivers information from the selected source to consciousness (passive filter). In the second view the person maintains an active set or orientation toward the selected channel. Two sets of experiments are presented. The first shows that any visual signal that occurs at a position eccentric to the line of sight produces a relative slowing on the response times for processing subsequent signals at that spatial position. This effect lasts approximately 1\u20132 seconds. 50Thus a consequence of a visual stimulus at a spatial position is to reduce the efficiency of attending to subsequent information at that location.", "num_citations": "88\n", "authors": ["1039"]}
{"title": "HIPS: Image processing under UNIX. Software and applications\n", "abstract": " HIPS (Human Information Processing Laboratory\u2019s Image processing System) is a software system for image processing that runs under the UNIX operating system. HIPS is modular and flexible: it provides automatic documentation of its actions, and is relatively independent of special equipment. It has proved its usefulness in the study of the perception of American Sign Language (ASL). Here, we demonstrate some of its applications in the study of vision, and as a tool in general signal processing. Ten examples of HIPS-generated stimuli and\u2014in some cases\u2014analyses are provided, including the spatial filtering analysis of two types of visual illusions; the study of frequency channels with sine-wave gratings and band-limited noise; 3-dimensional perceptual reconstruction from 2-dimensional images in the kinetic depth effect; the perception of depth in random dot stereograms and cinematograms; and the\u00a0\u2026", "num_citations": "63\n", "authors": ["1039"]}
{"title": "Vectorgraph coding: efficient coding of line drawings\n", "abstract": " A method for the efficient coding of line drawings is discussed. The intent is to provide an extremely low bandwidth representation for images, preserving \u201cintelligible\u201d image content but not necessarily image quality. This has led to an image transformation involving edge enhancement, detection, line thinning, and polygonal splining which is termed the polygonal transformation. The graph-like image which results from this transformatiom is coded quite efficiently by using vectorgraph coding, which codes a series of vectors in a manner similar to that used in many computer graphics systems. This technique has been applied to a body of images of American Sign Language and the results are encouraging.", "num_citations": "34\n", "authors": ["1039"]}
{"title": "Image processing in perception and cognition\n", "abstract": " In this paper we briefly survey theories and ideas about image processing, with some illustrative examples, taken mostly from the Human information Processing Laboratory at N.Y.U. First we develop the concepts of multiple stable states and path dependence in a basic visual-motor task (vergence of the eyes) and show how these can be encompassed in potential theory. We then consider two examples of human information extraction from complex, dynamic, visual displays: (1) the extraction of the shape and the motion of 3D wire objects from 2D images, and (2) the extraction of meaning from displays of deaf signers communicating in American Sign Language (ASL).", "num_citations": "33\n", "authors": ["1039"]}
{"title": "The Effect of Specific Language Features on the Complexity of Systems for Automated Essay Scoring.\n", "abstract": " This paper focuses on the relationship between different aspects of the linguistic structure of a given language and the complexity of the computer program, whether existing or prospective, that is to be used for the scoring of essays in that language. The first part of the paper discusses common scales used to assess writing products, then briefly describes various methods of Automated Essay Scoring (AES) and reviews several AES programs currently in use. It also presents empirical results attesting to the reliability and validity of these programs, principally with regard to essays written in English. The second part of the paper presents various linguistic features that may vary extensively across languages and examines the ramifications of these features on the complexity of the AES operational system. This analysis is presented chiefly with regard to Hebrew and English, which are used to illustrate the differences that may exist between languages.(Contains 5 tables and 30 references.)(SLD)", "num_citations": "30\n", "authors": ["1039"]}
{"title": "Regulating the diagnosis of learning disability and the provision of test accommodations in institutions of higher education\n", "abstract": " The vast diversity of operational definitions of learning disabilities (LD) and practices used for its diagnosis threaten standardization, objectivity and fairness in the diagnosis of LD and the provision of test accommodations. The current paper describes an endeavor to overcome this problem by regulating and standardizing the diagnosis of learning disability (LD) in tertiary education and the provision of test accommodations. This endeavor, conducted by The National Institute for Testing and Evaluation (NITE) in cooperation with the Council of Higher Education in Israel, included:(1) development, validation and norming of MATAL: a computer-based test battery for the diagnosis of LD;(2) development of statistical decision rules for determining diagnosis based on test results;(3) development of guidelines for the provision of test accommodations;(4) establishment of diagnostic centers within institutions of higher education; and (5) establishment of a professional network of all parties involved in the diagnosis and support of students with LD in institutions of higher education.", "num_citations": "26\n", "authors": ["1039"]}
{"title": "Internal and external control of visual orienting\n", "abstract": " A visual stimulus appearing at the periphery of the visual field, speeds up the detection of subsequent stimuli at the same location. When attention is redirected away from this location, detection of subsequent stimuli is slowed down. These observations can be explained by assuming that a peripheral stimulus triggers two parallel processes; a fast facilitatory process and a slower inhibitory process. Two paradigms were employed in order to determine whether the two processes come from different levels of a processing hierarchy. A dichoptic viewing experiment demonstrated that neither process is mediated by monocular pathways only. Experiments in which subjects executed vertical saccades in addition to the detection task, showed that the facilitatory effect can be described by retinal coordinates (and not by environmental coordinates)--as if attention is moving with the retinae. However, anchoring of attentional\u00a0\u2026", "num_citations": "22\n", "authors": ["1039"]}
{"title": "A revised modified parallel analysis for the construction of unidimensional item pools\n", "abstract": " Modified parallel analysis (MPA) is a heuristic method for assessing \"approximate unidimensionality\" of item pools. It compares the second eigenvalue of the observed correlation matrix with the corresponding eigenvalue extracted from a \"parallel\" matrix generated by a unidimensional and locally independent model. Revised MPA (RMPA) generalizes MPA and alleviates some of its technical limitations. RMPA includes an important and useful feature for eliminating items that violate the test's unidimensionality. This is achieved by eliminating items, one at a time, to determine their contribution to the matrices' eigenvalues. A test for detecting items with large impact in the observed dataset and then eliminating them is proposed. The new method was tested in several simulations in which unidimensional item pools were \"contaminated\" by various proportions of items from a secondary pool. The results indicate that\u00a0\u2026", "num_citations": "20\n", "authors": ["1039"]}
{"title": "Translating and adapting a test, yet another source of variance; the standard error of translation\n", "abstract": " Test transadaptation (translation and adaptation) is the process whereby a test constructed in one language and culture is prepared for use in a second language and culture. Test transadaptation involves both the translation and adaptation of items written originally in the source language and the replacement of items unsuitable for translation/adaptation with items written in the target language. In the process, the transadaptation team effects a series of changes and modifications before the test attains its final transadapted form.One of the International Test Commission (ITC) Guidelines for Test Translation and Adaptation is (Guideline D1., ITC, 2001; Hambleton, 2005):\" Test developers/publishers should ensure that the adaptation process takes full account of linguistic and cultural differences in the intended populations.\" The rationale provided for this guideline is that\" because a single translator cannot be expected to have all of the required qualities and brings a single perspective to the task of translation, in general, it seems clear that a team of specialists is needed to accomplish an accurate adaptation.\"", "num_citations": "19\n", "authors": ["1039"]}
{"title": "Consequences of visual orienting\n", "abstract": " Paper delivered to Conference Psychonomics Society, November Science Foundation Grant# BNS on Atter0. 4on, Seattle, September 1980 and to the 1980. This research was supported by the National 7923527o-233'", "num_citations": "18\n", "authors": ["1039"]}
{"title": "The Hebrew language project: Automated essay scoring & readability analysis\n", "abstract": " Automated essay scoring (AES) systems have been in use for the past two decades and have proven to yield reliable and valid measures of writing ability (Shermis& Burstein, 2003; Ben-Simon & Bennett, 2007). In a typical system, a large number of statistical and natural language processing (NLP) features are extracted from a substantial corpus of student essays. The most useful features are identified by correlating the features with human scores and a scoring model is developed. Almost all AES systems attempt to mimic, as closely as possible, the scores produced by human raters. Yet, since the machine-generated features are all but proxies to the criteria used by human raters to assess writing skills, it is important to establish their relationship to writing characteristics that are grounded in a sound theoretical model.Several commercial essay scoring systems have been developed in the past two decades. The four leading systems are; PEG--Project Essay Grade (page 2003), IntelliMetric (1997), IEA--the Intelligent Essay Assessor (1997), and e-rater\u00ae(1997). All four systems were developed predominantly for the analysis of texts in the English language, though some of them have also been applied to texts in other languages. In such cases, where systems developed in and for a given language are applied to other languages, they typically use statistical (surface) features rather than natural language processing (NLP) features, which are contingent on the specific lexical, morphological syntactic and discourse features of a given language.", "num_citations": "16\n", "authors": ["1039"]}
{"title": "International Assesments: Merits and Pitfalls\n", "abstract": " Forty years have passed since educational achievements were first compared on an international scale. What began as a hesitant and sporadic attempt to compare scholastic achievements in various countries has grown into a well-established enterprise encompassing close to 50 countries worldwide. Perhaps as a function of globalization and increasing awareness of the role human capital plays in furthering economic development, policy makers around the world are expressing growing interest in the results of such surveys, realizing their importance for precipitating educational reform.The quality of international comparisons of educational achievements has improved consistently as experience in the field has accumulated. Nevertheless, policy makers in many countries still fail to interpret the results of cross-national surveys in an accurate and useful manner, partly because they are unaware of the potential influence that diverse methodological factors have on the results of the tests.", "num_citations": "14\n", "authors": ["1039"]}
{"title": "Decision theory approach to the problem of polygraph interrogation\n", "abstract": " To counter the prevailing unsystematic approach to the use of polygraph data, a generalized decision theory approach applicable to a variety of polygraph uses is discussed. Examples of applications of decision theoretic tools to the polygraph interrogation problem are then presented, and typical misuses of the polygraph as a basis for decisions are described. A computed example based on accumulated experimental validity data for 399 Ss was constructed to show how decision analyses should be used in polygraph interrogation. These analyses supplied first approximations for the limits within which a polygraph interrogation system might be used as a sole decision tool. Recommendations for polygraph users are also discussed.(23 ref)(PsycINFO Database Record (c) 2016 APA, all rights reserved)", "num_citations": "12\n", "authors": ["1039"]}
{"title": "Validating human and automated scoring of essays against \u201cTrue\u201d scores\n", "abstract": " In the current study, two pools of 250 essays, all written as a response to the same prompt, were rated by two groups of raters (14 or 15 raters per group), thereby providing an approximation to the essay\u2019s true score. An automated essay scoring (AES) system was trained on the datasets and then scored the essays using a cross-validation scheme. By eliminating one, two, or three raters at a time, and by calculating an estimate of the true scores using the remaining raters, an independent criterion against which to judge the validity of the human raters and that of the AES system, as well as the interrater reliability was produced. The results of the study indicated that the automated scores correlate with human scores to the same degree as human raters correlate with each other. However, the findings regarding the validity of the ratings support a claim that the reliability and validity of AES diverge: although the AES\u00a0\u2026", "num_citations": "10\n", "authors": ["1039"]}
{"title": "Computer based testing (CBT) in the service of test accommodations\n", "abstract": " In the last two decades there has been an increase in the number of university applicants who are diagnosed as learning disabled (LD) and for whom test accommodations on university entrance exams are provided. The most frequent recommendation in the diagnostic reports of LD applicants is to extend the time limits of their tests. In the context of high-stakes testing, this kind of accommodation raises the question of equity: is it fair to extend the time limit of a speeded test to a particular group of examinees? Does it really give the LD a fair chance? And if so, by how much should the time limit be extended? Administering a computer-based version of the test to the LD can largely circumvent these issues.University applicants in Israel were required, until recently, to submit scores on the Psychometric Entrance Test (PET) to universities. This paper discusses the issues associated with test accommodations in general\u00a0\u2026", "num_citations": "7\n", "authors": ["1039"]}
{"title": "Estimating the intra-rater reliability of essay raters\n", "abstract": " The intra-rater reliability in rating essays is usually indexed by the inter-rater correlation. We suggest an alternative method for estimating intra-rater reliability, in the framework of classical test theory, by using the dis-attenuation formula for inter-test correlations. The validity of the method is demonstrated by extensive simulations, and by applying it to an empirical dataset. It is recommended to use this estimation method whenever the emphasis is not on the average intra-reliability of a group of raters, but when the intra-rater reliability of a specific rater is of interest, e.g. when the error-variance component of the scores is of interest in order to estimate true scores.", "num_citations": "6\n", "authors": ["1039"]}
{"title": "Applications of CAT in admissions to higher education in Israel: Twenty-two years of experience\n", "abstract": " The use of CAT in higher education admissions testing in Israel is described. This includes:(1) AMIRAM\u2014a CAT of English as a foreign language that has been used by various institutions of higher education for placement purposes for the past 22 years, and (2) MIFAM\u2014a CAT version of the Psychometric Entrance Test that has been in use for nine years as a higher education admissions tool for examinees with disabilities. Both applications run in parallel with paper-and-pencil test versions. This presentation focuses on the specific procedures used to produce equitable scores across the two media as well as examining the suitability of CAT for examinees with disabilities. Also discussed are a number of practical issues that were encountered during conversion of the Psychometric Entrance Test (PET) to a CAT format. Issues that pertain to the meeting of content specifications, item exposure, item banks, item bank\u00a0\u2026", "num_citations": "6\n", "authors": ["1039"]}
{"title": "Improving the predictive validity of a test: A time-efficient perspective\n", "abstract": " Tests used for college or university admissions normally contain several types of items. After the desired set of item types has been specified, a decision regarding the proportions of the various item types has to be made. This work offers an approach for determining these proportions. The proposed approach is based on maximization of the predictive validity of the total score with respect to success in higher education, under the constraint of the total testing time available. A procedure of searching for the best allocation of the total testing time among the various item types is presented. This procedure makes use of statistical characteristics of the item types, such as reliability, validity, intercorrelations and variance, coupled with data regarding the response latencies for the item types. The proposed procedure can accommodate additional considerations regarding the desired proportions of the item types by\u00a0\u2026", "num_citations": "5\n", "authors": ["1039"]}
{"title": "A revised modified parallel analysis (RMPA) for the construction of unidimensional item pools\n", "abstract": " Modified Parallel Analysis MPA is a heuristic method for assessing approximate unidimensionality of item pools. It compares the second eigenvalue of the observed correlation matrix with the corresponding eigenvalue extracted from a parallel matrix generated by a unidimensional and locally independent model. Revised Modified Parallel Analysis RMPA generalizes MPA and alleviates some of its technical limitations. An important and useful feature is a new method for eliminating items which violate the tests unidimensionality. This is achieved by eliminating items, one at a time to determine their contribution to the matrices eigenvalues. We propose a test for detecting item with larger impact in the observed data set, and eliminating them. The new method was tested in several simulations in which unidimensional item pools were contaminated by various proportions of items from a secondary pool. The results indicate that RMPA does an excellent job in detecting low 10 and moderate 25 levels of contamination, but fails in cases of maximal 50 contamination. Parallel Analysis, Dimensionality, Gapping. Unidimensionality, Item Pools.Descriptors:", "num_citations": "4\n", "authors": ["1039"]}
{"title": "The handbook of cognition and assessment; Frameworks, methodologies, and applications\n", "abstract": " Rich, varied, integrative, multidisciplinary, challenging and innovative; these are some of the adjectives that come to mind after reading The Handbook of Cognition and Assessment, skillfully edited by Andre Rupp and Jacqueline Leighton. The handbook comprises 23 chapters\u2013most of them, 20\u201330 pages long\u2013that map modern models and methods of educational assessment.Irvin Katz begins the foreword to the book by recollecting that in his first year at the ETS, a colleague told him that cognitive psychology is irrelevant to their work (saying something like \u2018I don\u2019t give a hoot about cognitive psychology\u2019). Decades have passed and the psychometric field has changed, permitting Katz to conclude that \u2018... many psychometricians now do give a hoot about cognitive psychology. About friggin\u2019[sic] time!\u2019The handbook attests to this fact, and thus fulfills the call, voiced long ago by Cronbach (1957), to unite two traditions in\u00a0\u2026", "num_citations": "3\n", "authors": ["1039"]}
{"title": "Components of visual orienting\n", "abstract": " A peripheral visual cue produces an orienting of attention that facilitates detection of targets in the cued area. Following a shift of attention away from the cued area, targets at that location are handled less efficiently than at other places. We demonstrate this inhibitory effect, show that it arises from the sensory information present in the cue, and discuss its relationship to shifts in eye position and its functional significance in the process of orienting of attention. We indicate how the inhibitory effect accounts for the difficulty in demonstrating attentional orienting in situations where attended information arises from a single spatial position. We believe that the components of visual orienting provide a model experimental system where impor-tant components of cognitive tasks can be linked to neural systems.", "num_citations": "3\n", "authors": ["1039"]}
{"title": "Consider avoiding the. 05 significance level\n", "abstract": " It is suggested that some shortcomings of Null Hypothesis Significance Testing (NHST), viewed from the perspective of Bayesian statistics, turn benign once the traditional threshold p value of .05 is substituted by a sufficiently smaller value. To illustrate, the posterior probability of H0 stating P=.5, given data that just render it rejected by NHST with a p value of .05 (and a uniform prior), is shown here to be not much smaller than .50 for most values of N below 100 (and even exceeds .50 for N>=100); in contrast, with a p value of .001 posterior probability does not exceed .06 for N<=100 (neither .25 for N<9000). Yet more interesting, posterior probability becomes quite independent of N with a p value of .0001, hence practically satisfying the alpha postulate - set by Cornfield (1966) as the condition for p value being a measure of evidence in itself. In view of the low prospect that most researchers will soon convert to use Bayesian statistics in any form, we thus suggest that researchers who elect the conservative option of resorting to NHST be encouraged to avoid as much as possible using a p value of .05 as a threshold for rejecting H0. The analysis presented here may be used to discuss afresh which level of threshold p value seems to be a reasonable, practical substitute.", "num_citations": "1\n", "authors": ["1039"]}
{"title": "Indices of semantic similarity for automated essay scoring (AES)\n", "abstract": " Content is one of the main writing dimensions on which essays are judged and rated. Since no automated essay scoring (AES) system is capable (yet) of truly understanding the content of an essay and assessing its breadth, depth and relevance, AES systems use indirect methods and proxy indices for judging its quality. Most such indices are based on measures of semantic similarity between a given essay and some gold standard.The purpose of this study is to examine the efficiency (validity) of five computer-generated sematic indices used by NiteRater\u2013an AES system for text analysis and essay scoring of Hebrew texts (NiteRater, 2007). These indices can be classified into three categories:(1) indices based on semantic proximity between essays\u2013the similarity of an essay's vocabulary to that of essays in various score-categories;(2) indices based on Principal Component Analysis (PCA) of semantic similarities\u00a0\u2026", "num_citations": "1\n", "authors": ["1039"]}
{"title": "Testing and cognitive enhancement\n", "abstract": " We are entering a new era. New and improved means of enhancing cognitive abilities are being developed at an ever faster rate. Cognitive enhancement (CE), both short-and long-term, can now be achieved by means of drugs and brain stimulation, in people of all ages. In the near future we may also witness CE through genetic engineering and man-machine coupling.", "num_citations": "1\n", "authors": ["1039"]}
{"title": "Indices of Lexical Diversity for Automated Essay Scoring\n", "abstract": " One of the criteria by which essays are judged and rated is lexical diversity, or richness of vocabulary: the quality, depth and sophistication of the lexicon that the writer employs.", "num_citations": "1\n", "authors": ["1039"]}
{"title": "The Computer as a Silent Partner in Essay Scoring\n", "abstract": " Psychometric measurement based on subjective judgments of performance quality (eg, essay ratings) is, typically, not very reliable. The subjective judgments are often integrated into a single score by means of the following scoring model: Initially, two independent judgments are conducted; then, if the absolute difference between them is not too large, their mean is used as the score. Otherwise, an additional judgment is conducted, and the score is determined by mean of the third judgment and whichever of the original two is closest to it. Whenever the two judgments are sampled from the same distribution, their mean is an unbiased estimate of the true score. However, quite surprisingly, substituting any one of the judgments according to the scoring model described above would result in increased error variance.In some domains, such as the rating of short essays, it is possible to attain a high level of agreement between a human judgment and a mechanical judgment (Automatic Essay Scoring\u2013AES) based on fairly simple considerations. Though it is not common practice to rely absolutely on AES, the aforesaid high level of agreement suggests that a model employing the difference between a mechanically generated score and a score generated by a human judge is worth considering.", "num_citations": "1\n", "authors": ["1039"]}
{"title": "A Manual for\n", "abstract": " MULTICAL is a software package comprising three separate programs for finding the optimal linear calibration of multiple scales. Given data regarding the linear relationship between several score scales, the user can arrive at a set of linear calibration equations which tie the scales together in a consistent manner. This is achieved by defining a\" global\" scale with which all the other score scales are calibrated.The need for a special method to solve the multiple-calibration problem arises in situations where multiple scales can be calibrated pair-wise, but the set of calibrations is not necessarily consistent. For example, suppose that there are three scales: x, y, & z, for which direct (or local) linear calibration functions F, F, and F, can be easily found (read F, to mean: F is a function for transforming scores on scale x to scores on scale y). In many situations the calibration of scalex with scale z using F, is different from the\u00a0\u2026", "num_citations": "1\n", "authors": ["1039"]}
{"title": "Linear Multiple Calibration: The Method and Its Application in Calibrating Essay Reters\n", "abstract": " A new method for the linear calibration of essay raters is presented. The method is based on finding a global scale with which all the raters are calibrated. The search for the global scale is constrained by the observed linear relations between the scales of paired raters. An application of the method to calibrating the ratings given by 24 raters to 3907 essays (two ratings per essay) is explored. The calibration procedure seems to be quite robust. In addition, it is argued that the linear calibration increases the reliability of the ratings and hence their validity. The method might prove useful in contexts other than inter rater calibration.", "num_citations": "1\n", "authors": ["1039"]}