{"title": "Economic perspectives in test automation: balancing automated and manual testing with opportunity cost\n", "abstract": " Testing is a major cost factor in software development. Test automation has been proposed as one solution to reduce these costs. Test automation tools promise to increase the number of tests they run and the frequency at which they run them. So why not automate every test? In this paper we discuss the question\" When should a test be automated?\" and the trade-off between automated and manual testing. We reveal problems in the overly simplistic cost models commonly used to make decisions about automating testing. We introduce an alternative model based on opportunity cost and present influencing factors on the decision of whether or not to invest in test automation. Our aim is to stimulate discussion about these factors as well as their influence on the benefits and costs of automated testing in order to support researchers and practitioners reflecting on proposed automation approaches.", "num_citations": "170\n", "authors": ["230"]}
{"title": "The role of experience in software testing practice\n", "abstract": " Practitioners report that experience plays an important role in effective software testing. We investigate the role of experience in a multiple case study about three successful projects conducted at Siemens Austria and document the state of practice in testing software systems. The studied projects were employed from the domains telecommunications, insurance and banking, as well as safety-critical railway systems. The study shows that test design is to a considerable extent based on experience in all three projects and that experience-based testing is an important supplementary approach to requirements-based testing. The study further analyzes the different sources of experience, the perceived value of experience for testing, and the measures taken to manage and evolve this experience.", "num_citations": "87\n", "authors": ["230"]}
{"title": "Value-based management of software testing\n", "abstract": " Testing is one of the most resource-intensive activities in software development and consumes between 30 and 50% of total development costs according to many studies. Testing is however often not organized to maximize business value and not aligned with a project\u2019s mission. Path, branch, instruction, mutation, scenario, or requirement testing usually treat all aspects of software as equally important, while in practice 80% of the value often comes from 20% of the software. In order to maximize the return of investment gained from software testing, the management of testing needs to maximize its value contribution. In this chapter we motivate the need for value-based testing, describe practices supporting the management of value-based testing, outline a framework for value-based test management, and illustrate the framework with an example.", "num_citations": "85\n", "authors": ["230"]}
{"title": "Grt: Program-analysis-guided random testing (t)\n", "abstract": " We propose Guided Random Testing (GRT), which uses static and dynamic analysis to include information on program types, data, and dependencies in various stages of automated test generation. Static analysis extracts knowledge from the system under test. Test coverage is further improved through state fuzzing and continuous coverage analysis. We evaluated GRT on 32 real-world projects and found that GRT outperforms major peer techniques in terms of code coverage (by 13 %) and mutation score (by 9 %). On the four studied benchmarks of Defects4J, which contain 224 real faults, GRT also shows better fault detection capability than peer techniques, finding 147 faults (66 %). Furthermore, in an in-depth evaluation on the latest versions of ten popular real-world projects, GRT successfully detects over 20 unknown defects that were confirmed by developers.", "num_citations": "66\n", "authors": ["230"]}
{"title": "Opportunities and challenges of static code analysis of IEC 61131-3 programs\n", "abstract": " Static code analysis techniques analyze programs by examining the source code without actually executing them. The main benefits lie in improving software quality by detecting potential defects and problematic code constructs in early development stages. Today, static code analysis is widely used and numerous tools are available for established programming languages like C/C++, Java, C# and others. However, in the domain of PLC programming, static code analysis tools are still rare. In this paper we present an approach and tool support for static code analysis of PLC programs. The paper discusses opportunities static code analysis can offer for PLC programming, it reviews techniques for static analysis, and it describes our tool that implements a rule-based analysis approach for IEC 61131-3 programs.", "num_citations": "51\n", "authors": ["230"]}
{"title": "Static code analysis of IEC 61131-3 programs: Comprehensive tool support and experiences from large-scale industrial application\n", "abstract": " Static code analysis techniques examine programs without actually executing them. The main benefits lie in improving software quality by detecting problematic code constructs and potential defects in early development stages. Today, static code analysis is a widely used quality assurance technique and numerous tools are available for established programming languages like C/C++, Java, or C#. However, in the domain of programmable logic controller (PLC) programming, static code analysis tools are still rare, although many properties of PLC programming languages are beneficial for static analysis techniques. Therefore, an approach and tool for static code analysis of IEC 61131-3 programs has been developed which is capable of detecting a range of issues commonly occurring in PLC programming. The approach employs different analysis methods, like pattern-matching on program structures, control flow\u00a0\u2026", "num_citations": "38\n", "authors": ["230"]}
{"title": "Automated testing in the continuous delivery pipeline: A case study of an online company\n", "abstract": " Companies running an online business need to be able to frequently push new features and bug fixes from development into production. Successful high-performance online companies deliver code changes often several times per day. Their continuous delivery model supports the business needs of the online world. At the same time, however, such practices increase the risk of introducing quality issues and unwanted side effects. Rigorous test automation is therefore a key success factor for continuous delivery. In this paper we describe how automated testing is used in the continuous delivery pipeline of an Austrian online business company. The paper illustrates the complex technical and organizational challenges involved and summarizes the lessons from more than six years of practical experience in establishing and maintaining an effective continuous delivery pipeline.", "num_citations": "37\n", "authors": ["230"]}
{"title": "Random test case generation and manual unit testing: Substitute or complement in retrofitting tests for legacy code?\n", "abstract": " Unit testing of legacy code is often characterized by the goal to find a maximum number of defects with minimal effort. In context of restrictive time frames and limited resources, approaches for generating test cases promise increased defect detection effectiveness. This paper presents the results of an empirical study investigating the effectiveness of (a) manual unit testing conducted by 48 master students within a time limit of 60 minutes and (b) tool-supported random test case generation with Randoop. Both approaches have been applied on a Java collection class library containing 35 seeded defects. With the specific settings, where time and resource restrictions limit the performance of manual unit testing, we found that (1) the number of defects detected by random test case generation is in the range of manual unit testing and, furthermore, (2) the randomly generated test cases detect different defects than manual\u00a0\u2026", "num_citations": "33\n", "authors": ["230"]}
{"title": "A quality-driven approach to web testing\n", "abstract": " The appropriate fulfillment of quality requirements of Web-based systems is essential for the success on the World Wide Web. Thus, in contrast to conventional software testing, where the focus is mainly on functionality, a wide range of quality issues are of utmost importance in testing Web-based systems. In this work, we present a systematic approach to Web testing that takes the importance of quality aspects for Web projects into account. Generally, tests can be characterized in three dimensions: quality, feature, and phase. The combination of these three dimensions results in a scheme that can be used to guide the different steps throughout the test workflow in a methodically sound and systematic way. The application of the scheme in test planning and design is demonstrated for security aspects on a sample Web application.", "num_citations": "32\n", "authors": ["230"]}
{"title": "A framework for defect prediction in specific software project contexts\n", "abstract": " Software defect prediction has drawn the attention of many researchers in empirical software engineering and software maintenance due to its importance in providing quality estimates and to identify the needs for improvement from project management perspective. However, most defect prediction studies seem valid primarily in a particular context and little concern is given on how to find out which prediction model is well suited for a given project context. In this paper we present a framework for conducting software defect prediction as aid for the project manager in the context of a particular project or organization. The framework has been aligned with practitioners\u2019 requirements and is supported by our findings from a systematical literature review on software defect prediction. We provide a guide to the body of existing studies on defect prediction by mapping the results of the systematic literature review to\u00a0\u2026", "num_citations": "30\n", "authors": ["230"]}
{"title": "Application lifecycle management as infrastructure for software process improvement and evolution: Experience and insights from industry\n", "abstract": " Application Lifecycle Management (ALM) is widely promoted by tool vendors and ALM solutions have attracted the attention of many software developing companies. In this paper we describe the introduction of an ALM solution for software development in a large industrial manufacturing company. The introduction is complemented by several small-scale process improvement initiatives. Thereby the ALM solution was turned on itself by using the tool for the tool evaluation, the introduction as well as the process improvement activities. Based on this experience we explore whether the features provided by ALM for software development are also an effective utility for software process management. The paper shows how the ALM solution was applied for process development, process documentation, process implementation and process monitoring. We found that the concepts underlying ALM were suitable to support\u00a0\u2026", "num_citations": "24\n", "authors": ["230"]}
{"title": "How to test the intangible properties of graphical user interfaces?\n", "abstract": " In this paper we describe our experience from developing and testing a visual graphical user interface (GUI) editor for mobile and multimedia devices. Testing of the editor's highly interactive user interface is critical for its success, yet remains a challenge due to the specification of often intangible quality characteristics of the GUI and its proneness to change. The approach we provide is supporting exploratory testing of the GUI with tools integrated with the tested object. Thus a step-by-step guide for manual exploratory testing can be enhanced with automated elements that directly manipulate the status of the editor, access internal properties of the GUI, and record interactions for bug reporting.", "num_citations": "23\n", "authors": ["230"]}
{"title": "Issues and effort in integrating data from heterogeneous software repositories and corporate databases\n", "abstract": " Software repositories and corporate databases capture different fragments of a project's history. Software cockpits integrate the data from these repositories and databases to provide a holistic view of the project and the capability to drill-down and analyze details. By incorporating existing data, the cockpit can be used effectively from the first day it is introduced. In this paper we describe our findings from integrating several repositories and databases for a large, distributed project. We highlight common issues in data integration, report on the resulting effort for the development of software cockpits, and share our lessons learned from this data integration project.", "num_citations": "21\n", "authors": ["230"]}
{"title": "Adapting automated test generation to GUI testing of industry applications\n", "abstract": " ContextAutomated test generation promises to improve the effectiveness of software testing and to reduce the involved manual effort. While automated test generation has been successfully applied for code-level API testing, it has not found widespread adoption in practice for testing of graphical user interfaces. Tools for test generation do not support GUI testing out-of-the-box but require dedicated extensions.ObjectiveThis paper explores the applicability of automated test generation for testing GUIs of industry applications. We propose a test adapter approach to bridge the gap between automated test generation tools and industry applications.MethodA multiple case study was conducted in which automated test generation with test adapters has been applied at the unit, integration, and system test level in three industry projects from two different companies.ResultsAutomated test generation via test adapters could\u00a0\u2026", "num_citations": "19\n", "authors": ["230"]}
{"title": "An empirical study on the application of mutation testing for a safety-critical industrial software system\n", "abstract": " Background: Testing is an essential activity in safety-critical software development, following high standards in terms of code coverage. Mutation testing allows assessing the effectiveness of testing and helps to further improve test cases. However, mutation testing is not widely practiced due to scalability problems when applied to real-world systems. Objective: The objective of the study is to investigate the applicability and usefulness of mutation testing for improving the quality of unit testing in context of safety-critical software systems. Method: A case study has been conducted together with an engineering company developing safety-critical systems. Mutation analysis has been applied to the studied system under test (60,000 LOC of C code) producing 75,043 mutants of which 27,158 survived test execution. A sample of 200 live mutants has been reviewed by the engineers, who also improved the existing unit test\u00a0\u2026", "num_citations": "19\n", "authors": ["230"]}
{"title": "A journey from manual testing to automated test generation in an industry project\n", "abstract": " Test automation is essential in fast-paced agile development environments. The main goal is to speed up test execution cycles and to reduce the effort involved in running tests manually. We took test automation one step further and applied test generation to a GUI-based application developed in a large industry project. The paper describes the transition from manual exploratory testing to automated GUI test generation. Key les-sons to be learned are: (1) the test automation pyramid proposed for agile development tends to underestimate the need for high-level GUI testing, (2) automated test generation does not reduce test effort but shifts it to writing test adapters and checks, and (3) the effort for analyzing results produced by generated tests limits the practical application of automated test generation. The report describes the successful application of test generation in a real-world industry project, but it also\u00a0\u2026", "num_citations": "16\n", "authors": ["230"]}
{"title": "A framework for monkey GUI testing\n", "abstract": " Testing via graphical user interfaces (GUI) is a complex and labor-intensive task. Numerous techniques, tools and frameworks have been proposed for automating GUI testing. In many projects, however, the introduction of automated tests did not reduce the overall effort of testing but shifted it from manual test execution to test script development and maintenance. As a pragmatic solution, random testing approaches (aka \"monkey testing\") have been suggested for automated random exploration of the system under test via the GUI. This paper presents a versatile framework for monkey GUI testing. The framework provides reusable components and a predefined, generic workflow with extension points for developing custom-built test monkeys. It supports tailoring the monkey for a particular application scenario and the technical requirements imposed by the system under test. The paper describes the customization of\u00a0\u2026", "num_citations": "16\n", "authors": ["230"]}
{"title": "Automated testing of industrial automation software: practical receipts and lessons learned\n", "abstract": " The share of software in industrial automation systems is steadily increasing. Thus, software quality issues become a critical concern for many automation projects, which require effective software quality assurance measures. In this paper we describe an architecture for automated testing of software applications part of industrial automation systems. We focus on testing programmable logic controller (PLC) software for machineries, which can be achieved by using test automation frameworks derived from software development. The paper provides a collection of practical receipts describing how different approaches from software engineering best-practices can be applied in the context of industrial automation systems. A combination of these receipts has been used for automating software tests in an industrial automation project. In this project, more than 200 tests have been developed to assure the quality of critical\u00a0\u2026", "num_citations": "15\n", "authors": ["230"]}
{"title": "Points-to analysis of IEC 61131-3 programs: Implementation and application\n", "abstract": " A call graph of a program represents the information which executable program element calls which other executable program elements. Based on the call graph, points-to sets can be computed, which represent the memory locations a reference variable can possibly point to. Call graph and points-to sets provide important information for static program analysis. This is especially true for PLC programs which heavily use pointer variables. However, due to the complexity of the algorithms, call graph and points-to analysis methods are not widely available in static analysis. In this paper, we present an approach for call graph and points-to analysis of IEC 61131-3 programs. We present the algorithm for computing call graph and points-to sets and its implementation in a tool environment, show several different application scenarios, and present first results from industrial application.", "num_citations": "15\n", "authors": ["230"]}
{"title": "A replicated study on random test case generation and manual unit testing: How many bugs do professional developers find?\n", "abstract": " This paper describes the replication of an empirical study comparing tool-supported test case generation and manual development of unit tests. As variation to the original study, which was based on test results from students performing manual unit testing for 60 minutes, the replication involves professional software developers with several years of industry experience and extends the initial time restriction. As part of the replication the paper explores the differences in unit testing by students and professionals and investigates the impact of the extended time limit. The main findings are: There are no significant differences in the results produced by students and by professional developers when performing manual unit testing for 60 minutes. Furthermore, there is a non-linear increase in the number of defects found when the time limit is extended from one to two hours, which indicates the transition from the initial ramp\u00a0\u2026", "num_citations": "15\n", "authors": ["230"]}
{"title": "Key questions in building defect prediction models in practice\n", "abstract": " The information about which modules of a future version of a software system are defect-prone is a valuable planning aid for quality managers and testers. Defect prediction promises to indicate these defect-prone modules. However, constructing effective defect prediction models in an industrial setting involves a number of key questions. In this paper we discuss ten key questions identified in context of establishing defect prediction in a large software development project. Seven consecutive versions of the software system have been used to construct and validate defect prediction models for system test planning. Furthermore, the paper presents initial empirical results from the studied project and, by this means, contributes answers to the identified questions.", "num_citations": "15\n", "authors": ["230"]}
{"title": "Concept, implementation and evaluation of a web-based software cockpit\n", "abstract": " Software cockpits (software project control centers) provide systematic support for monitoring and controlling the activities in a software development project. Important aspects are to track progress, to visualize team performance, and to provide feedback about the quality of delivered results. Therefore, software cockpits integrate and visualize data from various data sources such as project plans, requirement management, version control, as well as test results. Each of these data sources represents a different perspective on the software project. The integrated view provided by a software cockpit produces a complete and persistent picture of the project status. This paper describes the architecture and functionality of a Web-based software cockpit and its implementation with open source software from the Business Intelligence area. Furthermore, the results and lessons learned from evaluating the practical benefits of\u00a0\u2026", "num_citations": "14\n", "authors": ["230"]}
{"title": "Exploring code clones in programmable logic controller software\n", "abstract": " The reuse of code fragments by copying and pasting is widely practiced in software development and results in code clones. Cloning is considered an anti-pattern as it negatively affects program correctness and increases maintenance efforts. Programmable Logic Controller (PLC) software is no exception in the code clone discussion as reuse in development and maintenance is frequently achieved through copy, paste, and modification. Even though the presence of code clones may not necessary be a problem per se, it is important to detect, track and manage clones as the software system evolves. Unfortunately, tool support for clone detection and management is not commonly available for PLC software systems or limited to generic tools with a reduced set of features. In this paper, we investigate code clones in a real-world PLC software system based on IEC 61131-3 Structured Text and C/C++. We extended a\u00a0\u2026", "num_citations": "12\n", "authors": ["230"]}
{"title": "Harnessing automated test case generators for GUI testing in industry\n", "abstract": " Modern graphical user interfaces (GUIs) are highly dynamic and support multi-touch interactions and screen gestures besides conventional inputs via mouse and keyboard. Hence, the flexibility of modern GUIs enables countless usage scenarios and combinations including all kind of interactions. From the viewpoint of testing, this flexibility results in a combinatorial explosion of possible interaction sequences. It dramatically raises the required time and effort involved in GUI testing, which brings manual exploration as well as conventional regression testing approaches to its limits. Automated test generation (ATG) has been proposed as a solution to reduce the effort for manually designing test cases and to speed-up test execution cycles. In this paper we describe how we successfully harnessed a state-of-the-art ATG tool (Randoop) developed for code-based API testing to generate GUI test cases. The key is an\u00a0\u2026", "num_citations": "12\n", "authors": ["230"]}
{"title": "Hybrid monkey testing: enhancing automated GUI tests with random test generation\n", "abstract": " Many software projects maintain automated GUI tests that are repeatedly executed for regression testing. Every test run executes exactly the same fixed sequence of steps confirming that the currently tested version shows precisely the same behavior as the last version. The confirmatory approach implemented by these tests limits their ability to find new defects. We therefore propose to combine existing automated regression tests with random test generation. Random test generation creates a rich variety of test steps that interact with the system under test in new, unexpected ways. Enhancing existing test cases with random test steps allows revealing new, hidden defects with little extra effort. In this paper we describe our implementation of a hybrid approach that enhances existing GUI test cases with additional, randomly generated interactions. We conducted an experiment using a mature, widely-used open source\u00a0\u2026", "num_citations": "11\n", "authors": ["230"]}
{"title": "Automated static analysis of unit test code\n", "abstract": " Automated unit tests are an essential software quality assurance measure that is widely used in practice. In many projects, thus, large volumes of test code have co-evolved with the production code throughout development. Like any other code, test code too may contain faults, affecting the effectiveness, reliability and usefulness of the tests. Furthermore, throughout the software system's ongoing development and maintenance phase, the test code too has to be constantly adapted and maintained. To support detecting problems in test code and improving its quality, we implemented 42 static checks for analyzing JUnit tests. These checks encompass best practices for writing unit tests, common issues observed in using xUnit frameworks, and our experiences collected from several years of providing trainings and reviews of test code for industry and in teaching. The checks can be run using the open source analysis\u00a0\u2026", "num_citations": "11\n", "authors": ["230"]}
{"title": "Software engineering\u2013processes and tools\n", "abstract": " Software engineering traditionally plays an important role among the different research directions located in the Software Park Hagenberg, as it provides the fundamental concepts, methods and tools for producing reliable and high quality software. Software engineering as a quite young profession and engineering discipline is not limited to focus on how to create simple software programs, but in fact introduces a complex and most of the time quite costly lifecycle of software and derived products. Some efforts have been made to define software engineering as a profession and to outline the boundaries of this emerging field of research [PP04, Som04]. Several different definitions of the term software engineering appeared since its first mentioning on a NATO Software Engineering Conference in 1968.", "num_citations": "11\n", "authors": ["230"]}
{"title": "From maintenance to evolutionary development of web applications: A pragmatic approach\n", "abstract": " Development of Web applications is dynamic by its very nature. Web development processes have to facilitate a Web application\u2019s continual refinement and evolution based on feedback from end-users. Evolutionary development can easily be achieved by end-user involvement through seamless integration of feedback and issue reporting mechanisms into Web applications. This paper discusses the use of conventional methods and tools for maintenance and change management as an infrastructure for evolutionary development of Web applications. An example demonstrates the feasibility of the proposed approach. It describes our experience from integrating the open source issue tracking system Bugzilla into a Web application.", "num_citations": "11\n", "authors": ["230"]}
{"title": "Automating test reuse for highly configurable software\n", "abstract": " Dealing with highly configurable systems is generally very complex. Hundreds of different analysis techniques have been conceived to deal with different aspects of configurable systems. One large focal point is the testing of configurable software. This is challenging due to the large number of possible configurations and because tests themselves are rarely configurable and instead built for specific configurations. Existing tests can usually not be reused on other configurations. Therefore, tests need to be adapted for the specific configuration they are supposed to test. In this paper we report on an experiment about reusing tests in a configurable system. We used manually developed tests for specific configurations of Bugzilla and investigated which of them could be reused for other configurations. Moreover, we automatically generated new test variants (by automatically reusing from existing ones) for combinations\u00a0\u2026", "num_citations": "9\n", "authors": ["230"]}
{"title": "Noise in bug report data and the impact on defect prediction results\n", "abstract": " The potential benefits of defect prediction have created widespread interest in research and generated a considerable number of empirical studies. Applications with real-world data revealed a central problem: Real-world data is \"dirty\" and often of poor quality. Noise in bug report data is a particular problem for defect prediction since it effects the correct classification of software modules. Is the module actually defective or not? In this paper we examine different causes of noise encountered when predicting defects in an industrial software system and we provide an overview of commonly reported causes in related work. Furthermore we conduct an experiment to explore the impact of class noise on the predictions performance. The experiment shows that the prediction results for the studied system remain reliable even at a noise level of 20% probability of incorrect links between bug reports and modules.", "num_citations": "9\n", "authors": ["230"]}
{"title": "Reusing automated regression tests for multiple variants of a software product line\n", "abstract": " The high number of possible variants of software product lines raises a considerable practical challenge in testing. In this paper we report our experience with a simple approach that reuses existing automated system tests of a specific product variant to increase the coverage of new variants with little extra effort. The approach has been developed and applied for a software product line in a mechanical engineering company. The existing 300 automated regression tests have been reused on ten new product variants. The results showed that the proposed approach successfully accomplished to increase the test coverage.", "num_citations": "9\n", "authors": ["230"]}
{"title": "Experiences and results from establishing a software cockpit at bmd systemhaus\n", "abstract": " What is the degree of completion of the current iteration? Are we on track? How accurate are estimates compared to actual effort? Software cockpits (software project control centers) provide systematic support for answering such questions. Therefore, like a cockpit in an aircraft, software cockpits integrate and visualize accurate and timely information from various data sources for operative and strategic decision making. Important aspects are to track progress, to visualize team activities, and to provide transparency about the status of a project. In this paper we present our experiences from implementing and introducing a software cockpit in a leading Austrian software development company. The introduction has been supported by a small-scale process improvement and a GM-based measurement initiative. Furthermore, the paper discusses challenges and potential pitfalls in establishing software cockpits and\u00a0\u2026", "num_citations": "9\n", "authors": ["230"]}
{"title": "The impact of product development on the lifecycle of defects\n", "abstract": " This paper investigates the defects of a large embedded software development project over a period of about two years. It describes how software development and product development are organized in parallel branches. By mapping the defects reported on product development branches to the releases on the main line of software development, the paper shows the impact of the product development strategy on the defect lifecycle in software development.", "num_citations": "9\n", "authors": ["230"]}
{"title": "Testing High-Reliability software for continuous casting steel plants-experiences and lessons learned from siemens VAI\n", "abstract": " As the world's leading supplier of metallurgical plants, Siemens VAI provides integrated and universally applicable continuous casting systems for the steel industry. The complexity of the process of casting liquid steel is supported by software products that enable high-quality steel casts and efficient plant performance. Over the last recent years Siemens VAI developed a flexible software product line. The system has been classified as highly reliable, which implies rigorous and systematic testing throughout all phases of the development lifecycle. In this paper we investigate how testing is embedded in the development life- cycle and how various testing methods are applied to ensure high software reliability. The lessons learned distilled from over five years of project experience discuss practices that contributed to the current testing approach.", "num_citations": "9\n", "authors": ["230"]}
{"title": "How to test in sixteen languages? automation support for localization testing\n", "abstract": " Developing for a global market requires the internationalization of software products and their localization to different countries, regions, and cultures. Localization testing verifies that the localized software variants work, look and feel as expected. Localization testing is a perfect candidate for automation. It has a high potential to reduce the manual effort in testing of multiple language variants and to speed-up release cycles. However, localization testing is rarely investigated in scientific work. There are only a few reports on automation approaches for localization testing providing very little empirical results or practical advice. In this paper we describe the approach we applied for automated testing of the different localized variants of a large industrial software system, we report on the various bugs found, and we discuss our experiences and lessons learned.", "num_citations": "8\n", "authors": ["230"]}
{"title": "An Integration-oriented Model for Application Lifecycle Management.\n", "abstract": " In the last years a new trend emerged in the software engineering tool market: Application Lifecycle Management (ALM). ALM aims at integrating processes and tools to coordinate development activities in software engineering. However, a common understanding or widely accepted definition of the term ALM has not yet evolved. Thus, companies introducing ALM are usually confronted with a wide range of solutions following different, vendor-specific interpretations. The aim of this paper is to clarify the concept of ALM and to provide guidance on how to develop an ALM strategy for software development organizations. The paper identifies key problem areas typically addressed by ALM and derives a model to relate the solution concepts of ALM to engineering and management activities. The work has been applied in the context of an improvement project conducted at an industrial company. This case shows how the model can be used to systematically develop a tailored, vendor-independent ALM solution.", "num_citations": "8\n", "authors": ["230"]}
{"title": "The usual suspects: a case study on delivered defects per developer\n", "abstract": " Individual differences of developers in performance and introduced defects have been reported by many research studies and are frequently observed in software development practice. Thus, when the source of defects in the final product is discussed, developers are usually the first under suspicion. However, defects residing in a released software product are the result of defects introduced throughout the sequence of development activities (eg, specification, design, implementation, testing and stabilization) less the defects detected and removed in these activities. This case study explores and describes the difference between developers in terms of associated post-release (ie, delivered) defects. The results are put in relation to the intensity with which a developer's changes and enhancements have been tested to identify a latent influence by pre-release quality assurance measures.", "num_citations": "7\n", "authors": ["230"]}
{"title": "A study of tool support for the evaluation of programming exercises\n", "abstract": " To foster the process of learning to program, theory and exercises are necessary. Traditionally, manual review of the source is used to provide feedback for the solutions. The effort is substantial and identified problems are prone to subjective interpretation. We study static analysis and testing tools as an enhancement to reviews and discuss the benefits. We analyze our findings by comparing the results from analysis by cross-checking the outcomes of the different tools with each other, with the tutors\u2019 remarks, and with the course outcome additionally taking into account final examination results. The effort was substantial and it turned out, that the tools are no replacement for manual review. Tool support is an enhancement due to localization of problem areas, accurate check of programming rules, and an efficient way to detect plagiarism.", "num_citations": "7\n", "authors": ["230"]}
{"title": "Decision support for test management in iterative and evolutionary development\n", "abstract": " Testing resources and time are usually limited, especially by schedules for market-driven products and in fast-paced software development projects. In this paper the author presents his PhD proposal about a framework to support rapid and informed decision-making for test management in the context of iterative and evolutionary development. The objective is to continually focus testing on the value it provides for the project and, thus, enable effective and efficient testing even under uncertainty and schedule pressure", "num_citations": "7\n", "authors": ["230"]}
{"title": "Unit testing beyond a bar in green and red\n", "abstract": " The actual and appealing objective of XP\u2019s approach to unit testing is to improve quality by avoiding errors beforehand rather than to find and fix bugs afterwards. Conventional testing, on the contrary, focuses on a posteriori analysis to find errors and issues that should be corrected. Both approaches have their advantages and drawbacks, and both are valuable and necessary. This paper describes how we combined both approaches by extending our test management environment TEMPPO for unit testing with JUnit to include testers in early unit testing activities.", "num_citations": "7\n", "authors": ["230"]}
{"title": "Testing web quality aspects\n", "abstract": " This report deals with quality aspects in testing Web applications and Web sites. In particular, reasons and arguments for the increased importance of quality aspects are discussed and possible sources of quality aspects as well as their relationship are presented and explained. Finally, a schema for the classification of quality aspects including their associations to tests is proposed. Thereby, this report draws to a large extent from research on quality assurance and, in addition, considers the role that requirements engineering plays.", "num_citations": "7\n", "authors": ["230"]}
{"title": "Applying AI in practice: key challenges and lessons learned\n", "abstract": " The main challenges along with lessons learned from ongoing research in the application of machine learning systems in practice are discussed, taking into account aspects of theoretical foundations, systems engineering, and human-centered AI postulates. The analysis outlines a fundamental theory-practice gap which superimposes the challenges of AI system engineering at the level of data quality assurance, model building, software engineering and deployment.", "num_citations": "6\n", "authors": ["230"]}
{"title": "Applying automated test case generation in industry: a retrospective\n", "abstract": " Automated test case generation promises to reduce the high effort of manually developing and maintaining test cases, to improve the effectiveness of testing, and to speed-up testing cycles. Research on generating test cases has advanced over the past decades and today a wide range of techniques and tools are available, including studies showing their successful evaluation in real-world scenarios. We conducted a multi-firm research project on automated software testing that involved the application of automated test case generation approaches in industry projects. This paper provides a retrospective on the related activities. It reports on our observations and insights from applying automated test case generation in practice, identifies pitfalls and gaps in current research, and summarizes lessons learned from transferring software testing research results to industry.", "num_citations": "6\n", "authors": ["230"]}
{"title": "Value-based coverage measurement in requirements-based testing: Lessons learned from an approach implemented in the tosca testsuite\n", "abstract": " Testing is one of the most widely practiced quality assurance measures and also one of the most resource-intensive activities in software development. Still, however, most of the available methods, techniques and tools for software testing are value-neutral and do not realize the potential value contribution of testing. In this paper we present an approach for value-based coverage measurement that can be used to align the testing effort with the achievable value associated with requirements and functional units. It has been implemented as part of a commercial test tool and was successfully applied in real-world projects. The results demonstrated its ability to adequately capture the distribution of the business value and risks involved in different requirements. The paper concludes with sharing important lessons learned from developing value-based coverage measurement in the practical setting of commercial tool\u00a0\u2026", "num_citations": "6\n", "authors": ["230"]}
{"title": "AI System Engineering\u2014Key Challenges and Lessons Learned\n", "abstract": " The main challenges are discussed together with the lessons learned from past and ongoing research along the development cycle of machine learning systems. This will be done by taking into account intrinsic conditions of nowadays deep learning models, data and software quality issues and human-centered artificial intelligence (AI) postulates, including confidentiality and ethical aspects. The analysis outlines a fundamental theory-practice gap which superimposes the challenges of AI system engineering at the level of data quality assurance, model building, software engineering and deployment. The aim of this paper is to pinpoint research topics to explore approaches to address these challenges. View Full-Text", "num_citations": "5\n", "authors": ["230"]}
{"title": "Improving manual change impact analysis with tool support: A study in an industrial project\n", "abstract": " Change impact analysis is a challenging activity due to the usually huge number of dependencies that have to be considered. Nevertheless it is still often performed manually, relying on expert knowledge and intuition. The aim of this paper is to evaluate the practice of manual change impact analysis and to explore the benefits of tool support in the context of an industrial project. A study has been conducted with experienced developers estimating the changes necessary for implementing bug fixes and feature requests extracted from the project\u2019s history. The results of the manual change impact analysis showed a low estimation performance, which could be improved with tool support to achieve a higher number of hits at the expense of more false positives.", "num_citations": "5\n", "authors": ["230"]}
{"title": "Combinatorial test design in the TOSCA testsuite: lessons learned and practical implications\n", "abstract": " The advantage of combinatorial techniques over less structured approaches is supported by the experience from numerous real-world projects where a significant reduction of the number of test cases has been achieved without compromising functional coverage. However, to fully benefit from combinatorial testing, the applied techniques and tools have to satisfy the requirements and needs of testers and practitioners. In this paper we explore such requirements distilled from testing software systems for over 15 years across a wide range of projects in business and industry. Their practical implications span from mastering the combinatorial explosion over support for fault localization to understandability, changeability and maintainability. Finally, the paper illustrates how the different combinatorial techniques are able to meet these requirements. The combinatorial techniques discussed in this paper are part of the\u00a0\u2026", "num_citations": "5\n", "authors": ["230"]}
{"title": "Issues in testing collection class libraries\n", "abstract": " Collections or containers have become a standard facility used by almost any software application. The availability and widespread use of collection class libraries, the large number of systems depending on them, their algorithmic complexity, as well as their object-oriented design demand an elaborated testing approach. Despite the availability of such testing approaches, many industry projects still rely on unstructured unit testing without particular test criteria applied. In this paper we highlight issues involved in testing collection class libraries and report preliminary results from a pilot study on ad-hoc unit testing of collection classes. We show that a reasonable number of defects can be found in a short period of time that higher coverage does not necessarily lead to a larger number of defects found, and report on three distinct strategies used for writing test cases. Still some questions remain and could be discuss in\u00a0\u2026", "num_citations": "5\n", "authors": ["230"]}
{"title": "What Software Repositories Should Be Mined for Defect Predictors?\n", "abstract": " The information about which modules in a software system's future version are potentially defective is a valuable aid for quality managers and testers. Defect prediction promises to indicate these defect-prone modules. Constructing effective defect prediction models in an industrial setting involves the decision from what data source the defect predictors should be derived. In this paper we compare defect prediction results based on three different data sources of a large industrial software system to answer the question what repositories to mine. In addition, we investigate whether a combination of different data sources improves the prediction results. The findings indicate that predictors derived from static code and design analysis provide slightly yet still significant better results than predictors derived from version control, while a combination of all data sources showed no further improvement.", "num_citations": "5\n", "authors": ["230"]}
{"title": "TestCockpit: business intelligence for test management\n", "abstract": " Up to 50 percent and more of the costs of software projects account for testing activities. Software developed is often under pressure to meet high-quality standards and, at the same time, to deliver in a tight schedule and budget. Under these circumstances it makes sense to ask: How can software testing be made more effective and more efficient? Besides making sure that the test process itself is carried out efficiently by using tools that actively support the testing activities (eg, test case administration tools or bug tracking systems), it is as important to support the activities that determine what, how and to which extent parts of a software system are tested. These activities fall into the scope of test management [3] and involve hard decisions and tradeoffs. Thereby, in a typical software project, test managers are faced with the following situations:\u25aa A typical software project uses a broad variety of different software tools\u00a0\u2026", "num_citations": "5\n", "authors": ["230"]}
{"title": "Enhancing acceptance test-driven development with model-based test generation\n", "abstract": " Acceptance test-driven development is widely used in practice. However, writing and maintaining acceptance tests is a costly and time-consuming activity, in particular when a system is tested via the GUI. In model-based testing, the tests are automatically generated from a model of the system. In this paper, we report our experience from applying a combination of acceptance test-driven development and model-based testing in several real-world projects from industry. With the application of model-based testing, we increased test coverage and extend testing to usage scenarios not exercised by the existing acceptance tests. In the industry projects, MBT was used as an enhancement rather than a replacement for ATDD. By creating a layered test automation architecture, we were able to reuse the established automation for model-based testing and to apply both approaches simultaneously. This strategy also helped\u00a0\u2026", "num_citations": "4\n", "authors": ["230"]}
{"title": "Extracting dependencies from software changes: an industry experience report\n", "abstract": " Retrieving and analyzing information from software repositories and detecting dependencies are important tasks supporting software evolution. Dependency information is used for change impact analysis, defect prediction as well as cohesion and coupling measurement. In this paper we report our experience from extracting dependency information from the change history of a commercial software system. We analyzed the software system's evolution of about six years, from the start of development to the transition to product releases and maintenance. Analyzing the co-evolution of software artifacts allows detecting logical dependencies between system parts implemented with heterogeneous technologies as well as between different types of development artifacts such as source code, data models or documentation. However, the quality of the extracted dependencies relies on established development practices\u00a0\u2026", "num_citations": "4\n", "authors": ["230"]}
{"title": "A retrospection on building a custom tool for automated system testing\n", "abstract": " The numerous commercial and open source test tools available today cover almost any of the features one may ever require for automating tests. However, companies still develop in-house solutions or extend existing tools with custom functionality. In our case, all started with the need to automate tests for a machinery system based on non-standard technologies. In this paper we review the experiences and results from building our own test tool. We discuss the unique advantages of this endeavor and contrast them to the actual effort and costs. We list the involved challenges, the solutions we found, and the issues that remained open. In the end, building our own tool was a success. But would we do it again?", "num_citations": "4\n", "authors": ["230"]}
{"title": "Probabilistic Software Modeling: A Data-driven Paradigm for Software Analysis\n", "abstract": " Software systems are complex, and behavioral comprehension with the increasing amount of AI components challenges traditional testing and maintenance strategies.The lack of tools and methodologies for behavioral software comprehension leaves developers to testing and debugging that work in the boundaries of known scenarios. We present Probabilistic Software Modeling (PSM), a data-driven modeling paradigm for predictive and generative methods in software engineering. PSM analyzes a program and synthesizes a network of probabilistic models that can simulate and quantify the original program's behavior. The approach extracts the type, executable, and property structure of a program and copies its topology. Each model is then optimized towards the observed runtime leading to a network that reflects the system's structure and behavior. The resulting network allows for the full spectrum of statistical inferential analysis with which rich predictive and generative applications can be built. Applications range from the visualization of states, inferential queries, test case generation, and anomaly detection up to the stochastic execution of the modeled system. In this work, we present the modeling methodologies, an empirical study of the runtime behavior of software systems, and a comprehensive study on PSM modeled systems. Results indicate that PSM is a solid foundation for structural and behavioral software comprehension applications.", "num_citations": "3\n", "authors": ["230"]}
{"title": "Process and Tool Support for Internationalization and Localization Testing in Software Product Development\n", "abstract": " Software globalization is an inevitable step for many companies. Developing for a global market requires the internationalization of software products and their localization to different countries, regions, and cultures. Internationalization and localization testing verifies that localized variants of the software product work, look and feel as expected. The highly repetitive task of testing of multiple language variants makes localization testing a perfect candidate for automation with a high potential to reduce the involved human effort and to speed-up release cycles. However, there is surprisingly little support for localization testing by existing test automation tools. Furthermore, there are only few empirical results or practical insights available as the topic is rarely addressed in the scientific literature. In this paper we describe the process and tools applied for automated testing of the different localized variants of a\u00a0\u2026", "num_citations": "3\n", "authors": ["230"]}
{"title": "Practical Challenges in Test Environment Management\n", "abstract": " Test environments are a critical prerequisite for successful test automation. The definition, setup and maintenance of a test environment are a common source for pitfalls and a major cost driver in test automation. This paper describes the practical challenges involved in managing test environments and discusses solutions proposed in the literature and by academic research. The identified challenges involve the four areas classical test management tasks, development and evolution, configuration issues as well as automation for test environments.", "num_citations": "3\n", "authors": ["230"]}
{"title": "Building defect prediction models in practice\n", "abstract": " The information about which modules of a future version of a software system will be defect-prone is a valuable planning aid for quality managers and testers. Defect prediction promises to indicate these defect-prone modules. In this chapter, building a defect prediction model from data is characterized as an instance of a data-mining task, and key questions and consequences arising when establishing defect prediction in a large software development project are discussed. Special emphasis is put on discussions on how to choose a learning algorithm, select features from different data sources, deal with noise and data quality issues, as well as model evaluation for evolving systems. These discussions are accompanied by insights and experiences gained by projects on data mining and defect prediction in the context of large software systems conducted by the authors over the last couple of years. One of these\u00a0\u2026", "num_citations": "3\n", "authors": ["230"]}
{"title": "Improving unfamiliar code with unit tests: an empirical investigation on tool-supported and human-based testing\n", "abstract": " Software testing is a well-established approach in modern software engineering practice to improve software products by systematically introducing unit tests on different levels during software development projects. Nevertheless existing software solutions often suffer from a lack of unit tests which have not been implemented during development because of time restrictions and/or resource limitations. A lack of unit tests can hinder effective and efficient maintenance processes. Introducing unit tests after deployment is a promising approach for (a) enabling systematic and automation-supported tests after deployment and (b) increasing product quality significantly. An important question is whether unit tests should be introduced manually by humans or automatically generated by tools. This paper focuses on an empirical investigation of tool-supported and human-based unit testing in a controlled experiment\u00a0\u2026", "num_citations": "3\n", "authors": ["230"]}
{"title": "Applying heuristic approaches for predicting defect-prone software components\n", "abstract": " Effective and efficient quality assurance has to focus on those parts of a software system that are most likely to fail. Defect prediction promises to indicate the defect-prone components of a software system. In this paper we investigate the viability of predicting defect-prone components in upcoming releases of a large industrial software system. Prediction models constructed with heuristic machine learning are used to classify the components of future versions of the software system as defective or defect-free. It could be shown that the accuracy of the predictions made for the next version is significantly higher (around 74%) than guessing even when taking only new or modified components into account. Furthermore, the results reveal that, depending on the specific prediction model, acceptable accuracy can be achieved for up to three versions in the future.", "num_citations": "3\n", "authors": ["230"]}
{"title": "Encouraging self-organization: reflections on a quality improvement workshop\n", "abstract": " Quality clearly is a team issue and endeavors to improve quality have to capitalize on each individual and each team's unique strengths. Agile software development successfully practices quality improvement by encouraging self-organization within an empowered team. Regular team reflection workshops provide feedback to improve quality and to adapt to new challenges as they arise. In this paper, we reflect on our experiences from a quality improvement workshop in an agile project. We describe the selected approach and discuss the effects of the workshop on the team and its readiness to self-organize.", "num_citations": "3\n", "authors": ["230"]}
{"title": "Automated test reuse for highly configurable software\n", "abstract": " Dealing with highly configurable systems is generally very complex. Researchers and practitioners have conceived hundreds of different analysis techniques to deal with different aspects of configurable systems. One large focal point is the testing of configurable software. This is challenging due to the large number of possible configurations. Moreover, tests themselves are rarely configurable and instead built for specific configurations. However, existing tests need to be adapted to run on a different configuration. In this paper, we report on an experiment about automatically reusing existing tests in configurable systems. We used manually developed tests for specific configurations of three configurable systems and investigated how changing the configuration affects the tests. Subsequently, we employed an approach for automated reuse to generate new test variants (by reusing from existing ones) for combinations\u00a0\u2026", "num_citations": "2\n", "authors": ["230"]}
{"title": "An Architecture for Automated Security Test Case Generation for MQTT Systems\n", "abstract": " Message Queuing Telemetry Transport (MQTT) protocol is among the preferred publish/subscribe protocols used for Machine-to-Machine (M2M) communication and Internet of Things (IoT). Although the MQTT protocol itself is quite simple, the concurrent iteration of brokers and clients and its intrinsic non-determinism, coupled with the diversity of platforms and programming languages in which the protocol is implemented and run, makes the necessary task of security testing challenging. We address precisely this problem by proposing an architecture for security test generation for systems relying on the MQTT protocol. This architecture enables automated test case generation to reveal vulnerabilities and discrepancies between different implementations. As a desired consequence, when implemented, our architectural design can be used to uncover erroneous behaviours that entail latent security risks in MQTT\u00a0\u2026", "num_citations": "2\n", "authors": ["230"]}
{"title": "Automated security test generation for MQTT using attack patterns\n", "abstract": " The dramatic increase of attacks and malicious activities has made security a major concern in the development of interconnected cyber-physical systems and raised the need to address this concern also in testing. The goal of security testing is to discover vulnerabilities in the system under test so that they can be fixed before an attacker finds and abuses them. However, testing for security issues faces the challenge of systematically exploring a potentially non-tractable number of interaction scenarios that have to include also invalid inputs and possible harmful interaction attempts. In this paper, we describe an approach for automated generation of test cases for security testing, which are based on attack patterns. These patterns are blueprints that can be used for exploiting common vulnerabilities. The approach combines random test case generation with attack patterns implemented for the Message Queuing\u00a0\u2026", "num_citations": "2\n", "authors": ["230"]}
{"title": "Live Replay of Screen Videos: Automatically Executing Real Applications as Shown in Recordings\n", "abstract": " Screencasts and videos with screen recordings are becoming an increasingly popular source of information for users to understand and learn about software applications. However, searching for answers to specific questions in screen videos is notoriously difficult due to the effort for locating specific events of interest and reproducing the application's state up to this event. To increase the efficiency when working with screen videos, we propose a solution for replaying recorded sequences shown in videos directly on live applications. In this paper, we describe the analysis of screen videos to automatically identify and extract user interactions and the construction of visual scripts, which are used to run the application in sync with replaying the video. Currently, a first prototype has been developed to demonstrate the technical feasibility of the approach. The paper provides an overview of the implemented solution\u00a0\u2026", "num_citations": "2\n", "authors": ["230"]}
{"title": "Integrating threat modeling and automated test case generation into industrialized software security testing\n", "abstract": " Industrial Internet of Things (IIoT) application provide a whole new set of possibilities to drive efficiency of industrial production forward. However, with the higher degree of integration among systems, comes a plethora of new threats to the latter, as they are not yet designed to be broadly reachable and interoperable. To mitigate these vast amount of new threats, systematic and automated test methods are necessary. This comprehensiveness can be achieved by thorough threat modeling. In order to automate security test, we present an approach to automate the testing process from threat modeling onward, closing the gap between threat modeling and automated test case generation.", "num_citations": "2\n", "authors": ["230"]}
{"title": "Lessons learned from making the transition to model-based GUI testing\n", "abstract": " Model-based testing (MBT) has been proposed as an effective and versatile approach for testing graphical user interfaces (GUIs) by automatically generating executable test cases from a model of the GUI. Model-based GUI testing has received increasing attention in research, but it is still rarely applied in practice. In this paper, we present our experiences and share the lessons we learned from successfully introducing MBT for GUI testing in three industry projects. We describe the underlying modeling approach, the development of tests models in joint workshops, the implementation of the test model in form of model programs, and the integration of MBT in the test automation architecture. The findings distilled from the three cases are summarized as lessons learned to support the adoption of a model-based approach for GUI testing in practice.", "num_citations": "2\n", "authors": ["230"]}
{"title": "GUI scalability issues of windows desktop applications and how to find them\n", "abstract": " Advancements in display technologies have constantly increased the numbers of pixels per inch (DPI) of modern monitors. To avoid that the GUI elements and texts appear crisp and sharp but miniscule and barely readable, operating systems allow scaling up the user interface. Proper scaling also requires applications to adjust to DPI changes correctly. Failures can lead to visual artifacts, distorted and misaligned GUI elements, blurry images, and clipped texts. Such issues are highly visible, irritating, and can considerably decrease productivity. In this paper, we present an approach used for testing the GUI of a large Windows application scaled to different DPI settings. We describe the various scalability issues we observed and the methods we implemented to detect them. We conclude the paper by discussing our insights about how to automate and perform GUI scalability testing.", "num_citations": "2\n", "authors": ["230"]}
{"title": "What You See Is What You Test-Augmenting Software Testing with Computer Vision\n", "abstract": " The blind spot of software testing is the assessment of the actual behavior of the system under test in the real, physical world. In this paper we show how this inherent restriction of software testing to the \"cyber world\" can be overcome with the use of methods and techniques from computer vision. It augments conventional software testing and allows making observations about states and events in the physical world as well as the system's real-world context. We implemented a demonstration scenario that shows how visual test automation can be combined with computer vision techniques to include observations of the physical properties of a mechatronic system in software testing. The successful application of the approach in a lab setting re-vealed several benefits and also some limitations. We discuss these benefits and limitations to highlight potential application scenarios in an industry setting and avenues for\u00a0\u2026", "num_citations": "2\n", "authors": ["230"]}
{"title": "Rule-based detection of process conformance violations in application lifecycle management\n", "abstract": " Software engineering processes are the basis for the development of quality software products within time and within budget. In this paper we present an approach to detect process conformance violations that reveal deviations between planned and executed software engineering processes. The approach is based on process rules that complement the process documentation. A framework for defining, executing and evaluating these rules has been implemented as extension to an Application Lifecycle Management (ALM) solution. The framework has been applied in context of introducing new processes and practices in an industrial environment. Over the timespan of more than a year, process conformance has been continuously evaluated as part of the nightly build. We were able to demonstrate that the results can be used to identify hot spots in process conformance calling for immediate action, to\u00a0\u2026", "num_citations": "2\n", "authors": ["230"]}
{"title": "Requirements and Solutions for Tool Integration in Software Test Automation\n", "abstract": " In this article, we exemplified today's requirements in integrating test automation tools in terms of three integration scenarios combining industrial strength tools in the area of test management, model-based testing and test executionThe article further sketches solutions for the three scenarios by introducing various integration concepts and by discussing their advantages and drawbacks. Based on successful results we propose a framework for test tool integration.", "num_citations": "2\n", "authors": ["230"]}
{"title": "Common Findings and Lessons Learned from Software Architecture and Design Analysis\n", "abstract": " The foundation for any software system is its architecture. It defines the components and the relevant relations among them [1]. Software architecture and design analysis makes the quality of the architecture and design visible and palpable. This paper describes an approach we distilled from software architecture and design analysis in several industrial projects. It summarizes our experience and the lessons learned from analyzing software systems up to two million lines of code. The approach applies static analysis techniques and relies on metrics to identify problem areas.", "num_citations": "2\n", "authors": ["230"]}
{"title": "Exploiting MQTT-SN for Distributed Reflection Denial-of-Service Attacks\n", "abstract": " Distributed Denial-of-Service attacks are a dramatically increasing threat to Internet-based services and connected devices. In the form of reflection attacks they are abusing other systems to perform the actual attack, often with an additional amplification factor. In this work we describe a reflection attack exploiting the industrial Message Queuing Telemetry Transport for Sensor Networks (MQTT-SN) protocol, which theoretically allows to achieve an unlimited amplification rate. This poses a significant risk not only for the organizations which are running a MQTT-SN broker but also for possible targets of such DRDoS attacks. Countermeasures are limited as the underlying weakness is rooted in the specification of MQTT-SN itself.", "num_citations": "1\n", "authors": ["230"]}
{"title": "Why software testing fails: Common pitfalls observed in a critical smart metering project\n", "abstract": " Over the last decades a considerable share of software engineering research has been dedicated to the area of software testing. Still, however, testing often fails or causes major problems in practice. In this paper we present insights and experiences from a large project in the energy sector. The obligatory switch from analog energy meters to smart metering technology poses a big challenge for many energy providers. Apart from technical issues concerning meters and transmission technology, the adaption of the internal business processes together with the development of backend software can turn out to be more difficult than expected. The criticality, size and complexity of the analyzed project are reflected in software and system testing, where the underestimated effort, mistakes, and wrong decisions caused serious difficulties. In our work we describe the observed testing problems and the underlying\u00a0\u2026", "num_citations": "1\n", "authors": ["230"]}
{"title": "Industry-academia collaboration in software testing: An overview of taic part 2017\n", "abstract": " Collaboration between industry and academia in software testing leads to improvement and innovation in industry, and it is the basis for achieving transferable and empirically evaluated results. Thus, the aim of TAIC PART is to forge collaboration between industry and academia on the challenging and exciting problem of real-world software testing. The workshop is promoted by representatives of both industry and academia, bringing together industrial software engineers and testers with researchers working on theory and practice of software testing. We present an overview of the 12th Workshop on Testing: Academia-Industry Collaboration, Practice and Research Techniques (TAIC PART 2017) and its contributions.", "num_citations": "1\n", "authors": ["230"]}
{"title": "Guiding random test generation with program analysis.\n", "abstract": " Random test generation is effective in creating method sequences for exercising the software under test. However, black-box approaches for random testing are known to suffer from low code coverage and limited defect detection ability. Analyzing the software under test and using the extracted knowledge to guide test generation can help to overcome these limitations. We developed a random test case generator augmented by a combination of six static and dynamic program analysis techniques. Our tool GRT (Guided Random Testing) has been evaluated on realworld software systems as well as Defects4J benchmarks. It outperformed related approaches in terms of code coverage, mutation score and detected faults. The results show a considerable improvement potential of random test generation when combined with advanced analysis techniques.", "num_citations": "1\n", "authors": ["230"]}
{"title": "Tool Support for Reuse-Driven Elicitation and Specification of User Requirements\n", "abstract": " Reuse is a promising approach meet the constantly increasing demand for prompt solutions and high-quality implementations. Systematic reuse has to start in requirements elicitation and specification. This paper presents an approach emphasizing the direct involvement of end users and domain experts. It is based on tool support promoting requirements reuse as a way for users to easily match their needs with the specifications of existing solutions. The approach has been implemented as an extension to a Web-based requirements management tool. It received positive feedback from professional requirements engineers and users, indicating following benefits: (1) Reduced time and effort for requirements engineering, (2) improved quality of specifications, and (3) better mapping to approved solutions.", "num_citations": "1\n", "authors": ["230"]}
{"title": "A business view on testing ERP systems with value-based requirements coverage\n", "abstract": " Testing has been identified as a critical factor for a successful implementation of ERP systems. However, most testing activities are still value-neutral and do not utilize the information about the system\u2019s achievable business value, which is a particularly promising improvement for testing of business software and ERP systems. In this paper we therefore present an approach for value-based coverage measurement that can be used to align the testing effort to the value associated with requirements and typical usage scenarios. It has been implemented as part of the commercial test tool TOSCA Testsuite by Tricentis and was successfully applied in real-world projects. The results demonstrated its ability to adequately capture the distribution of the business value involved in different functional units. Furthermore, when compared with a value-neutral and a pure requirements-based approach for test case\u00a0\u2026", "num_citations": "1\n", "authors": ["230"]}
{"title": "Applicability and benefits of mutation analysis as an aid for unit testing\n", "abstract": " Unit testing is a highly popular and widely practiced measure for assuring software quality. Nevertheless, writing good unit tests requires experience in test design and in applying the testing frameworks. Hence, existing unit test suites often suffer from issues that limit their defect detection capability or that impact the understandability and maintainability of the implemented tests. Several methods and techniques have been proposed to aid the developer in creating good unit tests. Mutation analysis is one of the most promising techniques to assess the quality of a test suite. Over the last years it has caught increasing attention by researchers and practitioners and a variety of tools have been developed to support this technique. In this work, mutation analysis is studied for its practical applicability and the potential benefits in providing guidance for unit testing. Five mutation analysis tools are investigated on four test\u00a0\u2026", "num_citations": "1\n", "authors": ["230"]}
{"title": "Observing Distributions in Size Metrics: Experience from Analyzing Large Software Systems\n", "abstract": " In this paper we observe and compare distributions of popular size metric values from the analysis of different software systems as well as from different consecutive versions of one software system. The typically heavy-tailed distributions are visualized and discussed with the help of Pareto diagrams. We found that the distributions remain remarkable stable over time, support the identification of problem areas by statistical and relative threshold-based filtering, and show the ability to reveal the fundamental characteristics of a software system.", "num_citations": "1\n", "authors": ["230"]}