{"title": "Active database systems\n", "abstract": " Active database systems support mechanisms that enable them to respond automatically to events that are taking place either inside or outside the database system itself. Considerable effort has been directed towards improving understanding of such systems in recent years, and many different proposals have been made and applications suggested. This high level of activity has not yielded a single agreed-upon standard approach to the integration of active functionality with conventional database systems, but has led to improved understanding of active behavior description languages, execution models, and architectures. This survey presents the fundamental characteristics of active database systems, describes a collection of representative systems within a common framework, considers  the consequences for implementations of certain design decisions, and discusses tools for developing active applications.", "num_citations": "882\n", "authors": ["1513"]}
{"title": "Rule Management in Object Oriented Databases: A Uniform Approach.\n", "abstract": " Rules have been proposed for providing active be-haviour in DBMS. Previous attempts to add rules to Object Oriented DBs have often resulted in a dichotomy between rules and other kind of objects. Bere a uniform approach is presented, in which rules are described and handled in the same way as any other object in the system, without any additional mechanisms being introduced. Thus rules can be related to other objects or arranged in hierarchies, and rules can even be defined which are triggered by methods attached to rules themselves. Since rules and classes are both objects, a relationship between these two kinds of objects can be used to provide a class-based index for rules. In this way, the search for applicable rules is considerably reduced. An early implementation and several examples are shown in ADAM, an Object Oriented DB in PROLOG.", "num_citations": "261\n", "authors": ["1513"]}
{"title": "A model-driven development for GWT-based rich internet applications with OOH4RIA\n", "abstract": " Traditionally, Web applications have had great limitations in the usability and interactivity of their user interfaces. To overcome these limitations, a new type of Web applications called rich Internet applications (RIAs) has recently appeared providing richer and more efficient graphical components similar to desktop applications. However, RIAs are rather complex and their development requires the designing and implementation tasks which are time-consuming and error-prone. Moreover, RIA development is a new challenge for the Web engineering methodologies requiring their modification and the introduction of other concerns. In this context, we propose a new approach called OOH4RIA which proposes a model-driven development process that extends OOH methodology. It introduces new structural and behavioural models in order to represent a complete RIA and to apply transformations that reduce the effort\u00a0\u2026", "num_citations": "168\n", "authors": ["1513"]}
{"title": "Dimensions of active behaviour\n", "abstract": " This paper introduces a number of dimensions of active rule system behaviour which can be used both to highlight differences between proposals for active rule systems, and to identify the requirements of different applications. These dimensions relate to the structure, execution model and management of active rules, and enable the concise expression of what facilities a system supports and what features an application requires.", "num_citations": "116\n", "authors": ["1513"]}
{"title": "Using health chatbots for behavior change: a mapping study\n", "abstract": " This study conducts a mapping study to survey the landscape of health chatbots along three research questions: What illnesses are chatbots tackling? What patient competences are chatbots aimed at? Which chatbot technical enablers are of most interest in the health domain? We identify 30 articles related to health chatbots from 2014 to 2018. We analyze the selected articles qualitatively and extract a triplet <technicalEnablers, competence, illness> for each of them. This data serves to provide a first overview of chatbot-mediated behavior change on the health domain. Main insights include: nutritional disorders and neurological disorders as the main illness areas being tackled; \u201caffect\u201d as the human competence most pursued by chatbots to attain change behavior; and \u201cpersonalization\u201d and \u201cconsumability\u201d as the most appreciated technical enablers. On the other hand, main limitations include lack of\u00a0\u2026", "num_citations": "85\n", "authors": ["1513"]}
{"title": "Model transformation co-evolution: A semi-automatic approach\n", "abstract": " Model transformations are precious and effortful outcomes of Model-Driven Engineering. As any other artifact, transformations are also subject to evolution forces. Not only are they affected by changes to transformation requirements, but also by the changes to the associated metamodels. Manual co-evolution of transformations after these metamodel changes is cumbersome and error-prone. In this setting, this paper introduces a semi-automatic process for the co-evolution of transformations after metamodel evolution. The process is divided in two main stages: at the detection stage, the changes to the metamodel are detected and classified, while the required actions for each type of change are performed at the co-evolution stage. The contributions of this paper include the automatic co-evolution of breaking and resolvable changes and the assistance to the transformation developer to aid in the co-evolution\u00a0\u2026", "num_citations": "83\n", "authors": ["1513"]}
{"title": "Advanced database technology and design\n", "abstract": " 6.7 Design Issues: Capturing the Essence of the Object-Relational Paradigm 201 6.8 An Object-Relational Example 203", "num_citations": "74\n", "authors": ["1513"]}
{"title": "EXACT: an extensible approach to active object-oriented databases\n", "abstract": " Active database management systems (DBMSs) are a fast-growing area of research, mainly due to the large number of applications which can benefit from this active dimension. These applications are far from being homogeneous, requiring different kinds of functionalities. However, most of the active DBMSs described in the literature only provide a fixed, hard-wired execution model to support the active dimension. In object-oriented DBMSs, event-condition-action rules have been propo sed for providing active behaviour. This paper presents EXACT, a rule manager for object-oriented DBMSs which provides a variety of options from which the designer can choose the one that best fits the semantics of the concept to be supported by rules. Due to the difficulty of foreseeing future requirements, special attention has been paid to making rule management easily extensible, so that the user can tailor it to suit\u00a0\u2026", "num_citations": "69\n", "authors": ["1513"]}
{"title": "Architectural and technological variability in rich internet applications\n", "abstract": " The advent of rich Internet applications (RIAs) has evolved into an authentic technological revolution, providing Web information systems with advanced requirements similar to desktop applications. At the same time, RIAs have multiplied the possible architectural and technological options, complicating development and increasing risks. The real challenge is selecting the right alternatives among the existing RIA variability, thus creating an optimal solution to satisfy most user requirements. To face this challenge, the authors' extended the OOH4RIA approach to generative RIA development, which introduces architectural and technological aspects at the design phase and provides a closer match between the modeled system and the final implementation.", "num_citations": "68\n", "authors": ["1513"]}
{"title": "DEAR: a DEbugger for Active Rules in an object-oriented context\n", "abstract": " Experience using active rules in database systems has shown that, while such rules can be utilised beneficially in a range of applications, it is not a straightforward task to implement, debug or maintain large rule bases. It is thus important for active rule systems to provide debugging and explanation facilities for two reasons: to inform the user which active rules have been fired during the execution of an operation thereby increasing the user\u2019s confidence and understanding of the system, and to help the designer to refine and analyze interactions among rules at, execution time. The idiosyncrasies of the rule\u2019s flow of control, where the rules to be fired cannot be known in advance, introduce some requirements different from those found in debuggers for conventional programming languages. This paper presents an approach to the design and implementation of a debugger for active rules in an object-oriented\u00a0\u2026", "num_citations": "65\n", "authors": ["1513"]}
{"title": "The augmented web: rationales, opportunities, and challenges on browser-side transcoding\n", "abstract": " Today\u2019s web personalization technologies use approaches like user categorization, configuration, and customization but do not fully support individualized requirements. As a significant portion of our social and working interactions are migrating to the web, we can expect an increase in these kinds of minority requirements. Browser-side transcoding holds the promise of facilitating this aim by opening personalization to third parties through web augmentation (WA), realized in terms of extensions and userscripts. WA is to the web what augmented reality is to the physical world: to layer relevant content/layout/navigation over the existing web to improve the user experience. From this perspective, WA is not as powerful as web personalization since its scope is limited to the surface of the web. However, it permits this surface to be tuned by developers other than the sites\u2019 webmasters. This opens up the web to third\u00a0\u2026", "num_citations": "55\n", "authors": ["1513"]}
{"title": "Combining active rules and metaclasses for enhanced extensibility in object-oriented systems\n", "abstract": " This paper is concerned with techniques for supporting extensibility in object-oriented data models. It has been recognised for a number of years that, in systems which support metaclasses as first-class objects, extensibility can be achieved by using specialisation to refine built-in object creation behaviour. At the same time, research into active rules has indicated the utility of mapping high-level descriptions of functionality onto active rules for evaluation. This paper proposes the integration of these two techniques, arguing that certain constructs which would be difficult to represent using either one alone can be supported effectively by a judicious mixing of the two.", "num_citations": "40\n", "authors": ["1513"]}
{"title": "Facing interaction-rich rias: The orchestration model\n", "abstract": " Promptness, efficiency and stickiness are among the advantages exhibited by the new crop of rich Internet applications (RIAs). These advantages came at the cost of increasing the complexity of development. Additionally, the plethora of RIA frameworks can lock this code into a specific platform. This scenario advises for using model-driven development (MDD). This paper focuses on interactionrich RIAs by addressing two issues: (1) interaction dependencies among widgets, and (2) grouping of widgets into Ajax pages. These concerns are captured in the Orchestration Model. MDD wise, OO-H metamodels accounts for the PIMs whereas Google Web Toolkit is the selected PSM. During transformation, a \"message broker\" pattern is introduced to decouple widgets from their dependencies. When Ajax pages are generated, heuristics are introduced to find a balance between communication overhead, presentation\u00a0\u2026", "num_citations": "37\n", "authors": ["1513"]}
{"title": "Improving portlet interoperability through deep annotation\n", "abstract": " Portlets (ie multi-step, user-facing applications to be syndicated within a portal) are currently supported by most portal frameworks. However, there is not yet a definitive answer to portlet interoperation whereby data flows smoothly from one portlet to a neighbouring one. Both data-based and API-based approaches exhibit some drawbacks in either the limitation of the sharing scope or the standardization effort required. We argue that these limitations can be overcome by using deep annotation techniques. By providing additional markup about the background services, deep annotation strives to interact with these underlying services rather than with the HTML surface that conveys the markup. In this way, the portlet producer can extend a portlet markup, a fragment, with data about the processes whose rendering this fragment supports. Then, the portlet consumer (eg a portal) can use deep annotation to map an output\u00a0\u2026", "num_citations": "36\n", "authors": ["1513"]}
{"title": "User acceptance testing for Agile-developed web-based applications: Empowering customers through wikis and mind maps\n", "abstract": " User Acceptance Testing (UAT) involves validating software in a real setting by the intended audience. The aim is not so much to check the defined requirements but to ensure that the software satisfies the customer\u2019s needs. Agile methodologies put stringent demands on UAT, if only for the frequency at which it needs to be conducted due to the iterative development of small product releases. In this setting, traditional in-person meetings might not scale up well. Complementary ways are needed to reduce the costs of developer-customer collaboration during UAT. This work introduces a wiki-based approach where customers and developers asynchronously collaborate: developers set the UAT scaffolding that will later shepherd customers when testing. To facilitate understanding, mind maps are used to represent UAT sessions. To facilitate engagement, a popular mind map editor, FreeMind, is turned into an editor\u00a0\u2026", "num_citations": "35\n", "authors": ["1513"]}
{"title": "A language for end-user web augmentation: Caring for producers and consumers alike\n", "abstract": " Web augmentation is to the Web what augmented reality is to the physical world: layering relevant content/layout/navigation over the existing Web to customize the user experience. This is achieved through JavaScript (JS) using browser weavers (e.g., Greasemonkey). To date, over 43 million of downloads of Greasemonkey scripts ground the vitality of this movement. However, Web augmentation is hindered by being programming intensive and prone to malware. This prevents end-users from participating as both producers and consumers of scripts: producers need to know JS, consumers need to trust JS. This article aims at promoting end-user participation in both roles. The vision is for end-users to prosume (the act of simultaneously caring for producing and consuming) scripts as easily as they currently prosume their pictures or videos. Encouraging production requires more \u201cnatural\u201d and abstract constructs\u00a0\u2026", "num_citations": "34\n", "authors": ["1513"]}
{"title": "Supporting dynamic displays using active rules\n", "abstract": " In a graphical interface which is used to display database objects, dynamic displays are updated automatically as modifications occur to the database objects being visualised. Approaches based on enlarging either the database system or the interface code to provide the appropriate communication, complicates the interaction between the two systems, as well as making later updates cumbersome. In this paper, an approach based on active rules is presented. The declarative and modular description of active rules enables active displays to be supported with minimal changes to the database or its graphical interface. Although this approach has been used to support the link between a database system and its graphical interface, it can easily be adapted to support dynamic interaction between an active database system and other external systems.", "num_citations": "34\n", "authors": ["1513"]}
{"title": "Requirement-driven evolution in software product lines: A systematic mapping study\n", "abstract": " CONTEXT. Software Product Lines (SPLs) aim to support the development of a whole family of software products through systematic reuse of shared assets. As SPLs exhibit a long life-span, evolution is an even greater concern than for single-systems. For the purpose of this work, evolution refers to the adaptation of the SPL as a result of changing requirements. Hence, evolution is triggered by requirement changes, and not by bug fixing or refactoring.OBJECTIVE. Research on SPL evolution has not been previously mapped. This work provides a mapping study along Petersen\u2019s and Kichenham\u2019s guidelines, to identify strong areas of knowledge, trends and gaps.RESULTS. We identified 107 relevant contributions. They were classified according to four facets: evolution activity (e.g., identify, analyze and plan, implement), product-derivation approach (e.g., annotation-based, composition-based), research type (e.g\u00a0\u2026", "num_citations": "32\n", "authors": ["1513"]}
{"title": "Chatbot dimensions that matter: Lessons from the trenches\n", "abstract": " Chatbots are becoming pervasive. From health assistance to cooking advisers, a myriad of chatbots are out there to help you in a broad range of activities. Natural Language capabilities have received a lot of coverage as one of the most distinctive and enabling features of this revolution. Nevertheless, other less glittering dimensions might well also play a major role on chatbots\u2019 success. This paper reports on the experience of three chatbots development. Here, unsophisticated script-based conversational capabilities are provided but the focus was on other four dimensions: interaction, integration, testing and analytics. The paper reports on the activities, arranged along these four dimensions. Our final aim is to bring to the forefront the concern for those dimensions as also main enablers of chatbot success.", "num_citations": "30\n", "authors": ["1513"]}
{"title": "Harvesting models from web 2.0 databases\n", "abstract": " Data rather than functionality are the sources of competitive advantage for Web2.0 applications such as wikis, blogs and social networking websites. This valuable information might need to be capitalized by third-party applications or be subject to migration or data analysis. Model-Driven Engineering (MDE) can be used for these purposes. However, MDE first requires obtaining models from the wiki/blog/website database (a.k.a. model harvesting). This can be achieved through SQL scripts embedded in a program. However, this approach leads to laborious code that exposes the iterations and table joins that serve to build the model. By contrast, a Domain-Specific Language (DSL) can hide these \u201chow\u201d concerns, leaving the designer to focus on the \u201cwhat\u201d, i.e. the mapping of database schemas to model classes. This paper introduces Schemol, a DSL tailored for extracting models out of databases which\u00a0\u2026", "num_citations": "30\n", "authors": ["1513"]}
{"title": "Turning web applications into portlets: Raising the issues\n", "abstract": " A portal is a key component of an enterprise integration strategy. It provides integration at the user interface level, whereas other integration technologies support business process, functional or data integration. To this end, portlet syndication is the next wave following the successful use of content syndication in current portals. A portlet is a full-fledge application, which is rendered within the portal framework. Over the last few years, organisations have invested in Web - enabling some of their existing systems, and they can be interested in capitalising on these Web applications by wrapping them as portlets so that they can be plugged into third-party portals. Differences between Web applications and portlets basically stem from the distinct running settings and the targeted end-users of each type of software. This paper explores the repercussion of these differences and raises the issues when \"portlet-ising\" an\u00a0\u2026", "num_citations": "30\n", "authors": ["1513"]}
{"title": "Extending ODBMSs using metaclasses\n", "abstract": " Metaclasses let database designers extend Adam, an object-oriented database-management system, at the model level. Designers and programmers can use objects to describe and extend the behavior of the database itself, without the coding involved in changing the application system. In this article, the authors extend Adam to handle constraints and relationships.< >", "num_citations": "29\n", "authors": ["1513"]}
{"title": "A quality analysis of facebook messenger's most popular chatbots\n", "abstract": " This work introduces a set of quality attributes for chatbots. The selection is grounded on scholarly but also reputed blog references from 2016 and 2017. In addition, attributes should be amenable to be extracted (semi) automatically. On these premises, we consider four attributes:\" support of a minimal set of common commands\",\" foresee language variations in both inputs and ouput\",\" human-assistance provision\" and\" timeliness\". These attributes are worked out for the 100 most popular chatbots in Facebook Messager. The aim is to look for correlations between these attributes and chatbot popularity in terms of number of\" likes\". Results show that there is no significance correlation with any of the attributes. However, the experiment come up with two main insights. First, the lack of common communication paterns that would permit users to move their experiences and expectations from one chatbot to another\u00a0\u2026", "num_citations": "26\n", "authors": ["1513"]}
{"title": "Tuning GitHub for SPL development: branching models & repository operations for product engineers\n", "abstract": " SPLs distinguish between domain engineering (DE) and application engineering (AE). Though each realm has its own lifecycle, they might need to be regularly synchronized to avoid SPL erosion during evolution. This introduces two sync paths: update propagation (from DE to AE) and feedback propagation (from AE to DE). This work looks at how to support sync paths in Version Control Systems (VCSs) using traditional VCS constructs (ie merge, branch, fork and pull). In this way, synchronization mismatches can be resolved \u00e0 la VCS, ie highlighting difference between distinct versions of the same artifact. However, this results in a conceptual gap between how propagations are conceived (ie update, feedback) and how propagation are realized (ie merge, branch, etc). To close this gap, we propose to enhance existing VCSs with SPL sync paths as first-class operations. As a proof-of-concept, we use Web\u00a0\u2026", "num_citations": "26\n", "authors": ["1513"]}
{"title": "Improving a portlet usability model\n", "abstract": " Second-generation portals are far from being monolithic pieces of software. Their complexity calls for a component-based approach where portlets are the technical enabler. That being the case nowadays portals tend to be constructed by means of portlets, i.e. a multi-step, user-facing application to be delivered through a Web application. The proposal for and ample support given to the WSRP (Web Services for Remote Portlets) portlet standard predict an emerging portlet market. A main requirement for the blossoming of this market is the existence of portlet quality models that assist portal developers to select the appropriate portlet. This paper focuses on usability. The aim, therefore, is to develop a usability model for portlets. The paper presents such a model and its realisation for a sample case.", "num_citations": "25\n", "authors": ["1513"]}
{"title": "Deriving active rules for constraint maintenance in an object-oriented database\n", "abstract": " This paper presents a framework for translating constraints, declaratively stated by the user, into event-condition-action rules. Constraints are specified using a constraint equation approach and they are defined as a property of the attributes. A set of rules are generated based on the Horn logic counterpart of constraint equations. Being in an object-oriented context, the description of the event modifying a constraint not only includes the name of the method but also the name of the class. This idiosyncrasy of the object-oriented paradigm account for many of the differences with how this problem has been tackled in deductive databases and relational databases. Examples are shown of an early implementation in ADAM, an object-oriented database in Prolog.", "num_citations": "25\n", "authors": ["1513"]}
{"title": "Promoting business policies in object-oriented methods\n", "abstract": " Business policies have been proposed to bridge the gap between business and information system professionals, and at the same time, for easing system evolution. So far, however, most approaches to business policies have been biased towards providing a structural perspective. Here, we argue that there is much to be gained from moving the business-policy idea to a behavioral setting such as the one used in most object-oriented methods. This paper proposes a division of behavioral domain features into two orthogonal dimensions depending on the stability of these features: the event dimension which mainly corresponds to state-transition diagrams that are rarely changed, and the policy dimension which describes restrictions and dependencies among elements on the event dimension that routinely evolve with time. This explicit and separate description of business policies allows the changing of these\u00a0\u2026", "num_citations": "24\n", "authors": ["1513"]}
{"title": "Wiki Scaffolding: Aligning wikis with the corporate strategy\n", "abstract": " Wikis are main exponents of collaborative development by user communities. This community may be created around the wiki itself (e.g., community of contributors in Wikipedia) or already exist (e.g., company employees in corporate wikis). In the latter case, the wiki is not created in a vacuum but as part of the information ecosystem of the hosting organization. As any other Information System resource, wiki success highly depends on the interplay of technology, work practice and the organization. Thus, wiki contributions should be framed along the concerns already in use in the hosting organization in terms of glossaries, schedules, policies, organigrams and the like. The question is then, how can corporate strategies permeate wiki construction while preserving wiki openness and accessibility? We advocate for the use of \u201cWiki Scaffoldings\u201d, i.e., a wiki installation that is provided at the onset to mimic these corporate\u00a0\u2026", "num_citations": "23\n", "authors": ["1513"]}
{"title": "Understanding web augmentation\n", "abstract": " Introduction               The increasing volume of content and actions on the web, combined with the growing number of \u201cdigital natives\u201d, anticipate a growing desire of more sophisticated ways of controlling the Web experience. Webies 2.0 do no longer take the web as it is but imagine fancy ways of customizing the web for their own purposes. So far, mashups are the forerunner exponent of this tendency where consumers (companies and laymen alike) come up with new applications by synergistically combining third-party resources. This presentation moves the focus to another approach: \u201cWeb Augmentation\u201d (WA). Rather than creating a new application, WA builds on top of the rendering of an existing website. In some sense, WA is to the Web what Augmented Reality is to the physical world: layering relevant content/layout/navigation over the existing Web to customize the user experience. Unlike mashups, the\u00a0\u2026", "num_citations": "23\n", "authors": ["1513"]}
{"title": "Providing personalized mashups within the context of existing web applications\n", "abstract": " There is an increasing tendency for Web applications to open their data silos and make them available through APIs and RSS-based mechanisms. This permits third parties to tap on those resources, combining them in innovative ways to conform the so-called mashup applications. So far, most of the approaches strive to facilitate the user to create bright new mashup applications which are regarded as stand-alone applications. However, the fact that these applications are data driven suggests that the mashup data is frequently used to achieve higher-order goals. Frequently, you are gathering data not just for the sake of the data itself but to help taking some decisions. Some of these decisions are conducted through Web applications. In this scenario, it would be most convenient to post the mashup data by the application where the decision is taken. To this end, the term \u201cmashup personalization\u201d is coined to\u00a0\u2026", "num_citations": "22\n", "authors": ["1513"]}
{"title": "End-user browser-side modification of web pages\n", "abstract": " The increasing volume of content and actions available on the Web, combined with the growing number of mature digital natives, anticipate a growing desire of controlling the Web experience. Akin to the Web2.0 movement, webies\u2019 desires do not stop at content authoring but look for controlling how content is arranged in websites. By content, we mainly refer to HTML pages, better said, their runtime representation: DOM trees. The vision is for users to \u201cprune\u201d (removing nodes) or \u201cgraft\u201d (adding nodes) existing DOM trees to improve their idiosyncratic and situational Web experience. Hence, Web content is no longer consumed as canned by Web masters. Rather, users can remove content of no interest, or place new content from somewhere else. This vision accounts for a post-production user-driven Web customization (referred to as \u201cWeb Modding\u201d). Being user driven, appropriate abstractions and tools are\u00a0\u2026", "num_citations": "21\n", "authors": ["1513"]}
{"title": "Interfaces for scripting: Making greasemonkey scripts resilient to website upgrades\n", "abstract": " Thousands of users are streamlining their Web interactions through user scripts using special weavers such as Greasemonkey. Thousands of programmers are releasing their scripts in public repositories. Millions of downloads prove the success of this approach. So far, most scripts are just a few lines long. Although the amateurism of this community can partially explain this fact, it can also stem from the doubt about whether larger efforts will pay off. The fact that scripts directly access page structure makes scripts fragile to page upgrades. This brings the nightmare of maintenance, even more daunting considering the leisure-driven characteristic of this community. On these grounds, this work introduces interfaces for scripting. Akin to the JavaScript programming model, Scripting Interfaces are event-based, but rather than being defined in terms of low-level, user-interface events, Scripting Interfaces abstract\u00a0\u2026", "num_citations": "21\n", "authors": ["1513"]}
{"title": "Towards federated web2. 0 sites: The tagmas approach\n", "abstract": " The success of Web2. 0 is draining user\u2019s resources from the desktop to the Web. An increasing number of users are keeping their pictures at flickr, their bookmarks at del. icio. us, their documents at googleDocs and so on. There are important advantages to be gained, but this dissemination of user\u2019s resources should go handby-hand with tooling that permits users to keep a global view of their resources regardless of where they are kept. Unfortunately, heterogeneity on API\u2019s, tag conventions and message protocols hinders interoperability. Consequently, this work promotes a looselycoupled federated view of Web2. 0 sites which powers traditional desktops with tagging and searching capabilities that expand over the desktop folders to transparently account for Web2. 0 sites. This federation is achieved in a user basis: the Web2. 0 sites to be integrated are those that keep resources of the user at hand. The paper introduces the current status of TAGMAS, a TAG MAnagement System that provides an interface to deal with multiple, autonomous Web2. 0 sites from the desktop.", "num_citations": "20\n", "authors": ["1513"]}
{"title": "Measuring triggering-interaction complexity on active databases\n", "abstract": " Distinct software metrics have been proposed for programs. By contrast, metrics for databases have been neglected on the grounds that databases were mere plain files that do not affect considerably information systems maintainability. However, later enhancements on database systems have considerable increase the complexity of the elements kept within the database realm. Such complexity makes metrics a valuable tool to understand, monitor, control, predict and improve software development and maintenance database projects. Triggers are a case in point. Several reports warned about the difficulties to cope with large sets of triggers. Based on the difficulty to ascertain the causes that make a given rule to be triggered, this paper proposes three different metrics for measuring trigger complexity, namely, the triggering potential, the number of anchors and the distance of a trigger. These measures are\u00a0\u2026", "num_citations": "20\n", "authors": ["1513"]}
{"title": "Effect of NO2 and NO3-/HNO3 adsorption on NO photocatalytic conversion\n", "abstract": " A study was undertaken of the adsorption and photocatalytic conversion of NO, NO2 and NO3\u2212/HNO3 using two photocatalysts (P25 and HT-ET). The HT-ET is a catalyst synthesized in our laboratory comprised only of anatase phase and with a surface area three times larger than that of the P25. In powder form, the catalyst was introduced into and extended along the length of a tube with no type of compaction on the part of the solid (pressure drops are negligible under these conditions). This tubular photoreactor arrangement operates as a continuous reactor system enabling FTIR analysis of the surface of the catalysts during the conversion process. NO adsorption was negligible, though the FTIR studies revealed the formation of nitrites on the surface after 18\u2009h of reaction. Overall NO conversion efficiency rates were above 68% with both catalysts in that reaction time. However, selectivity to NO2 was very high\u00a0\u2026", "num_citations": "19\n", "authors": ["1513"]}
{"title": "Generating blogs out of product catalogues: An MDE approach\n", "abstract": " Blogs can be used as a conduit for customer opinions and, in so doing, building communities around products. We attempt to realise this vision by building blogs out of product catalogues. Unfortunately, the immaturity of blog engines makes this endeavour risky. This paper presents a model-driven approach to face this drawback. This implies the introduction of (meta)models: the catalogue model, based on the standard Open Catalog Format, and blog models, that elaborate on the use of blogs as conduits for virtual communities. Blog models end up being realised through blog engines. Specifically, we focus on two types of engines: a hosted blog platform and a standalone blog platform, both in Blojsom. However, the lack of standards in a broad and constantly evolving blog-engine space, hinders both the portability and the maintainability of the solution. Hence, we resort to the notion of \u201cabstract platform\u201d as a way\u00a0\u2026", "num_citations": "19\n", "authors": ["1513"]}
{"title": "Generalizing the\" like\" button: empowering websites with monitoring capabilities\n", "abstract": " Increasingly, a user's action in a website might have an impact in other websites. The Like and ShareThis buttons are forerunners of this tendency whereby websites strive to influence and be influenced by the actions of their users in the websphere. The term Web Radar is coined to denote software that serves to impact a website (the host) from what is happening somewhere else in the websphere (ie the target). Current approaches provided limited expressivity in either the reactions (eg the Like button is limited to write entries on the user's wall in Facebook), or the range of participating sites (pre-set in the Radar platform, eg Ifttt). We believe supporting Radars as configurable services might account for more domain-specific Radars, ie Radars where the monitoring sites, the tracking conditions and the reactions are not fixed by the Radar platform but rather determined by the Radar host. This vision is confronted with\u00a0\u2026", "num_citations": "18\n", "authors": ["1513"]}
{"title": "Sharing behaviour in an object-oriented database using a rule-based mechanism\n", "abstract": " Sharing Behaviour in an Object-Oriented Database using a Rule-Based Mechanism | Research Explorer | The University of Manchester The University of Manchester Menu Search the University of Manchester site Search Search text Search type Research Explorer Website Staff directory Alternatively, use our A\u2013Z index Home Study Undergraduate Undergraduate Courses Prospectus (undergraduate) Offer-holders Undergraduate Teaching and learning Expanding your study (undergraduate) After you graduate (undergraduate) Undergraduate Applications Undergraduate Student finance Webinars (undergraduate) Contextual admissions Mature students Parents and supporters Contact us (undergraduate) Taught master's Why study a master's? Why Manchester? (taught master's) Taught master's Courses Teaching and learning (taught master's) After you graduate (taught master's) Postgraduate prospectus (taught \u2026", "num_citations": "18\n", "authors": ["1513"]}
{"title": "Layman tuning of websites: facing change resilience\n", "abstract": " Client scripting permits end users to customize content, layout or style of their favourite websites. But current scripting suffers from a tight coupling with the website. If the page changes, all the scripting can fall apart. The problem is that websites are reckoned to evolve frequently, and this can jeopardize all the scripting efforts. To avoid this situation, this work enriches websites with a\" modding interface\" in an attempt to decouple layman's script from website upgrades. From the website viewpoint, this interface ensures safe scripting, ie scripts that do not break the page. From a scripter perspective, this interface limits tuning but increases change resilience. The approach tries to find a balance between openness (scripter free inspection) and modularity (scripter isolation from website design decisions) that permits scripting to scale up as a mature software practice. The approach is realized for Greasemonkey scripts.", "num_citations": "17\n", "authors": ["1513"]}
{"title": "Metaclasses in object-oriented databases\n", "abstract": " Metaclasses in Object-Oriented Databases | Research Explorer | The University of Manchester The University of Manchester Menu Search the University of Manchester site Search Search text Search type Research Explorer Website Staff directory Alternatively, use our A\u2013Z index Home Study Undergraduate Undergraduate Courses Prospectus (undergraduate) Offer-holders Undergraduate Teaching and learning Expanding your study (undergraduate) After you graduate (undergraduate) Undergraduate Applications Undergraduate Student finance Webinars (undergraduate) Contextual admissions Mature students Parents and supporters Contact us (undergraduate) Taught master's Why study a master's? Why Manchester? (taught master's) Taught master's Courses Teaching and learning (taught master's) After you graduate (taught master's) Postgraduate prospectus (taught master's) Admissions process (taught \u2026", "num_citations": "16\n", "authors": ["1513"]}
{"title": "Crowdsourced web augmentation: A security model\n", "abstract": " Web augmentation alters the rendering of existing Web applications at the back of these applications. Changing the layout, adding/removing content or providing additional hyperlinks/widgets are examples of Web augmentation that account for a more personalized user experience. Crowdsourced Web augmentation considers end users not only the beneficiaries but also the contributors of augmentation scripts. The fundamental problem with so augmented Web applications is that code from numerous and possibly untrusted users are placed into the same security domain, hence, raising security and integrity concerns. Current solutions either coexist with the danger (e.g. Greasemonkey, where scripts work on the same security domain that the hosting application) or limit augmentation possibilities (e.g. virtual iframes in Google\u2019s Caja, where the widget is prevented from accessing the application space\u00a0\u2026", "num_citations": "15\n", "authors": ["1513"]}
{"title": "Generating active rules from high-level specifications\n", "abstract": " Rules have been proposed as a mechanism for providing active behaviour in databases; some of the most popular uses being the support of integrity constraints, the maintenance of materialised views and security enforcement. However, the difficulty of defining rules discourages end users from taking full advantage of their functionality. What is required is a mechanism for the automatic translation of high-level specifications of behaviour into equivalent sets of rules. In addition to making rules easier and safer to use, such a facility makes the specification of behaviour explicit \u2014 rather than having it embedded within rule code \u2014 and allows it to be used by other parts of the database management system. For example, if constraints are specified declaratively, they can be used for other purposes such as semantic query optimisation. This paper describes how rules can be generated automatically from\u00a0\u2026", "num_citations": "15\n", "authors": ["1513"]}
{"title": "Web augmentation as a promising technology for end user development\n", "abstract": " This chapter presents Web Augmentation (WA) technologies as tools and techniques for end-user development. WA technologies differ from other web development technologies as they target at improving existing Web pages and not at creating new Web sites. These improvements can deeply alter the way users use and interact with Web sites. This chapter revisits the concept of WA and provides an overview of the main features that characterize WA technologies. This characterization is used to position and compare the various contributions that have been made in WA. To make things more concrete we provide an illustration of WA technology through a case study using a dedicated tool called WebMakeup. Despite all their advantages, WA technologies present some limitations that might result in challenges on the user side. These aspects are also presented and discussed, highlighting directions for future\u00a0\u2026", "num_citations": "14\n", "authors": ["1513"]}
{"title": "Using DITA for documenting software product lines\n", "abstract": " Aligning the software process and the documentation process is a recipe for having both software and documentation in synchrony where changes in software seamlessly ripple along its documentation counterpart. This paper focuses on documentation for Software Product Lines (SPLs). A SPL is not intended to build one application, but a number of them: a product family. In contrast to single-software product development, SPL development is based on the idea that the distinct products of the family share a significant amount of assets. This forces a change in the software process. Likewise, software documentation development should now mimic their code counterpart: product documentation should also be produced out of a common set of assets. Specifically, the paper shows how DITA process and documents are recasted using a feature-oriented approach, a realization mechanism for SPLs. In so doing\u00a0\u2026", "num_citations": "14\n", "authors": ["1513"]}
{"title": "Portlet syndication: Raising variability concerns\n", "abstract": " A Portlet is a multistep, user-facing application delivered through a Web application (e.g., a portal). OASIS approved standard, WSRP, is an attempt to standardize the interface between the provider and the consumer of the Portlet. This initiative promotes Portlet interoperability, componentware practices, and the existence of a Portlet market. This work argues that the diversity of the settings where a Portlet might be syndicated recommends that Portlets be instrumented for variability, and this, in turn, demands a product-line approach. This work introduces a new source of variability, the \u201cinteraction lifecycle\u201d, a description of the visible flow of a Portlet, and shows how this feature can be adapted to cater to the idiosyncrasies of the hosting application. Distinct variants are identified that permit the consumer to customize the presentation, content, and links of the Portlet markup in a controlled way. The use of product-line\u00a0\u2026", "num_citations": "14\n", "authors": ["1513"]}
{"title": "DRANs: Resilient disaster recovery access networks\n", "abstract": " Wireless access network is an appropriate solution to provide Internet connection to users in disasters where communication infrastructures might completely be damaged. However, existing researches commonly focus on separate issues, given strong requisite assumptions. Basically, those assumptions could not be satisfied in harsh environments like in disasters. In addition, a combination of those separate research aspects into an integrated system has not been discussed. This paper thoroughly analyzes current states of existing wireless access network technologies by which suitable solutions for resilient disaster recovery access networks (DRANs) are proposed. Moreover, a novel wireless multihop access network virtualization (WMANV) approach to resilient DRANs is proposed. The feasibility of the proposed approach is verified using experimental evaluations.", "num_citations": "12\n", "authors": ["1513"]}
{"title": "The operational semantics of user-defined relationships in object oriented database systems\n", "abstract": " In semantic data models, abstract relationship (e.g. generalization, aggregation, etc.) semantics are defined, specifying how insertion, deletion and modification operations made at a higher level of abstraction can affect the objects abstracted over and vice versa. These semantics, also known as structural constraints, are expressed through so-called update rules. This perspective has been somewhat lost in most object-oriented systems, where user-defined relationships are supported as simple pointers and their semantics are embedded, distributed and replicated within the operations accessing these pointers. This paper inherits and extends the treatment of relationships found in semantic data models to behavioural object-oriented models by presenting an approach to uniformly capture the update rules for user-defined relationships. The stress is not on supporting relationships as first-class objects, but on\u00a0\u2026", "num_citations": "12\n", "authors": ["1513"]}
{"title": "Addressing web locator fragility: a case for browser extensions\n", "abstract": " Web locators uniquely identify elements on the Web Content. They are heavily used in different scenarios, from Web harvesting to Web testing and browser extensions. Locators' Achilles heel is their fragility upon Website upgrades. This work tackles locator fragility in the context of browser extensions. We introduce regenerative locator, ie traditional structure-based locators which are supplemented with contingency data from the target node. The aim: keeping browser extensions up and running for as long as possible. Eight case studies are analysed by considering real Website upgrades taken from Wayback Machine. Figures indicate a 70% success in regenerating broken locators without interrupting extension functioning.", "num_citations": "11\n", "authors": ["1513"]}
{"title": "Web mashups with WebMakeup\n", "abstract": " Modding refers to the act of modifying hardware, software, or virtually anything else, to perform a function not originally conceived or intended by the designer. The rationales for modding should be sought in the aspiration of users to contextualize to their own situation the artefact at hand. Websites are not exception. WebMakeup targets mod scenarios where web pages are turned into canvases users can tune to account for their situational, idiosyncratic, and potentially, short-lived needs. By clicking, users turn DOM nodes into widgets. Widgets can next be rearranged, deleted, updated or stored for later reuse in other pages. In addition, widgets can be involved in \u201cblink\u201d patterns where interactions with a widget might affect the related widgets. This empowers users to tune not only what but also when content is to show up in an AJAX-like way. WebMakeup is publicly available as a Chrome extension.", "num_citations": "11\n", "authors": ["1513"]}
{"title": "Wiki refactoring as mind map reshaping\n", "abstract": " Wikis\u2019 organic growth inevitably leads to wiki degradation and the need for regular wiki refactoring. So far, wiki refactoring is a manual, time-consuming and error-prone activity. We strive to ease wiki refactoring by using mind maps as a graphical representation of the wiki structure, and mind map manipulations as a way to express refactoring. This paper (i) defines the semantics of common refactoring operations based on Wikipedia best practices, (ii) advocates for the use of mind maps as a visualization of wikis for refactoring, and (iii) introduces a DSL for wiki refactoring built on top of FreeMind, a mind mapping tool. Thus, wikis are depicted as FreeMind maps, and map manipulations are interpreted as refactoring operations over the wiki. The rationales for the use of a DSL are based not only on reliability grounds but also on facilitating end-user participation.", "num_citations": "11\n", "authors": ["1513"]}
{"title": "An automatic approach to displaying web applications as portlets\n", "abstract": " Wrapping existing Web applications into portals allows to protect investment and improves user experience. Most current portlet-based portal servers provide a bridge portlet that allows to \u201cportletize\u201d a single Web page, that is, wrapping the whole page or a set of regions as a portlet. They use an annotation-based approach to specifying the page\u2019s regions that must be extracted. This approach does not scale well when a whole application is to be portletized, since it requires to manually annotate each page. This paper describes the design of a bridge portlet that automatically adapts pages according to the space available in the portlet\u2019s window. The bridge portlet delegates page adaptation to a framework that uses a chain of user-configurable \u201ctransformers\u201d. Each transformer implements an automatic page adaptation technique. Experiments show that our approach is effective.", "num_citations": "11\n", "authors": ["1513"]}
{"title": "Invoking web applications from portals: Customisation implications\n", "abstract": " Customisation sits at the core of current portal technology. So does content syndication as well as the most recent, application syndication whereby external applications can be integrated into the portal realm through the use of Portlet technology. However, these applications do not always exhibit the sophisticated customisation mechanisms available within a portal. This leads to a discontinuity in the user experience when accessing an external application being syndicated within a portal. This work introduces the notion of bridge Portlet as a proxy to an external Web application. This Portlet is responsible for customising the external application to the portal environment, supplementing it with commodities such as single sign on, profiles and the like. The paper illustrates how to improve the adaptation of the external application through a bookmarking module enhancement. Now, portal users can enjoy\u00a0\u2026", "num_citations": "11\n", "authors": ["1513"]}
{"title": "Sticklet: An end-user client-side augmentation-based mashup tool\n", "abstract": " A critical aspect of mashup tools for end users is to come up with an intuitive metaphor. Sticklet is an augmentation-based mashup tool that conceives websites as walls where you can fix HTML fragments (sticky notes) from other websites. Notes are contextualized to the hosting website, i.e. location, parameter passing and layout should be harmonized to those of the website. A set of declarative constructs are available to declaratively specify complex sticky notes. Sticklet is realized as an internal DSL in JavaScript that capitalizes on browser weavers (e.g. Greasemonkey (GM)). Being full-fledged GM scripts, Sticklet benefits from the sharing repositories (e.g. www.userscripts.org) or management utilities (e.g. activation, installation, edition) available for GM.", "num_citations": "10\n", "authors": ["1513"]}
{"title": "Wiki scaffolding: helping organizations to set up wikis\n", "abstract": " Organizational wikis are framed by an existing organization. This makes these wikis be especially vigilant upon (1) facilitating the alignment of the wiki with organizational practices,(2) engaging management or (3), promoting employees' participation. To this end, we advocate for the use of\" wiki scaffoldings\". A wiki scaffolding is a wiki installation that is provided at the onset, before any contribution is made. It aims to frame wiki contribution along the concerns already known in the hosting organization in terms of glossaries, schedules, organigrams and the like. Thus, wiki contributions do not start from scratch but within a known setting. This paper introduces a language to capture wiki scaffolding in terms of FreeMind's mind maps. These maps can later be mapped into wiki installations in MediaWiki. The paper seeks to validate the approach in a twofold manner. Firstly, by providing literature quotes that suggest the\u00a0\u2026", "num_citations": "10\n", "authors": ["1513"]}
{"title": "a DSL for corporate wiki initialization\n", "abstract": " Some wikis support virtual communities that are built around the wiki itself (e.g., Wikipedia). By contrast, corporate wikis are not created in a vacuum since the community already exists. Documentation, organigrams, etc are all there by the time the wiki is created. The wiki should then be tuned to the existing information ecosystem. That is, wiki concerns (e.g., categories, permissions) are to be influenced by the corporate settings. So far, \u201call wikis are created equal\u201d: empty. This paper advocates for corporate wikis to be initialized with a \u201cwiki scaffolding\u201d: a wiki installation where some categories, permissions, etc, are initialized to mimic the corporate settings. Such scaffolding is specified in terms of a Domain Specific Language (DSL). The DSL engine is then able to turn the DSL expression into a Media Wiki installation which is ready to be populated but now, along the company settings. The DSL is provided as\u00a0\u2026", "num_citations": "10\n", "authors": ["1513"]}
{"title": "RESTful, resource-oriented architectures: a model-driven approach\n", "abstract": " RESTful Web services have opened the door to clients to use Web sites in ways the original designers never imagined giving rise to the mashup phenomenon. The main advantage of the model based approach in Web engineering is that the models specify sort of contract the Web application adheres to and promises to deliver. Similarly, in RESTful scenario, mashup components responsible for delivering composite functionalities out of RESTful components could benefit from such contracts in search, automatic mashup, and other scenarios. Such scenarios ground the need for taking RESTful Web services in existing Web methods. This paper proposes the Application Facade Component Model in existing Web methods to support RESTful, resource-oriented architectures generation. Amazon Simple Storage Service is used as the running example and proof of concept to show advantages of such approach.", "num_citations": "10\n", "authors": ["1513"]}
{"title": "Blogouse: Turning the Mouse into a Copy&Blog Device\n", "abstract": " Blogs are tools that put web publication into the layman\u2019s hands. Despite its simplicity, the publication process is a cumbersome task when the content to be published is already in desktop documents. In order to ease this process, we have created Blogouse, a user-friendly, editor-independent, and blog-independent publication tool, which applies annotation techniques to the publication system. To attain this aim, we have extended the mouse device functionality to be ontology-aware.", "num_citations": "10\n", "authors": ["1513"]}
{"title": "Opening personalization to partners: An architecture of participation for websites\n", "abstract": " Open innovation and collaborative development are attracting considerable attention as new software construction models. Traditionally, website code is a \u201cwall garden\u201d hidden from partners. In the other extreme, you can move to open source where the entirety of the code is disclosed. A middle way is to expose just those parts where collaboration might report the highest benefits. Personalization can be one of those parts. Partners might be better positioned to foresee new ways to adapt/extend your website based on their own resources and knowledge of their customer base. We coin the term \u201cOpen Personalization\u201d to refer to those practises and architectures that permit partners to inject their own personalization rules. We identify four main requirements for OP architectures, namely, resilience (i.e. partner rules should be sheltered from website upgrades, and vice versa), affordability (easy contribution\u00a0\u2026", "num_citations": "9\n", "authors": ["1513"]}
{"title": "Providing resilient xpaths for external adaptation engines\n", "abstract": " Approaches to Web application adaptation can be classified based on whether the application is aware of the adaptation or not. In the latter case, adaptation is referred to as external. External adaptation requires the use of addressing patterns that locate the target portion/data on the application pages to be adapted. Unfortunately, changes on the application normally also require updates to the addressing patterns. This raises pattern robustness as a main concern. This papers focuses on the (semi) automatic generation of change-resilience XPath patterns. Two different categories of changes are addressed, ie in space (eg, different personalizations of a page) and in time (eg, site upgrades), by exploiting two different techniques: induction and simulated annealing. These techniques permit to obtain XPath patterns\" resilient-enough\" to a\" controlled set of page designs\". SiSy, a tool that assists the user in obtaining\u00a0\u2026", "num_citations": "9\n", "authors": ["1513"]}
{"title": "Web Engineering\n", "abstract": " Over the last few years Web Engineering has begun to gain mainstream acceptance within the software engineering, IT and related disciplines. In particular, both researchers and practitioners are increasingly recognizing the unique characteristics of Web systems, and what these characteristics imply in terms of the approaches we take to Web systems development and deployment in practice. A scan of the publications in related conference proceedings and journals highlights the diversity of the discipline areas which contribute to both the richness and the complexity of Web Engineering. The 5th International Conference on Web Engineering (ICWE 2005), held in Sydney, Australia, extends the traditions established by the earlier conferences in the series: ICWE2004 in Munich, Germany; ICWE2003 in Oviedo, Spain; ICWE 2002 in Santa Fe, Argentina; and ICWE 2001 in C\u00e1ceres, Spain. Not only have these\u00a0\u2026", "num_citations": "9\n", "authors": ["1513"]}
{"title": "Metrics for active database maintainability\n", "abstract": " Databases are becoming more complex and it is necessary to measure schemata complexity in order understand, monitor, control, predict and improve software development and maintenance projects. Active databases are a case in point where several reports warned the difficulties to cope with large rule sets. This paper proposes three different metrics for measuring active databases complexity, based on the difficulty to ascertain the causes that make a given rule to be triggered. The measurement theory is used to characterise these metrics.", "num_citations": "9\n", "authors": ["1513"]}
{"title": "Tool support\n", "abstract": " Despite the broad range of applications that can benefit from active database systems, current practice shows that the availability of active mechanisms in most commercial database systems is no guarantee that they will be used. This is partly due to the lack of sophisticated tools to assist in the process of designing, debugging, and administrating large rule sets. This chapter reports advances achieved so far, and identifies areas where enhancements are required.", "num_citations": "9\n", "authors": ["1513"]}
{"title": "Formalizing and validating behavioral models through the event calculus\n", "abstract": " Accurate gathering of requirements is a major concern during conceptual modelling. Such accurateness can only be achieved through major involvement of users, who should check whether the system's specification conforms with their expectations. This task can be facilitated both by intuitive conceptual constructs and by executable models that allow interaction with the user to explain the behavior of the system in accordance with its specification. This work proposes the notions of stimuli and business policies as intuitive behavioral constructs, and the use of the event calculus as an appropriate formalism for building executable specifications for behavioral models. The approach is borne out by an early implementation that allows the user to question why and how a given state is reached, where the answer is given in terms of the specifications, i.e. stimuli and policies, being applied. The utilization of use-cases as\u00a0\u2026", "num_citations": "9\n", "authors": ["1513"]}
{"title": "Object-oriented systems: a cross-discipline overview\n", "abstract": " The object-oriented paradigm is characterized in a general sense by a grouping of information with the concept or entity to which it relates. Corresponding to this rather vague definition, there is a wide range of systems that can be classified as object-oriented. However, such systems may provide significantly different perspectives on the structure and manipulation of objects. This stems principally from the different motivations underlying the distinct fields from which object-oriented systems have emerged, such as Data Bases, Artificial Intelligence and Programming Languages. As a result, a myriad of systems have appeared in which diverse terminology is used. For example, are terms such as class, frame, term, actor and entity synonyms, related notions, or descriptions of distinct concepts? How is an object different from these terms? This paper proposes a classification of object-oriented systems based upon the\u00a0\u2026", "num_citations": "9\n", "authors": ["1513"]}
{"title": "Object-oriented databases and frame-based systems: comparison\n", "abstract": " Research into knowledge representation within the artificial intelligence (AI) community has led to the development of AI tools that use frames to structure knowledge. Concurrent research in databases has led to the development of semantic data models and object-oriented databases. These two types of system seem to have much in common \u2014 they are structurally object-oriented, support inheritance, and store programs with the objects to which they relate. What then are the differences between frame systems and object-oriented databases? The paper compares a frame system called CRL with an object-oriented database called ADAM to identify common ground and differences between the systems and the philosophies underlying them. What emerges from the comparison is that while the systems have many superficial similarities, the different rationales that led to their development have resulted in significant\u00a0\u2026", "num_citations": "9\n", "authors": ["1513"]}
{"title": "Tagging-Aware Portlets\n", "abstract": " A corporate portal supports a community of users on cohesively managing a shared set of resources. Such management should also include social tagging, i.e. the practice of collaboratively creating and managing tags to annotate and categorize content. This task involves to know both what to tag (hence, the rendering of the resource content) and how to tag (i.e. the tagging functionality itself). Traditionally both efforts are accomplished by the same application (Flickr is a case in point). However, portals decouple these endeavours. Tagging functionality is up to the portal, but content rendering can be outsourced to third-party applications: the portlets. Portlets are Web applications that transparently render their markup through a portal. The portal is a mere conduit for the portlet markup, being unaware of what this markup conveys. This work addresses how to make portlets tagging-aware, i.e. portlets that can\u00a0\u2026", "num_citations": "8\n", "authors": ["1513"]}
{"title": "Toward the semantic desktop: The semouse approach\n", "abstract": " Modern computers have enjoyed increasing storage capacity, but the mechanisms that harness this storage power haven't improved proportionally. Whether current desktops have scaled to handle the enormous number of files computers must handle compared to just a few years ago is doubtful at best. Scalability includes not only fault tolerance or performance stability of tools for users to harness this power. The lack of appropriate structures and tools for locating, navigating, relating, and sharing bulky file sets is preventing users from harnessing their PCs' full storage power. Powering desktops with metadata, leading to the semantic desktop, is a promising way to realize this potential. The seMouse approach realizes the promising vision of the semantic desktop. This approach provides seamless integration between file-centered tooling and semantically aware, resource-centered applications.", "num_citations": "8\n", "authors": ["1513"]}
{"title": "New approaches to portletization of web applications\n", "abstract": " Portlets are interactive Web mini-applications that can be plugged into a portal. This chapter focuses on \u201cportletizing\u201d existing Web applications, that is, wrapping them as portlets, without requiring any modification. After providing some background on portlet technology, we discuss two kinds of approaches to portletization: automatic and annotation-based. Automatic approaches make use of heuristics to automatically choose the fragments of the Web application pages to be displayed into the space available in the portlet\u2019s window. In turn, in annotation-based approaches, it is the portal administrator who annotates each page of the portletized Web application to specify which fragments should be displayed. Annotation-based approaches also allow to supplement the functionality of the original Web application. Each approach is explained by using a sample scenario based on the same Web application. We also\u00a0\u2026", "num_citations": "8\n", "authors": ["1513"]}
{"title": "Reactive behaviour support: Themes and variations\n", "abstract": " Unlike previous behaviour models, reactive behaviour description includes not only what to execute but also when to execute it. Programming languages, database systems and graphical user interfaces are being enhanced to provide explicit support for reactive behaviour due to the large range of application which naturally express their semantics using this paradigm. This paper presents a common framework in which current alternatives to reactive behaviour support in objectoriented systems can be placed and compared. This framework imposes some clasification features, that suggest some new approaches for the reactive behaviour support.", "num_citations": "8\n", "authors": ["1513"]}
{"title": "Refactoring affordances in corporate wikis: a case for the use of mind maps\n", "abstract": " The organisation of corporate wikis tends to deteriorate as time goes by. Rearranging categories, structuring articles and even moving sections among articles are cumbersome tasks in current wiki engines. This discourages the layman. But, it is the layman who writes the articles, knows the wiki content and detects refactoring opportunities. Our goal is to improve the refactoring affordances of current wiki engines by providing an alternative front-end tuned to refactoring. This is achieved by (1) surfacing the structure of the wiki corpus as a mind map, and (2) conducting refactoring as mind map reshaping. To this end, we introduce WikiWhirl, a domain-specific language for wiki refactoring. WikiWhirl is supported as an extension of FreeMind, a popular mind mapping tool. In this way, refactoring operations are intuitively conducted as actions upon mind map nodes. In a refactoring session a user imports the wiki structure\u00a0\u2026", "num_citations": "7\n", "authors": ["1513"]}
{"title": "La agricultura familiar campesina en Centroam\u00e9rica: una apuesta estrat\u00e9gica frente a los desaf\u00edos de los territorios rurales\n", "abstract": " La agricultura familiar campe-sina es la principal proveedora de alimentos b\u00e1sicos en los pa\u00edses centroamericanos, siendo parte de las estrategias de vida de una tercera parte o m\u00e1s de los hogares de la regi\u00f3n. A pesar de la extrema vulnerabilidad y altos niveles de pobreza de las familias campesinas, el sector es clave para garantizar la seguridad alimentaria, as\u00ed como contrarrestar la degradaci\u00f3n de ecosistemas y paisajes en un contexto adverso de cambio clim\u00e1tico.", "num_citations": "7\n", "authors": ["1513"]}
{"title": "Reactive tags: Associating behaviour to prescriptive tags\n", "abstract": " Social tagging is one of the hallmarks of Web2. 0. The most common role of tags is descriptive. However, tags are being used for other purposes such as to indicate some actions to be conducted on the resource (eg'toread'). This work focuses on'prescriptive tags' that have associated some implicit behaviour in the user's mind. So far, little support is given for the automation of this\" implicit behaviour\", more to the point, if this behaviour is outside the tagging site. This paper introduces the notion of'reactive tags' as a means for tagging to impact sites other than the tagging site itself. The operational semantics of reactive tags is defined through event-condition-action rules. Events are the action of tagging. Conditions check for additional data. Finally, rule's actions might impact someone else's account in a different website. The specification of this behaviour semantics is hidden through a graphical interface that permits\u00a0\u2026", "num_citations": "7\n", "authors": ["1513"]}
{"title": "Model-aware Wiki analysis tools: the case of HistoryFlow\n", "abstract": " Wikis are becoming mainstream. Studies confirm how wikis are finding their way into organizations. This paper focuses on requirements for analysis tools for corporate wikis. Corporate wikis differ from their grow-up counterparts such as Wikipedia. First, they tend to be much smaller. Second, they require analysis to be customized for their own domains. So far, most analysis tools focus on large wikis where handling efficiently large bulks of data is paramount. This tends to make analysis tools access directly the wiki database. This binds the tool to the wiki engine, hence, jeopardizing customizability and interoperability. However, corporate wikis are not so big while customizability is a desirable feature. This change in requirements advocates for analysis tools to be decoupled from the underlying wiki engines. Our approach argues for characterizing analysis tools in terms of their abstract analysis model (eg a graph\u00a0\u2026", "num_citations": "7\n", "authors": ["1513"]}
{"title": "Powering RSS Aggregators with Ontologies-A Case for the RSSOWL Aggregator.\n", "abstract": " Content syndication through RSS is gaining wide acceptance, and it is envisaged that feed aggregators will be provided as a commodity in future browsers. As we consume more of our information by way of RSS feeds, search mechanisms other than simple keyword search will be required. To this end, advances in semantic tooling can effectively improve the current state of the art in feed aggregators. This work reports on the benefits of making a popular RSS aggregator, RSSOwl, ontology-aware. The paper uses three common functions, namely, semantic view, semantic navigation and semantic query, to illustrate how RSS aggregators can be \u201contology powered\u201d. The outcome is that location, browsing and rendering of RSS feeds are customised to the conceptual model of the reader, making RSS aggregators a powerful companion to face the \u201cRSSosphere\u201d. The system has been fully implemented, and successfully tested by distinct users.", "num_citations": "7\n", "authors": ["1513"]}
{"title": "An object-oriented metric to measure the degree of dependency due to unused interfaces\n", "abstract": " Object-Oriented frameworks are sets of classes designed to work together in order to offer generic solutions to many specific problems within the same application domain. A situation that often arises from the design of a framework is the interface dependency problem produced by interface inheritance when subclasses do not really need the interfaces. This problem negatively affects frameworks in their reuse and extension qualities. Although we know that this problem exists, we do not have a way to measure to what extent this problem affects frameworks. In this paper an object-oriented metric to measure the degree of dependency due to unused interfaces is proposed. Case studies are presented in order to show how this metric helps to detect when frameworks have a serious interface dependency problem. With this information a quantitative decision can be made to take care of the problem.", "num_citations": "7\n", "authors": ["1513"]}
{"title": "Seamless Integration of Inquiry and Transactional Tasks in Web Applications\n", "abstract": " Most conceptual Web design methods proposed so far focus on browsing (i.e. inquiry tasks) but it is not clear how to integrate them with transactional tasks which have a lasting effect. Moreover, tasks are commonly integrated into higher-order behavioural units: the processes. For instance, the process of a purchase includes \u201cbrowsing the catalog\u201d, \u201cadding to the trolley\u201d, \u201cfilling up billing data\u201d and other tasks that end up in the fulfillment of the order. We claim that these distinct task types (i.e. inquiry and transactional tasks) impose different demands and require distinct skills from the designer. On these grounds, we envisage a bottom-up approach to web application construction. First, inquiry and transactional task design is conducted by two separate teams each with expertise in one area. Second, processes are realised through inter-task dependencies. Declarative and separate description of tasks and\u00a0\u2026", "num_citations": "7\n", "authors": ["1513"]}
{"title": "Change case analysis\n", "abstract": " In todays competitive world, companies should adapt to changing conditions, and rapid evolution is a key success factor. The software systems that serve these companies to fulfill their objectives should evolve accordingly. So, even if a system correctly matches the initial requirements, change is inexorable. This has led to an increasing awareness of the importance of considering change scenarios early in the analysis process so that potential changes can be identified early during analysis leading to more robust software and lower maintenance costs. A systematic approach to this issue, should provide means to (1) identify potential changes and (2), determine the impact of the change. The paper promotes a stepwise use case construction to be used as a baseline for change identification. Some insights are provided to ascertain potential changes, and examples illustrates how to produce change resilience designs.", "num_citations": "7\n", "authors": ["1513"]}
{"title": "Strategic reading in design science: Let root-cause analysis guide your readings\n", "abstract": " Reading literature is important, but problematic. In Quora and other PhD forums, students moan about their frustrating reading and literature review experiences. Strategic reading might help. This term is coined to conceive of reading as a process of constructing meaning by interacting with text in a targeted way. The fact that strategic reading is purpose-driven suggests that the purpose might qualify the reading. If this purpose is Design Science Research (DSR), what would be the strategy for reading? Traditionally, students are encouraged to annotate while reading. Digital annotations are expected to be useful for supporting comprehension and interpretation. Our belief is that strategic reading can be more effective if annotation is conducted in direct relationship to a main DS activity: root-cause analysis (RCA). RCA can provide the questions whose answers should be sought in the literature. Unfortunately\u00a0\u2026", "num_citations": "6\n", "authors": ["1513"]}
{"title": "Wiki refactoring: an assisted approach based on ballots\n", "abstract": " Wikis' organic growth inevitably leads to a gradual degradation of the wiki content/structure which, in turn, may entail recurrent wiki refactoring. Unfortunately, no regression test exists to check the validity of the refactoring output. Some changes, even if compliant with good practices, can still require to be backed by the community which ends up bearing the maintenance burden. This calls for a semiautomatic approach where\" refactoring bots\" interact with wiki users to confirm the upgrades. This paper outlines this as follows. First, a refactoring bot detects wiki degradation. Second, the community evaluates the severity of the degradation through voting. Finally, the refactoring bot takes control and enacts the appropriate changes, if so decided by the community. This lessens but does not exclude, the participation of the community. We aim at reducing the maintenance penalty that goes with the laissez-faire way that\u00a0\u2026", "num_citations": "6\n", "authors": ["1513"]}
{"title": "A Tool for Assessing the Consistency of Websites.\n", "abstract": " Usability is becoming an increasingly important design factor for web sites. However time and budget contstraints for web projects prevents the hiring of usability professionals to conduct tests that are costly and time consuming to perform. A number of automatic usability assessment tools have been developed most of which offer reports on a per-page basis. However, they fail to provide inter-page assessments to test, for example the consistency of the site. Consistency refers to the extent to which a set of pages share a common layout. This work presents CAT, a Consistency Analysis Tool that, besides providing static, page-based usability measures, strives to assess the consistency of a website using Java and XSLT. The tool is based on a consistency model which is updated every time a page has been processed. Consistency testing involves collating the page with this model, reporting mismatches with the consistency attributes and adapting the model as new features are encountered for the first time.", "num_citations": "6\n", "authors": ["1513"]}
{"title": "YQL as a platform for Linked-Data wrapper development\n", "abstract": " Linked-Data Wrappers (LDWs) have been proposed to integrate Open APIs into the linked-data cloud. A main stumbling block is maintenance: LDWs need to be kept in sync with the APIs they wrap. Hence, LDWs are not single-shot efforts, but sustained endeavors that developers might not always afford. As a result, it is not uncommon for third-party LDWs to stop working when their underlying APIs upgrade. Collaborative development might offer a way out. This requires a common platform and a community to tap into. This work investigates the suitability of the YQL platform for this job. Specifically, we look into two main properties for LDW success: effectiveness (i.e. the capability of YQL to enable users to develop LDWs) and scalability (i.e. graceful time degradation on URI dereferencing). The aim: moving LDW development from in-house development to collaborative development as promoted by YQL, on\u00a0\u2026", "num_citations": "5\n", "authors": ["1513"]}
{"title": "Software product line testing: A feature oriented approach\n", "abstract": " Software Product Lines (SPLs) are not intended to create one application, but a number of them: a product family. In contrast to one-off development, SPLs are based on the idea that the distinct products of the family share a significant amount of assets. This forces a change in how software is developed. Likewise, software testing should mimic its code counterpart: product testing should also be produced out of a common set of assets. Specifically, this paper addresses how model-driven testing, used for one-off development, can be moved to an SPL setting. We focus on feature-oriented software development as the SPL realization technique. UML sequence diagrams are used to represent the common and feature scenarios. This models are transformed through model transformations to obtain test cases that conform to the UML Testing Profile.", "num_citations": "5\n", "authors": ["1513"]}
{"title": "Facing tagging data scattering\n", "abstract": " Web2.0 has brought tagging at the forefront of user practises for organizing and locating resources. Unfortunately, these tagging efforts suffer from a main drawback: lack of interoperability. Such situation hinders tag sharing (e.g. tags introduced at del.icio.us to be available at Flickr) and, in practice, leads to tagging data to be locked to tagging sites. This work argues that for tagging to reach its full potential, tag management systems should be provided that accounts for a common way to handle tags no matter the tagging site (e.g. del.icio.us, Flickr) that frontended the tagging. This paper introduces TAGMAS (TAG MAnagement System) that offers a global view of your tagging data no matter where it is located. By capitalizing on TAGMAS, tagging applications can be built in a quicker and robust way. Using measurements and one use case, we demonstrate the practicality and performance of TAGMAS.", "num_citations": "5\n", "authors": ["1513"]}
{"title": "Modeling portlet aggregation through statecharts\n", "abstract": " A portal is a key component of an enterprise integration strategy. It provides integration at the user interface level, whereas other integration technologies support business process, functional or data integration. To this end, portlet syndication is the next wave following the successful use of content syndication in current portals. A portlet is a front-end application which is rendered within the portal framework. From this perspective, portlets can be regarded as Web components, and the portal as the component container where portlets are aggregated to provide higher order applications. Unlike back-end integration approaches (e.g. workflow systems), portlet aggregation demands front-end solutions that permit users navigate freely among portlets in a hypertext way. To this end, the Hypermedia Model Based on Statecharts is used. This model uses the structure and execution semantics of statecharts to specify\u00a0\u2026", "num_citations": "5\n", "authors": ["1513"]}
{"title": "A reusability model for portlets\n", "abstract": " By means of portals, a company can give each person the inform-ation that responds to their specific needs. Nowadays, portals tend to be constructed by means of portlets. So, if we want \u201cgood\u201d portals, we must select the most appropriate portlets for their construction. This requires the existence of appropriate quality models to assess portlet\u2019s diverse characteristics. Perhaps one of the most important non-functional characteristics (from the point of view of the portlet consumer) is reusability.This work aims to define a reusability model for portlets that will allow the assessment of the portlet reusability level. As an example of application, we have applied the reusability model to a concrete portlet in order to know its level of reusability.", "num_citations": "5\n", "authors": ["1513"]}
{"title": "Generating Blogs from Product Catalogues: A Model-Driven Approach\n", "abstract": " Blogs can be used as a conduit for customers opinions, and in so doing, building communities around products. We attempt to realise this vision by building blogs out of product catalogues. Unfortunately, the lack of standards for blog APIs, and the limited experience in virtual communities, make this endeavour risky. This refrains smalland-medium companies from setting such blog-based communities. This paper presents a model-driven approach to alleviate these drawbacks. To this end, two abstract models are introduced: the catalogue model, based on the standard Open Catalog Format, and the blog model, that elaborates on the use of blogs as conduits for virtual communities. Blog models end up being realised through blog engines. Specifically, we focus on two popular platforms: a hosted and a standalone blog platform, both in Blojsom. The paper outlines blog construction as an instance of the MDD process, provides some transformation samples, and concludes by comparing MDD and direct manual coding of blogs.", "num_citations": "5\n", "authors": ["1513"]}
{"title": "Portlet usability model\n", "abstract": " Portlet usability model Page 1 Portlet usability model \u00d3scar D\u00edaz ONEKIN research group Dpt. Of Computer Science University of the Basque Country (Spain) 34 943 01 8064 oscar@si.ehu.es Coral Calero, Mario Piattini ALARCOS research group Dpt. Of Computer Science, University of Castilla-La Mancha (Spain) 34 926 29 5300 {Coral.Calero, Mario.Piattini}@uclm.es Arantza Irastorza ONEKIN research group Dpt. Of Computer Science University of the Basque Country (Spain) 34 943 01 8064 jipirgoa@si.ehu.es ABSTRACT Emerging portlet standards (eg WSRP) promise to achieve true portlet interoperability. This will certainly fuel portlet syndication, and facilitate a market for portlets in the long run. As with other component technologies, this requires the existence of quality models that assist in ascertaining the provider that better fits the consumer needs. Usability is one of the characteristics defined in the ISO \u2026", "num_citations": "5\n", "authors": ["1513"]}
{"title": "Moving Web Services Dependencies at the front-end\n", "abstract": " Most Web sites offer loosely-coupled services where the role of the site is almost restricted to be a front-end for service enactment. If the number of services is large, the designer should struggle to provide a sense of coherence and unity among the services that can be accomplished through the site. This endeavour is similar to business process automation, which are traditionally achieved through the use of workflow management systems. The difference stems from workflows working at the back-end (i.e. it normally implies database-level or API-based integration) whereas now the integration is achieved at the front-end. So far, these aspects are directly hard-coded and scattered around HTML pages. This hinders not only development, but most importantly, the maintenance and evolution of the site. This work investigates how traditional workflow concepts can be redefined in terms of front-end notions.", "num_citations": "5\n", "authors": ["1513"]}
{"title": "Integraci\u00f3n, navegaci\u00f3n y presentaci\u00f3n: experiencias utilizando XML\n", "abstract": " La creciente necesidad de integrar aplicaciones, tanto dentro de la propia organizaci\u00f3n como con organizaciones asociadas, ha promovido el est\u00e1ndar XML. Este est\u00e1ndar permite describir la estructura de los documentos, con independencia, tanto de su presentaci\u00f3n, como del soporte donde se asienten sus datos. Alrededor de XML est\u00e1n surgiendo diferentes lenguajes que se centran en alg\u00fan tratamiento espec\u00edfico del documento. Este trabajo presenta nuestra experiencia en la utilizaci\u00f3n de XML para la realizaci\u00f3n de aplicaciones hipermedia. Las aplicaciones hipermedia se caracterizan por organizar los datos en grafos de nodos, y donde el acceso se realiza por medio de enlaces entre los nodos. En la concepci\u00f3n y desarrollo de estas aplicaciones, se suelen distinguir los siguientes esquemas: esquema conceptual, esquema de derivaci\u00f3n, esquema de navegaci\u00f3n y esquema de presentaci\u00f3n. En\u00a0\u2026", "num_citations": "5\n", "authors": ["1513"]}
{"title": "DScaffolding: A tool to support learning and conducting design science research\n", "abstract": " Learning and conducting Design Science Research (DSR) are complex undertakings, for which there is little assistance other than publications describing how to do them. They include many activities which must be mastered and coordinated, sometimes when doing them for the first time. This paper describes a new tool, DScaffolding, developed to support novice DSR researchers in learning DSR while conducting DSR research projects. DSR activities are supported within an existing mind-mapping tool (MindMeister), through the use of features such as (1) integrating MindMeister with literature management and annotation tools, (2) prompting for needed inputs, (3) tracking incomplete tasks, and (4) automatically piping information from one activity to another activity and ensuring consistency of information. An initial version of DScaffolding was evaluated formatively. The prototype is available as a plugin\u00a0\u2026", "num_citations": "4\n", "authors": ["1513"]}
{"title": "User-driven automation of web form filling\n", "abstract": " Form-intensive Web applications are common among institutions that collect bulks of data in a piecemeal fashion. European funding programs or income tax return illustrate these scenarios. Very often, most of this data is already digitalized in terms of documents, spreadsheets or databases. The task of manually filling Web forms out of these resources is not only cumbersome but also prone to typos. It does not benefit from the fact that the data is already in electronic format. Alternatively, externally-fed autofilling scripts can be programmed (e.g. using iMacros and Visual Basic) to code once, and enact many times. Unfortunately, this approach is programming intensive and fragile upon upgrades in either the website or the structure of the external source. This moves these tools away from users with scarce programming skills. We strive to empower these users by abstracting the way feeding solutions are\u00a0\u2026", "num_citations": "4\n", "authors": ["1513"]}
{"title": "Gobernanza ambiental-territorial y desarrollo en El Salvador: El caso del Bajo Lempa\n", "abstract": " El Bajo Lempa fue un territorio clave para la consolidaci\u00f3n del modelo agroexportador que predomin\u00f3 en El Salvador hasta finales del siglo XX, as\u00ed como un importante espacio de construcci\u00f3n de nuevas expresiones sociales y productivas por parte de pobladores desplazados durante la guerra que se asentaron en esa zona como resultado de programas de repatriaci\u00f3n y reinserci\u00f3n luego de la finalizaci\u00f3n del conflicto interno salvadore\u00f1o. En el Bajo Lempa se han desatado procesos relevantes de construcci\u00f3n de capacidades organizativas e institucionales para el desarrollo social y productivo, incluyendo el despliegue de nuevos arreglos para la gesti\u00f3n del riesgo ante la variabilidad y el cambio clim\u00e1tico.El Bajo Lempa refleja con bastante nitidez los desaf\u00edos e implicaciones para la gobernanza ambiental y el desarrollo del pa\u00eds. Los alcances de la degradaci\u00f3n ambiental heredada por el viejo modelo agroexportador en ese territorio, ahora magnificados por el cambio clim\u00e1tico, hacen del Bajo Lempa uno de los territorios m\u00e1s vulnerables en el pac\u00edfico centroamericano. Sin embargo, el potencial productivo de ese territorio, tanto por los recursos naturales y los servicios ecosist\u00e9micos a\u00fan existentes (tierra, playas y zonas costeras, recursos pequeros, etc.), como por su ubicaci\u00f3n para la consolidaci\u00f3n de estrategias de promoci\u00f3n de corredores y servicios log\u00edsticos (provisi\u00f3n de mano de obra, provisi\u00f3n de materias primas y alimentos, etc.), est\u00e1n reconfigurando el rol del Bajo Lempa y de la Franja Costero-Marina del pa\u00eds, como territorios claves para un nuevo ciclo de promoci\u00f3n del crecimiento, la inversi\u00f3n y el empleo. En este\u00a0\u2026", "num_citations": "4\n", "authors": ["1513"]}
{"title": "Wikipedia customization through web augmentation techniques\n", "abstract": " Wikipedia is a successful example of collaborative knowledge construction. This can be synergistically complemented with personal knowledge construction whereby individuals are supported in their sharing, experimenting and building of information in a more private setting, without the scrutiny of the whole community. Ideally, both approaches should be seamlessly integrated so that wikipedians can easily transit from the public sphere to the private sphere, and vice versa. To this end, we introduce WikiLayer, a plugin for Wikipedia that permits wikipedians locally supplement Wikipedia articles with their own content (ie a layer). Layering additional content is achieved locally by seamlessly interspersing Wikipedia content with custom content. WikiLayer is driven by three main wiki principles: affordability (ie, if you know how to edit articles, you know how to layer), organic growth (ie, layers evolve in synchrony with\u00a0\u2026", "num_citations": "4\n", "authors": ["1513"]}
{"title": "Script programmers as value co-creators\n", "abstract": " Website owners are gradually realising the benefits of viewing customers as co-creators of value. Unfortunately, current development models offer little help in understanding and managing this new form of value co-creation. The Metropolis Model has recently identified three realms of roles for crowdsourcing: the kernel (providing the core functionality), the periphery (the partners) and the masses (the end users). Technically wise, the periphery requires mechanisms for the commons to suggest, develop and maintain additional services on top of the kernel. This work concretizes the Metropolis Model for crowdsourced website development based on user scripts. We outline some technical challenges to foster the relationship between end users (the masses), scripters (the periphery) and the web site (the kernel) on the way to promote script-based crowdsourcing.", "num_citations": "4\n", "authors": ["1513"]}
{"title": "Turning the mouse into a semantic device: the seMouse experience\n", "abstract": " The desktop is not foreign to the semantic way that is percolating broad areas of computing. This work reports on the experiences on turning the mouse into a semantic device. The mouse is configured with an ontology, and from then on, this ontology is used to annotate the distinct desktop resources. The ontology plays the role of a clipboard which can be transparently accessed by the file editors to either export (i.e. annotation) or import (i.e. authoring) metadata. Traditional desktop operations are now re-interpreted and framed by this ontology: copy&paste becomes annotation&authoring, and folder digging becomes property traversal. Being editor-independent, the mouse accounts for portability and maintainability to face the myriad of formats and editors which characterizes current desktops. This paper reports on the functionality, implementation, and user evaluation of this \u201csemantic mouse\u201d.", "num_citations": "4\n", "authors": ["1513"]}
{"title": "Stimuli and Business Policies as Modelling Constructs: their definition and validation through the event calculus\n", "abstract": " Accurate gathering of requirements is a major concern during conceptual modelling. Such accurateness can only be achieved through major involvement of users, who should check whether the system's specification conforms with their expectations. This task can be facilitated both by intuitive conceptual constructs and by executable models that allow interaction with the user to explain the behaviour of the system in accordance with its specification. This work proposes the notions of stimuli and business policies as intuitive behavioural constructs, and the use of the event calculus as an appropriate formalism for building executable specifications for behavioural models. The approach is borne out by an early implementation that allows the user to question why and how a given state is reached, where the answer is given in terms of the specifications, i.e. stimuli and policies, being applied.", "num_citations": "4\n", "authors": ["1513"]}
{"title": "Exploitation of object-oriented and active constructs in database interface development\n", "abstract": " This paper presents some experiences in the exploitation of a database interface development architecture in which the interface is implemented using the facilities of the database. It is shown how novel interfaces, specifically a multi-paradigm query interface and a debugger for an active rule system, can benefit from and exploit the uniform representation of interface and database system concepts as database objects.", "num_citations": "4\n", "authors": ["1513"]}
{"title": "Supervivencia de diab\u00e9ticos insulinodependientes con inicio del s\u00edndrome antes de los 15 a\u00f1os de edad\n", "abstract": " Se realiz\u00f3 un estudio descriptivo, de tipo prospectivo no concurrente, para conocer la supervivencia de pacientes diab\u00e9ticos insulinodependientes cuya enfermedad comenz\u00f3 antes de los 15 a\u00f1os de edad. Fueron identificados, mediante una b\u00fasqueda exhaustiva en pr\u00e1cticamente todas las fuentes posibles, 504 pacientes en Ciudad de la Habana entre 1965 y 1980. El status que presentaban el 31 de diciembre de 1991 fue de 400 vivos (79, 4 por ciento), 70 fallecidos (13, 9 por ciento), 23 emigrados (4, 6 por ciento) y 11 ilocalizables (2, 2 por ciento). El tiempo medio de seguimiento fue de 17, 5 a\u00f1os. Se emple\u00f3 el m\u00e9todo de Kaplan-Meier para el c\u00e1lculo de la supervivencia, seg\u00fan duraci\u00f3n de esta afecci\u00f3n que el resto de los individuos (p< 0, 01). Existe una reserva, es este aspecto, a alcanzar en nuestros pacientes cuando se comparan con los de otros pa\u00edses", "num_citations": "4\n", "authors": ["1513"]}
{"title": "Clasificaci\u00f3n actual de la diabetes mellitus:(criterios del comit\u00e9 de expertos de la OMS; 1985)\n", "abstract": " Se presentan los nuevos criterios diagn\u00f3sticos para la diabetes mellitus tipos I (DMID) y II (DMNID), as\u00ed como la tolerancia alterada a la glucosa (TGA) y la diabetes gestacional (DG). Se aborda el valor que pueden tener otras determinaciones e \u00edndices no glic\u00e9micos para el diagn\u00f3stico de las diferentes subclases de DM y en los estudios epidemiol\u00f3gicos; adem\u00e1s, la validez de los m\u00e9todos de pesquisaje. Se expone la nueva clasificaci\u00f3n revisada con la inclusion de la diabetes mellitus asociada a la malnutrici\u00f3n como una clase clinica", "num_citations": "4\n", "authors": ["1513"]}
{"title": "What Matters for Chatbots? Analyzing Quality Measures for Facebook Messenger\u2019s 100 Most Popular Chatbots\n", "abstract": " Chatbots are becoming mainstream. This work aims at ascertaining what are the enablers behind this popularity. To this end, we introduce four quality attributes, namely, \u201csupport of a minimal set of commands\u201d, \u201cforesee language variations\u201d, \u201chuman-assistance provision\u201d and \u201ctimeliness\u201d. These criteria are applied to the 100 most popular Facebook Messenger chatbots. We review and measure both capacities and performance in order to find correlations between quality attribute fulfilment and popularity (chatbots\u2019 \u2019likes\u2019). Results show no significance correlations between quality attributes and chatbot popularity. However, the experiment comes up with three main contributions. First, a detailed description of how to measure these four quality attributes. Second, insights about how this assessment can be automatized, paving the way towards chatbot-evaluation platforms. Third, a checklist of frequently\u00a0\u2026", "num_citations": "3\n", "authors": ["1513"]}
{"title": "Reducing coordination overhead in SPLs: peering in on peers\n", "abstract": " SPL product customers might not always wait for the next core asset release. When an organization aims to react to market events, quick bug fixes or urgent customer requests, strategies are needed to support fast adaptation, eg with product-specific extensions, which are later propagated into the SPL. This leads to the grow-and-prune model where quick reaction to changes often requires copying and specialization (grow) to be later cleaned up by merging and refactoring (prune). This paper focuses on the grow stage. Here, application engineers branch off the core-asset Master branch to account for their products' specifics within the times and priorities of their customers without having to wait for the next release of the core assets. However, this practice might end up in the so-called\" integration hell\". When long-living branches are merged back into the Master, the amount of code to be integrated might cause build\u00a0\u2026", "num_citations": "3\n", "authors": ["1513"]}
{"title": "Visualizing product customization efforts for spotting SPL reuse opportunities\n", "abstract": " Migrating a set of product variants to a managed SPL is rarely a one-shot effort. Experiences from industry revealed that a complete migration to an SPL might take years, during which customers' requirements still need to be fulfilled by the company (customization effort). Analyzing the assets that have been customized by products (customization analysis) becomes a main stepping stone in ascertaining reuse opportunities. This requires to remain vigilant to arising reuse opportunities not just at the SPL onset, but throughout the whole process. Traditionally, a common mechanism to identify reuse opportunities is the diff utility whereby differences between two files are calculated and displayed. But this mechanism might not scale up. Given the sheer number of both core-assets and SPL products, visualizations that abstract from conventional line-level diffs to higher level visualization are required to spot reuse\u00a0\u2026", "num_citations": "3\n", "authors": ["1513"]}
{"title": "Uso de Chatbots en la Docencia Universitaria\n", "abstract": " Los chatbots son aplicaciones inform\u00e1ticas que pueden simular una conversaci\u00f3n con un ser humano. Hoy en d\u00eda, los chatbots-o bots-pueden integrarse y aprovechar las ventajas de las aplicaciones de mensajer\u00eda (sin esfuerzo de instalaci\u00f3n y disponibilidad masiva). Los chatbots pueden convertirse en un nuevo tipo de aplicaciones integradas dentro del m-learning. Sin embargo, el dise\u00f1o de estas nuevas aplicaciones suponen un desaf\u00edo. En este art\u00edculo presentamos un ejemplo de dise\u00f1o e implementaci\u00f3n de un bot de Telegram que permite plantear cuestionarios de respuesta m\u00faltiple y hacer un seguimiento de los resultados. Los estudiantes opinan que el uso de bots para la realizaci\u00f3n de este tipo de tests es una buena idea (89%) que les permite involucrarse m\u00e1s en la asignatura (72%) y cuyo uso recomendar\u00edan para otras asignaturas universitarias (94%).", "num_citations": "3\n", "authors": ["1513"]}
{"title": "Testing mofscript transformations with handymof\n", "abstract": " Model transformation development is a complex task. Therefore, having mechanisms for transformation testing and understanding becomes a matter of utmost importance. Understanding, among others, implies being able to trace back bugs to their causes. In model transformations, causes can be related with either the input model or the transformation code. This work describes HandyMOF, a tool that first eases the transition between the effect (i.e. generated code file) and the causes (i.e. input model and transformations) and then provides the means to check the transformation coverage obtained by a test suite. The challenges are twofold. First, the obtainment of input model suites which yield to a quantifiable transformation coverage. Second, providing fine-grained traces that permit to trace back code not just to the transformation rule but to the inner \u2019print\u2019 statements. A transformation that generates\u00a0\u2026", "num_citations": "3\n", "authors": ["1513"]}
{"title": "El peso y la edad gestacional: su efecto en la mortalidad fetal\n", "abstract": " Objetivo: Describir la relaci\u00f3n peso-edad gestacional, seg\u00fan el resultado del embarazo (nacido vivo, muerte fetal) y brindar estimaciones de riesgo de muerte fetal, atendiendo a combinaciones de estos dos factores.M\u00e9todo: El universo de estudio estuvo comprendido por todos los embarazos expulsados durante el a\u00f1o 2003, con 22 \u00f3 m\u00e1s semanas de gestaci\u00f3n, de la provincia Granma. La informaci\u00f3n proviene de las bases de datos de nacidos vivos y defunciones perinatales de la Oficina de Estad\u00edsticas (ONE) y de la Direcci\u00f3n Nacional de Estad\u00edstica (DNE) del Ministerio de Salud P\u00fablica. Se dise\u00f1aron tablas de frecuencias relativas, seg\u00fan la edad gestacional y peso para los eventos nacido vivo y muerte fetal, asimismo se calcularon las medidas de posici\u00f3n, tendencia central y de dispersi\u00f3n, adem\u00e1s del dise\u00f1o de tablas de vida, seg\u00fan el resultado del embarazo, con lo que se realizaron las estimaciones de riesgo de mortalidad fetal, seg\u00fan categor\u00edas de peso, en funci\u00f3n de la edad gestacional.Resultados: Las desventajas en cuanto a desarrollo y crecimiento fetal correspondieron a fetos cuyo destino es nacer muertos y los riesgos de mortalidad fetal fueron mayores en las categor\u00edas inferiores de peso aunque estos tienden a elevarse aceleradamente a partir de la semana 42 de gestaci\u00f3n en las categor\u00edas de peso donde el riesgo de muerte es menor.Conclusiones: Con este estudio fue posible constatar diferencias notables en cuanto a la edad gestacional y peso del producto de la concepci\u00f3n, as\u00ed como en la relaci\u00f3n simult\u00e1nea de ambos en dependencia del resultado del embarazo.", "num_citations": "3\n", "authors": ["1513"]}
{"title": "A performance comparison of CMOS voltage-controlled ring oscillators for its application to generation and distribution clock networks\n", "abstract": " In this work, a performance comparison of expanded CMOS voltage-controlled ring oscillators for non-resonant local clock generation and distribution networks is presented. Several differential and single-ended ring oscillators are designed and fabricated using long interconnection lines to achieve wide coverage chip. A test chip containing the several oscillators was fabricated using an Austria Microsystems (AMS) 0.35 \u00b5m CMOS technology. Experimental results show that it is possible to generate and distribute high frequency signals (GHz range) on a relativity large area (coverage) and low phase noise using non-resonant ring oscillators. This represents an attractive alternative for the design and implementation of local Clock Generation and Distribution Networks for systems on chip.", "num_citations": "3\n", "authors": ["1513"]}
{"title": "Schemol: Un lenguaje especifico del dominio para extraer modelos de bases de datos relacionales\n", "abstract": " La Modernizaci\u00f3n Dirigida por Modelos ha emergido recientemente como una nueva \u00e1rea dedicada a la automatizaci\u00f3n basada en modelos de procesos de reingenier\u0131a o modernizaci\u00f3n de software. En estos procesos existe una primera etapa de ingenier\u0131a inversa en la cual se aplican tareas de extracci\u00f3n de modelos a partir de los artefactos del sistema (p. ej., c\u00f3digo o datos). En esta demostraci\u00f3n presentamos ScheMoL, un lenguaje espec\u0131fico del dominio para extraer modelos desde datos almacenados en una base de datos relacional. El lenguaje permite definir transformaciones datos-a-modelo basadas en reglas que est\u00e1n inspiradas en las reglas del lenguaje de transformaci\u00f3n modelo-a-modelo ATL. En el caso de ScheMoL, las reglas tienen como elemento origen una tabla y como elemento destino una metaclase de un metamodelo. Tambi\u00e9n incorpora un lenguaje de consultas especialmente adaptado para obtener informaci\u00f3n de las bases de datos.", "num_citations": "3\n", "authors": ["1513"]}
{"title": "Trombocitopenia severa, persistente a transfusiones plaquetarias, secundaria a readministraci\u00f3n de abciximab en paciente con antecedentes de p\u00farpura trombocitop\u00e9nica idiop\u00e1tica\u00a0\u2026\n", "abstract": " Acute severe thrombocytopenia is a serious although infrequent complication following abciximab infusion that is usually managed with platelet transfusions. We present a patient who underwent multivessel percutaneous coronary intervention with concomitant abciximab administration. Soon after the procedure the patient developed severe thrombocytopenia that persisted despite multiple platelet transfusions. This patient had been previously diagnosed as having idiopathic thrombocytopenic purpura, although this diagnosis was not recorded in our medical records, and at the time of the intervention the patient had a normal platelet count. He was successfully managed with IgG administration. The clinical and therapeutic implications of this case are discussed.", "num_citations": "3\n", "authors": ["1513"]}
{"title": "Extending xml schema with derived elements\n", "abstract": " XML is becoming the standard for document description, and XML Schema is gaining wide acceptance as the schema language to define the set of elements and attribute names that describe the content of a document. This work proposes both a knowledge model and an execution model to extend XML Schema with derived elements: the XDerive vocabulary. A derived element is an element whose content can be calculated by examining the content of other elements. The common presence of derived data in everyday documents supports this endeavour. The feasibility of this approach has been checked out by making the Oracles XML Parser able to interpret XDerive tags.", "num_citations": "3\n", "authors": ["1513"]}
{"title": "On use case elicitation\n", "abstract": " Use cases currently enjoy a wide popularity among object-oriented practitioners. However, evidence has been reported that users find difficult to ascertain the right use cases, and that comprehensive process guidance is required. This paper presents an a pproach based on decision making where the construction of use cases is sequenced along four steps. At each level a distinct decision is made. In so doing, it offers a first attempt to provide a set of guidelines to this popular and useful requirement gat hering method.", "num_citations": "3\n", "authors": ["1513"]}
{"title": "Coding-Data Portability in Systematic Literature Reviews: a W3C's Open Annotation Approach\n", "abstract": " Systematic Literature Reviews (SLRs) are increasingly popular to categorize and identify research gaps. Their reliability largely depends on the rigour of the attempt to identify, appraise and aggregate evidences through coding, ie the process of examining and organizing the data contained in primary studies in order to answer the research questions. Current Qualitative Data Analysis Software (QDAS) lack of a common format. This jeopardizes reuse (ie difficult to share coding data among different tools), evolution (ie difficult to turn coding data into living documents that evolve as new research is published), and replicability (ie difficult for third parties to access and query coding data). Yet, the result of a recent survey indicates that 71, 4% of participants (expert SLR reviewers) are ready to share SLR artifacts in a common repository. On the road towards open coding-data repositories, this work looks into W3C's Open\u00a0\u2026", "num_citations": "2\n", "authors": ["1513"]}
{"title": "A tool for management of knowledge dispersed throughout multiple references\n", "abstract": " When modeling tasks are performed, it is important that the different modeling team members share a common vocabulary. This implies not only agreement on the terminology itself but especially on the meaning of the terms used. To this end it comes in handy to have graphical tools for sharing and analyzing the knowledge dispersed throughout different sources. In this paper we present RCMTool, a tool for creating References-enriched Concept Maps (RCM). This technique has been specially designed to facilitate the compact presentation and comparison of different definitions provided by multiple authors in diverse sources. This paper presents the main features of RCMTool, based on the development of an RCM metamodel and the inclusion of a natural language processing engine.", "num_citations": "2\n", "authors": ["1513"]}
{"title": "Cross publishing 2.0: Letting users define their sharing practices on top of YQL\n", "abstract": " One of Web2.0 hallmarks is the empowerment of users in the transit from consumers to producers. So far, the focus has been on content: text, video or pictures on the Web has increasingly a layman\u2019s origin. This paper looks at another Web functionality, cross publishing, whereby items in one website might also impact on sister websites. The Like and ShareThis buttons are forerunners of this tendency whereby websites strive to influence and be influenced by the actions of their users in the websphere (e.g. clicking on Like in site A impacts a different site B, i.e. Facebook). This brings cross publishing into the users\u2019 hands but in a \u201ccanned\u201d way, i.e. the \u2019what\u2019 (i.e. the resource) and the \u2019whom\u2019 (the addressee website) is set by the hosting website. However, this built-in focus does not preclude the need for a \u2019do-it-yourself\u2019 approach where users themselves are empowered to define their cross publishing\u00a0\u2026", "num_citations": "2\n", "authors": ["1513"]}
{"title": "Lightweight end-user software sharing\n", "abstract": " This paper looks into the sharing of end-user software (referred to as \u201cscript\u201d). Based on this study four implications are drawn: reduce the effort to make scripts shareable, minimize deployment burdens, less stringent protection mechanisms, and tap into communities of practice as for sharing. To attend these implications, we introduce a URL-based distribution schema for scripts combined with an IP-address-based authorization model. This makes scripts URL-addressable and easy to install, because choosing to install a script means that all of the necessary frameworks, plug-ins, etc. that are needed to make this script run are simultaneously installed. On the other hand, IP-based protection uses IP network prefixes as cypher keys. A script language is used as a proof of concept.", "num_citations": "2\n", "authors": ["1513"]}
{"title": "A federated approach to crossblogging through contracts\n", "abstract": " Blogs are good at authoring and publishing. However, they fall short as communication platforms. By contrast, social platforms such as Face book, are good at creating communities, though the price is a lost in autonomy and control over your own data. This paper advocates for a federated approach for blogs where bloggers freely decide to hand over some rights to other bloggers so that posts/comments/track backs can flow along the \"blog union\". Bloggers keep full control over their blogs but permit content from other blogs to be published. \"Blog unions\" are governed through contracts. This work describes both a contract life cycle and an RDF-based contract specification using event-condition-action rules. The approach is borne out by Blog Union, an extension for Blojsom that permits a blog to set contracts to other union-aware blogs.", "num_citations": "2\n", "authors": ["1513"]}
{"title": "The Modding Web: Layman Tuning of Websites\n", "abstract": " The Web is still much regarded as a user space rather than an author space. Hence, Web engineering cares for both current user requirements (eg usability) and future user requirements (eg maintainability), but overlooks author needs. This tendency is already observed in the increasing availability of open APIs and mashup applications. This work addresses another way of end user authorship, client scripting, whose vigour is evidenced by initiatives such as Greasemonkey. Client scripting permits end users to locally customize content, layout or style of their favourite websites. But current scripting suffers from a tight coupling with the website. As a result, website upgrades can make the script to fall apart. This can refrain users from participating, and slow down open innovation for website owners. To avoid this situation, this work proposes to characterise websites with a\" tuning interface\" in an attempt to decouple layman\u2019s script from website upgrades. Scripts do not longer access the website code (ie the implementation) but a stable description of the website (ie the interface). This interface limits tuning but increases change resilience, and offer a balance between openness (scripter free inspection) and modularity (scripter isolation from website design decisions).", "num_citations": "2\n", "authors": ["1513"]}
{"title": "Model Transformations Should Be Functors\n", "abstract": " The concept of model transformations is of increasing importance in different areas of Computer Science, but up to now, there is a lack of common understanding concerning the mathematical and practical point of view. In this paper, we discuss some of the different aspects. Especially interesting is the new proposal of the POPL\u201907 keynote speaker Don Batory claiming that model transformations should be functors. This claim is compared with different mathematical concepts of model transformation. BEATCS no 92 THE EATCS COLUMNS", "num_citations": "2\n", "authors": ["1513"]}
{"title": "PTSM: A portlet selection model.\n", "abstract": " The use of Web portals continues to rise, showing their importance in the current information society. The success of a portal depends on customers using and returning to it. Nowadays, it is very easy for users to change from one portal to another, so improving/assessing portal quality is a must. Hence, appropriate quality model should be available to measure and drive portal development. Specifically, this work focuses on portlet-based portals. Portlets are web components, and they can be thought as COTS but in a Web setting. This paper presents a portlet selection model that guides the portal developer in choosing the best portlet, among a set of portlets with similar functions for specified tasks and user objectives, in accordance to five quality measures, namely, functionality, reliability, usability, efficiency and reusability, and other three characteristics not related to the quality but important to carry out the selection.", "num_citations": "2\n", "authors": ["1513"]}
{"title": "Semantically integrating portlets in portals through annotation\n", "abstract": " Portlets are currently supported by most portal frameworks. However, there is not yet a definitive answer to portlet interoperation whereby data flows smoothly from one portlet to a neighboring one. One of the approaches is to use deep annotation. By providing additional markup about the background services, deep annotation strives to interact with these underlying services rather than with the HTML surface that conveys the markup. In this way, the portlet can extend portlet markup with meta-data about the processes this markup conveys. Then, the portlet consumer (e.g. a portal) can use this meta-data to guide mapping from available data found in markup of portlet A to required data in markup of portlet B. This mapping is visualised as portlet B having its input form (or other \u201cinput\u201d widget) filled up. However, annotating is a cumbersome process that forces to keep in synchrony the meta-data and the\u00a0\u2026", "num_citations": "2\n", "authors": ["1513"]}
{"title": "Peer-Blog-Peer: The Swiss Knife\n", "abstract": " Web-based support for teaching requires appropriate backing for identity, communication and collaboration. This paper assesses widely available approaches for teaching support, namely, personal web pages, computer-mediated communication, wikis and blogs along these three dimensions, and argues that blogs communities based on P2P architectures offer the potential to fulfil these requirements.", "num_citations": "2\n", "authors": ["1513"]}
{"title": "The Semantic Desktop: an architecture to leverage document processing with metadata\n", "abstract": " The new crop of document processors (editors, workflow, content managers) are metadata-aware. Each processor takes the document as input, processes it, and potentially, generates some metadata. For large and heterogeneous document sets where metadata come from diverse origins, automatic assistance is required to map and keep consistent a common model that provides an integrated view of the document regardless of the different process it has undergone. The Resource Description Framework (RDF) provides a domain-neutral foundation on which extensible element sets can be defined and expressed in a standard notation. This paper describes how the effects of the distinct processes (eg editing, retrieving, consulting) on the document repository can be automatically propagated to the shared RDF model counterpart. To this end, a rule-based approach has been used. Their self-contained, isolated\u00a0\u2026", "num_citations": "2\n", "authors": ["1513"]}
{"title": "A model-based approach to web-application development\n", "abstract": " The increasing growth in size and complexity of portals calls for a systematic way to web-application development that is able to face the stringent demands imposed on both the development and maintenance of these systems Model-based approaches have been proposed to mitigate this situation. These approaches aim to find models, preferably orthogonal, that allow designers to declaratively specify a distinct concern of the application without being immediately immersed in details of implementations. This paper presents AtariX, a model-based tool that renders HTML pages from the declarative schemata specified by the designer. Each concern is described by a separate XML document: how data is integrated and structured (the content document), the topology of links (the navigation document) and the layout of each element (the presentation document). An application is then conformed by a set of\u00a0\u2026", "num_citations": "2\n", "authors": ["1513"]}
{"title": "Stability: a criterion for software evolution enhancement\n", "abstract": " Different surveys points to user request evolution as the most important cause for software maintenance. Such process is seen as a main challenge in software practice, and represents a substantial cost for many organization. This paper proposes the introduction of the concept of stability as a main analysis and design criterion. This criterion aims to identify those aspects of the real world likely to evolve, and to explicitly separate between stable and volatile user requirements. In so doing, volatile requirements can be changed without impacting unnecessarily on the underlying domain, thus easing requirement modifications and finally, enhancing software evolution. 1 Introduction Software maintenance refers to the process of modifying the software system once it is delivered in order to correct faults, improve performance or other attributes, or adapt to a change in environment [16]. Such process is seen as a main challenge in software practice, and represents a substantial cost for...", "num_citations": "2\n", "authors": ["1513"]}
{"title": "Onboarding in Software Product Lines: Concept Maps as Welcome Guides\n", "abstract": " With a volatile labour and technological market, onboarding is becoming increasingly important. The process of incorporating a new developer, a.k.a. the newcomer, into a software development team is reckoned to be lengthy, frustrating and expensive. Newcomers face personal, interpersonal, process and technical barriers during their incorporation, which, in turn, affects the overall productivity of the whole team. This problem exacerbates for Software Product Lines (SPLs), where their size and variability combine to make onboarding even more challenging, even more so for developers that are transferred from the Application Engineering team into the Domain Engineering team, who will be our target newcomers. This work presents concept maps on the role of sensemaking scaffolds to help to introduce these newcomers into the SPL domain. Concept maps, used as knowledge visualisation tools, have been\u00a0\u2026", "num_citations": "1\n", "authors": ["1513"]}
{"title": "Volunteering for Linked Data Wrapper maintenance: A platform perspective\n", "abstract": " Linked Data Wrappers (LDWs) turn Web APIs into RDF end-points, leveraging the Linked Open Data cloud with current data. Unfortunately, LDWs are fragile upon upgrades on the underlying APIs, compromising LDW stability. Hence, for API-based LDWs to become a sustainable foundation for the Web of Data, we should recognize LDW maintenance as a continuous effort that outlives their breakout projects. This is not new in Software Engineering. Other projects in the past faced similar issues. The strategy: becoming open source and turning towards dedicated platforms. By making LDWs open, we permit others not only to inspect (hence, increasing trust and consumption), but also to maintain (to cope with API upgrades) and reuse (to adapt for their own purposes). Promoting consumption, adaptation and reuse might all help to increase the user base, and in so doing, might provide the critical mass of volunteers\u00a0\u2026", "num_citations": "1\n", "authors": ["1513"]}
{"title": "Change Analysis of #if-def Blocks with FeatureCloud\n", "abstract": " FeatureCloud is a git client for the visualization of evolution in annotated SPL, ie those resorting to ifdefs for variability. Specifically, FeatureCloud (1) mines git repositories;(2) extracts ifdefs;(3) works out differences between two versions of the same ifdefs;(4) abstracts ifdefs in terms of their code churn, tangling and scattering; and finally (5), aggregates and visualizes these properties through\" feature clouds\". Feature clouds aim to play the same role for SPLs that\" word clouds\" for textual content: provide an abstract view of the occurrence of features along evolving code, where\" repetition\" account for scattering and tangling of features. Here, we introduce the analysis goals, the perspective (ie the object of analysis) and visualization strategies that underpin FeatureCloud.", "num_citations": "1\n", "authors": ["1513"]}
{"title": "Strategic Reading & Conceptual Modeling\n", "abstract": " \u201cStrategic reading\u201d is a term coined to conceive reading as a process of constructing meaning by interacting with text. While reading, individuals use their prior knowledge along with clues from the text to construct meaning, and place the new knowledge within this frame. Strategic reading is then a pivotal ability for conceptual modelers, more so if domain knowledge needs to be acquired mainly from the literature as it is the case for research projects. But this might turn problematic. In Quora and other PhD forums, students moan about their frustrating reading and literature review experiences. Traditionally, students are encouraged to annotate while reading. Digital annotations are expected to be useful for supporting comprehension and interpretation. Our belief is that strategic reading (and hence, conceptual modeling) can be more effective if annotation is conducted in direct relationship to a main research\u00a0\u2026", "num_citations": "1\n", "authors": ["1513"]}
{"title": "Linked Data Wrappers atop Yahoo's YQL.\n", "abstract": " The Yahoo Query Language (YQL) specializes on providing a framework for abstracting developers from the heterogeneity of API requests and its optimization [1]. This specialization is what makes YQL attractive for LDW development. YQL abstracts APIs through the so-called Open Data Tables (ODT). As an example, consider Last. fm. This is a music website that provides information about musical events through an Open API1. ODTs abstract API specifics through a table-like view. Figure 1 shows the ODT for the service lastfm. event. getInfo2. Main tags include< meta> and< bindings>. The former contains descriptive information about the ODT such as author, description or documentation link 3-5). The bindings indicate how YQL operations are mapped into API calls. An entry exists for each operation (eg< select>). The sample case illustrates the SELECT case (10-16):< url> accounts for the URL pattern to invoke whereas< inputs> denotes the possible YQL statement input field. Each field (eg event) accounts for variables to be instantiated when SELECT is enacted. YQL promotes reuse through ODTs so that the YQL community can tap on someone else\u2019s ODT for their own developments. ODTs provide a good starting point for LDWs. This entails a double wrapping: YQL wraps APIs as tables while LDWs wrap tables as linked data. Grounding and lifting concerns are considered during the second wrapping. Back to our running example, this is achieved as follows (see Figure 1). YQL\u2019s sampleQuery tag is used to describe the URI pattern (line 6) and the URI grounding (line 7). When a linked wrapper server receives a URI, it identifies the ODT at\u00a0\u2026", "num_citations": "1\n", "authors": ["1513"]}
{"title": "Integrating microblogging into domain specific language editors\n", "abstract": " Micro logging is emerging as a suitable means for question-answering in working settings. This leads to different efforts to seamlessly integrate microblogging into the daily-used tools. Specifically, microblogging is being regarded as particularly useful during software development, akin to the tradition of Q&A forums. This paper looks at a particular kind of software: the one being developed by domain experts through the use of Domain Specific Languages (DSLs). We believe this setting is specially amenable to benefit from Q&A microblogging due to inherent limitations of the target audience. This brings the twist of domain specific ness into microblogging, i.e. the Q&A process is now framed by the semantics of the DSL constructs. This permits the introduction of editing assistants that embed domain knowledge about the kind of questions that can be posed, and the way answers can be selected. This opens an\u00a0\u2026", "num_citations": "1\n", "authors": ["1513"]}
{"title": "WikiLayer: annotation for Wikipedia\n", "abstract": " Reading Wikipedia is the entry to more involved activities such as editing. However, the jump from reading to editing could be too big for some wikipedians who can be intimidated by exposing their content to public scrutiny. Annotating might foster not only reading but also be the prelude to editing. Different annotation tools exist for the Web (eg, Diigo, A. nnotate). Being a Web application, Wikipedia can benefit from these tools. However, general-purpose annotation tools do not make annotation a natural gesture within Wikipedia. That is, annotation editing, rendering or retrieval in eg Diigo is dissociated from the edition, rendering or location of articles in Wikipedia, hindering the role of annotation as the prelude to article edition. WikiLayer is a Wikipedia-specific annotation tool. The implications include:(1) wikinotes (ie annotations on Wikipedia articles) might be WikiText formatted;(2) wikinote rendering is seamlessly\u00a0\u2026", "num_citations": "1\n", "authors": ["1513"]}
{"title": "NoCmodel: An extensible framework for Network-on-Chips modeling\n", "abstract": " Network-on-Chips (NoC) is an emerging concept to address the growing complexity in digital electronics systems. However, current design methodology is based on traditional HDL languages written manually or with the help of code generation tools. In order to deal with NoC design and management we create NoCModel: an extensible framework for NoC modeling based on Python language, with support for simulation and code generation. This paper presents the motivation behind the build and use of this tool, the capabilities currently present in it, an explanation of the core and its add-ons and some results obtained from it.", "num_citations": "1\n", "authors": ["1513"]}
{"title": "Authoring and annotation of desktop files in seMouse.\n", "abstract": " Coping with an increasing number of files is one of the challenges of current desktops. Adding semantic capabilities is one possible solution. Aligned with this proposal, this work introduces the notion of \u201cknowledge folder\u201d as a coarse set of documents bound together by a common ontology. The ontology plays the role of a clipboard which can be transparently accessed by the file editors to either export (ie annotation) or import (ie authoring) metadata within the knowledge folder. Traditional desktop operations are now re-interpreted and framed by this ontology: copy&paste becomes annotation&authoring, and folder digging becomes property traversal. However, a desktop setting requires seamless tooling for these ideas to get through. To this end, this work proposes the use of the mouse as the \u201csemantic device\u201d. Through the mouse, the user can classify, annotate, author, and locate a file as a resource of the underlying ontology. Moreover, being editor-independent, the mouse accounts for portability and maintainability to face the myriad of formats and editors which characterizes current desktops. The \u201csemantic mouse\u201d is implemented as a plug-in for Windows.", "num_citations": "1\n", "authors": ["1513"]}
{"title": "Improving self-interpretation of XML-based business documents by introducing derived elements\n", "abstract": " XML is becoming the standard for document description in a B2B setting, and XML Schema is gaining wide acceptance as the schema language to define the structure of these documents. Business documents such as those currently found in B2B applications, frequently comprise derived elements, i.e. elements whose content can be calculated through a deriving function that examines the content of other elements. Based on this observation, this work advocates incorporating the notion of derived elements in XML Schema. Despite its wide presence, the notion of derived elements is not yet supported in XML Schema. To this end two issues are addressed: (1) the implicitness of current approaches to deriving function support for XML documents, and (2) the externality of some deriving data which participate in the deriving function. These aspects are respectively tackled both (1) by moving the derivation semantics\u00a0\u2026", "num_citations": "1\n", "authors": ["1513"]}
{"title": "XDerive: a namespace for defining derived elements in XML Schema\n", "abstract": " XML is becoming the standard for document description in a B2B setting, and XML Schema is gaining wide acceptance as the schema language to define the structure of these documents. Transactional documents as those currently found in B2B applications, frequently comprise derived elements, ie elements whose content can be calculated through deriving function that examines the content of other elements. Based on this observation, this work advocates incorporating the notion of derived element in XML Schema. Despite its wide presence, the notion of derived element is not yet supported in XML Schema. To this end two issues are addressed:(1) the implicitness of current approaches to deriving function support for XML documents, and (2) the externality of some deriving data which participate in the deriving function. These aspects are respectively tackled both by (1) moving the derivation semantics to the document schema, and (2) by proposing an attachment where the deriving elements are recorded. These ideas have been realized by extending the Oracles XML Parser. Now, this parser can be configured to become \u201cderivation aware\u201d. That is, the deriving functions can now be found in the XML Schema. At parsing time, these functions are interpreted, and the returned values become the content of the associated derived elements.", "num_citations": "1\n", "authors": ["1513"]}
{"title": "An Overview on XML Initiatives to Bring Modularization to Web Application Development.\n", "abstract": " The increasing growth in size and complexity of web applications requires a systematic way to web application development that is able to incorporate the stringent demands imposed on both the development and maintenance of these systems. In the past a common strategy to alleviate these problems has been modularization. This paper outlines distinct initiatives within the XML research that attempt to present alternatives for accomplishing modularization at distinct levels of a Web application. The initiatives compared in this paper include XLink, the Web Composition Markup Language, the Web Object Composition Model, and the", "num_citations": "1\n", "authors": ["1513"]}
{"title": "A client-intensive, model-based approach to web application development: The AtariX system\n", "abstract": " Web application development is currently suffering from a severe bottleneck as the gap between available implementation tools and application's requirements is enlarging. There is tremendous pressure on developers to \u201ccode-and-publish\u201d. And the background of developers can be quite diverse with typically no experience in software engineering. They are guided by the features in the tools and language constructs. This free-form style of development can lead \u201cto use ad-hoc, hacker-type approaches, which lack rigor, systematic techniques, sound methodologies, and quality assurance\"| 3|. And these practices can be disastrous as web masters have to face maintenance. This situation is specially stressful in the area of e-commerce. In today's e-commerce world, companies should adapt to changing conditions and rapid cvolution. Some practitioners have roportcd that \u201cmost web sites today change their\u00a0\u2026", "num_citations": "1\n", "authors": ["1513"]}
{"title": "Dise\u00f1o basado en componentes: alternativas en el paso de partici\u00f3n\n", "abstract": " Recientemente han surgido diferentes m\u00e9todos para el dise\u00f1o basado en componentes (DBC). Estos m\u00e9todos conforman un conjunto de gu\u00edas en el proceso de gestaci\u00f3n e interconexi\u00f3n de componentes. Este trabajo examina el enfoque que se da en algunas de estas propuestas a la etapa de partici\u00f3n de componentes. El resultado de las mismas se muestra para un ejemplo com\u00fan. La diferencia de los resultados obtenidos pone en evidencia la necesidad de unos criterios que ayuden a decidir la alternativa m\u00e1s razonable en cada caso.", "num_citations": "1\n", "authors": ["1513"]}
{"title": "A Tool for defining the semantics of prescriptive tags\n", "abstract": " The most common role of tags is descriptive. However, this work focuses on \u201cprescriptive tags\u201d that have associated some implicit behaviour in the user\u2019s mind. We introduce the notion of \u201creactive tags\u201d as a means for tagging to impact sites other than the tagging site itself. The operational semantics of reactive tags is defined through event-conditionaction rules. The specification of this behaviour semantics is hidden through a graphical interface that permits users with no programming background to easily associate \u201creactions\u201d to the act of tagging. This contribution presents a demo on TABASCO, a tool that supports the specification and enactment of reactive tags.", "num_citations": "1\n", "authors": ["1513"]}
{"title": "Coarse-grained delivery units: from HTML pages to XML Leaflets\n", "abstract": " Web applications traditionally follow a thinbrowser architecture whereby all of the application control resides on the server, and the browser is only used for rendering purposes. This makes sense for B2C applications where no control is held on the browser configuration. However, this architecture can overload the server and slow down the promptness of the site. B2B applications, which are characterized by a establishment of tighter links among partners, can gain benefit from a thick-browser architecture where moving responsabilities to the browser can lead to a reduction in network traffic and an improvement in the promptness of the site. This paper explores this kind of architecture and proposes a coarse-grained delivery unit: the leaflet. A leaflet is a cohesive set of data from a browsing perspective (eg a catalogue). This work outlines the definition of a leaflet, presents a leaflet interpreter, and provides some time figures to assess the feasibility of this approach. The outcome is, that this architecture can pay off in a B2B setting where relationships tend to be more stable that in a B2C context. Thus, a business partner might be willing to install a plug-in if better efficiency can be obtained while accessing one of its partner sites in the future. The leaflet interpreter has been fully implemented and its use is illustrated by designing and delivering a conference site.", "num_citations": "1\n", "authors": ["1513"]}