{"title": "Spectrum enhanced dynamic slicing for better fault localization\n", "abstract": " Debugging consumes a considerable amount of time in software engineering, but it is rarely automated. In this paper, we focus on improving existing fault localization techniques. Spectrumbased fault localization (SFL) and slicing-hitting-set-computation (SHSC) are two techniques based on program execution traces. Both techniques come with small computational overhead and aid programmers to faster identify possible locations of faults. However, they have disadvantages: SHSC results in an undesirable high ranking of statements which are executed in many test cases, such as constructors. SFL operates on block level. Therefore, it cannot provide fine-grained results. We combine SHSC with SFL in order to eliminate these disadvantages. Our objective is to improve the ranking of faulty statements so that they allow for better fault localization than when using the previously mentioned methods separately. We show empirically that the resulting approach reduces the number of statements a programmer needs to check manually. In particular, we gain improvements of about 50% percent for SHSC and 25% for SFL.", "num_citations": "47\n", "authors": ["1849"]}
{"title": "Removing Coincidental Correctness in Spectrum-Based Fault Localization for Circuit and Spreadsheet Debugging\n", "abstract": " Spectrum-based fault localization (SBFL) has a wide area of application, ranging from debugging circuits over Java programs to spreadsheets. While SBFL has a low computational complexity and is easy to apply, its results are sometimes imprecise. In this paper, we address one of the reasons for the impreciseness, namely coincidental correctness. Coincidental correctness occurs when a program computes the correct result even though a faulty statement has been executed. We propose a technique which identifies potential coincidentally correct outcomes in circuits and spreadsheets. Our empirical evaluation shows that the removal of the actual coincidentally correct outcomes often positively influences the ranking of the faulty component(s). Furthermore, the evaluation shows that the proposed approach is well suited for identifying potential coincidentally correct outcomes in spreadsheets, but not in circuits.", "num_citations": "2\n", "authors": ["1849"]}
{"title": "What we can learn from how programmers debug their code\n", "abstract": " Researchers have developed numerous debugging approaches to help programmers in the debugging process, but these approaches are rarely used in practice. In this paper, we investigate how programmers debug their code and what researchers should consider when developing debugging approaches. We conducted an online questionnaire where 102 programmers provided information about recently fixed bugs. We found that the majority of bugs (69.6 %) are semantic bugs. Memory and concurrency bugs do not occur as frequently (6.9 % and 8.8 %), but they consume more debugging time. Locating a bug is more difficult than reproducing and fixing it. Programmers often use only IDE build-in tools for debugging. Furthermore, programmers frequently use a replication-observation-deduction pattern when debugging. These results suggest that debugging support is particularly valuable for memory and concurrency bugs. Furthermore, researchers should focus on the fault localization phase and integrate their tools into commonly used IDEs.", "num_citations": "1\n", "authors": ["1849"]}
{"title": "Root cause prediction based on bug reports\n", "abstract": " This paper proposes a supervised machine learning approach for predicting the root cause of a given bug report. Knowing the root cause of a bug can help developers in the debugging process\u2014either directly or indirectly by choosing proper tool support for the debugging task. We mined 54755 closed bug reports from the issue trackers of 103 GitHub projects and applied a set of heuristics to create a benchmark consisting of 10459 reports. A subset was manually classified into three groups (semantic, memory, and concurrency) based on the bugs\u2019 root causes. Since the types of root cause are not equally distributed, a combination of keyword search and random selection was applied. Our data set for the machine learning approach consists of 369 bug reports (122 concurrency, 121 memory, and 126 semantic bugs). The bug reports are used as input to a natural language processing algorithm. We evaluated the\u00a0\u2026", "num_citations": "1\n", "authors": ["1849"]}
{"title": "Spectrum-based fault localization for spreadsheets: Influence of correct output cells on the fault localization quality\n", "abstract": " Spreadsheets used in companies often contain several thousand formulas. The localization of faulty cells in such large spreadsheets could be time-consuming and frustrating. Spectrum-based fault localization (SFL) supports users in faster locating the faulty cell (s). However, SFL depends on the information the user provides. In this paper, we address three research questions in this context: (RQ1) Do spreadsheets contain correct output cells that positively or negatively influence the ranking of the faulty cells? (RQ2) If yes, is it possible to a-priori determine which correct output cells would positively influence the ranking? (RQ3) Is it possible to avoid a decreasing fault localization quality when adding more correct output cells? This paper shows that there exist correct output cells which positively or negatively influence the ranking. In particular, correct output cells with the largest cones positively influence the ranking\u00a0\u2026", "num_citations": "1\n", "authors": ["1849"]}