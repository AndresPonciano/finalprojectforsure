{"title": "Variability-aware parsing in the presence of lexical macros and conditional compilation\n", "abstract": " In many projects, lexical preprocessors are used to manage different variants of the project (using conditional compilation) and to define compile-time code transformations (using macros). Unfortunately, while being a simple way to implement variability, conditional compilation and lexical macros hinder automatic analysis, even though such analysis is urgently needed to combat variability-induced complexity. To analyze code with its variability, we need to parse it without preprocessing it. However, current parsing solutions use unsound heuristics, support only a subset of the language, or suffer from exponential explosion. As part of the TypeChef project, we contribute a novel variability-aware parser that can parse almost all unpreprocessed code without heuristics in practicable time. Beyond the obvious task of detecting syntax errors, our parser paves the road for further analysis, such as variability-aware type\u00a0\u2026", "num_citations": "289\n", "authors": ["1507"]}
{"title": "Variability Modeling in the Real\n", "abstract": " Abstract (EN) Variability modeling is one of the key disciplines to cope with complex variability in large software product lines. It aims at creating, evolving, and configuring variability models, which describe the common and variable characteristics, also known as features, of products in a product line. Since the introduction of feature models more than twenty years ago, many variability modeling languages and notations have been proposed both in academia and industry, followed by hundreds of publications on variability modeling techniques that have built upon these theoretical foundations. Surprisingly, there are relatively few empirical studies that aim at understanding the use of such languages. What variability modeling concepts are actually used in practice? Do variability models applied in real-world look similar to those published in literature? In what technical and organizational contexts are variability models applicable? We present an empirical study that addresses this research gap. Our goals are i) to verify existing theoretical research, and ii) to explore real-world variability modeling languages and models expressed in them. We study concepts and semantics of variability modeling languages conceived by practitioners, and the usage of these concepts in real, large-scale models. Our aim is to support variability modeling research by providing empirical data about the use of its core modeling concepts, by identifying and characterizing further concepts that have not been as widely addressed, and by providing realistic assumptions about scale, structure, content, and complexity of real-world variability models. We believe that our\u00a0\u2026", "num_citations": "207\n", "authors": ["1507"]}
{"title": "An examination of the current rating system used in mobile app stores\n", "abstract": " Unlike products on Amazon.com, mobile apps are continuously evolving, with new versions rapidly replacing the old ones. Nevertheless, many app stores still use an Amazon-style rating system, which aggregates every rating ever assigned to an app into one store rating. To examine whether the store rating captures the changing user satisfaction levels regarding new app versions, researchers mined the store ratings of more than 10,000 mobile apps in Google Play, every day for a year. Even though many apps' version ratings rose or fell, their store rating was resilient to fluctuations once they had gathered a substantial number of raters. The conclusion is that current store ratings aren't dynamic enough to capture changing user satisfaction levels. This resilience is a major problem that can discourage developers from improving app quality.", "num_citations": "84\n", "authors": ["1507"]}
{"title": "Maintaining Feature Traceability with Embedded Annotations\n", "abstract": " Features are commonly used to describe functional and nonfunctional aspects of software. To effectively evolve and reuse features, their location in software assets has to be known. However, locating features is often difficult given their crosscutting nature. Once implemented, the knowledge about a feature's location quickly deteriorates, requiring expensive recovering of these locations. Manually recording and maintaining traceability information is generally considered expensive and error-prone. In this paper, we argue to the contrary and hypothesize that such information can be effectively embedded into software assets, and that arising costs will be amortized by the benefits of this information later during development. We test this hypothesis in a study where we simulate the development of a product line of cloned/forked projects using a lightweight code annotation approach. We identify annotation evolution\u00a0\u2026", "num_citations": "67\n", "authors": ["1507"]}
{"title": "Principles of Feature Modeling\n", "abstract": " Feature models are arguably one of the most intuitive and successful notations for modeling the features of a variant-rich software system. Feature models help developers to keep an overall understanding of the system, and also support scoping, planning, development, variant derivation, configuration, and maintenance activities that sustain the system's long-term success. Unfortunately, feature models are difficult to build and evolve. Features need to be identified, grouped, organized in a hierarchy, and mapped to software assets. Also, dependencies between features need to be declared. While feature models have been the subject of three decades of research, resulting in many feature-modeling notations together with automated analysis and configuration techniques, a generic set of principles for engineering feature models is still missing. It is not even clear whether feature models could be engineered using\u00a0\u2026", "num_citations": "45\n", "authors": ["1507"]}
{"title": "FLOrIDA: Feature LOcatIon DAshboard for Extracting and Visualizing Feature Traces\n", "abstract": " Features are high-level, domain-specific abstractions over implementation artifacts. Developers use them to communicate and reason about a system, in order to maintain and evolve it. These activities, however, require knowing the locations of features---a common challenge when a system has many developers, many (cloned) variants, or a long lifespan. We believe that embedding feature-location information into software artifacts via annotations eases typical feature-related engineering tasks, such as modifying and removing features, or merging cloned features into a product line. However, regardless of where such annotations stem from---whether embedded by developers when writing code, or retroactively recovered using a feature-location technique---tool support is needed for developers to exploit such annotations.", "num_citations": "41\n", "authors": ["1507"]}
{"title": "Specification Patterns for Robotic Missions\n", "abstract": " Mobile and general-purpose robots increasingly support our everyday life, requiring dependable robotics control software. Creating such software mainly amounts to implementing their complex behaviors known as missions. Recognizing this need, a large number of domain-specific specification languages has been proposed. These, in addition to traditional logical languages, allow the use of formally specified missions for synthesis, verification, simulation or guiding implementation. For instance, the logical language LTL is commonly used by experts to specify missions as an input for planners, which synthesize the behavior a robot should have. Unfortunately, domain-specific languages are usually tied to specific robot models, while logical languages such as LTL are difficult to use by non-experts. We present a catalog of 22 mission specification patterns for mobile robots, together with tooling for instantiating\u00a0\u2026", "num_citations": "40\n", "authors": ["1507"]}
{"title": "Towards a Better Understanding of Software Features and Their Characteristics: A Case Study of Marlin\n", "abstract": " The notion of features is commonly used to describe, structure, and communicate the functionalities of a system. Unfortunately, features and their locations in software artifacts are rarely made explicit and often need to be recovered by developers. To this end, researchers have conceived automated feature-location techniques. However, their accuracy is generally low, and they mostly rely on few information sources, disregarding the richness of modern projects. To improve such techniques, we need to improve the empirical understanding of features and their characteristics, including the information sources that support feature location. Even though, the product-line community has extensively studied features, the focus was primarily on variable features in preprocessor-based systems, largely side-stepping mandatory features, which are hard to identify. We present an exploratory case study on identifying and\u00a0\u2026", "num_citations": "38\n", "authors": ["1507"]}
{"title": "Where is my Feature and What is it About? A Case Study on Recovering Feature Facets\n", "abstract": " Developers commonly use features to define, manage, and communicate functionalities of a system. Unfortunately, the locations of features in code and other characteristics (feature facets), relevant for evolution and maintenance, are often poorly documented. Since developers change, and knowledge fades with time, such information often needs to be recovered. Modern projects boast a richness of information sources, such as pull requests, release logs, and otherwise specified domain knowledge. However, it is largely unknown from what sources the features, their locations, and their facets can be recovered. We present an exploratory study on identifying such information in two popular, variant-rich, and long-living systems: The 3D-printer firmware Marlin and the Android application Bitcoin-wallet. Besides the available information sources, we also investigated the projects\u2019 communities, communications, and\u00a0\u2026", "num_citations": "35\n", "authors": ["1507"]}
{"title": "Towards system analysis with variability model metrics\n", "abstract": " Variability models are central artifacts in highly configurable systems. They aim at planning, developing, and configuring systems by describing configuration knowledge at different levels of formality. The existence of large models using a variety of modeling concepts in heterogeneous languages with intricate semantics calls for a unified measuring approach. In this position paper, we attempt to take a first step towards such a measurement. We discuss perspectives of metrics, define low-level measurement goals, and conceive and implement metrics based on variability modeling concepts found in real-world languages and models. An evaluation of these metrics with real-world models and codebases provides insight into the benefits of such metrics for the defined perspectives.", "num_citations": "34\n", "authors": ["1507"]}
{"title": "Features and How to Find Them: A Survey of Manual Feature Location\n", "abstract": " The notion of features is commonly used to maintain, evolve, reuse, or re-engineer a software system. To this end, developers need to understand the features and their\u2013potentially scattered\u2013locations within the codebase of a system. Unfortunately, features are rarely documented, developers\u2019 knowledge about the features fades quickly, and developers leave projects. In such cases, feature locations need to be recovered from the codebase\u2013a costly, but still one of the most common tasks performed by developers. While automated feature-location techniques have been proposed, they typically require significant adjustments to the particular system and often fall short in their accuracy. To improve this situation, it is necessary to understand how developers perform feature location manually\u2013a surprisingly neglected research area. In this chapter, we provide an overview on existing studies of manual feature location, focusing on the topics addressed in the studies and open issues. We find that the seven studies we identified analyze four topics of manual feature location in detail: Search tools, performance, influencing factors, and distinct phases. We observe that a focus of these studies is on understanding the process of manual feature location regarding the developers\u2019 activities and actions. We also find that, still, little is known about the actual efforts of performing feature location, how different factors influence these efforts, how automated techniques are scoped to the identified phases, and which additional information sources help developers to locate features.", "num_citations": "31\n", "authors": ["1507"]}
{"title": "Leveraging semantic data wikis for distributed requirements elicitation\n", "abstract": " Using Wikis for the collaborative creation of structured textual content has gained increasing importance in the past decade. As Wikis facilitate the involvement of large user groups to create content in an easy way, their application in large, spatially distributed software development efforts seems to be very promising. In this context, we present a classification of Wiki-based approaches to requirements engineering (RE) and discuss their suitability. Next, we introduce the ontology of an approach that aims at supporting the collaboration of stakeholders with regard to the RE process. This approach enables large stakeholder groups to elicit, semantically structure and classify requirements in the very early and creative RE phases. Instead of leveraging text-based Wikis, the approach is based on our semantic data Wiki OntoWiki, which focuses on the structuring and management of fine-grained data by employing\u00a0\u2026", "num_citations": "29\n", "authors": ["1507"]}
{"title": "Semi-Automated Feature Traceability with Embedded Annotations\n", "abstract": " Engineering software amounts to implementing and evolving features. While some engineering approaches advocate the explicit use of features, developers usually do not record feature locations in software artifacts. However, when evolving or maintaining features - especially in long-living or variant-rich software with many developers - the knowledge about features and their locations quickly fades and needs to be recovered. While automated or semi-automated feature-location techniques have been proposed, their accuracy is usually too low to be useful in practice. We propose a semi-automated, machine-learning-assisted feature-traceability technique that allows developers to continuously record feature-traceability information while being supported by recommendations about missed locations. We show the accuracy of our proposed technique in a preliminary evaluation, simulating the engineering of an\u00a0\u2026", "num_citations": "28\n", "authors": ["1507"]}
{"title": "PEoPL: Projectional Editing of Product Lines\n", "abstract": " The features of a software product line - a portfolio of system variants - can be realized using various implementation techniques (a. k. a., variability mechanisms). Each technique represents the software artifacts of features differently, typically classified into annotative (e.g., C preprocessor) and modular representations (e.g., feature modules), each with distinct advantages and disadvantages. Annotative representations are easy to realize, but annotations clutter source code and hinder program comprehension. Modular representations support comprehension, but are difficult to realize. Most importantly, to engineer feature artifacts, developers need to choose one representation and adhere to it for evolving and maintaining the same artifacts. We present PEoPL, an approach to combine the advantages of annotative and modular representations. When engineering a feature artifact, developers can choose the most\u00a0\u2026", "num_citations": "27\n", "authors": ["1507"]}
{"title": "An Architecture for Decentralized, Collaborative, and Autonomous Robots\n", "abstract": " Robotic applications are typically realized using ad hoc and domain-specific solutions, which challenges the engineering and cross-project reuse of such applications. Especially in complex scenarios, where self-adaptive robots collaborate among themselves or with humans, the effective and systematic engineering of such applications is becoming increasingly important. Such scenarios require decentralized software architectures that foster fault-tolerant ways of managing large teams of (possibly) heterogeneous robots. To the best of our knowledge, no existing architecture for robot applications supports decentralized and self-adaptive collaboration. To address this gap, we conducted a design science study with 21 practitioners and experts in the field of robotics to develop an architecture fulfilling these requirements through several iterations. We present SERA, an architecture for robot applications that supports\u00a0\u2026", "num_citations": "26\n", "authors": ["1507"]}
{"title": "Service-Oriented Product Lines: Towrads a Development Process and Feature Management Model for Web Services.\n", "abstract": " Service-Oriented Architecture fosters the loose coupling of services aimed at maximizing flexibility, adaptability and configurability. Services of different providers can easily be integrated into a common framework with standardized technology like Web Services. A Software Product Line depicts a systematic software reuse approach by handling various types of flexible software artifacts that form a common platform and are the basis for deriving concrete products. This paper contributes towards the combination of both concepts by proposing a differentiated development process for Software Product Lines implementing a Service-Oriented Architecture. An extensive example shows how parts of this process can be solved technically with already developed methods for feature modeling and management using Web Services.", "num_citations": "26\n", "authors": ["1507"]}
{"title": "PsALM: Specification of Dependable Robotic Missions\n", "abstract": " Engineering dependable software for mobile robots is becoming increasingly important. A core asset to engineering mobile robots is the mission specification - a description of the mission that mobile robots shall achieve. Mission specifications are used, among others, to synthesize, verify, simulate or guide the engineering of robot software. However, development of precise mission specifications is challenging, as engineers need to translate requirements into specification structures often expressed in a logical language - a laborious and error-prone task. Specification patterns, as solutions for recurrent specification problems have been recognized as a solution for this problem. Each pattern details the usage intent, known uses, relationships to other patterns, and-most importantly-a template mission specification in temporal logic. Patterns constitute reusable building blocks that can be used by engineers to create\u00a0\u2026", "num_citations": "22\n", "authors": ["1507"]}
{"title": "Higher-Level Mission Specification for Multiple Robots\n", "abstract": " Mobile robots are increasingly used in our everyday life to autonomously realize missions. A variety of languages has been proposed to support roboticists in the systematic development of robotic applications, ranging from logical languages with well-defined semantics to domain-specific languages with user-friendly syntax. The characteristics of both of them have distinct advantages, however, developing a language that combines those advantages remains an elusive task. We present PROMISE, a novel language that enables domain experts to specify missions on a high level of abstraction for teams of autonomous robots in a user-friendly way, while having well-defined semantics. Our ambition is to permit users to specify high-level goals instead of a series of specific actions the robots should perform. The language contains a set of atomic tasks that can be executed by robots and a set of operators that allow the\u00a0\u2026", "num_citations": "21\n", "authors": ["1507"]}
{"title": "Robotics Software Engineering: A Perspective from the Service Robotics Domain\n", "abstract": " Robots that support humans by performing useful tasks (aka, service robots) are booming worldwide. In contrast to industrial robots, the development of service robots comes with severe software engineering challenges, since they require high levels of robustness and autonomy to operate in highly heterogeneous environments. As a domain with critical safety implications, service robotics faces a need for sound software development practices. In this paper, we present the first large-scale empirical study to assess the state of the art and practice of robotics software engineering. We conducted 18 semi-structured interviews with industrial practitioners working in 15 companies from 9 different countries and a survey with 156 respondents from 26 countries from the robotics domain. Our results provide a comprehensive picture of (i) the practices applied by robotics industrial and academic practitioners, including\u00a0\u2026", "num_citations": "20\n", "authors": ["1507"]}
{"title": "Facing the Truth: Benchmarking the Techniques for Evolving Variant-Rich Systems\n", "abstract": " The evolution of variant-rich systems is a challenging task. To support developers, the research community has proposed a range of different techniques over the last decades. However, many techniques have not been adopted in practice so far. To advance such techniques and to support their adoption, it is crucial to evaluate them against realistic baselines, ideally in the form of generally accessible benchmarks. To this end, we need to improve our empirical understanding of typical evolution scenarios for variant-rich systems and their relevance for benchmarking. In this paper, we establish eleven evolution scenarios in which benchmarks would be beneficial. Our scenarios cover typical lifecycles of variant-rich system, ranging from clone & own to adopting and evolving a configurable product-line platform. For each scenario, we formulate benchmarking requirements and assess its clarity and relevance via a\u00a0\u2026", "num_citations": "20\n", "authors": ["1507"]}
{"title": "Activities and Costs of Re-Engineering Cloned Variants Into an Integrated Platform\n", "abstract": " Many software systems need to exist in multiple variants. Organizations typically develop variants using clone&own---copying and adapting systems towards new requirements. However, while clone & own is a simple and readily available strategy, it does not scale with the number of variants, and then requires a costly reengineering of the cloned variants into a configurable software platform (aka, software product line). Ideally, organizations could rely on decision models or at least on substantial empirical data to assess the costs and benefits of such a re-engineering. Unfortunately, despite decades of research on product lines and platforms, such data is scarce, not least because obtaining it from industrial reengineering efforts is challenging. We address this gap with a study on re-engineering two cases of cloned variants of open-source Android and Java games. Student developers re-engineered the clones into\u00a0\u2026", "num_citations": "18\n", "authors": ["1507"]}
{"title": "Property specification patterns for robotic missions\n", "abstract": " Engineering dependable software for mobile robots is becoming increasingly important. A core asset in engineering mobile robots is the mission specification---a formal description of the goals that mobile robots shall achieve. Such mission specifications are used, among others, to synthesize, verify, simulate, or guide the engineering of robot software. Development of precise mission specifications is challenging. Engineers need to translate the mission requirements into specification structures expressed in a logical language---a laborious and error-prone task.", "num_citations": "17\n", "authors": ["1507"]}
{"title": "Static analysis of app dependencies in android bytecode\n", "abstract": " Android applications (apps) are highly interactive, but have\u2014by design\u2014no facilities to declare dependencies reflecting such interactions. Dependencies are hidden in code and uncovering them requires static analysis techniques. This technical note presents our static analysis infrastructure to extract dependency information from Android (Dalvik) bytecode. This infrastructure is used in a study of variability mechanisms in software ecosystems [5]. In the present paper, we provide details on the implementation, our dataset, and the statistics we calculated.", "num_citations": "16\n", "authors": ["1507"]}
{"title": "Promote-pl: A Round-Trip Engineering Process Model for Adopting and Evolving Product Lines\n", "abstract": " Process models for software product-line engineering focus on proactive adoption scenarios---that is, building product-line platforms from scratch. They comprise the two phases domain engineering (building a product-line platform) and application engineering (building individual variants), each of which defines various development activities. Established more than two decades ago, these process models are still the de-facto standard for steering the engineering of platforms and variants. However, observations from industrial and open-source practice indicate that the separation between domain and application engineering, with their respective activities, does not fully reflect reality. For instance, organizations rarely build platforms from scratch, but start with developing individual variants that are re-engineered into a platform when the need arises. Organizations also appear to evolve platforms by evolving\u00a0\u2026", "num_citations": "15\n", "authors": ["1507"]}
{"title": "Variability Modeling of Service Robots: Experiences and Challenges\n", "abstract": " Sensing, planning, controlling, and reasoning, are human-like capabilities that can be artificially replicated in an autonomous robot. Such a robot implements data structures and algorithms devised on a large spectrum of theories, from probability theory, mechanics, and control theory to ethology, economy, and cognitive sciences. Software plays a key role in the development of robotic systems, as it is the medium to embody intelligence in the machine. During the last years, however, software development is increasingly becoming the bottleneck of robotic systems engineering due to three factors:(a) the software development is mostly based on community efforts and it is not coordinated by key stakeholders;(b) robotic technologies are characterized by a high variability that makes reuse of software a challenging practice; and (c) robotics developers are usually not specifically trained in software engineering. In this\u00a0\u2026", "num_citations": "15\n", "authors": ["1507"]}
{"title": "Model Transformation Languages Under a Magnifying Glass - A Controlled Experiment with Xtend, ATL, and QVT\n", "abstract": " In Model-Driven Software Development, models are automatically processed to support the creation, build, and execution of systems. A large variety of dedicated model-transformation languages exists, promising to efficiently realize the automated processing of models. To investigate the actual benefit of using such specialized languages, we performed a large-scale controlled experiment in which over 78 subjects solve 231 individual tasks using three languages. The experiment sheds light on commonalities and differences between model transformation languages (ATL, QVT-O) and on benefits of using them in common development tasks (comprehension, change, and creation) against a modern general-purpose language (Xtend). Our results show no statistically significant benefit of using a dedicated transformation language over a modern general-purpose language. However, we were able to identify several\u00a0\u2026", "num_citations": "15\n", "authors": ["1507"]}
{"title": "Model Transformation Languages Under a Magnifying Glass -- A Controlled Experiment with Xtend, ATL, and QVT\n", "abstract": " In Model-Driven Software Development, models are automatically processed to support the creation, build, and execution of systems. A large variety of dedicated model-transformation languages exists, promising to efficiently realize the automated processing of models. To investigate the actual benefit of using such specialized languages, we performed a large-scale controlled experiment in which over 78 subjects solve 231 individual tasks using three languages. The experiment sheds light on commonalities and differences between model transformation languages (ATL, QVT-O) and on benefits of using them in common development tasks (comprehension, change, and creation) against a modern general-purpose language (Xtend). Our results show no statistically significant benefit of using a dedicated transformation language over a modern general-purpose language. However, we were able to identify several\u00a0\u2026", "num_citations": "15\n", "authors": ["1507"]}
{"title": "An Empirical Analysis of the Costs of Clone- and Platform-Oriented Software Reuse\n", "abstract": " Software reuse lowers development costs and improves the quality of software systems. Two strategies are common: clone & own (copying and adapting a system) and platform-oriented reuse (building a configurable platform). The former is readily available, flexible, and initially cheap, but does not scale with the frequency of reuse, imposing high maintenance costs. The latter scales, but imposes high upfront investments for building the platform, and reduces flexibility. As such, each strategy has distinctive advantages and disadvantages, imposing different development activities and software architectures. Deciding for one strategy is a core decision with long-term impact on an organization\u2019s software development. Unfortunately, the strategies\u2019 costs are not well-understood-not surprisingly, given the lack of systematically elicited empirical data, which is difficult to collect. We present an empirical study of the\u00a0\u2026", "num_citations": "14\n", "authors": ["1507"]}
{"title": "Variability modeling in the wild\n", "abstract": " Variability modeling is one of the key disciplines in software product line engineering and has been addressed by academic and industrial research over the past twenty years. While the research community's focus was on creating notations and tools, most of which based on feature modeling, there are relatively few empirical studies that aim at understanding the actual use of these techniques.", "num_citations": "13\n", "authors": ["1507"]}
{"title": "Migrating the Java-Based Apo-Games into a Composition-Based Software Product Line\n", "abstract": " A software product line enables an organization to systematically reuse software features that allow to derive customized variants from a common platform, promising reduced development and maintenance costs. In practice, however, most organizations start to clone existing systems and only extract a software product line from such clones when the maintenance and coordination costs increase. Despite the importance of extractive software-product-line adoption, we still have only limited knowledge on what practices work best and miss datasets for evaluating automated techniques. To improve this situation, we performed an extractive adoption of the Apo-Games, resulting in a systematic analysis of five Java games and the migration of three games into a composition-based software product line. In this paper, we report our analysis and migration process, discuss our lessons learned, and contribute a feature\u00a0\u2026", "num_citations": "12\n", "authors": ["1507"]}
{"title": "Migrating the Android Apo-Games into an Annotation-Based Software Product Line\n", "abstract": " Most organizations start to reuse software by cloning complete systems and adapting them to new customer requirements. However, with an increasing number of cloned systems, the problems of this approach become severe, due to synchronization efforts. In such cases, organizations often decide to extract a software product line, which promises to reduce development and maintenance costs. While this scenario is common in practice, the research community is still missing knowledge about best practices and needs datasets to evaluate supportive techniques. In this paper, we report our experiences with extracting a preprocessor-based software product line from five cloned Android games of the Apo-Games challenge. Besides the process we employed, we also discuss lessons learned and contribute corresponding artifacts, namely a feature model and source code. The insights into the processes help\u00a0\u2026", "num_citations": "11\n", "authors": ["1507"]}
{"title": "Multi-View Editing of Software Product Lines with PEoPL\n", "abstract": " A software product line is a portfolio of software variants in an application domain. It relies on a platform integrating common and variable features of the variants using variability mechanisms- typically classified into annotative and compositional mechanisms. Annotative mechanisms (e.g., using the C preprocessor) are easy to apply, but annotations clutter source code and feature code is often scattered across the platform, which hinders program comprehension and increases maintenance effort. Compositional mechanisms (e.g., using feature modules) support program comprehension and maintainability by modularizing feature code, but are difficult to adopt. Most importantly, engineers need to choose one mechanism and then stick to it for the whole life cycle of the platform. The PEoPL (Projectional Editing of Product Lines) approach combines the advantages of both kinds of mechanisms. In this paper, we\u00a0\u2026", "num_citations": "11\n", "authors": ["1507"]}
{"title": "A Chrestomathy of DSL Implementations\n", "abstract": " Selecting and properly using approaches for DSL implementation can be challenging, given their variety and complexity. To support developers, we present the software chrestomathy MetaLib, a well-organized and well-documented collection of DSL implementations useful for learning. We focus on basic metaprogramming techniques for implementing DSL syntax and semantics. The DSL implementations are organized and enhanced by feature modeling, semantic annotation, and model-based documentation. The chrestomathy enables side-by-side exploration of different implementation approaches for DSLs. Source code, feature model, feature configurations, semantic annotations, and documentation are publicly available online, explorable through a web application, and maintained by a collaborative process.", "num_citations": "11\n", "authors": ["1507"]}
{"title": "Eine dienste-und komponentenbasierte Architektur zur elektronischen Durchf\u00fchrung von Pr\u00fcfungen und zum Management von Lehrveranstaltungen\n", "abstract": " Die Erziehungswissenschaftliche Fakult\u00e4t setzt erfolgreich eTesting zur Abwicklung von Klausuren unter Examensbedingungen und eine Portalapplikation zur Verwaltung von Lehrveranstaltungen ein. Der Artikel stellt die entwickelten Systeme vor. Nach einer kurzen Darstellung der Ausgangssituation werden vor allem Anforderungen und die Gesamtarchitektur des Systems skizziert. Der letzte Teil gibt eine Auswertung der Erfahrungen beim Einsatz von eTesting wieder.", "num_citations": "10\n", "authors": ["1507"]}
{"title": "Feature-Oriented Defect Prediction\n", "abstract": " Software errors are a major nuisance in software development and can lead not only to reputation damages, but also to considerable financial losses for companies. Therefore, numerous techniques for predicting software defects, largely based on machine learning methods, have been developed over the past decades. These techniques usually rely on code and process metrics in order to predict defects at the granularity of typical software assets, such as subsystems, components, and files. In this paper, we present the first systematic investigation of feature-oriented defect prediction: the prediction of defects at the granularity of features---domain-oriented entities abstractly representing (and often cross-cutting) typical software assets. Feature-oriented prediction can be beneficial, since:(i) particular features might be more error-prone than others,(ii) characteristics of features known as defective might be useful to\u00a0\u2026", "num_citations": "7\n", "authors": ["1507"]}
{"title": "Variability Representations in Class Models: An Empirical Assessment\n", "abstract": " Owing to the ever-growing need for customization, software systems often exist in many different variants. To avoid the need to maintain many different copies of the same model, developers of modeling languages and tools have recently started to provide representations for such variant-rich systems, notably variability mechanisms that support the implementation of differences between model variants. Available mechanisms either follow the annotative or the compositional paradigm, each of them having unique benefits and drawbacks. Language and tool designers select the used variability mechanism often solely based on intuition. A better empirical understanding of the comprehension of variability mechanisms would help them in improving support for effective modeling.", "num_citations": "6\n", "authors": ["1507"]}
{"title": "A Common Notation and Tool Support for Embedded Feature Annotations\n", "abstract": " Features are typically used to describe the functionalities of software systems. They help understanding systems as well as planning their evolution and managing systems. Especially agile methods foster their use. However, to use features, their locations need to be known. When not documented, they are easily forgotten and then need to be recovered, which is costly. While automated feature-location techniques exist, they are not usable in practice given their inaccuracies. We take a different route and advocate to record locations early using a lightweight annotation system, where feature information is embedded in software assets. However, given the potential design space of annotations, a unified notation and tool support is needed. Extending our prior work, we present a unified, concise notation for embedded annotations, which we implemented in FAXE, a library for parsing and retrieving such annotations\u00a0\u2026", "num_citations": "6\n", "authors": ["1507"]}
{"title": "Software Product-Line Evaluation in the Large\n", "abstract": " Software product-line engineering is arguably one of the most successful methods for establishing large portfolios of software variants in an application domain. However, despite the benefits, establishing a product line requires substantial upfront investments into a software platform with a proper product-line architecture, into new software-engineering processes (domain engineering and application engineering), into business strategies with commercially successful product-line visions and financial planning, as well as into re-organization of development teams. Moreover, establishing a full-fledged product line is not always possible or desired, and thus organizations often adopt product-line engineering only to an extent that deemed necessary or was possible. However, understanding the current state of adoption, namely, the maturity or performance of product-line engineering in an organization, is challenging\u00a0\u2026", "num_citations": "5\n", "authors": ["1507"]}
{"title": "How to configure a configuration management system\u2013an approach based on feature modeling\n", "abstract": " The accomplishment of an efficient IT service management is considered a significant success factor in large businesses. Configuration Management (CM) constitutes one of its core disciplines. Off-the-shelf CM systems support the maintenance of the IT by handling the lifecycle of so-called Configuration Items (CIs) and by establishing Change, Configuration and Release Management processes. However, due to the complexity of today\u2019s IT infrastructure in large companies, the tailoring of these systems based on concrete stakeholder requirements can become a laborious and error-prone task.We present an approach that enables the configuration of a CM system by leveraging variability management techniques stemming from product line engineering. The synthesis and configuration of a feature model is driven by the Common Data Model, a large domain-specific model that describes CIs and their relationships. We show how our feature-based approach can improve the tailoring of CM systems. Furthermore, we expand on its prototypical realization, elaborate on the integration into the requirements engineering process and discuss its applicability based on experiences obtained from a first evaluation.", "num_citations": "5\n", "authors": ["1507"]}
{"title": "Seamless Variability Management With the Virtual Platform\n", "abstract": " Customization is a general trend in software engineering, demanding systems that support variable stakeholder requirements. Two opposing strategies are commonly used to create variants: software clone&own and software configuration with an integrated platform. Organizations often start with the former, which is cheap, agile, and supports quick innovation, but does not scale. The latter scales by establishing an integrated platform that shares software assets between variants, but requires high up-front investments or risky migration processes. So, could we have a method that allows an easy transition or even combine the benefits of both strategies? We propose a method and tool that supports a truly incremental development of variant-rich systems, exploiting a spectrum between both opposing strategies. We design, formalize, and prototype the variabilitymanagement framework virtual platform. It bridges clone\u00a0\u2026", "num_citations": "4\n", "authors": ["1507"]}
{"title": "Detecting Semantic Conflicts Via Automated Behavior Change Detection\n", "abstract": " Branching and merging are common practices in collaborative software development. They increase developer productivity by fostering teamwork, allowing developers to independently contribute to a software project. Despite such benefits, branching and merging comes at a cost\u2014the need to merge software and to resolve merge conflicts, which often occur in practice. While modern merge techniques, such as 3-way or structured merge, can resolve many such conflicts automatically, they fail when the conflict arises not at the syntactic, but the semantic level. Detecting such conflicts requires understanding the behavior of the software, which is beyond the capabilities of most existing merge tools. As such, semantic conflicts can only be identified and fixed with significant effort and knowledge of the changes to be merged. While semantic merge tools have been proposed, they are usually heavyweight, based on static\u00a0\u2026", "num_citations": "4\n", "authors": ["1507"]}
{"title": "Softwareproduktlinien-Entwicklung\u2013Domain Engineering: Konzepte, Probleme und L\u00f6sungsans\u00e4tze\n", "abstract": " Software Product Line Engineering (SPLE) has become the most successful approach for software reuse in the last ten years. It has proven to reduce development times, lower costs and improve the quality of software-intensive systems. One of its key points is the up-front development of a flexible and highly extensible platform (Domain Engineering) as a basis for deriving concrete applications (Application Engineering).The thesis describes the Domain Engineering in a case study that deals with the development of an Open Source project in the J2EE environment. It mainly focuses on concerns regarding the high-level architecture and process descriptions as proposed by the framework. To fit the needs of the project it also had to be tailored in numerours aspects. Furthermore, the experience gained during the lifecycle of the project yields an estimation of theoretical and practical issues of the development\u00a0\u2026", "num_citations": "4\n", "authors": ["1507"]}
{"title": "Languages for Specifying Missions of Robotic Applications\n", "abstract": " Robot application development is gaining increasing attention both from the research and industry communities. Robots are complex cyber-physical and safety-critical systems with various dimensions of heterogeneity and variability. They often integrate modules conceived by developers with different backgrounds. Programming robotic applications typically requires programming and mathematical or robotic expertise from end-users. In the near future, multipurpose robots will be used in the tasks of everyday life in environments such as our houses, hotels, airports or museums. It would then be necessary to democratize the specification of missions that robots should accomplish. In other words, the specification of missions of robotic applications should be performed via easy-to-use and accessible ways, and, at the same time, the specification should be accurate, unambiguous, and precise. This chapter\u00a0\u2026", "num_citations": "3\n", "authors": ["1507"]}
{"title": "Causes of Merge Conflicts: A Case Study of ElasticSearch\n", "abstract": " Software branching and merging allows collaborative development and creating software variants, commonly referred to as clone & own. While simple and cheap, a trade-off is the need to merge code and to resolve merge conflicts, which frequently occur in practice. When resolving conflicts, a key challenge for developer is to understand the changes that led to the conflict. While merge conflicts and their characteristics are reasonably well understood, that is not the case for the actual changes that cause them.", "num_citations": "3\n", "authors": ["1507"]}
{"title": "Asset Management in Machine Learning: A Survey\n", "abstract": " Machine Learning (ML) techniques are becoming essential components of many software systems today, causing an increasing need to adapt traditional software engineering practices and tools to the development of ML-based software systems. This need is especially pronounced due to the challenges associated with the large-scale development and deployment of ML systems. Among the most commonly reported challenges during the development, production, and operation of ML-based systems are experiment management, dependency management, monitoring, and logging of ML assets. In recent years, we have seen several efforts to address these challenges as witnessed by an increasing number of tools for tracking and managing ML experiments and their assets. To facilitate research and practice on engineering intelligent systems, it is essential to understand the nature of the current tool support for\u00a0\u2026", "num_citations": "2\n", "authors": ["1507"]}
{"title": "ConfigFix: Interactive Configuration Conflict Resolution for the Linux Kernel\n", "abstract": " Highly configurable systems are highly complex systems. The Linux kernel is arguably one of the most well-known examples. Given its vast configuration space, researchers have used it to conduct many empirical studies as well as to build dedicated methods and tools for analyzing, configuring, testing, optimizing, and maintaining the kernel. However, despite a large body of work, mainly bug fixes that were the result of such research made it back into the kernel\u2019s source tree. Unfortunately, Linux users still struggle with kernel configuration and resolving configuration conflicts, since the kernel largely lacks automated support. Additionally, there are technical and community requirements for supporting automated conflict resolution in the kernel, for example, using a pure C-based solution that uses only compatible third-party libraries (if any). With the aim of contributing back to the Linux community, we present\u00a0\u2026", "num_citations": "2\n", "authors": ["1507"]}
{"title": "A Survey on the Design Space of End-User-Oriented Languages for Specifying Robotic Missions\n", "abstract": " Mobile robots are becoming increasingly important in society. Fulfilling complex missions in different contexts and environments, robots are promising instruments to support our everyday live. As such, the task of defining the robot\u2019s mission is moving from professional developers and roboticists to the end-users. However, with the current state-of-the-art, defining missions is non-trivial and typically requires dedicated programming skills. Since end-users usually lack such skills, many commercial robots are nowadays equipped with environments and domain-specific languages tailored for end-users. As such, the software support for defining missions is becoming an increasingly relevant criterion when buying or choosing robots. Improving these environments and languages for specifying missions toward simplicity and flexibility is crucial. To this end, we need to improve our empirical understanding of the\u00a0\u2026", "num_citations": "2\n", "authors": ["1507"]}
{"title": "Feature-Oriented Traceability\n", "abstract": " [Context and Motivation] Features are commonly used to describe the functional and non-functional aspects of a system. Features are abstractions over implementation assets and understood by many different roles, including domain experts, architects, and developers. As such, features are often used for communication, planning, and keeping an overview understanding of a system. Some software-engineering methods advocate the explicit use of features, such as feature-driven development (FDD) and software product line engineering with feature modeling. Especially the latter requires abstractions (features) to cope with complex product lines\u2014portfolios of system variants tailored towards specific requirements, such as different market segments, hardware, or non-functional properties (eg, performance or energy consumption).Variants are typically developed using clone&own [3]\u2014that is, copying and adapting existing variants to new requirements. This strategy is simple and allows experimenting with new ideas and rapidly prototyping variants. However, it does not scale well, and maintaining variants quickly becomes costly. Then, variants often need to be migrated to an integrated product-line platform. Such a platform is often configurable and allows deriving variants by selecting dedicated features in a configurator tool. Unfortunately, the product-line migration is costly and risky, requiring architectural and organizational changes, as well as recovering features and their locations.", "num_citations": "2\n", "authors": ["1507"]}
{"title": "Der UebManager und das elatePortal als eTesting-Systeme\n", "abstract": " Der UebManager und das elatePortal als eTesting-Systeme Page 1 Thorsten Berger 1 Institut f\u00fcr Informatik Betriebliche Informationssysteme Der UebManager und das elatePortal als eTesting-Systeme Thorsten Berger mail@thorsten-berger.net 24.11.2005 Page 2 Thorsten Berger 2 Der UebManager und das elatePortal als eTesting-Systeme Institut f\u00fcr Informatik Betriebliche Informationssysteme 1. UebManager \u25aa \u00dcberblick \u25aa Einsatz: \u00dcbungsbetrieb BIS Online-Klausuren an der Erziehungswissenschaftl. Fakult\u00e4t, Allgemeine P\u00e4dagogik 2. elatePortal \u25aa \u00dcberblick, Ziele \u25aa Exkurs: \u201eEinf\u00fchrung in Portaltechnologie\u201c Portale Java Portlet Standard Jetspeed 2 \u25aa Architektur \u25aa Demonstration des aktuellen Systems Inhalt Page 3 Thorsten Berger 3 Der UebManager und das elatePortal als eTesting-Systeme Institut f\u00fcr Informatik Betriebliche Informationssysteme UebManager http://uebman.sourceforge.net \u2022 \u00dcbersicht \u25aa \u2026", "num_citations": "2\n", "authors": ["1507"]}
{"title": "Semi-Automated Test-Case Propagation in Fork Ecosystems\n", "abstract": " Forking provides a flexible and low-cost strategy for developers to adapt an existing project to new requirements, for instance, when addressing different market segments, hardware constraints, or runtime environments. Then, small ecosystems of forked projects are formed, with each project in the ecosystem maintained by a separate team or organization. The software quality of projects in fork ecosystems varies with the resources available as well as team experience, and expertise, especially when the forked projects are maintained independently by teams that are unaware of the evolution of other\u2019s forks. Consequently, the quality of forked projects could be improved by reusing test cases as well as code, thereby leveraging community expertise and experience, and commonalities between the projects. We propose a novel technique for recommending and propagating test cases across forked projects. We\u00a0\u2026", "num_citations": "1\n", "authors": ["1507"]}
{"title": "How Explicit Feature Traces Did Not Impact Developers\u2019 Memory\n", "abstract": " Software features are intuitive entities used to abstract and manage the functionalities of a software system, for instance, in product-line engineering and agile software development. Nonetheless, developers rarely make features explicit in code, which is why they have to perform costly program comprehension and particularly feature location to (re-)gain knowledge about the code. In a previous paper, we conducted an experiment on how explicit feature traces impact developers\u2019 program comprehension by facilitating feature location. We found that annotating features in code improved program comprehension, while decomposing them into classes had a negative impact. Additionally, but not reported in that paper, we were concerned with understanding whether the different traces would impact developers\u2019 memory regarding the code and its features. To this end, we repeatedly asked our participants questions\u00a0\u2026", "num_citations": "1\n", "authors": ["1507"]}
{"title": "A Maturity Assessment Framework for Conversational AI Development Platforms\n", "abstract": " Conversational Artificial Intelligence (AI) systems have recently sky-rocketed in popularity and are now used in many applications, from car assistants to customer support. The development of conversational AI systems is supported by a large variety of software platforms, all with similar goals, but different focus points and functionalities. A systematic foundation for classifying conversational AI platforms is currently lacking. We propose a framework for assessing the maturity level of conversational AI development platforms. Our framework is based on a systematic literature review, in which we extracted common and distinguishing features of various open-source and commercial (or in-house) platforms. Inspired by language reference frameworks, we identify different maturity levels that a conversational AI development platform may exhibit in understanding and responding to user inputs. Our framework can guide\u00a0\u2026", "num_citations": "1\n", "authors": ["1507"]}
{"title": "Experiences from Reengineering and Modularizing a Legacy Software Generator with a Projectional Language Workbench\n", "abstract": " We present a case study of migrating a legacy language infrastructure and its codebase to a projectional language workbench. Our subject is the generator tool ADS used for generating COBOL code for critical software systems. We decompose the ADS language into smaller sub-languages, which we implement as individual DSLs in the projectional language workbench JetBrains Meta Programming System (MPS). Our focus is on ADS'preprocessor sub-language, used to realize static variability by conditionally including or parameterizing target code. The modularization of ADS supports future extensions and tailoring the language infrastructure to the needs of individual customers. We re-implement the generation process of target code as chained model-to-model and model-to-text transformations. For migrating existing ADS code, we implement an importer relying on a parser in order to create a model in MPS\u00a0\u2026", "num_citations": "1\n", "authors": ["1507"]}
{"title": "Variability Models in Large-Scale Systems: A Study and a Reverse-Engineering Technique\n", "abstract": " Highly configurable systems can easily have thousands of configuration options, together with intricate configuration constraints. Variability models-higherlevel representations of options and constraints-facilitate the development of large, highly configurable systems. Since models are difficult to create and to maintain, we strive to support both activities, automating them as much as possible. To this end, we present an empirical study of real-world variability models, and static code-analysis techniques that support reverse-engineering and consistency-checking of such models.", "num_citations": "1\n", "authors": ["1507"]}