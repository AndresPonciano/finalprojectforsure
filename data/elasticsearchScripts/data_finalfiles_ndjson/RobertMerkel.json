{"title": "XML-manipulating test case prioritization for XML-manipulating services\n", "abstract": " A web service may evolve autonomously, making peer web services in the same service composition uncertain as to whether the evolved behaviors are compatible with its original collaborative agreement. Although peer services may wish to conduct regression testing to verify the agreed collaboration, the source code of the former service may be inaccessible to them. Owing to the black-box nature of peer services, traditional code-based approaches to regression testing are inapplicable. In addition, traditional techniques assume that a regression test suite for verifying a web service is available. The location to store a regression test suite is also a problem. On the other hand, we note that the rich interface specifications of a web service provide peer services with a means to formulate black-box testing strategies. In this paper, we provide a strategy for black-box service-oriented testing. We also formulate new test\u00a0\u2026", "num_citations": "52\n", "authors": ["482"]}
{"title": "Analysis and enhancements of adaptive random testing\n", "abstract": " Random testing is a standard software testing method. It is a popular method for reliability assessment, but its use for debug testing has been opposed by some authorities. Random testing does not use any information to guide test case selection, and so, it is argued, testing is less likely to be effective than other methods. Based on the observation that failures often cluster in contiguous regions, Adaptive Random Testing (ART) is a more effective random testing method. While retaining random selection of test cases, selection is guided by the idea that tests should be widely spread throughout the input domain. A simple way to implement this concept, FSCSART, involves randomly generating a number of candidates, and choosing the candidate most widely spread from any already-executed test. This method has already shown to be up to 50% more effective than random testing. This thesis examines a number of theoretical and practical issues related to ART. Firstly, an theoretical examination of the scope of adaptive methods to improve testing effectiveness is conducted. Our results show that the maximum improvement in failure detection effectiveness possible is only 50%-so ART performs close to this limit on many occasions. Secondly, the statistical validity of the previous empirical results is examined. A mathematical analysis of the sampling distribution of the various failuredetection effectiveness methods shows that the measure preferred in previous studies has a slightly unusual distribution known as the geometric distribution, and that that it and other measures are likely to show high variance, requiring very large sample sizes for accurate\u00a0\u2026", "num_citations": "36\n", "authors": ["482"]}
{"title": "Tag-based techniques for black-box test case prioritization for service testing\n", "abstract": " A web service may evolve autonomously, making peer web services in the same service composition uncertain as to whether the evolved behaviors may still be compatible to its originally collaborative agreement. Although peer services may wish to conduct regression testing to verify the original collaboration, the source code of the former service can be inaccessible to them. Traditional code-based regression testing strategies are inapplicable. The rich interface specifications of a web service, however, provide peer services with a means to formulate black-box testing strategies. In this paper, we formulate new test case prioritization strategies using tags embedded in XML messages to reorder regression test cases, and reveal how the test cases use the interface specifications of services. We evaluate experimentally their effectiveness on revealing regression faults in modified WS-BPEL programs. The results show\u00a0\u2026", "num_citations": "35\n", "authors": ["482"]}
{"title": "Does the individual matter in software testing?\n", "abstract": " Most software testing research has focused on the development of systematic, standardised, and automated testing methodologies and tools. The abilities and expertise needed to apply such techniques and tools-such as personality traits, education, and experience-have attracted a comparatively small amount of research attention. However, the limited research in the area to date provides some indication that the human traits of testers are important for effective testing. This paper presents the opinions of testers themselves, collected through an online survey, on the importance of a variety of factors that influence effective testing, including testing-specific training, experience, skills, and human qualities like dedication and general intelligence. The survey responses strongly suggest that while testing tools and training are important, human factors were similarly considered highly important. Domain knowledge, experience, intelligence, and dedication, amongst other traits, were considered crucial for a tester to be effective. As such, while systematic methodologies are important, the individual most clearly does matter in software testing.", "num_citations": "20\n", "authors": ["482"]}
{"title": "Dynamic test reconfigurationfor composite web services\n", "abstract": " This paper introduces a testing strategy that is suitable for testing service-based applications. We describe an architecture that responds to changes of service operation, operation arguments and service composition changes. Our proof-of-concept test system performs runtime testing on our model atomic and composite web services using a random testing technique. A novel change identification method was developed to capture changes at the service interface. The test system is able to identify changes that occur in service operations and operational arguments in a service description of a test candidate. Our approach uses a new method to detect changes in a service inventory. Automated reconfiguration is used to support the continuous operation of the testing systems during a test candidate change.", "num_citations": "11\n", "authors": ["482"]}
{"title": "On the improvement of a fault classification scheme with implications for white-box testing\n", "abstract": " Different testing techniques can be more or less effective on different fault types; therefore, testing methods that are most likely to detect the most common fault types should be preferred. However, to enable such a selection of testing methods, a suitable and effective fault classification scheme is essential. Much software testing research proposes techniques to generate test cases and evaluates these techniques based on some hypothesized fault classification scheme. However, there is a lack in the justification of whether such'hypothesized faults' are realistic and how often these faults occur. Recently, Pan et al. analyzed the syntactic changes in the source code, made in fixing faults, of 7 open source software projects implemented in Java. Based on their experience, they proposed a fault classification scheme with relative frequencies of each fault type. As always, readers may question whether the resulting fault\u00a0\u2026", "num_citations": "11\n", "authors": ["482"]}
{"title": "Test reconfiguration for service oriented applications\n", "abstract": " Software testing in a service oriented and/or cloud computing environment is made challenging by its dynamic and loosely coupled nature. In this work, we propose and demonstrate a methodology for capturing changes and reconfiguring test data for an atomic service based on changes in the WSDL service description. Based on our results we believe that our technique can be extended further to capture changes in composite services and services that run on the Software as a Service (SaaS) platform in cloud computing.", "num_citations": "11\n", "authors": ["482"]}
{"title": "Software reliability growth models predict autonomous vehicle disengagement events\n", "abstract": " The acceptance of autonomous vehicles is dependent on the rigorous assessment of their safety. Furthermore, the commercial viability of AV programs depends on the ability to estimate the time and resources required to achieve desired safety levels. Naive approaches to estimating the reliability and safety levels of autonomous vehicles under development are will require infeasible amounts of testing of a static vehicle configuration. To permit both the estimation of current safety, and make predictions about the reliability of future systems, I propose the use of a standard tool for modelling the reliability of evolving software systems, software reliability growth models (SRGMs). Publicly available data from Californian public-road testing of two autonomous vehicle systems is modelled using two of the best-known SRGMs. The ability of the models to accurately estimate current reliability, as well as for current testing data to predict reliability in the future after additional testing, is evaluated. One of the models, the Musa-Okumoto model, appears to be a good estimator and a reasonable predictor.", "num_citations": "6\n", "authors": ["482"]}
{"title": "Covering array constructors: An experimental analysis of their interaction coverage and fault detection\n", "abstract": " Combinatorial interaction testing (CIT) aims at constructing a covering array (CA) of all value combinations at a specific interaction strength, to detect faults that are caused by the interaction of parameters. CIT has been widely used in different applications, with many algorithms and tools having been proposed to support CA construction. To date, however, there appears to have been no studies comparing different CA constructors when only some of the CA test cases are executed. In this paper, we present an investigation of five popular CA constructors: ACTS, Jenny, PICT, CASA and TCA. We conducted empirical studies examining the five programs, focusing on interaction coverage and fault detection. The experimental results show that when there is no preference or special justification for using other CA constructors, then Jenny is recommended\u2014because it achieves better interaction coverage and fault\u00a0\u2026", "num_citations": "4\n", "authors": ["482"]}
{"title": "Towards a better understanding of testing if conditionals\n", "abstract": " Fault based testing is a technique for choosing test cases to reveal certain classes of faults. Due to limited resources and time, testing professionals use their personal experience to (1) \"guess\" which fault classes are most likely to be present and, then, (2) select appropriate testing methods to reveal such fault classes. The quality of the software depends on whether they can make a good \"guess\" about the type of faults present and then choose the right testing methods to reveal those faults. However, there is little empirical evidence available in the open literature to support these intuitions. For example, there is no empirical evidence about which types of faults are most commonly made by software developers. By examining the source code changes when faults were fixed in seven open source software artifacts, we propose to classify bug fix patterns into fault classes, and recorded the relative frequencies of those\u00a0\u2026", "num_citations": "3\n", "authors": ["482"]}
{"title": "Cloud-Based Distributed Mutation Analysis\n", "abstract": " Mutation Testing is a fault-based software testing technique which is too computationally expensive for industrial use. Cloud-based distributed computing clusters, taking advantage of the MapReduce programming paradigm, represent a method by which the long running time can be reduced. In this paper, we describe an architecture, and a prototype implementation, of such a cloud-based distributed mutation testing system. To evaluate the system, we compared the performance of the prototype, with various cluster sizes, to an existing \"state-of-the-art\" non-distributed tool, PiT. We also analysed different approaches to work distribution, to determine how to most efficiently divide the mutation analysis task. Our tool outperformed PiT, and analysis of the results showed opportunities for substantial further performance improvement.", "num_citations": "2\n", "authors": ["482"]}
{"title": "An Analysis of a fault classification scheme for Java software\n", "abstract": " Classifying software faults is an essential step in empirical analysis of fault trends. Pan et al. defined a fault classification scheme in Java software, based on automated syntactic analysis of the code changes made in fixing faults. We applied their fault classification to a subset of the faults in Checkstyle, an open source Java program, manually, to validate their method and determine whether the classification were reasonable and appropriate. While we generally found their classification scheme reasonable, we noted that some faults could be classified in multiple ways. We also found that the frequencies of fault categories in Checkstyle were significantly different to the seven artifacts studied by Pan et al., which had all shown quite similar fault category frequencies. Based on our analysis, we identified several potential improvements to their classification, permitting the classification of a larger proportion of faults. We consider implications of the combined results for fault-based testing, and propose follow-up studies to examine this issue in more detail.", "num_citations": "1\n", "authors": ["482"]}