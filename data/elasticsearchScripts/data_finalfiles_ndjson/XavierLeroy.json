{"title": "Formal verification of a realistic compiler\n", "abstract": " This paper reports on the development and formal verification (proof of semantic preservation) of CompCert, a compiler from Clight (a large subset of the C programming language) to PowerPC assembly code, using the Coq proof assistant both for programming the compiler and for proving its correctness. Such a verified compiler is useful in the context of critical software and its formal verification: the verification of the compiler guarantees that the safety properties proved on the source code hold for the executable compiled code as well.", "num_citations": "1393\n", "authors": ["661"]}
{"title": "Formal certification of a compiler back-end or: programming a compiler with a proof assistant\n", "abstract": " This paper reports on the development and formal certification (proof of semantic preservation) of a compiler from Cminor (a C-like imperative language) to PowerPC assembly code, using the Coq proof assistant both for programming the compiler and for proving its correctness. Such a certified compiler is useful in the context of formal methods applied to the certification of critical software: the certification of the compiler guarantees that the safety properties proved on the source code hold for the executable compiled code as well.", "num_citations": "893\n", "authors": ["661"]}
{"title": "A formally verified compiler back-end\n", "abstract": " This article describes the development and formal verification (proof of semantic preservation) of a compiler back-end from Cminor (a simple imperative intermediate language) to PowerPC assembly code, using the Coq proof assistant both for programming the compiler and for proving its soundness. Such a verified compiler is useful in the context of formal methods applied to the certification of critical software: the verification of the compiler guarantees that the safety properties proved on the source code hold for the executable compiled code as well.", "num_citations": "601\n", "authors": ["661"]}
{"title": "Manifest types, modules, and separate compilation\n", "abstract": " This paper presents a variant of the SML module system that introduces a strict distinction between abstract types and manifest types (types whose definitions are part of the module specification), while retaining most of the expressive power of the SML module system. The resulting module system provides much better support for separate compilation.", "num_citations": "357\n", "authors": ["661"]}
{"title": "Unboxed objects and polymorphic typing\n", "abstract": " This paper presents a program transformation that allows languages with polymorphic typing (eg ML) to be implemented with unboxed, multi-word data representations. The transformation introduces coercions between various representations, based on a typing derivation. A prototype ML compiler utilizing this transformation demonstrates important speedups.", "num_citations": "304\n", "authors": ["661"]}
{"title": "The ZINC experiment : an economical implementation of the ML language\n", "abstract": " This report details the design and implementation of the ZINC system. This is an implementation of the ML language, intended to serve as a test eld for various extensions of the language, and for new implementation techniques as well. This system is strongly oriented toward separate compilation and the production of small, standalone programs; type safety is ensured by a Modula-2-like module system. ZINC uses simple, portable techniques, such as bytecode interpretation; a sophisticated execution model helps counterbalance the interpretation overhead. Other highlights include an e cient implementation of records with inclusion (subtyping).", "num_citations": "289\n", "authors": ["661"]}
{"title": "The Objective Caml system release 3.10: Documentation and user's manual\n", "abstract": " CiNii \u8ad6\u6587 - The Objective Caml system release 3.10 : Documentation and user's manual CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e \u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u306e\u30b5\u30fc\u30d3\u30b9\u306b\u95a2\u3059\u308b\u30a2\u30f3\u30b1\u30fc\u30c8\u3092\u5b9f\u65bd\u4e2d\u3067\u3059\uff0811/11(\u6c34)-12/23(\u6c34)\uff09 CiNii Research\u30d7\u30ec \u7248\u306e\u516c\u958b\u306b\u3064\u3044\u3066 The Objective Caml system release 3.10 : Documentation and user's manual LEROY X. \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 LEROY X. \u53ce\u9332\u520a\u884c\u7269 http://caml.inria.fr/ http://caml.inria.fr/, 2007 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 \u591a\u76f8\u30ec\u30b3\u30fc\u30c9\u578b\u306b\u57fa\u3065\u304fRuby\u30d7\u30ed\u30b0\u30e9\u30e0\u306e\u578b\u63a8\u8ad6 \u677e\u672c \u5b97\u592a\u90ce , \u5357\u51fa \u9756\u5f66 \u60c5\u5831\u51e6\u7406\u5b66\u4f1a\u8ad6\u6587\u8a8c\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\uff08PRO\uff09 49(SIG3(PRO36)), 39-54, 2008-03-15 \u53c2\u8003\u6587\u732e9\u4ef6 \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u8a2d\u7acb20\u5468\u5e74 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u8ad6\u6587ID(NAID) \u2026", "num_citations": "286\n", "authors": ["661"]}
{"title": "A concurrent, generational garbage collector for a multithreaded implementation of ML\n", "abstract": " This paper presents the design and implementation of a \u201cquasi real-time\u201d garbage collector for Concurrent Caml Light, an implementation of ML with threads. This two-generation system combines a fast, asynchronous copying collector on the young generation with a non-disruptive concurrent marking collector on the old generation. This design crucially relies on the ML compile-time distinction between mutable and immutable objects.", "num_citations": "281\n", "authors": ["661"]}
{"title": "A compiled implementation of strong reduction\n", "abstract": " Motivated by applications to proof assistants based on dependent types, we develop and prove correct a strong reducer and \u00df-equivalence checker for the \u03bb-calculus with products, sums, and guarded fixpoints. Our approach is based on compilation to the bytecode of an abstract machine performing weak reductions on non-closed terms, derived with minimal modifications from the ZAM machine used in the Objective Caml bytecode interpreter, and complemented by a recursive\" read back\" procedure. An implementation in the Coq proof assistant demonstrates important speed-ups compared with the original interpreter-based implementation of strong reduction in Coq.", "num_citations": "238\n", "authors": ["661"]}
{"title": "Java bytecode verification: algorithms and formalizations\n", "abstract": " Bytecode verification is a crucial security component for Java applets, on the Web and on embedded devices such as smart cards. This paper reviews the various bytecode verification algorithms that have been proposed, recasts them in a common framework of dataflow analysis, and surveys the use of proof assistants to specify bytecode verification and prove its correctness.", "num_citations": "226\n", "authors": ["661"]}
{"title": "The Objective Caml System, release 3. 08\n", "abstract": " This part of the manual is a tutorial introduction to the Objective Caml language. A good familiarity with programming in a conventional languages (say, Pascal or C) is assumed, but no prior exposure to functional languages is required. The present chapter introduces the core language. Chapter 3 deals with the object-oriented features, and chapter 2 with the module system.", "num_citations": "219\n", "authors": ["661"]}
{"title": "Coinductive big-step operational semantics\n", "abstract": " Using a call-by-value functional language as an example, this article illustrates the use of coinductive definitions and proofs in big-step operational semantics, enabling it to describe diverging evaluations in addition to terminating evaluations. We formalize the connections between the coinductive big-step semantics and the standard small-step semantics, proving that both semantics are equivalent. We then study the use of coinductive big-step semantics in proofs of type soundness and proofs of semantic preservation for compilers. A methodological originality of this paper is that all results have been proved using the Coq proof assistant. We explain the proof-theoretic presentation of coinductive definitions and proofs offered by Coq, and show that it facilitates the discovery and the presentation of the results.", "num_citations": "216\n", "authors": ["661"]}
{"title": "Applicative functors and fully transparent higher-order modules\n", "abstract": " we present a variety of the Standard ML module system where parameterized abstract types (ie functors returning generative types) map provably equal arguments to compatible abstract types, instead of generating distinct types at each applications as in Standard ML. This extension solves the full transparency problem (how to give syntactic signatures for higher-order functors that express exactly their propagation of type equations), and also provides better support for non-closed code fragments.", "num_citations": "201\n", "authors": ["661"]}
{"title": "The OCaml System Release. 4.03\n", "abstract": " You may consider this module as providing an extension to the printf facility to provide automatic line splitting. The addition of pretty-printing annotations to your regular printf format strings gives you fancy indentation and line breaks. Pretty-printing annotations are described below in the documentation of the function Format. fprintf [25.18]. You may also use the explicit pretty-printing box management and printing functions provided by this module. This style is more basic but more verbose than the concise fprintf format strings. For instance, the sequence open_box 0; print_string\" x=\"; print_space (); print_int 1; close_box (); print_newline () that prints x= 1 within a pretty-printing box, can be abbreviated as printf\"@[% s@% i@]@.\"\" x=\" 1, or even shorter printf\"@[x=@% i@]@.\" 1. Rule of thumb for casual users of this library:\u2022 use simple pretty-printing boxes (as obtained by open_box 0);\u2022 use simple break hints as obtained by print_cut () that outputs a simple break hint, or by print_space () that outputs a space indicating a break hint;", "num_citations": "200\n", "authors": ["661"]}
{"title": "A modular module system\n", "abstract": " A simple implementation of an SML-like module system is presented as a module parameterized by a base language and its type-checker. This implementation is useful both as a detailed tutorial on the Harper\u2013Lillibridge\u2013Leroy module system and its implementation, and as a constructive demonstration of the applicability of that module system to a wide range of programming languages.", "num_citations": "185\n", "authors": ["661"]}
{"title": "Managing the complexity of large free and open source package-based software distributions\n", "abstract": " The widespread adoption of free and open source software (FOSS) in many strategic contexts of the information technology society has drawn the attention on the issues regarding how to handle the complexity of assembling and managing a huge number of (packaged) components in a consistent and effective way. FOSS distributions (and in particular GNU/Linux-based ones) have always provided tools for managing the tasks of installing, removing and upgrading the (packaged) components they were made of While these tools provide a (not always effective) way to handle these tasks on the client side, there is still a lack of tools that could help the distribution editors to maintain, on the server side, large and high-quality distributions. In this paper we present our research whose main goal is to fill this gap: we show our approach, the tools we have developed and their application with experimental results. Our\u00a0\u2026", "num_citations": "181\n", "authors": ["661"]}
{"title": "Type-based analysis of uncaught exceptions\n", "abstract": " This article presents a program analysis to estimate uncaught exceptions in ML programs. This analysis relies on unification-based type inference in a nonstandard type system, using rows to approximate both the flow of escaping exceptions (a la effect systems) and the flow of result values (a la control-flow analyses). The resulting analysis is efficient and precise; in particular, arguments carried by exceptions are accurately handled.", "num_citations": "176\n", "authors": ["661"]}
{"title": "Implementing multi-stage languages using ASTs, gensym, and reflection\n", "abstract": " The paper addresses theoretical and practical aspects of implementing multi-stage languages using abstract syntax trees (ASTs), gensym, and reflection. We present an operational account of the correctness of this approach, and report on our experience with a bytecode compiler called MetaOCaml that is based on this strategy. Current performance measurements reveal interesting characteristics of the underlying OCaml compiler, and illustrate why this strategy can be particularly useful for implementing domain-specific languages in a typed, functional setting.", "num_citations": "175\n", "authors": ["661"]}
{"title": "The Caml Light system, release 0.6: Documentation and user's manual\n", "abstract": " The CAML light system release 0.5 : documentation and user's manual - OpenGrey fra | eng OpenGrey Open System for Information on Grey literature in Europe Home Search Subjects Partners Export Help Search XML To cite or link to this reference: http://hdl.handle.net/10068/42090 Title : The CAML light system release 0.5 : documentation and user's manual Authors : Leroy, Xavier ; Mauny, Michel ; Corporate author : Institut National de Recherche en Informatique et en Automatique (INRIA), 78 - Rocquencourt (France). Unite de Recherche de Rocquencourt ; Publication year : 1992 Language : English ; Pagination/Size : 288 p. ; SIGLE classification : 09H - Computer software, programming ; Document type : R - Report ; ISBN : ISBN 2-7261-0748-6 ; Report number : INRIA--92-01 ; Other identifier : FR ; FR_ 1994:1476 ; handle : http://hdl.handle.net/10068/42090 Provenance : SIGLE ; Get a copy : INIST-CNRS - \u2026", "num_citations": "151\n", "authors": ["661"]}
{"title": "Bytecode verification on Java smart cards\n", "abstract": " This article presents a novel approach to the problem of bytecode verification for Java Card applets. By relying on prior off\u2010card bytecode transformations, we simplify the bytecode verifier and reduce its memory requirements to the point where it can be embedded on a smart card, thus increasing significantly the security of post\u2010issuance downloading of applets on Java Cards. This article describes the on\u2010card verification algorithm and the off\u2010card code transformations, and evaluates experimentally their impact on applet code size. Copyright \u00a9 2002 John Wiley & Sons, Ltd.", "num_citations": "150\n", "authors": ["661"]}
{"title": "Polymorphic type inference and assignment\n", "abstract": " We present a new approach to the polymorphic typing of data accepting in-place modification in ML-like languages. This approach is based on restrictions over type generalization, and a refined typing of functions. The type system given here leads to a better integration of imperative programming style with the purely applicative kernel of ML. In particular, generic functions that allocate mutable data can safely be given fully polymorphic types. We show the soundness of this type system, and give a type reconstruction algorithm.", "num_citations": "137\n", "authors": ["661"]}
{"title": "Security properties of typed applets\n", "abstract": " This paper formalizes the folklore result that strongly-typed applets are more secure than untyped ones. We formulate and prove several security properties that all well-typed applets possess, and identify sufficient conditions for the applet execution environment to be safe, such as procedural encapsulation, type abstraction, and systematic type-based placement of run-time checks. These results are a first step towards formal techniques for developing and validating safe execution environments for applets.", "num_citations": "129\n", "authors": ["661"]}
{"title": "Java bytecode verification: an overview\n", "abstract": " Bytecode verification is a crucial security component for Java applets, on the Web and on embedded devices such as smart cards. This paper describes the main bytecode verification algorithms and surveys the variety of formal methods that have been applied to bytecode verification in order to establish its correctness.", "num_citations": "120\n", "authors": ["661"]}
{"title": "Formal verification of translation validators: a case study on instruction scheduling optimizations\n", "abstract": " Translation validation consists of transforming a program and a posteriori validating it in order to detect a modification of itssemantics. This approach can be used in a verified compiler, provided that validation is formally proved to be correct. We present two such validators and their Coq proofs of correctness. The validators are designed for two instruction scheduling optimizations: list scheduling and trace scheduling.", "num_citations": "110\n", "authors": ["661"]}
{"title": "The CompCert C verified compiler: Documentation and user\u2019s manual\n", "abstract": " This document is the user\u2019s manual for the CompCert C verified compiler. It is organized as follows:    Chapter 1 gives an overview of the CompCert C compiler and of the formal verification of compilers.    Chapter 2 explains how to install CompCert C.    Chapter 3 explains how to use the CompCert C compiler.    Chapter 4 explains how to use the CompCert C reference interpreter.    Chapter 5 describes the subset of the ISO C99 language that is implemented by CompCert.    Chapter 6 describes the supported language extensions: pragmas, attributes, built-in functions.", "num_citations": "109\n", "authors": ["661"]}
{"title": "Abstract types and the dot notation\n", "abstract": " We investigate the use of the dot notation in the context of abstract types.  The dot notation -- that is, a.f referring to the operation f provided by the abstraction a -- is used by programming languages such as Modula-2 and CLU. We compare this notation with the Mitchell-Plotkin approach, which draws a parallel between type abstraction and (weak) existential quantification in constructive logic. The basic operations on existentials coming from logic give new insights about the meaning of type abstraction, but differ completely from the more familiar dot notation. In this paper, we formalize simple calculi equipped with the dot notation, and relate them to a more classical calculus a la Mitchell and Plotkin. This work provides some theoretical foundations for the dot notation, and suggests some useful extensions.", "num_citations": "106\n", "authors": ["661"]}
{"title": "Benchmarking implementations of functional languages with \u2018Pseudoknot\u2019, a float-intensive benchmark\n", "abstract": " Over 25 implementations of different functional languages are benchmarked using the same program, a floating-point intensive application taken from molecular biology. The principal aspects studied are compile time and execution time for the various implementations that were benchmarked. An important consideration is how the program can be modified and tuned to obtain maximal performance on each language implementation. With few exceptions, the compilers take a significant amount of time to compile this program, though most compilers were faster than the then current GNU C compiler (GCC version 2.5.8). Compilers that generate C or Lisp are often slower than those that generate native code directly: the cost of compiling the intermediate form is normally a large fraction of the total compilation time. There is no clear distinction between the runtime performance of eager and lazy implementations when\u00a0\u2026", "num_citations": "96\n", "authors": ["661"]}
{"title": "Mixin modules in a call-by-value setting\n", "abstract": " The ML module system provides powerful parameterization facilities, but lacks the ability to split mutually recursive definitions across modules, and does not provide enough facilities for incremental programming. A promising approach to solve these issues is Ancona and Zucca\u2019s mixin modules calculus CMS. However, the straightforward way to adapt it to ML fails, because it allows arbitrary recursive definitions to appear at any time, which ML does not support. In this paper, we enrich CMS with a refined type system that controls recursive definitions through the use of dependency graphs. We then develop a separate compilation scheme, directed by dependency graphs, that translate mixin modules down to a CBV \u03bb-calculus extended with a non-standard let rec construct.", "num_citations": "91\n", "authors": ["661"]}
{"title": "Dynamics in ML\n", "abstract": " Objects with dynamic types allow the integration of operations that essentially require runtime type-checking into statically-typed languages. This paper presents two extensions of the ML language with dynamics, based on our work on the CAML implementation of ML, and discusses their usefulness. The main novelty of this work is the combination of dynamics with polymorphism.", "num_citations": "88\n", "authors": ["661"]}
{"title": "A syntactic theory of type generativity and sharing\n", "abstract": " This paper presents a purely syntactic account of type generativity and sharing \u2013 two key mechanisms in the SML module system \u2013 and shows its equivalence with the traditional stamp-based description of these mechanisms. This syntactic description recasts the SML module system in a more abstract, type-theoretic framework.", "num_citations": "85\n", "authors": ["661"]}
{"title": "Polymorphism by name for references and continuations\n", "abstract": " This article investigates an ML-like language with byname semantics for polymorphism: polymorphic objects are not evaluated once for all at generalization time, but re-evaluated at each specialization. Unlike the standard ML semantics, the by-name semantics works well with polymorphic references and polymorphic continuations: the naive typing rules for references and for continuations are sound with respect to this semantics. Polymorphism by name leads to a better integration of these imperative features into the ML type discipline. Practical experience shows that it retains most of the efficiency and predictability of polymorphism by value.", "num_citations": "78\n", "authors": ["661"]}
{"title": "Polymorphic typing of an algorithmic language\n", "abstract": " The polymorphic type discipline, as in the ML language, fits well within purely applicative languages, but does not extend naturally to the main feature of algorithmic languages : in-place update of data structures. Similar typing difficulties arise with other extensions of applicative languages : logical variables, communication channels, continuation handling. This work studies (in the setting of relational semantics) two new approaches to the polymorphic typing of these non-applicative features. The first one relies on a restriction of generalization over types (the notion of dangerous variables), and on a refined typing of functional values (closure typing). The resulting type system is compatible with the ML core language, and is the most expressive type systems for ML with imperative features proposed so far. The second approach relies on switching to \"by-name\" semantics for the constructs of polymorphism, instead of the usual \"by-value\" semantics. The resulting language differs from ML, but lends itself easily to polymorphic typing. Both approaches smoothly integrate non-applicative features and polymorphic typing.", "num_citations": "78\n", "authors": ["661"]}
{"title": "Dynamics in ML\n", "abstract": " Objects with dynamic types allow the integration of operations that essentially require run-time type-checking into statically-typed languages. This paper presents two extensions of the ML language with dynamics, based on what has been done in the CAML implementation of ML, and discusses their usefulness. The main novelty of this work is the combination of dynamics with polymorphism.", "num_citations": "78\n", "authors": ["661"]}
{"title": "On-card bytecode verification for Java card\n", "abstract": " This paper presents a novel approach to the problem of bytecode verification for Java Card applets. Owing to its low memory requirements, our verification algorithm is the first that can be embedded on a smart card, thus increasing tremendously the security of post-issuance downloading of applets on Java Cards.", "num_citations": "67\n", "authors": ["661"]}
{"title": "A simple, verified validator for software pipelining\n", "abstract": " Software pipelining is a loop optimization that overlaps the execution of several iterations of a loop to expose more instruction-level parallelism. It can result in first-class performance characteristics, but at the cost of significant obfuscation of the code, making this optimization difficult to test and debug. In this paper, we present a translation validation algorithm that uses symbolic evaluation to detect semantics discrepancies between a loop and its pipelined version. Our algorithm can be implemented simply and efficiently, is provably sound, and appears to be complete with respect to most modulo scheduling algorithms. A conclusion of this case study is that it is possible and effective to use symbolic evaluation to reason about loop transformations.", "num_citations": "66\n", "authors": ["661"]}
{"title": "Verified validation of lazy code motion\n", "abstract": " Translation validation establishes a posteriori the correctness of a run of a compilation pass or other program transformation. In this paper, we develop an efficient translation validation algorithm for the Lazy Code Motion (LCM) optimization. LCM is an interesting challenge for validation because it is a global optimization that moves code across loops. Consequently, care must be taken not to move computations that may fail before loops that may not terminate. Our validator includes a specific check for anticipability to rule out such incorrect moves. We present a mechanically-checked proof of correctness of the validation algorithm, using the Coq proof assistant. Combining our validator with an unverified implementation of LCM, we obtain a LCM pass that is provably semantics-preserving and was integrated in the CompCert formally verified compiler.", "num_citations": "65\n", "authors": ["661"]}
{"title": "A formally verified compiler for Lustre\n", "abstract": " The correct compilation of block diagram languages like Lustre, Scade, and a discrete subset of Simulink is important since they are used to program critical embedded control software. We describe the specification and verification in an Interactive Theorem Prover of a compilation chain that treats the key aspects of Lustre: sampling, nodes, and delays. Building on CompCert, we show that repeated execution of the generated assembly code faithfully implements the dataflow semantics of source programs.", "num_citations": "62\n", "authors": ["661"]}
{"title": "The effectiveness of type-based unboxing\n", "abstract": " We compare the efficiency of type-based unboxing strategies with that of simpler, untyped unboxing optimizations, building on our practical experience with the Gallium and Objective Caml compilers. We find the untyped optimizations to perform as well on the best case and significantly better in the worst case.", "num_citations": "62\n", "authors": ["661"]}
{"title": "A structured approach to proving compiler optimizations based on dataflow analysis\n", "abstract": " This paper reports on the correctness proof of compiler optimizations based on data-flow analysis. We formulate the optimizations and analyses as instances of a general framework for data-flow analyses and transformations, and prove that the optimizations preserve the behavior of the compiled programs. This development is a part of a larger effort of certifying an optimizing compiler by proving semantic equivalence between source and compiled code.", "num_citations": "60\n", "authors": ["661"]}
{"title": "Objective caml\n", "abstract": " CiNii \u8ad6\u6587 - Objective Caml CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092 \u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 Objective Caml LEROY X. \u88ab\u5f15\u7528\u6587\u732e: 2\u4ef6 \u8457\u8005 LEROY X. \u53ce\u9332\u520a\u884c\u7269 http://caml.inria.fr/ http://caml.inria.fr/ \u88ab\u5f15\u7528\u6587\u732e: 2\u4ef6\u4e2d 1-2\u4ef6\u3092 \u8868\u793a 1 \u30bb\u30ad\u30e5\u30ea\u30c6\u30a3\u30d7\u30ed\u30c8\u30b3\u30eb\u306e\u7565\u5f0f\u8a18\u6cd5\u304b\u3089spi \u8a08\u7b97\u3078\u306e\u5909\u63db \u4f4f\u4e95\u82f1\u4e8c\u90ce , \u7acb\u6ca2 \u79c0\u6643 , \u7c73\u6fa4 \u660e\u61b2 \u60c5\u5831 \u51e6\u7406\u5b66\u4f1a\u8ad6\u6587\u8a8c\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\uff08PRO\uff09 45(SIG12(PRO23)), 1-10, 2004-11-15 \u53c2\u8003\u6587\u732e21\u4ef6 \u88ab\u5f15\u7528 \u6587\u732e1\u4ef6 2 \u4f8b\u5916\u51e6\u7406\u6a5f\u69cb\u3092\u5099\u3048\u305f\u547d\u4ee4\u578b\u8a00\u8a9e\u306eCPS\u5909\u63db\u3068\u305d\u306e\u5b9a\u5f0f\u5316 \u4f4f\u4e95\u82f1\u4e8c\u90ce , \u5927\u6839\u7530\u88d5\u4e00 , \u7c73\u6fa4 \u660e\u61b2 \u60c5\u5831\u51e6\u7406\u5b66\u4f1a\u8ad6\u6587\u8a8c\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0\uff08PRO\uff09 45(SIG12(PRO23)), 67-82, 2004-11-15 \u53c2\u8003\u6587\u732e19\u4ef6 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u8ad6\u6587ID(NAID) 10014951066 \u8cc7\u6599\u7a2e\u5225 \u305d\u306e\u4ed6 \u30c7\u30fc\u30bf\u2026", "num_citations": "57\n", "authors": ["661"]}
{"title": "Parallel functional programming with skeletons: the OCamlP3L experiment\n", "abstract": " Writing parallel programs is not easy, and debugging them is usually a nightmare. To cope with these diiculties, a structured approach to parallel programs using skeletons and template based compiler techniques has been developed over the past years by several researchers, including the P3L group in Pisa. This approach is based on the use of a set of primitive forms that are just functionals implemented via templates exploiting the underlying parallelism, so it is natural to ask whether marrying a real functional language like Ocaml with the P3L skeletons can be the basis of a powerful parallel programming environment. We show that this is the case: our prototype, written entirely in Ocaml using a limited form of closure passing, allows a very simple and clean programming style, shows real speed-up over a network of workstations and, as an added fundamental bonus, allows logical debug-ging of parallel programs in a sequential framework without changing the user code.", "num_citations": "55\n", "authors": ["661"]}
{"title": "Coinductive big-step operational semantics\n", "abstract": " This paper illustrates the use of coinductive definitions and proofs in big-step operational semantics, enabling the latter to describe diverging evaluations in addition to terminating evaluations. We show applications to proofs of type soundness and to proofs of semantic preservation for compilers.", "num_citations": "54\n", "authors": ["661"]}
{"title": "Mechanized verification of CPS transformations\n", "abstract": " Transformation to continuation-passing style (CPS) is often performed by optimizing compilers for functional programming languages. As part of the development and proof of correctness of a compiler for the mini-ML functional language, we have mechanically verified the correctness of two CPS transformations for a call-by-value \u03bb-calculus with n-ary functions, recursive functions, data types and pattern-matching. The transformations generalize Plotkin\u2019s original call-by-value transformation and Danvy and Nielsen\u2019s optimized transformation, respectively. We used the Coq proof assistant to formalize the transformations and conduct and check the proofs. Originalities of this work include the use of big-step operational semantics to avoid difficulties with administrative redexes, and of two-sorted de Bruijn indices to avoid difficulties with \u03b1-conversion.", "num_citations": "49\n", "authors": ["661"]}
{"title": "Typage polymorphe d'un langage algorithmique\n", "abstract": " Le typage statique avec types polymorphes, comme dans le langage ML, s'adapte parfaitement aux langages purement applicatifs, leur apportant souplesse et expressivit\u00e9. Mais il ne s'\u00e9tend pas naturellement au trait principal des langages algorithmiques: la modification en place des structures de donn\u00e9es.  Des difficult\u00e9s de typage similaires apparaissent avec d'autres extensions des langages applicatifs: les variables logiques, la communication inter-processus \u00e0 travers des canaux, et la manipulation de continuations en tant que valeurs. Ce travail \u00e9tudie, dans le cadre de la s\u00e9mantique relationnelle, deux nouvelles approches du typage polymorphe de ces constructions non-applicatives. La premi\u00e8re repose sur une restriction de l'op\u00e9ration de g\u00e9n\u00e9ralisation des types (la notion de variables dangereuses), et sur un typage plus fin des valeurs fonctionnelles (le typage des fermetures). Le syst\u00e8me de types obtenu reste compatible avec le noyau applicatif de ML, et se r\u00e9v\u00e8le \u00eatre le plus expressif parmi les syst\u00e8mes de types pour ML plus traits imp\u00e9ratifs propos\u00e9s jusqu'ici. La seconde approche repose sur l'adoption d'une s\u00e9mantique ``par nom'' pour les constructions du polymorphisme, au lieu de la s\u00e9mantique ``par valeur'' usuelle. Le langage obtenu s'\u00e9carte de ML, mais se type tr\u00e8s simplement avec du polymorphisme. Les deux approches rendent possible l'interaction sans heurts entre les traits non-applicatifs et le typage polymorphe.", "num_citations": "49\n", "authors": ["661"]}
{"title": "A formally-verified alias analysis\n", "abstract": " This paper reports on the formalization and proof of soundness, using the Coq proof assistant, of an alias analysis: a static analysis that approximates the flow of pointer values. The alias analysis considered is of the points-to kind and is intraprocedural, flow-sensitive, field-sensitive, and untyped. Its soundness proof follows the general style of abstract interpretation. The analysis is designed to fit in the CompCert C verified compiler, supporting future aggressive optimizations over memory accesses.", "num_citations": "45\n", "authors": ["661"]}
{"title": "Manuel de r\u00e9f\u00e9rence du langage Caml\n", "abstract": " Cet ouvrage contient le manuel de r\u00e9f\u00e9rence du langage Caml et la documentation complete du systeme Caml Light, un environnement de programmation en Caml distribu\u00e9e gratuitement. Il s\u2019 adressea des programmeurs Caml exp\u00e9riment\u00e9s, et non pas aux d\u00e9butants. Il vient en compl\u00e9ment du livre Le langage Caml, des m\u00eames auteurs chez le m\u00eame \u00e9diteur, qui fournit une introduction progressive au langage Caml eta l\u2019\u00e9criture de programmes dans ce langage. Le pr\u00e9sent ouvrage s\u2019 organise comme suit:\u2022 La partie I,\u00abManuel de r\u00e9f\u00e9rence du langage Caml\u00bb, documente pr\u00e9cis\u00e9ment la syntaxe et la s\u00e9mantique du langage Caml.", "num_citations": "39\n", "authors": ["661"]}
{"title": "Formal C semantics: CompCert and the C standard\n", "abstract": " We discuss the difference between a formal semantics of the C standard, and a formal semantics of an implementation of C that satisfies the C standard. In this context we extend the CompCert semantics with end-of-array pointers and the possibility to byte-wise copy objects. This is a first and necessary step towards proving that the CompCert semantics refines the formal version of the C standard that is being developed in the Formalin project in Nijmegen.", "num_citations": "38\n", "authors": ["661"]}
{"title": "Validating register allocation and spilling\n", "abstract": " Following the translation validation approach to high-assurance compilation, we describe a new algorithm for validating a posteriori the results of a run of register allocation. The algorithm is based on backward dataflow inference of equations between variables, registers and stack locations, and can cope with sophisticated forms of spilling and live range splitting, as well as many architectural irregularities such as overlapping registers. The soundness of the algorithm was mechanically proved using the Coq proof assistant.", "num_citations": "38\n", "authors": ["661"]}
{"title": "Compilation of extended recursion in call-by-value functional languages\n", "abstract": " This paper formalizes and proves correct a compilation scheme for mutually-recursive definitions in call-by-value functional languages. This scheme supports a wider range of recursive definitions than standard call-by-value recursive definitions. We formalize our technique as a translation scheme to a lambda-calculus featuring in-place update of memory blocks, and prove the translation to be faithful.", "num_citations": "35\n", "authors": ["661"]}
{"title": "Le systeme Caml Special Light: modules et compilation efficace en Caml\n", "abstract": " Ce rapport pr\u00e9sente une vue d'ensemble du syst\u00e8me Caml Special Light, une impl\u00e9mentation exp\u00e9rimentale du langage Caml offrant deux extensions majeures: premi\u00e8rement, un calcul de modules (incluant les foncteurs et les vues multiples d'un m\u00eame module) dans le style de celui de Standard ML, mais s'appuyant sur les avanc\u00e9es r\u00e9centes dans la th\u00e9orie du typage des modules et pr\u00e9servant la compatibilit\u00e9 avec la compilation s\u00e9par\u00e9e; deuxi\u00e8mement, un double compilateur, produisant \u00e0 la fois du du code natif efficace, pour les applications de Caml gourmandes en temps de calcul, et du code abstrait interpr\u00e9t\u00e9, pour la rapidit\u00e9 de compilation et le confort de mise au point.", "num_citations": "34\n", "authors": ["661"]}
{"title": "V\u00e9rification formelle d'un compilateur optimisant pour langages fonctionnels\n", "abstract": " La pr\u00e9servation de propri\u00e9t\u00e9s \u00e9tablies sur le programme source jusqu'au code ex\u00e9cutable est un point important dans les m\u00e9thodes formelles. Cette propri\u00e9t\u00e9 de pr\u00e9servation est \u00e9tablie par la v\u00e9rification formelle du proccessus de compilation. Un compilateur est formellement v\u00e9rifi\u00e9 s'il est accompagn\u00e9 d'une preuve de pr\u00e9servation s\u00e9mantique : \"si la compilation r\u00e9ussit, le code compil\u00e9 se comporte comme le code source le pr\u00e9dit.\" Le projet CompCert \u00e9tudie la v\u00e9rification formelle de compilateurs r\u00e9alistes utilisable dans l'embarqu\u00e9-critique. Il s'agit de d\u00e9velopper et formellement v\u00e9rifier de tels compilateur via l'assistant de preuve Coq. Un compilateur pour le langage C vers l'assembleur PowerPC a d\u00e9j\u00e0 ainsi \u00e9t\u00e9 produit. Le code ex\u00e9cutable du compilateur a \u00e9t\u00e9 obtenu en deux \u00e9tapes non v\u00e9rifi\u00e9s : la g\u00e9n\u00e9ration automatique de code Ocaml par le m\u00e9canisme d'extration de Coq et la compilation du de ce code extrait par le syst\u00e8me Objective Caml. En fait, cette lacune est commune \u00e0 tous les d\u00e9veloppements sp\u00e9cifi\u00e9s dans l'assistant de preuve Coq et destin\u00e9s \u00e0 produire un \u00e9x\u00e9cutable. Cette th\u00e8se d\u00e9crit l'\u00e9tude, le d\u00e9veloppement et la v\u00e9rification formelle, dans l'assistant de preuve Coq, d'un compilateur pour le fragment purement fonctionnel du langage ML : le langage cible du m\u00e9canisme d'extraction de Coq. Concr\u00e8tement, il s'git d'une cha\u00eene de compilation en amont pour mini-ML (lambda calcul, let, letrec et filtrage) vers le premier langage interm\u00e9diaire de la cha\u00eene de compilation en aval du compilateur CompCert. Ce langage, Cminor, est un langage de bas niveau \u00e0 la C. L'expressivit\u00e9 du langage source trait\u00e9 rend ce compilateur\u00a0\u2026", "num_citations": "32\n", "authors": ["661"]}
{"title": "Towards formally verified optimizing compilation in flight control software\n", "abstract": " This work presents a preliminary evaluation of the use of the CompCert formally specified and verified optimizing compiler for the development of level A critical flight control software. First, the motivation for choosing CompCert is presented, as well as the requirements and constraints for safety-critical avionics software. The main point is to allow optimized code generation by relying on the formal proof of correctness instead of the current un-optimized generation required to produce assembly code structurally similar to the algorithmic language (and even the initial models) source code. The evaluation of its performance (measured using WCET) is presented and the results are compared to those obtained with the currently used compiler. Finally, the paper discusses verification and certification issues that are raised when one seeks to use CompCert for the development of such critical software.", "num_citations": "31\n", "authors": ["661"]}
{"title": "A locally nameless solution to the POPLmark challenge\n", "abstract": " The POPLmark challenge is a collective experiment intended to assess the usability of theorem provers and proof assistants in the context of fundamental research on programming languages. In this report, we present a solution to the challenge, developed with the Coq proof assistant, and using the \"locally nameless\" presentation of terms with binders introduced by McKinna, Pollack, Gordon, and McBride.", "num_citations": "30\n", "authors": ["661"]}
{"title": "Maintaining large software distributions: new challenges from the FOSS era.\n", "abstract": " Inria - Maintaining large software distributions: new challenges from the FOSS era. Acc\u00e9der directement au contenu Acc\u00e9der directement \u00e0 la navigation Toggle navigation CCSD HAL HAL HALSHS TEL M\u00e9diHAL Liste des portails AUR\u00e9HAL API Data Documentation Episciences.org Episciences.org Revues Documentation Sciencesconf.org Support HAL-Inria Les publications, logiciels... des scientifiques Inria Accueil D\u00e9poser Consulter tout HAL par date de publication/r\u00e9daction par domaine par type de publication par collection arXiv les derniers d\u00e9p\u00f4ts Publications Inria Recherche Services HalTools : cr\u00e9er sa page web Haltools : export RAWEB X2Hal : import par lot Consulter les structures de recherche connues de HAL Documentation Aide en ligne de HAL V3 Derni\u00e8res \u00e9volutions de HAL V3 Documentation API HAL Ajouter des vignettes Aide en ligne Haltools Aide en ligne de X2hal OpenAccess Inria soutient \u2026", "num_citations": "30\n", "authors": ["661"]}
{"title": "The CompCert verified compiler\n", "abstract": " \u2022 Chapter 1 gives an overview of the CompCert C compiler and of the formal verification of compilers.\u2022 Chapter 2 explains how to install CompCert C.\u2022 Chapter 3 explains how to use the CompCert C compiler.\u2022 Chapter 4 explains how to use the CompCert C reference interpreter.\u2022 Chapter 5 describes the subset of the ISO C99 language that is implemented by CompCert.\u2022 Chapter 6 describes the supported language extensions: pragmas, attributes, built-in functions, inline assembly.", "num_citations": "29\n", "authors": ["661"]}
{"title": "Tilting at windmills with Coq: Formal verification of a compilation algorithm for parallel moves\n", "abstract": " This article describes the formal verification of a compilation algorithm that transforms parallel moves (parallel assignments between variables) into a semantically-equivalent sequence of elementary moves. Two different specifications of the algorithm are given: an inductive specification and a functional one, each with its correctness proofs. A functional program can then be extracted and integrated in the Compcert verified compiler.", "num_citations": "29\n", "authors": ["661"]}
{"title": "Formal verification of object layout for C++ multiple inheritance\n", "abstract": " Object layout - the concrete in-memory representation of objects - raises many delicate issues in the case of the C++ language, owing in particular to multiple inheritance, C compatibility and separate compilation. This paper formalizes a family of C++ object layout schemes and mechanically proves their correctness against the operational semantics for multiple inheritance of Wasserrab et al. This formalization is flexible enough to account for space-saving techniques such as empty base class optimization and tail-padding optimization. As an application, we obtain the first formal correctness proofs for realistic, optimized object layout algorithms, including one based on the popular \"common vendor\" Itanium C++ application binary interface. This work provides semantic foundations to discover and justify new layout optimizations; it is also a first step towards the verification of a C++ compiler front-end.", "num_citations": "26\n", "authors": ["661"]}
{"title": "Call-by-value mixin modules\n", "abstract": " Mixin modules are a framework for modular programming that supports code parameterization, incremental programming via late binding and redefinitions, and cross-module recursion. In this paper, we develop a language of mixin modules that supports call-by-value evaluation, and formalize a reduction semantics and a sound type system for this language.", "num_citations": "25\n", "authors": ["661"]}
{"title": "Pseudoknot: a float-intensive benchmark for functional compilers\n", "abstract": " Over 20 implementations of different functional languages are compared using one program. Aspects studied are compile time and execution time. Another important point is how the program can be modified and tuned to obtain maximal performance on each language implementation. Finally, an interesting question is whether laziness is or is not beneficial for this application. With few exceptions, the compilers take a long time to compile this program. Compilers that generate C or Lisp are much slower than those that generate native code directly. Interestingly, there is no clear distinction between the runtime performance of eager and lazy implementations when appropriate annotations are used: lazy implementations have clearly come of age for this application. The speed of C can even be approached by some implementations, but not without special measures such as strictness annotations. No implementation that has been tested actually equals the performance of C. 1 Introduction At the Dagstu...", "num_citations": "23\n", "authors": ["661"]}
{"title": "Mechanized semantics\n", "abstract": " The goal of this lecture is to show how modern theorem provers\u2014in this case, the Coq proof assistant\u2014can be used to mechanize the specification of programming languages and their semantics, and to reason over individual programs and over generic program transformations, as typically found in compilers. The topics covered include: operational semantics (small-step, big-step, definitional interpreters); a simple form of denotational semantics; axiomatic semantics and Hoare logic; generation of verification conditions, with application to program proof; compilation to virtual machine code and its proof of correctness; an example of an optimizing program transformation (dead code elimination) and its proof of correctness.", "num_citations": "22\n", "authors": ["661"]}
{"title": "Efficient data representation in polymorphic languages\n", "abstract": " Languages with polymorphic types (e.g. ML) have traditionally been implemented using Lisp-like data representations\u2014everything has to fit in one word, if necessary by being heap-allocated and handled through a pointer. The reason is that, in contrast with conventional statically-typed languages such as Pascal, it is not possible to assign one unique type to each expression at compile-time, an absolute requirement for using more efficient representations (e.g. unallocated multi-word values). In this paper, we show how to take advantage of the static polymorphic typing to mix correctly two styles of data representation in the implementation of a polymorphic language: specialized, efficient representations are used when types are fully known at compile-time; uniform, Lisp-like representations are used otherwise.", "num_citations": "22\n", "authors": ["661"]}
{"title": "Mechanized semantics for compiler verification\n", "abstract": " The formal verification of compilers and related programming tools depends crucially on the availability of appropriate mechanized semantics for the source, intermediate and target languages. In this invited talk, I review various forms of operational semantics and their mechanization, based on my experience with the formal verification of the CompCert\u00a0C compiler.", "num_citations": "20\n", "authors": ["661"]}
{"title": "Mixin modules in a call-by-value setting\n", "abstract": " The ML module system provides powerful parameterization facilities, but lacks the ability to split mutually recursive definitions across modules and provides insufficient support for incremental programming. A promising approach to solve these issues is Ancona and Zucca's mixin module calculus CMS. However, the straightforward way to adapt it to ML fails, because it allows arbitrary recursive definitions to appear at any time, which ML does not otherwise support. In this article, we enrich CMS with a refined type system that controls recursive definitions through the use of dependency graphs. We then develop and prove sound a separate compilation scheme, directed by dependency graphs, that translates mixin modules down to a call-by-value \u03bb-calculus extended with a nonstandard let rec construct.", "num_citations": "20\n", "authors": ["661"]}
{"title": "A list-machine benchmark for mechanized metatheory\n", "abstract": " We propose a benchmark to compare theorem-proving systems on their ability to express proofs of compiler correctness. In contrast to the first POPLmark, we emphasize the connection of proofs to compiler implementations, and we point out that much can be done without binders or alpha-conversion. We propose specific criteria for evaluating the utility of mechanized metatheory systems; we have constructed solutions in both Coq and Twelf metatheory, and we draw conclusions about those two systems in particular.", "num_citations": "18\n", "authors": ["661"]}
{"title": "Edos: Environment for the development and distribution of open source software\n", "abstract": " The open-source software community is now comprised of a very large and growing number of contributors and users. The GNU/Linux operating system for instance has an estimated 18 million users worldwide and its contributing developers can be counted by thousands. The critical mass of contributors taking part in various opensource projects has helped to ensure high quality for open source software. However, despite the achievements of the open-source software industry, there are issues in the production of large scale open-source software (OSS) such as the GNU/Linux operating system that have to be addressed as the numbers of users, of contributors, and of available applications grow. EDOS is a European project supported by IST started October 2004 and ending in 2007, whose objective is to provide a new generation of methodologies, theoretical models, technical tools and quality models specifically tailored to OSS engineering and to software distribution over the Internet.", "num_citations": "17\n", "authors": ["661"]}
{"title": "A mechanized semantics for C++ object construction and destruction, with applications to resource management\n", "abstract": " We present a formal operational semantics and its Coq mechanization for the C++ object model, featuring object construction and destruction, shared and repeated multiple inheritance, and virtual function call dispatch. These are key C++ language features for high-level system programming, in particular for predictable and reliable resource management. This paper is the first to present a formal mechanized account of the metatheory of construction and destruction in C++, and applications to popular programming techniques such as \"resource acquisition is initialization\". We also report on irregularities and apparent contradictions in the ISO C++03 and C++11 standards.", "num_citations": "15\n", "authors": ["661"]}
{"title": "A bytecodecompiled, type-safe, multi-stage language\n", "abstract": " \u00b95pfx \u00a7 H! 3R%(\u00a9 v\u00a3\u00a6\u00a5 A1D $59 XX \u00a7 C8Cs\u00a5)\u00a9\u00a3\u00a6\u00a1 Q d 1y'c XC \u00a7 \u00a1\u00a4\u00a3|'c\u00a9% 53\u00fe!\u00a4 \u00a7 3R\u00a5\u00a4 C 3R\u00a1 Q 217 \u00a7 8%(\u00a1 r% D'!\u00a4 p\u00a6\u00a9 21D\u00a1\u00a4\u00a3\u00a6 C81D \u00a7 %(\u00a1!\u00a4 6\u00a9 5gs \u00c6 pfx \u00a7 H! d 3R% D\u00a9\u00a3\u00a6\u00a5 A1D $59 XX \u00a7 CC 15 r 3R% D\u00a9 T 6 1 (3R\u00a5\u00a4 C\u00a3 i! 6\u00a9 5gs pp\u00c4\u00a4 ss\u00ba\u00b5 \u00c4 pp\u00c4\u00a4 ss\u00a4 4\u00bb \u00ed \u00b5 \u00c2! \u00c0y\u00c4s\u00c4 tme\u00c4to \u00c7\u00c8 \u00aaq pp\u00c4\u00a4 ss\u00a4 4\u00bb \u00ed \u00b5 \u00c9 \u00ca \u00be \u00c4 tme\u00c4to x pp \u00ed \u00c6ss \u00ba\u00b5 pp \u00edss \u00ba\u00b5 pp \u00c6ss \u00ba\u00b5 pp \u00ed \u00c6ss\u00a4 4\u00bb \u00ed \u00b5 \u00bc4\u00beE\u00be| m\u00a6 pp \u00edss\u00a4 4\u00bb \u00ed\u00b5pp \u00c6ss\u00a4 4\u00bb \u00ed \u00b5 o ppi\u00a4 \u00c4\u00a4 j ss\u00ba\u00b5 i\u00a4 \u00c4\u00a4 j8pp ss\u00ba\u00b5 ppi\u00a4 \u00c4\u00a4 j ss\u00a4 E\u00bb \u00ed \u00b5\u00cb\u00ae 4 y \u00c4 \u00cc \u00b2\u00caX\u00cd \u00c1dmVo\u00b1\u00b2\u00bf! \u00c0V\u00c1 me\u00c4d pp ss\u00a4 4\u00bb \u00ed\u00b5\u00ce\u00cf \u00d0\u00d1\u00d2\u00a4 4\u00bb \u00edl\u00d3 o pp\u00d4j\u00a6\u00ab\u00aa E\u00ac jss\u00ba\u00b5 pp ss\u00ed \u00b5 pp\u00d4j\u00a6\u00ab\u00aa E\u00ac jss\u00a4 E\u00bb \u00ed\u00b5 \u00d5h\u00c4y\u00d6rpp ss\u00a4 4\u00bb \u00c6 \u00b5 pp\u00a1 j 4 ss\u00ed \u00b5 pp ss\u00ba\u00b5 pp\u00a1 j 4 ss\u00a4 4\u00bb \u00c6 \u00b5\u00d7# \u00caE\u00d8Upp ss\u00a4 4\u00bb \u00ed \u00b5 pp\u00d4j|{ss\u00ba\u00b5 w\u00a9 k\u00a9 gwQ 6 P pp ss\u00ba\u00b5 pp\u00d4j|{ss\u00a4 E\u00bb \u00ed \u00b5 \u00d9E\u00da\u00b2 pp ss\u00a4 4\u00bb \u00ed \u00b5 pp\u00e2 ss\u00ba\u00b5 pp\u00e2 ss\u00a4 4\u00bb \u00ed \u00b5 \u00c9 \u00ca \u00be)", "num_citations": "15\n", "authors": ["661"]}
{"title": "Verified squared: does critical software deserve verified tools?\n", "abstract": " The formal verification of programs has progressed tremendously in the last decade. In this talk, I review some of the obstacles that [6, 8, 15, 18] remain to be lifted before source-level verification tools can be taken really seriously in the critical software industry. A direction I advocate is the systematic formal verification of the development tools that participate in the production and verification of critical software.", "num_citations": "14\n", "authors": ["661"]}
{"title": "A verified framework for higher-order uncurrying optimizations\n", "abstract": " Function uncurrying is an important optimization for the efficient execution of functional programming languages. This optimization replaces curried functions by uncurried, multiple-argument functions, while preserving the ability to evaluate partial applications. First-order uncurrying (where curried functions are optimized only in the static scopes of their definitions) is well understood and implemented by many compilers, but its extension to higher-order functions (where uncurrying can also be performed on parameters and results of higher-order functions) is challenging. This article develops a generic framework that expresses higher-order uncurrying optimizations as type-directed insertion of coercions, and prove its correctness. The proof uses step-indexed logical relations and was entirely mechanized using the Coq proof assistant.", "num_citations": "14\n", "authors": ["661"]}
{"title": "Formal verification of an optimizing compiler\n", "abstract": " Formal verification of an optimizing compiler - or: a software-proof codesign approach to the development of trusted compile Page 1 Formal verification of an optimizing compiler or: a software-proof codesign approach to the development of trusted compilers Xavier Leroy INRIA Rocquencourt MEMOCODE 2007 X. Leroy (INRIA) Formal compiler verification MEMOCODE 2007 1 / 61 Page 2 The compilation process General definition: any automatic translation from a computer language to another. Restricted definition: efficient (\u201coptimizing\u201d) translation from a source language (understandable by programmers) to a machine language (executable in hardware). A mature area of computer science: Already 50 years old! (Fortran I: 1957) Huge corpus of code generation and optimization algorithms. Many industrial-strength compilers that perform subtle transformations. X. Leroy (INRIA) Formal compiler verification \u2026", "num_citations": "13\n", "authors": ["661"]}
{"title": "A proposal for recursive modules in Objective Caml\n", "abstract": " However, a recursive module definition must be contained whole within a compilation unit: the proposal does not support recursion between compilation units. The latter can however be encoded using separately-compiled functors, whose fix-point is taken later using the module rec construct. 1 The scope of the identifiers ident1,..., identn encompasses not only the module expressions module-expri, but also the module types module-typei. Thus, not only the modules are recursive, but also their types.", "num_citations": "13\n", "authors": ["661"]}
{"title": "Embedded program annotations for WCET analysis\n", "abstract": " We present __builtin_ais_annot(), a user-friendly, versatile way to transfer annotations (also known as flow facts) written on the source code level to the machine code level. To do so, we couple two tools often used during the development of safety-critical hard real-time systems, the formally verified C compiler CompCert and the static WCET analyzer aiT. CompCert stores the AIS annotations given via __builtin_ais_annot() in a special section of the ELF binary, which can later be extracted automatically by aiT.", "num_citations": "11\n", "authors": ["661"]}
{"title": "Objective Caml\u2014a general purpose high-level programming language\n", "abstract": " Objective Caml is a general purpose programming language that combines functional, imperative, and object-oriented programming. The language is statically typed; its type system ensures the correct evaluation of programs. Types are automatically inferred. The language offers powerful constructions such as user-definable data-types, the ability to define functions by pattern-matching, and an exception mechanism. Programming in the large is facilitated by a full-fledge class-based object-oriented layer and an expressive module system.Objective Caml belongs to the ML family of programming languages and has been implemented at INRIA Rocquencourt within the Cristal research team. Since ML\u2019s inception in the late seventies, there has been a continuous line of research at INRIA devoted to implementations and improvements of ML. Objective Caml owes a lot to the original core ML language and to our first\u00a0\u2026", "num_citations": "11\n", "authors": ["661"]}
{"title": "A reduction semantics for call-by-value mixin modules\n", "abstract": " Module systems are important for software engineering: they facilitate code reuse without compromising the correctness of programs. However, they still lack some flexibility: first, they do not allow mutually recursive definitions to span module boundaries ; second, definitions inside modules are bound early, and cannot be overridden later, as opposed to inheritance and overriding in class-based object-oriented languages, which follow the late binding semantics. This paper examines an alternative, hybrid idea of modularization concept, called mixin modules. We develop a language of call-by-value mixin modules with a reduction semantics, and a sound type system for it, guaranteeing that programs will run correctly.", "num_citations": "10\n", "authors": ["661"]}
{"title": "The Objective Caml system, release 3.02, Documentation and user\u2019s manual, Institut National de Recherche en Informatique et en Automatique\n", "abstract": " CiteSeerX \u2014 The Objective Caml system, release 3.02, Documentation and user\u2019s manual, Institut National de Recherche en Informatique et en Automatique Documents Authors Tables Log in Sign up MetaCart DMCA Donate CiteSeerX logo Documents: Advanced Search Include Citations Authors: Advanced Search Include Citations Tables: DMCA The Objective Caml system, release 3.02, Documentation and user\u2019s manual, Institut National de Recherche en Informatique et en Automatique (1999) Cached Download as a PDF Download Links [www.cs.cornell.edu] [caml.inria.fr] Save to List Add to Collection Correct Errors Monitor Changes by Xavier Leroy , Damien Doligez , Jacques Garrigue , Didier R\u00e9my , J\u00e9r\u00f4me Vouillon Citations: 8 - 0 self Summary Citations Active Bibliography Co-citation Clustered Documents Version History Share Facebook Twitter Reddit Bibsonomy OpenURL Abstract Keyphrases objective \u2026", "num_citations": "10\n", "authors": ["661"]}
{"title": "OcamlP3l--a functional parallel programming system\n", "abstract": " Writing parallel programs is not easy, and debugging them is usually a nightmare. To cope with these difficulties, a structured approach to parallel programs using skeletons and template based compiler techniques has been developed over the past years by several researchers, including the P3L group in Pisa. This approach is based on the use of a set of primitives that are just functionals implemented via templates exploiting the underlying parallelism, so it is natural to ask whether marrying a real functional language like Ocaml with the P3L skeletons can be the basis of a powerful parallel programming environment. We show that this is the case: our prototype, written entirely in Ocaml using a limited form of closure passing, allows a very simple and clean programming style, shows real speed-up over a network of workstations and, as an added fundamental bonus, allows logical debugging of a user parallel program in a sequential framework without changing the user code.", "num_citations": "10\n", "authors": ["661"]}
{"title": "Computer security from a programming language and static analysis perspective\n", "abstract": " Computer security [16,5] is usually defined as ensuring integrity, confidentiality, and availability requirements even in the presence of a determined, malicious opponent. Sensitive data must be modified and consulted by authorized users only (integrity, confidentiality); moreover, the system should resist \u201cdenial of service\u201d attacks that attempt to render it unusable (availability). In more colorful language, computer security has been described as \u201cprogramming Satan\u2019s computer\u201d [6]: the implementor must assume that every weakness that can be exploited will be.", "num_citations": "8\n", "authors": ["661"]}
{"title": "Compilation of extended recursion in call-by-value functional languages\n", "abstract": " This paper formalizes and proves correct a compilation scheme for mutually-recursive definitions in call-by-value functional languages. This scheme supports a wider range of recursive definitions than previous methods. We formalize our technique as a translation scheme to a lambda-calculus featuring in-place update of memory blocks, and prove the translation to be correct.", "num_citations": "7\n", "authors": ["661"]}
{"title": "News from the EDOS project: improving the maintenance of free software distributions\n", "abstract": " The EDOS project is a research effort whose goal is to contribute to ensure the quality of a free software distribution. This is a major technical and engineering challenge, owing to the size and complexity of these distributions (tens of thousands of software packages). We present here some of the challenges that we have already tackled, and some of the advanced tools that are already available to the community as an outcome of the first year of work.", "num_citations": "5\n", "authors": ["661"]}
{"title": "Camlidl user\u2019s manual Version 1.05\n", "abstract": " Camlidl generates stub code for interfacing Caml with C (as described in chapter \u201cInterfacing with C\u201d of the Objective Caml reference manual1) from an IDL description of the C functions to be made available in Caml. Thus, Camlidl automates the most tedious task in interfacing C libraries with Caml programs. It can also be used to interface Caml programs with other languages, as long as those languages have a well-defined C interface. In addition, Camlidl provides basic support for COM interfaces and components. It supports both using COM components (usually written in C++ or C) from Caml programs, and packaging Caml objects as COM components that can then be used from C++ or C.", "num_citations": "5\n", "authors": ["661"]}
{"title": "On the implementation of recursion in call-by-value functional languages\n", "abstract": " Functional languages encourage the extensive use of recursive fonctions and data structures. It is therefore important that they efficiently implement recursion. In this paper, we formalize and improve a known implementation technique for recursion. The original technique was introduced by Cousineau and Mauny as the \u00abin-place updating trick\u00bb. Consider a list of mutually recursive definitions. The technique consists in allocating a dummy, uninitialized heap block for each recursive definition. The size of these blocks is guessed from the shape of each definition. Then, the right-hand sides of the definitions are computed. Recursively-defined identifiers thus refer to the corresponding dummy blocks. This leads, for each definition, to a block of the expected size. Eventually, the contents of the obtained blocks are copied to the dummy blocks, updating them in place. The only change we propose to this scheme is to update the dummy blocks as soon as possible, immediately after each definition is computed, thus making it available for further use. At the source language level, the improvement allows to extend the class of expressions allowed as right-hand sides of recursive definitions, usually restricted to syntactic functions. We formalize our technique as a translation scheme to a lambda-calculus featuring in-place updating of memory blocks, and prove the translation to be faithful.", "num_citations": "5\n", "authors": ["661"]}
{"title": "An overview of Types in Compilation\n", "abstract": " Most programming languages are equipped with a type system that detects type errors in the program, such as using a variable or result of a given type in a context that expects data of a different, incompatible type. Such type checking can take place either statically (at compile-time) or dynamically (at run-time). Type checking has proved to be very effective in catching a wide class of programming errors, from the trivial (misspelled identifiers) to the fairly deep (violations of data structure invariants). It makes program considerably safer, ensuring integrity of data structures and type-correct interconnection of program components.Safety is not the only motivation for equipping programming languages with type systems, however. Another motivation, which came first historically, is to facilitate the efficient compilation of programs. Static typing restricts the set of programs to be compiled, possibly eliminating programs containing constructs that are difficult to compile efficiently or even to compile correctly at all. Also, static typing guarantees certain properties and invariants on the data manipulated by the program; the compiler can take advantage of these semantic guarantees to generate better code. The \u201cTypes in Compilation\u201d workshops are dedicated to the study of these interactions between type systems and the compilation process.", "num_citations": "5\n", "authors": ["661"]}
{"title": "N. R ojemo, M. Serrano, J.-P. Talpin, J. Thackray, P. Weis, and P. Wentworth. Pseudoknot: a Float-Intensive benchmark for functional compilers (DRAFT)\n", "abstract": " Over 20 implementations of different functional languages are benchmarked using the same program, a floating-point intensive application taken from molecular biology. The principal aspects studied are compile time and execution time for the varying implementations. An important consideration is how the program can be modified and tuned to obtain maximal performance on each language implementation.With few exceptions, the compilers take a significant amount of time to compile this program, though almost all compilers were faster than the current GNU C compiler. Compilers that generate C or Lisp are often slower than those that generate native code directly; the cost of compiling the intermediate form is normally a large fraction of the total compilation time. There is no clear distinction between the runtime performance of eager and lazy implementations when appropriate annotations are used: lazy\u00a0\u2026", "num_citations": "5\n", "authors": ["661"]}
{"title": "Verified code generation for the polyhedral model\n", "abstract": " The polyhedral model is a high-level intermediate representation for loop nests that supports elegantly a great many loop optimizations. In a compiler, after polyhedral loop optimizations have been performed, it is necessary and difficult to regenerate sequential or parallel loop nests before continuing compilation. This paper reports on the formalization and proof of semantic preservation of such a code generator that produces sequential code from a polyhedral representation. The formalization and proofs are mechanized using the Coq proof assistant.", "num_citations": "4\n", "authors": ["661"]}
{"title": "How I found a crash bug with hyperthreading in Intel's Skylake processors\n", "abstract": " How I found a crash bug with hyperthreading in Intel's Skylake processors - Inria Acc\u00e9der directement au contenu Acc\u00e9der directement \u00e0 la navigation Toggle navigation CCSD HAL HAL HALSHS TEL M\u00e9diHAL Liste des portails AUR\u00e9HAL API Data Documentation Episciences.org Episciences.org Revues Documentation Sciencesconf.org Support HAL-Inria Les publications, logiciels... des scientifiques Inria Accueil D\u00e9poser Consulter tout HAL par date de publication/r\u00e9daction par domaine par type de publication par collection arXiv les derniers d\u00e9p\u00f4ts Publications Inria Recherche Services HalTools : cr\u00e9er sa page web Haltools : export RAWEB X2Hal : import par lot Consulter les structures de recherche connues de HAL Documentation Aide en ligne de HAL V3 Derni\u00e8res \u00e9volutions de HAL V3 Documentation API HAL Ajouter des vignettes Aide en ligne Haltools Aide en ligne de X2hal OpenAccess Inria soutient la \u2026", "num_citations": "4\n", "authors": ["661"]}
{"title": "Programming with dependent types: Passing fad or useful tool\n", "abstract": " Programming with dependent types: passing fad or useful tool? Page 1 Programming with dependent types: passing fad or useful tool? Xavier Leroy INRIA Paris-Rocquencourt IFIP WG 2.8, 2009-06 X. Leroy (INRIA) Dependently-typed programming 2009-06 1 / 22 Page 2 Dependent types In a very general sense: all frameworks enabling programmers to Write functional programs; State logical properties about them; Prove these properties with machine assistance. Examples: most proof assistants (HOL, Isabelle/HOL, Coq, Agda, . . . ) Unquestionably a Very Very Good Thing. X. Leroy (INRIA) Dependently-typed programming 2009-06 2 / 22 Page 3 Dependent types In a narrower sense: all frameworks enabling programmers to Include logical propositions within data and function types; Include proof terms within data and functions. Foundations: Martin-L\u00f6f\u2019s type theory. Examples: Coq, Agda, Epigram (general); \u2026", "num_citations": "4\n", "authors": ["661"]}
{"title": "Compiling functional languages\n", "abstract": " Goal of this lecture: survey implementation techniques for functional languages, and show some of the (syntactic) theories explaining these techniques.", "num_citations": "4\n", "authors": ["661"]}
{"title": "Programmation du syst\u00e8me UNIX en CAML light\n", "abstract": " Ce rapport est en cours d'introduction a la programmation du systeme Unix, mettant l'accent sur la communication entre les processus. La principale nouveaute de ce travail est l'utilisation du langage Caml Light, un dialecte du langage ML, a la place du langage C qui est d'ordinaire associe a la programmation systeme. Ceci donne des poinst de vue nouveaux a la fois sur la programmation systeme et sur le langage ML.", "num_citations": "4\n", "authors": ["661"]}
{"title": "Compiler verification for fun and profit\n", "abstract": " Summary form only given. Formal verification of software or hardware systems - be it by model checking, deductive verification, abstract interpretation, type checking, or any other kind of static analysis - is generally conducted over high-level programming or description languages, quite remote from the actual machine code and circuits that execute in the system. To bridge this particular gap, we all rely on compilers and other code generators to automatically produce the executable artifact. Compilers are, however, vulnerable to miscompilation: bugs in the compiler that cause incorrect code to be generated from a correct source code, possibly invalidating the guarantees so painfully obtained by source-level formal verification. Recent experimental studies [1] show that many widely-used production-quality compilers suffer from miscompilation. The formal verification of compilers and related code generators is a\u00a0\u2026", "num_citations": "3\n", "authors": ["661"]}
{"title": "How much is a mechanized proof worth, certification-wise\n", "abstract": " Purpose: obtain appropriate assurance that the tools are at least as dependable as the manual processes that they are replacing.", "num_citations": "3\n", "authors": ["661"]}
{"title": "From Krivine's machine to the Caml implementations\n", "abstract": " From Krivine\u2019s machine to the Caml implementations Page 1 From Krivine\u2019s machine to the Caml implementations Xavier Leroy INRIA Rocquencourt 1 Page 2 In this talk An illustration of the strengths and limitations of abstract machines for the purpose of efficient execution of strict functional languages (Caml). 1. A retrospective on the ZAM, a call-by-value variant of Krivine\u2019s machine. 2. From abstract machines to efficient PL implementations: the example of Caml Light and Objective Caml. 3. Beyond abstract machines: push-enter models vs. eval-apply models. 2 Page 3 Why are abstract machines interesting? On the theory side (\u03bb-calculus, semantics): Abstract machines expose concepts lacking or implicit in the \u03bb-calculus: \u2022 Reduction strategy, evaluation order. \u2022 Data representations, esp. closures and environments. On the implementation side: Compilation to abstract machine code offers much better performance \u2026", "num_citations": "3\n", "authors": ["661"]}
{"title": "Exploiting type systems and static analyses for smart card security\n", "abstract": " Exploiting type systems and static analyses for smart card security Page 1 Exploiting type systems and static analyses for smart card security Xavier Leroy INRIA Rocquencourt & Trusted Logic 1 Page 2 Outline 1. What makes strongly typed programs more secure? 2. Enforcing strong typing (bytecode verification). 3. Static analyses beyond strong typing. 2 Page 3 Part 1 The role of strong typing 3 Page 4 Context OS Appl.1 Appl.2 Appl.3 Appl.4 A secure system running multiple applications, possibly untrusted: \u2022 Workstation: OS kernel + users\u2019 applications. \u2022 Web browser: browser + Web applets + Web scripts. \u2022 Java Card: OS + applications + cardlets. Must ensure isolation between the applications (integrity, confidentiality), as well as controlled communications between them. 4 Page 5 Enforcing isolation between applications Hardware protection mechanisms: (classic OS model) \u2022 Hardware access control on memory \u2026", "num_citations": "3\n", "authors": ["661"]}
{"title": "The caml special light system: modules and efficient compilation for caml\n", "abstract": " The Caml special light system : modules and efficient compilation for Caml - OpenGrey fra | eng OpenGrey Open System for Information on Grey literature in Europe Home Search Subjects Partners Export Help Search XML To cite or link to this reference: http://hdl.handle.net/10068/40982 Title : The Caml special light system : modules and efficient compilation for Caml Le systeme Caml special light : modules et compilation efficace en Caml Author : Leroy, Xavier ; Corporate author : Institut National de Recherche en Informatique et en Automatique (INRIA), 78 - Rocquencourt (France). Unite de Recherche de Rocquencourt ; Publication year : 1995 Language : French ; Pagination/Size : 20 p. ; SIGLE classification : 09H - Computer software, programming ; Keyword(s) : The Caml special light system : modules and efficient compilation for Caml [ ML ; Functional language ; Module system ; Functor ; Separate compilation ; \u2026", "num_citations": "3\n", "authors": ["661"]}
{"title": "Le Logiciel: entre l'esprit et la mati\u00e8re\n", "abstract": " Chaire Sciences du logiciel Un m\u00eame mat\u00e9riel informatique peut remplir de nombreuses fonctions diff\u00e9rentes par simple changement du logiciel qu\u2019il ex\u00e9cute. Cette extraordinaire plasticit\u00e9 a permis \u00e0 l\u2019ordinateur de sortir des centres de calcul et de se r\u00e9pandre partout, des objets du quotidien aux infrastructures de la cit\u00e9. Quels concepts fondamentaux sous-tendent cette prouesse technique? Comment ma\u00eetriser l\u2019incroyable et souvent effrayante complexit\u00e9 du logiciel? Comment \u00e9viter les \u00abbugs\u00bb de programmation et r\u00e9sister aux attaques? Comment \u00e9tablir qu\u2019un logiciel est digne de confiance? \u00c0 ces questions, la logique math\u00e9matique offre des \u00e9l\u00e9ments de r\u00e9ponse qui permettent de construire une approche scientifiquement rigoureuse du logiciel. Xavier Leroy est informaticien, sp\u00e9cialiste des langages et outils de programmation. Il est l\u2019un des auteurs du langage OCaml et du compilateur formellement v\u00e9rifi\u00e9 CompCert. Auparavant chercheur \u00e0 l\u2019Inria, il a \u00e9t\u00e9 nomm\u00e9 professeur au Coll\u00e8ge de France, titulaire de la chaire Sciences du logiciel, en mai 2018.", "num_citations": "2\n", "authors": ["661"]}
{"title": "The formal verification of compilers\n", "abstract": " 3 Compilation to virtual machine code: before execution, the program is translated to a sequence of instructions, These instructions are those of a virtual machine. They do not correspond to that of an existing hardware processor, but are chosen close to the basic operations of the source language. Then, 1 either the virtual machine instructions are interpreted (efficiently) 2 or they are further translated to machine code (JIT).", "num_citations": "2\n", "authors": ["661"]}
{"title": "Formally verifying a compiler: Why? How? How far?\n", "abstract": " Given the complexity and sophistication of code generation and optimization algorithms, and the difficulty of systematically testing a compiler, it is unsurprising that bugs occur in compilers and cause miscompilation: incorrect executable code is silently generated from a correct source program. The formal verification of a compiler is a radical solution to the miscompilation issue.  By applying formal methods (program proof) to the compiler itself, compiler verification proves, with mathematical certainty, that the generated executable code behaves exactly as prescribed by the semantics of the source program. Why indulge in compiler verification?  Miscompilation bugs are uncommon enough that, for ordinary, non-critical software, they are negligible compared with the bugs already present in the source program.  This is no longer true, however, for critical software, as found in aircraft, medical equipment or nuclear plants, for example. There, miscompilation is a concern, which is currently addressed in unsatisfactory ways such as turning all optimizations off.  The risk of miscompilation also diminishes the usefulness of formal methods (model checking, static analysis, program proof) applied at the source level: the guarantees so painfully obtained by source-level verification may not extend to the compiled code that actually runs. How to verify a compiler?  For every pass, there is a choice between 1- proving its implementation correct once and for all, and 2- leaving the implementation untrusted, but at each run feed its input and output into a validator: a separate algorithm that tries to establish semantic preservation between input and output code, and\u00a0\u2026", "num_citations": "2\n", "authors": ["661"]}
{"title": "Some uses of Caml in industry\n", "abstract": " Some uses of Caml in industry Page 1 Some uses of Caml in industry Xavier Leroy INRIA Paris-Rocquencourt CUFP 2007 X. Leroy (INRIA) Some uses of Caml in industry CUFP 2007 1 / 34 Page 2 Outline 1 Examples of industrial uses of Caml 2 Perceived needs; the Caml consortium experiment 3 A quick look at the smart card industry 4 Conclusions X. Leroy (INRIA) Some uses of Caml in industry CUFP 2007 2 / 34 Page 3 Static Driver Verifier (Microsoft) Static verification of Windows kernel-mode drivers, detecting violations of the Windows Driver Model API and usage rules. Sophisticated static analysis with model checking technology. Distributed to developers as part of the Windows Driver Kit. We developed SLAM using INRIA\u2019s OCaml functional programming language. The expressiveness of this language and robustness of its implementation provided a great productivity boost. MSR-TR-2004-08, T.Ball, B.Cook, \u2026", "num_citations": "2\n", "authors": ["661"]}
{"title": "Security properties of typed applets\n", "abstract": " This paper formcdizes the folklore result that strongly-typed applets are more secure than untyped ones. We formulate and prove several security properties that all well-typed applets possess, and identify sufficient conditions for the applet execution environment to be safe, such as procedural encapsulation, type abstraction, and systematic typebased placement of run-time checks. These results are a first step towards formal techniques for developing and validating safe execution environments for applets.", "num_citations": "2\n", "authors": ["661"]}
{"title": "Compilation techniques for functional and object-oriented languages\n", "abstract": " The high-level features of functional and OO languages are not hard to translate into a simple C-like intermediate language.", "num_citations": "2\n", "authors": ["661"]}
{"title": "In search of software perfection\n", "abstract": " In search of software perfection Page 1 In search of software perfection Xavier Leroy Inria Paris Milner award lecture, Royal Society, 2016-11-24 Page 2 Part I Imperfect software Page 3 Software crashes. . . Paris highway Las Vegas billboard Page 4 Software crashes. . . Metro station, Manhattan Heathrow airport Page 5 Software crashes. . . Olympic games, 2008 Nine Inch Nails concert Page 6 Software has security holes. . . Attacker can remotely control many of the car\u2019s functions. Fiat-Chrysler recalled 1.5 M vehicles for software update. he architecture of the 2014 Jeep Cherokee was very intriguing to us due to the fact that the head un Radio) is connected to both CAN buses that are implemented in the vehicle. Figure: 2014 Jeep Cherokee architecture diagram Remote Exploitation of an Unaltered Passenger Vehicle, C. Miller and C. Valasek, 2015 Page 7 Software kills. . . Therac 25 radiation machine Newborn \u2026", "num_citations": "1\n", "authors": ["661"]}
{"title": "Formally verifying a compiler: what does it mean, exactly?\n", "abstract": " To improve the quality of C compilers, we created Csmith, a randomized test-case generation tool, and spent three years using it to find compiler bugs. During this period we reported more than 325 previously unknown bugs to compiler developers. Every compiler we tested was found to crash and also to silently generate wrong code when presented with valid input.", "num_citations": "1\n", "authors": ["661"]}
{"title": "Formal proofs of code generation and verification tools\n", "abstract": " Tool-assisted verification of critical software has great potential but is limited by two risks: unsoundness of the verification tools, and miscompilation when generating executable code from the sources that were verified. A radical solution to these two risks is the deductive verification of compilers and verification tools themselves. In this invited talk, I describe two ongoing projects along this line: CompCert, a verified C\u00a0compiler, and Verasco, a verified static analyzer based on abstract interpretation.", "num_citations": "1\n", "authors": ["661"]}
{"title": "Formal verification of a static analyzer: abstract interpretation in type theory\n", "abstract": " This invited talk describes the logical foundations and the status of the ongoing Verasco project, whose aim is to formalize and prove sound a static analyzer for the C programming language based on abstract interpretation, using the Coq proof assistant. (Joint work with David Pichardie, Sandrine Blazy, Jacques-Henri Jourdan, and Vincent Laporte.)", "num_citations": "1\n", "authors": ["661"]}
{"title": "Safety first! technical perspective\n", "abstract": " Software misbehaves all too often. This is a truism, but also the driving force behind many computing techniques intended to increase software reliability, safety, and security, ranging from basic testing to full formal verification.In this wide spectrum of approaches, a sweet spot is type and memory safety. Rather than attempting to rule out all bugs, type and memory safety focuses on strict enforcement of a few basic safety properties: a character string is not a code pointer; arrays are always accessed within bounds; memory blocks are not accessed after deallocation; pointers or object references cannot be forged from integers; and so on. Such properties are enforced through a combination of static (compile-time) type-checking, dynamic (runtime) checks such as array bound checks, and automatic memory management. These humble safety properties not only catch a number of common programming errors, but are\u00a0\u2026", "num_citations": "1\n", "authors": ["661"]}
{"title": "Extended recursive definitions in call-by-value languages, with applications to mixin modules and recursive modules\n", "abstract": " Recursive definitions and call-by-value Call-by-name or lazy languages naturally support the evaluation of arbitrary recursive definitions x= e [x]. On-demand unrolling of e leads either to the fixpoint when it exists, or to divergence otherwise (as in x= 1+ x). This is not possible with a strict call-by-value strategy, where the right-hand side e [x] must be evaluated exactly once and at definition time. Therefore, CBV languages must restrict the expressions e [x] allowed as rhs of recursive definitions\u2013typically, in ML, e [x] must be a function abstraction \u03bbx. e.However, less drastic restrictions can remain compatible with CBV. A famous example is Scheme\u2019s letrec construct [8, 9], which builds on a \u201cbackpatching\u201d imperative semantics. Operationally, to evaluate (letrec (xe) f), first, x is bound to a reference initialized to a special undefined value; then, e is evaluated (causing an error if the undefined value of x is used); finally, x is updated (via reference assignment) with the value thus obtained.", "num_citations": "1\n", "authors": ["661"]}
{"title": "Objects, classes and modules in Objective Caml (invited lecture, abstract only)\n", "abstract": " In a programming language with procedures and assignments, it is often important to isolate uses of state to particular program fragments. The frameworks of type, region, and effect inference, and monadic state are technologies that have been used to state and enforce the property that an expression has no visible side-effects. This property has been exploited to justify the deallocation of memory regions despite the presence of dangling pointers. Starting from an idea developed in the context of monadic state in Haskell, we develop an ML-like language with full assignments and an operator that enforces the encapsulation of effects. Using this language, we formalize and prove the folklore connection between effect masking and monadic encapsulation. Then, by employing a novel set of reductions to deal with dangling pointers, we establish the soundness of the type-based encapsulation with a proof based on a\u00a0\u2026", "num_citations": "1\n", "authors": ["661"]}
{"title": "Types in Compilation: Second International Workshop, TIC'98, Kyoto, Japan, March 25-27, 1998 Proceedings\n", "abstract": " This book constitutes the thoroughly refereed post-workshop proceedings of the Second International Workshop on Types in Compilation, TIC'98, held in Kyoto, Japan in March 1998. The book presents 13 revised full papers carefully selected during an iterated reviewing process together with three invited papers. The papers are organized in topical sections on typed intermediate languages, program analyses, program transformations and code generation, memory management, partial evaluation and run-time code generation, and distributed computing.", "num_citations": "1\n", "authors": ["661"]}
{"title": "Proceedings of the Second International Workshop on Types in Compilation\n", "abstract": " Proceedings of the Second International Workshop on Types in Compilation | Guide Proceedings ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsTIC '98 ABSTRACT No abstract available. Comments Login options Check if you have access through your login credentials or your institution to get full access on this article. Sign in Full Access Get this Publication Information Contributors Published in Guide Proceedings cover image TIC '98: Proceedings of the Second International Workshop on Types in Compilation March 1998 296 pages ISBN:3540649255 Editors: Xavier Leroy profile image Xavier Leroy, Atsushi Ohori \u2026", "num_citations": "1\n", "authors": ["661"]}