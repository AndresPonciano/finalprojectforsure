{"title": "Stream processing on demand for lambda architectures\n", "abstract": " Growing amounts of data and the demand to process them within time constraints have led to the development of big data systems. A generic principle to design such systems that allows for low latency results is called the lambda architecture. It defines that data is analyzed twice by combining batch and stream processing techniques in order to provide a real time view. This redundant processing of data makes this architecture very expensive. In cases where process results are not continuously required to be low latency or time constraints lie within several minutes, a clear decision whether both processing layers are inevitable is not possible yet. Therefore, we propose stream processing on demand within the lambda architecture in order to efficiently use resources and reduce hardware investments. We use performance models as an analytical decision-making solution to predict response times of batch\u00a0\u2026", "num_citations": "26\n", "authors": ["724"]}
{"title": "Modeling and simulating apache spark streaming applications\n", "abstract": " Stream processing systems are used to analyze big data streams with low latency. The performance in terms of response time and throughput is crucial to ensure all arriving data are processed in time. This depends on various factors such as the complexity of used algorithms and configurations of such distributed systems and applications. To ensure a desired system behavior, performance evaluations should be conducted to determine the throughput and required resources in advance. In this paper, we present an approach to predict the response time of Apache Spark Streaming applications by modeling and simulating them. In a preliminary controlled experiment, our simulation results suggest accurate prediction values for an upscaling scenario.", "num_citations": "19\n", "authors": ["724"]}
{"title": "Modeling big data systems by extending the Palladio component model\n", "abstract": " The growing availability of big data has induced new storing and processing techniques implemented in big data systems such as Apache Hadoop or Apache Spark. With increased implementations of these systems in organizations, simultaneously, the requirements regarding performance qualities such as response time, throughput, and resource utilization increase to create added value. Guaranteeing these performance requirements as well as efficiently planning needed capacities in advance is an enormous challenge. Performance models such as the Palladio component model (PCM) allow for addressing such problems. Therefore, we propose a metamodel extension for PCM to be able to model typical characteristics of big data systems. The extension consists of two parts. First, the meta-model is extended to support parallel computing by forking an operation multiple times on a computer cluster as intended by the single instruction, multiple data (SIMD) architecture. Second, modeling of computer clusters is integrated into the meta-model so operations can be properly scheduled on contained computing nodes.", "num_citations": "14\n", "authors": ["724"]}
{"title": "Model-based Performance Evaluation of Batch and Stream Applications for Big Data\n", "abstract": " Batch and stream processing represent the two main approaches implemented by big data systems such as Apache Spark and Apache Flink. Although only stream applications are intended to satisfy real-time requirements, both approaches are required to meet certain response time constraints. In addition, cluster architectures continuously expand and computing resources constitute high investments and expenses for organizations. Therefore, planning required capacities and predicting response times is crucial. In this work, we present a performance modeling and simulation approach by using and extending the Palladio component model. We predict performance metrics of batch and stream applications and its underlying processing systems by the example of Apache Spark on Apache Hadoop. Whereas most related work concentrates on one specific processing technique and focuses on the metric response\u00a0\u2026", "num_citations": "13\n", "authors": ["724"]}
{"title": "Model-based performance evaluation of large-scale smart metering architectures\n", "abstract": " Smart meter devices are used to monitor and control energy consumption and are interlinked with smart grids. Their growing use leads to an extensive amount of available data to be processed and causes smart grids to evolve to large-scale systems of systems. Guaranteeing appropriate scalability and performance characteristics is a tremendous challenge. In this paper, we focus on the provisioning of sufficient computing capacity to efficiently analyze the produced data in such a distributed system. For this purpose, we show the use of performance models to plan and simulate this distributed computation in smart grid systems. It demonstrates how different system architectures can be evaluated and required capacities can be estimated to cope with the occurring data volume. We analyze response times for time-critical tasks and assess the scalability of smart grid systems.", "num_citations": "5\n", "authors": ["724"]}
{"title": "PerTract: Model Extraction and Specification of Big Data Systems for Performance Prediction by the Example of Apache Spark and Hadoop\n", "abstract": " Evaluating and predicting the performance of big data applications are required to efficiently size capacities and manage operations. Gaining profound insights into the system architecture, dependencies of components, resource demands, and configurations cause difficulties to engineers. To address these challenges, this paper presents an approach to automatically extract and transform system specifications to predict the performance of applications. It consists of three components. First, a system-and tool-agnostic domain-specific language (DSL) allows the modeling of performance-relevant factors of big data applications, computing resources, and data workload. Second, DSL instances are automatically extracted from monitored measurements of Apache Spark and Apache Hadoop (ie, YARN and HDFS) systems. Third, these instances are transformed to model-and simulation-based performance evaluation tools to allow predictions. By adapting DSL instances, our approach enables engineers to predict the performance of applications for different scenarios such as changing data input and resources. We evaluate our approach by predicting the performance of linear regression and random forest applications of the HiBench benchmark suite. Simulation results of adjusted DSL instances compared to measurement results show accurate predictions errors below 15% based upon averages for response times and resource utilization. View Full-Text", "num_citations": "4\n", "authors": ["724"]}
{"title": "Towards a model-driven performance prediction approach for internet of things architectures\n", "abstract": " Indisputable, security and interoperability play major concerns in Internet of Things (IoT) architectures and applications. In this paper, however, we emphasize the role and importance of performance and scalability as additional, crucial aspects in planning and building sustainable IoT solutions. IoT architectures are complicated system-of-systems that include different developer roles, development processes, organizational units, and a multilateral governance. Its performance is often neglected during development but becomes a major concern at the end of development and results in supplemental efforts, costs, and refactoring. It should not be relied on linearly scaling for such systems only by using up-to-date technologies that may promote such behavior. Furthermore, different security or interoperability choices also have a considerable impact on performance and may result in unforeseen trade-offs. Therefore, we propose and pursue the vision of a model-driven approach to predict and evaluate the performance of IoT architectures early in the system lifecylce in order to guarantee efficient and scalable systems reaching from sensors to business applications.", "num_citations": "3\n", "authors": ["724"]}
{"title": "Cloudburst-simulating workload for IaaS clouds\n", "abstract": " In this work we implemented Cloudburst to generate realistic workload in Infrastructure as a Service cloud testbeds. Our goal was to minimize the memory footprint of such workload generators by leveraging alternative programming paradigms for highly concurrent applications. In contrast to many existing we leverage the concurrency model of the Go programming language instead of threads. Initial benchmarks with Cloudburst and Rain suggest that Cloudburst consumes significantly less memory at the cost of a higher CPU footprint. In our experimental testbed memory is a more critical resource. Leveraging Cloudburst allows us to run larger benchmarks with the same hardware.", "num_citations": "2\n", "authors": ["724"]}