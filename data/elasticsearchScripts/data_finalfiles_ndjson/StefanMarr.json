{"title": "Partitioned global address space languages\n", "abstract": " The Partitioned Global Address Space (PGAS) model is a parallel programming model that aims to improve programmer productivity while at the same time aiming for high performance. The main premise of PGAS is that a globally shared address space improves productivity, but that a distinction between local and remote data accesses is required to allow performance optimizations and to support scalability on large-scale parallel architectures. To this end, PGAS preserves the global address space while embracing awareness of nonuniform communication costs. Today, about a dozen languages exist that adhere to the PGAS model. This survey proposes a definition and a taxonomy along four axes: how parallelism is introduced, how the address space is partitioned, how data is distributed among the partitions, and finally, how data is accessed across partitions. Our taxonomy reveals that today\u2019s PGAS languages\u00a0\u2026", "num_citations": "90\n", "authors": ["1843"]}
{"title": "Cross-Language Compiler Benchmarking\u2014Are We Fast Yet?\n", "abstract": " Comparing the performance of programming languages is difficult because they differ in many aspects including preferred programming abstractions, available frameworks, and their runtime systems. Nonetheless, the question about relative performance comes up repeatedly in the research community, industry, and wider audience of enthusiasts.   This paper presents 14 benchmarks and a novel methodology to assess the compiler effectiveness across language implementations. Using a set of common language abstractions, the benchmarks are implemented in Java, JavaScript, Ruby, Crystal, Newspeak, and Smalltalk. We show that the benchmarks exhibit a wide range of characteristics using language-agnostic metrics. Using four different languages on top of the same compiler, we show that the benchmarks perform similarly and therefore allow for a comparison of compiler effectiveness across languages\u00a0\u2026", "num_citations": "53\n", "authors": ["1843"]}
{"title": "Zero-Overhead Metaprogramming: Reflection and Metaobject Protocols Fast and without Compromises\n", "abstract": " Runtime metaprogramming enables many useful applications and is often a convenient solution to solve problems in a generic way, which makes it widely used in frameworks, middleware, and domain-specific languages. However, powerful metaobject protocols are rarely supported and even common concepts such as reflective method invocation or dynamic proxies are not optimized. Solutions proposed in literature either restrict the metaprogramming capabilities or require application or library developers to apply performance improving techniques. For overhead-free runtime metaprogramming, we demonstrate that dispatch chains, a generalized form of polymorphic inline caches common to self-optimizing interpreters, are a simple optimization at the language-implementation level. Our evaluation with self-optimizing interpreters shows that unrestricted metaobject protocols can be realized for the first time\u00a0\u2026", "num_citations": "36\n", "authors": ["1843"]}
{"title": "Tracing vs. Partial Evaluation: Comparing Meta-Compilation Approaches for Self-Optimizing Interpreters\n", "abstract": " Tracing and partial evaluation have been proposed as meta-compilation techniques for interpreters to make just-in-time compilation language-independent. They promise that programs executing on simple interpreters can reach performance of the same order of magnitude as if they would be executed on state-of-the-art virtual machines with highly optimizing just-in-time compilers built for a specific language. Tracing and partial evaluation approach this meta-compilation from two ends of a spectrum, resulting in different sets of tradeoffs. This study investigates both approaches in the context of self-optimizing interpreters, a technique for building fast abstract-syntax-tree interpreters. Based on RPython for tracing and Truffle for partial evaluation, we assess the two approaches by comparing the impact of various optimizations on the performance of an interpreter for SOM, an object-oriented dynamically-typed\u00a0\u2026", "num_citations": "32\n", "authors": ["1843"]}
{"title": "Fork/join parallelism in the wild: Documenting patterns and anti-patterns in java programs using the fork/join framework\n", "abstract": " Now that multicore processors are commonplace, developing parallel software has escaped the confines of high-performance computing and enters the mainstream. The Fork/Join framework, for instance, is part of the standard Java platform since version 7. Fork/Join is a high-level parallel programming model advocated to make parallelizing recursive divide-and-conquer algorithms particularly easy. While, in theory, Fork/Join is a simple and effective technique to expose parallelism in applications, it has not been investigated before whether and how the technique is applied in practice. We therefore performed an empirical study on a corpus of 120 open source Java projects that use the framework for roughly 362 different tasks.", "num_citations": "24\n", "authors": ["1843"]}
{"title": "Domains: safe sharing among actors\n", "abstract": " The actor model is a concurrency model that avoids issues such as deadlocks and data races by construction, and thus facilitates concurrent programming. While it has mainly been used for expressing distributed computations, it is equally useful for modeling concurrent computations in a single shared memory machine. In component based software, the actor model lends itself to divide the components naturally over different actors and use message-passing concurrency for the interaction between these components. The tradeoff is that the actor model sacrifices expressiveness and efficiency with respect to parallel access to shared state.This paper gives an overview of the disadvantages of the actor model when trying to express shared state and then formulates an extension of the actor model to solve these issues. Our solution proposes domains and synchronization views to solve the issues without\u00a0\u2026", "num_citations": "21\n", "authors": ["1843"]}
{"title": "The som family: Virtual machines for teaching and research\n", "abstract": " This paper introduces the SOM (Simple Object Machine) family of virtual machine (VM) implementations, a collection of VMs for the same Smalltalk dialect addressing students at different levels of expertise. Starting from a Java-based implementation, several ports of the VM to different programming languages have been developed and put to successful use in teaching at both undergraduate and graduate levels since 2006. Moreover, the VMs have been used in various research projects. The paper documents the rationale behind each of the SOM VMs and results that have been achieved in teaching and research.", "num_citations": "21\n", "authors": ["1843"]}
{"title": "Just-in-time data structures\n", "abstract": " Today, software engineering practices focus on finding the single``right''data representation for a program. The``right''data representation, however, might not exist: changing the representation of an object during program execution can be better in terms of performance. To this end we introduce Just-in-Time Data Structures, which enable representation changes at runtime, based on declarative input from a performance expert programmer. Just-in-Time Data Structures are an attempt to shift the focus from finding the``right''data structure to finding the``right''sequence of data representations. We present JitDS, a programming language to develop such Just-in-Time Data Structures. Further, we show two example programs that benefit from changing the representation at runtime.", "num_citations": "20\n", "authors": ["1843"]}
{"title": "Towards an actor-based concurrent machine model\n", "abstract": " In this position paper we propose to extend an existing delegation-based machine model with concurrency primitives. The original machine model which is built on the concepts of objects, messages, and delegation, provides support for languages enabling multi-dimensional separation of concerns (MDSOC). We propose to extend this model with an actor-based concurrency model, allowing for both true parallelism as well as lightweight concurrency primitives such as coroutines. In order to demonstrate its expressiveness, we informally describe how three high-level languages supporting different concurrency models can be mapped onto our extended machine model. We also provide an outlook on the extended model's potential to support concurrency-related MDSOC features.", "num_citations": "20\n", "authors": ["1843"]}
{"title": "An analysis of x86-64 inline assembly in c programs\n", "abstract": " C codebases frequently embed nonportable and unstandardized elements such as inline assembly code. Such elements are not well understood, which poses a problem to tool developers who aspire to support C code. This paper investigates the use of x86-64 inline assembly in 1264 C projects from GitHub and combines qualitative and quantitative analyses to answer questions that tool authors may have. We found that 28.1% of the most popular projects contain inline assembly code, although the majority contain only a few fragments with just one or two instructions. The most popular instructions constitute a small subset concerned largely with multicore semantics, performance optimization, and hardware control. Our findings are intended to help developers of C-focused tools, those testing compilers, and language designers seeking to reduce the reliance on inline assembly. They may also aid the design of\u00a0\u2026", "num_citations": "18\n", "authors": ["1843"]}
{"title": "Domains: Sharing state in the communicating event-loop actor model\n", "abstract": " The actor model is a message-passing concurrency model that avoids deadlocks and low-level data races by construction. This facilitates concurrent programming, especially in the context of complex interactive applications where modularity, security and fault-tolerance are required. The tradeoff is that the actor model sacrifices expressiveness and safety guarantees with respect to parallel access to shared state.In this paper we present domains as a set of novel language abstractions for safely encapsulating and sharing state within the actor model. We introduce four types of domains, namely immutable, isolated, observable and shared domains that each is tailored to a certain access pattern on that shared state. The domains are characterized with an operational semantics. For each we discuss how the actor model\u05f3s safety guarantees are upheld even in the presence of conceptually shared state. Furthermore\u00a0\u2026", "num_citations": "14\n", "authors": ["1843"]}
{"title": "Intermediate language design of high-level language virtual machines: Towards comprehensive concurrency support\n", "abstract": " Today's major high-level language virtual machines (VMs) are becoming successful in being multi-language execution platforms, hosting a wide range of languages. With the transition from few-core to many-core processors, we argue that VMs will also have to abstract from concrete concurrency models at the hardware level, to be able to support a wide range of abstract concurrency models on a language level. To overcome the lack of sufficient abstractions for concurrency concepts in VMs, we proposed earlier to extend VM intermediate languages by special concurrency constructs [Marr et al. 2009].", "num_citations": "14\n", "authors": ["1843"]}
{"title": "Are We There Yet? Simple Language Implementation Techniques for the 21st Century\n", "abstract": " Research on language implementation techniques has regained importance with the rise of domain-specific languages (DSLs). Although DSLs can help manage a domain's complexity, building highly optimizing compilers or virtual machines is rarely affordable. So, performance remains an issue. Ideally, you would implement a simple interpreter and still be able to achieve acceptable performance. RPython and Truffle are implementation techniques based on simple interpreters; they promise to perform at the same order of magnitude as highly optimizing virtual machines. This case study compares the two techniques to identify their similarities, weaknesses, and areas for further research.", "num_citations": "13\n", "authors": ["1843"]}
{"title": "Parallelization of dynamic languages: synchronizing built-in collections\n", "abstract": " Dynamic programming languages such as Python and Ruby are widely used, and much effort is spent on making them efficient. One substantial research effort in this direction is the enabling of parallel code execution. While there has been significant progress, making dynamic collections efficient, scalable, and thread-safe is an open issue. Typical programs in dynamic languages use few but versatile collection types. Such collections are an important ingredient of dynamic environments, but are difficult to make safe, efficient, and scalable.   In this paper, we propose an approach for efficient and concurrent collections by gradually increasing synchronization levels according to the dynamic needs of each collection instance. Collections reachable only by a single thread have no synchronization, arrays accessed in bounds have minimal synchronization, and for the general case, we adopt the Layout Lock paradigm\u00a0\u2026", "num_citations": "11\n", "authors": ["1843"]}
{"title": "Identifying A Unifying Mechanism for the Implementation of Concurrency Abstractions on Multi-Language Virtual Machines\n", "abstract": " Supporting all known abstractions for concurrent and parallel programming in a virtual machines (VM) is a futile undertaking, but it is required to give programmers appropriate tools and performance. Instead of supporting all abstractions directly, VMs need a unifying mechanism similar to INVOKEDYNAMIC for JVMs.             Our survey of parallel and concurrent programming concepts identifies concurrency abstractions as the ones benefiting most from support in a VM. Currently, their semantics is often weakened, reducing their engineering benefits. They require a mechanism to define flexible language guarantees.             Based on this survey, we define an ownership-based meta-object protocol as candidate for VM support. We demonstrate its expressiveness by implementing actor semantics, software transactional memory, agents, CSP, and active objects. While the performance of our prototype confirms\u00a0\u2026", "num_citations": "11\n", "authors": ["1843"]}
{"title": "Building efficient and highly run-time adaptable virtual machines\n", "abstract": " Programming language virtual machines (VMs) realize language semantics, enforce security properties, and execute applications efficiently. Fully Reflective Execution Environments (EEs) are VMs that additionally expose their whole structure and behavior to applications. This enables develop- ers to observe and adapt VMs at run time. However, there is a belief that reflective EEs are not viable for practical usages because such flexibility would incur a high performance overhead. To refute this belief, we built a reflective EE on top of a highly optimizing dynamic compiler. We introduced a new optimization model that, based on the conjecture that variability of low-level (EE-level) reflective behavior is low in many scenarios, mitigates the most significant sources of the performance overheads related to the reflective capabilities in the EE. Our experiments indicate that reflective EEs can reach peak performance in the\u00a0\u2026", "num_citations": "10\n", "authors": ["1843"]}
{"title": "Towards fully reflective environments\n", "abstract": " Modern development environments promote live programming (LP) mechanisms because it enhances the development experience by providing instantaneous feedback and interaction with live objects. LP is typically supported with advanced reflective techniques within dynamic languages. These languages run on top of Virtual Machines (VMs) that are built in a static manner so that most of their components are bound at compile time. As a consequence, VM developers are forced to work using the traditional edit-compile-run cycle, even when they are designing LP-supporting environments. In this paper we explore the idea of bringing LP techniques to the VM domain for improving their observability, evolution and adaptability at run-time. We define the notion of fully reflective execution environments (EEs), systems that provide reflection not only at the application level but also at the level of the VM. We\u00a0\u2026", "num_citations": "10\n", "authors": ["1843"]}
{"title": "Trace Register Allocation Policies: Compile-time vs. Performance Trade-offs\n", "abstract": " Register allocation is an integral part of compilation, regardless of whether a compiler aims for fast compilation or optimal code quality. State-of-the-art dynamic compilers often use global register allocation approaches such as linear scan. Recent results suggest that non-global trace-based register allocation approaches can compete with global approaches in terms of allocation quality. Instead of processing the whole compilation unit (ie, method) at once, a trace-based register allocator divides the problem into linear code segments, called traces.", "num_citations": "9\n", "authors": ["1843"]}
{"title": "Gems: shared-memory parallel programming for node. js\n", "abstract": " JavaScript is the most popular programming language for client-side Web applications, and Node.js has popularized the language for server-side computing, too. In this domain, the minimal support for parallel programming remains however a major limitation. In this paper we introduce a novel parallel programming abstraction called Generic Messages (GEMs). GEMs allow one to combine message passing and shared-memory parallelism, extending the classes of parallel applications that can be built with Node.js. GEMs have customizable semantics and enable several forms of thread safety, isolation, and concurrency control. GEMs are designed as convenient JavaScript abstractions that expose high-level and safe parallelism models to the developer. Experiments show that GEMs outperform equivalent Node.js applications thanks to their usage of shared memory.", "num_citations": "9\n", "authors": ["1843"]}
{"title": "Tanks: Multiple reader, single writer actors\n", "abstract": " In the past, the Actor Model has mainly been explored in a distributed context. However, more and more application developers are also starting to use it to program shared-memory multicore machines because of the safety guarantees it provides. It avoids issues such as deadlocks and race conditions by construction, and thus facilitates concurrent programming. The tradeoff is that the Actor Model sacrifices expressiveness with respect to accessing shared state because actors are fully isolated from each other (aka\" shared-nothing parallelism\"). There is a need for more high level synchronization mechanisms that integrate with the actor model without sacrificing the safety and liveness guarantees it provides. This paper introduces a variation on the communicating event-loops actor model called the TANK model. A tank is an actor that can expose part of its state as a shared read-only resource. The model ensures\u00a0\u2026", "num_citations": "9\n", "authors": ["1843"]}
{"title": "Parallel gesture recognition with soft real-time guarantees\n", "abstract": " Applying imperative programming techniques to process event streams, like those generated by multi-touch devices and 3D cameras, has significant engineering drawbacks. Declarative approaches solve these problems but have not been able to scale on multicore systems while providing guaranteed response times.", "num_citations": "9\n", "authors": ["1843"]}
{"title": "Parallel gesture recognition with soft real-time guarantees\n", "abstract": " Using imperative programming to process event streams, such as those generated by multi-touch devices and 3D cameras, has significant engineering drawbacks. Declarative approaches solve common problems but so far, they have not been able to scale on multicore systems while providing guaranteed response times.We propose PARTE, a parallel scalable complex event processing engine that allows for a declarative definition of event patterns and provides soft real-time guarantees for their recognition. The proposed approach extends the classical Rete algorithm and maps event matching onto a graph of actor nodes. Using a tiered event matching model, PARTE provides upper bounds on the detection latency by relying on a combination of non-blocking message passing between Rete nodes and safe memory management techniques.The performance evaluation shows the scalability of our approach on\u00a0\u2026", "num_citations": "7\n", "authors": ["1843"]}
{"title": "Optimizing Communicating Event-Loop Languages with Truffle\n", "abstract": " Communicating Event-Loop Languages similar to E and AmbientTalk are recently gaining more traction as a subset of actor languages. With the rise of JavaScript, E\u2019s notion of vats and non-blocking communication based on promises entered the mainstream. For implementations, the combination of dynamic typing, asynchronous message sending, and promise resolution pose new optimization challenges.This paper discusses these challenges and presents initial experiments for a Newspeak implementation based on the Truffle framework. Our implementation is on average 1.65 x slower than Java on a set of 14 benchmarks. Initial optimizations improve the performance of asynchronous messages and reduce the cost of encapsulation on microbenchmarks by about 2x. Parallel actor benchmarks further show that the system scales based on the workload characteristics. Thus, we conclude that Truffle is a promising platform also for communicating event-loop languages.", "num_citations": "7\n", "authors": ["1843"]}
{"title": "Towards composable concurrency abstractions\n", "abstract": " In the past decades, many different programming models for managing concurrency in applications have been proposed, such as the actor model, Communicating Sequential Processes, and Software Transactional Memory. The ubiquity of multi-core processors has made harnessing concurrency even more important. We observe that modern languages, such as Scala, Clojure, or F#, provide not one, but multiple concurrency models that help developers manage concurrency. Large end-user applications are rarely built using just a single concurrency model. Programmers need to manage a responsive UI, deal with file or network I/O, asynchronous workflows, and shared resources. Different concurrency models facilitate different requirements. This raises the issue of how these concurrency models interact, and whether they are composable. After all, combining different concurrency models may lead to subtle bugs or inconsistencies. In this paper, we perform an in-depth study of the concurrency abstractions provided by the Clojure language. We study all pairwise combinations of the abstractions, noting which ones compose without issues, and which do not. We make an attempt to abstract from the specifics of Clojure, identifying the general properties of concurrency models that facilitate or hinder composition.", "num_citations": "7\n", "authors": ["1843"]}
{"title": "Insertion tree phasers: Efficient and scalable barrier synchronization for fine-grained parallelism\n", "abstract": " This paper presents an algorithm and a data structure for scalable dynamic synchronization in fine-grained parallelism. The algorithm supports the full generality of phasers with dynamic, two-phase, and point-to-point synchronization. It retains the scalability of classical tree barriers, but provides unbounded dynamicity by employing a tailor-made insertion tree data structure. It is the first completely documented implementation strategy for a scalable phaser synchronization construct. Our evaluation shows that it can be used as a drop-in replacement for classic barriers without harming performance, despite its additional complexity and potential for performance optimizations. Furthermore, our approach overcomes performance and scalability limitations which have been present in other phaser proposals.", "num_citations": "7\n", "authors": ["1843"]}
{"title": "Cloud PARTE: elastic complex event processing based on mobile actors\n", "abstract": " Traffic monitoring or crowd management systems produce large amounts of data in the form of events that need to be processed to detect relevant incidents. Rule-based pattern recognition is a promising approach for these applications, however, increasing amounts of data as well as large and complex rule sets demand for more and more processing power and memory. In order to scale such applications, a rule-based pattern detection system needs to be distributable over multiple machines. Today's approaches are however focused on static distribution of rules or do not support reasoning over the full set of events. We propose Cloud PARTE, a complex event detection system that implements the Rete algorithm on top of mobile actors. These actors can migrate between machines to respond to changes in the work load distribution. Cloud PARTE is an extension of PARTE and offers the first rule engine specifically\u00a0\u2026", "num_citations": "6\n", "authors": ["1843"]}
{"title": "Few versatile vs. many specialized collections: how to design a collection library for exploratory programming?\n", "abstract": " While an integral part of all programming languages, the design of collection libraries is rarely studied. This work briefly reviews the collection libraries of 14 languages to identify possible design dimensions. Some languages have surprisingly few but versatile collections, while others have large libraries with many specialized collections. Based on the identified design dimensions, we argue that a small collection library with only a sequence, a map, and a set type are a suitable choice to facilitate exploratory programming. Such a design minimizes the number of decisions programmers have to make when dealing with collections, and it improves discoverability of collection operations. We further discuss techniques that make their implementation practical from a performance perspective. Based on these arguments, we conclude that languages which aim to support exploratory programming should strive for small\u00a0\u2026", "num_citations": "5\n", "authors": ["1843"]}
{"title": "Applying optimizations for dynamically-typed languages to java\n", "abstract": " While Java is a statically-typed language, some of its features make it behave like a dynamically-typed language at run time. This includes Java's boxing of primitive values as well as generics, which rely on type erasure.", "num_citations": "5\n", "authors": ["1843"]}
{"title": "Understanding GCC builtins to develop better tools\n", "abstract": " C programs can use compiler builtins to provide functionality that the C language lacks. On Linux, GCC provides several thousands of builtins that are also supported by other mature compilers, such as Clang and ICC. Maintainers of other tools lack guidance on whether and which builtins should be implemented to support popular projects. To assist tool developers who want to support GCC builtins, we analyzed builtin use in 4,913 C projects from GitHub. We found that 37% of these projects relied on at least one builtin. Supporting an increasing proportion of projects requires support of an exponentially increasing number of builtins; however, implementing only 10 builtins already covers over 30% of the projects. Since we found that many builtins in our corpus remained unused, the effort needed to support 90% of the projects is moderate, requiring about 110 builtins to be implemented. For each project, we\u00a0\u2026", "num_citations": "4\n", "authors": ["1843"]}
{"title": "A formal foundation for trace-based JIT compilers\n", "abstract": " Trace-based JIT compilers identify frequently executed program paths at run-time and subsequently record, compile and optimize their execution. In order to improve the performance of the generated machine instructions, JIT compilers heavily rely on dynamic analysis of the code. Existing work treats the components of a JIT compiler as a monolithic whole, tied to particular execution semantics. We propose a formal framework that facilitates the design and implementation of a tracing JIT compiler and its accompanying dynamic analyses by decoupling the tracing, optimization, and interpretation processes. This results in a framework that is more configurable and extensible than existing formal tracing models. We formalize the tracer and interpreter as two abstract state machines that communicate through a minimal, well-defined interface. Developing a tracing JIT compiler becomes possible for arbitrary interpreters\u00a0\u2026", "num_citations": "4\n", "authors": ["1843"]}
{"title": "Supporting Concurrency Abstractions in High-level Language Virtual Machines\n", "abstract": " During the past decade, software developers widely adopted JVM and CLI as multi-language virtual machines (VMs). At the same time, the multicore revolution burdened developers with increasing complexity. Language implementers devised a wide range of concurrent and parallel programming concepts to address this complexity but struggle to build these concepts on top of common multi-language VMs. Missing support in these VMs leads to tradeoffs between implementation simplicity, correctly implemented language semantics, and performance guarantees. Departing from the traditional distinction between concurrency and parallelism, this dissertation finds that parallel programming concepts benefit from performance-related VM support, while concurrent programming concepts benefit from VM support that guarantees correct semantics in the presence of reflection, mutable state, and interaction with other languages and libraries. Focusing on these concurrent programming concepts, this dissertation finds that a VM needs to provide mechanisms for managed state, managed execution, ownership, and controlled enforcement. Based on these requirements, this dissertation proposes an ownership-based metaobject protocol (OMOP) to build novel multi-language VMs with proper concurrent programming support. This dissertation demonstrates the OMOP's benefits by building concurrent programming concepts such as agents, software transactional memory, actors, active objects, and communicating sequential processes on top of the OMOP. The performance evaluation shows that OMOP-based implementations of concurrent programming\u00a0\u2026", "num_citations": "4\n", "authors": ["1843"]}
{"title": "CSOM/PL: A Virtual Machine Product Line\n", "abstract": " Business process models are abstractions of concrete operational procedures that occur in the daily business of organizations. To cope with the complexity of these models, business process model abstraction has been introduced recently. Its goal is to derive from a detailed process model several abstract models that provide a high-level understanding of the process. While techniques for constructing abstract models are reported in the literature, little is known about the relationships between process instances and abstract models. In this paper we show how the state of an abstract activity can be calculated from the states of related, detailed process activities as they happen. The approach uses activity state propagation. With state uniqueness and state transition correctness we introduce formal properties that improve the understanding of state propagation. Algorithms to check these properties are devised. Finally, we use behavioral profiles to identify and classify behavioral inconsistencies in abstract process models that might occur, once activity state propagation is used.", "num_citations": "4\n", "authors": ["1843"]}
{"title": "Data interface+ algorithms= efficient programs: Separating logic from representation to improve performance\n", "abstract": " Finding the right algorithm--data structure combination is easy, but finding the right data structure for a set of algorithms is much less trivial. Moreover, using the same data representation throughout the whole program might be sub-optimal. Depending on several factors, often only known at runtime, some programs benefit from changing the data representation during execution. In this position paper we introduce the idea of Just-In-Time data structures, a combination of a data interface and a set of concrete data representations with different performance characteristics. These Just-In-Time data structures can dynamically swap their internal data representation when the cost of swapping is payed back many times in the remainder of the computation. To make Just-In-Time data structures work, research is needed at three fronts: 1. We need to better understand the synergy between different data representations and\u00a0\u2026", "num_citations": "3\n", "authors": ["1843"]}
{"title": "Many-core virtual machines: Decoupling abstract from concrete concurrency\n", "abstract": " We propose to search for common abstractions for concurrency models to enable multi-language virtual machines to support a wide range of them. This would enable domain-specific solutions for concurrency problems. Furthermore, such an abstraction could improve portability of virtual machines to the vastly different upcoming many-core architectures.", "num_citations": "3\n", "authors": ["1843"]}
{"title": "Encapsulation and locality: a foundation for concurrency support in multi-language virtual machines?\n", "abstract": " We propose to search for common abstractions for different concurrency models to enable high-level language virtual machines to support a wide range of different concurrency models. This would enable domain-specific solutions for the concurrency problem. Furthermore, advanced knowledge about concurrency in the VM model will most likely lead to better implementation opportunities on top of the different upcoming many-core architectures. The idea is to investigate the concepts of encapsulation and locality to this end. Thus, we are going to experiment with different language abstractions for concurrency on top of a virtual machine, which supports encapsulation and locality, to see how language designers could benefit, and how virtual machines could optimize programs using these concepts.", "num_citations": "3\n", "authors": ["1843"]}
{"title": "A metaobject protocol for optimizing application-specific run-time variability\n", "abstract": " Just-in-time compilers and their aggressive speculative optimizations reduced the performance gap between dynamic and static languages drastically. To successfully speculate, compilers rely on the program variability observed at run time to be low, and use heuristics to determine when optimization is beneficial. However, some variability patterns are hard to capture with heuristics. Specifically, ephemeral, warmup, rare, and highly indirect variability are challenges for today's compiler heuristics. As a consequence, they can lead to reduced application performance. However, these types of variability are identifiable at the application level and could be mitigated with information provided by developers. As a solution, we propose a metaobject protocol for dynamic compilation systems to enable application developers to provide such information at run time. As a proof of concept, we demonstrate performance\u00a0\u2026", "num_citations": "2\n", "authors": ["1843"]}
{"title": "Fully-reflective VMs for ruling software adaptation\n", "abstract": " A recent survey on paradigms for software adaptation at the language level assessed contemporary reflective systems (RS), aspect-oriented programming (AOP), and context-oriented programming (COP) as three well-established approaches. The survey did not find a clear winner. Our opinion is that this is due to the fact that none of these approaches is flexible enough to handle the diversity of possible adaptation scenarios. The reason is that instead of operating directly on the entity that conceptually requires the adaptation, these approaches often require to handle the adaptations in an indirect fashion. In this paper we advocate that a suitable paradigm for software adaptation at the language level must enable direct modification to every concept at both, the application and the execution environment level. This is enabled by a Fully-Reflective Execution Environment (FREE), a flavor of virtual machine in which\u00a0\u2026", "num_citations": "2\n", "authors": ["1843"]}
{"title": "Modularity and Conventions for Maintainable Concurrent Language Implementations: A Review of Our Experiences and Practices\n", "abstract": " In this paper, we review what we have learned from implementing languages for parallel and concurrent programming, and investigate the role of modularity. To identify the approaches used to facilitate correctness and maintainability, we ask the following questions: What guides modularization? Are informal approaches used to facilitate correctness? Are concurrency concerns modularized? And, where is language support lacking most?", "num_citations": "2\n", "authors": ["1843"]}
{"title": "Which Problems Does a Multi-Language Virtual Machine Need to Solve in the Multicore/Manycore Era?\n", "abstract": " While parallel programming for very regular problems has been used in the scientific community by non-computer-scientists successfully for a few decades now, concurrent programming and solving irregular problems remains hard. Furthermore, we shift from few expert system programmers mastering concurrency for a constrained set of problems to mainstream application developers being required to master concurrency for a wide variety of problems.", "num_citations": "2\n", "authors": ["1843"]}
{"title": "Meta Programming and Reflection in PHP\n", "abstract": " A meta program is a program, which has other programs or even itself as its application domain. This technique is commonly used to implement advanced software development tools and frameworks. PHP is one of the most popular programming languages for web applications and provides a comprehensive set of meta programming and reflection facilities. This paper gives an overview of these capabilities and also presents our own enhancements.The default configuration of PHP includes a set of functions and an object-oriented reflection API. Additional features are provided by extensions to the virtual machine of PHP. On top of the features mentioned above, we implemented two advanced APIs, providing annotation support, type introspection, and object-oriented intercession. A class browser, which is capable of modifying its own source code at runtime, demonstrates the most important reflection features.", "num_citations": "2\n", "authors": ["1843"]}
{"title": "Fully reflective execution environments: Virtual machines for more flexible software\n", "abstract": " VMs are complex pieces of software that implement programming language semantics in an efficient, portable, and secure way. Unfortunately, mainstream VMs provide applications with few mechanisms to alter execution semantics or memory management at run time. We argue that this limits the evolvability and maintainability of running systems for both, the application domain, e.g., to support unforeseen requirements, and the VM domain, e.g., to modify the organization of objects in memory. This work explores the idea of incorporating reflective capabilities into the VM domain and analyzes its impact in the context of software adaptation tasks. We characterize the notion of a fully reflective VM, a kind of VM that provides means for its own observability and modifiability at run time. This enables programming languages to adapt the underlying VM to changing requirements. We propose a reference architecture for\u00a0\u2026", "num_citations": "1\n", "authors": ["1843"]}
{"title": "Generic messages: capability-based shared memory parallelism for event-loop systems\n", "abstract": " Systems based on event-loops have been popularized by Node.JS, and are becoming a key technology in the domain of cloud computing. Despite their popularity, such systems support only share-nothing parallelism via message passing between parallel entities usually called workers. In this paper, we introduce a novel parallel programming abstraction called Generic Messages (GEMs), which enables shared-memory parallelism for share-nothing event-based systems. A key characteristic of GEMs is that they enable workers to share state by specifying how the state can be accessed once it is shared. We call this aspect of the GEMs model capability-based parallelism.", "num_citations": "1\n", "authors": ["1843"]}
{"title": "Synchronization Views for Event-loop Actors\n", "abstract": " The actor model has already proven itself as an interesting concurrency model that avoids issues such as deadlocks and race conditions by construction, and thus facilitates concurrent programming. The tradeoff is that it sacrifices expressiveness and efficiency especially with respect to data parallelism. However, many standard solutions to computationally expensive problems employ data parallel algorithms for better performance on parallel systems.", "num_citations": "1\n", "authors": ["1843"]}
{"title": "A language-oriented approach to teaching concurrency\n", "abstract": " This paper argues in favour of a language-oriented approach to teach the principles of concurrency to graduate students. Over the past years, the popularity of programming languages that promote a functional programming style has steadily grown. We want to promote the use of such languages as the appropriate basic tools to deal with the \u201cmulticore revolution\u201d.We describe some of these programming languages and highlight two of them: Erlang and Clojure. We use these languages in a new graduate-level course that we will teach starting next academic year. Our goal is not to convince the reader that Erlang and Clojure are the best possible choices among this pool of candidate languages. Rather, our goal is to promote a functional programming style to tackle concurrency issues, and to teach this style in a programming language that makes it easy, straightforward and convenient to use that style.", "num_citations": "1\n", "authors": ["1843"]}
{"title": "Modularisierung virtueller maschinen\n", "abstract": " Today high level language virtual machines are custom made special purpose systems optimized for specific domains like embedded devices Their implementation suffers from high complexity strongly intertwined subsystems and little maintainability This is caused by insufficient modularization techniques failing to represent the system ar chitecture in the code To overcome this situation the 6\u00a9\u2264\u00a5 \u00b5-\u00a3\u00ae\u00a9 \u00c6\u2022!\u2264\u00a3\u00ae\u00a9\u00a5\u2022\u00a3\u00a5 \u00b5\u2264\u2022$\u2022\u00b6\u00a9 \u00c6\u00a9\u00a5\u00a9 \u00d8\u00c6, \u00c6\u00df\u00b5\u00df\u2022 VMADL has been proposed In this work the language features of VMADL are investigated and a VMADL compiler is implemented to conduct a case study on an existing Smalltalk VM written in C named CSOM The aim of this case study is to test the language on CSOM and to modularize it in a way that it is possible to build a product family of VMs out of it to be able to benefit from a product line approach for customizing VMs In a first step CSOM is reverse en gineered and several feature implementations are analyzed for their specific require ments on modularization Based on this examination a CSOM specific feature oriented class definition language is added to VMADL to allow a completely modularized imple mentation of all analyzed features", "num_citations": "1\n", "authors": ["1843"]}
{"title": "Feature-Diagramme und Variabilit\u00e4t\n", "abstract": " Feature-Diagramme und ihre Mittel zur Darstellung von Variabilit\u00e4t in Produktfamilien werden vorgestellt. Einleitend wird das Paradigma des Generative Programming betrachtet, in welchem die Methodik des Domain Engineerings verwendet wird. Diese Methodik wird kurz dargelegt, um \u00fcber die Feature-oriented Domain Analyse zur Feature-Modellierung zu kommen, in welcher Feature-Diagramme zur Darstellung eingesetzt werden. \u00dcber die Notation hinaus wird der Prozess der Feature-Modellierung und die M\u00f6glichkeit zur Implementierung von Features mit UML skizziert. Abschlie\u00dfend werden verf\u00fcgbare Werkzeuge und die Verwendung von Feature-Modellierung in der Industrie untersucht, um mit einem Fazit f\u00fcr die Einsatzm\u00f6glichkeiten zu schlie\u00dfen.", "num_citations": "1\n", "authors": ["1843"]}
{"title": "The Java Data Objects Persistence Model\n", "abstract": " JDO is a specification for design object domain models without having to consider the persistency of data. The main target of JDO is the abstraction of concrete data storage solutions and the provision of transparent and implementation-independent solutions for persistent data.Starting with an introduction to the architectural model of Java Data Objects, benefits of this approach and the realization by a tool-based enhancement are outlined. Furthermore, the API itself is in focus of examination, main programming interfaces and the JDO-QL will be discussed. Finally, it is aimed to give an outlook on the upcoming JDO 2.0 specification.", "num_citations": "1\n", "authors": ["1843"]}
{"title": "RESTful Web Services\n", "abstract": " State Transfer als Basis f\u00fcr das Design von Web Services werden vorgestellt. Als Heranf\u00fchrung werden die Grundlagen f\u00fcr interoperable Schnittstellen behandelt, welche an HTTP als eine Implementierung konkretisiert werden, um darauf aufbauend die vier wesentlichen Fragen und acht notwendigen Prinzipien zur konkreten Erstellung eines RESTful Web Services an einem Beispiel zu verdeutlichen. Dar\u00fcber hinaus werden kurz Ans\u00e4tze zur L\u00f6sung g\u00e4ngiger Probleme angerissen, um anschlie\u00dfend auf Vorteil des REST-Architekturstils insgesamt einzugehen und damit ein Fazit zu ziehen.", "num_citations": "1\n", "authors": ["1843"]}