{"title": "Towards a meaning of LIFE\n", "abstract": " LIFE is an experimental programming language proposing to integrate three orthogonal programming paradigms proven useful for symbolic computation. From the programmer's standpoint, it may be perceived as a language taking after logic programming, functional programming, and object-oriented programming. From a formal perspective, it may be seen as an instance (or rather, a composition of three instances) of a Constraint Logic Programming scheme due to H\u00f6hfeld and Smolka refining that of Jaffar and Lassez.We start with an informal overview demonstrating LIFE as a programming language, illustrating how its primitives offer rather unusual, and perhaps (pleasantly) startling, conveniences. The second part is a formal account of LIFE's object unification seen as constraint-solving over specific domains. We build on work by Smolka and Rounds to develop type-theoretic, logical, and algebraic renditions of\u00a0\u2026", "num_citations": "379\n", "authors": ["274"]}
{"title": "Model checking in CLP\n", "abstract": " We show that Constraint Logic Programming (CLP) can serve as a conceptual basis and as a practical implementation platform for the model checking of infinite-state systems. Our contributions are: (1) a semantics-preserving translation of concurrent systems into CLP programs, (2) a method for verifying safety and liveness properties on the CLP programs produced by the translation. We have implemented the method in a CLP system and verified well-known examples of infinite-state programs over integers, using here linear constraints as opposed to Presburger arithmetic as in previous solutions.", "num_citations": "239\n", "authors": ["274"]}
{"title": "A feature constraint system for logic programming with entailment\n", "abstract": " We introduce a constraint system called FT. This system offers a theoretical and practical alternative to the usual Herbrand system of constraints over constructor trees. Like Hrerbrand, FT provides a universal data structure based on trees. However, the trees of FT (called feature trees) are more general than the constructor trees of Herbrand, and the constraints of FT are of finer grain and of different expressiveness. The essential novelty of FT is provided by functional attributes called features which allow representing data as extensible records, a more flexible way than that offered by Herbrand's fixed arity constructors. The feature tree structure determines an algebraic semantics for FT. We establish a logical semantics, thanks to three axiom schemes presenting the first-order theory FT. We propose using FT as a constraint system for logic programming. We provide a test for constraint unsatisfiability, and a test for\u00a0\u2026", "num_citations": "176\n", "authors": ["274"]}
{"title": "Software model checking for people who love automata\n", "abstract": " In this expository paper, we use automata for software model checking in a new way. The starting point is to fix the alphabet: the set of statements of the given program. We show how automata over the alphabet of statements can help to decompose the main problem in software model checking, which is to find the right abstraction of a program for a given correctness property.", "num_citations": "132\n", "authors": ["274"]}
{"title": "Nested interpolants\n", "abstract": " In this paper, we explore the potential of the theory of nested words for partial correctness proofs of recursive programs. Our conceptual contribution is a simple framework that allows us to shine a new light on classical concepts such as Floyd/Hoare proofs and predicate abstraction in the context of recursive programs. Our technical contribution is an interpolant-based software model checking method for recursive programs. The method avoids the costly construction of the abstract transformer by constructing a nested word automaton from an inductive sequence of `nested interpolants' (i.e., interpolants for a nested word which represents an infeasible error trace).", "num_citations": "121\n", "authors": ["274"]}
{"title": "Constraint-based deductive model checking\n", "abstract": " We show that constraint logic programming (CLP) can serve as a conceptual basis and as a practical implementation platform for the model checking of infinite-state systems. CLP programs are logical formulas (built up from constraints) that have both a logical interpretation and an operational semantics. Our contributions are: (1) a translation of concurrent systems  (imperative programs) into CLP programs with the same operational semantics; and (2)  a deductive method for verifying safety and liveness properties of the systems which is based on the logical interpretation of the CLP programs produced by the translation. We have implemented the method in a CLP system and verified well-known examples of infinite-state programs over integers, using linear constraints here as opposed to Presburger arithmetic as in previous solutions.", "num_citations": "112\n", "authors": ["274"]}
{"title": "Directed model checking with distance-preserving abstractions\n", "abstract": " In directed model checking, the traversal of the state space is guided by an estimate of the distance from the current state to the nearest error state. This paper presents a distance-preserving abstraction for concurrent systems that allows one to compute an interesting estimate of the error distance without hitting the state explosion problem. Our experiments show a dramatic reduction both in the number of states explored by the model checker and in the total runtime.", "num_citations": "101\n", "authors": ["274"]}
{"title": "Boolean heaps\n", "abstract": " We show that the idea of predicates on heap objects can be cast in the framework of predicate abstraction. This leads to an alternative view on the underlying concepts of three-valued shape analysis by Sagiv, Reps and Wilhelm. Our construction of the abstract post operator is analogous to the corresponding construction for classical predicate abstraction, except that predicates over objects on the heap take the place of state predicates, and boolean heaps (sets of bitvectors) take the place of boolean states (bitvectors). A program is abstracted to a program over boolean heaps. For each command of the program, the corresponding abstract command is effectively constructed by deductive reasoning, namely by the application of the weakest precondition operator and an entailment test. We thus obtain a symbolic framework for shape analysis.", "num_citations": "94\n", "authors": ["274"]}
{"title": "Refinement of trace abstraction\n", "abstract": " We present a new counterexample-guided abstraction refinement scheme. The scheme refines an over-approximation of the set of possible traces. Each refinement step introduces a finite automaton that recognizes a set of infeasible traces. A central idea enabling our approach is to use interpolants (assertions generated, e.g., by the infeasibility proof for an error trace) in order to automatically construct such an automaton. A data base of interpolant automata has an interesting potential for reuse of theorem proving work (from one program to another).", "num_citations": "93\n", "authors": ["274"]}
{"title": "Model checking of hybrid systems: From reachability towards stability\n", "abstract": " We call a hybrid system stable if every trajectory inevitably ends up in a given region. Our notion of stability deviates from classical definitions in control theory. In this paper, we present a model checking algorithm for stability in the new sense. The idea of the algorithm is to reduce the stability proof for the whole system to a set of (smaller) proofs for several one-mode systems.", "num_citations": "81\n", "authors": ["274"]}
{"title": "Order-sorted feature theory unification\n", "abstract": " Order-sorted feature (OSF) terms provide an adequate representation for objects as flexible records. They are sorted, attributed, possibly nested structures, ordered thanks to a subsort ordering. Sorts definitions offer the functionality of classes imposing structural constraints on objects. These constraints involve variable sorting and equations among feature paths, including self-reference. Formally, sort definitions may be seen as axioms forming an OSF theory. OSF theory unification is the process of normalizing an OSF term taking into account sort definitions, enforcing structural constraints imposed by an OSF theory. It allows objects to inherit, and thus abide by, constraints from their classes. We propose a formal system that logically models record objects with (possibly recursive) class definitions accommodating multiple inheritance. We show that OSF theory unification is undecidable in general. However, we give a\u00a0\u2026", "num_citations": "74\n", "authors": ["274"]}
{"title": "Inductive data flow graphs\n", "abstract": " The correctness of a sequential program can be shown by the annotation of its control flow graph with inductive assertions. We propose inductive data flow graphs, data flow graphs with incorporated inductive assertions, as the basis of an approach to verifying concurrent programs. An inductive data flow graph accounts for a set of dependencies between program actions in interleaved thread executions, and therefore stands as a representation for the set of concurrent program traces which give rise to these dependencies. The approach first constructs an inductive data flow graph and then checks whether all program traces are represented. The size of the inductive data flow graph is polynomial in the number of data dependencies (in a sense that can be made formal); it does not grow exponentially in the number of threads unless the data dependencies do. The approach shifts the burden of the exponential\u00a0\u2026", "num_citations": "67\n", "authors": ["274"]}
{"title": "Termination analysis by learning terminating programs\n", "abstract": " We present a novel approach to termination analysis. In a first step, the analysis uses a program as a black-box which exhibits only a finite set of sample traces. Each sample trace is infinite but can be represented by a finite lasso. The analysis can \u201dlearn\u201d a program from a termination proof for the lasso, a program that is terminating by construction. In a second step, the analysis checks that the set of sample traces is representative in a sense that we can make formal. An experimental evaluation indicates that the approach is a potentially useful addition to the portfolio of existing approaches to termination analysis.", "num_citations": "62\n", "authors": ["274"]}
{"title": "Set constraints: a pearl in research on constraints\n", "abstract": " The topic of set constraints is a pearl among the research topics on constraints. It combines theoretical investigations (ranging from logical expressiveness, decidability, algorithms and complexity analysis to program semantics and domain theory) with practical experiments in building systems for program analysis, addressing questions like implementation issues and scalability. The research has its direct applications in type inference, optimization and verification of imperative, functional, logic and reactive programs.", "num_citations": "62\n", "authors": ["274"]}
{"title": "Set-based analysis of reactive infinite-state systems\n", "abstract": " We present an automated abstract verification method for infinite-state systems specified by logic programs (which are a uniform and intermediate layer to which diverse formalisms such as transition systems, pushdown processes and while programs can be mapped). We establish connections between: logic program semantics and CTL properties, set-based program analysis and pushdown processes, and also between model checking and constraint solving, viz. theorem proving. We show that set-based analysis can be used to compute supersets of the values of program variables in the states that satisfy a given CTL property.", "num_citations": "57\n", "authors": ["274"]}
{"title": "Ultimately periodic words of rational \u03c9-languages\n", "abstract": " In this paper we initiate the following program: Associate sets of finite words to B\u00fcchi-recognizable sets of infinite words, and reduce algorithmic problems on B\u00fcchi automata to simpler ones on automata on finite words. We know that the set of ultimately periodic words UP(L) of a rational language of infinite words L is sufficient to characterize L, since UP(L 1)=UP(L 2) implies L 1=L 2. We can use this fact as a test, for example, of the equivalence of two given B\u00fcchi automata. The main technical result in this paper is the construction of an automaton which recognizes the set of all finite words u \u00b7 $ \u00b7 v which naturally represent the ultimately periodic words of the form u \u00b7 554-01 in the language of infinite words recognized by a given B\u00fcchi automaton.", "num_citations": "57\n", "authors": ["274"]}
{"title": "Set constraints with intersection\n", "abstract": " Set constraints are inclusions between expressions denoting sets of trees. The efficiency of their satisfiability test is a central issue in set-based program analysis, their main application domain. We introduce the class of set constraints with intersection (the only operators forming the expressions are constructors and intersection) and show that its satisfiability problem is DEXPTIME-complete. The complexity characterization continues to hold for negative set constraints with intersection (which have positive and negated inclusions). We reduce the satisfiability problem for these constraints to one over the interpretation domain of nonempty sets of trees. Set constraints with intersection over the domain of nonempty sets of trees enjoy the fundamental property of independence of negated conjuncts. This allows us to handle each negated inclusion separately by the entailment algorithm that we devise. We furthermore\u00a0\u2026", "num_citations": "55\n", "authors": ["274"]}
{"title": "Automotive behavioral requirements expressed in a specification pattern system: a case study at BOSCH\n", "abstract": " To allow an automatic formal analysis of requirements, the requirements have to be formalized first. However, logical formalisms are seldom accessible to stakeholders in the automotive context. Konrad and Cheng proposed a specification pattern system (SPS) represented in a restricted English grammar that can be automatically translated to logics, but looks like natural language. In this paper, we investigate whether this SPS can be applied to automotive requirements of BOSCH, in the sense that it is expressive enough to specify automotive behavioral requirements of BOSCH. We did a case study over 289 informal behavioral requirements taken from automotive BOSCH projects. We evaluated whether these requirements could be formulated in the SPS and whether the SPS has to be adapted to the automotive context. The case study strongly indicates that the SPS, extended with 3 further patterns, is\u00a0\u2026", "num_citations": "54\n", "authors": ["274"]}
{"title": "Assume-guarantee abstraction refinement meets hybrid systems\n", "abstract": " Compositional verification techniques in the assume-guarantee style have been successfully applied to transition systems to efficiently reduce the search space by leveraging the compositional nature of the systems under consideration. We adapt these techniques to the domain of hybrid systems with affine dynamics. To build assumptions we introduce an abstraction based on location merging. We integrate the assume-guarantee style analysis with automatic abstraction refinement. We have implemented our approach in the symbolic hybrid model checker SpaceEx. The evaluation shows its practical potential. To the best of our knowledge, this is the first work combining assume-guarantee reasoning with automatic abstraction-refinement in the context of hybrid automata.", "num_citations": "53\n", "authors": ["274"]}
{"title": "Linear ranking for linear lasso programs\n", "abstract": " The general setting of this work is the constraint-based synthesis of termination arguments. We consider a restricted class of programs called lasso programs. The termination argument for a lasso program is a pair of a ranking function and an invariant. We present the\u2014to the best of our knowledge\u2014first method to synthesize termination arguments for lasso programs that uses linear arithmetic.We prove a completeness theorem. The completeness theorem establishes that, even though we use only linear (as opposed to non-linear) constraint solving, we are able to compute termination arguments in several interesting cases. The key to our method lies in a constraint transformation that replaces a disjunction by a sum.", "num_citations": "53\n", "authors": ["274"]}
{"title": "Planning as model checking in hybrid domains\n", "abstract": " Planning in hybrid domains is an important and challenging task, and various planning algorithms have been proposed in the last years. From an abstract point of view, hybrid planning domains are based on hybrid automata, which have been studied intensively in the model checking community. In particular, powerful model checking algorithms and tools have emerged for this formalism. However, despite the quest for more scalable planning approaches, model checking algorithms have not been applied to planning in hybrid domains so far. In this paper, we make a first step in bridging the gap between these two worlds. We provide a formal translation scheme from PDDL+ to the standard formalism of hybrid automata, as a solid basis for using hybrid system model-checking tools for dealing with hybrid planning domains. As a case study, we use the SpaceEx model checker, showing how we can address PDDL+ domains that are out of the scope of state-of-the-art planners.", "num_citations": "52\n", "authors": ["274"]}
{"title": "Model checking as constraint solving\n", "abstract": " We show how model checking procedures for different kinds of infinite-state systems can be formalized as a generic constraint-solving procedure, viz. the saturation under a parametric set of inference rules. The procedures can be classified by the solved form they are to compute. This solved form is a recursive (automaton-like) definition of the set of states satisfying the given temporal property in the case of systems over stacks or other symbolic data.", "num_citations": "51\n", "authors": ["274"]}
{"title": "Ultimate automizer with SMTInterpol\n", "abstract": " Ultimate                 Automizer is an automatic software verification tool for C programs. This tool is the first implementation of trace abstraction, which is an automata-theoretic approach to software verification. The implemented algorithm uses nested interpolants in its interprocedural program analysis. The interpolating SMT solver SMTInterpol is used to compute Craig interpolants.", "num_citations": "50\n", "authors": ["274"]}
{"title": "Abstraction refinement for quantified array assertions\n", "abstract": " We present an abstraction refinement technique for the verification of universally quantified array assertions such as \u201call elements in the array are sorted\u201d. Our technique can be seamlessly combined with existing software model checking algorithms. We implemented our technique in the ACSAR software model checker and successfully verified quantified array assertions for both text book examples and real-life examples taken from the Linux operating system kernel.", "num_citations": "50\n", "authors": ["274"]}
{"title": "Functions as passive constraints in LIFE\n", "abstract": " LIFE is a programming language proposing to integrate logic programming, functional programming, and object-oriented programming. It replaces first-order terms with \u03c8-terms, data structures that allow computing with partial information. These are approximation structures denoting sets of values. LIFE further enriches the expressiveness of \u03c8-terms with functional dependency constraints. We must explain the meaning and use of functions in LIFE declaratively, as solving partial information constraints. These constraints do not attempt to generate their solutions but behave as demons filtering out anything else. In this manner, LIFE functions act as declarative coroutines. We need to show that the \u03c8-term's approximation semantics is congruent with an operational semantics viewing functional reduction as an effective enforcing of passive constraints. In this article, we develop a general formal framework for entailment\u00a0\u2026", "num_citations": "50\n", "authors": ["274"]}
{"title": "Region stability proofs for hybrid systems\n", "abstract": " We present a method and tool (and implementation) for automatic proofs of region stability for hybrid systems. The formal basis of our approach is the new notion of snapshot sequences. We use snapshot sequences for a characterization of region stability. Our abstraction-based algorithm checks the conditions in this characterization. A number of experiments demonstrate the practical potential of our approach.", "num_citations": "49\n", "authors": ["274"]}
{"title": "Ultimate automizer and the search for perfect interpolants\n", "abstract": " Ultimate Automizer is a software verifier that generalizes proofs for traces to proofs for larger parts for the program. In recent years the portfolio of proof producers that are available to Ultimate has grown continuously. This is not only because more trace analysis algorithms have been implemented in Ultimate but also due to the continuous progress in the SMT community. In this paper we explain how Ultimate Automizer dynamically selects trace analysis algorithms and how the tool decides when proofs for traces are \u201cgood\u201d enough for using them in the abstraction refinement.", "num_citations": "45\n", "authors": ["274"]}
{"title": "Feature automata and recognizable sets of feature trees\n", "abstract": " Feature trees generalize first-order trees whereby argument positions become keywords (\u201cfeatures\u201d) from an infinite symbol set F. Constructor symbols can occur with any argument positions, in any finite number. Feature trees are used to model flexible records; the assumption on the infiniteness of F accounts for dynamic record field updates.             We develop a universal algebra framework for feature trees. We introduce the classical set-defining notions: automata, regular expressions and equational systems, and show that they coincide. This extension of the regular theory of trees requires new notions and proofs. Roughly, a feature automaton reads a feature tree in two directions: along its branches and along the fan-out of each node.             We illustrate the practical motivation of our regular theory of feature trees by pointing out an application on the programming language LIFE.", "num_citations": "43\n", "authors": ["274"]}
{"title": "Size-change termination and transition invariants\n", "abstract": " Two directions of recent work on program termination use the concepts of size-change termination resp. transition invariants. The difference in the setting has as consequence the inherent incomparability of the analysis and verification methods that result from this work. Yet, in order to facilitate the crossover of ideas and techniques in further developments, it seems interesting to identify which aspects in the respective formal foundation are related. This paper presents initial results in this direction.", "num_citations": "42\n", "authors": ["274"]}
{"title": "Symbolic shape analysis.\n", "abstract": " Shape analysis deals with the synthesis of invariants for programs manipulating heap-allocated data structures. Explicit shape analysis algorithms do not scale very well. This work proposes a framework for symbolic shape analysis that addresses this problem. Our contribution is a framework that allows to abstract programs with heap-allocated data symbolically by Boolean programs. For this purpose, we combine abstraction techniques from shape analysis with ideas from predicate abstraction. Our framework is parameterized by a set of abstraction predicates. We propose a class of predicates that can be used to analyze reachability properties for linked data structures. This class may potentially be used for automated abstraction refinement. v", "num_citations": "41\n", "authors": ["274"]}
{"title": "Counterexample-guided focus\n", "abstract": " The automated inference of quantified invariants is considered one of the next challenges in software verification. The question of the right precision-efficiency tradeoff for the corresponding program analyses here boils down to the question of the right treatment of disjunction below and above the universal quantifier. In the closely related setting of shape analysis one uses the focus operator in order to adapt the treatment of disjunction (and thus the efficiency-precision tradeoff) to the individual program statement. One promising research direction is to design parameterized versions of the focus operator which allow the user to fine-tune the focus operator not only to the individual program statements but also to the specific verification task. We carry this research direction one step further. We fine-tune the focus operator to each individual step of the analysis (for a specific verification task). This fine-tuning must be\u00a0\u2026", "num_citations": "40\n", "authors": ["274"]}
{"title": "Reach set approximation through decomposition with low-dimensional sets and high-dimensional matrices\n", "abstract": " Approximating the set of reachable states of a dynamical system is an algorithmic yet mathematically rigorous way to reason about its safety. Although progress has been made in the development of efficient algorithms for affine dynamical systems, available algorithms still lack scalability to ensure their wide adoption in the industrial setting. While modern linear algebra packages are efficient for matrices with tens of thousands of dimensions, set-based image computations are limited to a few hundred. We propose to decompose reach set computations such that set operations are performed in low dimensions, while matrix operations like exponentiation are carried out in the full dimension. Our method is applicable both in dense-and discrete-time settings. For a set of standard benchmarks, it shows a speed-up of up to two orders of magnitude compared to the respective state-of-the-art tools, with only modest losses\u00a0\u2026", "num_citations": "39\n", "authors": ["274"]}
{"title": "Co-definite set constraints\n", "abstract": " In this paper, we introduce the class of co-definite set constraints. This is a natural subclass of set constraints which, when satisfiable, have a greatest solution. It is practically motivated by the set-based analysis of logic programs with the greatest-model semantics. We present an algorithm solving co-definite set constraints and show that their satisfiability problem is DEXPTIME-complete.", "num_citations": "39\n", "authors": ["274"]}
{"title": "Applying restricted English grammar on automotive requirements\u2014does it work? a case study\n", "abstract": " [Context and motivation] For an automatic consistency check on requirements the requirements have to be formalized first. However, logical formalisms are seldom accessible to stakeholders in the automotive context. Konrad and Cheng proposed a restricted English grammar that can be automatically translated to logics, but looks like natural language. [Question/problem] In this paper we investigate whether this grammar can be applied in the automotive domain, in the sense that it is expressive enough to specify automotive behavioral requirements. [Principal ideas/results] We did a case study over 289 informal behavioral requirements taken from the automotive context. We evaluated whether these requirements could be formulated in the grammar and whether the grammar has to be adapted to the automotive context. [Contribution] The case study strongly indicates that the grammar, extended with 3\u00a0\u2026", "num_citations": "37\n", "authors": ["274"]}
{"title": "Minimal ascending and descending tree automata\n", "abstract": " We propose a generalization of the notion \"deterministic\" to \"l-r-deterministic\" for descending tree automata (also called root-to-frontier). The corresponding subclass of recognizable tree languages is characterized by a structural property that we name \"homogeneous.\" Given a descending tree automaton recognizing a homogeneous tree language, it can be left-to-right (l-r) determinized and then minimized. The obtained minimal l-r-deterministic tree automaton is characterized algebraically. We exhibit a formal correspondence between the two evaluation modes on trees (ascending and descending) and the two on words (right-to-left and left-to-right). This is possible by embedding trees into the free monoid of pointed trees. We obtain a unified view of the theories of minimization of deterministic ascending and l-r-deterministic descending tree automata.", "num_citations": "37\n", "authors": ["274"]}
{"title": "Tree automata and languages\n", "abstract": " Tree Automata and Languages | Guide books ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksTree Automata and Languages ABSTRACT No abstract available. Comments Login options Check if you have access through your login credentials or your institution to get full access on this article. Sign in Full Access Get this Publication Information Contributors Published in Guide books cover image Tree Automata and Languages July 1992 486 pages ISBN:0444890262 Editors: Maurice Nivat, Andreas Podelski Copyright \u00a9 1992 Publisher Elsevier Science Inc. United States Publication History Published: 1 July 1992 Qualifiers book \u2026", "num_citations": "37\n", "authors": ["274"]}
{"title": "Proof spaces for unbounded parallelism\n", "abstract": " In this paper, we present a new approach to automatically verify multi-threaded programs which are executed by an unbounded number of threads running in parallel. The starting point for our work is the problem of how we can leverage existing automated verification technology for sequential programs (abstract interpretation, Craig interpolation, constraint solving, etc.) for multi-threaded programs. Suppose that we are given a correctness proof for a trace of a program (or for some other program fragment). We observe that the proof can always be decomposed into a finite set of Hoare triples, and we ask what can be proved from the finite set of Hoare triples using only simple combinatorial inference rules  (without access to a theorem prover and without the possibility to infer genuinely new Hoare triples)? We introduce a proof system where one proves the correctness of a multi-threaded program by showing that for\u00a0\u2026", "num_citations": "36\n", "authors": ["274"]}
{"title": "Proofs that count\n", "abstract": " Counting arguments are among the most basic proof methods in mathematics. Within the field of formal verification, they are useful for reasoning about programs with infinite control, such as programs with an unbounded number of threads, or (concurrent) programs with recursive procedures. While counting arguments are common in informal, hand-written proofs of such programs, there are no fully automated techniques to construct counting arguments. The key questions involved in automating counting arguments are: how to decide what should be counted?, and how to decide when a counting argument is valid? In this paper, we present a technique for automatically constructing and checking counting arguments, which includes novel solutions to these questions.", "num_citations": "35\n", "authors": ["274"]}
{"title": "Tools and Algorithms for the Construction and Analysis of Systems\n", "abstract": " This special section contains the revised and expanded versions of eight of the papers from the 10th International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS) held in March/April 2004 in Barcelona, Spain. The conference proceedings appeared as volume 2988 in the Lecture Notes in Computer Science series published by Springer. TACAS is a forum for researchers, developers and users interested in rigorously based tools for the construction and analysis of systems. The conference serves to bridge the gaps between different communities \u2013 including but not limited to those devoted to formal methods, software and hardware verification, static analysis, programming languages, software engineering, real-time systems, and communications protocols \u2013 that share common interests in, and techniques for, tool development. Other more theoretical papers from the\u00a0\u2026", "num_citations": "35\n", "authors": ["274"]}
{"title": "Guided search for hybrid systems based on coarse-grained space abstractions\n", "abstract": " Hybrid systems represent an important and powerful formalism for modeling real-world applications such as embedded systems. A verification tool like SpaceEx is based on the exploration of a symbolic search space (the region space). As a verification tool, it is typically optimized towards proving the absence of errors. In some settings, e.g., when the verification tool is employed in a feedback-directed design cycle, one would like to have the option to call a version that is optimized towards finding an error trajectory in the region space. A recent approach in this direction is based on guided search. Guided search relies on a cost function that indicates which states are promising to be explored, and preferably explores more promising states first. In this paper, we propose an abstraction-based cost function based on coarse-grained space abstractions for guiding the reachability analysis. For this purpose, a\u00a0\u2026", "num_citations": "32\n", "authors": ["274"]}
{"title": "Fairness modulo theory: A new approach to LTL software model checking\n", "abstract": " The construction of a proof for unsatisfiability is less costly than the construction of a ranking function. We present a new approach to LTL software model checking (i.e., to statically analyze a program and verify a temporal property from the full class of LTL including general liveness properties) which aims at exploiting this fact. The idea is to select finite prefixes of a path and check these for infeasibility before considering the full infinite path. We have implemented a tool which demonstrates the practical potential of the approach. In particular, the tool can verify several benchmark programs for a liveness property just with finite prefixes (and thus without the construction of a single ranking function).", "num_citations": "32\n", "authors": ["274"]}
{"title": "A sound and complete proof rule for region stability of hybrid systems\n", "abstract": " Region stability allows one to formalize hybrid systems whose trajectories may oscillate (within a given allowance) even after having \u2018stabilized\u2019. Unfortunately, until today no proof rule (giving necessary and sufficient conditions for the purpose of verifying region stability) has been available. This paper fills the gap. Our (sound and complete) proof rule connects region stability with the finiteness of specific state sequences and thus with the emerging set of verification methods for program termination.", "num_citations": "32\n", "authors": ["274"]}
{"title": "Constraint Programming: Basics and Trends 1994 Ch\u00e2tillon Spring School Ch\u00e2tillon-sur-Seine, France, May 16\u201320, 1994 Selected Papers\n", "abstract": " This book contains thoroughly revised versions of the papers presented at the 1994 Ch\u00e2tillon Spring School held in May 1994. This spring school was the 22nd event in a series of advanced seminars presenting important new areas of research to the theoretical computer science community.The interdisciplinary area of constraint (logic) programming and constraint-based systems has recently developed a discernible identity, which is promising both in terms of simple and general foundations and in terms of significant practical applications. The 15 papers presented in this volume make the new area accessible to all interested computer scientists and report the state of the art in this exciting new field, particularly in the subfield of constraint logic programming.", "num_citations": "31\n", "authors": ["274"]}
{"title": "Uppaal/DMC\u2013abstraction-based heuristics for directed model checking\n", "abstract": " Uppaal/DMC is an extension of Uppaal which provides generic heuristics for directed model checking. In this approach, the traversal of the state space is guided by a heuristic function which estimates the distance of a search state to the nearest error state. Our tool combines two recent approaches to design such estimation functions. Both are based on computing an abstraction of the system and using the error distance in this abstraction as the heuristic value. The abstractions, and thus the heuristic functions, are generated fully automatically and do not need any additional user input. Uppaal/DMC needs less time and memory to find shorter error paths than Uppaal\u2019s standard search methods.", "num_citations": "30\n", "authors": ["274"]}
{"title": "Ultimate automizer with two-track proofs\n", "abstract": " Ultimate Automizer is a software verification tool that implements an automata-based approach for the analysis of safety and liveness problems. The version that participates in this year\u2019s competition is able to analyze non-reachability, memory safety, termination, and overflow problems. In this paper we present the new features of our tool as well as the instructions how to install and use it.", "num_citations": "29\n", "authors": ["274"]}
{"title": "Ultimate Automizer with Array Interpolation\n", "abstract": " Ultimate Automizer is a software verification tool that is able to analyze reachability of an error label, memory safety, and termination of C programs. For all three tasks, our tool follows an automata-based approach where interpolation is used to compute proofs for traces. The interpolants are generated via a new scheme that requires only the post operator, unsatisfiable cores and live variable analysis. This new scheme enables our tool to use the SMT theory of arrays in combination with interpolation.", "num_citations": "29\n", "authors": ["274"]}
{"title": "Inclusion constraints over non-empty sets of trees\n", "abstract": " We present a new constraint system called Ines. Its constraints are conjunctions of inclusions   between first-order terms (without set operators) which are interpreted over non-empty sets of trees. The existing systems of set constraints can express Ines constraints only if they include negation. Their satisfiability problem is NEXPTIME-complete. We present an incremental algorithm that solves the satisfiability problem of Ines constraints in cubic time. We intend to apply Ines constraints for type analysis for a concurrent constraint programming language.", "num_citations": "29\n", "authors": ["274"]}
{"title": "Faster than UPPAAL?\n", "abstract": " It is probably very hard to develop a new model checker that is faster than Uppaal for verifying (correct) timed automata. In fact, our tool Mcta does not even try to compete with Uppaal in this (i.e., Uppaal\u2019s) arena. Instead, Mcta is geared towards analyzing incorrect specifications of timed automata. It returns (shorter) error traces faster.", "num_citations": "27\n", "authors": ["274"]}
{"title": "Entailment and disentailment of order-sorted feature constraints\n", "abstract": " LIFE uses matching on order-sorted feature structures for passing arguments to functions. As opposed to unification which amounts to normalizing a conjunction of constraints, solving a matching problem consists of deciding whether a constraint (guard) or its negation are entailed by the context. We give a complete and consistent set of rules for entailment and disentailment of order-sorted feature constraints. These rules are directly usable for relative simplification, a general proof-theoretic method for proving guards in concurrent constraint logic languages using guarded rules.", "num_citations": "27\n", "authors": ["274"]}
{"title": "Proving liveness of parameterized programs\n", "abstract": " Correctness of multi-threaded programs typically requires that they satisfy liveness properties. For example, a program may require that no thread is starved of a shared resource, or that all threads eventually agree on a single value. This paper presents a method for proving that such liveness properties hold. Two particular challenges which are addressed in this work are that (1) the correctness argument may rely on global behaviour of the system (e.g., the correctness argument may require that all threads collectively progress towards \"the good thing\" rather than one thread progressing while the others do not interfere), and (2) such programs are often designed to be executed by any number of threads, and the desired liveness properties must hold no matter how many threads are active in the system.", "num_citations": "25\n", "authors": ["274"]}
{"title": "Reducing GUI test suites via program slicing\n", "abstract": " A crucial problem in GUI testing is the identification of accurate event sequences that encode corresponding user interactions with the GUI. Ultimately, event sequences should be both feasible (ie, executable on the GUI) and relevant (ie, cover as much of the code as possible). So far, most work on GUI testing focused on approaches to generate feasible event sequences. In addition, based on event dependency analyses, a recently proposed static analysis approach systematically aims at selecting both relevant and feasible event sequences. However, statically analyzing event dependencies can cause the generation of a huge number of event sequences, leading to unmanageable GUI test suites that are not executable within reasonable time. In this paper we propose a refined static analysis approach based on program slicing. On the theoretical side, our approach identifies and eliminates redundant event\u00a0\u2026", "num_citations": "25\n", "authors": ["274"]}
{"title": "Abstraction-based guided search for hybrid systems\n", "abstract": " Hybrid systems represent an important and powerful formalism for modeling real-world applications such as embedded systems. A verification tool like SpaceEx is based on the exploration of a symbolic search space (the region space). As a verification tool, it is typically optimized towards proving the absence of errors. In some settings, e.g., when the verification tool is employed in a feedback-directed design cycle, one would like to have the option to call a version that is optimized towards finding an error path in the region space. A recent approach in this direction is based on guided search. Guided search relies on a cost function that indicates which states are promising to be explored, and preferably explores more promising states first. In this paper, an abstraction-based cost function based on pattern databases for guiding the reachability analysis is proposed. For this purpose, a suitable abstraction\u00a0\u2026", "num_citations": "25\n", "authors": ["274"]}
{"title": "Vacuous real-time requirements\n", "abstract": " We introduce the property of vacuity for requirements. A requirement is vacuous in a set of requirements if it is equivalent to a simpler requirement in the context of the other requirements. For example, the requirement \u201cif A then B\u201d is vacuous together with the requirement \u201cnot A\u201d. The existence of a vacuous requirement is likely to indicate an error. We give an algorithm that proves the absence of this kind of error for real-time requirements. A case study in an industrial context demonstrates the practical potential of the algorithm.", "num_citations": "25\n", "authors": ["274"]}
{"title": "It\u2019s doomed; we can prove it\n", "abstract": " Programming errors found early are the cheapest. Tools applying to the early stage of code development exist but either they suffer from false positives (\u201cnoise\u201d) or they require strong user interaction. We propose to avoid this deficiency by defining a new class of errors. A program fragment is doomed if its execution will inevitably fail, in whatever state it is started. We use a formal verification method to identify such errors fully automatically and, most significantly, without producing noise. We report on preliminary experiments with a prototype tool.", "num_citations": "25\n", "authors": ["274"]}
{"title": "Directional type inference for logic programs\n", "abstract": " We follow the set-based approach to directional types proposed by Aiken and Lakshman [1]. Their type checking algorithm works via set constraint solving and is sound and complete for given discriminative types. We characterize directional types in model-theoretic terms. We present an algorithm for inferring directional types. The directional type that we derive from a logic program P is uniformly at least as precise as any discriminative directional type of P, i.e., any directional type out of the class for which the type checking algorithm of Aiken and Lakshman is sound and complete. We improve their algorithm as well as their lower bound and thereby settle the complexity (Dexptime-complete) of the corresponding problem.", "num_citations": "25\n", "authors": ["274"]}
{"title": "Ordering constraints over feature trees\n", "abstract": " Feature trees have been used to accommodate records in constraint programming and record like structures in computational linguistics. Feature trees model records, and feature constraints yield extensible and modular record descriptions. We introduce the constraint system fFT \u2264of ordering constraints interpreted over feature trees. Under the view that feature trees represent symbolic information, the relation \u2264 corresponds to the information ordering (\u201ccarries less information than\u201d). We present a polynomial algorithm that decides the satisfi ability of conjunctions of positive and negative information ordering constraints over feature trees. Our results include algorithms for the satisfiability problem and the entailment problem of FT \u2264 in time O(n 3). We also show that FT \u2264 has the independence property and are thus able to handle negative conjuncts via entailment. Furthermore, we reduce the satisfiability\u00a0\u2026", "num_citations": "24\n", "authors": ["274"]}
{"title": "Tree monoids and recognizability of sets of finite trees\n", "abstract": " Publisher SummaryThis chapter presents a new structure called the monoid of trees with a pointed border node, that is, the set \u03a3(#) of pairs (t, f) where t is a binary tree on \u03a3 and f is a border node of t, equipped with the associative composition law. It is shown that the transition monoid of a deterministic finite ascending tree automaton (dfata) is naturally a homomorphic image of the monoid \u03a3(#). This transition monoid is, as in the case of word automata, a monoid of functions from the set of states into itself under the ordinary composition law. The chapter discusses binary trees and ascending finite automata.", "num_citations": "24\n", "authors": ["274"]}
{"title": "Ultimate kojak with memory safety checks\n", "abstract": " Ultimate Kojak is a symbolic software model checker implemented in the Ultimate framework. It follows the CEGAR approach and uses Craig interpolants to refine an overapproximation of the program until it can either prove safety or has found a real counterexample. This year\u2019s version features a new refinement algorithm, a precise treatment of heap memory, which allows us to deal with pointer aliasing and to participate in the memsafety category, and an improved interpolants generator.", "num_citations": "23\n", "authors": ["274"]}
{"title": "A box-based distance between regions for guiding the reachability analysis of SpaceEx\n", "abstract": " A recent technique used in falsification methods for hybrid systems relies on distance-based heuristics for guiding the search towards a goal state. The question is whether the technique can be carried over to reachability analyses that use regions as their basic data structure. In this paper, we introduce a box-based distance measure between regions. We present an algorithm that, given two regions, efficiently computes the box-based distance between them. We have implemented the algorithm in SpaceEx and use it for guiding the region-based reachability analysis of SpaceEx. We illustrate the practical potential of our approach in a case study for the navigation benchmark.", "num_citations": "23\n", "authors": ["274"]}
{"title": "Interpretability and tree automata: a simple way to solve algorithmic problems on graphs closely related to trees\n", "abstract": " The main goal of this article is to point out the strong connection between recent results in complexity theory and results on decidability of monadic second order theories. Both sets of results employ the following three concepts:\u2022 tiling problems, in order to deduce high complexity or undecidability,\u2022 tree automata, in order to deduce polynomial time complexity or decidability,\u2022 the interpretability method, in order to transfer complexity or decidability results from trees to other structures.", "num_citations": "23\n", "authors": ["274"]}
{"title": "If A fails, can B still succeed? Inferring dependencies between test results in automotive system testing\n", "abstract": " In this paper we propose an approach that, given a structured requirements specification, allows the automatic online detection of a redundant test case. This means that, at each time point during a testing phase, one automatically infers the failure of a test case from the current status of successful tests and failed tests. By a structured requirements specification we mean that one uses a hierarchical structure and types to document the (natural language) formulation of requirements. We have implemented the approach. The evaluation of our implementation in a case study in the context of the development process for Mercedes-Benz vehicles at Daimler AG indicates the practical potential of our approach.", "num_citations": "22\n", "authors": ["274"]}
{"title": "Reducing quasi-equal clocks in networks of timed automata\n", "abstract": " We introduce the novel notion of quasi-equal clocks and use it to improve the verification time of networks of timed automata. Intuitively, two clocks are quasi-equal if, during each run of the system, they have the same valuation except for those points in time where they are reset. We propose a transformation that takes a network of timed automata and yields a network of timed automata which has a smaller set of clocks and preserves properties up to those not comparing quasi-equal clocks. Our experiments demonstrate that the verification time in three transformed real world examples is much lower compared to the original.", "num_citations": "21\n", "authors": ["274"]}
{"title": "Splitting via interpolants\n", "abstract": " A common problem in software model checking is the automatic computation of accurate loop invariants. Loop invariants can be derived from interpolants for every path leading through the corresponding loop header. However, in practice, the consideration of single paths often leads to very path specific interpolants. Inductive invariants can only be derived after several iterations by also taking previous interpolants into account.             In this paper, we introduce a software model checking approach that uses the concept of path insensitive interpolation to compute loop invariants. In contrast to current approaches, path insensitive interpolation summarizes several paths through a program location instead of one. As a consequence, it takes the abstraction refinement considerably less effort to obtain an adequate interpolant. First experiments show the potential of our approach.", "num_citations": "21\n", "authors": ["274"]}
{"title": "The independence property of a class of set constraints\n", "abstract": " We investigate a class of set constraints that is used for the type analysis of concurrent constraint programs. Its constraints are inclusions between first-order terms (without set operators) interpreted over non-empty sets of finite trees. We show that this class has the independence property. We give a polynomial algorithm for entailment. The independence property is a fundamental property of constraint systems. It says that the constraints cannot express disjunctions, or, equivalently, that negated conjuncts are independent from each other. As a consequence, the satisfiability of constraints with negated conjuncts can be directly reduced to entailment.", "num_citations": "21\n", "authors": ["274"]}
{"title": "A monoid approach to tree automata\n", "abstract": " CiNii \u8ad6\u6587 - A monoid approach to tree automata CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3 ] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb \u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u7a93\u53e3\u696d\u52d9\u306e\u518d\u958b\u306b\u3064\u3044\u3066 A monoid approach to tree automata PODELSKI A. \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 PODELSKI A. \u53ce\u9332 \u520a\u884c\u7269 Tree Automata and Languages Tree Automata and Languages, 1992 North-Holland \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 \u69cb\u9020\u5316\u6587\u66f8\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306e\u305f\u3081\u306e\u6587\u8108\u6761\u4ef6\u3068\u30d1\u30bf\u30fc\u30f3 \u6751\u7530 \u771f \u60c5\u5831\u51e6\u7406\u5b66\u4f1a\u7814\u7a76\u5831\u544a. DBS,\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u30b7\u30b9\u30c6\u30e0\u7814\u7a76\u4f1a\u5831\u544a 112, 25-32, 1997-05-13 \u53c2\u8003 \u6587\u732e37\u4ef6 \u88ab\u5f15\u7528\u6587\u732e1\u4ef6 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u8ad6\u6587ID(NAID) 10020853716 \u8cc7\u6599\u7a2e\u5225 \u56f3\u66f8\u306e\u4e00 \u90e8 \u30c7\u30fc\u30bf\u63d0\u4f9b\u5143 CJP\u5f15\u7528 \u66f8\u304d\u51fa\u3057 RefWorks\u306b\u66f8\u304d\u51fa\u3057 EndNote\u306b\u66f8\u304d\u51fa\u3057 Mendeley\u306bRefer/| \u2026", "num_citations": "21\n", "authors": ["274"]}
{"title": "A geometrical view of the determinization and minimization of finite-state automata\n", "abstract": " With every finite-state word or tree automaton, we associate a binary relation on words or trees. We then consider the \u201crectangular decompositions\u201d of this relation, i.e., the various ways to express it as a finite union of Cartesian products of sets of words or trees, respectively. We show that the determinization and the minimization of these automata correspond to simple geometrical reorganizations of the rectangular decompositions of the associated relations.", "num_citations": "21\n", "authors": ["274"]}
{"title": "Ready for testing: ensuring conformance to industrial standards through formal verification\n", "abstract": " The design of distributed, safety-critical real-time systems is challenging due to their high complexity, the potentially large number of components, and complicated requirements and environment assumptions that stem from international standards. We present a case study that shows that despite those challenges, the automated formal verification of such systems is not only possible, but practicable even in the context of small to medium-sized enterprises. We considered a wireless fire alarm system, regulated by the EN 54 standard. We performed formal requirements engineering, modeling and verification and uncovered severe design flaws that would have prevented its certification. For an improved design, we provided dependable verification results which in particular ensure that certification tests for a relevant regulation standard will be passed. In general we observe that if system tests are specified by\u00a0\u2026", "num_citations": "20\n", "authors": ["274"]}
{"title": "Doomed program points\n", "abstract": " Any programming error that can be revealed before compiling a program saves precious time for the programmer. While integrated development environments already do a good job by detecting, e.g., data-flow abnormalities, current static analysis tools suffer from false positives (\u201cnoise\u201d) or require strong user interaction.               We propose to avoid this deficiency by defining a new class of errors. A program fragment is doomed if its execution will inevitably fail, regardless of which state it is started in. We use a formal verification method to identify such errors fully automatically and, most significantly, without producing noise. We report on experiments with a prototype tool.", "num_citations": "20\n", "authors": ["274"]}
{"title": "Eliminating spurious transitions in reachability with support functions\n", "abstract": " Computing an approximation of the reachable states of a hybrid system is a challenge, mainly because overapproximating the solutions of ODEs with a finite number of sets does not scale well. Using template polyhedra can greatly reduce the computational complexity, since it replaces complex operations on sets with a small number of optimization problems. However, the use of templates may make the over-approximation too conservative. Spurious transitions, which are falsely considered reachable, are particularly detrimental to performance and accuracy, and may exacerbate the state explosion problem. In this paper, we examine how spurious transitions can be avoided with minimal computational effort. To this end, detecting spurious transitions is reduced to the well-known problem of showing that two convex sets are disjoint by finding a hyperplane that separates them. We generalize this to flowpipes by\u00a0\u2026", "num_citations": "19\n", "authors": ["274"]}
{"title": "Beyond region graphs: Symbolic forward analysis of timed automata\n", "abstract": " Theoretical investigations of infinite-state systems have so far concentrated on decidability results; in the case of timed automata these results are based on region graphs. We investigate the specific procedure that is used practically in order to decide verification problems, namely symbolic forward analysis. This procedure is possibly nonterminating. We present basic concepts and properties that are useful for reasoning about sufficient termination conditions, and then derive some conditions. The central notions here are constraint transformers associated with sequences of automaton edges and zone trees labeled with successor constraints.", "num_citations": "19\n", "authors": ["274"]}
{"title": "Operational Semantics of Constraint Logic Programs with Coroutining.\n", "abstract": " The semantics of constraint logic programming languages with coroutining facilities (\" freeze,\" suspension, residuation, etc.) cannot be fully declarative; thus, an operational semantics has to be taken as the defining one. We give a formal operational semantics for a Prolog-like language with cut and entailment-based conditional. The difficulty here is to present the semantics in a form that abstracts away inessential details and highlights the interaction between language constructs. Our approach is derived from those used for concurrent calculi. We use abstract syntax trees, congruence laws and rewrite rules to define the semantics. A computation step is modeled as the application of a rewrite rule to an abstract syntax tree modulo structural congruence. This semantics serves as a defining tool for the language designer and as the interface between the language designer and implementor; it allows the programmer to check his intuition with a formal execution model and it gives him a performance measure for the execution of programs. We have used the semantics to make precise, for the first time, the critical interaction between sequential execution (including backtracking and cut pruning) and coroutining. In particular we exhibit cases where this interaction can lead to indeterministic results (ie, to non-predictable program execution).", "num_citations": "19\n", "authors": ["274"]}
{"title": "Adaptive moment closure for parameter inference of biochemical reaction networks\n", "abstract": " Continuous-time Markov chain (CTMC) models have become a central tool for understanding the dynamics of complex reaction networks and the importance of stochasticity in the underlying biochemical processes. When such models are employed to answer questions in applications, in order to ensure that the model provides a sufficiently accurate representation of the real system, it is of vital importance that the model parameters are inferred from real measured data. This, however, is often a formidable task and all of the existing methods fail in one case or the other, usually because the underlying CTMC model is high-dimensional and computationally difficult to analyze. The parameter inference methods that tend to scale best in the dimension of the CTMC are based on so-called moment closure approximations. However, there exists a large number of different moment closure approximations and it is\u00a0\u2026", "num_citations": "18\n", "authors": ["274"]}
{"title": "Ultimate automizer with an on-demand construction of Floyd-Hoare automata\n", "abstract": " Ultimate Automizer is a software verifier that implements an automata-based approach for the verification of safety and liveness properties. A central new feature that speeded up the abstraction refinement of the tool is an on-demand construction of Floyd-Hoare automata.", "num_citations": "17\n", "authors": ["274"]}
{"title": "Automated program verification\n", "abstract": " A new approach to program verification is based on automata. The notion of automaton depends on the verification problem at hand (nested word automata for recursion, B\u00fcchi automata for termination, a form of data automata for parametrized programs, etc.). The approach is to first construct an automaton for the candidate proof and then check its validity via automata inclusion. The originality of the approach lies in the construction of an automaton from a correctness proof of a given sequence of statements. A sequence of statements is at the same time a word over a finite alphabet and it is (a very simple case of) a program. Just as we ask whether a word has an accepting run, we can ask whether a sequence of statements has a correctness proof (of a certain form). The automaton accepts exactly the sequences that do.", "num_citations": "17\n", "authors": ["274"]}
{"title": "rt-inconsistency: a new property for real-time requirements\n", "abstract": " We introduce rt-inconsistency, a property of real-time requirements. The property reflects that the requirements specify apparently inconsistent timing constraints. We present an algorithm to check rt-inconsistency automatically. The algorithm works via a stepwise reduction to real-time model checking. We implement the algorithm using an existing module for the reduction and the Uppaal tool for the real-time model checking. As a case study, we apply our prototype implementation to existing real-time requirements for automotive projects at Bosch. The case study demonstrates the relevance of rt-inconsistency for detecting errors in industrial real-time requirements specifications.", "num_citations": "17\n", "authors": ["274"]}
{"title": "Tools and Algorithms for the Construction and Analysis of Systems: 6th International Conference, TACAS 2000 Held as Part of the Joint European Conferences on Theory and\u00a0\u2026\n", "abstract": " This book constitutes the refereed proceedings of the 6th International Conference on Tools and Algorithms for the Construction and Analysis of Systems, TACAS 2000, held as part of ETAPS 2000 in Berlin, Germany, in March/April 2000. The 33 revised full papers presented together with one invited paper and two short tool descriptions were carefully reviewed and selected from a total of 107 submissions. The papers are organized in topical sections on software and formal methods, formal methods, timed and hybrid systems, infinite and parameterized systems, diagnostic and test generation, efficient model checking, model-checking tools, symbolic model checking, visual tools, and verification of critical systems.", "num_citations": "17\n", "authors": ["274"]}
{"title": "Paths vs. trees in set-based program analysis\n", "abstract": " Set-based analysis of logic programs provides an accurate method for descriptive type-checking of logic programs. The key idea of this method is to upper approximate the least model of the program by a regular set of trees. In 1991, Fr\u00fchwirth, Shapiro, Vardi and Yardeni raised the question whether it can be more efficient to use the domain of sets of paths instead, ie, to approximate the least model by a regular set of words. We answer the question negatively by showing that type-checking for path-based analysis is as hard as the set-based one, that is DEXPTIME-complete. This result has consequences also in the areas of set constraints, automata theory and model checking.", "num_citations": "16\n", "authors": ["274"]}
{"title": "Solving set constraints for greatest models\n", "abstract": " In set-based program analysis, one first infers a set constraint'from a program and then, in a constraintsolving process, one transforms' into an effective representation of sets of program values. Heintze and Jaffar have thus analyzed logic programs with respect to the least-model semantics. In this paper, we present a set-based analysis of logic programs with respect to the greatest model semantics, and we give its complexity characterization. We consider set constraints consisting of inclusions x\u00f8 between a variable x and a term \u00f8 with intersection, union and projection. We solve such a set constraint by computing a representation of its greatest solution (essentially as a tree automaton). We obtain that the problem of the emptiness of its greatest solution is DEXPTIME-complete. The choice of the greatest model for set-based analysis is motivated by the verification of safety properties (\" no failure\") of reactive (ie, possibly non-terminating) logic programs over infinite t...", "num_citations": "16\n", "authors": ["274"]}
{"title": "Loop invariants from counterexamples\n", "abstract": " We propose a new approach to software model checking where we integrate abstract interpretation and trace abstraction. We use abstract interpretation to derive loop invariants for the path program corresponding to a given spurious counterexample. A path program is the smallest subprogram that still contains a given path in the control flow graph. We use the principle of trace abstraction to construct an overall proof. The key observation of our approach is that proofs by abstract interpretation on individual program fragments can be composed directly if we use the framework of trace abstraction (in trace abstraction, composing proofs amounts to a set-theoretic operation, i.e., set union). We implemented our approach in the open-source software model checking framework Ultimate. Our evaluation shows that we can solve up\u00a0to 40% more benchmarks.", "num_citations": "15\n", "authors": ["274"]}
{"title": "Craig vs. Newton in software model checking\n", "abstract": " Ever since the seminal work on SLAM and BLAST, software model checking with counterexample-guided abstraction refinement (CEGAR) has been an active topic of research. The crucial procedure here is to analyze a sequence of program statements (the counterexample) to find building blocks for the overall proof of the program. We can distinguish two approaches (which we name Craig and Newton) to implement the procedure. The historically first approach, Newton (named after the tool from the SLAM toolkit), is based on symbolic execution. The second approach, Craig, is based on Craig interpolation. It was widely believed that Craig is substantially more effective than Newton. In fact, 12 out of the 15 CEGAR-based tools in SV-COMP are based on Craig. Advances in software model checkers based on Craig, however, can go only lockstep with advances in SMT solvers with Craig interpolation. It may be time\u00a0\u2026", "num_citations": "15\n", "authors": ["274"]}
{"title": "Ultimate Taipan: Trace abstraction and abstract interpretation\n", "abstract": " Ultimate Taipan is a software model checker for C programs. It is based on a CEGAR variant, trace abstraction\u00a0[7], where program abstractions, counterexample selection and abstraction refinement are based on automata. Ultimate Taipan constructs path programs from counterexamples and computes fixpoints for those path programs using abstract interpretation. If the fixpoints are strong enough to prove the path program to be correct, they are guaranteed to be loop invariants for the path program. If they are not strong enough, Ultimate Taipan uses an interpolating SMT solver to obtain state assertions from the original counterexample, thus guaranteeing progress.", "num_citations": "15\n", "authors": ["274"]}
{"title": "Timed automata with disjoint activity\n", "abstract": " The behavior of timed automata consists of idleness and activity, i.e. delay and action transitions. We study a class of timed automata with periodic phases of activity. We show that, if the phases of activity of timed automata in a network are disjoint, then location reachability for the network can be decided using a concatenation of timed automata. This reduces the complexity of verification in Uppaal-like tools from quadratic to linear time (in the number of components) while traversing the same reachable state space. We provide templates which imply, by construction, the applicability of sequential composition, a variant of concatenation, which reflects relevant reachability properties while removing an exponential number of states. Our approach covers the class of TDMA-based (Time Division Multiple Access) protocols, e.g. FlexRay and TTP. We have successfully applied our approach to an industrial TDMA\u00a0\u2026", "num_citations": "15\n", "authors": ["274"]}
{"title": "Disambiguation of industrial standards through formalization and graphical languages\n", "abstract": " Natural language safety requirements in industrial standards pose risks for ambiguities which need to be resolved by the system manufacturer in concertation with the certificate authority. This is especially challenging for small and medium-sized enterprises (SME). In this paper we report on our experiences with applying traditional requirements engineering techniques, formal methods, and visual narratives in an exploratory case-study in an SME.", "num_citations": "15\n", "authors": ["274"]}
{"title": "Composing reachability analyses of hybrid systems for safety and stability\n", "abstract": " We present a method to enhance the power of a given reachability analysis engine for hybrid systems. The method works by a new form of composition of reachability analyses, each on a different relaxation of the input hybrid system. We present preliminary experiments that indicate its practical potential for checking safety and stability.", "num_citations": "15\n", "authors": ["274"]}
{"title": "Transition-based directed model checking\n", "abstract": " Directed model checking is a well-established technique that is tailored to fast detection of system states that violate a given safety property. This is achieved by influencing the order in which states are explored during the state space traversal. The order is typically determined by an abstract distance function that estimates a state\u2019s distance to a nearest error state. In this paper, we propose a general enhancement to directed model checking based on the evaluation of state transitions. We present a schema, parametrized by an abstract distance function, to evaluate transitions and propose a new method for the state space traversal. Our framework can be applied automatically to a wide range of abstract distance functions. The empirical evaluation impressively shows its practical potential. Apparently, the new method identifies a sweet spot in the trade-off between scalability (memory consumption) and short\u00a0\u2026", "num_citations": "15\n", "authors": ["274"]}
{"title": "Ordering constraints over feature trees\n", "abstract": " Feature trees are the formal basis for algorithms manipulating record like structures in constraint programming, computational linguistics and in concrete applications like software configuration management. Feature trees model records, and constraints over feature trees yield extensible and modular record descriptions. We introduce the constraint system FT\u2264 of ordering constraints interpreted over feature trees. Under the view that feature trees represent symbolic information, the relation \u2264 corresponds to the information ordering (\u201ccarries less information than\u201d). We present two algorithms in cubic time, one for the satisfiability problem and one for the entailment problem of FT\u2264. We show that FT\u2264 has the independence property. We are thus able to handle negative conjuncts via entailment and obtain a cubic algorithm that decides the satisfiability of conjunctions of positive and negated ordering\u00a0\u2026", "num_citations": "15\n", "authors": ["274"]}
{"title": "Classifying bugs with interpolants\n", "abstract": " We present an approach to the classification of error messages in the context of static checking in the style of ESC/Java. The idea is to compute a semantics-based signature for each error message and then group\u00a0together error messages with the same signature. The approach aims at exploiting modern verification techniques based on, e.g., Craig interpolation in order to generate small but significant signatures. We have implemented the approach and applied it to three benchmark sets (from Apache Ant, Apache Cassandra, and our own tool). Our experiments indicate an interesting practical potential. More than half of the considered error messages (for procedures with more than just one error message) can be grouped together with another error message.", "num_citations": "14\n", "authors": ["274"]}
{"title": "The Beauty and the Beast Algorithm: Quasi-Linear Incremental Tests of Entailment and Disentailment over Trees.\n", "abstract": " We consider the problem of the simultaneous tests of matching and non-unifiability (logically: entailment and disentailment over trees) where the input consists of one fixed term (one fixed constraint) and an incrementally growing set of variable bindings (the constraint store). These tests are used in logic programming systems with suspensions, eg for proving guards as in LIFE, AKL and Oz. A weaker version of the problem tests entailment only, which is sufficient for solving inequations as in Prolog-II and CLP (Rat). The on-line complexity of previous algorithms for either version of the problem is at least quadratic. We present an on-line algorithm which is quasi-linear.", "num_citations": "14\n", "authors": ["274"]}
{"title": "Useless Actions Are Useful.\n", "abstract": " Planning as heuristic search is a powerful approach to solving domain independent planning problems. In recent years, various successful heuristics and planners like FF, LPG, FAST DOWNWARD or SGPLAN have been proposed in this context. However, as heuristics only estimate the distance to goal states, a general problem of heuristic search is the existence of plateaus in the search space topology which can cause the search process to degenerate. Additional techniques like helpful actions or preferred operators that evaluate the \u201cusefulness\u201d of actions are often successful strategies to support the search in such situations. In this paper, we introduce a general method to evaluate the usefulness of actions. We propose a technique to enhance heuristic search by identifying \u201cuseless\u201d actions that are not needed to find optimal plans. In contrast to helpful actions or preferred operators that are specific to the FF and Causal Graph heuristic, respectively, our method can be combined with arbitrary heuristics. We show that this technique often yields significant performance improvements.", "num_citations": "13\n", "authors": ["274"]}
{"title": "Set-based failure analysis for logic programs and concurrent constraint programs\n", "abstract": " This paper presents the first approximation method of the finite-failure set of a logic program by set-based analysis. In a dual view, the method yields a type analysis for programs with ongoing behaviors (perpetual processes). Our technical contributions are (1) the semantical characterization of finite failure of logic programs over infinite trees and (2) the design and soundness proof of the first set-based analysis of logic programs with the greatest-model semantics. Finally, we exhibit the connection between finite failure and the inevitability of the \u2018inconsistentstore\u2019 error in fair executions of concurrent constraint programs where no process suspends forever. This indicates a potential application to error diagnosis for concurrent constraint programs", "num_citations": "13\n", "authors": ["274"]}
{"title": "Logic programming with functions over order-sorted feature terms\n", "abstract": " LIFE is an experimental programming language proposing to integrate logic programming, functional programming, and object-oriented programming. It replaces first-order terms with \u03c8-terms, data structures which allow computing with partial information. These arc approximation structures denoting sets of values. LIFE further enriches the expressiveness of \u03c8-terms with functional dependency constraints. Whereas LIFE's relations defined as Horn-clauses use \u03c8-term unification for parameter-passing, LFFE's functions use \u03c8-term matching (i.e., one-way unification). We explain the meaning and use of functions in LIFE declaralively as solving partial information constraints. These constraints do not attempt to generate their solutions but behave as demons filtering out anything else. In this manner, LIFE functions act as declarative coroutines.", "num_citations": "13\n", "authors": ["274"]}
{"title": "Adaptive moment closure for parameter inference of biochemical reaction networks\n", "abstract": " Continuous-time Markov chain (CTMC) models have become a central tool for understanding the dynamics of complex reaction networks and the importance of stochasticity in the underlying biochemical processes. When such models are employed to answer questions in applications, in order to ensure that the model provides a sufficiently accurate representation of the real system, it is of vital importance that the model parameters are inferred from real measured data. This, however, is often a formidable task and all of the existing methods fail in one case or the other, usually because the underlying CTMC model is high-dimensional and computationally difficult to analyze. The parameter inference methods that tend to scale best in the dimension of the CTMC are based on so-called moment closure approximations. However, there exists a large number of different moment closure approximations and it is typically\u00a0\u2026", "num_citations": "12\n", "authors": ["274"]}
{"title": "Requirements defects over a project lifetime: an empirical analysis of defect data from a 5-year automotive project at Bosch\n", "abstract": " [Context and motivation] Requirements defects are notoriously costly. Analysing the defect data in a completed project may help to improve practice in follow up projects. [Question/Problem] The problem is to analyse the different kinds of requirements defects that may occur during the lifetime of an industrial project, and, for each kind of requirement defect, the respective number of occurrences and the cost incurred. [Principal ideas/results] In this paper, we present a post hoc analysis for an automotive project at Bosch. We have analysed 588 requirements defects reported during the elapsed project lifetime of 4.5\u00a0years. The analysis is based on a specific classification scheme for requirements defects which takes its eight attributes (incorrect, incomplete, etc.) from the IEEE 830 standard and refines them further by distinguishing nine possible defect sources (relating to parameters, wording, timing, etc\u00a0\u2026", "num_citations": "12\n", "authors": ["274"]}
{"title": "Detecting quasi-equal clocks in timed automata\n", "abstract": " A recent optimizations technique for timed model checking starts with a given specification of quasi-equal clocks. In principle, the zone graph can used to detect which clocks are quasi-equal; the construction of the zone graph would, however, defeat its very purpose (which is the optimization of this construction). In this paper, we present an abstraction that is effective for the goal of the optimization based on quasi-equal clocks: it is coarse enough to yield a drastic reduction of the size of the zone graph. Still, it is precise enough to identify a large class of quasi-equal clocks. The abstraction is motivated by an intuition about the way quasi-equalities can be tracked. We have implemented the corresponding reasoning method in the Jahob framework using an SMT solver. Our experiments indicate that our intuition may lead to a useful abstraction.", "num_citations": "12\n", "authors": ["274"]}
{"title": "Parameterized GUI tests\n", "abstract": " GUI testing is a form of system testing where test cases are based on user interactions. A user interaction may be encoded by a sequence of events (e.g., mouse clicks) together with input data (e.g., string values for text boxes). For selecting event sequences, one can use the black-box approach based on Event Flow Graphs. For selecting input data, one can use the white-box approach based on parameterized unit tests and symbolic execution. The contribution of this paper is an approach to make the principle of parameterized unit testing available to black-box GUI testing. The approach is based on the new notion of parameterized GUI tests. We have implemented the approach in a new tool. In order to evaluate whether parameterized GUI tests have the potential to achieve high code coverage, we apply the tool to four open source GUI applications. The results are encouraging.", "num_citations": "12\n", "authors": ["274"]}
{"title": "Principles and Practice of Constraint Programming-CP'95: First International Conference, CP'95, Cassis, France, September 19-22, 1995. Proceedings\n", "abstract": " This book constitutes the proceedings of the First International Conference on Principles and Practice of Constraint Programming, CP'95, held in Cassis near Marseille, France in September 1995. The 33 refereed full papers included were selected out of 108 submissions and constitute the main part of the book; in addition there is a 60-page documentation of the four invited papers and a section presenting industrial reports. Thus besides having a very strong research component, the volume will be attractive for practitioners. The papers are organized in sections on efficient constraint handling, constraint logic programming, concurrent constraint programming, computational logic, applications, and operations research.", "num_citations": "12\n", "authors": ["274"]}
{"title": "On reverse and general definite tree languages\n", "abstract": " We show: There is no tree language whose syntactic semigroup lies in Kr, or in LI unless it is in K. Instead, reverse (resp. general) definite tree languages have syntactic semigroups in Kr V J1 (resp. LI v J1). We give concise combinatorial descriptions of the tree languages whose syntactic semigroups are in Kr v J 1 (resp. LI v J 1), in terms of the properties reverse (resp. general) J 1-definite. These properties are more general than the properties reverse (general) definite as defined by Heuter. Finally we show that they are decidable.", "num_citations": "12\n", "authors": ["274"]}
{"title": "Quasi-dependent variables in hybrid automata\n", "abstract": " The concept of hybrid automata provides a powerful framework to model and analyze real-world systems. Due to the structural complexity of hybrid systems it is important to ensure the scalability of analysis algorithms. We approach this problem by providing an effective generalisation of the recently introduced notion of quasi-equal clocks to hybrid systems. For this purpose, we introduce the concept of quasi-dependent variables. Our contribution is two-fold: we demonstrate how such variables can be automatically detected, and we present a transformation leading to an abstraction with a smaller state space which, however, still retains the same properties as the original system. We demonstrate the practical applicability of our methods on a range of industrial benchmarks.", "num_citations": "11\n", "authors": ["274"]}
{"title": "Satisfiability checking with difference constraints\n", "abstract": " This thesis studies the problem of determining the satisfiability of a Boolean combination of binary difference constraints of the form x\u2212 y\u2264 c where x and y are numeric variables and c is a constant. In particular, we present an incremental and model-based interpreter for the theory of difference constraints in the context of a generic Boolean satisfiability checking procedure capable of incorporating interpreters for arbitrary theories. We show how to use the model based approach to efficiently make inferences with the option of complete inference.", "num_citations": "11\n", "authors": ["274"]}
{"title": "Ultimate automizer with unsatisfiable cores\n", "abstract": " Ultimate                 Automizer is an automatic software verification tool for C programs. This tool is a prototype implementation of an automata-theoretic approach that allows a modular verification of programs. Furthermore, this is the first implementation of a novel interpolation technique where interpolants are not obtained from an interpolating theorem prover but from a combination of a live variable analysis, interprocedural predicate transformers and unsatisfiable cores.", "num_citations": "10\n", "authors": ["274"]}
{"title": "Model checking for timed logic processes\n", "abstract": " We apply techniques from logic programming and constraint databases to verify real time systems. We introduce timed logic processes (TLPs) as a fragment of constraint query languages over reals. We establish a formal connection between TLPs and timed automata, and between the procedure of the UPPAAL model checker for restricted temporal-logic properties of timed automata and the top-down query evaluation of TLPs (with tabling in the XSB style). This connection yields an alternative implementation of the UPPAAL procedure. Furthermore, we can extend that procedure in order to accommodate more expressive properties.", "num_citations": "10\n", "authors": ["274"]}
{"title": "Situated simplification\n", "abstract": " Testing satisfaction of guards is the essential operation of concurrent constraint programming (CCP) systems. We present and prove correct, for the first time, an incremental algorithm for the simultaneous tests of entailment and disentailment of rational tree constraints to be used in CCP systems with deep guards (e.g., AKL or Oz). The algorithm is presented as the simplification of the constraints which form the (possibly deep) guards and which are situated at different nodes (or, local computation spaces) in a tree (of arbitrary depth). In this algorithm, each variable may have multiple bindings (representing multiple constraints on the same variable in different nodes). These may be realized by re- and de-installation upon each newly resumed check of the guard in the corresponding node (as done, e.g., in AKL or Oz), or by using look-up tables (with entries indexed by the nodes). We give a simple fixed-point\u00a0\u2026", "num_citations": "10\n", "authors": ["274"]}
{"title": "Quasi-equal clock reduction: more networks, more queries\n", "abstract": " Quasi-equal clock reduction for networks of timed automata replaces equivalence classes of clocks which are equal except for unstable phases, i.e., points in time where these clocks differ on their valuation, by a single representative clock. An existing approach yields significant reductions of the overall verification time but is limited to so-called well-formed networks and local queries, i.e., queries which refer to a single timed automaton only. In this work we present two new transformations. The first, for networks of timed automata, summarises unstable phases without losing information under weaker well-formedness assumptions than needed by the existing approach. The second, for queries, now supports the full query language of Uppaal. We demonstrate that the cost of verifying non-local properties is much lower in transformed networks than in their original counterparts with quasi-equal clocks.", "num_citations": "9\n", "authors": ["274"]}
{"title": "Push-down automata with gap-order constraints\n", "abstract": " We consider push-down automata with data (Pdad) that operate on variables ranging over the set of natural numbers. The conditions on variables are defined via gap-order constraint. Gap-order constraints allow to compare variables for equality, or to check that the gap between the values of two variables exceeds a given natural number. The messages inside the stack are equipped with values that are natural numbers reflecting their \u201cvalues\u201d. When a message is pushed to the stack, its value may be defined by a variable in the program. When a message is popped, its value may be copied to a variable. Thus, we obtain a system that is infinite in two dimensions, namely we have a stack that may contain an unbounded number of messages each of which is equipped with a natural number. We present an algorithm for solving the control state reachability problem for Pdad based on two steps. We first provide\u00a0\u2026", "num_citations": "9\n", "authors": ["274"]}
{"title": "Hidden Markov Models\n", "abstract": " Chapter 7: Hidden Markov Models Page 1 Fall 2010 Graduate Course on Dynamic Learning Chapter 7: Hidden Markov Models October 25 2010 October 25, 2010 Byoung-Tak Zhang School of Computer Science and Engineering & Cognitive Science and Brain Science Programs Seoul National University http://bi.snu.ac.kr/~btzhang/ Page 2 Overview M ti ti A li ti \u2022 Motivating Applications \u2013 Computational Linguistics \u2013 Computational Biology p gy \u2022 HMM: A Graphical Description \u2022 HMM: A More Formal Description \u2013 Elements of HMM \u2013 Three Central Problems \u2022 Algorithms \u2013 Evaluation: Forward-Backward Algorithm \u2013 Decoding: Viterbi Algorithm \u2013 Learning: Baum-Welch Algorithm \u2022 Extensions 2 Page 3 Markov Random Processes \u2022 A random sequence has the Markov property if its dis tribution is determined solely by its current state. Any yy y random process having this property is called a Mark ov random process. p \u2022 ())\u2026", "num_citations": "9\n", "authors": ["274"]}
{"title": "The Wild LIFE handbook (prepublication edition)\n", "abstract": " This handbook provides a tutorial of the LIFE programming language as well as a complete description of the capabilities of the Wild LIFE 1.0 system. Although we have attempted to make the tutorial self-contained, it is preferable that the reader be familiar with Prolog. The tutorial exposes gradually the main components of LIFE in a synthetic approach: its original data structure\u2014-term\u2014and its use in predicates, functions, and sort (type) definitions. Along the way, many useful examples are provided and some common pitfalls are discussed and illustrated.", "num_citations": "9\n", "authors": ["274"]}
{"title": "Ultimate kojak\n", "abstract": " Ultimate Kojak is a symbolic software model checker for C programs. It is based on CEGAR and Craig interpolation. The basic algorithm, described in an earlier work\u00a0[1], was extended to be able to deal with recursive programs using nested word automata and nested (tree) interpolants.", "num_citations": "8\n", "authors": ["274"]}
{"title": "Is lazy abstraction a decision procedure for broadcast protocols?\n", "abstract": " Lazy abstraction builds up an abstract reachability tree by locally refining abstractions in order to eliminate spurious counterexamples in smaller and smaller subtrees. The method has proven useful to verify systems code. It is still open how good the method is as a decision procedure, i.e., whether the method terminates for already known decidable verification problems. In this paper, we answer the question positively for broadcast protocols and other infinite-state models in the class of so-called well-structured systems. This extends an existing result on systems with a finite bisimulation quotient.", "num_citations": "8\n", "authors": ["274"]}
{"title": "Constraint-based infinite model checking and tabulation for stratified clp\n", "abstract": " Forward analysis procedures for infinite-state systems such as timed systems were limited to safety properties. We give the first constraint-based forward analysis for infinite-state systems that goes beyond safety properties. Namely, we take the restriction of the \u03bc-calculus to least-fixpoint formulas where negation is applied to closed subformulas only. We characterize these properties as perfect models of constraint logic programs, and we present a tabulation procedure for the top-down evaluation of stratified constraint logic programs.", "num_citations": "8\n", "authors": ["274"]}
{"title": "Another variation on the common subexpression problem\n", "abstract": " In their work from 1980 (to which our title makes reference) Downey et al. (1980) study various cases of the problem of constructing the \u2018congruence closure\u2019 of a relation R on a graph (which is the unique extension R' of R on the vertex set V such that R' is an equivalence relation and closed under congruences; the problem is viewed by Kozen (1977) as the word problem for finite algebras and by Nelson and Oppen (1980) as the decision problem for the quantifier-free theory of equality with uninterpreted function symbols). In this work they prove the upper bound O(n log n) for the general case (n=|V|) and linear upper bounds for various special cases.We give an almost linear algorithm for yet another special case: the case of congruences of finite index (without any acyclicity restrictions), in the notation of Kozen (1977). It is there that the relationship to the finite tree automata of Thatcher and Wright (1968) was\u00a0\u2026", "num_citations": "8\n", "authors": ["274"]}
{"title": "ACSAR: Software model checking with transfinite refinement\n", "abstract": " ACSAR (Automatic Checker of Safety properties based on Abstraction Refinement) is a software model checker for C programs in the spirit of Blast [6], F-Soft [7], Magic [5] and Slam [1]. It is based on the counterexample-guided abstraction refinement (CEGAR) paradigm. Its specificity lies in the way it overcomes a problem common to all tools based on this paradigm. The problem arises from creating more and more spurious counterexamples by unfolding the same (while- or for-) loop over and over again; this leads to an infinite or at least too large sequence of refinement steps. The idea behind ACSAR is to abstract not just states but also the state changes induced by structured program statements, including for- and while-statements. The use of the new abstraction allows one to shortcut such a \u201ctransfinite\u201d sequence of refinement steps.", "num_citations": "7\n", "authors": ["274"]}
{"title": "Ultimate TreeAutomizer (CHC-COMP Tool Description)\n", "abstract": " We present Ultimate TreeAutomizer, a solver for satisfiability of sets of constrained Horn clauses. Constrained Horn clauses (CHC) are a fragment of first order logic with attractive properties in terms of expressiveness and accessibility to algorithmic solving. Ultimate TreeAutomizer is based on the techniques of trace abstraction, tree automata and tree interpolation. This paper serves as a tool description for TreeAutomizer in CHC-COMP 2019.", "num_citations": "6\n", "authors": ["274"]}
{"title": "Verification of GUI applications: A black-box approach\n", "abstract": " In this paper, we propose to base the verification of a GUI application on a reference model used in black-box testing. The reference model is a formal model for the behavior of the GUI application. It is derived by dynamic analysis (hence \u201cblack-box\u201d). Thus, it can be used to account for the graphical interface even when the GUI toolkit is not amenable to formal analysis or its source code is not available. We have implemented our approach; a preliminary case study indicates its feasibility in principle.", "num_citations": "6\n", "authors": ["274"]}
{"title": "Shape-based barrier estimation for RNAs\n", "abstract": " The ability of some RNA molecules to switch between different metastable conformations plays an important role in cellular processes. In order to identify such molecules and to predict their conformational changes one has to investigate the refolding pathways. As a qualitative measure of these transitions, the barrier height marks the energy peak along such refolding paths. We introduce a meta-heuristic to estimate such barriers, which is an NP-complete problem. To guide an arbitrary path heuristic, the method uses RNA shape representative structures as intermediate checkpoints for detours. This enables a broad but efficient search for refolding pathways. The resulting Shape Triples meta-heuristic enables a close to optimal estimation of the barrier height that outperforms the precision of the employed path heuristic.", "num_citations": "6\n", "authors": ["274"]}
{"title": "Model checking communication protocols\n", "abstract": " Brand and Zafiropulo [1] introduced the model of communicating finite-state machines to represent a distributed system connected with FIFO channels. Several different communication protocols can be specified with this simple model. In this paper we address the problem of automatically validating protocols by verifying properties such as well-formedness and absence of deadlock. Our method is based on a representation of communicating finite-state machines in terms of logic programs. This leads to efficient verification algorithms based on the ground and non-ground semantics of logic programming.", "num_citations": "6\n", "authors": ["274"]}
{"title": "Ultimate Taipan with Dynamic Block Encoding\n", "abstract": " Ultimate Taipan is a software model checker that uses trace abstraction and abstract interpretation to prove correctness of programs. In contrast to previous versions, Ultimate Taipan now uses dynamic block encoding to obtain the best precision possible when evaluating transition formulas of large block encoded programs.", "num_citations": "5\n", "authors": ["274"]}
{"title": "Composing stability proofs for hybrid systems\n", "abstract": " A recent automatic proof method for the region stability of a hybrid system is based on the reachability analysis for a transformed hybrid system with double dimensionality (the transformation duplicates each of the continuous variables). We propose a new method which composes the reachability analyses for a sequence of transformed hybrid systems with essentially the same dimensionality (each transformation in the sequence duplicates one of the continuous variables). The new method thus trades the double dimensionality for the number of reachability analyses.", "num_citations": "5\n", "authors": ["274"]}
{"title": "Fairness for dynamic control\n", "abstract": " Already in Lamport\u2019s bakery algorithm, integers are used for fair schedulers of concurrent processes. In this paper, we present the extension of a fair scheduler from \u2018static control\u2019 (the number of processes is fixed) to \u2018dynamic control\u2019 (the number of processes changes during execution). We believe that our results shed new light on the concept of fairness in the setting of dynamic control.", "num_citations": "5\n", "authors": ["274"]}
{"title": "A method and a tool for automatic veriication of region stability for hybrid systems\n", "abstract": " We propose a model checking method and tool that integrates state abstraction techniques for the automatic proof of a stability property for hybrid systems called\\emph {region stability}. It is based on a new notion of\\emph {snapshots} which yield characteristic discretizations of trajectories. We have implemented the tool and applied it to solve a number of verification problems, including the fully automatic stability proof for the break curve behavior of a train system.", "num_citations": "5\n", "authors": ["274"]}
{"title": "On Formal Verification of ACT-R Architectures and Models.\n", "abstract": " Subject of this article is the question whether the potential for automatic defect analysis for symbolic timed ACT-R models as demonstrated in earlier work can be developed into a scalable and comprehensible technique. We present a formal, operational model of an ACT-R architecture and a translation scheme of ACT-R models into timed automata. We have applied this translation to ACT-R models and report on scalability experiments with automatic defect analysis.", "num_citations": "4\n", "authors": ["274"]}
{"title": "Towards successful subcontracting for software in small to medium-sized enterprises\n", "abstract": " Many small to medium sized enterprises (SMEs) that specialise in electrical or communications engineering are challenged by the increasing importance of software in their products. Although they have a strong interest in subcontracting competent partners for software development tasks, they tend to refrain from doing so. In this paper we identify three main reasons for this situation, propose an approach to overcome some of them and state remaining challenges. Those reasons are situated in the intersection of software engineering and jurisprudence and therefore need to be addressed in an integrated and multidisciplinary fashion.", "num_citations": "4\n", "authors": ["274"]}
{"title": "System verification through program verification\n", "abstract": " We present an automatable approach to verify that a system satisfies its requirements by verification of the program that controls the system. The approach can be applied if the interaction of the program with the system hardware can be faithfully described by a table relating domain phenomena and program variables. We show the applicability of the approach with a case study based on a real-world system.", "num_citations": "4\n", "authors": ["274"]}
{"title": "Explicit fair scheduling for dynamic control\n", "abstract": " In explicit fair schedulers, auxiliary integer-valued scheduling variables with non-deterministic assignments and with decrements keep track of each processor\u2019s relative urgency. Every scheduled execution is fair and yet, the scheduler is sufficiently permissive (every fair run can be scheduled). In this paper we investigate whether explicit fair scheduling also works with dynamic control, i.e., when new processes may be created dynamically. We give a positive and a negative answer.", "num_citations": "4\n", "authors": ["274"]}
{"title": "Constraints in program analysis and verification\n", "abstract": " Program verification is a classical research topic in core computer science. Recent developments have lead to push-button software verification tools that are industrially used e.g. to check interface specifications of device drivers. These developments are based on program analysis, model checking and constraint solving.", "num_citations": "4\n", "authors": ["274"]}
{"title": "Software model checking with abstraction refinement\n", "abstract": " Automated verification of programs is a topic of increasing interest [1],[2],[3],[4],[5],[6], [7],[8],[9],[10],[11],[12],[13]. In a recent approach known as software model checking, one tries to prove a safety property of a program by iterating three steps: (1) the construction of an abstract system for an abstraction given by predicates over sets of states, (2) the model checking (in fact, a reachability analysis) of the abstract system, and (3) the refinement of the abstraction. The third step is done by generating additional predicates from the spurious counterexamples of the abstract system, if there are any; if not, the program property is either proven or disproven, and the method terminates.", "num_citations": "4\n", "authors": ["274"]}
{"title": "Efficient Algorithms for Pre and Post on Interprocedural  Parallel Flow Graphs\n", "abstract": " Efficient Algorithms for Pre$^\\star$ and Post$^\\star$ on Interprocedural Parallel Flow Graphs :: MPG.PuRe \u65e5\u672c\u8a9e Help Privacy Policy \u30dd\u30ea\u30b7\u30fc/\u514d\u8cac\u4e8b\u9805 \u5168\u6587\u3092\u542b\u3080 \u8a73\u7d30\u691c\u7d22 \u30d6\u30e9\u30a6\u30ba \u30db\u30fc\u30e0 \u4e00\u6642\u4fdd\u5b58 (0)\u30c4\u30fc\u30eb \u30a2\u30a4\u30c6\u30e0\u8a73\u7d30 \u767b\u9332\u5185\u5bb9\u3092\u7de8\u96c6\u30d5\u30a1\u30a4\u30eb\u5f62\u5f0f\u3067\u4fdd\u5b58 \u4e00\u6642 \u4fdd\u5b58\u3078\u8ffd\u52a0 \u30bf\u30b0\u60c5\u5831\u3092\u8868\u793a\u5229\u7528\u7d71\u8a08\u3092\u8868\u793a\u30ea\u30ea\u30fc\u30b9\u5c65\u6b74\u3092\u8868\u793a\u8a73\u7d30\u8981\u7d04 \u516c\u958b \u4f1a\u8b70\u8ad6\u6587 Efficient Algorithms for Pre$^\\star$ and Post$^\\star$ on Interprocedural Parallel Flow Graphs MPS-Authors /persons/resource/persons44391 Esparza, Javier Programming Logics, MPI for Informatics, Max Planck Society; /persons/resource/persons45201 Podelski, Andreas Programming Logics, MPI for Informatics, Max Planck Society; External Resource There are no locators available \u30d5\u30eb\u30c6\u30ad\u30b9\u30c8 (\u516c\u958b) \u516c\u958b\u3055\u308c\u3066\u3044\u308b\u30d5\u30eb\u30c6\u30ad\u30b9\u30c8\u306f\u3042\u308a\u307e\u305b\u3093 \u4ed8\u968f\u8cc7\u6599 (\u516c\u958b) There is no public supplementary material available \u2026", "num_citations": "4\n", "authors": ["274"]}
{"title": "Set-based analysis of reactive infinite-state systems\n", "abstract": " We consider reactive infinite-state systems specified by logic programs. Using set-based program analysis, we infer conservative approximations of temporal logic (CTL) properties of the systems. Our approach is based on a characterization of such properties through least and greatest models of logic programs with oracles. We apply the analysis of Heintze and Jaffar to approximate least models with definite set constraints. For greatest models, we design a new analysis. We introduce co-definite set constraints (which, when satisfiable, have a greatest solution) and present an algorithm for solving them. We establish the DEXPTIME-completeness of the satisfiability problem. A direct application is to the static prediction of errors (inevitability of failure or deadlock) in concurrent constraint programs.", "num_citations": "4\n", "authors": ["274"]}
{"title": "Temporal planning as refinement-based model checking\n", "abstract": " Planning as model checking based on source-to-source compilations has found increasing attention. Previously proposed approaches for temporal and hybrid planning are based on static translations, in the sense that the resulting model checking problems are uniquely defined by the given input planning problems. As a drawback, the translations can become too large to be efficiently solvable. In this paper, we address propositional temporal planning, lifting static translations to a more flexible framework. Our framework is based on a refinement cycle that allows for adaptively computing suitable translations of increasing size. Our experiments on temporal IPC domains show that the resulting translations to timed automata often become succinct, resulting in promising performance when applied with the directed model checker MCTA.", "num_citations": "3\n", "authors": ["274"]}
{"title": "The map equality domain\n", "abstract": " We present a method that allows us to infer expressive invariants for programs that manipulate arrays and, more generally, data that are modeled using maps (including the program memory which is modeled as a map over integer locations). The invariants can express, for example, that memory cells have changed their contents only at locations that have not been previously allocated by another procedure. The motivation for the new method stems from the fact that, although state-of-the-art SMT solvers are starting to be able to check the validity of more and more complex invariants, there is not much work yet on their automatic inference. We present our method as a static analysis over an abstract domain that we introduce, the map equality domain. The main challenge in the design of the method lies in scalability; given the expressiveness of the invariants, it is a priori not clear that a corresponding static\u00a0\u2026", "num_citations": "3\n", "authors": ["274"]}
{"title": "Refining trace abstraction using abstract interpretation\n", "abstract": " The CEGAR loop in software model checking notoriously diverges when the abstraction refinement procedure does not derive a loop invariant. An abstraction refinement procedure based on an SMT solver is applied to a trace, i.e., a restricted form of a program (without loops). In this paper, we present a new abstraction refinement procedure that aims at circumventing this restriction whenever possible. We apply abstract interpretation to a program that we derive from the given trace. If the program contains a loop, we are guaranteed to obtain a loop invariant. We call an SMT solver only in the case where the abstract interpretation returns an indefinite answer. That is, the idea is to use abstract interpretation and an SMT solver in tandem. An experimental evaluation in the setting of trace abstraction indicates the practical potential of this idea.", "num_citations": "3\n", "authors": ["274"]}
{"title": "Refinement with exceptions\n", "abstract": " Counterexample-guided abstraction refinement (CEGAR) was successfully applied to verify sequential programs. We give a CEGAR scheme for verifying concurrent programs with threads.", "num_citations": "3\n", "authors": ["274"]}
{"title": "Set-based error diagnosis of concurrent constraint programs\n", "abstract": " We present an automated method for the static prediction of the runtime errordeadlock or failure'in concurrent constraint programs. Operationally, the method is based on a new set-based analysis of reactive logic programs which computes an approximation of the greatest-model semantics. Semantically, the method is based on the connection between the inevitability ofdeadlock or failure'in concurrent constraint programs, nite failure in logic programming and the greatest-model semantics over in nite trees.", "num_citations": "3\n", "authors": ["274"]}
{"title": "Situated simplification\n", "abstract": " Testing satisfaction of guards is the essential operation of concurrent constraint programming (CCP) systems. We present and prove correct, for the first time, an incremental algorithm for the simultaneous tests of entailment and disentailment of rational tree constraints to be used in CCP systems with deep guards (e.g., in AKL or in Oz). The algorithm is presented as the simplification of the constraints which form the (possibly deep) guards and which are situated at different nodes in a tree (of arbitrary depth). The nodes correspond to local computation spaces. In this algorithm, a variable may have multiple bindings (which each represent a constraint on that same variable in a different node). These may be realized in various ways. We give a simple fixed-point algorithm and use it for proving that the tests implemented by another, practical algorithm are correct and complete for entailment and disentailment. We\u00a0\u2026", "num_citations": "3\n", "authors": ["274"]}
{"title": "Equational and membership constraints for infinite trees\n", "abstract": " We present a new constraint system with equational and membership constraints over infinite trees. It provides for complete and correct satisfiability and entailment tests and is therefore suitable for the use in concurrent constraint programming systems which are based on cyclic data structures.             Our set defining devices are greatest fixpoint solutions of regular systems of equations with a deterministic form of union. As the main technical particularity of the algorithms we present a novel memorization technique. We believe that both satisfiability and entailment tests can be implemented in an efficient and incremental manner.", "num_citations": "3\n", "authors": ["274"]}
{"title": "But does it really do that? Using formal analysis to ensure desirable ACT-R model behaviour.\n", "abstract": " Cognitive modelling uses computer models to investigate psychological theories. To conclude from executions of a cognitive model to the theory, the model needs to be a correct implementation of the theory since a defective cognitive model may yield wrong statistical figures. We consider three common reasons for a model to be incorrect wrt. a theory: situations which unintentionally do not enable any production rule, rules which erroneously construct undesired declarative knowledge, and wrongly chosen architecture parameters. Defects of these kinds are hard to detect since repeated execution and observation of the model does not guarantee to uncover these defects. In this work, we give formal definitions of the three kinds of defects in terms of an existing abstract formal semantics of the hybrid architecture ACT-R. We demonstrate the application of formal analysis techniques to ACT-R models to reliably detect the considered defects and to thereby increase the confidence that the model behaves according to the psychological theory.", "num_citations": "2\n", "authors": ["274"]}
{"title": "System testing and program verification\n", "abstract": " The effectiveness of black-box system testing can be increased by automatic program verification techniques. For example, the redundancy of a test case can be detected by static analysis; the analysis must be applied to a program in the `whitebox' layer of the system under test (e.g., in the setting of GUI testing, to the program which defines the event handlers). We will investigate the question of how automatic program verification techniques can be used to reduce the cost of testing and at the same time provide a guarantee for test coverage.", "num_citations": "2\n", "authors": ["274"]}
{"title": "Introducing Recurrence in Self-Stabilization?\n", "abstract": " CiteSeerX \u2014 Introducing Recurrence in Self-Stabilization? Documents Authors Tables Log in Sign up MetaCart DMCA Donate CiteSeerX logo Documents: Advanced Search Include Citations Authors: Advanced Search Include Citations Tables: DMCA Introducing Recurrence in Self-Stabilization? (2014) Cached Download as a PDF Download Links [www.avacs.org] Save to List Add to Collection Correct Errors Monitor Changes by Oday Jubran , Oliver Theel , Bernd Becker , Werner Damm , Bernd Finkbeiner , Andreas Podelski , Oday Jubran , Oliver Theel Summary Citations Active Bibliography Co-citation Clustered Documents Version History Share Facebook Twitter Reddit Bibsonomy OpenURL Abstract Copyright c \u00a9 July 2014 by the author(s) Powered by: Apache Solr About CiteSeerX Submit and Index Documents Privacy Policy Help Data Source Contact Us Developed at and hosted by The College of Sciences \u2026", "num_citations": "2\n", "authors": ["274"]}
{"title": "Verified Software: Theories, Tools, Experiments: 4th International Conference, VSTTE 2012, Philadelphia, PA, USA, January 28-29, 2012 Proceedings\n", "abstract": " This volume contains the proceedings of the 4th International Conference on Verified Software: Theories, Tools, and Experiments, VSTTE 2012, held in Philadelphia, PA, USA, in January 2012. The 20 revised full papers presented together with 2 invited talks and 2 tutorials were carefully revised and selected from 54 initial submissions for inclusion in the book. The goal of the VSTTE conference is to advance the state of the art through the interaction of theory development, tool evolution, and experimental validation. The papers address topics such as: specification and verification techniques, tool support for specification languages, tool for various design methodologies, tool integration and plug-ins, automation in formal verification, tool comparisons and benchmark repositories, combination of tools and techniques, customizing tools for particular applications, challenge problems, refinement methodologies, requirements modeling, specification languages, specification/verification case-studies, software design methods, and program logic.", "num_citations": "2\n", "authors": ["274"]}
{"title": "A Mode Change Protocol for Distributed Real-Time Systems\n", "abstract": " ATRs (AVACS Technical Reports) are freely downloadable from www. avacs. org Copyright c\u00a9 February 2007 by the author (s)", "num_citations": "2\n", "authors": ["274"]}
{"title": "Compositional termination analysis of symbolic forward analysis\n", "abstract": " Existing model checking tools for infinite state systems, such as UPPAAL, HYTECH and KRONOS, use symbolic forward analysis, a possibly nonterminating procedure. We give termination criteria that allow us to reason compositionally about systems defined with asynchronous parallel composition; we can prove the termination of symbolic forward analysis for a composed system from the syntactic conditions satisfied by the component systems.               Our results apply to nonlinear hybrid systems; in particular to rectangular hybrid systems, timed automata and o-minimal systems. In the case of integer-valued systems we give negative results: forward analysis is not well-suited for this class of infinite-state systems.", "num_citations": "2\n", "authors": ["274"]}
{"title": "Constraint database models characterizing timed bisimilarity\n", "abstract": " The problem of deciding timed bisimilarity has received increasing attention; it is important for verification of timed systems. Using a characterization of timed bisimilarity in terms of models of constraint databases, we present to our knowledge, the first local, symbolic algorithm for deciding timed bisimilarity; previous algorithms were based on a finite, but prohibitively large, abstraction (the region graph or the full backward stable graph). Our algorithm uses XSB-style tabling with constraints. Our methodology is more general than those followed in the previous approaches in the sense that our algorithm can be used to decide whether two timed systems are alternating timed bisimilar.", "num_citations": "2\n", "authors": ["274"]}
{"title": "Model checking infinite-state systems in CLP\n", "abstract": " The verification of safety and liveness properties for infinite-state systems is an important research problem. Can the well-established concepts and the existing technology for programming over constraints as first-class data structures contribute to this research? The work reported in this paper is a starting point for the experimental evaluation of constraint logic programming as a conceptual basis and practical implementation platform for model checking. We have implemented an automated verification method in CLP using real and boolean constraints. We have used the method on a number of infinite-state systems that model concurrent programs using integers or buffers. The basis of the correctness of our implementation is a formal connection between CLP programs and the formalism used for specifying concurrent systems.", "num_citations": "2\n", "authors": ["274"]}
{"title": "Widen, narrow and relax\n", "abstract": " We apply results from linear programming to show that the relaxation of model checking over integers to reals is accurate, ie yields a full test of temporal properties, for a large class of concurrent systems. We define abstractions similar to widening and narrowing that accelerate least and greatest fixpoint computations in model checking over integers or reals. We show that these abstractions are accurate in the same sense. Preliminary experimental results (eg safety for the ticket algorithm, liveness of a parameterized elevator program) indicate the potential usefulness of our abstraction techniques.", "num_citations": "2\n", "authors": ["274"]}
{"title": "Different Maps for Different Uses. A Program Transformation for Intermediate Verification Languages\n", "abstract": " In theorem prover or SMT solver based verification, the program to be verified is often given in an intermediate verification language such as Boogie, Why, or CHC. This setting raises new challenges. We investigate a preprocessing step which takes the similar role that alias analysis plays in verification, except that now, a (mathematical) map is used to model the memory or a data object of type array. We present a program transformation that takes a program P to an equivalent program P' such that, by verifying P' instead of P, we can reduce the burden of the exponential explosion in the number of case splits. Here, the case splits are according to whether two statements using the same map variable are independent or not; if they are independent, we might as well employ two different map variables and thus remove the need for a case split (this is the idea behind the program transformation). We have implemented the program transformation and show that, in an ideal case, we can avoid the exponential explosion.", "num_citations": "1\n", "authors": ["274"]}
{"title": "Temporal planning as refinement-based model checking: Proofs and additional descriptions\n", "abstract": " Planning as model checking based on source-to-source compilations has found increasing attention. Previously proposed approaches for temporal and hybrid planning are based on static translations, in the sense that the resulting model checking problems are uniquely defined by the given input planning problems. As a drawback, the translations can become too large to be efficiently solvable. In this paper, we address propositional temporal planning, lifting static translations to a more flexible framework. Our framework is based on a refinement cycle that allows for adaptively computing suitable translations of increasing size. Our experiments on temporal IPC domains show that the resulting translations to timed automata often become succinct, resulting in promising performance when applied with the directed model checker MCTA.", "num_citations": "1\n", "authors": ["274"]}
{"title": "A Tree-Based Approach to Data Flow Proofs\n", "abstract": " In this paper, we investigate the theoretical foundation for the cost/precision trade-off of data flow graphs for verification. We show that one can use the theory of tree automata in order to characterize the loss of precision inherent in the abstraction of a program by a data flow graph. We also show that one can transfer a result of Oh et al. and characterize the power of the proof system of data flow proofs (through a restriction on the assertion language in Floyd-Hoare proofs).", "num_citations": "1\n", "authors": ["274"]}
{"title": "A Logical Approach to Generating Test Plans\n", "abstract": " During the execution of a test plan, a test manager may decide to drop a test case if its result can be inferred from already executed test cases. We show that it is possible to automatically generate a test plan to exploit the potential to justifiably drop a test case and thus reduce the number of test cases. Our approach uses Boolean formulas to model the mutual dependencies between test results. The algorithm to generate a test plan comes with the formal guarantee of optimality with regards to the inference of the result of a test case from already executed test cases.", "num_citations": "1\n", "authors": ["274"]}
{"title": "Using the requirements specification to infer the implicit test status of requirements\n", "abstract": " We investigate a method to infer the implicit test status of requirements and thus increase the number of requirements for which the test status is known. The general idea is to improve the data set for measuring the maturity of the system in the current release. The inference is based on the structuring mechanisms (hierarchy, types) which are typically used to document the (natural language) requirements specification. We present a case study in the context of the development process for Mercedes-Benz passenger cars at Daimler AG. The results of the case study indicate the usefulness of the structuring mechanisms in the requirements specification as the basis for the inference. In particular, the number of requirements for which the status is known could be increased by almost a third.", "num_citations": "1\n", "authors": ["274"]}
{"title": "Fairness for infinitary control\n", "abstract": " In 1988, Olderog and Apt developed a fair scheduler for a system with finitely many processes based on the concept of explicit scheduling. In 2010, Hoenicke, Olderog, and Podelski extended the fair scheduler from static to dynamic control. In systems with dynamic control, processes can be created dynamically. Thus, the overall number of processes can be infinite, but the number of created processes is finite at each step of an execution of the system. In this paper we extend the fair scheduler to infinitary control. In systems with infinitary control, the number of created processes can be infinite. The fair scheduler for infinitary control is perhaps interesting for its apparent unfairness: instead of treating all processes equal, the scheduler discriminates each process against finitely many other processes. However, it also privileges each process against infinitely many other processes (in fact, all but finitely many).", "num_citations": "1\n", "authors": ["274"]}
{"title": "Automata as proofs\n", "abstract": " A recent approach to the verification of programs constructs a correctness proof in the form of a finite automaton. The automaton recognizes a set of traces. Here, a trace is any sequence of statements (not necessarily feasible and not necessarily on a path in the control flow graph of the program). A trace can be formalized as a word over the alphabet of statements. A trace can also be viewed as as special case of a program. Applying static analysis or a symbolic method (e.g., SMT solving with interpolant generation) to a single trace \u03c4, a correctness proof for the trace \u03c4 can be obtained in the form of a sequence of consecutive Hoare triples (or, phrased differently, an inductive sequence of assertions). We can construct an automaton that contains a transition $q_{\\varphi } \\stackrel{a}{\\longrightarrow} q_{\\varphi '}$ for each Hoare triple {\u03d5}a{\u03d5\u2032} in the correctness proof for the trace \u03c4. The automaton accepts the\u00a0\u2026", "num_citations": "1\n", "authors": ["274"]}
{"title": "Integrating incremental flow pipes into a symbolic model checker for hybrid systems\n", "abstract": " We describe an approach to integrate incremental ow pipe computation into a fully symbolic backward model checker for hybrid systems. Our method combines the advantages of symbolic state set representation, such as the ability to deal with large numbers of boolean variables, with an effcient way to handle continuous ows de ned by linear differential equations, possibly including bounded disturbances.", "num_citations": "1\n", "authors": ["274"]}
{"title": "Directed model checking with distance-preserving abstractions\n", "abstract": " Directed Model Checking with Distance-Preserving Abstractions Page 1 Directed Model Checking with Distance-Preserving Abstractions Bernd Finkbeiner Universit\u00e4t des Saarlandes joint work with Klaus Dr\u00e4ger and Andreas Podelski Page 2 2 Model Checking \u25aa Verification by exhaustive state space exploration Fundamental complexity-theoretic barrier State space is exponential in number of components \u25aa Error detection by search Hope despite state space explosion A good search strategy is likely to explore only a small portion of the state space Page 3 3 Search Strategies \u25aa Standard Model Checking Depth-first search Breadth-first search \u25aa Directed Model Checking Best-first search A* h h g Page 4 4 Heuristics \u25aa User-provided hints \u25aa Pattern databases \u25aa Property-specific heuristics \u25aa Structural heuristics \u25aa Hamming Distance \u25aa FSM heuristic interactive automatic Page 5 5 User-Provided Hints Example: Biphase Mark -\u2026", "num_citations": "1\n", "authors": ["274"]}
{"title": "Introduction to the special issue on Verification and Computational Logic\n", "abstract": " The past decade has seen dramatic growth in the application of model checking techniques to the validation and verification of correctness properties of hardware, and more recently software systems. Recently, there has been increasing interest in applying logic programming techniques to model checking in particular and verification in general. For example, table-based logic programming can be used as an efficient means of performing explicit model checking. Other research has successfully exploited set-based logic program analysis, constraint logic programming, and logic program transformation techniques to verify systems.", "num_citations": "1\n", "authors": ["274"]}
{"title": "An algebraic framework for abstract model checking\n", "abstract": " Symbolic forward analysis is a semi-algorithm that in many cases solves the model checking problem for infinite state systems in practice. This semi-algorithm is implemented in many practical model checking tools like UPPAAL [BLL+96], KRONOS [DT98] and HYTECH [HHWT97]. In most practical experiments, termination of symbolic forward analysis is achieved by employing abstractions resulting in an abstract symbolic forward analysis. This paper presents a unified algebraic framework for deriving and reasoning about abstract symbolic forward analysis procedures for a large class of infinite state systems with variables ranging over a numeric domain. The framework is obtained by lifting notions from classical algebraic theory of automata to constraints representing sets of states. Our framework provides sufficient conditions under which the derived abstract symbolic forward analysis procedure is always\u00a0\u2026", "num_citations": "1\n", "authors": ["274"]}
{"title": "Accurate widenings and boundedness properties of timed systems\n", "abstract": " We propose a symbolic model checking procedure for timed systems that is based on operations on constraints. To accelerate the termination of the model checking procedure, we define history-dependent widening operators, again in terms of constraint-based operations. We show that these widenings are accurate, i.e., they don\u2019t lose precision even with respect to the test of boundedness properties.", "num_citations": "1\n", "authors": ["274"]}
{"title": "A detailed algorithm testing guards over feature trees\n", "abstract": " We give the detailed formulation of an algorithm testing guards over feature trees. Such an algorithm is needed in constraint logic programming with entailment-based coroutining and in concurrent constraint programming; feature-tree constraint systems model extensible record descriptions (for example, in LIFE). We call this algorithm \u201cBeauty-and-Beast\u201d algorithm because it uses, for each variable X and for each guard test being suspended on X, a special-purpose data structure (the \u201cbeast\u201d) which encodes the data relevant for that guard test (essentially, a unifier). A variable X has a multiple-binding list where each of its bindings to a beast is indexed by the particular guard test. This is how we achieve that the algorithm is incremental when it is applied for repeated resumptions of suspended tests. Its online time complexity is almost-linear (which is the same as for the best existing offline algorithms for the\u00a0\u2026", "num_citations": "1\n", "authors": ["274"]}