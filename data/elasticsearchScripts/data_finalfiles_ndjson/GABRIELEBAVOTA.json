{"title": "Mining unstructured data in software repositories: Current and future trends\n", "abstract": " The amount of unstructured data available to software engineering researchers in versioning systems, issue trackers, achieved communications, and many other repositories is continuously growing over time. The mining of such data represents an unprecedented opportunity for researchers to investigate new research questions and to build a new generation of recommender systems supporting development and maintenance activities. This paper describes works on the application of Mining Unstructured Data (MUD) in software engineering. The paper briefly reviews the types of unstructured data available to researchers providing pointers to basic mining techniques to exploit them. Then, an overview of the existing applications of MUD in software engineering is provided with a specific focus on textual data present in software repositories and code components. The paper also discusses perils the \"miner\" should\u00a0\u2026", "num_citations": "53\n", "authors": ["2285"]}
{"title": "Improving code: The (mis) perception of quality metrics\n", "abstract": " Code quality metrics are widely used to identify design flaws (e.g., code smells) as well as to act as fitness functions for refactoring recommenders. Both these applications imply a strong assumption: quality metrics are able to assess code quality as perceived by developers. Indeed, code smell detectors and refactoring recommenders should be able to identify design flaws/recommend refactorings that are meaningful from the developer's point-of-view. While such an assumption might look reasonable, there is limited empirical evidence supporting it. We aim at bridging this gap by empirically investigating whether quality metrics are able to capture code quality improvement as perceived by developers. While previous studies surveyed developers to investigate whether metrics align with their perception of code quality, we mine commits in which developers clearly state in the commit message their aim of improving\u00a0\u2026", "num_citations": "46\n", "authors": ["2285"]}
{"title": "A large-scale empirical study on code-comment inconsistencies\n", "abstract": " Code comments are a primary means to document source code. Keeping comments up-to-date during code change activities requires substantial time and attention. For this reason, researchers have proposed methods to detect code-comment inconsistencies (i.e., comments that are not kept in sync with the code they document) and studies have been conducted to investigate this phenomenon. However, these studies were performed at a small scale, relying on quantitative analysis, thus limiting the empirical knowledge about code-comment inconsistencies. We present the largest study at date investigating how code and comments co-evolve. The study has been performed by mining 1.3 Billion AST-level changes from the complete history of 1,500 systems. Moreover, we manually analyzed 500 commits to define a taxonomy of code-comment inconsistencies fixed by developers. Our analysis discloses the extent\u00a0\u2026", "num_citations": "35\n", "authors": ["2285"]}
{"title": "On the impact of refactoring operations on code naturalness\n", "abstract": " Recent studies have demonstrated that software is natural, that is, its source code is highly repetitive and predictable like human languages. Also, previous studies suggested the existence of a relationship between code quality and its naturalness, presenting empirical evidence showing that buggy code is \u201cless natural\u201d than non-buggy code. We conjecture that this qualitynaturalness relationship could be exploited to support refactoring activities (e.g., to locate source code areas in need of refactoring). We perform a first step in this direction by analyzing whether refactoring can improve the naturalness of code. We use state-of-the-art tools to mine a large dataset of refactoring operations performed in open source systems. Then, we investigate the impact of different types of refactoring operations on the naturalness of the impacted code. We found that (i) code refactoring does not necessarily increase the naturalness\u00a0\u2026", "num_citations": "15\n", "authors": ["2285"]}
{"title": "On the uniqueness of code redundancies\n", "abstract": " Code redundancy widely occurs in software projects. Researchers have investigated the existence, causes, and impacts of code redundancy, showing that it can be put to good use, for example in the context of code completion. When analyzing source code redundancy, previous studies considered software projects as sequences of tokens, neglecting the role of the syntactic structures enforced by programming languages. However, differences in the redundancy of such structures may jeopardize the performance of applications leveraging code redundancy. We present a study of the redundancy of several types of code constructs in a large-scale dataset of active Java projects mined from GitHub, unveiling that redundancy is not uniform and mainly resides in specific code constructs. We further investigate the implications of the locality of redundancy by analyzing the performance of language models when applied\u00a0\u2026", "num_citations": "15\n", "authors": ["2285"]}
{"title": "Knowledge transfer in modern code review\n", "abstract": " Knowledge transfer is one of the main goals of modern code review, as shown by several studies that surveyed and interviewed developers. While knowledge transfer is a clear expectation of the code review process, there are no analytical studies using data mined from software repositories to assess the effectiveness of code review in\" training\" developers and improve their skills over time. We present a mining-based study investigating how and whether the code review process helps developers to improve their contributions to open source projects over time. We analyze 32,062 peer-reviewed pull requests (PRs) made across 4,981 GitHub repositories by 728 developers who created their GitHub account in 2015. We assume that PRs performed in the past by a developer D that have been subject to a code review process have\" transferred knowledge\" to D. Then, we verify if over time (ie, when more and more\u00a0\u2026", "num_citations": "10\n", "authors": ["2285"]}
{"title": "An annotation-based API for supporting runtime code annotation reading\n", "abstract": " Code annotations are the core of the main APIs and frameworks for enterprise development, and are widely used on several applications. However, despite these APIs and frameworks made advanced uses of annotations, the language API for annotation reading is far from their needs. In particular, annotation reading is still a relatively complex task, that can consume a lot of development time and that can couple the framework internal structure to its annotations. This paper proposes an annotation-based API to retrieve metadata from code annotations and populate an instance with meta-information ready to be used by the framework. The proposed API is based on best practices and approaches for metadata definition documented on patterns, and has been implemented by a framework named Esfinge Metadata. We evaluated the approach by refactoring an existing framework to use it through Esfinge Metadata\u00a0\u2026", "num_citations": "9\n", "authors": ["2285"]}
{"title": "Using structural and semantic information to support software refactoring\n", "abstract": " In the software life cycle the internal structure of the system undergoes continuous modifications. These changes push away the source code from its original design, often reducing its quality. In such cases refactoring techniques can be applied to improve the design quality of the system. Approaches existing in literature mainly exploit structural relationships present in the source code, e.g., method calls, to support the software engineer in identifying refactoring solutions. However, also semantic information is embedded in the source code by the developers, e.g., the terms used in the comments. This research investigates about the usefulness of combining structural and semantic information to support software refactoring.", "num_citations": "8\n", "authors": ["2285"]}
{"title": "Automated identification of on-hold self-admitted technical debt\n", "abstract": " Modern software is developed under considerable time pressure, which implies that developers more often than not have to resort to compromises when it comes to code that is well written and code that just does the job. This has led over the past decades to the concept of \u201ctechnical debt\u201d, a short-term hack that potentially generates long-term maintenance problems. Self-admitted technical debt (SATD) is a particular form of technical debt: developers consciously perform the hack but also document it in the code by adding comments as a reminder (or as an admission of guilt). We focus on a specific type of SATD, namely \u201cOn-hold\u201d SATD, in which developers document in their comments the need to halt an implementation task due to conditions outside of their scope of work (e.g., an open issue must be closed before a function can be implemented).We present an approach, based on regular expressions and\u00a0\u2026", "num_citations": "7\n", "authors": ["2285"]}
{"title": "An empirical study of quick remedy commits\n", "abstract": " Software systems are continuously modified to implement new features, to fix bugs, and to improve quality attributes. Most of these activities are not atomic changes, but rather the result of several related changes affecting different parts of the code. For this reason, it may happen that developers omit some of the needed changes and, as a consequence, leave a task partially unfinished, introduce technical debt or, in the worst case scenario, inject bugs. Knowing the changes that are mistakenly omitted by developers can help in designing recommender systems able to automatically identify risky situations in which, for example, the developer is likely to be pushing an incomplete change to the software repository.", "num_citations": "7\n", "authors": ["2285"]}
{"title": "On the quality of identifiers in test code\n", "abstract": " Meaningful, expressive identifiers in source code can enhance the readability and reduce comprehension efforts. Over the past years, researchers have devoted considerable effort to understanding and improving the naming quality of identifiers in source code. However, little attention has been given to test code, an important resource during program comprehension activities. To better grasp identifier quality in test code, we conducted a survey involving manually written and automatically generated test cases from ten open source software projects. The survey results indicate that test cases contain low quality identifiers, including the manually written ones, and that the quality of identifiers is lower in test code than in production code. We also investigated the use of three state-of-the-art rename refactoring recommenders for improving test code identifiers. The analysis highlights their limitations when applied to test\u00a0\u2026", "num_citations": "7\n", "authors": ["2285"]}
{"title": "Sampling projects in github for MSR studies\n", "abstract": " Almost every Mining Software Repositories (MSR) study requires, as first step, the selection of the subject software repositories. These repositories are usually collected from hosting services like GitHub using specific selection criteria dictated by the study goal. For example, a study related to licensing might be interested in selecting projects explicitly declaring a license. Once the selection criteria have been defined, utilities such as the GitHub APIs can be used to \"query\" the hosting service. However, researchers have to deal with usage limitations imposed by these APIs and a lack of required information. For example, the GitHub search APIs allow 30 requests per minute and, when searching repositories, only provide limited information (e.g., the number of commits in a repository is not included). To support researchers in sampling projects from GitHub, we present GHS (GitHub Search), a dataset containing 25\u00a0\u2026", "num_citations": "6\n", "authors": ["2285"]}
{"title": "RETICULA: Real-time code quality assessment\n", "abstract": " Code metrics can be used to assess the internal quality of software systems, and in particular their adherence to good design principles. While providing hints about code quality, metrics are difficult to interpret. Indeed, they take a code component as input and assess a quality attribute (e.g., code readability) by providing a number as output. However, it might be unclear for developers whether that value should be considered good or bad for the specific code at hand. We present RETICULA (REal TIme Code qUaLity Assessment), a plugin for the IntelliJ IDE to assist developers in perceiving code quality during software development. RETICULA compares the quality metrics for a project (or a single class) under development in the IDE with those of similar open source systems (classes) previously analyzed. With the visualized results, developers can gain insights about the quality of their code. A video illustrating the\u00a0\u2026", "num_citations": "6\n", "authors": ["2285"]}
{"title": "An empirical study on the usage of BERT models for code completion\n", "abstract": " Code completion is one of the main features of modern Integrated Development Environments (IDEs). Its objective is to speed up code writing by predicting the next code token(s) the developer is likely to write. Research in this area has substantially bolstered the predictive performance of these techniques. However, the support to developers is still limited to the prediction of the next few tokens to type. In this work, we take a step further in this direction by presenting a large-scale empirical study aimed at exploring the capabilities of state-of-the-art deep learning (DL) models in supporting code completion at different granularity levels, including single tokens, one or multiple entire statements, up to entire code blocks (e.g., the iterated block of a for loop). To this aim, we train and test several adapted variants of the recently proposed RoBERTa model, and evaluate its predictions from several perspectives, including: (i\u00a0\u2026", "num_citations": "5\n", "authors": ["2285"]}
{"title": "Shallow or deep? An empirical study on detecting vulnerabilities using deep learning\n", "abstract": " Deep learning (DL) techniques are on the rise in the software engineering research community. More and more approaches have been developed on top of DL models, also due to the unprecedented amount of software-related data that can be used to train these models. One of the recent applications of DL in the software engineering domain concerns the automatic detection of software vulnerabilities. While several DL models have been developed to approach this problem, there is still limited empirical evidence concerning their actual effectiveness especially when compared with shallow machine learning techniques. In this paper, we partially fill this gap by presenting a large-scale empirical study using three vulnerability datasets and five different source code representations (i.e., the format in which the code is provided to the classifiers to assess whether it is vulnerable or not) to compare the effectiveness of\u00a0\u2026", "num_citations": "3\n", "authors": ["2285"]}
{"title": "Simultaneous Refactoring and Regression Testing\n", "abstract": " Currently, refactoring and regression testing are treated independently by existing studies. However, software developers frequently switch between these two activities, using regression testing to identify unwanted behavior changes introduced while refactoring and applying refactoring on identified buggy code fragments. Our hypothesis is that the tools to support developers in these two tasks could transfer part of the knowledge extracted from the process of finding refactoring opportunities to identify relevant test cases, and vice-versa. We propose a simultasking, search-based algorithm that unifies the tasks of refactoring and regression testing, hence solving them simultaneously and enabling knowledge transfer between them. The salient feature of the proposed algorithm is a unified and generic solution representation scheme for both problems, which serves as a common platform for knowledge transfer\u00a0\u2026", "num_citations": "3\n", "authors": ["2285"]}
{"title": "PYREF: Refactoring Detection in Python Projects\n", "abstract": " Refactoring, the process of improving the internal code structure of a software system without altering its external behavior, is widely applied during software development. Understanding how developers refactor source code can help gain better understanding of the software development process and the relationship between various versions of a system. Refactoring detection tools have been developed for many popular programming languages, such as Java (e.g., REFACTORINGMINER and REF-FINDER) but, quite surprisingly, this is not the case for Python, a widely used programming language.Inspired by REFACTORING MINER, we present PYREF, a tool that automatically detects method-level refactoring operations in Python projects. We evaluated PYREF against a manually built oracle and compared it with a PYTHON-ADAPTED REFACTOR-INGMINER, which converts Python program to Java and\u00a0\u2026", "num_citations": "2\n", "authors": ["2285"]}
{"title": "Opinion Mining for Software Development: A Systematic Literature Review\n", "abstract": " Opinion mining, sometimes referred to as sentiment analysis, has gained increasing attention in software engineering (SE) studies. SE researchers have applied opinion mining techniques in various contexts, such as identifying developers\u2019 emotions expressed in code comments and extracting users\u2019 critics toward mobile apps. Given the large amount of relevant studies available, it can take considerable time for researchers and developers to figure out which approaches they can adopt in their own studies and what perils these approaches entail. We conducted a systematic literature review involving 185 papers. More specifically, we present (1) well-defined categories of opinion mining-related software development activities, (2) available opinion mining approaches, whether they are evaluated when adopted in other studies, and how their performance is compared, (3) available datasets for performance\u00a0\u2026", "num_citations": "1\n", "authors": ["2285"]}
{"title": "CI/CD Pipelines Evolution and Restructuring: A Qualitative and Quantitative Study\n", "abstract": " Continuous Integration and Delivery (CI/CD) pipelines entail the build process automation on dedicated machines, and have been demonstrated to produce several advantages including early defect discovery, increased productivity, and faster release cycles. The effectiveness of CI/CD may depend on the extent to which such pipelines are properly maintained to cope with the system and its underlying technology evolution, as well as to limit bad practices. This paper reports the results of a study combining a qualitative and quantitative evaluation on CI/CD pipeline restructuring actions. First, by manually analyzing and coding 615 pipeline configuration change commits, we have crafted a taxonomy of 34 CI/CD pipeline restructuring actions, either improving extra-functional properties or changing the pipeline's behavior. Based on such actions, we have developed a metric extractor for Travis-CI pipelines, which\u00a0\u2026", "num_citations": "1\n", "authors": ["2285"]}
{"title": "Does Refactoring Break Tests and to What Extent?\n", "abstract": " Refactoring as a process is aimed at improving the quality of a software system while preserving its external behavior. In practice, refactoring comes in the form of many specific and diverse refactoring operations, which have different scopes and thus a different potential impact on both the production and the test code. We present a large-scale quantitative study complemented by a qualitative analysis involving 615,196 test cases to understand how and to what extent different refactoring operations impact a system's test suites. Our findings show that while the vast majority of refactoring operations do not or very seldom induce test breaks, some specific refactoring types (e.g., \u201cRENAME Attribute\u201d and \u201cRENAME Class\u201d) have a higher chance of breaking test suites. Meanwhile, \u201cADD Parameter\u201d and \u201cCHANGE Return Type\u201d refactoring operations often require additional lines of changes to fix the test suite they break\u00a0\u2026", "num_citations": "1\n", "authors": ["2285"]}
{"title": "When and Why Your Code Starts to Smell Bad\u2014Additional Analyses\u2014\n", "abstract": " As explained in our paper, the main construct validity threat that could affect our results is related to the use of DECOR rules to detect smells. Indeed, our results can be affected by the presence of false positives and false negatives. Concerning false positives, Moha et al. reported a precision above 60% and a recall of 100% on Xerces 2.7. 0. Other than relying on their assessment, we have manually validated a statistically signifiant subset of the detected smells. Such a manual validation has been performed by two of the authors independently, and cases of disagreement were discussed. In total, 1,107 smells were validated, including 241 Blob instances, 317 CDSBP, 166 Complex Class, 65 Spaghetti Code, and 318 Functional Decomposition. The results of the manual validation indicated a mean precision of 73%, and specifically of 79% for Blob, 62% for CDSBP, 74% for Complex Class, 82% for Spaghetti Code, and 70% for Functional Decomposition. In this document we replicated the analysis performed in our paper to answer the two formulated research questions (RQ1 and RQ2) by just considering the smell-introducing commits (2,555) involving smell instances that have been manually validated as true positives (and thus, only those commits that we are sure introduced a smell in the systems). This analysis was needed to verify if the main findings of our paper are confirmed when just considering commits introducing smells that have been manually verified. In particular:\u2022 Table I reports the descriptive statistics of the number of commits needed by each smell type to affect code files\u2014RQ1.\u2022 Table II presents the descriptive statistics (mean and\u00a0\u2026", "num_citations": "1\n", "authors": ["2285"]}
{"title": "Taxonomy of security weaknesses in Java and Kotlin Android apps\n", "abstract": " Android is nowadays the most popular operating system in the world, not only in the realm of mobile devices, but also when considering desktop and laptop computers. Such a popularity makes it an attractive target for security attacks, also due to the sensitive information often manipulated by mobile apps. The latter are going through a transition in which the Android ecosystem is moving from the usage of Java as the official language for developing apps, to the adoption of Kotlin as the first choice supported by Google. While previous studies have partially studied security weaknesses affecting Java Android apps, there is no comprehensive empirical investigation studying software security weaknesses affecting Android apps considering (and comparing) the two main languages used for their development, namely Java and Kotlin. We present an empirical study in which we: (i) manually analyze 681 commits\u00a0\u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "AI-Driven Development Is Here: Should You Worry?\n", "abstract": " Artificial Intelligence Driven Development Environments (AIDEs) integrate the power of modern AI into IDEs like Visual Studio Code and JetBrains IntelliJ. By leveraging massive language models and the plethora of openly available source code, AIDEs promise to automate many of the obvious, routine tasks in programming. At the same time, AIDEs come with new challenges to think about, such as bias, legal compliance, security vulnerabilities, and their impact on learn programming.", "num_citations": "0\n", "authors": ["2285"]}
{"title": "Using Reinforcement Learning for Load Testing of Video Games\n", "abstract": " Different from what happens for most types of software systems, testing video games has largely remained a manual activity performed by human testers. This is mostly due to the continuous and intelligent user interaction video games require. Recently, reinforcement learning (RL) has been exploited to partially automate functional testing. RL enables training smart agents that can even achieve super-human performance in playing games, thus being suitable to explore them looking for bugs. We investigate the possibility of using RL for load testing video games. Indeed, the goal of game testing is not only to identify functional bugs, but also to examine the game's performance, such as its ability to avoid lags and keep a minimum number of frames per second (FPS) when high-demanding 3D scenes are shown on screen. We define a methodology employing RL to train an agent able to play the game as a human while also trying to identify areas of the game resulting in a drop of FPS. We demonstrate the feasibility of our approach on three games. Two of them are used as proof-of-concept, by injecting artificial performance bugs. The third one is an open-source 3D game that we load test using the trained agent showing its potential to identify areas of the game resulting in lower FPS.", "num_citations": "0\n", "authors": ["2285"]}
{"title": "Using Pre-Trained Models to Boost Code Review Automation\n", "abstract": " Code review is a practice widely adopted in open source and industrial projects. Given the non-negligible cost of such a process, researchers started investigating the possibility of automating specific code review tasks. We recently proposed Deep Learning (DL) models targeting the automation of two tasks: the first model takes as input a code submitted for review and implements in it changes likely to be recommended by a reviewer; the second takes as input the submitted code and a reviewer comment posted in natural language and automatically implements the change required by the reviewer. While the preliminary results we achieved are encouraging, both models had been tested in rather simple code review scenarios, substantially simplifying the targeted problem. This was also due to the choices we made when designing both the technique and the experiments. In this paper, we build on top of that work by demonstrating that a pre-trained Text-To-Text Transfer Transformer (T5) model can outperform previous DL models for automating code review tasks. Also, we conducted our experiments on a larger and more realistic (and challenging) dataset of code review activities.", "num_citations": "0\n", "authors": ["2285"]}
{"title": "Using Deep Learning to Generate Complete Log Statements\n", "abstract": " Logging is a practice widely adopted in several phases of the software lifecycle. For example, during software development log statements allow engineers to verify and debug the system by exposing fine-grained information of the running software. While the benefits of logging are undisputed, taking proper decisions about where to inject log statements, what information to log, and at which log level (e.g., error, warning) is crucial for the logging effectiveness. In this paper, we present LANCE (Log stAtemeNt reCommEnder), the first approach supporting developers in all these decisions. LANCE features a Text-To-Text-Transfer-Transformer (T5) model that has been trained on 6,894,456 Java methods. LANCE takes as input a Java method and injects in it a full log statement, including a human-comprehensible logging message and properly choosing the needed log level and the statement location. Our results show that LANCE is able to (i) properly identify the location in the code where to inject the statement in 65.9% of Java methods requiring it; (ii) selecting the proper log level in 66.2% of cases; and (iii) generate a completely correct log statement including a meaningful logging message in 15.2% of cases.", "num_citations": "0\n", "authors": ["2285"]}
{"title": "Quick remedy commits and their impact on mining software repositories\n", "abstract": " Most changes during software maintenance and evolution are not atomic changes, but rather the result of several related changes affecting different parts of the code. It may happen that developers omit needed changes, thus leaving a task partially unfinished, introducing technical debt or injecting bugs. We present a study investigating \u201cquick remedy commits\u201d performed by developers to implement changes omitted in previous commits. With quick remedy commits we refer to commits that (i) quickly follow a commit performed by the same developer, and (ii) aim at remedying issues introduced as the result of code changes omitted in the previous commit (e.g., fix references to code components that have been broken as a consequence of a rename refactoring) or simply improve the previously committed change (e.g., improve the name of a newly introduced variable). Through a manual analysis of 500 quick\u00a0\u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "Studying eventual connectivity issues in Android apps\n", "abstract": " Mobile apps have become indispensable for daily life, not only for individuals but also for companies/organizations that offer their services digitally. Inherited by the mobility of devices, there are no limitations regarding the locations or conditions in which apps are being used. For example, apps can be used where no internet connection is available. Therefore, offline-first is a highly desired quality of mobile apps. Accordingly, inappropriate handling of connectivity issues and miss-implementation of good practices lead to bugs and crashes occurrences that reduce the confidence of users on the apps\u2019 quality. In this paper, we present the first study on Eventual Connectivity (ECn) issues exhibited by Android apps, by manually inspecting 971 scenarios related to 50 open-source apps. We found 304 instances of ECn issues (6 issues per app, on average) that we organized in a taxonomy of 10 categories. We\u00a0\u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "How Software Refactoring Impacts Execution Time\n", "abstract": " Refactoring aims at improving the maintainability of source code without modifying its external behavior. Previous works proposed approaches to recommend refactoring solutions to software developers. The generation of the recommended solutions is guided by metrics acting as proxy for maintainability (e.g., number of code smells removed by the recommended solution). These approaches ignore the impact of the recommended refactorings on other non-functional requirements, such as performance, energy consumption, and so forth. Little is known about the impact of refactoring operations on non-functional requirements other than maintainability. We aim to fill this gap by presenting the largest study to date to investigate the impact of refactoring on software performance, in terms of execution time. We mined the change history of 20 systems that defined performance benchmarks in their repositories, with the\u00a0\u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "Why Do Developers Reject Refactorings in Open-Source Projects?\n", "abstract": " Refactoring operations are behavior-preserving changes aimed at improving source code quality. While refactoring is largely considered a good practice, refactoring proposals in pull requests are often rejected after the code review. Understanding the reasons behind the rejection of refactoring contributions can shed light on how such contributions can be improved, essentially benefiting software quality. This article reports a study in which we manually coded rejection reasons inferred from 330 refactoring-related pull requests from 207 open-source Java projects. We surveyed 267 developers to assess their perceived prevalence of these identified rejection reasons, further complementing the reasons. Our study resulted in a comprehensive taxonomy consisting of 26 refactoring-related rejection reasons and 21 process-related rejection reasons. The taxonomy, accompanied with representative examples and\u00a0\u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "FeaRS: Recommending Complete Android Method Implementations\n", "abstract": " Several techniques have been proposed in the literature to support code completion, showing excellent results in predicting the next few tokens a developer is likely to type given the current context. Only recently, approaches pushing the boundaries of code completion (e.g., by presenting entire code statements) have been proposed. In this line of research, we present FeaRS, a recommender system that, given the current code a developer is writing in the IDE, recommends the next complete method to be implemented. FeaRS has been deployed to learn \u201cimplementation patterns\u201d (i.e., groups of methods usually implemented within the same task) by continuously mining open-source Android projects. Such knowledge is leveraged to provide method recommendations when the code written by the developer in the IDE matches an \u201cimplementation pattern\u201d. Preliminary results of FeaRS\u2019 accuracy show its potential as\u00a0\u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "An Empirical Study on Code Comment Completion\n", "abstract": " Code comments play a prominent role in program comprehension activities. However, source code is not always documented and code and comments not always co-evolve. To deal with these issues, researchers have proposed techniques to automatically generate comments documenting a given code at hand. The most recent works in the area applied deep learning (DL) techniques to support such a task. Despite the achieved advances, the empirical evaluations of these approaches show that they are still far from a performance level that would make them valuable for developers. We tackle a simpler and related problem: Code comment completion. Instead of generating a comment for a given code from scratch, we investigate the extent to which state-of-the-art techniques can help developers in writing comments faster. We present a large-scale study in which we empirically assess how a simple n-gram model\u00a0\u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "An Adaptive Search Budget Allocation Approach for Search-Based Test Case Generation\n", "abstract": " Search-based techniques have been successfully used to automate test case generation. Such approaches allocate a fixed search budget to generate test cases aiming at maximizing code coverage. The search budget plays a crucial role; due to the hugeness of the search space, the higher the assigned budget, the higher the expected coverage. Code components have different structural properties that may affect the ability of search-based techniques to achieve a high coverage level. Thus, allocating a fixed search budget for all the components is not recommended and a component-specific search budget should be preferred. However, deciding the budget to assign to a given component is not a trivial task. In this article, we introduce Budget Optimization for Testing (BOT), an approach to adaptively allocate the search budget to the classes under test. BOT requires information about the branch coverage that will\u00a0\u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "Appreciation to Empirical Software Engineering reviewers of 2020\n", "abstract": " For helping us deliver timely decisions to our authors, the Editors-in-Chief and Publisher would like to thank the following individuals who contributed reviews between January 1, 2020 and December 31, 2020. We applaud your efforts and dedication to the community.", "num_citations": "0\n", "authors": ["2285"]}
{"title": "Characterizing leveraged stack overflow posts\n", "abstract": " Stack Overflow is the most popular question and answer website on computer programming with more than 2.5M users, 16M questions, and a new answer posted, on average, every five seconds. This wide availability of data led researchers to develop techniques to mine Stack Overflow posts. The aim is to find and recommend posts with information useful to developers. However, and not surprisingly, not every Stack Overflow post is useful from a developer's perspective. We empirically investigate what the characteristics of \"useful\" Stack Overflow posts are. The underlying assumption of our study is that posts that were used (referenced in the source code) in the past by developers are likely to be useful. We refer to these posts as leveraged posts. We study the characteristics of leveraged posts as opposed to the non-leveraged ones, focusing on community aspects (e.g., the reputation of the user who authored the\u00a0\u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "Turning the IDE into a self-confident programming assistant\n", "abstract": " Developers often require knowledge beyond the one they possess, which boils down to asking co-workers for help or consulting additional sources of information, such as Application Programming Interfaces (API) documentation, forums, and Q&A websites. However, it requires time and energy to formulate one\u2019s problem, peruse and process the results. We propose a novel approach that, given a context in the Integrated Development Environment (IDE), automatically retrieves pertinent discussions from Stack Overflow, evaluates their relevance using a multi-faceted ranking model, and, if a given confidence threshold is surpassed, notifies the developer. We have implemented our approach in PROMPTER, an Eclipse plug-in. PROMPTER was evaluated in two empirical studies. The first study was aimed at evaluatingPROMPTER\u2019s ranking model and involved 33 participants.", "num_citations": "0\n", "authors": ["2285"]}
{"title": "Using Structural and Semantic Information to Recommend Source Code Refactoring Solutions\n", "abstract": " Using Structural and Semantic Information to Recommend Source Code Refactoring Solutions IRIS nascondi/visualizza icone a destra nascondi/visualizza menu in alto Aiuto Sfoglia Scorri i prodotti per: Autore Titolo Riviste Serie Login IRIS IRIS Universit\u00e0 degli Studi del Molise Catalogo Ricerca 2 Contributo in Volume 2.1 Contributo in volume (Capitolo o Saggio) Using Structural and Semantic Information to Recommend Source Code Refactoring Solutions Italiano Italiano English Using Structural and Semantic Information to Recommend Source Code Refactoring Solutions / G. Bavota; A. De Lucia; A. Marcus; OLIVETO R. - (2014). Scheda breve Scheda completa Titolo: Using Structural and Semantic Information to Recommend Source Code Refactoring Solutions Autori: OLIVETO, Rocco mostra contributor esterni Data di pubblicazione: 2014 Handle: http://hdl.handle.net/11695/10371 ISBN: 978-3-642-45134-8 \u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "2021 IEEE 21st International Working Conference on Source Code Analysis and Manipulation (SCAM)| 978-1-6654-4897-0/21/$31.00\u00a9 2021 IEEE| DOI: 10.1109/SCAM52516. 2021.00039\n", "abstract": " Author Index IEEE.org Help Cart Jobs Board Create Account Toggle navigation IEEE Computer Society Digital Library Jobs Tech News Resource Center Press Room Advertising About Us IEEE IEEE Computer Society IEEE Computer Society Digital Library My Subscriptions Magazines Journals Conference Proceedings Institutional Subscriptions IEEE IEEE Computer Society More Jobs Tech News Resource Center Press Room Advertising About Us Cart All Advanced Search Conference Cover Image Download 1.Home 2.Proceedings 3.scam 2021 Author Index 2021, pp. 253-254, DOI Bookmark: 10.1109/SCAM52516.2021.00039 Keywords Authors Author Index,Abukar, Suada , 165,Adler, Felix , 120,Antoniol, Giuliano , 58,Atwi, Hassan , 136,Baldi, Pierre , 198,Barnett, Scott , 76,Bavota, Gabriele , 136,Baysal, Olga , 142,Bergel, Alexandre , 165,Berger, Bernhard J. , 30,Bergmans, Lodewijk , 47,Besz\u00e9des, \u00c1rp\u00e1d , 103, \u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "2021 IEEE International Conference on Software Maintenance and Evolution (ICSME)| 978-1-6654-2882-8/21/$31.00\u00a9 2021 IEEE| DOI: 10.1109/ICSME52107. 2021.00085\n", "abstract": " Presents an index of the authors whose articles are published in the conference proceedings record.", "num_citations": "0\n", "authors": ["2285"]}
{"title": "Identifying Method Friendships to Remove the Feature Envy Bad Smell (NIER Track) Rocco Oliveto\n", "abstract": " We propose a novel approach to identify Move Method refactoring opportunities and remove the Feature Envy bad smell from source code. The proposed approach analyzes both structural and conceptual relationships between methods and uses Relational Topic Models to identify sets of methods that share several responsabilities, ie,\u201cfriend methods\u201d. The analysis of method friendships of a given method can be used to pinpoint the target class (envied class) where the method should be moved in. The results of a preliminary empirical evaluation indicate that the proposed approach provides meaningful refactoring opportunities. Categories and Subject Descriptors", "num_citations": "0\n", "authors": ["2285"]}
{"title": "2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR)| 978-1-7281-8710-5/20/$31.00\u00a9 2021 IEEE| DOI: 10.1109/MSR52588. 2021.00090\n", "abstract": " Author Index Page 1 Author Index Abdalkareem, Rabe 500 Afroz, Sadia 46 Aggarwal, Deepti 18 Aghajani, Emad 560 Agrahari, Vartika 605 Alamin, Md Abdullah Al 46 Albonico, Michel 483 Alfadel, Mahmoud 254 Alghamdi, Mahfouth 460 Allamanis, Miltiadis 329 Aloise, Daniel 120 Alves Pereira, Juliana 471 Aniche, Maur\u00edcio 58, 143 Antal, G\u00e1bor 495 Autili, Marco 271 Azhari, Seyed Vahid 120 Badihi, Sahar 610 Bagrow, James P. 242 Bansal, Chetan 575 Barbosa, Caio 471 Baudry, Benoit 545 Bavota, Gabriele 108, 560 Baysal, Olga 283 Bezemer, Cor-Paul 520 Blockhaus, Paul 535 Bogart, Chris 621 Bogomolov, Egor 13 Bryksin, Timofey 13 Burgin, Noah 624 Cai, Haipeng 570 Calefato, Fabio 550 C\u00e2ndido, Jeanderson 143 Casari, Amanda 242 Cassee, Nathan 403 Chaniotaki, Alexandra-Maria 190 Chauhan, Jigyasa 85 Chernishev, George 266 Chimalakonda, Sridhar 605 Chinnappan, Katerina 300, 483 Ciborowska\u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "MSR 2021 Program Committee\n", "abstract": " Program Committee Page 1 MSR 2021 Program Committee MSR Technical Papers Program Co-Chairs Kelly Blincoe, University of Auckland, New Zealand Mei Nagappan, University of Waterloo, Canada Program Committee Members Rabe Abdalkareem, Queens University, Kingston, Canada Daniel Alencar Da Costa, University of Otago, New Zealand Vescan Andreea, Babes-Bolyai University, Romania Maur\u00edcio Aniche, Delft University of Technology, Netherlands Francesca Arcelli Fontana, University of Milano \u2013 Bicocca, Italy Hamid Bagheri, University of Nebraska-Lincoln Chetan Bansal, Microsoft Research, USA Earl T. Barr, University College London, UK Gabriele Bavota, Software Institute, USI Universit\u00e0 della Svizzera italiana, Switzerland Olga Baysal, Carleton University, Canada Moritz Beller, Facebook, Inc., USA Christian Bird, Microsoft Research, USA Timofey Bryksin, JetBrains Research, Saint Petersburg \u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "Gao, Jianhua 230 Ge, Fan 196 Gong, Siyi 71 Graciotto Silva, Marco Aur\u00e9lio 444\n", "abstract": " Author Index Page 1 Author Index Al Madi, Naser 172 AlOmar, Eman Abdullah 335 Anderson, Zachary JC 358 Aniche, Maur\u00edcio 25 Aniche, Mauricio 490 Avgeriou, Paris 311 Bansal, Aakash 253 Bavota, Gabriele 276 Beigelbeck, Aaron 490 Bissyand\u00e9, Tegawend\u00e9 F. 36 Boerstra, Evelien 358 Bond, Raymond 300 Brito, Rodrigo 265 Cao, Junming 207 Cates, Roee 118 Ceccato, Mariano 127 Chen, Jiajun 335 Chen, Jianqiang 184 Chen, Songqiang 369 Chen, Xu 369 Cito, J\u00fcrgen 490 C. Murphy, Gail 13 Contro, Filippo 127 Counsell, Steve 323 Crosara, Marco 127 Dalla Preda, Mila 127 De Lucia, Andrea 396 Di Nucci, Dario 396 Endo, Andre Takeshi 444 Fan, Guisheng 230 Fard, Fatemeh H. 411 Feitelson, Dror G. 106, 118, 347 Gao, Hui 149 Gao, Jianhua 230 Ge, Fan 196 Gong, Siyi 71 Graciotto Silva, Marco Aur\u00e9lio 444 Grundy, John 422 Gu, Xiaodong 1 Han, Xiaofeng 323 Haque, Sakib 253 Hayashi, Shinpei 495 \u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)| 978-1-6654-0296-5/20/$31.00\u00a9 2021 IEEE| DOI: 10.1109/ICSE43902. 2021.00152\n", "abstract": " Author Index Page 1 Author Index Abualhaija, Sallam 1485 Adams, Bram 1033 Aghajani, Emad 138 Aguirre, Nazareno 637, 1135, 1223 Ahmed, Iftekhar 736, 1423 Alhamed, Mohammed 1 Alhwikem, Faisal 835 Almanee, Sumaya 1347 Alshammari, Abdulrahman 1572 Alsuhaibani, Reem 587 An, Ju 613 An, Seungmin 13 Apel, Sven 524, 1059, 1072 Arora, Chetan 1485 Arzt, Steven 1098 Atlidakis, Vaggelis 1535 Bacchelli, Alberto 499 Bagheri, Hamid 637, 1135 Bagherzadeh, Mehdi 238 Bajammal, Mohammad 1610 Baltes, Sebastian 1273 Baluta, Teodora 312 Bangert, Julian 1360 Bao, Qinkun 797 Bardin, S\u00e9bastien 1236 Bartel, Alexandre 1398 Bavota, Gabriele 138, 163, 336, 436 Bell, Jonathan 1572 Berger, Thorsten 1658 Bernal-C\u00e1rdenas, Carlos 957 Bertino, Elisa 1671 Beschastnikh, Ivan 372 Bianculli, Domenico 847 Bichler, Stefan 1298 Bissyand\u00e9, Tegawend\u00e9 F. 1398 Bonichon, Richard 1236 Borzacchiello, \u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "New Ideas and Emerging Results (NIER) Program Committee of ICSE 2020\n", "abstract": " Program Committee of ICSE-NIER 2020 IEEE.org Help Cart Jobs Board Create Account Toggle navigation IEEE Computer Society Digital Library Jobs Tech News Resource Center Press Room Advertising About Us IEEE IEEE Computer Society IEEE Computer Society Digital Library My Subscriptions Magazines Journals Conference Proceedings Institutional Subscriptions IEEE IEEE Computer Society More Jobs Tech News Resource Center Press Room Advertising About Us Cart All Advanced Search Conference Cover Image Download 1.Home 2.Proceedings 3.icse-nier 2020 Program Committee of ICSE-NIER 2020 2020, pp. 13-13, DOI Bookmark: Keywords Authors Abstract Provides a listing of current committee members and society officers. New Ideas and Emerging Results (NIER) , Program Committee of ICSE 2020 , ,Willem Visser, ,Stellenbosch University, ,Shin Yoo, ,Korea Advanced Institute of Science and \u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "Research Track\n", "abstract": " List of Names - Program Committee Page 1 Program Committee Research Track Kelly Blincoe, University of Auckland, New Zealand (Co-Chair) Zhenchang Xing, Australian National University, Australia (Co-Chair) Giuliano Antoniol, Ecole Polytechnique de Montr\u00e9al, Canada Francesca Arcelli Fontana, University of Milano - Bicocca, Italy Venera Arnaoudova, Washington State University, USA Hamid Bagheri, University of California, Irvine, USA Maria Teresa Baldassarre, University of Bari, Italy Lingfeng Bao, Zhejiang University, China Gabriele Bavota, Universit\u00e0 della Svizzera italiana (USI), Switzerland Olga Baysal, Carleton University, Canada \u00c1rp\u00e1d Besz\u00e9des, University of Szeged, Hungary Dave Binkley, Loyola University Maryland, USA Tegawend\u00e9 F. Bissyand\u00e9, SnT, University of Luxembourg, Luxembourg Fernando Castor, Universidade Federal de Pernambuco, Brazil Gemma Catolino, Delft University of \u2026", "num_citations": "0\n", "authors": ["2285"]}
{"title": "Towards Automated Tools for Detecting Test Smells: An Empirical Investigation into the Nature of Test Smells\n", "abstract": " Test smells have been defined as poorly designed tests and, as reported by recent empirical studies, their presence may negatively affect comprehension and consequently maintenance of test suites. Despite this, there are no available automated tools to support identification and removal of test smells. In this paper, we firstly investigate developers\u2019 perception of test smells in a study with 19 developers. The results show that developers generally do not recognize (potentially harmful) test smells, highlighting that automated tools for identifying such smells are much needed. However, to build effective tools, deeper insights into the test smells phenomenon are required. To this aim, we conducted a large-scale empirical investigation aimed at analyzing (i) when test smells occur in source code,(ii) what their survivability is, and (iii) whether their presence is associated with the presence of design problems in production code (code smells). The results indicate that test smells are usually introduced when the corresponding test code is committed in the repository for the first time, and they tend to remain in a system for a long time. Moreover, we found various unexpected relationships between test and code smells. Finally, we show how the results of this study can be used to build effective automated tools for test smell detection and refactoring.", "num_citations": "0\n", "authors": ["2285"]}