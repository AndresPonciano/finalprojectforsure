{"title": "Transformative effects of IoT, Blockchain and Artificial Intelligence on cloud computing: Evolution, vision, trends and open challenges\n", "abstract": " Cloud computing plays a critical role in modern society and enables a range of applications from infrastructure to social media. Such system must cope with varying load and evolving usage reflecting societies\u2019 interaction and dependency on automated computing systems whilst satisfying Quality of Service (QoS) guarantees. Enabling these systems are a cohort of conceptual technologies, synthesized to meet demand of evolving computing applications. In order to understand current and future challenges of such system, there is a need to identify key technologies enabling future applications. In this study, we aim to explore how three emerging paradigms (Blockchain, IoT and Artificial Intelligence) will influence future cloud computing systems. Further, we identify several technologies driving these paradigms and invite international experts to discuss the current status and future directions of cloud computing\u00a0\u2026", "num_citations": "153\n", "authors": ["1208"]}
{"title": "Co-FAIS: Cooperative fuzzy artificial immune system for detecting intrusion in wireless sensor networks\n", "abstract": " Due to the distributed nature of Denial-of-Service attacks, it is tremendously challenging to identify such malicious behavior using traditional intrusion detection systems in Wireless Sensor Networks (WSNs). In the current paper, a bio-inspired method is introduced, namely the cooperative-based fuzzy artificial immune system (Co-FAIS). It is a modular-based defense strategy derived from the danger theory of the human immune system. The agents synchronize and work with one another to calculate the abnormality of sensor behavior in terms of context antigen value (CAV) or attackers and update the fuzzy activation threshold for security response. In such a multi-node circumstance, the sniffer module adapts to the sink node to audit data by analyzing the packet components and sending the log file to the next layer. The fuzzy misuse detector module (FMDM) integrates with a danger detector module to identify the\u00a0\u2026", "num_citations": "110\n", "authors": ["1208"]}
{"title": "Relationship between convenience, perceived value, and repurchase intention in online shopping in Vietnam\n", "abstract": " Electronic commerce (e-commerce) is an increasingly popular trend in modern economy concomitant with the development of the Internet. E-commerce has developed considerably, making Vietnam one of the fastest growing markets in the world. However, its growth rate has not matched its potential, leading to the question how online retailers could improve their practices and thus contribute to the sustainable development of emerging markets such as Vietnam. Therefore, with the goal of providing online retailers with many methods to improve their online shopping service, this study examined the direct and indirect influence of the dimensions of online shopping convenience on repurchase intention through customer-perceived value. A survey of 230 Vietnamese customers was conducted to test the theoretical model. A structural equation model was used for data analysis. The results determined that the five dimensions of online shopping convenience are: access, search, evaluation, transaction, and possession/post-purchase convenience. All dimensions have a direct impact on perceived value and repurchase intention. The results also show the important role of perceived value when a factor both directly influences repurchase intention and mediates the relationship between convenience and repurchase intention. View Full-Text", "num_citations": "94\n", "authors": ["1208"]}
{"title": "Estimating the incidence of breast cancer in Africa: a systematic review and meta-analysis\n", "abstract": " BackgroundBreast cancer is estimated to be the most common cancer worldwide. We sought to assemble publicly available data from Africa to provide estimates of the incidence of breast cancer on the continent.MethodsA systematic search of Medline, EMBASE, Global Health and African Journals Online (AJOL) was conducted. We included population-or hospital-based registry studies on breast cancer conducted in Africa, and providing estimates of the crude incidence of breast cancer among women. A random effects meta-analysis was employed to determine the pooled incidence of breast cancer across studies.ResultsThe literature search returned 4648 records, with 41 studies conducted across 54 study sites in 22 African countries selected. We observed important variations in reported cancer incidence between population-and hospital-based cancer registries. The overall pooled crude incidence of breast\u00a0\u2026", "num_citations": "81\n", "authors": ["1208"]}
{"title": "Practical scrum-scrum team: Way to produce successful and quality software\n", "abstract": " Scrum is the most popular agile methodology in software industry. By using scrum practices, several companies have improved their quality and productivity. This paper presents a practical view inside the Scrum practices, specifically, the team size, team structure and description of roles in Scrum teams are explained. The paper is based on our experiences in multiple projects executed in Scrum Agile methodology. Scrum is most suitable for products with team size of 3-9 members. For larger products, Scrum provides a mechanism called Scrum of Scrums. Scrum of Scrums distribute the large work/project into several teams and to control the quality and speed of each team, regular meetings are organized amongst the representatives of each team. We also present the guidelines for work distribution for the Scrum of Scrum (SoS) teams.", "num_citations": "80\n", "authors": ["1208"]}
{"title": "Measuring and evaluating a design complexity metric for XML schema documents\n", "abstract": " The eXtensible Markup Language (XML) has been gaining extraordinary acceptance from many diverse enterprise software companies for their object repositories, data interchange, and development tools. Further, many different domains, organizations and content providers have been publishing and exchanging information via internet by the usage of XML and standard schemas. Efficient implementation of XML in these domains requires well designed XML schemas. In this point of view, design of XML schemas plays an extremely important role in software development process and needs to be quantified for ease of maintainability. In this paper, an attempt has been made to evaluate the quality of XML schema documents (XSD) written in W3C XML Schema language. We propose a metric, which measures the complexity due to the internal architecture of XSD components, and due to recursion. This is the single metric, which cover all major factors responsible for complexity of XSD. The metric has been empirically and theoretically validated, demonstrated with examples and supported by comparison with other well known structure metrics applied on XML schema documents.", "num_citations": "62\n", "authors": ["1208"]}
{"title": "Acceptance and use of e-learning based on cloud computing: the role of consumer innovativeness\n", "abstract": " Cloud computing and E-learning are the inevitable trend of computational science in general, and information systems and technologies in specific. However, there are not many studies on the adoption of cloud-based E-learning systems. Moreover, while there are many papers on information system adoption as well as customer innovativeness, the innovativeness and adoption in the same model seems to be rare in the literature. The study combines the extended Unified Theory of Acceptance and Use of Technology (UTAUT2) and consumer innovativeness on the adoption of E-learning systems based on cloud computing. A survey was conducted among 282 cloud-based E-learning participants and analyzed by structural equation modeling (SEM). The findings indicate that the adoption of cloud-based E-learning is influenced by performance expectancy, social influence, hedonic motivation, and habit\u00a0\u2026", "num_citations": "61\n", "authors": ["1208"]}
{"title": "Weighted class complexity: a measure of complexity for object oriented system\n", "abstract": " Software complexity metrics are used to predict critical information about reliability and maintainability of software systems. Object oriented software development requires a different approach to software complexity metrics. In this paper, we propose a metric to compute the structural and cognitive complexity of class by associating a weight to the class, called as Weighted Class Complexity (WCC). On the contrary, of the other metrics used for object oriented systems, proposed metric calculates the complexity of a class due to methods and attributes in terms of cognitive weight. The proposed metric has been demonstrated with OO examples. The theoretical and  practical evaluations based on the information theory have shown that the proposed metric is on ratio scale and satisfies most of the parameters required by the measurement theory", "num_citations": "59\n", "authors": ["1208"]}
{"title": "Evaluating cognitive complexity measure with Weyuker properties\n", "abstract": " Cognitive complexity measure is based on cognitive informatics, which in turn helps in comprehending the software characteristics. Weyuker properties must be satisfied by every complexity measure to qualify as a good and comprehensive one. An attempt has been made to evaluate cognitive complexity measure in terms of nine Weyuker properties, through examples. It has been found that eight of nine Weyuker properties have been satisfied by the cognitive weight software complexity measure and hence establishes the cognitive complexity as a well structured one.", "num_citations": "55\n", "authors": ["1208"]}
{"title": "Android malware detection: A survey\n", "abstract": " In the world today, smartphones are evolving every day and with this evolution, security becomes a big issue. Security is an important aspect of the human existence and in a world, with inadequate security, it becomes an issue for the safety of the smartphone users. One of the biggest security threats to smartphones is the issue of malware. The study carried out a survey on malware detection techniques towards identifying gaps, and to provide the basis for improving and effective measure for unknown android malware. The results showed that machine learning is a more promising approach with higher detection accuracy. Upcoming researchers should look into deep learning approach with the use of a large dataset in order to achieve a better accuracy.", "num_citations": "47\n", "authors": ["1208"]}
{"title": "A complexity measure based on cognitive weights\n", "abstract": " Cognitive Informatics plays an important role in understanding the fundamental characteristics of software. This paper proposes a model of the fundamental characteristics of software, complexity in terms of cognitive weights of basic control structures. Cognitive weights are degree of difficulty or relative time and effort required for comprehending a given piece of software, which satisfy the definition of complexity. An attempt has also been made to prove the robustness of proposed complexity measure by comparing it with the other measures based on cognitive informatics.", "num_citations": "44\n", "authors": ["1208"]}
{"title": "An empirical analysis of the effectiveness of software metrics and fault prediction model for identifying faulty classes\n", "abstract": " Software fault prediction models are used to predict faulty modules at the very early stage of software development life cycle. Predicting fault proneness using source code metrics is an area that has attracted several researchers' attention. The performance of a model to assess fault proneness depends on the source code metrics which are considered as the input for the model. In this work, we have proposed a framework to validate the source code metrics and identify a suitable set of source code metrics with the aim to reduce irrelevant features and improve the performance of the fault prediction model. Initially, we applied a t-test analysis and univariate logistic regression analysis to each source code metric to evaluate their potential for predicting fault proneness. Next, we performed a correlation analysis and multivariate linear regression stepwise forward selection to find the right set of source code metrics for\u00a0\u2026", "num_citations": "43\n", "authors": ["1208"]}
{"title": "Hybrid microgrid for microfinance institutions in rural areas\u2013A field demonstration in West Africa\n", "abstract": " We present a hybrid energy microgrid optimization model for a microbank in a remote rural residential area. The model is based on the use of renewable (wind turbines & solar photovoltaic (PV)) and conventional (gasoline generators) energy sources and battery storage systems. We conducted a detailed assessment of a typical microbank\u2019s load, residential loads and energy resources in a village called Ajasse-Ipo in Kwara State, Nigeria. We performed the modeling of a hybrid microgrid system, followed by an economic analysis and sensitivity analysis to optimize the hybrid system design. We performed simulations based on the energy resources available (solar PV, wind, gasoline generator & battery energy storage system) to satisfy the energy demands of the microbank, while the excess energy was supplied to meet the demand of the community loads, i.e. water pumping machine and rural home lighting. The\u00a0\u2026", "num_citations": "42\n", "authors": ["1208"]}
{"title": "Cloud-Based Security Driven Human Resource Management System.\n", "abstract": " With the emergence of cloud computing, it has become easy to store large volumes of data in the cloud to enhance Human Resource Management (HRM), based on the elasticity and scalability that cloud computing offers. This paper proposes the OnibereOdunayoSecurity-4 (OOS-4) security model for Human Resource Information System (HRIS) deployed on a cloud platform. The OOS-4 framework is a holistic and integrated model that is expected to allow for better interrelatedness of the various components of a HRM organization with adequate consideration for security. Furthermore, utilizing the Platform as a Service (PaaS) cloud computing architecture, the model was implemented using the Google App Engine. The result is a scalable application in which the data in storage is encrypted and visible on the Google Cloud Platform data store. The application is secured by proving encryption for data in storage on the Google Cloud Platform. The application will enhance HRM.", "num_citations": "41\n", "authors": ["1208"]}
{"title": "A review of models for evaluating quality in open source software\n", "abstract": " Open source products/projects targeting the same or similar applications are common nowadays. This makes choosing a tricky task. Quality is one factor that can be considered when choosing among similar open source solutions. In order to measure quality in software, quality models can be used. Open source quality models emerged due to the inability of traditional quality models to measure unique features (such as community) of open source software. The aim of the paper therefore is to examine the characteristic features, unique strengths, and limitations of existing open source quality models. In addition, we compare the models based on some selected attributes.", "num_citations": "41\n", "authors": ["1208"]}
{"title": "Metrics suite for maintainability of extensible markup language Web Services\n", "abstract": " The eXtensible Markup Language (XML) web services are emerging as the de-facto mechanism for exchanging structured information between applications. The large popularity and acceptance of web services led the developers to adopt the best practices of web service implementation and to find the ways for managing and maintaining web services more effectively. Maintainability, one of the important factors, which affects the quality of XML web services, can be controlled by the proper software metrics that are specifically designed and developed for it. In this paper, we present a suite of metrics to evaluate the quality of the XML web service in terms of its maintainability. The present suite of metrics includes: data weight of a web service description language, distinct message ratio metric, message entropy metric and message repetition scale metric. All the proposed metrics have been evaluated theoretically and\u00a0\u2026", "num_citations": "41\n", "authors": ["1208"]}
{"title": "Artificial intelligence, smart classrooms and online education in the 21st century: Implications for human development\n", "abstract": " The advent of artificial intelligence (AI) technology in the education sector has largely taken over conventional classrooms and revolutionized the way education is conducted to the admiration of many. Other scholars however, believe that such early celebration of AI benefits is unfounded and inimical to the education sector since the adoption of modern AI teaching systems now raises long-term issues about the relevance of teachers and their classrooms in 21st Century AI education. The Marxian Alienation Theory was adopted for the article. The Ex-post factor method and Derrida's critical method of analysis was utilized for attaining the objectives of the article. The article faults recent attempts at eulogizing the impact of AI innovations in the education sector and on human development. Extensive research is proposed as necessary for contemporary scholars of AI and education technologist before proper\u00a0\u2026", "num_citations": "39\n", "authors": ["1208"]}
{"title": "Empirical studies of cloud computing in education: a systematic literature review\n", "abstract": " The purpose of this paper is to present the evidence about adoption of cloud computing in the education system in universities or higher education institutions. We performed a systematic literature review (SLR) of empirical studies that investigated the current level of adoption of cloud computing in the education systems and motivations for using cloud computing in the institution. Seven papers were included in our synthesis of evidence. It has been found that several universities are interested in using cloud computing in their education systems, and they have utilized different types of cloud computing service models (IaaS, PaaS, SaaS). The results of this SLR show that a clear gap exists in this research field: a lack of empirical studies focusing on utilizing cloud computing within educational institutions.", "num_citations": "39\n", "authors": ["1208"]}
{"title": "Identifying phishing attacks in communication networks using URL consistency features\n", "abstract": " Phishing is a fraudulent attempt by cybercriminals, where the target audience is addressed by a text message, phone call or e-mail, requesting classified and sensitive information after presenting himself/herself as a legitimate agent. Successful phishing attack may result into financial loss and identity theft. Identifying forensic characteristics of phishing attack can help to detect the attack and its perpetuators and as well as to enable defence against it. To shield internet users from phishing assaults, numerous anti-phishing models have been proposed. Currently employed techniques to handle these challenges are not sufficient and capable enough. We aim at identifying phishing sites in order to guard internet users from being vulnerable to any form of phishing attacks by verifying the conceptual and literal consistency between the uniform resource locator (URL) and the web content. The implementation of the\u00a0\u2026", "num_citations": "35\n", "authors": ["1208"]}
{"title": "A systematic literature review of open source software quality assessment models\n", "abstract": " Many open source software (OSS) quality assessment models are proposed and available in the literature. However, there is little or no adoption of these models in practice. In order to guide the formulation of newer models so they can be acceptable by practitioners, there is need for clear discrimination of the existing models based on their specific properties. Based on this, the aim of this study is to perform a systematic literature review to investigate the properties of the existing OSS quality assessment models by classifying them with respect to their quality characteristics, the methodology they use for assessment, and their domain of application so as to guide the formulation and development of newer models. Searches in IEEE Xplore, ACM, Science Direct, Springer and Google Search is performed so as to retrieve all relevant primary studies in this regard. Journal and conference papers between the year 2003 and 2015 were considered since the first known OSS quality model emerged in 2003. A total of 19 OSS quality assessment model papers were selected. To select these models we have developed assessment criteria to evaluate the quality of the existing studies. Quality assessment models are classified into five categories based on the quality characteristics they possess namely: single-attribute, rounded category, community-only attribute, non-community attribute as well as the non-quality in use models. Our study reflects that software selection based on hierarchical structures is found to be the most popular selection method in the existing OSS quality assessment models. Furthermore, we found that majority (47%) of the existing\u00a0\u2026", "num_citations": "35\n", "authors": ["1208"]}
{"title": "A comparative study of agile, component-based, aspect-oriented and mashup software development methods\n", "abstract": " This paper compares Agile Methods, Component-Based Software Engineering (CBSE), Aspect-Oriented Software Development (AOSD) and Mashups as the four most advanced software development methods. These different approaches depend almost totally on their application domain but their usability can be equally applied across domains. The purpose of this comparative analysis is to give a succinct and clear review of these four methodologies. Their definitions, characteristics, advantages and disadvantages are considered and a conceptual mind-map is generated that sets out a foundation to assist in the formulation and design of a possible new integrated software development approach. This includes supportive techniques to benefit from the examined methods' potential advantages for cross-fertilization. It is a basis upon which new thinking may be initiated and further research stimulated in the software engineering subject field.", "num_citations": "34\n", "authors": ["1208"]}
{"title": "Computational Science And Its Applications-Iccsa 2005: International Conference, Singapore, May 9-12, 2005, Proceedings\n", "abstract": " The four volume set assembled following The 2005 International Conference on Computational Science and its Applications, ICCSA 2005, held in Suntec International Convention and Exhibition Centre, Singapore, from 9 May 2005 till 12 May 2005, represents the? ne collection of 540 refereed papers selected from nearly 2,700 submissions. Computational Science has? rmly established itself as a vital part of many scienti? c investigations, a? ecting researchers and practitioners in areas ranging from applications such as aerospace and automotive, to emerging technologies such as bioinformatics and nanotechnologies, to core disciplines such as ma-ematics, physics, and chemistry. Due to the shear size of many challenges in computational science, the use of supercomputing, parallel processing, and-phisticated algorithms is inevitable and becomes a part of fundamental t-oretical research as well as endeavors in emerging? elds. Together, these far reaching scienti? c areas contribute to shape this Conference in the realms of state-of-the-art computational science research and applications, encompassing the facilitating theoretical foundations and the innovative applications of such results in other areas.", "num_citations": "34\n", "authors": ["1208"]}
{"title": "Survey of object detection methods in camouflaged image\n", "abstract": " Camouflage is an attempt to conceal the texture of a foreground object into the background image frame texture. Camouflage detection method or Decamouflaging method is basically used to detect foreground object hidden in the background image. In this research paper authors presented survey of camouflage detection methods for different applications and areas.", "num_citations": "33\n", "authors": ["1208"]}
{"title": "Data complexity metrics for XML Web Services\n", "abstract": " Markup Language (XML) technologies enable integration of diverse IT processes and systems and have been gaining extraordinary acceptance from the basic to the most complicated business and scientific processes. The maintainability is one of the important factors that affect the quality of the Web services that can be seen a kind of software project. The effective management of any type of software projects requires modelling, measurement, and quantification. This study presents a metric for the assessment of the quality of the Web services in terms of its maintainability. For this purpose we proposed a data complexity metric that can be evaluated by analyzing WSDL (Web Service Description Language) documents used for describing Web services.", "num_citations": "33\n", "authors": ["1208"]}
{"title": "Modified cognitive complexity measure\n", "abstract": " In cognitive functional size measure, the functional size is proportional to weighted cognitive complexity of all internal BCS\u2018s and number of input and output. This paper proposes the modification in cognitive functional size complexity measure. The proposed complexity measure is proportional to total occurrence of operators and operands and all internal BCS\u00b4s. The operators and operands are equally important in design consideration. Thus, the contribution of the operators, operands and cognitive aspects complete the definition of a complexity measure in terms of cognitive. Accordingly, a new formula is developed for calculating the modified cognitive complexity measure. An attempt has also been made to evaluate modified cognitive complexity measure in terms of nine Weyuker\u2019s properties, through examples. It has been found that seven of nine Weyuker\u2019s properties have been satisfied by the modified\u00a0\u2026", "num_citations": "33\n", "authors": ["1208"]}
{"title": "An inheritance complexity metric for object-oriented code: A cognitive approach\n", "abstract": " Software metrics should be used in order to improve the productivity and quality of software, because they provide critical information about reliability and maintainability of the system. In this paper, we propose a cognitive complexity metric for evaluating design of object-oriented (OO) code. The proposed metric is based on an important feature of the OO systems: Inheritance. It calculates the complexity at method level considering internal structure of methods, and also considers inheritance to calculate the complexity of class hierarchies. The proposed metric is validated both theoretically and empirically. For theoretical validation, principles of measurement theory are applied since the measurement theory has been proposed and extensively used in the literature as a means to evaluate the software engineering metrics. We applied our metric on a real project for empirical validation and compared it with\u00a0\u2026", "num_citations": "32\n", "authors": ["1208"]}
{"title": "ESR of Cu2+ doped cadmium (II) formate dihydrate\n", "abstract": " Electron spin resonance (ESR) of Cu2+ doped cadmium formate dihydrate single crystal was studied at room temperature. Copper enters the lattice substitutionally and is trapped at two magnetically inequivalent sites. The observed spectra are fitted to a spin-Hamiltonian of rhombic symmetry with the following values of the spin-Hamiltonian parameters, Cu2+(I): gx=2.097\u00b10.002, gy=2.1166\u00b10.002, gz=2.2887\u00b10.002 and Ax=(140\u00b12)\u00d710\u22124\u00a0cm\u22121, Ay=(151\u00b12)\u00d710\u22124\u00a0cm\u22121, Az=(239\u00b12)\u00d710\u22124\u00a0cm\u22121, Cu2+(II): gx=2.0843\u00b10.002, gy=2.1045\u00b10.002, gz=2.2742\u00b10.002 and Ax=(141\u00b12)\u00d710\u22124\u00a0cm\u22121, Ay=(158\u00b12)\u00d710\u22124\u00a0cm\u22121, Az=(267\u00b12)\u00d710\u22124\u00a0cm\u22121. The ground state wave function of the Cu2+ ion in this lattice is evaluated. It is found that the ground state is predominantly |x2\u2212y2>. The g-factor anisotropy is also calculated and compared with the experimental value. With the help of the optical absorption study, the nature of\u00a0\u2026", "num_citations": "32\n", "authors": ["1208"]}
{"title": "Adoption of mobile applications for teaching-learning process in rural girls\u2019 schools in India: an empirical study\n", "abstract": " The purpose of this study is to identify the factors that can impact the adoption of mobile apps for teaching-learning process focusing on the girls\u2019 school in rural India. The hypotheses were proposed and a conceptual model has been developed. There is a survey work conducted to collect the data from different respondents using a convenience sampling method. The model has been validated statistically through PLS-SEM analysis covering feedbacks of 271 effective respondents. The study highlights the impact of different antecedents of the behavioural intention of the students of using mobile applications for teaching-learning process. The results also show that among other issues, price value has insignificant influence on the intention of the girl students of the rural India. During survey feedbacks have been obtained from the 271 respondents, which is meagre compared to vastness of the population and school of rural India. Only few predictors have been considered leaving possibilities of inclusion of other boundary conditions to enhance the explanative power more than that has been achieved in the proposed model with the explanative power of 81%. The model has provided laudable inputs to the educational policy makers and technology enablers and administrators to understand the impact of the mobile applications on the rural girls\u2019 school of India and facilitate the development of m-learning. Very few studies been conducted to explore the impact of mobile applications on the school education of rural India especially focusing on the girls\u2019 schools.", "num_citations": "31\n", "authors": ["1208"]}
{"title": "Outdoor path loss predictions based on extreme learning machine\n", "abstract": " In a typical outdoor environment,\u00a0the propagation of radio waves is usually random in nature, to the extent that the characterization of the wireless channel often becomes very difficult. Several models have been developed to predict the average Received Signal Strength (RSS) for specified distance ranges. However, the use of deterministic models requires high computational efficiency while the prediction results of empirical models may not be as accurate as\u00a0required. On machine learning approach, the performances of multi-layered feed-forward network models are limited by slow convergence and local minimum, such that a global optimal solution is not guaranteed. In this paper, Extreme Learning Machine (ELM) algorithm is\u00a0considered in the development of an optimal path loss prediction model for outdoor propagation scenario. Single Hidden Layer Feed-forward Neural Networks (SHLFNNs)\u00a0are\u00a0\u2026", "num_citations": "31\n", "authors": ["1208"]}
{"title": "Providing knowledge recommendations: an approach for informal electronic mentoring\n", "abstract": " The use of Web 2.0 technologies for knowledge management is invading the corporate sphere. The Web 2.0 is the most adopted knowledge transfer tool within knowledge intensive firms and is starting to be used for mentoring. This paper presents IM-TAG, a Web 2.0 tool, based on semantic technologies, for informal mentoring. The tool offers recommendations of mentoring contents built upon personal competencies of the mentee, combined with content and opinion tagging. To validate the tool, a case study comparing recommendations from the IM-TAG and a group of experts was conducted. Results show that the accuracy of IM-TAG's recommendations is notable and satisfactory. The main conclusions of this research may be valuable to organizations immersed in mentoring programs.", "num_citations": "30\n", "authors": ["1208"]}
{"title": "Impact of ICT on universities administrative services and management of students' records: ICT in university administration\n", "abstract": " This article describes the issue of governance in higher education, of which administration is key, is saddled with numerous challenges, as such, new approaches are being sought out to enhance the process. It is obvious that Information and Communication Technology (ICT) is a tool that enhances administrative activities of higher education institution. This article is based on descriptive survey design which investigates the impact of ICT on the administrative services/management of students' records in Nigerian universities. A questionnaire was the research instrument employed, and questionnaire items were developed through a review of related literature. A total of 200 respondents participated, comprising students, lecturers and administrators were randomly selected from ten universities in Nigeria. Data collected was analyzed using ANOVA. The major impacts of ICT in administrative services/management of\u00a0\u2026", "num_citations": "29\n", "authors": ["1208"]}
{"title": "A comparative study on the ant colony optimization algorithms\n", "abstract": " The ant colony optimization (ACO) algorithm is a member of the ant colony algorithms which is part of the swarm intelligence methods. It is a probabilistic technique for finding close to optimal paths through a problem space. The ant colony optimization algorithms therefore mimic the behavior of natural ants with the use of artificial ants as agents to find a reasonable solution to optimization problems by following the model of optimization used by natural ants to get to their destination in the shortest possible time. This paper presents a review and aims to show the main variants of the ant colony optimization algorithms by comparing the results of mainly four variants on some selected combinatorial optimization problems. A review of the varieties of the ACO algorithms, application of ACO algorithms and the comparative analysis of some selected variants are presented.", "num_citations": "29\n", "authors": ["1208"]}
{"title": "Applicability of weyuker's properties on oo metrics: Some misunderstandings\n", "abstract": " Weyuker's properties have been suggested as a guiding tool in identification of a good and comprehensive complexity measure by several researchers. Weyuker proposed nine properties to evaluate complexity measure for traditional programming. However, they are extensively used for evaluating object-oriented (OO) metrics, although the object-oriented features are entirely different in nature. In this paper, two recently reported OO metrics were evaluated and, based on it; the usefulness and relevance of these properties for evaluation purpose for object-oriented systems is discussed.", "num_citations": "29\n", "authors": ["1208"]}
{"title": "Cognitive program complexity measure\n", "abstract": " In cognitive informatics, the functional complexity of software depends on three factors: internal architecture, input, and output. In the earlier proposed metrics based on cognitive informatics, these above factors are not fully considered. This paper proposes an improved cognitive complexity measure. Accordingly, new formula is developed to calculate the cognitive complexity. An attempt has also been made to evaluate and validate the proposed measure through Weyuker's properties and a practical framework. It has been found that seven of nine Weyuker's properties have been satisfied by the proposed cognitive complexity measure. It also satisfies most of the parameters required by the practical framework, hence establishes as a well-structured one. Finally, a comparative study with similar measures has been made to prove its robustness.", "num_citations": "29\n", "authors": ["1208"]}
{"title": "An object oriented complexity metric based on cognitive weights\n", "abstract": " Complexity in general is defined as \"the degree to which a system or component has a design or implementation that is difficult to understand and verify \". Complexity metrics are used to predict critical information about reliability and maintainability of software systems. Object oriented software development requires a different approach to software metrics. In this paper, an attempt has been made to propose a metric for an object oriented code, which calculates the complexity of a class at method level. The proposed measure considers the internal architecture of the class, subclass, and member functions, while other proposed metrics for object oriented programming do not. An attempt has also been made to evaluate and validate the proposed measure in terms of Weyuker's properties and against the principles of measurement theory. It has been found that seven of nine Weyuker's properties have been satisfied by\u00a0\u2026", "num_citations": "29\n", "authors": ["1208"]}
{"title": "Evaluation and comparison of cognitive complexity measure\n", "abstract": " Weyuker properties have been suggested as a guiding tool in identification of a good and comprehensive complexity measure. In this paper, an attempt has been made to compare cognitive complexity measure in terms of nine Weyuker's properties with other complexity measures, such as McCabe's, Halstead's and Oviedo's complexity measures. Our intension is to study what kinds of new information about the measures are able to give.", "num_citations": "29\n", "authors": ["1208"]}
{"title": "Software measurement activities in small and medium enterprises: an empirical assessment\n", "abstract": " An empirical study for evaluating the proper implementation of measurement/metric programs in software companies in one area of Turkey is presented. The research questions are discussed and validated with the help of senior software managers (more than 15 years\u2019 experience) and then used for interviewing a variety of medium and small scale software companies in Ankara. Observations show that there is a common reluctance/lack of interest in utilizing measurements/metrics despite the fact that they are well known in the industry. A side product of this research is that internationally recognized standards such as ISO and CMMI are pursued if they are a part of project/job requirements; without these requirements, introducing those standards to the companies remains as a long-term target to increase quality.", "num_citations": "28\n", "authors": ["1208"]}
{"title": "Large scale community detection using a small world model\n", "abstract": " In a social network, small or large communities within the network play a major role in deciding the functionalities of the network. Despite of diverse definitions, communities in the network may be defined as the group of nodes that are more densely connected as compared to nodes outside the group. Revealing such hidden communities is one of the challenging research problems. A real world social network follows small world phenomena, which indicates that any two social entities can be reachable in a small number of steps. In this paper, nodes are mapped into communities based on the random walk in the network. However, uncovering communities in large-scale networks is a challenging task due to its unprecedented growth in the size of social networks. A good number of community detection algorithms based on random walk exist in literature. In addition, when large-scale social networks are being considered, these algorithms are observed to take considerably longer time. In this work, with an objective to improve the efficiency of algorithms, parallel programming framework like Map-Reduce has been considered for uncovering the hidden communities in social network. The proposed approach has been compared with some standard existing community detection algorithms for both synthetic and real-world datasets in order to examine its performance, and it is observed that the proposed algorithm is more efficient than the existing ones. View Full-Text", "num_citations": "27\n", "authors": ["1208"]}
{"title": "Entropy as a measure of quality of XML schema document\n", "abstract": " In this paper, a metric for the assessment of the structural complexity of eXtensible Markup Language schema document is formulated. The present metric \u2018Schema Entropy is based on entropy concept and intended to measure the complexity of the schema documents written in W3C XML Schema Language due to diversity in the structures of its elements. The SE is useful in evaluating the efficiency of the design of Schemas. A good design reduces the maintainability efforts. Therefore, our metric provides valuable information about the reliability and maintainability of systems. In this respect, this metric is believed to be a valuable contribution for improving the quality of XML-based systems. It is demonstrated with examples and validated empirically through actual test cases.", "num_citations": "27\n", "authors": ["1208"]}
{"title": "Methodological framework for the allocation of work packages in global software development\n", "abstract": " Global software development in software development industry is a new aspect for many software project managers. In this scenario, the allocation of work packages among project participants is not a simple task. This allocation was traditionally determined by availability and competence but this new trend introduces complexity in an already complex process. Given the need to define new models to guide managers in these operations, this paper presents a framework to allocate work packages among project participants. Apart from the introduction of the framework itself, the results of its implementation are presented. These results show a notable output of the implementation in terms of accuracy of task execution to planning, effect introduction and overall satisfaction. Copyright \u00a9 2013 John Wiley & Sons, Ltd.", "num_citations": "25\n", "authors": ["1208"]}
{"title": "Survey on agile metrics and their inter-relationship with other traditional development metrics\n", "abstract": " In our civilized world today, measurement is very important in every aspect of our lives as a means of quantifying our success or progress in whatever activity we involve ourselves in. Consequently, this paper outlines the various metrics that are utilized in the Agile development process and compares them with the ones used in time past to measure success and progress.", "num_citations": "25\n", "authors": ["1208"]}
{"title": "A review of soft techniques for SMS spam classification: Methods, approaches and applications\n", "abstract": " Background:The easy accessibility and simplicity of Short Message Services (SMS) have made it attractive to malicious users thereby incurring unnecessary costing on the mobile users and the Network providers\u2019 resources.Aim:The aim of this paper is to identify and review existing state of the art methodology for SMS spam based on some certain metrics: AI methods and techniques, approaches and deployed environment and the overall acceptability of existing SMS applications.Methodology:This study explored eleven databases which include IEEE, Science Direct, Springer, Wiley, ACM, DBLP, Emerald, SU, Sage, Google Scholar, and Taylor and Francis, a total number of 1198 publications were found. Several screening criteria were conducted for relevant papers such as duplicate removal, removal based on irrelevancy, abstract eligibility based on the removal of papers with ambiguity (undefined methodology\u00a0\u2026", "num_citations": "24\n", "authors": ["1208"]}
{"title": "Distributed centrality analysis of social network data using MapReduce\n", "abstract": " Analyzing the structure of a social network helps in gaining insights into interactions and relationships among users while revealing the patterns of their online behavior. Network centrality is a metric of importance of a network node in a network, which allows revealing the structural patterns and morphology of networks. We propose a distributed computing approach for the calculation of network centrality value for each user using the MapReduce approach in the Hadoop platform, which allows faster and more efficient computation as compared to the conventional implementation. A distributed approach is scalable and helps in efficient computations of large-scale datasets, such as social network data. The proposed approach improves the calculation performance of degree centrality by 39.8%, closeness centrality by 40.7% and eigenvalue centrality by 41.1% using a Twitter dataset. View Full-Text", "num_citations": "24\n", "authors": ["1208"]}
{"title": "Smart irrigation system for environmental sustainability in Africa: An Internet of Everything (IoE) approach\n", "abstract": " Abstract [eng]Water and food are two of the most important commodities in the world, which makes agriculture crucial to mankind as it utilizes water (irrigation) to provide us with food. Climate change and a rapid increase in population have put a lot of pressure on agriculture which has a snowball effect on the earth\u2019s water resource, which has been proven to be crucial for sustainable development. The need to do away with fossil fuel in powering irrigation systems cannot be over emphasized due to climate change. Smart Irrigation systems powered by renewable energy sources (RES) have been proven to substantially improve crop yield and the profitability of agriculture. Here we show how the control and monitoring of a solar powered smart irrigation system can be achieved using sensors and environmental data from an Internet of Everything (IoE). The collected data is used to predict environment conditions\u00a0\u2026", "num_citations": "24\n", "authors": ["1208"]}
{"title": "Cloud multi-tenancy: Issues and developments\n", "abstract": " Cloud Computing (CC) is a computational paradigm that provides pay-per use services to customers from a pool of networked computing resources that are provided on demand. Customers therefore does not need to worry about infrastructure or storage. Cloud Service Providers (CSP) make custom built applications available to customers online. Also, organisations and enterprises can build and deploy applications based on platforms provided by the Cloud service provider. Scalable storage and computing resources is also made available to consumers on the Clouds at a cost. Cloud Computing takes virtualization a step further through the use of virtual machines, it allows several customers share the same physical machine. In addition, it is possible for numerous customers to share applications provided by a CSP; this sharing model is known as multi-tenancy. Though Multi-tenancy has its drawbacks but\u00a0\u2026", "num_citations": "24\n", "authors": ["1208"]}
{"title": "A requirements engineering techniques review in agile software development methods\n", "abstract": " The first phase in the software development process is the Requirements Engineering (RE). Several methods for software development and RE techniques have been used to extract these users\u2019 needs depending on the software complexity. Our goal is to map the evidence available about requirements engineering techniques adopted and challenges faced by agile methods in order to understand how traditional requirements engineering issues are resolved using agile requirements engineering. The agile methods considered for this work are: SCRUM, Dynamic Systems Development Method (DSDM), Adaptive Software Development (ASD) and Crystal Family. The present work is based on the Systematic Literature Review (SLR) method proposed by Kitchenham; we have reviewed publications from ACM, IEEE, Science Direct, DBLP and World Wide Web. From a population of 34 papers, we identified\u00a0\u2026", "num_citations": "24\n", "authors": ["1208"]}
{"title": "Critical success factors for implementing business intelligence system: Empirical study in vietnam\n", "abstract": " Although the application of business intelligence (BI) system has increased recently, the critical success factors (CSFs) of BI system implementation remain poorly understood. Therefore, understanding CSFs for BI system is necessary for a company to be successful in implementing a BI system. Currently, the number of business successfully implemented BI in Vietnam is still limited. In order to understand the current situation of BI implementation in Vietnam, case study method has been used. Based on the research framework developed by Yeoh & Koronios, in-depth interviews have been conducted with 4 Vietnamese companies, who already implemented BI system. The main result of this study helps to extract the lessons learnt from 4 cases to rank the importance of CSFs for BI implementation in Vietnam context. Based on this result, recommendations were made for increasing the probability of\u00a0\u2026", "num_citations": "23\n", "authors": ["1208"]}
{"title": "Predicting web service maintainability via object-oriented metrics: a statistics-based approach\n", "abstract": " The Service-Oriented Computing paradigm enables the construction of distributed systems by assembling loosely coupled pieces of software called services, which have clear interfaces to their functionalities. Service interface descriptions have many aspects, such as complexity and quality, all of which can be measured. This paper presents empirical evidence showing that services interfaces maintainability can be predicted by applying traditional software metrics in service implementations. A total of 11\u00a0source code level metrics and 5\u00a0service interface metrics have been statistically correlated using 154\u00a0real world services.", "num_citations": "23\n", "authors": ["1208"]}
{"title": "Evaluation criteria for object-oriented metrics\n", "abstract": " In this paper an evaluation model for object-oriented (OO) metrics is proposed. We have evaluated the existing evaluation criteria for OO metrics, and based on the observations, a model is proposed which tries to cover most of the features for the evaluation of OO metrics. The model is validated by applying it to existing OO metrics. In contrast to the other existing criteria, the proposed model is simple in implementation and includes the practical and important aspects of evaluation; hence it suitable to evaluate and validate any OO complexity metric.", "num_citations": "23\n", "authors": ["1208"]}
{"title": "NIGEDU CLOUD: model of a national e-education cloud for developing countries\n", "abstract": " To achieve global competitiveness, governments in developing countries are evolving and implementing information technology policies, to enable their countries participate in the current ICT revolution. One barrier to attaining the education objectives of the policies is inadequate national ICT infrastructure and services. The inadequacy of ICT infrastructure and services is attributed to inadequate government funding, which in turn becomes difficult for education institutions to own and use sophisticated ICT facilities. In spite of inadequate funding, the gap can be reduced if education institutions in developing countries have access to ICT infrastructures available in developed countries. A technology platform that makes this possible is cloud computing. The design for national cloud computing model is proposed in this paper. This model is envisioned as a good strategy for achieving the education-related objectives of\u00a0\u2026", "num_citations": "22\n", "authors": ["1208"]}
{"title": "Lossless text compression technique using syllable based morphology\n", "abstract": " In this paper, we present a new lossless text compression technique which utilizes syllable-based morphology of multi-syllabic languages. The proposed algorithm is designed to partition words into its syllables and then to produce their shorter bit representations for compression. The method has six main components namely source file, filtering unit, syllable unit, compression unit, dictionary file and target file. The number of bits in coding syllables depends on the number of entries in the dictionary file. The proposed algorithm is implemented and tested using 20 different texts of different lengths collected from different fields. The results indicated a compression of up to 43%.", "num_citations": "22\n", "authors": ["1208"]}
{"title": "Evaluating open source software quality models against ISO 25010\n", "abstract": " Quite a number of open source software quality models exist today. These models emerged as a result of the need to measure quality in open source software, which is quite unlike closed source, or proprietary software. ISO 9126 standard forms the basis from which most of these models derive. However, ISO 9126 standard has been replaced by ISO 25010. Therefore, as research endeavors progress towards evolving the \"silver bullet\" open source software quality model, it is the aim of this paper to evaluate existing open source software quality models against the ISO 25010 standard. The findings from this study reveal a candidate model (from among the existing models) that can be leveraged in deriving a generic open source software quality model.", "num_citations": "21\n", "authors": ["1208"]}
{"title": "Estimating quality of JavaScript\n", "abstract": " This paper proposes a complexity metric for Java script since Javascript is the most popular scripting language that can run in all of the major web browsers. The proposed metric \u00b3Javascript Cognitive Complexity Measure (JCCM) is intended to assess the design quality of scripts. The metrics has been evaluated theoretically and validated empirically through real test cases. The metric has also been compared with other similar metrics. The theoretical, empirical validation and comparative study prove the worth and robustness of the metric.", "num_citations": "21\n", "authors": ["1208"]}
{"title": "A discussion on assuring software quality in small and medium software enterprises: An empirical investigation\n", "abstract": " Under the studies of general core activities including software inspection, review and testing to achieve quality objectives in small-medium size enterprises (SMEs), the paper presents a contemporary view of such companies against quality measures. The results from a local empirical investigation of quality standards in the Turkish software industry are reported. Around 150 software companies have been approached from which 17 detailed feedback inform that in order to ensure software quality, standards including internationally recognized International Standards Organization (ISO) and Capability Maturity Model Integration (CMMI) are given credit. However the substantial workload and resources required to obtain them are also reported as serious; downscaled frameworks of such large models proposed in the literature are not well known by the SMEs either. The paper also discusses\" work around\" that bypasses such standards to ease delivery of products while keeping certificates as labels just to acquire new jobs for the business.", "num_citations": "21\n", "authors": ["1208"]}
{"title": "ESR of copper-doped sodium citrate\n", "abstract": " Single crystal ESR spectra of Cu 2+ ion doped in sodium citrate are reported at room temperature. The observed spectra are fitted to a spin-Hamiltonian of rhombic symmetry with g x= 2.1076\u00b10.002, g y= 2.1289\u00b10.002, g z= 2.4454\u00b10.002, A x=(40\u00b12) 10-4 cm-1, A y=(62\u00b12) 10-4 cm-1 and A z=(78\u00b12) 10-4 cm-1. It is found that Cu 2+ enters the lattice as a substitutional impurity replacing an Na+ ion. The ground state wave function of Cu 2+ ion in this lattice is also determined from the spin-Hamiltonian constants obtained from ESR results. It is found that the ground state is predominantly| x 2-y 2>. With the help of the optical absorption study, the nature of bonding in the complex has also been discussed.", "num_citations": "21\n", "authors": ["1208"]}
{"title": "Anomaly detection using fuzzy Q-learning algorithm\n", "abstract": " Wireless networks are increasingly overwhelmed by Distributed Denial of Service (DDoS) attacks by generating flooding packets that exhaust critical computing and communication resources of a victim\u2019s mobile device within a very short period of time. This must be protected. Effective detection of DDoS attacks requires an adaptive learning classifier, with less computational complexity, and an accurate decision making to stunt such attacks. In this paper, we propose an intrusion detection system called Fuzzy Q-learning (FQL) algorithm to protect wireless nodes within the network and target nodes from DDoS attacks to identify the attack patterns and take appropriate countermeasures. The FQL algorithm was trained and tested to establish its performance by generating attacks from the NSL-KDD and CAIDA DDoS Attack datasets during the simulation experiments. Experimental results show that the proposed FQL IDS has higher accuracy of detection rate than Fuzzy Logic Controller and Q-learning algorithm alone.", "num_citations": "20\n", "authors": ["1208"]}
{"title": "Agile software development: it is about knowledge management and creativity\n", "abstract": " Software development is a knowledge intensive activity and its success depends on knowledge and creativity of the developers. In the last years the traditional perspective on software development is changing and agile methods have received considerable attention. The purpose of this paper is to provide an understanding of knowledge management and creativity in relation with new software engineering trends. The implications of these findings are considered, and some possible directions for future research are suggested.", "num_citations": "20\n", "authors": ["1208"]}
{"title": "Network intrusion detection with a hashing based Apriori algorithm using Hadoop MapReduce\n", "abstract": " Ubiquitous nature of Internet services across the globe has undoubtedly expanded the strategies and operational mode being used by cybercriminals to perpetrate their unlawful activities through intrusion on various networks. Network intrusion has led to many global financial loses and privacy problems for Internet users across the globe. In order to safeguard the network and to prevent Internet users from being the regular victims of cyber-criminal activities, new solutions are needed. This research proposes solution for intrusion detection by using the improved hashing-based Apriori algorithm implemented on Hadoop MapReduce framework; capable of using association rules in mining algorithm for identifying and detecting network intrusions. We used the KDD dataset to evaluate the effectiveness and reliability of the solution. Our results obtained show that this approach provides a reliable and effective means of detecting network intrusion. View Full-Text", "num_citations": "19\n", "authors": ["1208"]}
{"title": "A neural network based expert system for the diagnosis of diabetes mellitus\n", "abstract": " Diabetes is a disease in which the blood glucose, or blood sugar levels in the body are too high. The damage caused by diabetes can be very severe and even more pronounced in pregnant women due to the tendency of transmitting the hereditary disease to the next generation. Expert systems are now used in medical diagnosis of diseases in patients so as to detect the ailment and help in providing a solution to it. This research developed and trained a neural network model for the diagnosis of diabetes mellitus in pregnant women. The model is a four-layer feed forward network, trained using back-propagation and Bayesian Regulation algorithm. The input layer has 8 neurons, two hidden layers have 10 neurons each, and the output layer has one neuron which is the diagnosis result. The developed model was also incorporated into a web-based application to facilitate its use. Validation by regression\u00a0\u2026", "num_citations": "19\n", "authors": ["1208"]}
{"title": "Bug severity assessment in cross project context and identifying training candidates\n", "abstract": " The automatic bug severity prediction will be useful in prioritising the development efforts, allocating resources and bug fixer. It needs historical data on which classifiers can be trained. In the absence of such historical data cross project prediction provides a good solution. In this paper, our objective is to automate the bug severity prediction by using a bug metric summary and to identify best training candidates in cross project context. The text mining technique has been used to extract the summary terms and trained the classifiers using these terms. About 63 training candidates have been designed by combining seven datasets of Eclipse projects to develop the severity prediction models. To deal with the imbalance bug data problem, we employed two approaches of ensemble by using two operators available in RapidMiner: Vote and Bagging. Results show that k-Nearest Neighbour (k-NN) performance is better\u00a0\u2026", "num_citations": "19\n", "authors": ["1208"]}
{"title": "An approach for the empirical validation of software complexity measures\n", "abstract": " Software metrics are widely accepted tools to control and assure software quality. A large number of software metrics with a variety of content can be found in the literature; however most of them are not adopted in industry as they are seen as irrelevant to needs, as they are unsupported, and the major reason behind this is due to improper empirical validation. This paper tries to identify possible root causes for the improper empirical validation of the software metrics. A practical model for the empirical validation of software metrics is proposed along with root causes. The model is validated by applying it to recently proposed and well known metrics.", "num_citations": "19\n", "authors": ["1208"]}
{"title": "Cloud-based ERP solution for modern education in Vietnam\n", "abstract": " Enterprise Resource Planning (ERP) and cloud computing are becoming more and more important in the World of Information Technology (IT) and Communication. These are two different sectors of modern information systems, and there are several in-depth investigations about ERP and also cloud computing. Recently, there have been some studies on ERP in cloud computing, but not much work as regards its applications in the field of education has been done. Besides that, deploying traditional ERP systems can be challenging and often costly and resource intensive. However, with the emergence of cloud-based ERP solutions, it has lower cost implications than traditional ERP. In this scenario, implementing a study on cloud-based ERP for modern education is an important and beneficial work. By considering this point, the objective of this research is to approach the relevant concepts multi\u00a0\u2026", "num_citations": "18\n", "authors": ["1208"]}
{"title": "Measurement theory and validation criteria for software complexity measures\n", "abstract": " The relation between measurement theory and evaluating criteria for software complexity measure is well established by several researchers. A new software complexity measure should also be satisfied by measurement theory criteria. However, most of the developers of new complexity measures do not care about measurement theory. In this paper, we evaluate measurement theory and point out why measurement theory is not well applicable for evaluating complexity measure.", "num_citations": "18\n", "authors": ["1208"]}
{"title": "Intrusion detection and prevention systems: an updated review\n", "abstract": " The evolution of Information Technology (IT), cutting across several divides in our daily endeavors allows us to interact with all forms of data at different OSI model layers from application to physical. These data are susceptible to intrusion, aimed at compromising its integrity; thus, the need to protect these data, maintain its integrity, confidentiality, and availability cannot be overemphasized. Intrusion Detection and Prevention System (IDPS) is a device or software application designed to monitor a network or system. It detects vulnerabilities, reports malicious activities, and enacts preventive measures to keep up with the advancement of computer-related crimes using several response techniques. This paper presents an updated review on IDPSs given the fact that the most recent review found on the subject was done in 2016. It will also discuss the use of IDPSs to identify vulnerabilities in various channels\u00a0\u2026", "num_citations": "17\n", "authors": ["1208"]}
{"title": "A binary fruit fly optimization algorithm to solve the set covering problem\n", "abstract": " The Set Covering Problem (SCP) is a well known -hard problem with many practical applications. In this work binary fruit fly optimization algorithms (bFFOA) were used to solve this problem using different binarization methods.                 The bFFOA is based on the food finding behavior of the fruit flies using osphresis and vision. The experimental results show the effectiveness of our algorithms producing competitive results when solve the benchmarks of SCP from the OR-Library.", "num_citations": "17\n", "authors": ["1208"]}
{"title": "Entropy metric for xml dtd documents\n", "abstract": " The eXtensible Markup Language (XML) has been gaining extraordinary acceptance from many diverse enterprise software companies for their object repositories, data interchange, and development tools. Further, many different domains, organizations and content providers have been publishing and exchanging information via internet by the usage of XML and standard schemas. Efficient implementation of XML in these domains requires well designed XML schemas. In this point of view, design of XML schemas plays an extremely important role in software development process and needs to be quantified for ease of maintainability. In this paper, we propose a new metric based on the entropy concept from information theory for the assessment of the structural complexity of XML schema documents written in W3C Document Type Definition (DTD), language. The new metric has been demonstrated with examples\u00a0\u2026", "num_citations": "17\n", "authors": ["1208"]}
{"title": "A step by step guide for choosing project topics and writing research papers in ICT related disciplines\n", "abstract": " ICT is fast-growing and changing field. A lot of researches are being done in various area of ICT, and results are presented in various platforms like conferences, journal and books. This is common observations in the publications from developing countries (especially in sub \u2013 Saharan africa) are not being published in reputed and established publishers even their technical/experiments are good. This is due to lack of several factors including professional presentation, the novelty of the topic, quality of literature review etc. This work guides final year bachelor\u2019s students, PG students (masters and PhD) and young researchers, especially working in computing-related disciplines, on how to convert their project works into quality publications. The authors provide details on how these researchers can select suitable project topics, do a proper review, write up the key components of a paper and present their\u00a0\u2026", "num_citations": "16\n", "authors": ["1208"]}
{"title": "Assessing cognitive complexity in java-based object-oriented systems: Metrics and tool support\n", "abstract": " Software cognitive complexity refers to how demanding the mental process of performing tasks such as coding, testing, debugging, or modifying source code is. Achieving low levels of cognitive complexity is crucial for ensuring high levels of software maintainability, which is one of the most rewardful software quality attributes. Therefore, in order to control and ensure software maintainability, it is first necessary to accurately quantify software cognitive complexity. In this line, this paper presents a software metric to assess cognitive complexity in Object-Oriented (OO) systems, and particularly those developed in the Java language, which is very popular among OO programming languages. The proposed metric is based on a characterization of basic control structures present in Java systems. Several algorithms to compute the metric and their materialization in the Eclipse IDE are also introduced. Finally, a theoretical validation of the metric against a framework specially designed to validate software complexity metrics is presented, and the applicability of the tool is shown by illustrating the metric in the context of ten real world Java projects and relevant metrics from the well-known Chidamber-Kemerer metric suite.", "num_citations": "16\n", "authors": ["1208"]}
{"title": "Computational Science and Its Applications-ICCSA 2014: 14th International Conference, Guimar\u00e3es, Portugal, June 30-July 3, 204, Proceedings, Part V\n", "abstract": " The six-volume set LNCS 8579-8584 constitutes the refereed proceedings of the 14th International Conference on Computational Science and Its Applications, ICCSA 2014, held in Guimar\u00e3es, Portugal, in June/July 2014. The 347 revised papers presented in 30 workshops and a special track were carefully reviewed and selected from 1167. The 289 papers presented in the workshops cover various areas in computational science ranging from computational science technologies to specific areas of computational science such as computational geometry and security.", "num_citations": "16\n", "authors": ["1208"]}
{"title": "Reconfiguration approaches in wireless sensor network: issues and challenges\n", "abstract": " This paper surveys reconfiguration approaches in Wireless Sensor Network applications. It relays the challenges associated with the different approaches explored as well as prevailing efforts currently in use at addressing them. It also suggests a model that employs context information in deciding the most appropriate reconfiguration approach to employ via the use of fuzzy logic. The idea is to reduce operational demands (overheads) placed on the entire network during software updates.", "num_citations": "16\n", "authors": ["1208"]}
{"title": "A model for measuring cognitive complexity of software\n", "abstract": " This paper proposes a model for calculating cognitive complexity of a code. This model considers all major factors responsible for (cognitive) complexity. The practical applicability of the measure is evaluated through experimentation, test cases and comparative study.", "num_citations": "16\n", "authors": ["1208"]}
{"title": "Determining suitability of speech-enabled examination result management system\n", "abstract": " The focus of this study is to determine the suitability of speech-enabled examination result management system as a tool for checking and managing students\u2019 examination results. The theory of task-technology fit was used to identify the factors that significantly influence the use of the system. 374 verified data from students and instructors that responded to the questionnaire were analyzed and reported. The factors investigated in this study were cost, task, mobility, attitude, fitness, performance and utilization. Structural equation modeling was engaged to study the relationship between the variables and also analyze the data. The outcome of the constructed model proved that mobility, task and cost had significant influence on the fitness of the system.", "num_citations": "15\n", "authors": ["1208"]}
{"title": "Reconstruction of 3D object shape using hybrid modular neural network architecture trained on 3D models from ShapeNetCore dataset\n", "abstract": " Depth-based reconstruction of three-dimensional (3D) shape of objects is one of core problems in computer vision with a lot of commercial applications. However, the 3D scanning for point cloud-based video streaming is expensive and is generally unattainable to an average user due to required setup of multiple depth sensors. We propose a novel hybrid modular artificial neural network (ANN) architecture, which can reconstruct smooth polygonal meshes from a single depth frame, using a priori knowledge. The architecture of neural network consists of separate nodes for recognition of object type and reconstruction thus allowing for easy retraining and extension for new object types. We performed recognition of nine real-world objects using the neural network trained on the ShapeNetCore model dataset. The results evaluated quantitatively using the Intersection-over-Union (IoU), Completeness, Correctness and Quality metrics, and qualitative evaluation by visual inspection demonstrate the robustness of the proposed architecture with respect to different viewing angles and illumination conditions. View Full-Text", "num_citations": "15\n", "authors": ["1208"]}
{"title": "Cloud ownership and reliability\u2013issues and developments\n", "abstract": " Cloud computing is a composite paradigm that provides crucial services to individuals and organisations over networked infrastructure at a cost. The Cloud provides custom built applications, made available by a CSP to customers. Several customers can access an instance of one application. The Cloud also affords an avenue for customers to build their own application in a language compatible with a CSP and subsequently deploy that application on the Cloud. In addition, massive scalable storage and computing devices are available on the Cloud. A customers expects optimum services whenever and wherever it is required. Hence, system failure on the part of a CSP must not affect the services being provided to the customer. This paper examines present trends in the area of Cloud ownership reliability and provides a guide for future research. The paper aims to answer the following question: what is\u00a0\u2026", "num_citations": "15\n", "authors": ["1208"]}
{"title": "Solving manufacturing cell design problems by using a dolphin echolocation algorithm\n", "abstract": " The Manufacturing Cell Design is a problem that consist in organize machines in cells to increase productivity, i.e., minimize the movement of parts for a given product between machines. In order to solve this problem we use a Dolphin Echolocation algorithm, a recent bio-inspired metaheuristic based on a dolphin feature, the echolocation. This feature is used by the dolphin\u00a0to search all around the search space for a target, then the dolphin exploits the surround area in order to find promising solutions. Our approach has been tested by using a set of 10 benchmark instances with several configurations, reaching to optimal values for all of them.", "num_citations": "15\n", "authors": ["1208"]}
{"title": "Overcoming barriers of effective health care delivery and electronic health records in Nigeria using socialized medicine\n", "abstract": " Health care system in Nigeria is currently in a state of anomie, preventable and curable diseases such as maternal mortality, diabetes, high blood pressure and other controllable diseases have been shockingly high. At the heart of transformation is the electronic medical record (EMR) which integrates patient's data and information, from registration to billing and payment into a single electronic record. With these, health care providers can easily and dynamically improve quality of care while at the same time lowering their cost. Despite the great characteristics of cloud computing, they haven't been utilized fairly yet in the health care industry. The use of online social networks explores an infrastructure with reduced initial costs and rapid application development. Facebook and Twitter can be used as an example of remote monitoring because of its flexibility; user defined applications and can be modified to suit\u00a0\u2026", "num_citations": "15\n", "authors": ["1208"]}
{"title": "Choice functions for autonomous search in constraint programming: GA vs. PSO\n", "abstract": " The variable and value ordering heuristics are a key element in Constraint Programming. Known together as the enumeration strategy they may have important consequences on the solving process. However, a suitable selection of heuristics is quite hard as their behaviour is complicated to predict. Autonomous search has been recently proposed to handle this concern. The idea is to dynamically replace strategies that exhibit poor performances by more promising ones during the solving process. This replacement is carried out by a choice function, which evaluates a given strategy in a given amount of time via quality indicators. An important phase of this process is performed by an optimizer, which aims at finely tuning the choice function in order to guarantee a precise evaluation of strategies. In this paper we evaluate the performance of two powerful choice functions: the first one supported by a genetic algorithm and the second one by a particle swarm optimizer. We present interesting results and we demonstrate the feasibility of using those optimization techniques for Autonomous Search in a Constraint Programming context.", "num_citations": "15\n", "authors": ["1208"]}
{"title": "A suite of cognitive complexity metrics\n", "abstract": " In this paper, we propose a suite of cognitive metrics for evaluating complexity of object-oriented (OO) codes. The proposed metric suite evaluates several important features of OO languages. Specifically, the proposed metrics are to measure method complexity, message complexity (coupling), attributes complexity and class complexity. We propose also a code complexity by considering the complexity due to inheritance for the whole system. All these proposed metrics (except attribute complexity) use the cognitive aspect of the code in terms of cognitive weight. All the metrics have critically examined through theoretical and empirical validation processes.", "num_citations": "15\n", "authors": ["1208"]}
{"title": "Complexity metrics for cascading style sheets\n", "abstract": " Web applications are becoming important for small and large companies since they are integrated with their business strategies. Cascading Style Sheets (CSS) however are an integral part of contemporary Web applications that are perceived as complex by users and this result in hampering its widespread adoption. The factors responsible for CSS complexity include size, variety in its rule block structures, rule block reuse, cohesion and attribute definition in rule blocks. In this paper, we have proposed relevant metric for each of the complexity factors. The proposed metrics are validated through a practical framework. The outcome shows that the proposed metrics satisfy most of the parameters required by the practical framework hence establishing them as well structured.", "num_citations": "15\n", "authors": ["1208"]}
{"title": "Using a weightless neural network to forecast stock prices: A case study of Nigerian stock exchange\n", "abstract": " This research work, proposes forecasting stock prices in the stock market industry in Nigeria using a Weightless Neural Network (WNN). A neural network application used to demonstrate the application of the WNN in the forecasting of stock prices in the market is designed and implemented in Visual Foxpro 6.0. The proposed network is tested with stock data obtained from the Nigeria Stock Exchange. This system is compared with Single Exponential Smoothing (SES) model. The WNN error value is found to be 0.39 while that of SES is 9.78, based on these values, forecasting with the WNN is observed to be more accurate and closer to the real data than those using the SES model.", "num_citations": "15\n", "authors": ["1208"]}
{"title": "People management in software industry: the key to success\n", "abstract": " Performance differences have been proved among software professionals even in the conditions of identical task. Companies and organizations are aware of the fact that talent has great effect on their success; still most of the software development organizations are focusing so much on tools and technology and little on people. In this paper, we are trying to uncover the relation between the people management-human resource management and software engineering.", "num_citations": "15\n", "authors": ["1208"]}
{"title": "A cloud-based intelligent toll collection system for smart cities\n", "abstract": " Electronic Toll Collection (ETC) systems may be adopted by city managers to combat the problems of long vehicular queues, fuel wastage, high accident risks, and environmental pollution that come with the use of traditional or manual toll collection systems. In this paper, an intelligent system is developed to eliminate long vehicular queues, fuel wastage, high accident risks, and environmental pollution in a smart city based on seamless interconnections of Wireless Sensor Networks (WSNs), and web and mobile applications that run on an Internet of Things (IoT)-Enabled cloud platform. A ZigBee WSN is designed and implemented using an Arduino UNO, XBee S2 radios, an XBee Shield, and a Seeduino GPRS Shield. For vehicle owners to make toll payments, view toll historical data, and get toll news feeds, a web application and a mobile application are designed and implemented based on Hyper Text\u00a0\u2026", "num_citations": "14\n", "authors": ["1208"]}
{"title": "Assessing the coverage of e-health services in sub-saharan africa\n", "abstract": " Background: E-Health has attracted growing interests globally. The relative lack of facilities, skills, funds and information on existing e-Health initiatives has affected progress on e-Health in Africa.     Objectives: To review publicly available literature on e-Health in sub-Saharan Africa (sSA) towards providing information on existing and ongoing e-Health initiatives in the region.     Methods: Searches of relevant literature were conducted on Medline, EMBASE and Global Health, with search dates set from 1990 to 2016. We included studies on e-Health initiatives (prototypes, designs, or completed projects) targeting population groups in sSA.     Results: Our search returned 2322 hits, with 26 studies retained. Included studies were conducted in 14 countries across the four sub-regions in sSA (Central, East, South and West) and spreading over a 12-year period, 2002-2014. Six types of e-Health interventions were\u00a0\u2026", "num_citations": "14\n", "authors": ["1208"]}
{"title": "Analysis of nutritional deficiency in citrus species tree leaf using image processing\n", "abstract": " Citrus trees are the nutrition food for humans as well as animals. However, due to the uncertain climatic conditions, it will prone to different pathological disorders because of the nutritional deficiency. In Vidarbha regions, citrus suffer from certain deficiencies of essential elements, in which plants gain from the soil. The segmentation of disease symptoms in citrus leaf images can be a valuable aid for the detection of nutritional deficiencies and disorders. In this research, different digital image segmentation techniques have been employed which analyses the regions of the citrus leaf caused by some diseases such as spots and wavy structure. This paper investigates the abnormalities in citrus leaf caused by the diseases by the segmentation methodologies. The nutritional deficiency of the citrus tree is directly reflected on its plants. If any temporal part of the symptom is disconnected then, it can be segmented to its\u00a0\u2026", "num_citations": "14\n", "authors": ["1208"]}
{"title": "An analysis of techniques and tools for requirements elicitation in model-driven web engineering methods\n", "abstract": " Until now, is well-known that Requirements Engineering (RE) is one of the critical factors for success software. In current literature we can find several reasons of this affirmation. One particular phase, which is vital for developing any new software application is the Requirements Elicitation, is spite of this, most of the development of new software fail because of wrong elicitation phase. Several proposals exist for Requirements Elicitation in Software Engineering, but in the current software development market is focusing on the development of Web and mobile applications, specially using Model-Driven methods, that\u2019s the reason why we asume that it is necessary to know the Elicitation techniques applied in Model-Driven Web Engineering. To do this, we selected the most representative methods such as NDT, UWE and WebML. We have reviewed 189 publications from ACM, IEEE, Science Direct, DBLP and\u00a0\u2026", "num_citations": "14\n", "authors": ["1208"]}
{"title": "An approach for e-commerce on-demand service-oriented product line development\n", "abstract": " The growth of Small, Medium and Micro Enterprises (SMMEs) is important to the economic development of Africa. This growth can be greatly enhanced by leveraging IT in business activities since e-commerce is a vital tool to allow participation in globalization. Many SMMEs cannot afford to own e-commerce facilities and to reduce cost. An SMME can pay for just the e-commerce facility they use without owning the services or infrastructure. Due to the dynamic nature of the business domain, delivering such on-demand functionalities involves high flexibility in adapting to new client requirements; therefore, a systematic approach to software component reuse must be adopted to reduce cost and the time to market for new products. This work explores the reuse capabilities of a hybridization of Service Oriented Architecture (SOA) and Software Product Line (SPL).", "num_citations": "14\n", "authors": ["1208"]}
{"title": "Unified complexity measure: a measure of complexity\n", "abstract": " This paper proposes a new complexity metric. The proposed metric is a unified complexity measure (UCM) and includes all major factors responsible for the complexity of a program including cognitive aspects. The applicability of the measure is evaluated through empirical, theoretical and practical validation processes. The test cases and comparative study prove its soundness and robustness.", "num_citations": "14\n", "authors": ["1208"]}
{"title": "A new complexity metric based on cognitive informatics\n", "abstract": " In this paper, a new complexity metric based on cognitive informatics is proposed for object oriented(OO) code. This is the single metric, which covers cognitive complexity of the OO system, method complexity and complexity due to inheritance together. The proposed metric was evaluated against Weyuker set of measurement principles. It was found that seven Weyuker properties are satisfied by this measure.", "num_citations": "14\n", "authors": ["1208"]}
{"title": "Comparative evaluation of mobile forensic tools\n", "abstract": " Mobile technology, over the years, has improved tremendously in sophistication and functionality. Today, there are mobile phones, known as smartphones, that can perform virtually most functions associated with personal computers. This has translated to increase in the adoption of mobile technology. Consequently, there has been an increase in the number of attacks against and with the aid of this technology. Mobile phones will often contain data that are needed as evidence in a court of law. And, therefore, the need to be able to acquire and present this data in an admissible form cannot be overemphasized. This requires the right forensic tools. This is the focus of this study. We evaluated the ability of four forensic tools to extract data, with emphasis on deleted data, from Android phones. Our results show that AccessData FTK Imager and EnCase performed better than MOBILedit Forensic and Oxygen Forensic Suite at acquiring deleted data. The conclusion is that, finding a forensic tool or toolkit that is virtually applicable across all mobile device platforms and operating systems is currently infeasible.", "num_citations": "13\n", "authors": ["1208"]}
{"title": "Developing a mobile application for taxi service company in Nigeria\n", "abstract": " Transportation is an issue of concern in big cities of many developing countries today. Due to the large population in these cities, there is constant traffic congestion and pollution. As a result taxi services are common. In Nigeria, companies offering these services have discovered that they can better serve the large population by providing their services through the mobile platform. Given the wide spread adoption of smart phones in these regions, we designed, developed and deployed an Android-based application for one of the taxi service company called Red Cab. The application makes it easier for Red Cab to cater for its current customers and also reach out to newer ones.", "num_citations": "13\n", "authors": ["1208"]}
{"title": "Using big data technology to contain current and future occurrence of Ebola Viral Disease and other epidemic diseases in West Africa\n", "abstract": " West Africa is currently plagued with Ebola Viral Disease (EVD) and other minor epidemic diseases which has led to major economic meltdown and high mortality rate in countries like Guinea, Sierra Leone and Liberia as a result of immigration, emigration, foreign trade and investment, bilateral, poor health care issues amidst others. Harmonized EVD related data can help identify individuals who are at risk of contracting the terminal disease and at the same time controlling the outbreak which will in turn lower cost of health care across West Africa. This paper presents the significance, framework as well as an implementation plan and design for using Big Data Technologies (BDT) as an aid to prevent and control EVD in West Africa and the provision of how the principles of cloud computing could be applied to present and impending expectations of the West African Health sector.", "num_citations": "13\n", "authors": ["1208"]}
{"title": "An empirical validation of the complexity of code changes and bugs in predicting the release time of open source software\n", "abstract": " With the increasing popularity of open source software, the changes in source code are inevitable. These changes in code are due to feature enhancement, new feature introduction and bug repair or fixed. It is important to note that these changes can be quantified by using entropy based measures. The pattern of bug fixing scenario with complexity of code change is responsible for the next release as these changes will cover the number of requirements and fixes. In this paper, we are proposing a method to predict the next release problem based on the complexity of code change and bugs fixed. We applied multiple linear regression to predict the time of the next release of the product and measured the performance using different residual statistics, goodness of fit curve and R2. We observed from the results of multiple linear regression that the predicted value of release time is fitting well with the observed value of\u00a0\u2026", "num_citations": "13\n", "authors": ["1208"]}
{"title": "ESR of copper doped calcium propionate\n", "abstract": " Electron spin resonance (ESR) of Cu 2+ doped calcium propionate has been studied at room temperature. Spin Hamiltonian parameters are calculated from the ESR absorption spectra which are gx= 2.1285\u00b10.002, gy= 2.1868\u00b10.002, gz= 2.2205\u00b10.002, Ax=(121\u00b12)\u00d7 10\u2212 4 cm\u2212 1, Ay=(140\u00b12)\u00d7 10\u2212 4 cm\u2212 1 and Az=(142\u00b12)\u00d7 10\u2212 4 cm\u2212 1. It is found that Cu 2+ enters the lattice interstitially. The ESR results indicate that the copper complex possesses rhombic symmetry. The ground state wave function of Cu 2+ ion in this lattice is also determined from the spin-Hamiltonian constants obtained from ESR results. It is found that the ground state is predominantly| x 2\u2212 y2\u232a.", "num_citations": "13\n", "authors": ["1208"]}
{"title": "Secure ear biometrics using circular kernel principal component analysis, Chebyshev transform hashing and Bose\u2013Chaudhuri\u2013Hocquenghem error-correcting codes\n", "abstract": " Ear biometrics has generated an increased interest in the domain of biometric identification systems due to its robustness and covert acquisition potential. The external structure of the human ear has a bilateral symmetry structure. Here, we analyse ear biometrics based on ear symmetry features. We apply iterative closest point and kernel principal component analysis with circular kernel for feature extraction while using a circular kernel function, combined with empirical mode decomposition into intrinsic mode functions perceptual hashing using and fast Chebyshev transform, and a secure authentication approach that exploits the discrete logarithm problem and Bose\u2013Chaudhuri\u2013Hocquenghem error-correcting codes to generate 128-bit crypto keys. We evaluate the proposed ear biometric cryptosecurity system using our data set of ear images acquired from 103 persons. Our results show that the ear biometric\u00a0\u2026", "num_citations": "12\n", "authors": ["1208"]}
{"title": "Forensic analysis of mobile banking apps\n", "abstract": " Over the years, the proliferation of mobile banking applications has been on the increase. Financial institutions are taking advantage of mobile technology to provide accessible, ubiquitous, user-friendly, convenient, and cost-effective services to their customers. The mobile banking applications access and process sensitive user data. As such, they are required to manage such data in a high secure manner and run in secure environment. This study conducts a forensic investigation of twelve popular Android m-banking apps in Nigeria to determine if the generated backups by the mobile OS do not save sensitive data; the application removes sensitive data from view when backgrounded; sensitive data are not held longer than necessary in the memory, with the memory cleared after use; minimum device access security policies are enforced by the app, and users are educated by the app about the type of\u00a0\u2026", "num_citations": "12\n", "authors": ["1208"]}
{"title": "Software reliability assessment using machine learning technique\n", "abstract": " Software reliability is one of the major attributes in software quality assurance system. A large number of research works have been attempted in order to improve the reliability of the software. Research directions in improving software reliability may be defined in a three-step process i.e., software modeling, software measurement and software improvement. Each of these phases is equally important in obtaining reliable software system. It is important to achieve better accuracy in estimating reliability in order to manage the software quality. A number of metrics have been proposed in the literature to evaluating the reliability of a software. Machine learning approaches are found to be suitable ways in evaluating different parameters of software reliability. Several machine learning techniques have been evolved in order to capture the different characteristics of a software system. The machine learning\u00a0\u2026", "num_citations": "12\n", "authors": ["1208"]}
{"title": "Cloud based simple employee management information system: a model for african small and medium enterprises\n", "abstract": " Cloud computing is gradually becoming accepted in different sectors and businesses are beginning to adopt the concept\u2019s shared infrastructure and applications. The aim of this paper is to design and implement a simple prototype of a cloud based application for SMEs to manage their human resources challenges. The choice of an Employee Information Management System (EIMS) is due to the fact that one of the basic challenges of SMEs is human resource management and how to effectively manage employee information. The prototype developed in this study is targeted at the Software as a Service (SaaS) layer of the cloud framework. It leverages on existing cloud platform providers to deliver four core modules, which include: payroll management, record management, leave management and staff appraisal. Among the things this study seeks to achieve is a cheaper and cost effective solution to some\u00a0\u2026", "num_citations": "12\n", "authors": ["1208"]}
{"title": "Application of ICT by small and medium enterprises in Ogun State Nigeria\n", "abstract": " Small and medium enterprises (SMEs) have emerged as promising opportunities to eliminate and reduce unemployment globally. Increasing levels of technological advancement has revolutionized the dynamics of the business terrain. However, SMEs in developing countries are yet to fully explore the benefits of Information and Communications Technology (ICT). Survey data was collected from 75 SME ICT users in Abeokuta and Otta through a structured questionnaire using stratified random sampling technique. Results of regression analysis revealed that demographic variable (Staff Strength) significantly influences ICT application among SMEs while SME service delivery had no influence. Also, analysis of variance on the categories of SMEs was not a determinant factor on the use of ICT. The outcome of this study has implications for owners of SMEs, stakeholders, government and academic\u00a0\u2026", "num_citations": "12\n", "authors": ["1208"]}
{"title": "A comparative study of e-Government successful implementation between Nigeria and Republic of Korea\n", "abstract": " Many countries in the world have now realized the relevance of adopting e-Government as a medium for providing effective and citizen-centered services. Developing countries like Nigeria have adopted e-government and are taking yet another step at improving their ranking in the United Nations (UN) e-Government Survey carried out bi-annually. The Federal Government of Nigeria in February, 2014 contracted the Korea International Cooperation Agency (KOICA) to evolve an e-Government master plan that will ensure total compliance with e-government practices worldwide. This paper investigates the e-government position in Nigeria and compares it with that of South Korea. The study is used the e-Government survey reports carried out by the UN for the period covering 2008 to 2014. The results present lessons learnt from South Korea and the measures Nigeria needs to put in place in order to improve her\u00a0\u2026", "num_citations": "12\n", "authors": ["1208"]}
{"title": "Application of an extended sysml requirements diagram to model real-time control systems\n", "abstract": " Most techniques for modeling requirements present many problems and limitations, including modeling requirements at a single level of abstraction, and are specific to model functional requirements. The objective of this article is to perform a study on modeling requirements of Real-Time Systems through an extension of the SysML Requirements Diagram focusing on the traceability of non-functional and functional requirements. The proposed approach has demonstrated to be effective for representing software requirements of real-time systems at multiple levels of abstraction and classification. The proposed metamodel represents concisely the traceability of requirements in a high abstraction level.", "num_citations": "12\n", "authors": ["1208"]}
{"title": "Estimating complexity of programs in Python language\n", "abstract": " In this paper, a complexity metric for Python language is formulated. Since Python is an object oriented language, the present metric is capable to evaluate any object-oriented language. We validate our metric with case study, comparative study and empirical validation. The case study is in Python, Java and C++ and the results prove that Python is better than other object-oriented languages. Later, we validate the metric empirically with a real project, which is developed in Python.", "num_citations": "12\n", "authors": ["1208"]}
{"title": "Efficient bit-parallel multi-patterns approximate string matching algorithms\n", "abstract": " Multi-patterns approximate string matching (MASM) problem is to find all the occurrences of set of patterns P0, P1, P2...Pr-1, rge;1, in the given text T[0hellip;n-1], allowing limited number of errors in the matches. This problem has many applications in computational biology viz. finding DNA subsequences after possible mutations, locating positions of a disease(s) in a genome etc. The MASM problem has been previously solved by Baeza-Yates and Navarro by extending the bit-parallel automata (BPA) of approximate matching and using the concept of classes of characters. The drawbacks of this approach are: (a) It requires verification for the potential matches and, (b) It can handle patterns of length less than or equal to word length (w) of computer used. In this paper, we propose two new bit-parallel algorithms to solve the same problem. These new algorithms requires no verification and can handle patterns of\u00a0\u2026", "num_citations": "12\n", "authors": ["1208"]}
{"title": "Complexity metric for XML schema documents\n", "abstract": " Web Services, as a new type of distributed application, use XML documents for their data representations, so design of XML schemas play an important role in software development process and needs to be quantified for ease of maintainability. In this paper, we propose a new complexity metric for XML Schema documents (XSD). On the contrary of the available complexity metrics, the proposed metric is based on the internal architecture of the XSD components and hence considers the complexities of its building components. The proposed metric has been demonstrated with examples. Further a comparative study with other similar metrics proves its soundness and robustness.", "num_citations": "12\n", "authors": ["1208"]}
{"title": "Long short-term memory model for time series prediction and forecast of solar radiation and other weather parameters\n", "abstract": " Interest in the solar radiation and associated meteorological variables have been growing over the years due to their effect on energy generation, agriculture and food security, Ozone layer and other industrial applications. Hence, forecasting these variables in long-term and short-terms using various fusions of measured weather parameters has become a major research focus in many regions. However, developing and selecting an accurate model for the prediction of solar radiation based on several weather parameters is still a challenging task. In this study, a time series model for predicting and forecasting Solar Radiation and other weather parameters was developed using Long Short-Term Memory (LSTM). A publicly available dataset of Mowo, Osun State, Nigeria containing Longitude and Latitude, Elevation, Maximum Temperature, Minimum Temperature, Precipitation, Wind speed, Relative Humidity, Solar\u00a0\u2026", "num_citations": "11\n", "authors": ["1208"]}
{"title": "An improved model for alleviating layer seven distributed denial of service intrusion on webserver\n", "abstract": " Application layer or Layer Seven Distributed Denial of service (L7DDoS) intrusion is one of the greatest threats that intrusion a webserver. The hackers have different motives which could be for Extortion, Exfiltration e.t.c Researchers have employed several methods to prevent L7DDoS intrusion especially using machine learning. Although Machine learning techniques has proven to be very effective with high detection accuracy, the approach still find it difficult to detect Hyper Text Transfer Protocol (HTTP) based botnet traffic on web server with high false positive rate. The adoption of deep learning based technique using Long Short Term Memory (LSTM) will alleviate this problem.", "num_citations": "11\n", "authors": ["1208"]}
{"title": "Cloud computing security with collaborating encryption\n", "abstract": " The security of bigger data is the bottleneck in the encryption and decryption because of the big data size. The single encryption technique using one source is not adequate to accomplish the big data cloud computing security. This paper elaborates the working of cloud computing and the collaborating source security system for the Big Data security. A collaborating encryption technique framework is proposed in this paper to meet the futures\u2019 faster encryption requirements. The traditional information security system is not capable to provide the complete security during the cloud computing. The method described in this research comprises the parallel and distributed encryption system which gets the benefits the homomorphic encryption technique. The encryption facility during the mobile communication of object is tedious. Every cloud has its own security features and can be working in collaboration with the other cloud servers. Therefore, the parallel and distributed encryption facilities can be possible at every next door of other cloud without breaking the sequence of encryption process. The essential resources become the remote resources and the allocation of these resources can be managed at every cloud. Most of the time while working with the cloud computing is the availability of network and other resources. Providing the information security in the unavailability of resources during encryption and decryption is a difficult task. The collaboration encryption technique is a framework where, different clouds can work in parallel with the distributed processing. The security mechanism is improved by the homomorphic encryption.", "num_citations": "11\n", "authors": ["1208"]}
{"title": "A teaching-learning-based optimization algorithm for solving set covering problems\n", "abstract": " The Set Covering Problem (SCP) is a representation of a kind of combinatorial optimization problem which has been applied in several problems in the real world. In this work we used a binary version of Teaching-Learning-Based Optimization (TLBO) algorithm to solve SCP, works with two phases known: teacher and learner; emulating the behavior into a classroom. The proposed algorithm has been tested on 65 benchmark instances. The results show that it has the ability to produce solutions competitively.", "num_citations": "11\n", "authors": ["1208"]}
{"title": "Knowledge Management and Creativity Practices in Software Engineering.\n", "abstract": " An increasing number of organizations are trending to teams for innovation and creativity. In software engineering it is the same, in the last years the traditional perspective on software development is changing and agile methods have received considerable attention. Among other attributes, the agilists claim that fostering knowledge sharing and creativity is one of the keys to response to common problems and challenges of software development today. The development of new software products requires the generation of novel and useful ideas. Here, we fixed some concepts from knowledge management and creativity in relation with new software engineering trends.", "num_citations": "11\n", "authors": ["1208"]}
{"title": "A unique complexity metric\n", "abstract": " Metrics, in general, are defined as \u201ca quantitative measure of the degree to which a system, component, or process possesses a given attribute\u201d. Complexity metrics are used to predict critical information about reliability and maintainability of software systems. This paper proposes complexity metric, which includes all major factors responsible for complexity. We validated our metric against the principles of measurement theory since the measurement theory has been proposed and extensively used in the literature as a means to evaluate the software engineering metrics. The scale of the metric is investigated through Extensive structure. It is found that the proposed measure is on ratio scale. The applicability of the proposed measure is tested through test cases and comparative study.", "num_citations": "11\n", "authors": ["1208"]}
{"title": "Agile Project Development Issues During COVID-19\n", "abstract": " Today\u2019s software development business is very much dynamic, and industries are changing their software development and requirements ways to meet the new changes in the environment. The environment also demands the rapid development and delivery of the product. In fast-changing environment and demands, agile methodology is the most useful development method. It gains fame due to its unique features that facilitate the software development more efficiently, client developer relation, rapid delivery of the product, and allow changes at any stage of the project, and client satisfaction. Currently, the world is suffering under a pandemic situation due to the COVID-19 disease. The disease spread with the close interaction with the human, for this reason many thousands of developers started working from home. The software industries working with the agile methodology are facing many issues to meet\u00a0\u2026", "num_citations": "10\n", "authors": ["1208"]}
{"title": "An ontology-based security risk management model for information systems\n", "abstract": " Security risk management is a knowledge-intensive procedure that requires monitoring and capturing relevant information that can assist in making the right decision by managers. In this paper, a semantically enhanced model for security management during the information system lifetime is proposed. The model supports the continuous collection of identified threat behaviours from the intrusion detection system, filtering and analysis of the threats within a time snapshot and re-appraiser of IS security countermeasures which involves the security administrator (S-Admin), managers, IS and security management system as stakeholders. The probe agent categorizes the security threats identified by the IDS using the developed ontology-driven knowledge base, while the likelihood of threats occurring in real time was obtained using long-term frequency probability. The case-based reasoning paradigm is employed for\u00a0\u2026", "num_citations": "10\n", "authors": ["1208"]}
{"title": "Prospects of ocean-based renewable energy for West Africa\u2019s sustainable energy future\n", "abstract": " PurposeThe limited supply of fossil fuels, constant rise in the demand of energy and the importance of reducing greenhouse emissions have brought the adoption of renewable energy sources for generation of electrical power. One of these sources that has the potential to supply the world\u2019s energy needs is the ocean. Currently, ocean in West African region is mostly utilized for the extraction of oil and gas from the continental shelf. However, this resource is depleting, and the adaptation of ocean energy could be of major importance. The purpose of this paper is to discuss the possibilities of ocean-based renewable energy (OBRE) and analyze the economic impact of adapting an ocean energy using a thermal gradient (OTEC) approach for energy generation.", "num_citations": "10\n", "authors": ["1208"]}
{"title": "COBOL systems migration to SOA: assessing antipatterns and complexity\n", "abstract": " SOA and Web Services allow users to easily expose business functions to build larger distributed systems. However, legacy systems\u2013mostly in COBOL\u2013are left aside unless applying a migration approach. Main approaches are: direct and indirect migration. The former implies to wrap COBOL programs with a thin layer of a Web Service oriented language/platform. The latter needs reengineering COBOL functions to a modern language/platform. In a previous work, we presented an intermediate approach based on direct migration where developed Web Services are later refactored to improve their interfaces quality. Refactorings mainly capture good practices inherent to indirect migration. For this, antipatterns for WSDL documents (common bad practices) are detected to prevent issues related to WSDLs understanding and discoverability. In this paper, we assess antipatterns of Web Services\u2019 WSDL documents generated upon the three migration approaches. In addition, generated Web Services\u2019 interfaces are measured in complexity to attend both comprehension and interoperability. We apply a metric suite (by Baski & Misra) to measure complexity on services interfaces\u2013ie, WSDL documents. Migrations of two real COBOL systems upon the three approaches were assessed on antipatterns evidences and the complexity level of the generated WSDL documents.", "num_citations": "10\n", "authors": ["1208"]}
{"title": "An educational math game for high school students in Sub-Saharan Africa\n", "abstract": " The concept of educational games is to aid students in understanding various subjects in an interactive and engaging environment. Subjects like mathematics have continued to pose a challenge to many secondary school students in developing countries like Nigeria as seen from recent low performance in the Senior Secondary Certificate Examination (SSCE). Lack of interest is one of the key factors that contribute to the low performance hence there is need for a system that can help to improve student\u2019s interest in mathematics and subsequently their rate of success. The goal of this study is thus to develop an educational game software to help stimulate students\u2019 interest in mathematics and to also help them in understanding and improving their performance in the subject. The game was created by leveraging on the Unity game engine platform and the programming language used for development was C#.", "num_citations": "10\n", "authors": ["1208"]}
{"title": "A critical review of the politics of artificial intelligent machines, alienation and the existential risk threat to America\u2019s labour force\n", "abstract": " While an increasing number of scholars are growing weary about the troubling predictions about when Artificial Intelligent Machines (AIMs) will fully acquire the capacity of intentionality - the ability for AIMs to possess the similitude of human-like knowledge for processing data and the knowledge of what is right and wrong in their own eyes, to the detriment of mankind \u2013 there are scholars who argue that politicians and the powers that be in the American government, have blatantly disregarded the existential threats magnified in the works of scholars like Katja Grace and Kevin Drum who frankly portrayed with some degree of certainty, an era of job apocalypse among other dangers mankind would be exposed to when AIMs eventually take over. Drawing from the Marxian Alienation Theory, the authors examine the degrees of extinction and existential threat imminent on humanity and the justification and\u00a0\u2026", "num_citations": "10\n", "authors": ["1208"]}
{"title": "Image enhancement of lemon grasses using image processing techniques (histogram equalization)\n", "abstract": " Lemon grass a type of medicinal plants has been part of human existence and has been applied in so many ways, like for healing, for drugs and for protection. In this paper, the conventional Histogram Equalization has been used to improve the images of the lemon grasses. MATLAB software was used to display the Histogram as well as the Histogram Equalization of the image of the lemon grasses. Image processing techniques to be used here is Histogram Equalization. The Histogram Equalization is considered, since it is one of the techniques in the enhancement of images and as such is being applied to the medicinal herb which in particular is the lemon grasses. The Histogram Equalization technique used may be seen as a conventional technique but the results obtained demonstrates its capability to improve the appearance of images by bringing out hidden details. The performance of the technique\u00a0\u2026", "num_citations": "10\n", "authors": ["1208"]}
{"title": "Quality model for evaluating platform as a service in cloud computing\n", "abstract": " Cloud computing is a style of computing in which dynamically scalable and often virtualized resources are provided as a service over the Internet. Cloud computing can be offered in three ways namely: Software as a Service (SaaS), Platform as a Service (PaaS), and Infrastructure as a Service (IaaS). Researchers have begun to investigate quality in SaaS and have proposed quality models in this regard. There is however a dearth of literature investigating quality in PaaS and IaaS which form the motivation for this work. In this paper, therefore a model is proposed for evaluating quality of PaaS. We first define key features of PaaS. And then, we derive quality attributes from the key features, and define metrics for the quality attributes. To validate our quality model for PaaS, we conduct assessment based on case studies using the Analytic Hierarchy Process. By using the proposed PaaS quality model\u00a0\u2026", "num_citations": "10\n", "authors": ["1208"]}
{"title": "Software project scheduling using the hyper-cube ant colony optimization algorithm\n", "abstract": " Original scientific paper This paper introduces a proposal of design of Ant Colony Optimization algorithm paradigm using Hyper-Cube framework to solve the Software Project Scheduling Problem. This NP-hard problem consists in assigning tasks to employees in order to minimize the project duration and its overall cost. This assignment must satisfy the problem constraints and precedence between tasks. The approach presented here employs the Hyper-Cube framework in order to establish an explicitly multidimensional space to control the ant behaviour. This allows us to autonomously handle the exploration of the search space with the aim of reaching encouraging solutions.", "num_citations": "10\n", "authors": ["1208"]}
{"title": "Apply agile method for improving the efficiency of software development project at VNG company\n", "abstract": " Software engineering process (SEP) is more and more considered the key factor for any software company to create a better quality software with low costs and high productivity. However, there is a gap between theory and practice of applying modern SEP, such as Agile method, for improving the efficiency of software project management, especially for software companies in a developing country like Vietnam. VNG Corporation, a software company in Vietnam with a lot of small and medium web based software projects, currently meets many difficulties in ensuring the success of these projects. The current approach for software development is no longer consistent with the increasing requirements and flexibilities of these projects and VNG is going to find a new method for improving the efficiency of their software projects. In this research, Agile method is applied and tested to check whether it can be a\u00a0\u2026", "num_citations": "10\n", "authors": ["1208"]}
{"title": "Towards developing grid-based portals for e-Commerce on-Demand services on a utility computing platform\n", "abstract": " Trends and current practices in the design and development of grid-enabled portals (GeP) reveal the need to identify and fulfill certain additional relevant requirements in order to build applicable and usable grid-enabled portals for evolving computing platforms such as the utility computing (UC). This paper reports an investigation of the minimum relevant additional requirements that must be fulfilled to attain effective GeP design for UC. A GeP prototype for the Grid-based Utility Infrastructure for Small, Micro, and Medium Enterprises (SMME) Enabling Technology (GUISET) initiative \u2013 a UC platform was developed, and an analytic evaluation experiment undertaken in the study to elicit these additional requirements using a set of benchmark requirements (standards) revealed that it fulfilled the minimum requirements to be suitable for UC context. The result of the study underlines the need for more controlled\u00a0\u2026", "num_citations": "10\n", "authors": ["1208"]}
{"title": "Toward ontology\u2010based risk management framework for software projects: An empirical study\n", "abstract": " Software risk management is a proactive decision\u2010making practice with processes, methods, and tools for managing risks in a software project. Many existing techniques for software project risk management are textual documentation with varying perspectives that are nonreusable and cannot be shared. In this paper, a life\u2010cycle approach to ontology\u2010based risk management framework for software projects is presented. A dataset from literature, domain experts, and practitioners is used. The identified risks are refined by 19 software experts; risks are conceptualized, modeled, and developed using Prot\u00e9g\u00e9. The risks are qualitatively analyzed and prioritized, and aversion methods are provided. The framework is adopted in real\u2010life software projects. Precision recall and F\u2010measure metrics are used to validate the performance of the extraction tool while performance and perception evaluation are carried out using\u00a0\u2026", "num_citations": "9\n", "authors": ["1208"]}
{"title": "AbsoluteSecure: A tri-layered data security system\n", "abstract": " Data has been touted as the new oil. This attests to the level of importance it has garnered over the years. With increased proliferation of and advancements in technology, data is bound to play more prominent role. The need for data security, therefore, cannot be overstated. Existing systems for securing data often rely on one or combination of biometric, cryptography, and steganography. In this paper, we propose AbsoluteSecure, a data security system that combines the three techniques to enhance the security of data. The system is implemented using C#. To evaluate its performance, experiments are performed to assess its usability and security. Specifically, on usability, its capacity to successfully enroll a new user\u2019s fingerprint and authenticate an enrolled user are evaluated. On the other hand, to ascertain its security, we measure how much it can detect and deny access to unauthorized users, both at\u00a0\u2026", "num_citations": "9\n", "authors": ["1208"]}
{"title": "Bridges reinforcement through conversion of tied-arch using crow search algorithm\n", "abstract": " The bridges reinforcement is an expensive activity. In this line, new cheap ways to fix bridges have been developed. One of them is the bridges reinforcement through conversion of the cable-stayed arch. The main aim is minimizing the distances between the tensions of each lengthwise position between the original bridge and the bridge with the reinforcement by the cable-stayed arch. For that, it is necessary to know the order that the tension must be applied. In this paper, we resolve this problem by using a recent metaheuristic called Crow Search Algorithm which is based on the intelligent behavior of crows, this approach is inspired by the feature of crows to hide their excess food. The obtained results are compared other approximate techniques by using a well-known statistical test. Promising results reveal that this new algorithm is competitive to solve the proposed problem.", "num_citations": "9\n", "authors": ["1208"]}
{"title": "Machine learning approach for reliability assessment of open source software\n", "abstract": " Some of the quality parameters for any successful open source software may be attributed to affordability, availability of source code, re-distributability, and modifiability etc. Quality of software can be further improvised subsequently by either users or associated developers by constantly monitoring some of the reliability aspects. Since multiple users are allowed to modify the code there is a potential threat for security, which might degrade the reliability of software. Bug tracking systems are often considered to monitor various software faults, detected mostly in open source software projects. Various authors have made research in this direction by applying different techniques in order to improve the reliability of open source software projects. In this work, an various machine learning models have been implemented to examine the reliability of the software. An extensive numerical illustration has also been\u00a0\u2026", "num_citations": "9\n", "authors": ["1208"]}
{"title": "Integrating the scrum framework and lean six sigma\n", "abstract": " Lean Six Sigma approach has been a successful manufacturing quality improvement tool. In the last decades, it has helped many services and product industries to achieve better performance and higher results. No wonder that the approach has aroused the interest of the software development industry. As result, some software companies have been trying to adopt Lean Six Sigma in their development processes, specifically in conjunction with agile methods. Based on some of these experiences this paper intends to propose the integration in the Scrum method the quality procedures defined on the Lean Six Sigma (LSS). By complementing the current generic quality procedures of Scrum method with more formalized and well-proven quality measures from LSS we intend to improve the efficacy and efficiency of Scrum.", "num_citations": "9\n", "authors": ["1208"]}
{"title": "Smart-Solar Irrigation System (SMIS) for Sustainable Agriculture\n", "abstract": " This study seeks to develop an automated solar-powered irrigation system. This will provide a cost-effective solution to the traditional irrigation method. This project is aimed at designing a system that harnesses solar energy for smart irrigation and allows for more efficient way to conserve water on the farmland. The system developed is portable and is designed to be adaptable to existing water system. The system incorporates wireless communication technology established using NRF module. For easy operations, the system can be controlled via an Android app-enabled with Bluetooth network. The user experience allows selection of either manual control for scheduled irrigation or automatic control using wireless sensors.", "num_citations": "9\n", "authors": ["1208"]}
{"title": "Cloud computing security: Issues and developments\n", "abstract": " Cloud computing is a technology paradigm that is offering useful services to consumers. Cloud service providers utilize huge computing resources spread over geographical distances to provide services to customers. The computing resources deployed over the Internet comprises hardware and software used in virtualization, storage and compute purposes. This has obvious security implications as data is transmitted and stored in different locations over the Internet. Such data is not within the control of the owner. Beyond data, there are other security issues in cloud computing relating to virtualization and applications. Security has severe impact on the decision as to whether an organisation will adopt the cloud or not. Hence, the discussion on security is dynamic and solutions are evolving daily. This paper examines present trends in the area of cloud security and provides a guide for future research. In the present work, the objective is to answer the following question: what is the current trend and development in cloud security? Papers published in journals, conferences, white papers and those published in reputable magazines were analysed. The expected result at the end of this review is the identification of trends in cloud security. This will be of benefit to prospective cloud users and even cloud providers.", "num_citations": "9\n", "authors": ["1208"]}
{"title": "Gender detection using 3d anthropometric measurements by kinect\n", "abstract": " Automatic gender detection is a process of determining the gender of a human according to the characteristic properties that represent the masculine and feminine attributes of a subject. Automatic gender detection is used in many areas such as customer behaviour analysis, robust security system construction, resource management, human-computer interaction, video games, mobile applications, neuro-marketing etc., in which manual gender detection may be not feasible. In this study, we have developed a fully automatic system that uses the 3D anthropometric measurements of human subjects for gender detection. A Kinect 3D camera was used to recognize the human posture, and body metrics are used as features for classification. To classify the gender, KNN, SVM classifiers and Neural Network were used with the parameters. A unique dataset gathered from 29 female and 31 male (a total of 60 people) participants was used in the experiment and the Leave One Out method was used as the cross-validation approach. The maximum accuracy achieved is 96.77% for SVM with an MLP kernel function.", "num_citations": "9\n", "authors": ["1208"]}
{"title": "Energy consumption forecast using demographic data approach with Canaanland as case study\n", "abstract": " Various methods or models of forecasting energy have been addressed in the past, but it has been observed from exhaustive research that these methods are highly complex and usually require past or historical data of load consumption in its analysis. Hence, a new model that is simple and only makes use of readily available demographic user data such as the Energy consumption in KWh per capita of the country in view, population and land mass area of the urban community under study (Canaanland in this case) was expatiated here. This paper reiterates this model in a clearer, more explicit and applicable way; developing a flow chart that shows a step by step process of forecasting the energy consumption and a matlab code which does the actually computation in KVAh for each forecast year. Results obtained in this case showed that though the forecast values seemed a bit lower than the actual peak\u00a0\u2026", "num_citations": "9\n", "authors": ["1208"]}
{"title": "Keeping web service interface complexity low using an oo metric-based early approach\n", "abstract": " Web Services have been steadily gaining maturity as their adoption in the software industry grew. Accordingly, metric suites for assessing different quality attributes of Web Service artifacts have been proposed recently. Some researchers have particularly focused on assessing service interface descriptions in WSDL, which like any other software artifact have several inherent attributes (e.g., size or complexity) that can be measured. We study the statistical relationships between some recent service interface complexity metrics (Basci & Misra's metrics suite) and the well-known Chidamber & Kemerer's metric suite applied to service implementations, on a data-set of 154 real-world services. First, to prove the ability of Basci & Misra's suite of measuring the complexity attribute in WSDL documents, a theoretical validation of these metrics using Weyuker's properties is presented. Then, after finding high correlation\u00a0\u2026", "num_citations": "9\n", "authors": ["1208"]}
{"title": "Particle swarm based evolution and generation of test data using mutation testing\n", "abstract": " Adequate test data generation is a vital task involved in the process software testing. Process of mutation testing, a fault-based testing technique, generates mutants of the program under test (PUT) by applying mutation operators. These mutants can assist in finding test cases that have the potential to detect faults in the PUT. Particle Swarm Optimisation (PSO) share similar working characteristics with Genetic Algorithm (GA) which has already been applied to test data generation using mutation testing. In this paper, applicability of PSO for the generation of test data with mutation testing is explored. The results obtained by empirical evaluation of the proposed approach on benchmark C programs are presented. The evaluated results show that the test cases generated from the technique proposed kills substantial number of mutants and therefore, has a scope of exploring its performance in the area of search\u00a0\u2026", "num_citations": "9\n", "authors": ["1208"]}
{"title": "Usability evaluation of mobile access to institutional repository\n", "abstract": " This paper investigates the usability of the core functionalities of an Institutional Repository on mobile devices. An EPrints-based repository (Covenant University Repository) was used as case study. The core functionalities of the Institutional Repository were modelled using the Unified Modelling Language and tested on five different mobile devices. Questionnaires were designed and administered to users of the repository based on known usability attributes and the results were analysed using SPSS software. Reliability and convergent validity of the questionnaire was estimated by Cronbach\u2019s alpha and produced a result of 0.771, which is above 0.7 - the minimum recommended. Also, the results from the analysis of the usability attributes show that for all the attributes considered, each scored well above 4.00 on a scale of (1-5) which represents good usability. In essence, the results show that the current web version of the repository provides good usability when accessed from a range of mobile devices. The novelty of this work is that it presents a case study of mobile access to Institutional Repositories in an elegant and repeatable way.", "num_citations": "9\n", "authors": ["1208"]}
{"title": "The role of leadership cognitive complexity in software development projects: An empirical assessment for simple thinking\n", "abstract": " Simple thinking (or simplicity) is a way of coping with complexity. It is especially important in the software development process (SDP), which is an error\u2010prone, time\u2010consuming, and complex activity. This article investigates the role of the thinking style\u2014namely, simple thinking\u2014which has been found effective in solving complicated problems during software development. For this purpose, it reviews and discusses simplicity issues from a general perspective and, then, reports the findings of a survey concerning the assessment of simplicity in SDP. The survey was conducted among information and communication technologies senior professionals and managers from government and private\u2010sector organizations. Relevant hypotheses have been developed under different empirical categories for analysis. Statistical analysis techniques were then used to draw inferences based on these hypotheses. The results\u00a0\u2026", "num_citations": "9\n", "authors": ["1208"]}
{"title": "Document Type De  nition (DTD) Metrics\n", "abstract": " In this paper, we present two complexity metrics for the assessment of schema quality written in Document Type De finition (DTD) language. Both \"Entropy (E) metric: E(DTD)\" and \"Distinct Structured Element Repetition Scale (DSERS) metric: DSERS(DTD)\" are intended to measure the structural complexity of schemas in DTD language. These metrics exploit a directed graph representation of schema document and consider the complexity of schema due to its similar structured elements and the occurrences of these elements. The empirical and theoretical validations of these metrics prove the robustness of the metrics.", "num_citations": "9\n", "authors": ["1208"]}
{"title": "Effective project leadership in computer science and engineering\n", "abstract": " Project leaders are the most important individuals in projects. A project leader should follow some thinking styles and values which can lead his or her team to success. There is a common notion among software specialists that the more complex a project manager thinks, the better his leadership is. In this paper, we discuss the significance of simple thinking in project leadership. If the leader thinks in a simple way, then the risk of being suffocated in details is less. Complex thinking brings out greater risks of losing the general control of the system because of spending too much time and effort on details and, as a result, more confusion. Not only simplicity, but also psychological factors are important in guiding teams and developing projects in the most effective way. Here, we present a set of qualities for a good project leader in software engineering. In addition to that, we also demonstrate how cognitive and\u00a0\u2026", "num_citations": "9\n", "authors": ["1208"]}
{"title": "Modified Set of Weyuker's Properties\n", "abstract": " Weyuker properties have been suggested as a guiding tool in identification of a good and comprehensive complexity measure by several researchers. However, some of the Weyuker's properties are useless and evaluations of any complexity measure by these properties are meaningless. In this paper, an attempt has been made to analyze Weyuker's properties and propose a new set of properties to evaluate complexity measures", "num_citations": "9\n", "authors": ["1208"]}
{"title": "A systematic literature review on compliance requirements management of business processes\n", "abstract": " One crucial aspect that had cost business organizations so much is management of compliance requirements from various regulatory sources. In a bid to avoid being penalized, some organizations have adopted various techniques to accomplish this task. However, literature revealed that few thorough reviews have been centered on this subject in a systematic way. This implies that a review that systematically captured the entire crucial elements such as implementation environment, constraints types addressed, main contributions and strengths of the existing techniques is missing. This has led to the lack of sufficiently good context of operation. A systematic review on existing literatures is presented in this paper, which focuses on the management of business process compliance requirements in order to present summarized evidences and provide a lead-up for appropriately positioning new research activities\u00a0\u2026", "num_citations": "8\n", "authors": ["1208"]}
{"title": "Image steganography and steganalysis based on least significant bit (LSB)\n", "abstract": " The sending of encrypted messages attracts the attention of programmers and crackers who would seek to intercept and uncover the messages before arrive their intended destination. Steganography is one way to mask communication by hiding unrevealed message inside another unsuspecting message. Steganography can be combined with cryptography in order to offer a satisfactory measure of privacy and security. In this study, a new approach of the least significant bit steganography has been proposed which improves on the 1 byte least significance technique. A detail description of image steganography procedures based on Least Significant Bit (LSB) to reduce the possibility of a message being recognized is provided. It includes steganalysis - the techniques by which secret information is been extracted.", "num_citations": "8\n", "authors": ["1208"]}
{"title": "Implementing a mobile voting system utilizing blockchain technology and two-factor authentication in Nigeria\n", "abstract": " The voting system in Nigeria has always been filled with different forms of manipulation, and m-voting was suggested as the solution but has a major problem which is securely storing the casted votes. Blockchain was proposed to mitigate this problem and with the utilization of two-factor authentication to prevent illegible voters from casting their votes. The objective of this paper is to develop a mobile voting system that utilizes two-factor authentication to authenticate the voters and blockchain technology to securely store the votes. The system was then evaluated using the ISO 9241-11 usability model, and the results showed that the proposed system had a good usability rating which implies that it can be utilized in a voting procedure.", "num_citations": "8\n", "authors": ["1208"]}
{"title": "Galactic swarm optimization applied to reinforcement of bridges by conversion in cable-stayed arch\n", "abstract": " The scouring of piers bridges, caused by hydraulic action, is one of the main risks that the structure suffer over the years. One of the methods in development is to change the structure of the bridge incorporating a upper cable-stayed arch, which allows to implement vertical and network hangers in charge of lifting the original bridge board. For this it is necessary to optimize the order and the adjustment magnitudes tension of the hangers. To solve this problem we implemented a software for optimization which uses Galactic Swarms Optimization, which is inspired by the movement of the stars, which is inspired by the movement of the stars, galaxies and superclusters under the influence of gravity. When comparing the results obtained with other approximate techniques, we can observe from the diagrams of distribution of instances that level two of the algorithm does not have the necessary and expected\u00a0\u2026", "num_citations": "8\n", "authors": ["1208"]}
{"title": "Design and implementation of a mobile webcast application with google analytics and cloud messaging functionality\n", "abstract": " Church cast is an application developed to bring the messages of ministries closer to their members by harnessing the Internet and mobile devices. Due to the very busy schedules of people and religious restrictions in some countries, people are not usually able to be physically present at their locations of worship to listen to or watch their ministers. Existing applications developed in the past like DOMI radio and Redemption TV Media were limited to only audio, poor and unintuitive user interfaces and not providing the administrator any interactions with the users of the application. In this work, we develop an Android-based application that makes it possible for users to watch live streams and on-demand videos from their ministries using their mobile devices. The application also incorporates sharing and analytics functionalities to enable users to share videos messages with loved ones and help the administrator\u00a0\u2026", "num_citations": "8\n", "authors": ["1208"]}
{"title": "FOSSES: Framework for open\u2010source software evaluation and selection\n", "abstract": " A plethora of approaches exists for the evaluation and selection of open\u2010source software (OSS) in the literature. However, these approaches are hardly ever used in practice for the following reasons: first, the lack of a situational\u2010based procedure to define the evaluation criteria for OSS given its varied and dynamic nature; second, the inability of existing evaluation techniques, such as the analytic hierarchy process, to cope well with uncertainty factors, thus producing misleading results that affect the quality of decisions made; and third, a significant number of existing approaches require the prototyping of alternatives being considered in order to facilitate evaluation and decision\u2010making. This study addresses the aforementioned challenges by evolving a process framework for evaluating and selecting OSS. The proposed framework is validated by applying it to a case study. In addition, expert opinion was elicited\u00a0\u2026", "num_citations": "8\n", "authors": ["1208"]}
{"title": "Solving the software project scheduling problem using intelligent water drops\n", "abstract": " Within the category of project scheduling problems, there is a specific problem within the software industry referred to as the software project scheduling problem. The problem consists in the correct allocation of employees to the different tasks that make up a software project, bearing in mind time and cost restraints. To achieve this goal, the present work first uses metaheuristic intelligent water drops illustrating; this is a recent stochastic swarm-based method increasingly used for solving optimization problems. Finally, the results and comparisons with experiments performed with other techniques are presented, demonstrating the solidity of the approach presented.", "num_citations": "8\n", "authors": ["1208"]}
{"title": "A fuzzy classifier-based penetration testing for web applications\n", "abstract": " The biggest challenge of Web application is the inestimable losses arising from security flaws. Two approaches were advanced by a number of scholars to provide security to Web space. One of such approach is vulnerability assessment, which is a conscious effort to isolate, identify and recognize potentials vulnerabilities exploited by attackers. The second being the estimation and determination of level of risks/threats posed to Web applications by vulnerabilities obvious to the developer (or tester); this is generally referred to as penetration testing. Recently, there is Vulnerability Assessment and Penetration Testing (VAPT) that combined these two schemes to improve safety and effectively combat the menace of attackers on Web applications. This paper proposed Fuzzy Classifier-based Vulnerability and Assessment Testing (FCVAPT) model to provide security for sensitive data/information in Web\u00a0\u2026", "num_citations": "8\n", "authors": ["1208"]}
{"title": "A decision support system for pediatric diagnosis\n", "abstract": " Newborns are fragile and have a high risk of dying within the first 28 days of their life, therefore they require quality care from conception. This research aims at implementing a mobile pediatric diagnostic system for the rural settlers in Nigeria, reducing childhood mortality and providing an alternative pediatric professional. 581 records classified with na\u00efve Bayes and decision-stump-tree classifier gave a higher accuracy level for na\u00efve Bayes. A decision-support system is developed to aid health workers in rural areas in providing quality health service for children below six, which will provide low-cost medical service and contribute to reducing childhood mortality.", "num_citations": "8\n", "authors": ["1208"]}
{"title": "Development of prepaid electricity payment system for a university community using the LUHN algorithm\n", "abstract": " This work presents a University Community based electricity prepaid billing system. Generally in Nigeria, electricity customers face a lot of problems with respect to their electricity bills from the distribution companies. The challenges they face include wrongly calculated bills as a result inaccurate reading of meters, general human errors in bill preparation among others. In some other semi-automated systems in which prepaid meters are used, consumers waste much time in purchasing utility units for electricity. This is the case presently at the university community we are considered in this work. This paper presents the design and implementation of a combination of a web-based and SMS alert prepaid electricity system called for the community. The implementation of the system was done using C# programming language and Microsoft SQL Server as the database platform. The system incorporates the Luhn\u00a0\u2026", "num_citations": "8\n", "authors": ["1208"]}
{"title": "Adapted cloudlet for mobile distance learning: design, prototype and evaluation\n", "abstract": " The Open and Distance Learning (ODL) currently operated by some institutions in Nigeria has problems of accessibility from remote locations due to bandwidth and latency issues. To address accessibility problem caused by network delays, cloudlet computing is introduced. With cloudlet technology, distant mobile learners are able to connect to the nearby cloudlet and access the learning content. Instead of relying on a distant cloud with latency issues during access, a nearby cloudlet with rich resources could go a long way to address the resource poverty of a mobile device. This paper presents an architectural design and a prototype implementation of an adapted cloudlet for mobile distance learning. The paper proposes a feature in which the learning content in the cloud or cloudlet platform is adapted to a nearby mobile learner depending on the availability of platform with minimum delays in terms of bandwidth and latency.", "num_citations": "8\n", "authors": ["1208"]}
{"title": "The use of metaheuristics to software project scheduling problem\n", "abstract": " This paper provides an overview of Software Project Scheduling problem as a combinatorial optimization problem. Since its inception by Alba, there have been multiple models to solve this problem. Metaheuristics provide high-level strategies capable of solving these problems efficiently. A set of metaheuristics used to solve this problem is presented, showing the resolution structure and its application. Among these we can find Simulated Annealing, Variable Neighborhood Search, Genetic Algorithms, and Ant Colony Optimization.", "num_citations": "8\n", "authors": ["1208"]}
{"title": "Pervasive computing in classroom environments and applications\n", "abstract": " Pervasive computing is an advanced computing paradigm which makes computing available everywhere and anywhere. It allows users to interact with computers. Such computers can exist in different forms such as laptops, tablets, a pair of glasses (wearable computers) and clothes or wearable fabrics that are sensor-embedded. It is essential to explore the different applications of pervasive computing to learning in classroom environments, in order to foster learning and promote well-being among students. One of the problems currently confronting some developing countries is a lack of adequate facilities to support proper learning in classroom environments. This has had a negative impact on the performance of students at various levels of educational learning. In this paper, a review of current trends, future trends and applications of pervasive computing was explored, particularly with respect to classroom\u00a0\u2026", "num_citations": "8\n", "authors": ["1208"]}
{"title": "Constraint programming for optimal design of architectures for water distribution tanks and reservoirs: a case study\n", "abstract": " A water distribution system is an essential component of any urban infrastructure system. Its design is commonly a hard task mainly due to the presence of several complex interrelated parameters. Among others, some parameters to study are the water demand, pressure requirements, topography, location of resources, system reliability, and energy uses. In this paper, we focus on a real case of water distribution system in order to minimize installation costs by satisfying the given system requirements. We solve the problem by using state-of-the-art Constraint Programming techniques combined with Interval Analysis for rigorously handling continuous decision variables. Experimental results demonstrate the feasibility of the proposed approach, where the global optimum is reached in all instances and in reasonable runtime.", "num_citations": "8\n", "authors": ["1208"]}
{"title": "Modern Software Engineering Concepts and Practices: Advanced Approaches: Advanced Approaches\n", "abstract": " Software engineering has advanced rapidly in recent years in parallel with the complexity and scale of software systems. New requirements in software systems yield innovative approaches that are developed either through introducing new paradigms or extending the capabilities of well-established approaches. Modern Software Engineering Concepts and Practices: Advanced Approaches provides emerging theoretical approaches and their practices. This book includes case studies and real-world practices and presents a range of advanced approaches to reflect various perspectives in the discipline.", "num_citations": "8\n", "authors": ["1208"]}
{"title": "Comparative study of cognitive complexity measures\n", "abstract": " Complexity metrics are used to predict critical information about reliability and maintainability of software systems. Cognitive complexity measure based on cognitive informatics, plays an important role in understanding the fundamental characteristics of software, therefore directly affects the understandability and maintainability of software systems. In this paper, we compared available cognitive complexity measures and evaluated cognitive weight complexity measure in terms of Weyukerpsilas properties.", "num_citations": "8\n", "authors": ["1208"]}
{"title": "Measuring complexity of object oriented programs\n", "abstract": " In this paper, a metric for object oriented language is formulated and validated. On the contrary of the other metrics used for object oriented programming (OOPs), the proposed metric calculates the complexity of a class at method level and hence considers the internal architecture of the classes, subclasses and member functions. The proposed metric is evaluated against Weyuker\u2019s proposed set of measurement principles through examples and validated through experimentation, case study and comparative study with similar measures. The practical usefulness of the metric is evaluated by a practical framework.", "num_citations": "8\n", "authors": ["1208"]}
{"title": "Quantifying influential communities in granular social networks using fuzzy theory\n", "abstract": " Community detection and centrality analysis in social networks are identified as pertinent research topics in the field of social network analysis. Community detection focuses on identifying the sub-graphs (communities) which have dense connections within it as compared to outside of it, whereas centrality analysis focuses on identifying significant nodes in a social network based on different aspects of importance. A number of research works have focused on identifying community structure in large-scale network. However, very less effort has been emphasized on quantifying the influence of the communities. In this paper, group of nodes that are likely to form communities are first uncovered and then they are quantified based on the influencing ability in the network. Identifying exact boundaries of communities are quite challenging in large scale network. The major contribution in this paper is to develop a\u00a0\u2026", "num_citations": "7\n", "authors": ["1208"]}
{"title": "An experimental approach to unravel effects of malware on system network interface\n", "abstract": " Malware is malicious code that tends to take control of the system remotely. The author of these codes drops their malicious payload on to the vulnerable system and continues to maintain access to this system at will. In order to unravel and establish the ability of rootkit to hide system network interface, we developed a network model, and implementation of this model was carried out on four notable live rootkits. Our results show the ability of the four rootkits to hide the system network interfaces, which are being used by the attackers to gain access and communicate correctly with the compromised system.", "num_citations": "7\n", "authors": ["1208"]}
{"title": "A machine learning prediction of automatic text based assessment for open and distance learning: a review\n", "abstract": " In this systematic literature review, automatic text-based and easy type assessment grading system using Machine Learning and Natural Language Processing (NLP) techniques was investigated. The major focus is on text-based and essay type assessment in ODL courses. Text-based and essay type questions is an important tool for performing quality examination and assessment to help the students gain mastery over the task and widen their horizon of knowledge and increase the learner\u2019s development and learning than, for instance subjective question type, single choice question (SCQ), multiple choice question (MCQ) and true/false question type. Automatic text-based and essay type assessment grading system can be used as an important tool in ODL institutions, where assessment and examination can be quickly and easily evaluated for the purpose of efficient feedback. We carried out this study\u00a0\u2026", "num_citations": "7\n", "authors": ["1208"]}
{"title": "Comparative Evaluation of Techniques for Detection of Phishing URLs\n", "abstract": " One of the popular cyberattacks today is phishing. It combines social engineering and online identity theft to delude Internet users into submitting their personal information to cybercriminals. Reports have shown continuous increase in the number and sophistication of this attack worldwide. Phishing Uniform Resource Locator (URL) is a malicious web address often created to look like legitimate URL, in order to deceive unsuspecting users. Many algorithms have been proposed to detect phishing URLs and classify them as benign or phishing. Most of these detection algorithms are based on machine learning and detect using inherent characteristics of the URLs. In this study, we examine the performance of a number of such techniques. The algorithms were tested using three publicly available datasets. Our results revealed, overall, the Random Forest algorithm as the best performing algorithm, achieving an\u00a0\u2026", "num_citations": "7\n", "authors": ["1208"]}
{"title": "A web framework for online peer tutoring application in a smart campus\n", "abstract": " Peer tutoring is a unique and efficient method of teaching that has been widely investigated. Related works in the literature ranges from cross-age peer tutoring, peer tutoring for the disabled, reciprocal peer tutoring, to peer tutoring for children. One unique method that has been scarcely documented, however, is peer tutoring with the aid of the Internet. In this paper, therefore, a web framework is proposed for online peer tutoring application in a smart campus. The peer tutoring web application identifies two key target users: the tutor and the tutee. The tutors will help in teaching other students; they are responsible for accepting requests from tutees and in turn holding tutoring sessions for the tutees. They also have the responsibility of uploading important documents to the platform which are accessible to tutees. On the other hand, the tutees search for the tutors with prowess in their course of need and make\u00a0\u2026", "num_citations": "7\n", "authors": ["1208"]}
{"title": "A systematic mapping study on software architectures description based on ISO/IEC/IEEE 42010: 2011\n", "abstract": " Software architecture is considered an important area of Software Engineering, as it is useful for managing the development and maintenance of large scale software-intensive systems. Due to Software Architecture importance, the ISO/IEC/IEEE 42010:2011 standard was published in 2011. In this paper, we present a Systematic Mapping Study (SMS) for describing studies that explicitly used the ISO/IEC/IEEE 42010:2011 standard, and identifying which parts of this standard were most considered in the literature. Through the research, we selected 19 papers published between 2007 and September 2018. One interesting result is that ISO/IEC/IEEE 42010:2011 standard has been used, and its presence in papers has increased since 2016. However, parts of the standard are still not considered in practice. Industry and academia can still benefit from learning and improve the use of ISO/IEC/IEEE 42010:2011\u00a0\u2026", "num_citations": "7\n", "authors": ["1208"]}
{"title": "A comparative study of methods for hiding large size audio file in smaller image carriers\n", "abstract": " The last 13 years or more has been characterized by unmatched progress in multimedia content and undercover communication. Sound file is chief among mode of transmitting classified and confidential information across the cyberspace and channels. Steganography is a traditional solution to address the problems of data security on public channels and transmitters. In general, the practice of image steganography favored smaller size secret message transmission in larger size carrier approach. However, there is a major of challenge of concealing classified large size audio data inside a smaller image cover with lesser distortions and quality retention of the cover medium and original message respectively. To achieve these, the audio file is compressed to appropriate size before embedding it into two distinct image files (grayscale and RGB color) at binary level using both Most Significant Bits (MSBs) and\u00a0\u2026", "num_citations": "7\n", "authors": ["1208"]}
{"title": "A case study on measuring the size of microservices\n", "abstract": " In cloud computing, the microservices has become the mostly used architectural style. However, there is still an ongoing debate about how big a microservice should be. In this case study, a monolith application is measured using Common Software Measurement International Consortium (COSMIC) Function Points. The same application is divided into pieces by following the Domain Driven Design (DDD) principles. The resulting cloud friendly microservices are measured again using COSMIC Function Points and the obtained results are compared.", "num_citations": "7\n", "authors": ["1208"]}
{"title": "Comparative evaluation of mobile forensic tools\n", "abstract": " The rapid rise in the technology today has brought to limelight mobile devices which are now being used as a tool to commit crime. Therefore, proper steps need to be ensured for Confidentiality, Integrity, Authenticity and legal acquisition of any form of digital evidence from the mobile devices. This study evaluates some mobile forensic tools that were developed mainly for mobile devices memory and SIM cards. An experiment was designed with five android phones with different Operating System. Four tools were used to find out the capability and efficiency of the tools when used on the sampled phones. This would help the forensic investigator to know the type of tools that will be suitable for each phone to be investigated for acquiring digital evidence. The evaluation result showed that AccessData FTK imager and Paraben device seizure performs better than Encase and Mobiledit. The experimental result\u00a0\u2026", "num_citations": "7\n", "authors": ["1208"]}
{"title": "Unit testing in global software development environment\n", "abstract": " Global software development has many challenges. Amongst them maintaining quality in the code developed in distributed sites is also a challenge. One of effective way to control the quality of the code is the unit testing. It removes defects at the early stage of development and further reduces the testing and maintenance efforts at the later phase of the development lifecycle. In this paper, a class complexity metric for testing the class, which is normally treated as a unit in object-oriented programming is proposed. The applicability of class complexity metrics for unit testing is demonstrated through a project in JAVA.", "num_citations": "7\n", "authors": ["1208"]}
{"title": "Migration from COBOL to SOA: Measuring the impact on Web services interfaces complexity\n", "abstract": " SOA and Web Services allow to easily expose business functions to build larger distributed systems. However, legacy systems \u2013 mostly in COBOL \u2013 are left aside unless applying a migration approach. Main approaches are: direct and indirect migration. The former implies to wrap COBOL programs with a thin layer of a Web Service oriented language/platform. The latter needs reengineering COBOL functions to a modern language/platform. In a previous work, we presented an intermediate approach based on direct migration where developed Web Services are later refactored to improve their interfaces quality. Refactorings mainly capture good practices inherent to indirect migration. In this paper, we measure the complexity of Web Services\u2019 interfaces generated by the three approaches. Both comprehension and interoperability can be affected according to the service interface complexity level. We apply\u00a0\u2026", "num_citations": "7\n", "authors": ["1208"]}
{"title": "Development of a Secured Cloud Based Health Information System for Antenatal and Postnatal Clinic in an African Country.\n", "abstract": " Maternal Mortality Ratio (MMR) in many African countries has consistently been in the range of 500-800 per 100,000 live births over the last two decades. A major challenge in these settings relates to the quality and promptness of antenatal and/or post-natal care given. Recent advancements in technology, notably health information systems (HIS), have helped in the response to many of these challenges. In Africa, and indeed Nigeria, there is yet a comprehensive HIS that cuts across health sector that can address these issues. Hence, this project seeks to design a Secured Cloud-Based Antenatal and Postnatal Clinic System of a Health Information System to assist in efficient utilization of material and human resources and enhance quality of delivery of health services, geared towards improving maternal health. Requirements gathering for the proposed system will be conducted through a study of Antenatal and Postnatal Clinic Systems of existing Cloud Based HIS. System Modeling and Implementation Evaluation would be carried out. The developed HIS will adopt a AGATE architecture (Stakes and objectives of the system Description of the related organizations, processes and information flows, Security requirements, Services of the system, and traceability with operational needs), and a test-run and evaluation of the completed project will be conducted at specified three primary health care facilities in Nigeria.", "num_citations": "7\n", "authors": ["1208"]}
{"title": "An analysis of the suitability of cloud computing services in the Nigerian Education Landscape\n", "abstract": " Cloud computing is fast gaining popularity in educational institutions of developing countries like Nigeria. Software as a Service, Platform as a Service and Infrastructure as a Service are the three key models through which cloud computing services are delivered to end-users. A number of studies have been conducted to identify the enabling factors as well as the issues being faced as regards the adoption of cloud computing in the Nigerian context. In this study however, Strength, Weakness, Opportunity and Threat analysis of the service delivery models in the Nigerian Education landscape has been presented. In addition, the issues that an educational institution needs to consider when adopting cloud computing is discussed.", "num_citations": "7\n", "authors": ["1208"]}
{"title": "An empirical evaluation of software quality assurance practices and challenges in a developing country\n", "abstract": " Globally, it has been ascertained that the implementation of software quality assurance practices throughout the software development cycle yields quality software products that satisfies the user and meets specified requirements. The awareness and adoption of these techniques has recorded increase in the quality and patronage of software products. However, in developing countries like Nigeria indigenous software produced is not patronized by large corporations such as banks for their financial portfolio, and even the government. This research investigated the software quality assurance practices of practitioners in Nigeria, and the challenges being faced in implementing software quality in a bid to improve the quality and patronage of software. It was observed that while most practitioners claim to adhere to software quality practices, they barely have an understanding of software quality standards and a vast\u00a0\u2026", "num_citations": "7\n", "authors": ["1208"]}
{"title": "Comparing cuckoo search, bee colony, firefly optimization, and electromagnetism-like algorithms for solving the set covering problem\n", "abstract": " The set covering problem is a classical model in the subject of combinatorial optimization for service allocation, that consists in finding a set of solutions for covering a range of needs at the lowest possible cost. In this paper, we report various approximate methods to solve this problem, such as Cuckoo Search, Bee Colony, Firefly Optimization, and Electromagnetism-Like Algorithms. We illustrate experimental results of these metaheuristics for solving a set of 65 non-unicost set covering problems from the Beasley\u2019s OR-Library.", "num_citations": "7\n", "authors": ["1208"]}
{"title": "A comparison of three recent nature-inspired metaheuristics for the set covering problem\n", "abstract": " The Set Covering Problem (SCP) is a classic problem in combinatorial optimization. SCP has many applications in engineering, including problems involving routing, scheduling, stock cutting, electoral redistricting and others important real life situations. Because of its importance, SCP has attracted attention of many researchers. However, SCP instances are known as complex and generally NP-hard problems. Due to the combinatorial nature of this problem, during the last decades, several metaheuristics have been applied to obtain efficient solutions. This paper presents a metaheuristics comparison for the SCP. Three recent nature-inspired metaheuristics are considered: Shuffled Frog Leaping, Firefly and Fruit Fly algorithms. The results show that they can obtainn optimal or close to optimal solutions at low computational cost.", "num_citations": "7\n", "authors": ["1208"]}
{"title": "Internet of Things (IoTs) and its application to road navigation and usage problem\n", "abstract": " In an age where there is constant upgrade, improvement and steady advances in microelectronics, communications and information technology, Internet of Things (IoTs, henceforth), plays a significant role. Some years ago, hearing things like smartphones, Internet and sensors would have sounded strange, but these are currently trending. Due to this steady trend, it is expedient to explore the numerous possibilities that may evolve. This paper provides an overview of IoTs and how it can be applied to easy navigation of traffic congestions on road networks. One of the major problems among major cities in Africa is that of traffic congestions. In Nigeria, for instance, due to the irregular traffic situations and the conditions of roads in Lagos, it will be appropriate to have a platform where road users can get real time and updated information from a car that had travelled past the road network they are about to travel through\u00a0\u2026", "num_citations": "7\n", "authors": ["1208"]}
{"title": "An Analysis of Weyuker\u2019s Properties and Measurement Theory\n", "abstract": " Software engineering is wanting in the standards for measurement techniques. The field of software measurement is still not mature and scientist and practitioners are trying to develop ideal and standard measurement techniques. Consequently, several proposals for measures (software metrics) and evaluating cliteria for those measures are available in the literature. Weyuker's properties are some of the most widely used evaJuation clitelia for software complexity measure. On the other hand, these properties are very much criticized by several researchers based on the principle of measurement theory. This paper evaluates the Weyuker's properties from measurement theory perspective and proves that all these properties are compatible with principles of measurement theory. A comprehensive literature survey to prove the claim has been carried out. Furthermore, a comparative study with other researchers' works and proposals are performed and the appropriateness and robustness of these properties have been proved. In addition, once there are clises for an ideal software measurement ftamework, and Weyuker's properties have several unique features like these properties are developed on scientific basis, represented by mathematical expressions, straight forward and therefore easily understandable, these properties may play an important role in establishing such a framework.", "num_citations": "7\n", "authors": ["1208"]}
{"title": "Ambidextrous Socio-Cultural Algorithms\n", "abstract": " Metaheuristics are a class of algorithms with some intelligence and self-learning capabilities to find solutions to difficult combinatorial problems. Although the promised solutions are not necessarily globally optimal, they are computationally economical. In general, these types of algorithms have been created by imitating intelligent processes and behaviors observed in nature, sociology, psychology and other disciplines. Metaheuristic-based search and optimization is currently widely used for decision making and problem solving in different contexts. The inspiration for metaheuristic algorithms are mainly based on nature\u2019s behaviour or biological behaviour. Designing a good metaheurisitcs is making a proper trade-off between two forces: Exploration and exploitation. It is one of the most basic dilemmas that both individuals and organizations constantly are facing. But there is a little researched branch\u00a0\u2026", "num_citations": "6\n", "authors": ["1208"]}
{"title": "Support vector machine for path loss predictions in urban environment\n", "abstract": " Path Loss (PL) propagation models are important for accurate radio network design and planning. In this paper, we propose a new radio propagation model for PL predictions in urban environment using Support Vector Machine (SVM). Field measurement campaigns are conducted in urban environment to obtain mobile network and path loss information of radio signals transmitted at 900, 1800 and 2100\u00a0MHz frequencies. SVM model is trained with field measurement data to predict path loss in urban propagation environment. Performance of SVM model is evaluated using Mean Absolute Error (MAE), Mean Square Error (MSE), Root Mean Square Error (RMSE) and Standard Error Deviation (SED). Results show that SVM achieve MAE, MSE, RMSE and SED of 7.953 dB, 99.966 dB, 9.998 dB and 9.940 dB respectively. SVM model outperforms existing empirical models (Okumura-Hata, COST 231, ECC-33\u00a0\u2026", "num_citations": "6\n", "authors": ["1208"]}
{"title": "Human Rights\u2019 Issues and Media/Communication Theories in the Wake of Artificial Intelligence Technologies: The Fate of Electorates in Twenty-First-Century American Politics\n", "abstract": " The ability for individuals to effectively communicate their thoughts, ideas and feelings amongst fellow beings is perceived as one of the greatest features distinguishing man from other living creatures on earth. The freedom to communicate such thoughts\u2014in certain nations of the world\u2014are perceived as one of man\u2019s inalienable rights as a free individual in the society. Consequently, scholars have propounded theories to aid in explaining the trends of thought which modes of communication should follow. The proliferation of artificial intelligence (AI) technologies in the twenty-first century into the media industry seems to question the very foundations on which most renowned media and communications theory were founded on. Some scholars argue that political campaign experts have taken advantage of the adoption of innovations in AI technologies in the media to manipulate man\u2019s freedom to communicate and\u00a0\u2026", "num_citations": "6\n", "authors": ["1208"]}
{"title": "An ontological approach to threats pattern collection and classification: a preliminary study to security management\n", "abstract": " This study presents an agent based approach to resolve issues related to the collection and classification of software application anomalies and misuses with the aim of facilitating the reappraisal of security controls of information system (IS). The proposed system is assumed to be integrated with the existing IS in order to enhance information system security maintenance by continuously collecting identified threat behaviour from the application intrusion detection system (IDS). The system comprises of several functional agents like the input collector agent, classifier agent, and tracking agent. The collector agent collects the identified threats by the IDS, the categoriser agent categorises according to STRIDE model using pattern matching algorithm on the content of security knowledge base. The security knowledge repository is developed based on existing security ontology. The classifier classifies based on the\u00a0\u2026", "num_citations": "6\n", "authors": ["1208"]}
{"title": "The politics of artificial intelligence behaviour and human rights violation issues in the 2016 US presidential elections: An appraisal\n", "abstract": " The outcry from organizations and concerned bodies responsible for regulating and protecting the security and privacy of citizens\u2019 data have suddenly been on the increase since the unearthing of the recent scandal regarding data gathered from the users of Facebook by Cambridge Analytica (CA) without prior consent. Data belonging to over 87 million Facebook users were admittedly passed on to third-party organizations who used them to manipulate the views and opinions of American citizens, a move largely believed influenced and altered the results and outcome of the 2016 US presidential elections in favour of certain individuals, an action largely believed undermines the Fundamental Human Rights (FHR) of the citizens affected. The Marxian Alienation Theory and Derrider\u2019s critical and qualitative analytical method for evaluating arguments and data gathered on the subject matter of the paper were\u00a0\u2026", "num_citations": "6\n", "authors": ["1208"]}
{"title": "Comparative study of the electrical energy consumption and cost for a residential building on fully ac loads vis-a-vis one on fully dc loads\n", "abstract": " The inability of direct current (DC) to transform voltage levels and the ability of alternating currents (AC) to do such during the first war of currents are the reasons why power system networks are AC designed today. However, since the growing need for energy systems to be green and efficient, DC is crawling back to the scene. This paper proposes the use of DC lighting and household appliances as DC applications are diverse and hold the promise for efficient power consumption and easy integration of renewable energy. For this work, AC and DC systems are set up and the systems which consist of lighting and household appliances, and these are compared in terms of energy demand and energy cost. It was seen that using DC lighting and household appliances reduces energy consumption and energy cost by 55.44% in residential buildings. Seeing that residential building accounts for 80% of energy\u00a0\u2026", "num_citations": "6\n", "authors": ["1208"]}
{"title": "A fuzzy based hybrid firefly optimization technique for load balancing in cloud datacenters\n", "abstract": " Cloud computing technology has massive inferences with the use of virtualization technologies. Most of the organizations have incorporated to practice the virtualization strategies to create and operate an effective dynamic data center. The growing maturity of the technologies and utilities of the cloud make the users hasten the adoption of the cloud. The dynamic demanding nature of cloud resources leads to an imbalance in virtual machine utilization and radically increases the energy consumption and operating cost of the data center. In this paper, we propose a fuzzy based hybrid load balancing algorithm for the optimal utilization of virtual machines. The proposed algorithm aim is to reduce the makespan, response time and cost with minimal energy usage and resource wastage. The fuzzy based hybrid optimization approach unveils better performance than existing metaheuristic load balancing algorithms.", "num_citations": "6\n", "authors": ["1208"]}
{"title": "A survey about the impact of requirements engineering practice in small-sized software factories in Sinaloa, Mexico\n", "abstract": " Scientific literature over time highlighted the relevance of requirements engineering for software development process for desktop, web or mobile applications. Nevertheless, not much contemporary information with regard to current practices in small-sized software factories is available. This is specially true in the region of Sinaloa, M\u00e9xico, for that reason this work presents an exploratory study which provides insight into industrial practices in Sinaloa. A combination of both qualitative and quantitative data is collected, using semi-structured interviews and a detailed questionnaire from sixteen software factories. A Pearson (r) correlation analysis was performed independently between the variables Company location (EU), Scope of coverage (AC), Number of workers (NT), Time to live in the market (TV), Projects completed (PY), Time dedicated to activities related to the project (TA), Outdated projects\u00a0\u2026", "num_citations": "6\n", "authors": ["1208"]}
{"title": "Comparative evaluation of machine learning algorithms for network intrusion detection using Weka\n", "abstract": " For the past few years, it has been seen that the computer intrusion attacks are becoming more sophisticated, and the volume, velocity, and variance of traffic data have greatly increased. Because the conventional methods and tools have become impotent in the detection of intrusion attacks, most intrusion detection systems now embrace the use of machine learning tools and algorithms for efficiency. This is because of their ability to process large volume, velocity, and very high variance data. This work reviews and analyzes the performance of three out of the most commonly used machine learning algorithms in network intrusion. In this work, the performance of Na\u00efve Bayes, decision tree, and random forest algorithms were evaluated as they were being trained and tested with the KDD CUP 1999 dataset from DARPA using a big data and machine learning tool called Weka. These classification algorithms\u00a0\u2026", "num_citations": "6\n", "authors": ["1208"]}
{"title": "Object-oriented cognitive complexity measures: An analysis\n", "abstract": " This chapter presents the analysis of ten recently proposed object-oriented metrics based on cognitive informatics. The metrics based on cognitive informatics use cognitive weight. Cognitive weight is the representation of the understandability of the piece of software that evaluates the difficulty experienced in comprehending and/or performing the piece of software. Development of metrics based on Cognitive Informatics (CI) is a new area of research, and from this point of view, for the analysis of these metrics, it is important to know their acceptability from other existing evaluation and validation criteria. This chapter presents a critical review on existing object-oriented cognitive complexity measures. In addition, a comparative study based on some selected attributes is presented.", "num_citations": "6\n", "authors": ["1208"]}
{"title": "Implementation of MANETs Routing Protocols in WLANs Environment: Issues and Prospects\n", "abstract": " In general, communication is the process of sending and receiving data packets between several participants or nodes connected within a network. There are two main ways of establishing communication. The first is the WLAN in which a defined network base is used to provide services to senders and receivers of data packets across wireless medium. The second is the MANETs that allow direct communication between senders and receivers nodes for the purpose exchanging of packet data through the wireless and baseless station in the network structure. The major challenges of WLANs are the cost of maintaining base station, network congestions, low throughput and delays. MANETs was considered appropriate for providing communication services in WLANs structure. This paper implemented AODV and DSR MANETs protocols in WLAN environment and analyzed its performance. The outcomes\u00a0\u2026", "num_citations": "6\n", "authors": ["1208"]}
{"title": "Developing a calorie counter fitness app for smartphones\n", "abstract": " A number of mobile fitness devices as well as smart watches have emerged on the technology landscape. However, the rate of adoption of these devices is still low especially in developing countries with a teeming population. On the other hand, smart phones are becoming ubiquitous given their steady price decline. To this end, the present study aims to leverage the smartphone platform by developing a smart phone fitness app that tracks the calories burnt by individuals who go about their daily activities while carrying their smart phones with them. In order to achieve this, the design specification for the application was done using Unified Modeling Language diagrams such as use case diagrams and sequence diagrams. This was then implemented using the following tools: Angular - a JavaScript framework and Ionic - a hybrid framework that was hosted via the Heroku Cloud Application Platform. The\u00a0\u2026", "num_citations": "6\n", "authors": ["1208"]}
{"title": "Evaluation and Comparison of Metrics for XML Schema Languages.\n", "abstract": " The importance of XML (eXtensible Markup Language) can\u2019t be understated; their usefulness may range from data sharing to data transport in software systems. Schema languages describe the structure of an XML document and the common schemas languages are Document Definition Type (DTD), W3C XML Schema and RelaxNG. Applications depend heavily on XML documents to be free of error and this makes it imperative to determine the quality of such schema document. Schema metrics is used to achieve this, and several of them have been proposed in recent years. In this paper we present the existing schema metrics and to make comparative studies on all schema metrics, figuring out the features, advantages and limitations of each metrics.", "num_citations": "6\n", "authors": ["1208"]}
{"title": "Model-driven engineering and creative arts approach to designing climate change response system for rural Africa: a case study of Adum-Aiona community in Nigeria\n", "abstract": " Experts at the just concluded climate summit in Paris (COP21) are unanimous in opinion that except urgent measures are taken by all humans, average global temperature rise would soon reach the deadly 2oC mark. When this happens, socio-economic livelihoods, particularly in developing economies, would be dealt lethal blow in the wake of associated natural causes such as increased disease burden, soil nutrient destruction, desertification, food insecurity, among others. To avert imminent dangers, nations, including those from Africa, signed a legally binding universally accepted climate control protocol to propagate and regulate environmentally-friendly behaviours globally. The climate vulnerability of Africa as established by literature is concerning. Despite contributing relatively less than other continents to aggregate environmental injustice, the continent is projected to bear the most brunt of environmental degradation. This is on account of her inability to put systems and mechanisms in place to stem consequences of climate change. Hence, our resolve to use a combination of scientific and artistic models to design a response system for tackling climate challenges in Africa. Our model formulation encompasses computational model and creative arts model for drawing attention to environmentally friendly behaviours and climate adaptation and mitigation strategies. In this work, we focus on rural Africa to share experience of climate change impact on agriculture\u2013mainstay of rural African economy. We examine the carbon footprints of a rural community in Nigeria\u2013the Adum-Aiona community\u2013as case study and for industrial experience. The\u00a0\u2026", "num_citations": "6\n", "authors": ["1208"]}
{"title": "Mobile-bayesian diagnostic system for childhood infectious diseases\n", "abstract": " About 5.9 million children under the age of 5 died in 2015, Preterm birth, delivery complications and infections source a great number of neonatal deaths. the Sustainable Development goals (SDGs) 3.2 is to end preventable deaths of newborns and children under 5 years of age, with a target to reduce neonatal mortality to at least 12 per 1,000 live births and under-5 mortality to at least as low as 25 per 1,000 live births in all countries. However quality and accessible healthcare service is essential to achieve this goal whereas most undeveloped and developing countries still have poor access to quality healthcare. with the emergences on mobile computing and telemedicine, this work provide diagnostics alternative for childhood infectious diseases using Na\u00efve Bayesian classier which has been proven to be efficient in handling uncertainty as regards learning of incomplete data. In this research, sample data was collected from hospitals to model a pediatric system using Na\u00efve Bayes classifier, which produce a 70% accuracy level suitable for a decision support system. The model was also integrated into a SMS platform to enable ease of usage.", "num_citations": "6\n", "authors": ["1208"]}
{"title": "Solving the set covering problem with a binary black hole inspired algorithm\n", "abstract": " There are multiple problems in several industries that can be solved with combinatorial optimization. In this sense, the Set Covering Problem is one of the most representative of them, being used in various branches of engineering and science, allowing find a set of solutions that meet the needs identified in the restrictions that have the lowest possible cost. This paper presents an algorithm inspired by binary black holes (BBH) to resolve known instances of SPC from the OR-Library. Also, it reproduces the behavior of black holes, using various operators to bring good solutions.", "num_citations": "6\n", "authors": ["1208"]}
{"title": "A Review of Student Attendance System Using Near-Field Communication (NFC) Technology\n", "abstract": " The rapid growth of system development is no longer subtle and continuously improving today\u2019s system. In education sector, the student attendance system is able to be applied by Near-Field Communication (NFC) technology. NFC can be referred to as a device that can detect information and/or command from a tag by bringing them together in a close proximity or even by touching together. Traditionally, the manual attendance system would require a lecturer to pass around an attendance sheet for students to sign beside their names and another method would require the lecturer to call out the students\u2019 names one by one and register their attendance. The attendance system based on NFC is meant to improve the manual attendance system and therefore the aim of this paper is to review the existing research", "num_citations": "6\n", "authors": ["1208"]}
{"title": "Towards a cloud-based data storage medium for e-learning systems in developing countries\n", "abstract": " The focus of this study is to propose a cloud computing data storage model for E-Learning systems in developing countries. Cloud computing is an information technology platform that refers to services which provide data storage, collaboration and software execution hosting services via the Internet. Cloud computing is a technology trend that has a significant impact on the teaching and learning environment. The idea behind this research work therefore is to enhance the storage capacity and utilize resources of E-learning system for universities in developing countries. This platform incorporates cloud data storage medium to accommodate/store all educational content/files on the E-learning system.", "num_citations": "6\n", "authors": ["1208"]}
{"title": "Modern techniques for successful IT project management\n", "abstract": " Computer technology provides the opportunity for innovation and progress in the daily operations and initiatives of corporations. Despite the positive elements of integrating technology into the workplace, corporations continue to struggle with the challenges created by rapid technological advancements. Modern Techniques for Successful IT Project Management brings together academic research and professional practice to examine the complexity of implementing technology into the structure and organization of a corporation's ventures. This publication is an essential reference source for researchers, professionals, and upper-level university students working in the fields of project management, information systems, and IT project management interested in the methodologies and research necessary to improve the impact of Information Technology.", "num_citations": "6\n", "authors": ["1208"]}
{"title": "Novel user interface for text entry on touch screen mobile device for visually impaired users\n", "abstract": " A touch screen mobile device become more popular in society because of its flexibility and discoverability. Unfortunately, due to its high visual demand it creates significant barriers for visually impaired users. But some touch screen devices available in the market with various accessible techniques like using screen reader, haptics and different input mechanisms. But they did not give any remarkable results in convenience handling and text entry speed. In this paper authors analyzes different interaction techniques and their impact on text entry speed. They also proposed new user interface for touch screen device to minimize accessibility barriers for visually impaired users.", "num_citations": "6\n", "authors": ["1208"]}
{"title": "A cognitive model for meetings in the software development process\n", "abstract": " Meetings are at the heart of the software development process (SDP) and can be of different types. The present article first proposes an abstract cognitive model for meetings, which represents how different types of meetings are affected by cognitive activities at different stages within the SDP. Second, and based on the analysis of meetings at different stages of SDP, it proposes the removal of such meetings from some of the stages within the program by using a cognitive evaluation model for meetings and their replacement, instead, with information and communication technology tools and techniques by means of a cognitive evaluation model. The abstract cognitive model and the evaluation model are validated empirically through experimentation, carried out through a detailed analysis of a target group composed of information technology professionals. \u00a9 2011 Wiley Periodicals, Inc.", "num_citations": "6\n", "authors": ["1208"]}
{"title": "A cognitive requirement specification model\n", "abstract": " Eliciting/gathering information from the customers in requirement phase is the most crucial task in the development of the software development process, because this phase builds the base for the success or failure of any software product. Requirements specification process highly depends on the knowledge and mental abilities of the customers. In this paper, we are proposing a cognitive requirement specification model based on the cognitive classification of customers.", "num_citations": "6\n", "authors": ["1208"]}
{"title": "Weyuker\u2019s properties, language independency and object oriented metrics\n", "abstract": " Weyuker proposed the nine properties to evaluate software complexity measures at a time when procedural languages were dominant; however, several researchers have used these properties to evaluate object oriented metrics although the object-oriented (OO) features are entirely different in nature. In this paper, we evaluate each of Weyuker\u2019s properties for its effective evaluation and relevance for OO metrics. In addition, we evaluate eleven OO metrics against language independency and additive property. A set of additional properties for object oriented metrics are also summarized in this paper.", "num_citations": "6\n", "authors": ["1208"]}
{"title": "Increasing innovative working behaviour of information technology employees in Vietnam by knowledge management approach\n", "abstract": " Today, Knowledge Management (KM) is becoming a popular approach for improving organizational innovation, but whether encouraging knowledge sharing will lead to a better innovative working behaviour of employees is still a question. This study aims to identify the factors of KM affecting the innovative working behaviour of Information Technology (IT) employees in Vietnam. The research model involves three elements: attitude, subjective norm and perceived behavioural control affecting knowledge sharing, and then, on innovative working behaviour. The research method is the quantitative method. The survey was conducted with 202 samples via the five-scale questionnaire. The analysis results show that knowledge sharing has a positive impact on the innovative working behaviour of IT employees in Vietnam. Besides, attitude and perceived behavioural control are confirmed to have a strong positive effect on knowledge sharing, but the subjective norm has no significant impact on knowledge sharing. Based on this result, recommendations to promote knowledge sharing and the innovative work behaviour of IT employees in Vietnam are made. View Full-Text", "num_citations": "5\n", "authors": ["1208"]}
{"title": "A Unified framework for outfit design and advice\n", "abstract": " The application of technology in the apparel industry has received significant attention from the research community in recent times. Technology is being leveraged to support the various processes in the supply chain of the industry. On the consumer side, choosing the right outfit for occasions can be quite challenging. It is for this reason that researchers have proposed a number of fashion recommender systems in the literature. Although the proposals in literature cover a number of areas, they are yet to touch on recommendation based on weather. It is also important to harmonise all of the proposals into a unified framework that will help guide developers. The aim of this study therefore is to propose a unified framework for outfit design and advice. The framework is developed using Unified Modelling Language (UML) diagrams and notations, which are globally recognised. In addition, a prototype of an aspect of the\u00a0\u2026", "num_citations": "5\n", "authors": ["1208"]}
{"title": "Systematic mapping study of utility-driven platforms for clouds\n", "abstract": " Cloud computing is a dynamic paradigm that applies utility driven platforms at all layers to provide on-demand elastic services to the users. Utility driven platforms on the cloud makes the services easy to use and access by customers. There are several utility platforms available and many more are being developed. This makes utility driven platforms on the cloud an interesting area to research on. However, deciding on a specific research area that relates to utility driven platforms on the cloud could be a cumbersome process for a researcher. A systematic mapping study allows an aggregation of publication in an area of interest, which provides a summary of the extent of work done in that field. The specific objective is to conduct a systematic mapping study of utility driven platforms for clouds. The study in this paper were carried out using three categories or facets; the topic, research, and contribution facets\u00a0\u2026", "num_citations": "5\n", "authors": ["1208"]}
{"title": "Internet of things: demystifying smart cities and communities\n", "abstract": " This paper presents a review on the use of IoT for demystifying smart cities and communities. The upward paradigm shift in the way standard of living has evolved, has pointed at the poor impact of service delivery in human homes and cities, owing to constrained amenities and resources. As such, the smart cities and homes concept has been adopted to boost the delivery of services in both suburban and urban areas. IoT\u2019s concept has been effective by facilitating right of entry and relations with an extensive range of devices, e.g. appliances, vehicles, security cameras, actuators, monitoring sensors, displays, etc. The increase in the development of a number of applications resulted from the existence of IoT, which allows the use of the big, rich and varied form of data generated by devices and objects to produce innovative services to individuals, organizations and government parastatals, who we identify as \u201cusers\u00a0\u2026", "num_citations": "5\n", "authors": ["1208"]}
{"title": "Multi-class classification of impulse and non-impulse sounds using deep convolutional neural network (DCNN)\n", "abstract": " Differentiating between military sounds can be quite tasking with high false detection rate. These sounds can either be impulse sounds (sounds released from the military weapons) or non-impulse sounds (sound released from other sources) thus causing public disturbance and unnecessary panic. This paper utilizes Deep Convolutional Neural Network (DCNN) classifier to detect military impulse and non-impulse sounds and also incorporates Adam algorithm for optimal classification. DCNN was utilized in this study based on its network embedded multiple hidden layers (non-linear) which can learn the very complicated relationship between the input data and require output. The dataset used in this study consist of six sound types with a total number of 37,464 datasets which was partitioned into training (67%) and testing (33%). The performance of the proposed classifier was evaluated based on the\u00a0\u2026", "num_citations": "5\n", "authors": ["1208"]}
{"title": "Computational Science and Its Applications\u2013ICCSA 2019\n", "abstract": " These 6 volumes (LNCS volumes 8579-8584) consist of the peer-reviewed papers from the 2014 International Conference on Computational Science and Its Applications (ICCSA 2014) held in Guimaraes, Portugal during 30 June\u20133 July 2014.ICCSA 2014 was a successful event in the International Conferences on Computational Science and Its Applications (ICCSA) conference series, previously held in Ho Chi Minh City, Vietnam (2013), Salvador da Bahia, Brazil (2012), Santander, Spain (2011), Fukuoka, Japan (2010), Suwon, South Korea (2009), Perugia, Italy (2008), Kuala Lumpur, Malaysia (2007), Glasgow, UK (2006), Singapore (2005), Assisi, Italy (2004), Montreal, Canada (2003), and (as ICCS) Amsterdam, The Netherlands (2002) and San Francisco, USA (2001). Computational science is a main pillar of most of the present research, industrial and commercial activities and plays a unique role in exploiting\u00a0\u2026", "num_citations": "5\n", "authors": ["1208"]}
{"title": "Design and implementation of a mobile-based personal digital assistant (MPDA)\n", "abstract": " In this work we present a mobile-based personal digital assistance for students of higher institutions of learning. These days, the need for a To-Do list or a daily plan cannot be over-emphasized. This is because so many things compete for our valuable. It appears that the 24\u00a0h of a day are no longer sufficient for our daily activities. Although this appears true, however, prioritizing our activities generally may go a long way in helping to manage our time. Several platforms and media that existed some years ago were based on the use of pen and paper to organize activities for the day. These can no longer match up recent advances in technology and information flow which are at a very great speed. This work leverages on the current proliferation of mobile devices where each student now has a mobile device for personal use. In this work a mobile-based personal digital assistant is developed specifically on the\u00a0\u2026", "num_citations": "5\n", "authors": ["1208"]}
{"title": "Controlling complexity of web services interfaces through a metrics-driven approach\n", "abstract": " Metric suites to assess Web Service quality attributes have been proposed recently. In particular, services interfaces in WSDL (Web Service Description Language) have distinct intrinsic aspects (e.g., size or complexity) able to be measured. We present an approach to prevent a high complexity on services interfaces (WSDLs), to ease consumers to reason about services' offered functionality. Mostly, WSDLs are automatically derived from object-oriented (OO) source code, with a likely impact on complexity. In a previous work, we studied the statistical relationships between a metric suite of service interface complexity (by Baski & Misra) and the Chidamber & Kemerer's OO metric suite (onto service implementations). In this work, we extend the study to find out how certain refactorings on services' source codes prior to derive WSDLs might reduce complexity. For this, we conducted a series of experiments on a data-set\u00a0\u2026", "num_citations": "5\n", "authors": ["1208"]}
{"title": "MOTIVATING EFFECTIVE ICT USERS\u2019SUPPORT THROUGH AUTOMATED MOBILE EDU-HELPDESK SYSTEM\n", "abstract": " An automated helpdesk system is meant to eradicate some of the barriers of reaching the Information and Communication Technology (ICT) technical staff to carry out repairs of ICT products and services in an educational institution. The problems faced with the existing ICT user support system include time wasting, difficulty in communication, and slow response to fix ICT related faults. The objective of this study is to develop an Automated Mobile Edu-Helpdesk System (AMES) for effective information dissemination, efficient management of operations and to resolve ICT challenges in higher education. The research methods adopted include unified modelling diagrams for design, Java and XML (Extended Mark-up Language) for Android application development as front end, while Hypertext Preprocessor (PHP) was used as the server side programming tool. MySQL database was used as backend. Findings: The findings from the usability survey shows a good usability based on total rating of 4.09 out of 5 point scale. The benefits of the system include creation of a medium for non teaching and teaching staff to pass their complaints or messages to the technical department for speedy attention; and provision of better and faster operational processes which will reduce time spent on documentation. The automated Edu-Helpdesk system is more reliable, effective and convenient than the manual method in reporting cases of faulty ICT product and services within the university community.", "num_citations": "5\n", "authors": ["1208"]}
{"title": "Cat swarm optimization with different transfer functions for solving set covering problems\n", "abstract": " This work presents a study of a new binary cat swarm optimization. The cat swarm algorithm is a recent swarm metaheuristic technique based on the behaviour of discrete cats. We test the proposed binary cat swarm optimization solving the set covering problem which is a well-known NP-hard discrete optimization problem with many practical applications, such as: political districting, information retrieval, production planning in industry, sector location and fire companies, among others. To tackle the mapping from a continuous search space to a discrete search space we use different transfer functions, S-shaped family and V-shaped family, which are investigated in terms of convergence speed and accuracy of results. The experimental results show the effectiveness of our approach where the binary cat swarm algorithm produce competitive results solving a portfolio of set covering problems from the OR\u00a0\u2026", "num_citations": "5\n", "authors": ["1208"]}
{"title": "Intelligence in the Era of Big Data: 4th International Conference on Soft Computing, Intelligent Systems, and Information Technology, ICSIIT 2015, Bali, Indonesia, March 11-14\u00a0\u2026\n", "abstract": " This book constitutes the refereed proceedings of the 4th International Conference on Soft Computing, Intelligent Systems, and Information Technology, ICSIIT 2015, held in Bali, Indonesia, in March 2015. The 34 revised full papers presented together with 19 short papers, one keynote and 2 invited talks were carefully reviewed and selected from 92 submissions. The papers cover a wide range of topics related to intelligence in the era of Big Data, such as fuzzy logic and control system; genetic algorithm and heuristic approaches; artificial intelligence and machine learning; similarity-based models; classification and clustering techniques; intelligent data processing; feature extraction; image recognition; visualization techniques; intelligent network; cloud and parallel computing; strategic planning; intelligent applications; and intelligent systems for enterprise, government and society.", "num_citations": "5\n", "authors": ["1208"]}
{"title": "Handbook of research on innovations in systems and software engineering\n", "abstract": " Professionals in the interdisciplinary field of computer science focus on the design, operation, and maintenance of computational systems and software. Methodologies and tools of engineering are utilized alongside the technological advancements of computer applications to develop efficient and precise databases of information. The Handbook of Research on Innovations in Systems and Software Engineering combines relevant research from all facets of computer programming to provide a comprehensive look at the challenges and changes in the field. With information spanning topics such as design models, cloud computing, and security, this handbook is an essential reference source for academicians, researchers, practitioners, and students interested in the development and design of improved and effective technologies.", "num_citations": "5\n", "authors": ["1208"]}
{"title": "A solution proposal for complex web application modeling with the I-star framework\n", "abstract": " In Web Engineering (WE), several Goal-oriented Requirements Engineering (GORE) approaches have emerged using its advantages, such as the representation of actors, their intentions, goals and the tasks needed to achieve the goal, for requirements specification with promising results. Regrettably, the use of GORE approaches has one, among others, gap detected, the scalability. In these modeling frameworks, when the designer performs the requirements specification, the requirements diagram (model) trends to rapidly grow, becoming very difficult to use in projects with a considerable amount of requirements changing and growing constantly. In this paper, we propose an association form for the i* goal-oriented modeling framework in order to define the creation of two type of modules: Navigational and Service modules, since these are the two types of functional requirements more used for\u00a0\u2026", "num_citations": "5\n", "authors": ["1208"]}
{"title": "Creative thinking in extreme programming\n", "abstract": " Agile methods such as eXtreme Programming have achieved an explosive interest in the software development community. They can be seen as a reaction to the more traditional and control-oriented methods, agile methods handle changes in design and requirements and they open up for creativity during the whole project lifecycle. The knowledge management in agile methods is also agile, it means that knowledge creation and sharing processes are simplified in comparison with other more comprehensive development methodologies. This paper is developed under the idea that agile software development can be enhanced by a better understanding of knowledge management and creativity. eXtreme Programming is analyzed from the perspective of the creativity, we believe that concepts related to creative teams (roles, structure, performance and purposes) are important insights about the use of agile methods in general and eXtreme Programming in particular.", "num_citations": "5\n", "authors": ["1208"]}
{"title": "Towards an iterative maintainability Web service model for effective mobile healthcare delivery\n", "abstract": " Web services are key component of software engineering design due to its inherent merits such as portability, testability and maintainability. It serves as a means of exchanging information over the Internet across several platforms, programs and protocols. However, Web services are problematic to measure, control, and manage. The problem of maintainability is prevalent in the software industry and does not leave out the web services. However, certain models have been proposed for software maintainability. In this paper, we propose an iterative maintainability web service process model for effective mobile health care delivery in Niger state, Nigeria. The model would further be enhanced using the open shortest path Dijikstra algorithm to locate the closest healthcare facility and validated using the Cloud Network platform. Google Cloud will be used for easier DBMS and model deployment.", "num_citations": "5\n", "authors": ["1208"]}
{"title": "Error density metrics for business process model\n", "abstract": " In this paper, metrics for business process model (BPM), are proposed, which are capable to measure the usability and effectiveness of BPMs. The proposed model is adapting error density metrics to BPMs by considering the similarities between the conceptual characteristics of BPMs and software products. We applied seven software metrics for evaluating quality of business processes/ process models. Results show that our metrics help the organization to improve their process, as weighted measurements are indicators for unexpected situations/behaviour for business processes.", "num_citations": "5\n", "authors": ["1208"]}
{"title": "A metric for global software development environment\n", "abstract": " Unit testing is one of the most effective techniques to find defects at an early stage, which reduces the testing and maintenance efforts exponentially at the later phase. It becomes more important when the environment is global software development, where the software developers are disparate over the different environments and places. In this paper, we suggest to apply cognitive weight complexity metric (CWCM) for unit testing in a global software development environment. On the contrary, to the other metrics, CWCM calculates the cognitive complexity of the code and is a language independent complexity measure. Cognitive complexity plays an important role in understanding the fundamental characteristics of software, therefore directly affects the understandability and maintainability of software systems. The CWCM is theoretically evaluated against Weyuker\u2019s proposed set of measurement principles and is found to satisfy seven Weyuker\u2019s properties. The empirical validation and practical applicability of the proposed metric is evaluated by test cases, comparative study and through a framework.", "num_citations": "5\n", "authors": ["1208"]}
{"title": "Exploring web service QoS estimation for web service composition\n", "abstract": " Web development, machine ubiquity, and the availability of communication networks impacted device design, replacing the idea of an isolated personal computer with one of distributed and connected computers. A web service is a component of software which provides a specific functionality that can be accessed over the Internet. Software development through the assembly of independent services follows the Service-Oriented Computing (SOC) paradigm. One key in the SOC model is that third parties provide resources by presenting only external access interfaces. In this context, the analysis of issues related to the quality of service (QoS) becomes crucial for several development activities related to web services, spanning the discovery of services, their selection, composition and their adaptation in client systems. As far as we know, little has been done in terms of estimation of unknown quality attribute levels\u00a0\u2026", "num_citations": "4\n", "authors": ["1208"]}
{"title": "SmartCitySysML: A SysML Profile for Smart Cities Applications\n", "abstract": " Current infrastructures in modern cities are highly dependent on complex software-intensive systems, which are composed of many elements, including software, sensors, actuators, and processes. Citizens and managers are also important stakeholders in these systems, as they provide data, provide and retrieve information and also manage the many systems that control the city infrastructures\u2019. UML has been often considered for designing these types of systems, mostly with focus only on designing the software elements of the system. However, these infrastructures systems are composed of many more elements than software, including processes, constraints, sensors, networks, laws and further documents. SysML is a UML profile that has gained attention in past years, as SysML also models systems elements that are not software. In this paper, the main idea is to describe a SysML profile for modeling\u00a0\u2026", "num_citations": "4\n", "authors": ["1208"]}
{"title": "The utilization of the biometric technology in the 2013 Manyu division legislative and municipal elections in cameroon: an appraisal\n", "abstract": " Artificial Intelligence (AI) scholars and election stakeholders in Cameroon believe that with the use of Biometric Technology (BT) the 2013 legislative and municipal elections in Manyu Division would be credible. The preciseness of AI in our daily lives lured them to underestimate the materialistic nature of humans. The study which made use of the ex post facto research design utilized Hardie\u2019s theoretical direction of psephology to critically analyze all the arguments in the paper. The researchers identified the fact that BT cannot secure credible and transparent elections in Manyu Division where the president of the country has no political will to do so by using the elites and members of the armed forces to sway votes in favor of the ruling party. For BT to be relevant, voting should be linked to the Internet and the president should embrace electronic voting and allow ELECAM the Election Management Body in\u00a0\u2026", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Smart ticketing for academic campus shuttle transportation system based on RFID\n", "abstract": " Monitoring campus shuttling system in any university is a serious issue when considering the numerous challenges faced by the public transportation system in Nigeria such as bus ticketing, route monitoring, and scheduling. In this study, a smart ticketing system was designed for Covenant University student as a means of paying for the shuttle T-fare charges. The prototype was done on the student identity card using a RFID technology, Bluetooth, and a microcontroller. In conclusion, the proposed system was simple and cheap in implementation with the goal of eradicating mismanagement of ticket funds, paper loitering in bus stations, etc.", "num_citations": "4\n", "authors": ["1208"]}
{"title": "A Transition Model from Web of Things to Speech of Intelligent Things in a Smart Education System\n", "abstract": " Several terms have been used to describe Internet of Things; Web of Things (WoT) is a term which can be used interchangeability and it is referred to as the capability of devices to interconnect to the World Wide Web and sharing the information and data to one another. WoT has been mentioned in the literature to improve interconnection between devices at all times. In WoT, two different modes of communication which are generally mentioned in previous studies include person-to-thing (or thing-to-person) and thing-to-thing. This paper presents an architecture for transiting from WoT to speech-enabled WoT known as Speech of Intelligent Things (SoIT). The system employs a combination of technologies such as system design, server-side scripting, speech-based system tools, and data management in developing the SoIT prototype system as a third mode of communication. This paper illustrates a\u00a0\u2026", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Post-occupancy evaluation of building facilities in a university community using an electronic platform\n", "abstract": " The study examined the prospects of carrying out a post-occupancy evaluation of building facilities in a university community using an electronic platform. The SRS showed the user classes and characteristics, software architecture, functionality, the coding language used and external interfaces. The Web pages were designed using HTML, while the database management system was developed using MySQL. C-Sharp programming language was used to control the post-occupancy system. The three main users identified in this study; the building user, the maintenance manager/facility manager and the management team can access the system to evaluate the building facilities. In conclusion, the study developed a post-occupancy evaluation system for a university community to effectively manage the state of its building facilities. By using the proposed system, the study aims to increase the speed of maintenance\u00a0\u2026", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Comparative analysis of optimisations of antecedents and consequents of fuzzy inference system rules lists using genetic algorithm operations\n", "abstract": " Researches have pointed to the fact that fuzzy logic controls (FLC) largely rely on the inputs, rules lists specifying logical notation and outputs for its inference applications. The accuracy of these inference systems outputs is directly influenced by the quantity of rules constituting the Rule Bases (RBs), which are often redundant, poorly mapped and inconsistent, arising from human experts\u2019 construction errors. This paper is investing the effectiveness of optimising antecedents and consequents of Rules Bases separately using genetic algorithms operations. The resultant rules lists realised from both genetic procedures are used to construct FLC. The training and evaluation of FLCs were carried out using DangoteCem PLC shares prices data set including opening, highest and closing prices. The paper found that the optimisation of RB-antecedents minimised the rules list redundancy to five (5) rules. Whereas, the optimisation of RB-consequents minimised the rules list to seven (7) rules when compared to nine (9) rules of initial human experts\u2019 rules. However, the FLC constructed with five rules produced better forecasting outcomes as against that with seven (7) rules using parameters such as MSE, RMSE, RAE and MAPE.", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Dynamic interface and access model by dead token for IoT systems\n", "abstract": " Communication between users and intelligent devices is normally done through a graphical user interface. In addition, devices that communicate using Bluetooth are also implementing a control interface. Thus, most of the devices in an enclosure such as home or work can be remotely controlled. This implies that each device can have an interface and an IP assignment for its own control. In this way, users must learn and manage several communication interfaces. In this paper, we present a model of a general graphical user interface to control different smart devices that can consume HTTP requests or that are controlled by Bluetooth. In addition, we present an authentication approach for the Internet of Things that uses the proposed model.", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Attitude of mobile telecommunication subscribers towards sim card registration in Lagos State, Southwestern Nigeria\n", "abstract": " Despite the concerted effort of the Nigeria Communication Commission (NCC) to ensure that Nigeria mobile phone subscribers register their SIM cards, there has been some level of apathy on the part of the mobile phone subscribers. This study investigated the attitude of mobile telecommunication subscribers towards SIM card registration in Lagos Metropolis, Nigeria. The theories of planned behaviour and reasoned action were adapted for the study because they provide the necessary constructs that help to investigate the attitudes of telecommunication subscribers. The purposive sampling technique was adopted in selecting five local government areas within Lagos. Random sampling method was used to select 300 mobile phone subscribers. In total, 290 responses were collected and were found usable. Data analysis was performed using statistical methods, and Spearman\u2019s correlation analysis was\u00a0\u2026", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Artificial intelligence techniques for electrical load forecasting in smart and connected communities\n", "abstract": " Electricity consumption has been on a rapid increase worldwide and it is a very vital component of human life in this age. Hence, reliable supply of electricity from the utility operators is a necessity. However, the constraints that electricity supplied must be the same as electricity consumed puts the burden on the utility operators to make sure that demand is equal to supply at any point in time in smart and connected communities. Load forecasting techniques, therefore, aim to resolve these challenges for the operators by providing accurate forecasts of electrical load demand. This paper reviews current and mostly used short term forecasting techniques, drawing parallels be-tween them; and highlighting their advantages and disadvantages. This paper concludes by stating that there is no one-size-fits-all technique for load forecasting problems, as appropriate techniques depend on several factors such as\u00a0\u2026", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Computational Science and Its Applications\u2013ICCSA 2018: 18th International Conference, Melbourne, VIC, Australia, July 2-5, 2018, Proceedings, Part I\n", "abstract": " The five volume set LNCS 10960 until 10964 constitutes the refereed proceedings of the 18th International Conference on Computational Science and Its Applications, ICCSA 2018, held in Melbourne, Australia, in July 2018. Apart from the general tracks, ICCSA 2018 also includes 34 international workshops in various areas of computational sciences, ranging from computational science technologies, to specific areas of computational sciences, such as computer graphics and virtual reality. The total of 265 full papers and 10 short papers presented in the 5-volume proceedings set of ICCSA 2018, were carefully reviewed and selected from 892 submissions.", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Database inconsistency measures and their applications\n", "abstract": " We investigate the measuring of inconsistency of formal sentences, a field with increasing popularity in the literature about computer science, mathematics and logic. In particular, we look at database inconsistency measures, as featured in various publications in the literature. We focus on similarities and differences between inconsistency measures for databases and for sets of logic sentences. Also some differences to quality measures are pointed out. Moreover, we pace some characteristic applications of database inconsistency measures, which are related to monitoring, maintaining and improving the quality of stored data across updates.", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Computational Science and Its Applications\u2013ICCSA 2017: 17th International Conference, Trieste, Italy, July 3-6, 2017, Proceedings, Part III\n", "abstract": " The six-volume set LNCS 10404-10409 constitutes the refereed proceedings of the 17th International Conference on Computational Science and Its Applications, ICCSA 2017, held in Trieste, Italy, in July 2017. The 313 full papers and 12 short papers included in the 6-volume proceedings set were carefully reviewed and selected from 1052 submissions. Apart from the general tracks, ICCSA 2017 included 43 international workshops in various areas of computational sciences, ranging from computational science technologies to specific areas of computational sciences, such as computer graphics and virtual reality. Furthermore, this year ICCSA 2017 hosted the XIV International Workshop On Quantum Reactive Scattering. The program also featured 3 keynote speeches and 4 tutorials.", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Lessons from intensive educational experiences for ICT students in multinational settings.\n", "abstract": " Original scientific paper Real internationalization of education is the current challenge for students, teachers and universities in Europe after assuming the implementation of the EHEA (European Higher Education Area). The Erasmus programme has been playing a key role in exposing stakeholders to European internationalization. Although the large global figures of the programme are frequently analyzed, it is important to study the effects of the participation in exchange programs on students and teachers. Erasmus Intensive programs enable a closer look at the daily experience of students. In this article, we analyse the effects of intensive international programs on participants' perceptions and attitudes referred to international and multicultural working environments. Data for the analysis were collected through several experiences where ICT students were involved in intensive multinational programs. Results from 125 students using pre-and post-experience questionnaires show interesting benefits of participating in intensive experiences before starting longer or more challenging activities: they feel more motivated to be engaged in semester long staying or professional work abroad, less worries about how to work in multicultural settings, increment in self-confidence, etc.", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Evaluation of a Cloud Based Health Information System\n", "abstract": " In ensuring adequate antenatal and postnatal care which has been a major challenge in Africa and indeed Nigeria, there has been a need to evaluate and profound a comprehensive Health Information System (HIS) required for reducing Maternal Mortality Ratio (MMR) in the continent of Africa. There is a need for promptness and efficient healthcare for mothers to stem infant mortality ratios while giving the mothers a chance to life in difficult circumstances during child delivery. In some health care facilities in Nigeria the presence of HIS is obvious but it has not fully achieved the aim by which it was implemented due to lack of evaluation of the application. Hence this presentation tends to evaluate a usability of Health Information System using Cloud Platform for Antenatal and Postnatal Clinic in Nigeria to assess its suitability and sustainability in healthcare services towards improving maternal health. In the\u00a0\u2026", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Syllable-based text compression: a language case study\n", "abstract": " Compression of texts has been widely studied by various researchers and in the process, several algorithms have been proposed. However, compression of texts using the syllabic structure of words in syllable-based languages has emerged as another dimension to the compression of texts. An algorithm for syllable extraction from words should be designed based on the structure of a language due to the ineffectiveness of the presently existing \u201cuniversal\u201d algorithms. Several syllable-based methods of compression proposed by different authors are reviewed in this work, including the methodologies used in achieving text compression. Finally, an algorithm for syllable extraction from words in the Yoruba language is presented and compared with four universal algorithms, recording the best result (100 % accuracy) among the five; the significance of this is that a dictionary of common syllables does not need\u00a0\u2026", "num_citations": "4\n", "authors": ["1208"]}
{"title": "An approach to solve the set covering problem with the soccer league competition algorithm\n", "abstract": " The Soccer League Competition algorithm (SLC) is a new nature-based metaheuristic approach to solve optimization problems. It gets its basis model from the interaction between soccer teams and their players in a soccer league competition, where each player (feasible solution) compete for victory and be the best player.                 This paper presents a review of the underlaying SLC model and a practical approach to solve the Set Covering Problem using SLC and Python as programming language and tested over a widely OR-Library SCP benchmarks to obtain convergence capability and effectiveness of the implementation.", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Measure-based repair checking by integrity checking\n", "abstract": " Quality damage in databases can be measured by seizing extant inconsistency, i.e., by quantifying the amount of violation of integrity constraints. A repair is an update that reduces inconsistency and hence improves data quality. Repair checking finds out if a given update is a repair or not. Repair checking can be done by checking if the undo of the update increases the amount of integrity or not. To do so, sound measure-based integrity checking methods can be used. To do so well, the used methods should also be complete. Repair checking by integrity checking is an attractive alternative to conventional repair checking approaches. However, the completeness of measure-based integrity checking may be a problem, in general. We build on concepts, techniques and results as presented in the first author\u2019s previous work.", "num_citations": "4\n", "authors": ["1208"]}
{"title": "A Cloud-Based Retail Management System\n", "abstract": " Retail management systems have been deployed extensively as web applications and stand-alone systems. However, in order to maximize return on investment while also improving on retail business efficiency and performance, it is imperative to explore newer technologies that can be leveraged. Cloud computing shows great potential in this regard; and so it is our aim in this paper to develop a cloud-based retail management system. We realize this by first designing the framework of the system and then implementing it.", "num_citations": "4\n", "authors": ["1208"]}
{"title": "A two-way loop algorithm for exploiting instruction-level parallelism in memory system\n", "abstract": " There is ever increasing need for the use of computer memory and processing elements in computations. Multiple and complex instructions processing require to be carried out almost concurrently and in parallel that exhibit interleaves and inherent dependencies. Loop architectures such as unrolling loop architecture do not allow for branch/conditional instructions processing (or execution). Two-Way Loop (TWL) technique exploits instruction-level parallelism (ILP) using TWL algorithm to transform basic block loops to parallel ILP architecture to allow parallel instructions processes and executions. This paper presents TWL for concurrent executions of straight forward and branch/conditional instructions. Further evaluation of TWL algorithm is carried out in this paper.", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Framework for maintainability measurement of web application for efficient knowledge-sharing on campus intranet\n", "abstract": " Web Application is placed and accessed over a network, which could be an intranet, extranet or the internet. An intranet is identified as an ideal platform for knowledge- sharing and collaboration in organizations, or institutions. But it is at times hampered by maintainability issue which indeed is a key quality attribute of web applications. This paper presents an explicit description of a process for prediction of maintainability of web application based on design metrics and statistical approach. The work investigates whether a set of measures identified for UML class diagram structural properties (size, complexity, coupling, cohesion) could be good predictors of class diagram maintainability based on the sub-characteristics; understandability, analyzability, and modifiability. Results indicate that useful prediction models can be built from the measures and identified the strongest predictors from the proposed\u00a0\u2026", "num_citations": "4\n", "authors": ["1208"]}
{"title": "An analysis of the factors influencing radiation dose and fluoroscopic time during renal artery stent placement\n", "abstract": " Purpose:To determine the factors that affect mean absorbed dose and fluoroscopic times during renal artery stent placement. Materials andMethods:After institutional review board approval, the HI-IQ database was queried for patients undergoing renal artery stent placement only from January 2007 to June 2010. Procedures that were performed as part of other procedures such as iliac artery stents were excluded. The HI-IQ data included fluoroscopy time (f) and radiation dose (mGy). Demographic, medical history, procedural details, and advanced preprocedural renal artery stent imaging were obtained. Variables (number of stents, average body mass index , number of stents placed per year and number of years\u2019 service of an interventional physician, pre-procedural imaging, and use of embolic protection device) were analyzed using a t test after log transformation and testing for variance with an F test.Results:A\u00a0\u2026", "num_citations": "4\n", "authors": ["1208"]}
{"title": "A Metric in Global Software Development Environment.\n", "abstract": " Metrics and measurement techniques for managing projects in global software development (GSD) environment. GSD, as a practice, offer a variety of advantages, as well as limitations. This paper mathematically models two common concepts in GSD environment, under the resource requirements of software development, namely coherence and collocation. Both terms have been used informally to explain some results obtained from on-site studies in respect of speed of project execution. The logic consists in exploiting the merits of GSD, whilst mitigating its demerits. Because this paper would only seek to introduce the metric, further studies are recommended to further explore the feasibility of the model, and possible enhancements to aid its efficiency.", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Plagiarism detection in software using efficient string matching\n", "abstract": " String matching refers to the problem of finding occurrence(s) of a pattern string within another string or body of a text. It plays a vital role in plagiarism detection in software codes, where it is required to identify similar program in a large populations. String matching has been used as a tool in a software metrics, which is used to measure the quality of software development process. In the recent years, many algorithms exist for solving the string matching problem. Among them, Berry\u2013Ravindran algorithm was found to be fairly efficient. Further refinement of this algorithm is made in TVSBS and SSABS algorithms. However, these algorithms do not give the best possible shift in the search phase. In this paper, we propose an algorithm which gives the best possible shift in the search phase and is faster than the previously known algorithms. This algorithm behaves like Berry-Ravindran in the worst case. Further\u00a0\u2026", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Electron Paramagnetic Resonance of Mn2+-Doped Cadmium Formate Dihydrate Single Crystals\n", "abstract": " An electron paramagnetic resonance (EPR) study on Mn 2+ doped Cadmium formate dihydrate single crystals is carried out. The EPR spectrum at room temperature exhibits only one out of five fine structural transitions which split into six hyperfine lines in all directions. The spectrum is simulated using the EasySpin program and evaluated spin Hamiltonian parameters. The simulated EPR spectrum is in good agreement with the experiment. By comparing direction cosines of spectroscopic splitting factor g and the direction cosines of different bonds determined by the crystal structure data it is found that Mn 2+ enters the lattice substitutionally and only one Mn 2+ site is identified. The obtained g and the hyperfine interaction constant A achieved are g= 2.006\u00b10.002, A=(98\u00b12)\u00d7 10\u2212 4 cm\u2212 1 and the second-order axial zero-field splitting parameter D=(60\u00b12)\u00d7 10\u2212 4 cm\u2212 1.", "num_citations": "4\n", "authors": ["1208"]}
{"title": "The impact of cognitive and socio-demographic factors at meetings during software development process\n", "abstract": " Most of the important decisions are taken at team meetings during software development process (SDP) and the way of thinking of project leader plays an important role in achieving quality objectives at these team meetings. Considering this important issue, this paper investigates the impact of cognitive and socio-demographic factors on manager's simple thinking style towards improving the quality of team meetings in SDP. We have performed experimentations among Information and Communication Technologies\u2019(ICT) senior professionals and managers from government and private sector organizations for this purpose. The hypotheses have been developed under different empirical categories and then statistical analysis techniques have been used to draw inferences. The results indicate that\" type of team meetings\",\" project leader's cognitive characteristics\" and\" adoption of a cognitive model at team meetings\" have statistically significant impact on manager's simple thinking in terms of improving productivity and contribution of team meetings.", "num_citations": "4\n", "authors": ["1208"]}
{"title": "ESR and optical study of Cu2+-doped bis-(5, 5\u2032-diethylbarbiturato) bis picoline Zn (II)\n", "abstract": " ESR studies were conducted on Cu2+-doped bis-(5,5\u2032-diethylbarbiturato)bis picoline Zn(II). Two Cu2+ lattice sites, Cu2+(I) and Cu2+(II), were identified. These sites exhibit two sets of four hyperfine lines in all directions. The g factor and hyperfine splitting were calculated from ESR absorption spectra: gx \u2009=\u20092.0201\u2009\u00b1\u20090.002, gy \u2009=\u20092.0900\u2009\u00b1\u20090.002, gz \u2009=\u20092.1634\u2009\u00b1\u20090.002, Ax \u2009=\u2009(30\u2009\u00b1\u20092)\u2009\u00d7\u200910\u22124\u2009cm\u22121, Ay \u2009=\u2009(40\u2009\u00b1\u20092)\u2009\u00d7\u200910\u22124\u2009cm\u22121 and Az \u2009=\u2009(154\u2009\u00b1\u20092)\u2009\u00d7\u200910\u22124\u2009cm\u22121. It was found that Cu2+ enters the lattice substitutionally. The ground-state wavefunction of the Cu2+ ion in this lattice was determined from the spin Hamiltonian constants obtained from the ESR studies. With the help of an optical absorption study, the nature of the bonding in the complex is also discussed.", "num_citations": "4\n", "authors": ["1208"]}
{"title": "A discussion on IS and software measurement terminology: flexibility as an example\n", "abstract": " Closeness in meaning of the terms in the information systems and software engineering may result in discussion of using proper affiliated terms while covering the scope of research. An example is touched in this exploratory study, which discusses flexibility and its affiliated terms: changeability, adaptability, compatibility, flexibility, expandability, extendibility, extensibility and portability. A risk of misinterpretation due to the variety of the usage of the term is noted whereas the adoption of the term has shown that the literature does not have such examples to a serious level; but this review informs about missing discussions in the research reports in the literature due to omitting or ignoring affiliated terms of the keywords. Another product of this paper is to provide basis for future studies in the flexibility as a quality factor in the software measurement.", "num_citations": "4\n", "authors": ["1208"]}
{"title": "Pair programming: an empirical investigation in an agile software development environment\n", "abstract": " Several experiments carried out on Pair Programming (PP) in a controlled environment by researchers and practitioners have been said to have a positive effect on software quality and time of delivery. Pair programming can be applied in all phases of software development. Although few empirical studies have shown the benefits of pair programming, not so much work has been done on maintainability of codes in a real agile environment. Therefore, in this work, we experimented using industry-based practitioners (working at an agile software development environment) to correct errors that were introduced deliberately into a set of python codes. Data was collected by recording the time to correct the mistakes. One hundred software practitioners were paired randomly and one hundred individual junior programmers to work on the same set of codes. Data obtained were analyzed, and we got very interesting\u00a0\u2026", "num_citations": "3\n", "authors": ["1208"]}
{"title": "A teaching-learning-based optimization algorithm for the weighted set-covering problem\n", "abstract": " The need to make good use of resources has allowed metaheuristics to become a tool to achieve this goal. There are a number of complex problems to solve, among which is the Set-Covering Problem, which is a representation of a type of combinatorial optimization problem, which has been applied to several real industrial problems. We use a binary version of the optimization algorithm based on teaching and learning to solve the problem, incorporating various binarization schemes, in order to solve the binary problem. In this paper, several binarization techniques are implemented in the teaching/learning based optimization algorithm, which presents only the minimum parameters to be configured such as the population and number of iterations to be evaluated. The performance of metaheuristic was evaluated through 65 benchmark instances. The results obtained are promising compared to those found in the literature.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Solving the 0/1 Knapsack Problem Using a Galactic Swarm Optimization with Data-Driven Binarization Approaches\n", "abstract": " Metaheuristics are used to solve high complexity problems, where resolution by exact methods is not a viable option since the resolution time when using these exact methods is not acceptable. Most metaheuristics are defined to solve problems of continuous optimization, which forces these algorithms to adapt its work in the discrete domain using discretization techniques to solve complex problems. This paper proposes data-driven binarization approaches based on clustering techniques. We solve different instances of Knapsack Problems with Galactic Swarm Optimization algorithm using this machine learning techniques.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "A Framework for Cyber Ethics and Professional Responsibility in Computing\n", "abstract": " In this study, a model was developed for cyber ethics and professional responsibility in computing. There is a need for every mobile phone user to have access to cyber ethics and professional issues. This study designed an architectural mobile application framework using HTML, JSP, and CSS. The back end of the application was developed using SQL. The application can be installed on handheld devices that support the android operating system. The effort taken for scripting is 12\u00a0h while the performance scripting productivity is calculated to be 3 operations per hour. The application is recommended for all mobile phone users.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Detection of Malicious URLs on Twitter\n", "abstract": " Twitter is an online social network that is popular for its use of 140-character messages called tweets to exchange information, news and connects the global world. Due to the large audience of people that make use of twitter, malicious users from time to time try to find ways to attack it. This is because the usages of URLs in tweets expose them and make them prone to attacks such as malware distribution, phishing, spam and scam. In this project, a system is developed that detected suspicious URLs on twitter, and the proposed system investigates the correlation of URL redirect chains extracted from various tweets on twitter. Therefore, after a large number of tweets are collected from twitter public timeline, a classifier by naive Bayes machine learning algorithm is built using the data.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Enhancing stock prices forecasting system outputs through genetic algorithms refinement of rules-lists\n", "abstract": " The intent of stock market was to amass capital in an economy and distribute of same to high-yielding return ventures. Recently, stock markets are considered the foremost meeting point of information such as macroeconomic, national and investor. There are significant mechanisms for measuring future progress in the economy and the markets. Studies have revealed that fuzzy logic control (FLC)-based forecasting models rely on the composition of rules-lists, which are often redundant due to poor mapping of their antecedents and conditions to the consequents. This paper introduced a process of refining the rules-lists with the use of genetic algorithm. A refined rules-list was constructed for FLC rules base after the removal of inherent redundancy. To evaluate the proposed enhanced FLC model, the inputs and output variables were opening, highest and closing prices of Dangote Cement Company Shares\u00a0\u2026", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Identifying Phishing Through Web Content and Addressed Bar-Based Features\n", "abstract": " Phishing which can also be called spoofing is mainly used to explain an approach being used by Internet scammers or cybercriminals to lure a genuine Internet user into revealing vital, confidential and classified information with the intention of using information gathered against them. Through this form of vulnerability, cybercriminals use the information obtained to gain access into personal information to rob individual of valuables ranging. Since Internet users have increased gloabally, the number of people accessing email, social media and only transaction has increased accordingly. The upsurge in the number of Internet user has therefore enhanced the nefarious activities of the cybercriminals. Verification and checking of address bar features and content of web were adopted in handling phishing detection in this work. Efforts were made to properly study various features of websites considered as phishing as\u00a0\u2026", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Smart City Waste Management System Using Internet of Things and Cloud Computing\n", "abstract": " Indiscriminate disposal of solid waste is a major issue in urban centers of most developing countries and it poses a serious threat to healthy living of the citizens. Access to reliable data on the state of solid waste at different locations within the city will help both the local authorities and the citizens to effectively manage the menace. In this paper, an intelligent solid waste monitoring system is developed using Internet of Things (IoT) and cloud computing technologies. The fill level of solid waste in each of the containers, which are strategically situated across the communities, is detected using ultrasonic sensors. A Wireless Fidelity (Wi-Fi) communication link is used to transmit the sensor data to an IoT cloud platform known as ThingSpeak. Depending on the fill level, the system sends appropriate notification message (in form of tweet) to alert relevant authorities and concerned citizen(s) for necessary action. Also, the\u00a0\u2026", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Comparative analysis of three obstacle detection and avoidance algorithms for a compact differential drive robot IN V-Rep\n", "abstract": " The aim of this research is to build a compact differential drive robot using the Virtual Robotics Experimentation Platform. Sensors are embedded in the Pioneer 3-dx mobile robot to provide necessary data from the real world to the robot. The main purpose of the mobile robot is its ability to arrive at a given destination (goal) precisely and astutely, hence, significantly reducing the risk of human mistakes. Many existing algorithms like obstacle detection, lane detection is combined to provide the essential and basic control functionalities to the car. The mobile robot controller model runs on a series of benchmark tasks, and its performance is compared to conventional controllers. During the scope of this project, comparisons between different algorithms, hardware and tools have been made to choose the best-fit for the project. The results are obstacle detection algorithms and a terrain handling feature, that works very\u00a0\u2026", "num_citations": "3\n", "authors": ["1208"]}
{"title": "An intelligent advisory system to support managerial decisions for a social safety net\n", "abstract": " Social investment programs are designed to provide opportunities to the less privileged so that they can contribute to the socioeconomic development of society. Stakeholders in social safety net programs (SSNPs) target vulnerable groups, such as the urban poor, women, the unemployed, and the elderly, with initiatives that have a transformative impact. Inadequate policy awareness remains a challenge, resulting in low participation rates in SSNPs. To achieve all-inclusive development, deliberate policies and programs that target this population have to be initiated by government, corporate bodies, and public-minded individuals. Artificial intelligence (AI) techniques could play an important role in improving the managerial decision support and policy-making process of SSNPs and increasing the social resilience of urban populations. To enhance managerial decision-making in social investment programs, we used a Bayesian network to develop an intelligent decision support system called the Social Safety Net Expert System (SSNES). Using the SSNES, we provide an advisory system to stakeholders who make management decisions, which clearly demonstrates the efficacy of SSNPs and inclusive development. View Full-Text", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Effect of feature selection on performance of internet traffic classification on NIMS multi-class dataset\n", "abstract": " The challenges faced by networks nowadays can be solved to a great extent by the application of accurate network traffic classification. Internet network traffic classification is responsible for associating network traffic with the application generating them and helps in the area of network monitoring, Quality of Service management, among other. Traditional methods of traffic classification including port-based, payload-load based, host-based, behavior-based exhibit a number of limitations that range from high computational cost to inability to access encrypted packets for the purpose of classification. Machine learning techniques based on statistical properties are now being employed to overcome the limitations of existing techniques. However, the high number of features of flows that serve as input to the learning machine poses a great challenge that requires the application of a pre-processing stage known as\u00a0\u2026", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Empirical Comparison of Cross-Validation and Test Data on Internet Traffic Classification Methods\n", "abstract": " In this paper, we compare two validation methods that are used to estimate the performance of classification algorithms in a non-problem-specific knowledge scenario. One way to measure the performance of a classification algorithm is to determine its prediction error rate. However, this value cannot be calculated but estimated. In this work, we apply and compare two common methods used for estimation namely: test data and cross-validation. Precisely, we analyze and compare the statistical properties of the K-fold cross-validation and test data estimators of the prediction error rates of six classifiers namely; Na\u00efve Bayes, KNN, Random Forest, SVM, J48, and OneR. From the study, the statistical property of repeated cross-validation tends to stabilize the prediction error estimation which in turn reduces the variance of the prediction error estimator when compared with test data. The NIMS dataset collected over a\u00a0\u2026", "num_citations": "3\n", "authors": ["1208"]}
{"title": "A Database for Handwritten Yoruba Characters\n", "abstract": " This paper describes a novel publicly available dataset for research on offline Yoruba handwritten character recognition. It contains a total of 6954 characters being made up of several categories from a total number of 183 writers thus making it the largest available dataset for Yoruba handwriting research. It can be used for designing and evaluating handwritten character recognition systems for the Yoruba language as well as provide valuable insights through writer identification. The dataset has been partitioned into training and test sets being shared into 70% and 30% respectively.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Representing contexual relations with sanskrit word embeddings\n", "abstract": " Language processing of Sanskrit presents various challenges in the field of computational linguistics. Prosodical, orthographic and inflectional complexities encountered in Sanskrit texts makes it difficult to apply linguistic analysis methods relevant for western European languages. The inadequacy of contemporary computational approaches in the analysis of Sanskrit language is vivdly apparent. In this exposition, we focus on the challenge of learning syntactic and semantic similarities in a rich Sanskrit literature. We present a simple yet effective approach of representing Sanskrit words in a continuous vector space. We utilise word embeddings in similarity, compositionality and visualization tasks to test its efficacy. Experiments show that our method produces interpretable vector offsets exhibiting shared relationships.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "A hybrid web caching design model for internet-content delivery\n", "abstract": " The need for online contents (or resources) to be shared and distributed in a large and sophisticated networks of users, geographical dispersed location of servers and their clients, time taken to fulfil clients requests pose major challenge. Therefore the choice of suitable architecture for", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Closing institutional gaps through academic research management system and implications in Nigeria\n", "abstract": " The world today has a number of valuable research scholars desiring connections and collaborations. The existing online collaboration platforms are not sufficient to accommodate the totality of researchers desiring dynamic platforms to network globally. Despite growing contributions in the literature on Social Network Site (SNS), regarding the capacity to connect people remotely, there is still a dearth of research on how SNS potentially integrates academics into social capital formation. The objective of this study is to provide Academic Research Management System (ARMS) for the research community. The research methods that were employed for the study include unified modeling language (UML) for the design; and Hypertext Mark-up Language (HTML), Hypertext Preprocessor (PHP) and MySQL for front end, server side programming and database respectively. The system was evaluated for usability and the implications for deploying the ARMS in Nigeria were also considered in this study. Findings: The findings from the usability survey showed a good usability based on total rating of 4.10 out of 5 point scale. The integration of the system into the academic institutions worldwide would foster a rapport between academics in all fields of learning and provide a means to have access to colleagues and research materials when needed.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Solving set covering problem with fireworks explosion\n", "abstract": " To solve the Set Covering Problem we will use a metaheuristic Fireworks Algorithm inspired by the fireworks explosion. Through the observation of the way that fireworks explode is much similar to the way that an individual searches the optimal solution in swarm. Fireworks algorithm (FWA) consists of four parts, i.e., the explosion operator, the mutation operator, the mapping rule and selection strategy. The Set Covering Problem is a formal model for many practical optimization problems. It consists in finding a subset of columns in a zero/one matrix such that they cover all the rows of the matrix at a minimum cost.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Applying Metaheuristic Algorithm to the Admission Problem as a Combinatorial Optimisation Problem.\n", "abstract": " Prominent among the factors militating against quality education is poor student intake standards. This in the long run has multiplier effect on the quality of a nation's human capital. The role of human capital in national transformation cannot be overemphasized. However, the process of developing human resource for socio-economic transformation, particularly in an optimal sense, means conscious and concerted efforts must be geared towards meritocracy. Secondary education is reputed for bridging the gap between primary education and tertiary education. It particularly provides the gateway for career development as subjects taken at the senior level are tailored towards future career choices. To ensure that resources invested in education are well utilized, students\u2019 admission process has to be streamlined to secure best candidates specifically in gifted schools where competition is high. This paper formulated a computational strategy to upgrade admission process by reducing cost and time associated with it. Using a Nigerian University Secondary School as case study, the researchers applied a Metaheuristics search algorithm to the admission problem of securing the best candidates from a pool of applicants. The results supported the claims that Metaheuristics algorithms are capable of optimizing an admission process in terms of cost and speed.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "A cooperative approach for malicious node detection in impromptu wireless networks\n", "abstract": " Security is at stake once communication takes place between mobile nodes in very hostile surroundings. Contrary to the wired networks, the exclusive individuality of mobile impromptu networks produce variety of major challenges to security style, like mutual wireless medium, open peer-to-peer specification, stern resource constraints and extremely dynamic topology. These unfavorable conditions clearly need a case for making dimensional security remedies that get not solely wide selection protection however additionally acceptable network performance. Popularly used existing routing protocols designed to include the wants of such endemic networks don't address doable threats aiming at the disruption of the protocol itself. The most important challenge in impromptu wireless networks is energy inefficiency; beneath bound circumstances, it's virtually not possible to interchange or recharge the batteries. Thence\u00a0\u2026", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Precise Delta Extraction Scheme for Reprogramming of Wireless Sensor Nodes\n", "abstract": " In this paper, we present a precise delta extraction scheme and tool for use in wireless sensor network reprogramming processes. Our approach involves the use of a novel algorithm based on SET theory and the unique pattern of the Execution Link File (ELF) structure to extract delta from two distinct firmware (original and the modified). The delta consist of two set of unique values: one set clearly indicate the address of where the change has occurred and the second relays the change Data content. In addition, we developed a set of metrics that relays the degree of modification made with respect to the original file. The scheme capabilities, when compared with similar utilities referred in literature, shows an appreciable capacity to reduce energy consumption rate as well as effect a reduction in the amount of memory space used during reprogramming processes.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "On the investigation of social network analysis for E-commerce transaction in south-west region of Nigeria\n", "abstract": " An investigative survey of the application of Social Network Analysis on e-commerce is presented and methods to improve e-commerce activity in this region is reported. The research reviewed relevant papers by survey based on the existing research work in the field of e-commerce, using social network analysis. This research presents an investigation on the application of social network analysis on e-commerce, with a case study of the user\u2019s perception in the South West Region of Nigeria. An investigation that was carried out revealed the different research works of others and the research was built upon by the metric presented. This approach was applied to influence the importance of Social Network Analysis in e-commerce. The data collected and the methods used by researcher proved the usefulness of the measures used in Social Network Analysis of e-Commerce. This research shows that the importance and potential of Social Network Analysis on e-commerce, is particularly, based on how Social Network Analysis has been used to improve e-commerce recommender systems which can give users a better shopping experience in Nigeria. Using Social Network Analysis for E-commerce in South west Nigeria to improve e- commerce activities.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Autonomous tuning for constraint programming via artificial bee colony optimization\n", "abstract": " Constraint Programming allows the resolution of complex problems, mainly combinatorial ones. These problems are defined by\u00a0a set of variables that are subject to a domain of possible values and a set of constraints. The resolution of these problems is carried out by a constraint satisfaction solver which explores a search tree of potential solutions. This exploration is controlled by the enumeration strategy, which is responsible for choosing the order in which variables and values are selected to generate the potential solution. Autonomous Search provides the ability to the solver to self-tune its enumeration strategy in order to select the most appropriate one for each part of the search tree. This self-tuning process is commonly supported by an optimizer which attempts to maximize the quality of the search process, that is, to accelerate the resolution. In this work, we present a new optimizer for self-tuning in\u00a0\u2026", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Data consistency: Toward a terminological clarification\n", "abstract": " \u2018Consistency\u2019 is an \u2018inconsistency\u2019 are ubiquitous term in data engineering. Its relevance to quality is obvious, since \u2018consistency\u2019 is a commonplace dimension of data quality. However, connotations are vague or ambiguous. In this paper, we address semantic consistency, transaction consistency, replication consistency, eventual consistency and the new notion of partial consistency in databases. We characterize their distinguishing properties, and also address their differences, interactions and interdependencies. Partial consistency is an entry door to living with inconsistency, which is an ineludible necessity in the age of big data.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "A scheduling problem for software project solved with ABC metaheuristic\n", "abstract": " The scheduling problems are very common in any industry or organization. The software project management is frequently faced with different scheduling problems. We present the Resource-Constrained Project Scheduling problem as a generic problem in which different resources must be assigned to different activities, so that the make span is minimized and a set of precedence constraints between activities and resource allocation to these activities are met. This Problem is a NP-hard combinatorial optimization problem. In this paper we present the model the resolution of the problem through the Artificial Bee Colony algorithm. The Artificial Bee Colony is a metaheuristic that uses foraging behavior of honey bees for solving problems, especially applied to combinatorial optimization. We present an Artificial Bee Colony algorithm able to solve the Resource-Constrained Project Scheduling efficiently.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Performance analysis of non-preemptive priority with application to cloud E-marketplaces\n", "abstract": " The increase in the level of awareness by consumers about the Cloud E-marketplaces has brought rapid growth in these competitive markets. As the markets grow, most providers are implementing different service offerings based on consumers' demand. One major challenge which has not been fully discussed in these markets is the performance impact of these offerings on consumers'. The goal of this research is to model a typical cloud marketplace and evaluate the performance impact on consumers' waiting time. To address this, we model a typical Cloud under a non-preemptive multi class discipline using Queuing theory to formulate our mathematical model and then use discrete event simulator to demonstrate a real scenario. Our evaluation was based on Non preemptive priority and non-priority discipline. Our results reveal that the unconditional average waiting time remains the same but we recorded a\u00a0\u2026", "num_citations": "3\n", "authors": ["1208"]}
{"title": "POTENTIAL OF SUPPORT-VECTOR REGRESSION FOR FORECASTING STREAM FLOW.\n", "abstract": " Original scientific paper Stream flow is an important input for hydrology studies because it determines the water variability and magnitude of a river. Water resources engineering always deals with historical data and tries to estimate the forecasting records in order to give a better prediction for any water resources applications, such as designing the water potential of hydroelectric dams, estimating low flow, and maintaining the water supply. This paper presents three soft-computing approaches for dealing with these issues, ie artificial neural networks (ANNs), adaptive-neuro-fuzzy inference systems (ANFISs), and support vector machines (SVMs). Telom River, located in the Cameron Highlands district of Pahang, Malaysia, was used in making the estimation. The Telom River\u2019s daily mean discharge records, such as rainfall and river-level data, were used for the period of March 1984\u2013January 2013 for training, testing, and validating the selected models. The SVM approach provided better results than ANFIS and ANNs in estimating the daily mean fluctuation of the stream\u2019s flow.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Exploratory study of techniques for exploiting instruction-level parallelism\n", "abstract": " The performance of memory system depends majorly on types of instruction constructs, speedup of executions, capacity of processing elements and scheduling techniques. Most scheduling techniques are faced with several challenges such as multiple issues, exploiting more parallelism in programs instructions, speedup rate of executions and support for conditional instructions constructs. Recent innovations in memory system and scheduling techniques required support for instruction-level parallelism (ILP) algorithm, which is overlapping of instructions sets for parallel processing and execution. To achieve these, a survey of the widely used techniques for exploiting of instruction-level parallelism (ILP) is carried out to identify their strengths and their weaknesses by reviewing several related works. This paper finds out the limitations of the various techniques for exploiting ILP and used these reviews to propose a\u00a0\u2026", "num_citations": "3\n", "authors": ["1208"]}
{"title": "An anti-cultism social education media system\n", "abstract": " Social media online forum is one of the most popular platforms used by students to communicate. Unfortunately, these media have been hijacked by people to plan and commit online fraud and societal evils. Some of the secondary and university campuses in Nigeria have been turned to cultist environments leading to killings and anarchy amongst students. This situation has defied solutions in most tertiary institutions in the country, particularly in the public institutions. The objective of this paper is to provide an anti-cultism social media educational system that will be accessed using three modes: Web, Mobile and Voice. The system will support learning and interaction on campus while at the same time helping to curb cultism on campus through filtering of communicated social media keywords that are cultism or crime related, among students. In carrying out this project, appropriate research methods and\u00a0\u2026", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Improving requirements specification in WebREd-Tool by using a NFR\u2019s classification\n", "abstract": " In Software Engineering (SE), a system has properties that emerge from the combination of its parts, these emergent properties will surely be a matter of system failure if the Non-Fuctional Requirements (NFRs), or system qualities, are not specified in advance. In Web Engineering (WE) field occurs very similar, but with some other issues related to special characteristics of the Web applications such as the navigation (with the application of the security). In this paper, we improve our Model-Driven tool, named WebREd-Tool, extending the requirements metamodel with a NFRs classification, the main idea is to help the Web application designer with the NFRs specification to make better design decisions and also to be used to validate the quality of the final Web application.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Computational Science and Its Applications--ICCSA 2013: 13th International Conference, ICCSA 2013, Ho Chi Minh City, Vietnam, June 24-27, 2013, Proceedings, Part III\n", "abstract": " The five-volume set LNCS 7971-7975 constitutes the refereed proceedings of the 13th International Conference on Computational Science and Its Applications, ICCSA 2013, held in Ho Chi Minh City, Vietnam in June 2013. The 248 revised papers presented in five tracks and 33 special sessions and workshops were carefully reviewed and selected. The 46 papers included in the five general tracks are organized in the following topical sections: computational methods, algorithms and scientific applications; high-performance computing and networks; geometric modeling, graphics and visualization; advanced and emerging applications; and information systems and technologies. The 202 papers presented in special sessions and workshops cover a wide range of topics in computational sciences ranging from computational science technologies to specific areas of computational sciences such as computer graphics and virtual reality.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Computational Science and Its Applications--ICCSA 2012: 12th International Conference, Salvador de Bahia, Brazil, June 18-21, 2012, Proceedings, Part I\n", "abstract": " The four-volume set LNCS 7333-7336 constitutes the refereed proceedings of the 12th International Conference on Computational Science and Its Applications, ICCSA 2012, held in Salvador de Bahia, Brazil, in June 2012. The four volumes contain papers presented in the following workshops: 7333-advances in high performance algorithms and applications (AHPAA); bioinspired computing and applications (BIOCA); computational geometry and applicatons (CGA); chemistry and materials sciences and technologies (CMST); cities, technologies and planning (CTP); 7334-econometrics and multidimensional evaluation in the urban environment (EMEUE); geographical analysis, urban modeling, spatial statistics (Geo-An-Mod); 7335-optimization techniques and applications (OTA); mobile communications (MC); mobile-computing, sensind and actuation for cyber physical systems (MSA4CPS); remote sensing (RS); 7336-software engineering processes and applications (SEPA); software quality (SQ); security and privacy in computational sciences (SPCS); soft computing and data engineering (SCDE). The topics of the fully refereed papers are structured according to the four major conference themes: 7333-computational methods, algorithms and scientific application; 7334-geometric modelling, graphics and visualization; 7335-information systems and technologies; 7336-high performance computing and networks.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Cognitive complexity measures: An analysis\n", "abstract": " Cognitive informatics (CI), a multidisciplinary area of research tries to solve the common problems in the field of informatics, computer science, software engineering, mathematics, cognitive science, neurobiology, psychology, and physiology. Measurement in software engineering is also a core issue which is still striving for its standardization process. In recent years, several cognitive complexity measures based on CI have been proposed. However, each of them has their own advantages and disadvantages. This chapter presents a critical review on existing cognitive complexity measures. Furthermore, a comparative study based on some selected attributes has been presented.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "A multi-paradigm complexity metric (MCM)\n", "abstract": " Huge amount of researches and software metrics have been proposed for procedural and object-oriented languages. However, there are only few metrics available in the literature related with multi-paradigm programming languages. In this paper, we propose a metric to evaluate the code written in multi-paradigm language. Our proposed metric can be used for most of the programming paradigms, including both procedural and object-oriented languages.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Parameterized String Matching Algorithms with Application to Molecular Biology\n", "abstract": " In the molecular biology, it is said that two biological sequences tend to have similar properties if they have similar 3-D structures. Hence, it is very important to find not only similar sequences in the string sense, but also structurally similar squences from the database. Parameterized string matchin has been used to find structurally similar sequences from the database. In the parameterized string matching problem, a given pattern P is said to match with a sub-string t of the text T, if there exist a bijection from the symbols of P to the symbols of t. Salmela and Tarhio solve the parameterized string matching problem in sub-linear time by applying the concept of q-gram in the Horspool algorithm (FPBMH). In this paper, we extend the Boyer Moore type algorithms: Smith, Raita and Quick Search, to solve the same problem by using the q-gram. We compare the performance of: FPBMH, Smith, Raita, and Quick search algorithms on DNA alphabet and found that Smith algorithm perform better than FPBMH algorithm.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "A comprehensive study on the Ant Colony Optimization algorithms\n", "abstract": " The ant colony optimization (ACO) algorithm is a member of the ant colony algorithms which is part of the swarm intelligence methods. It is a probabilistic technique for finding close to optimal paths through a problem space. Natural ants move from their nests to a source of food by communicating with one another by depositing a substance called pheromone along the path taken by an ant from its base to its destination (source of food). An ant that perceives the substance will naturally tend to follow that same path thereby creating a tendency for every other ant to follow through that same path where pheromone is constantly deposited by ants which had previously toured that path. The ant colony optimization algorithms therefore mimic the behavior of natural ants with the use of artificial ants as agents to find a reasonable solution to optimization problems by following the model of optimization used by natural ants to get to their destination in the shortest possible time. A review of the varieties of the ACO algorithm, application of ACO algorithms and the comparative analysis of certain variants will be presented.", "num_citations": "3\n", "authors": ["1208"]}
{"title": "Architecture Conceptualization for Health Information Systems Using ISO/IEC/IEEE 42020\n", "abstract": " Health Information Systems (HIS) are complex systems which present many difficulties in their development. From the software engineering point of view, among the difficulties for HIS development are the necessity of managing and controlling data that must be held for decades, even considering the evolution of technology in the following years, as well as the necessity of cooperating with legacy systems and describing the needs and concerns of a variety of stakeholders. Considering the domain, HIS deal with human life, and errors during software development, management and operation can be catastrophic. These concerns are relevant from the software architecture point of view. Therefore, developing HIS based on a solid software architecture is a success factor that cannot be neglected. However, the processes related to the software architecture of HIS are often considered only from low level of\u00a0\u2026", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Parameter tuning using adaptive moment estimation in deep learning neural networks\n", "abstract": " The twin issues of loss quality (accuracy) and training time are critical in choosing a stochastic optimizer for training deep neural networks. Optimization methods for machine learning include gradient descent, simulated annealing, genetic algorithm and second order techniques like Newton\u2019s method. However, the popular method for optimizing neural networks is gradient descent. Overtime, researchers have made gradient descent more responsive to the requirements of improved quality loss (accuracy) and reduced training time by progressing from using simple learning rate to using adaptive moment estimation technique for parameter tuning. In this work, we investigate the performances of established stochastic gradient descent algorithms like Adam, RMSProp, Adagrad, and Adadelta in terms of training time and loss quality. We show practically, using series of stochastic experiments, that adaptive\u00a0\u2026", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Metaheuristic-Based Intelligent Solutions Searching Algorithms of Ant Colony Optimization and Backpropagation\n", "abstract": " Computation is concerned with the validation of algorithm, estimation of complexity and optimization. This requires large dataset analysis for the purpose of finding the unknown optimal solution. Aside the intricacies in completing tasks, this process is expensive and time inefficient; attaining solutions with conventional mathematical approaches are unrealizable. Search algorithms were advanced to improve solution approaches for optimization problems by finding the possible sets of solution to a particular problem as contained in search space. However, metaheuristic algorithms suggest three solutions to optimization problems on the basis of the application areas in real-life situations including: near optima, the optimal or the best solution. This paper analyses the decision-making processes of two natureinspired search algorithms namely: Backpropagation search algorithm and ant colony optimization (ACO). The results revealed that, backpropagation search algorithm without ACO training trailed those trained with ACO for MSE, RMSE, RAE and MAPE. Again, forecasts errors estimated in the neural network set-up were smaller due to directional search mechanism of the ACO as against the approach provided in neuro-fuzzy rules set tuning by Rajab and Sharma (Soft Comput 23: 921\u2013936, 2017)[1]. There is need to consider metaheuristic algorithms approaches to obtain better solutions or nearest optimal values to the optimization problems in neural networks.", "num_citations": "2\n", "authors": ["1208"]}
{"title": "An Effective Instruction Execution and Processing Model in Multiuser Machine Environment\n", "abstract": " The quest for distributed computing and processing has further expanded multiple instruction sets for multiple users\u2019 architecture of processing elements and machines. In the past, the difficulty of distributed computing architecture of machines arose from complex nature of tasks consisting of branched and straight constructs. Again, majority of conditional (or branched) instructions rely on outputs of several other executions and processes in order to attain complete computational tasks. The underlying structures of existing compilers/processors ensure that every branched instruction construct is first transformed into straight instruction sets for ease of executions and processing. However, this structure is unsupportive of parallel processes and computations. More so, there is limited advantage for a distributed and multiuser environment. Instruction-level parallelism is advanced for distributed, time efficient, and\u00a0\u2026", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Implications of Job Loading and Scheduling Structures on Machine Memory Effectiveness\n", "abstract": " The reliable parameter for the determining the effectiveness of processing elements (such as memory and processors) is the number of cycles per instructions (CPI), execution speedups, and frequency. Job loading and scheduling techniques target instructions processing in a manner to support the underlying hardware requirements. One of the earliest methods of scheduling jobs for machines involves arrangements of instruction sets in serial order known as pipelining. Another technique uses the principle of overlapping for instruction sets in order to allow current processing and executions which is introduced in this paper. Again, there is job scheduling technique that requires enlargement of processing elements known as static approach as in the case of Intel Itanium. But, there is a great concern about the most appropriate means of scheduling and loading jobs entirely composed of dependent and branched\u00a0\u2026", "num_citations": "2\n", "authors": ["1208"]}
{"title": "A web based system for the discovery of blood banks and donors in emergencies\n", "abstract": " The blood is a connective tissue in the body and one of the most critical elements of human life. The shortage of this life-saving fluid has become a recurrent problem to deliver medical care in many countries, because in emergencies, relatives of patients run around to get specific blood type when unavailable at the medical institution, without adequate information on the closest available source. While there are existing blood bank management systems that help locate available blood bank centers with the needed blood type, they do not provide information on the nearest center and donor. This research therefore developed a web based system that provides information for the discovery of the blood bank centers and human donors with the highest proximity during emergencies. Web development technologies were used, and the Google Map API was used to track, calculate and display the location of each blood\u00a0\u2026", "num_citations": "2\n", "authors": ["1208"]}
{"title": "A Novel Unsupervised Learning Approach for Assessing Web Services Refactoring\n", "abstract": " During the last years, the development of Service-Oriented applications has become a trend. Given the characteristics and challenges posed by current systems, it has become essential to adopt this solution since it provides a great performance in distributed and heterogeneous environments. At the same time, the necessity of flexibility and great capacity of adaptation introduce a process of constant modifications and growth. Thus, developers easily make mistakes such as code duplication or unnecessary code, generating a negative impact on quality attributes such as performance and maintainability. Refactoring is considered a technique that greatly improves the quality of software and provides a solution to this issue. In this context, our work proposes an approach for comparing manual service groupings and automatic groupings that allows analyzing, evaluating and validating clustering techniques\u00a0\u2026", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Investigating Enterprise Resource Planning (ERP) Effect on Work Environment\n", "abstract": " This study aims to identify the effect of ERP system on the work environment of end users, in regarding of problem-solving support, job discretion, management visibility and cross-functionality, authority and decision rights and overall impact on the organization. This research used the survey methodology to collect data from the end-users who work for enterprises with an ERP system in Ho Chi Minh City, Vietnam. SPSS and Amos were used to test hypotheses through the Structural Equation Modeling (SEM). The study reports the impact of ERP system product performance in term of problem-solving support, job discretion, management visibility and cross-functionality, authority and decision rights and overall impact on the organization in the period of post-ERP implementation in the viewpoint of end-user in Vietnam. Based on this result, some managerial implications have been suggested.", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Conflict resolution via emerging technologies?\n", "abstract": " This paper presents a review of the current techniques and approaches adopted in conflict resolution in Multi-Agent Systems (MAS). The review highlights the strength and weaknesses, and thus, their success in fostering cooperation and collaboration in multi-agent systems. We survey alternative approaches to conflict resolution that rely on emerging technologies such as deep learning. From the survey, we discuss the benefits of using these emerging technologies in the conflict resolution process.", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Design and Development of a Cloud-Based Electronic Medical Records (EMR) System\n", "abstract": " An Electronic Medical Record System is an electronic record management tool that helps to manage the flow of patient files within a hospital, as well as improving the efficiency of the patient lifecycle and optimization of the record retrieval process. There seems to be a relationship between delayed access to a healthcare service and mortality rate. The problem of managing patient time, quick access to records, patient workflow coordination, ineffective retrieval of records, and depleting storage spaces for already digitized files are some of the issues this work seeks to address. This project is implemented in two parts. The first part deals with the design and implementation of an automated records system. The second part deals with the utilization of better storage capabilities, more flexible scalability, and access to gold standard security for the application, talking about cloud technology. The implementation\u00a0\u2026", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Towards extensible and adaptable methods in computing\n", "abstract": " Extensible and adaptable computing refers to the array of methods and techniques that systematically tackle the future growth of systems by responding proactively to change. This mandates a synergetic coordination amongst various facets of computing. Agile software development is a significant driver towards this paradigm shift and has indeed become the industry de facto standard. The ever-evolving data is another component that requires new methods of storage, transmission and processing. The Web which hosts almost all applications and data is potent with latent intelligence, ready to be mined and utilized for extending the applications and making them respond seamlessly to changing contexts. Innovative machine learning tools enable us to extricate patterns of information from repositories and adapt to changes in real time.Our journey towards extensible and adaptable methods in computing investigates\u00a0\u2026", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Cloud Computing and E-Governance: Current Issues and Developments\n", "abstract": " Cloud computing is an IT paradigm that aggregates computing resources across data centres in different location for use at a cost to cloud consumers. Cloud providers are making software application available on their platform for cloud users, making access possible anytime anywhere on a platform. Cloud providers also allow user to leverage on their operating systems to design and develop applications. In both instances mentioned, users have no control of the cloud providers\u2019 operating system, but they can always run applications at affordable cost. Infrastructure is also available in terms of storage. Storing large volumes of data makes the cloud amenable to e-governance. E-governance deals with online services made available to its people by a government. Government is involved with several ministries, department and agencies generating information and also requiring information themselves. The aim of this paper is to discuss the convergence of cloud computing and e-governance. It examines the utilization and benefits of e-governance on the cloud. It also discusses current issues and prospects of cloud e-government. The paper is an explorative work that examines qualitatively trends in e-governance and cloud computing. As a result, the paper therefore recommends that local, state and the federal government take advantages of the huge benefits of cloud computing to improve service delivery and government activities.", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Scale transformation of analytical hierarchy process to Likert weighted measurement method: an analysis on environmental consciousness and brand equity\n", "abstract": " The interdisciplinary research has found relevance in every field of data analysis, interpretation and decision making applications. The choice of important variables along with the criteria gives rise to the immense reliance of the researchers on quantitative data. The flexibility of choosing between scales for decision making, give rise to a new era of translation of scales. It also aids the researcher to reduce their efforts put in the data collection process. It needs more expertise to select the appropriate tool and scales for measuring the variables and their impact. For this purpose this piece of work is an attempt to convert Saaty's 9 point scale used for analytical hierarchy process (AHP) to a generalised Likert scale for ranking. Analytical hierarchy process (AHP) is an appropriate multicriteria decision making model, which suits the prioritising of variables for decision making process. But AHP is a much complex technique\u00a0\u2026", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Repair checking by integrity checking\n", "abstract": " Repairs are updates to reduce inconsistency. Repair checking finds out if an update is a repair. To do so, we check if the undo of the update increases the amount of integrity violation, using measure-based integrity checking. Sound repair checking by integrity checking requires the latter to be complete. Repair checking by integrity checking compares well to conventional approaches.", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Forensic investigation and analysis of user input information in business application\n", "abstract": " Objectives: This paper investigates the amount of user input that can be recovered from the volatile memory of Windows computer systems while an application is still running. Additionally, an investigation into temporal, functional analysis and event reconstruction of user input activities in business application is discussed and reported upon. Methods/Analysis: Forensically, relevant user information is suitable for an evidentiary purpose. Therefore, the qualitative assessment of user input on commonly used windows-based applications is presented. Findings: In this research, detailed emphasis has been laid on the quality of evidence recovered from the allocated line numbers of the application memory. This approach describes the process of securing digital evidence for investigators. The research uncovers the process of analysing the forensically relevant data recovered from Windows applications. The investigation comprises of the following; dumping of memory, data extraction, strings evidence strings conversion, result finding of the evidence and also, reconstructing the extracted evidence of user information. Applications/Improvement: This research focuses on digital forensic investigation of digital images captured and the memory analysis of user information on using some very popular windowsbased applications. It is aimed that this may become part of forensic analysis in digital investigations.", "num_citations": "2\n", "authors": ["1208"]}
{"title": "A Baseline Domain Specific Language Proposal for Model-Driven Web Engineering Code Generation\n", "abstract": " It is well-known that Model-Driven Web Engineering requires the development of code-generation tools in order to be adopted outside research field as a complete solution in Web application development industry. Regrettably, a fully-guided methodology supported by a complete code-generation tool that considers a complete development process based on MDA (Model-Driven Architecture) is missing. The idea behind MDA is that requirements are considered (functional and nonfunctional requirements) from the Computational Independent Model (CIM), to the Platform Specific Model (PSM) passing for the Platform Independent Model (PIM) to generate the source code for the Web application. In our work is presented a baseline DSL (Domain Specific Language) for Web application code-generation considering the basic language used in a small software factory in Mexico. This is an ongoing work which is\u00a0\u2026", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Solving biobjective set covering problem using binary cat swarm optimization algorithm\n", "abstract": " The set cover problem is a classical question in combinatorics, computer science and complexity theory. It is one of Karp\u2019s 21 NP-complete problems shown to be NP-complete in 1972. Several algorithms have been proposed to solve this problem, based on genetic algorithms (GA), Particle Swarm Optimizer (PSO) and in recent years algorithms based in behavior algorithms based groups or herds of animals, such as frogs, bats, bees and domestic cats. This work presents the basic features of the algorithm based on the behavior of domestic cats and results to solve the SCP bi-objective, experimental results and opportunities to improve results using adaptive techniques applied to Cat Swarm Optimization. For this purpose we will use instances of SCP OR-Library of Beasley by adding an extra function fitness to transform the Beasly instance to Bi-Objective problem.", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Towards e-Healthcare Deployment in Nigeria: The Open Issues\n", "abstract": " Information and communication Technology (ICT) has played vital roles in so many disciplines and it is one ofthe driving forces behind globalization. It has closed the gap in communication as well as enhanced prompt decision making thus accomplishing the United Nation Millennium Development Goals Target 18 which expresses the maximization of the values of advancement in ICT through collaboration with private sectors. Healthcare as a discipline has also embraced this dynamic tool to fashion out what is known as e-health targeted towards improving the health system of the people. Consumers are tired of the usual routine of waiting long hours on queue for appointments; struggling with inconvenient scheduling that deprives them of being fully at work or engaging in productive work. The fact still remains that healthcare system in developing countries has not kept pace with other sectors of the\u00a0\u2026", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Evaluation of hadoop/mapreduce framework migration tools\n", "abstract": " In distributed systems, database migration is not an easy task Companies will encounter challenges moving data including legacy data to the big data platform. This paper reviews some tools for migrating from traditional databases to the big data platform and thus suggests a model, based on the review.", "num_citations": "2\n", "authors": ["1208"]}
{"title": "An Evaluation on Developer\u2019s Perception of XML Schema Complexity Metrics for Web Services\n", "abstract": " Undoubtedly, the Service-Oriented Computing (SOC) is not an incipient computing paradigm anymore, while Web Services technologies is now a very mature stack of technologies. Both have been steadily gaining maturity as their adoption in the software industry grew. Accordingly, several metric suites for assessing different quality attributes of Web Services have been recently proposed. In particular, researchers have focused on measuring services interfaces descriptions, which like any other software artifact, have a measurable size, complexity and quality. This paper presents a study that assesses human perception of some recent services interfaces complexity metrics (Basci and Misra\u2019s metrics suite). Empirical evidence suggests that a service interface that it is not complex for a software application, in terms of time and space required to analyze it, will not be necessarily well designed, in terms of best\u00a0\u2026", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Measuring the Reusable Quality for XML Schema Documents\n", "abstract": " eXtensible Markup Language (XML) based web applications are widely used for data describing and providing internet services. The design of XML schema document (XSD) needs to be quantified with software with the reusable nature of XSD. This nature of documents helps software developers to produce software at a lower software development cost. This paper proposes a metric Entropy Measure of Complexity (EMC), which is intended to measure the reusable quality of XML schema documents. A higher EMC value tends to more reusable quality, and as well, a higher EMC value implies that this schema document contains inheritance feature, elements and attributes. For empirical validation, the metric is applied on 70 WSDL schema files. A comparison with similar measures is also performed. The proposed EMC metric is also validated practically and theoretically. Empirical, theoretical and practical validation and a comparative study proves that the EMC metric is a valid metric and capable of measuring the reusable quality of XSD.", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Maintaining software through Bit-Parallelism and Hashing the Parameterized Q-Grams.\n", "abstract": " In the so\ufb01ware maintenance, it is often required to \ufb01nd duplicity present in the codes. Two code fragments are equivalent, if one can be transformed into the other via consistent renaming of identi\ufb01ers, literals and variables. This equivalency can be detected by parameterized string matching. In this matching, a given pattern P is said to match with a substring t of the text T, if there exists a one-to-one correspondence between symbols of P and symbols of t. In this paper, we propose an e\ufb01icient algorithm for this problem by using both the overlapping and non-overlapping q-gram. We show the e\ufb01 \u2018ect of running time of the algorithm on increasing the duplicity present in the code.", "num_citations": "2\n", "authors": ["1208"]}
{"title": "A Cognitive Evaluation for Meetings in Software Development Process\n", "abstract": " Software development includes number of different type of meetings in the whole development process. The cognitive activities also play an important role in decision making activities in these meetings since they are carried out by human being. In this paper, we evaluated the relevance of meetings in different phases of the software development process with reference to cognitive aspects.", "num_citations": "2\n", "authors": ["1208"]}
{"title": "A proposed additional property to the Weyuker's existing properties\n", "abstract": " The existing Weyuker's properties as they stand do not account for the programming language. So there is a need to add more properties to the list, which will address the language of a program. If we compute the same function in a different language, the complexity of the program should be the same, a concern which is not yet addressed by any of the existing Weyuker properties. For this purpose a new property to tackle this problem is proposed. This paper attempts to establish this property as useful in evaluating the complexity of a program.", "num_citations": "2\n", "authors": ["1208"]}
{"title": "Calibration of Empirical Models for Path Loss Prediction in Urban Environment\n", "abstract": " The reliability and accuracy of radio propagation models depends on the unique localized features in the area under study. In this paper, we calibrate empirical radio propagation models for 1800\u00a0MHz cellular network planning in Lagos Metropolis, Nigeria. Drive test are conducted to obtain measured data within suburban and dense urban propagation environment. Received Signal Strength (RSS) and path loss values of radio signals in 1800 MHz cellular networks are recorded for model calibration and evaluation. COST 231\u2013Hata model achieved the closest prediction results relative to the field measurement. Mean Error (ME), Standard Deviation (SD) and Root Mean Square (RMS) results are 11.004 dB, 12.194 dB and 16.43 dB respectively in dense suburban, while the corresponding results are 9.151 dB, 8.151 dB and 12.254 dB in dense urban. ME of all the calibrated propagation prediction models\u00a0\u2026", "num_citations": "1\n", "authors": ["1208"]}
{"title": "A Software Engineering Approach to Implementation of SDG 6 in Adum-Aiona Community of Nigeria\n", "abstract": " In this work, we adopt an engineering problem-solving approach to the open-air defecation health problem. We model social and behaviour change communication intervention among other components of a water-sanitation-hygiene (WASH) system in response to the menace of open defecation in rural and urban communities globally. We also used experimental outcomes to show empirically that patterns in data captured in the WASH process could be learnt for effective decision making using deep learning neural networks as an intelligent software engineering technique. Eradicating open defecation is one of the indicators used for measuring progress made towards the attainment of Sustainable Development Goal 6 (SDG 6). We use the Adum-Aiona community in Nigeria as case study in designing community-based total sanitation programs using software model-driven engineering approaches with\u00a0\u2026", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Empirical Framework for Tackling Recurring Project Management Challenges Using Knowledge Management Mechanisms\n", "abstract": " The construction industry is termed as a highly risky industry, considering the alarming rate of recurring challenges and its negative impact on the economy, man, and his environment. This study aimed to develop a framework using knowledge management in tackling recurring problems in the Nigerian construction industry. The data instrument was a well-designed questionnaire directed at construction professionals. Out of the 80 questionnaires distributed, the study used 78 (97.5%) questionnaires for analysis. The study identified corruption, inadequate planning measures, and reduced government policies as the main factors influencing recurring project management challenges in the Nigerian construction industry. The study revealed significant knowledge management strategies used by Nigerian construction professionals, which include the use of emails, face-to-face interactions, and brainstorming\u00a0\u2026", "num_citations": "1\n", "authors": ["1208"]}
{"title": "MAFODKM: mobile application framework for the management of Omics data and knowledge mining\n", "abstract": " There are many infectious diseases still plaguing different nations of the world. Some of these infectious diseases such as HIV, malaria, Ebola, and Lassa fever tend to affect less developed nations including those in Africa. In order to combat these diseases, there is need for ready access to omics data as the knowledge gained from this data can be used to combat infectious diseases globally. This study proposes a Mobile Application Framework for the management of Omics Data and Knowledge Mining (MAFODKM). The proposed framework was designed using a layered architecture. A prototype client application was implemented using JavaScript. In order to make it cross-platform, Apache Cordova framework was leveraged. The proposed framework will among other benefits provide an integrated platform for researchers to collaborate and conduct omics-related research to fight infectious diseases.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Modeling and Simulation of Impedance-Based Algorithm on Overhead Power Distribution Network Using MATLAB\n", "abstract": " Rapid location of faults in electrical distribution system is very critical for effective and efficient operation. The operation of the power system must be reliable and as economical as possible. The persistent lingering of fault conditions in the distribution networks is the lack of efficient technology to locate the faults in the distribution network and lack of proper maintenance of the equipment in the network. Most of the accidents caused to individuals (either the consumers or the workers) in this distribution networks are caused by some of these faults that not easily identified. This research proposes a model to locate faults in a distribution network using an enhanced impedance-based method for fault location. The model was simulated on the 2nd Avenue 11\u00a0kV feeder (Lagos) with the use of one-end impedance-based method. The results show a little marginal error when the location values obtained with the model are\u00a0\u2026", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Uses and impact of social media on work performance of low literate people\n", "abstract": " Social media is a famous method for communication and entertainment not only among the younger generation but also older ones. The social media applications such as Facebook, YouTube, Twitter, WhatsApp and much more are used by the users of all age groups. However, the excessive use of social media can affect the work performance of the people. This paper presents a survey, which was conducted on the low literate adults of Pakistan, in regard to social media usage and their work performance. This survey also explored which social media application is more frequently used and what factors affect their work performance other than social media usage (SMU). This survey conducted on 111 illiterate participants then descriptive statistics were used to examine the average number of hours that they spent on social media applications. Also, the effects of these applications on the work performance of\u00a0\u2026", "num_citations": "1\n", "authors": ["1208"]}
{"title": "The Role of ICTs in Sex Education: The Need for a SexEd App\n", "abstract": " Youths being in their formative years are extremely curious and adventurous and would attempt to get answers to their questions at any cost and from anywhere. This is also the case of sexually-related information. Studies have shown that deficient sex education has led to inappropriate practices/involvement among children and adolescents and subsequently, different social vices that are threatening to the society. However, with the advent and proliferation of smart phones, tablets and other gadgets, coupled with the internet technology, disseminating apt information or knowledge to youths and adolescents have been made much easier. Research has shown that these vices are reduced when children/adolescents are exposed to comprehensive formal/informal sex education. This research thus seeks to investigate the viability of applying ICT, specifically a mobile application to proliferate correct\u00a0\u2026", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Developing a Multi-modal Listing Service for Real Estate Agency Practice in Nigeria\n", "abstract": " Fraudsters posing as real estate agents threaten the reputation of real estate agencies in Nigeria. These fraudsters have continually defrauded unsuspecting members of the public. The major cause of this lapse is due largely to the fact that there is no known platform provided in the country that allows members of the public to verify a given real estate agent. This paper aims to provide support to real estate agency practice in Nigeria by developing a multi-modal listing service for verifying registered real estate agents and to also provide information on real estates available for sale, lease or rent. The requirements for the system were gathered through observation, literature survey and user survey. These requirements were then modelled using the Unified Modelling Language (UML). The system is developed both as a web and mobile application using an open source content management system (WordPress). This\u00a0\u2026", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Data Acquisition for Effective E-Governance: Nigeria, a Case Study\n", "abstract": " Implementation of e-government system as a means of administering government services promotes efficiency and effectiveness in governance. E-government provides a platform for adequate information exchange between the government, who deploys the system and its users which comprises of its citizens. Involving citizens in the decision making process highlights one of the qualities of good governance. Accurate data acquisition is required for developing a competent model for distribution of available resources. This paper examines different platforms that can be used for communication with the government in Nigeria and the awareness that these platforms exist by collating data gotten from 120 interviewees. A more efficient information exchange model is developed after analysis of the acquired data using a statistical software.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Development of Online Clearance System for an Educational Institution\n", "abstract": " It is mandatory for graduating students of an educational institution to exit the system in an orderly manner. The students usually do this through the mandatory clearance process. The manual process is time-consuming and stressful as the students have to move from place to place to get their clearance document endorsed. It has also been found to be vulnerable to fraud and other vices. The few automated ones also exhibit some limitations in their functionalities such as non-user-friendly interface, lack of adequate information to user, non-prioritization of processes and so on. This study therefore proposes a system that overcomes the issues with manual processing while improving on the identified automated ones. The study adopts a case study approach of a complete manual system for a leading institution of learning in Southwest Nigeria, with a view to evolving a working prototype. First a thorough\u00a0\u2026", "num_citations": "1\n", "authors": ["1208"]}
{"title": "A Complexity Metrics Suite for Cascading Style Sheets\n", "abstract": " We perform a theoretical and empirical analysis of a set of Cascading Style Sheets (CSS) document complexity metrics. The metrics are validated using a practical framework that demonstrates their viability. The theoretical analysis is performed using the Weyuker\u2019s properties\u2212 a widely adopted approach to conducting empirical validations of metrics proposals. The empirical analysis is conducted using visual and statistical analysis of distribution of metric values, Cliff\u2019s delta, Chi-square and Liliefors statistical normality tests, and correlation analysis on our own dataset of CSS documents. The results show that five out of the nine metrics (56%) satisfy Weyuker\u2019s properties except for the Number of Attributes Defined per Rule Block (NADRB) metric, which satisfies six out of nine (67%) properties. In addition, the results from the statistical analysis show good statistical distribution characteristics (only the Number of Extended Rule Blocks (NERB) metric exceeds the rule-of-thumb threshold value of the Cliff\u2019s delta). The correlation between the metric values and the size of the CSS documents is insignificant, suggesting that the presented metrics are indeed complexity rather than size metrics. The practical application of the presented CSS complexity metric suite is to assess the risk of CSS documents. The proposed CSS complexity metrics suite allows identification of CSS files that require immediate attention of software maintenance personnel. View Full-Text", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Reducing Efforts in Web Services Refactoring\n", "abstract": " In Service-Oriented Computing, systems provide a service interface described by a computer-readable language called Web Services Description Language (WSDL), but document descriptions often exhibit design problems as systems expand. Moreover, a major problem in this type of applications is its growth; as size and complexity of applications increase, the probability of duplicity of code also increases. This issue could have a negative impact on quality attributes, such as performance, maintainability and evolution, among others, providing developers with some clues to detect refactoring opportunities. Conducting a detection process of these opportunities could be a daunting task; however, this work proposes a methodology to conduct manual refactoring of service descriptions of legacy systems. The methodology allows software developers to collect metrics of time effort and space reduction. The\u00a0\u2026", "num_citations": "1\n", "authors": ["1208"]}
{"title": "A Survey on the Skills, Activities and Role of the Software Architect in Brazil\n", "abstract": " Although the skills and knowledge of software architects have already been the subject of some studies in recent years, researchers and practitioners still have not come to a clear consensus about the activities that a software architect is often responsible in practice in order to be considered successful. In recent years, due to occurrence of successive changes and evolution of new technologies, the roles of the architect and even practices related to software architecture have been continuously changed in the software development life cycle. The software architect is expected to possess a diversity of skills. In addition to technical knowledge, domain knowledge and communication skills must be considered. However, there are many job offerings for this position which have in their description skills and roles totally different from the ones already known and considered essential by academic and industry\u00a0\u2026", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Data Analytics: Global Contributions of World Continents to Computer Science Research\n", "abstract": " In this paper, we present and analyze comprehensive data about scholarly contributions that were indexed in Scopus database between 2012 and 2017. The datasets are categorized (based on the country where the research was carried out) into: Africa; Asia Pacific; Europe; Middle East; North America; and South America. Scholarly contributions of each region are measured based on fifteen Scival metrics namely: grant award volume (count); grant award volume (value); international collaboration; academic-corporate collaboration; scholarly output; citations; field-weighted citation impact; outputs in\u00a0top citation percentiles; publications in top journal percentiles; citations per publications; publication views; citing-patents count; patent-cited scholarly output; patent-citations count; and the number of authors. Frequency distributions and trends across the six-year study period are presented in graphs and plots\u00a0\u2026", "num_citations": "1\n", "authors": ["1208"]}
{"title": "An improved SMS based metering system\n", "abstract": " Electricity Metering has experienced significant changes through the years and the technology of e-metering continually advanced. This paper develops an improved SMS based metering system using GSM technology. An Arduino microcontroller is connected to a GSM-based wireless communication module. It monitors electrical pulses and the units consumed and the costs are calculated. This data is displayed on an LCD screen, and the data is also sent to the user via SMS. The user will be able to get SMS alerts of low and expired credit. The maximum and minimum units are set to 20 units and 0 units respectively. The alert on the LCD does not show until the units are getting close to the minimum. The experimental test was taken at different times at an interval of 5\u00a0min during the late hours of the day and the result shows that the proposed system is very effective.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "The implications of deploying MANETs routing protocols in WLANs setup\n", "abstract": " Wireless LANs are distinct networks type because; they requires a central system for controlling devices such base station, wireless access point, and wireless router. The basic operation of networks is to facilitate the tasks of conveyance and delivery of data packets among various participants or connected nodes. In the case of WLANs, this is achieved by means of a network base offering wireless medium. On the other hand, Mobile Ad-hoc Networks (MANETs) allow a one-to-one exchange of packet data between senders and receivers with a wireless baseless station. The Quality of Service offered by WLANs structures is limited due to the network congestions, cost of maintaining base station, large delays and small throughputs. This paper assesses the implications of using MANETs routing protocols in WLANs situations. The results are expected to further improve the QoS issues and other related challenges of WLANs.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "A Proposed Pragmatic Software Development Process Model\n", "abstract": " The rapid growth in technology and the dynamism in our society today poses a lot of problems for Software Engineering practitioners. The result is a series of software development process methods that can be used to combat or meet up with the problems. What we can do is evolve, grow, and adapt to the changes that come along with development. This is the dynamism inherent in man\u2014to adapt to change and improve ourselves and our existing systems\u2014since the world is a far cry from what it was a few decades ago. On this basis lay the need to develop the model proposed in this chapter to meet the variations that exist as a result of technological development.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Analysis of Existing Software Cognitive Complexity Measures\n", "abstract": " In order to maintain the quality of software, it is important to measure it complexity. This provides an insight into the degree of comprehensibility and maintainability of the software. Measurement can be carried out using cognitive measures which are based on cognitive informatics. A number of such measures have been proposed in literature. The goal of this article is to identify the features and advantages of the existing measures. In addition, a comparative analysis is done based on some selected criteria. The results show that there is a similar trend in the output obtained from the different measures when they are applied to different examples. This makes it easy for adopting organisations to readily choose from the options based on the availability of tool support.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "An exploratory study of techniques for monitoring oil pipeline vandalism\n", "abstract": " Wireless Sensor Networks are crucial substructure made up of microcontroller, sensing units and communication interfaces designed to enable the users possess the capability to measure, collect and responds to phenomenon within the surrounding been monitored. WSN are viewed as an edge between the physical and the virtual world. More so, the demand of fluid transportation from the production point to the region of end users has led to an increase in the number of pipelines that are fabricated globally. Pipeline infrastructure is generally regarded by many countries as a key element for national development, therefore shielding and observing the pipeline is essential for a successful economy. The current techniques in pipeline monitoring and surveillance include visual inspection, the use of Unmanned Aircraft, Ground Penetrating Radar, Fibre Cabling Technology, and Wireless Sensor Networks. This paper presents the various techniques, strengths and weaknesses when deployed for continuous monitoring of oil pipeline infrastructure.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Pouke za ICT studente iz intenzivnih obrazovnih iskustava u multinacionalnom okru\u017eenju\n", "abstract": " Stvarna internacionalizacija obrazovanja je trenutni izazov za studente, nastavnike i sveu\u010dili\u0161ta u Europi nakon provedbe EHEA (podru\u010dja Europskog visokog obrazovanja). Program Erasmus je odigrao klju\u010dnu ulogu u izlaganju zainteresiranih za europsku internacionalizaciju. Iako se \u010desto analiziraju velike globalne brojke programa, va\u017eno je prou\u010davati u\u010dinke sudjelovanja u programima razmjene na studente i nastavnike. Intenzivni programi Erasmusa omogu\u0107uju bolji uvid u svakodnevna iskustva u\u010denika. U ovom \u010dlanku analiziramo u\u010dinke intenzivnih me\u0111unarodnih programa na iskustva i stavove sudionika koji se odnose na me\u0111unarodna i multikulturalna okru\u017eenja. Podaci za analizu prikupljeni su od ICT studenata uklju\u010denih u intenzivne multinacionalne programe. Rezultati dobiveni od 125 studenata analizom upitnika provedenih prije i poslije sudjelovanja pokazuju zanimljive prednosti sudjelovanja u intenzivnim iskustvima prije zapo\u010dimanja du\u017eih i izazovnijih aktivnosti: osje\u0107aju se vi\u0161e motivirani da u inozemstvu ostanu na studiju ili na profesionalnom radu tijekom cijelog semestra, s manje brige o tome kako raditi u multikulturalnim okru\u017eenjima, s pove\u0107anim samopouzdanjem, itd.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "A software project management problem solved by firefly algorithm\n", "abstract": " In software project management there are several problems to deal, one of those is the Software Project Scheduling Problem (SPSP). This problem requires to assign a set of resources to tasks for a given project, trying to decrease the duration and cost of the whole project. The workers and their skills are the main resources in the project. In this paper we present the SPSP as a combinatorial optimization problem and a novel approach to solve SPSP by a Firefly algorithm. Firefly algorithm is a new metaheuristic based on the behaviour of the firefly. We present the design of the resolution model to solve the SPSP using an algorithm of fireflies and we illustrate some experimental results in order to demonstrate the viability and soundness of our approach.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Set Covering Problem Resolution by Biogeography-Based Optimization Algorithm\n", "abstract": " The research on Artificial Intelligence and Operational Research has provided models and techniques to solve many industrial problems. For instance, many real life problems can be formulated as a Set Covering Problem (SCP). The SCP is a classic NP-hard combinatorial problem consisting in find a set of solutions that cover a range of needs at the lowest possible cost following certain constraints. In this work, we use a recent metaheuristic called Biogeography-Based Optimization Algorithm (BBOA) inspired by biogeography, which mimics the migration behavior of animals in nature to solve optimization and engineering problems. In this paper, BBOA for the SCP is proposed. In addition, to improve performance we provide a new feature for the BBOA, which improve stagnation in local optimum. Finally, the experiment results show that BBOA is a excellent method for solving such problems.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Policy framework for adoption of bring your own device (BYOD) by institutions in Nigeria\n", "abstract": " Mobile computing makes access to data and services available anytime and anywhere. The recent increase in the number of mobile devices like smartphones and tablets has given rise to a phenomenon known as \u201cIT Consumerization\u201d that focuses on satisfying the needs of the consumers to improve their productivity for the benefit of their organization. Recent report from mobile trends indicates that in 2014 alone, manufacturers will ship more than a billion Android devices. It is estimated that seven out of every ten employees (7/10) will use their mobile devices for work in corporate environments. Mobile devices according to studies are known to be more vulnerable compared to laptops and PCs due to their small size, mobility and general lack of protection against viruses and malware. The use of these devices therefore can impact negatively on corporate networks unless properly and effectively managed. Organizations are now adopting a program known as \u201ebring your own device\u201f (BYOD) that will enable them capture, register, and manage the mobile devices that connect and use their corporate infrastructure to guarantee the security of the infrastructure and data of the organization. They achieve this by putting in place strategies and policies that involves all stakeholders. This paper surveys literature to extract useful information that serve to enlighten the community of workers and IT leaders on the current and rapid growing phenomenon of BYOD, including the strategies for deployment, BYOD models, benefits, security threats on corporate and user data and infrastructure. The study presents guidelines and a framework for adoption of BYOD\u00a0\u2026", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Analysis of fuzzy and neural networks expert systems in forecasting stock prices\n", "abstract": " In 2010, Hadavandi, Shavandi & Ghanbari noted that fuzzy inference systemused for forecasting stock price requires an effective Rule Base and Knowledge Base to be built in its Expert System. Similarly, neural networks rely on expert systems in predicting quantities such as stock price. However, forecasts of stock price movements are non-linear and linear at the same time, which make the traditional time series and regression analysis less significant in delivering accurate outcomes especially when multiple factors (such as opening price, highest price and closing) are considered. This paper analyzed the forecasting capabilities of two widely deployed expert systems, fuzzyand neural networks. Also, the MSE, RMSE, MAPE and RAE served as performance measuring parameters.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Design and Implementation of an Online Examination System for Grading Objective and Essay-type Questions\n", "abstract": " Online examination systems are replacing traditional methods of writing examinations. A lot of progress has been made in administering objective examinations online with a high rate of success. However, research is on-going as to the administration and grading of essay-type (subjective) examination. This is because computers do not have the ability to reason like humans in grading essay-type examinations with instant feedback. In most essay-type examination systems, the answers from the students need to be submitted to the examiners for grading which often takes time. In this study, we apply a keyword match approach using SQL MATCH AGAINST syntax to grade essaytype examination questions. The system also handles the grading of objective examinations. The proposed system offers many advantages over the traditional method of writing and grading exams including fast grading and instant result feedback to candidates.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Efficient utilization of various network coding techniques in different wireless scenarios\n", "abstract": " The nodes of a communication network use network coding technique for generating packets for output links by systematically processing the packets received on its input links such that the original packets should be recovered by the destination nodes. Under low traffic conditions higher bandwidth efficiency and power efficiency can be achieved using network coding but the performance degrades as the traffic in the network increases. Overall performance of the network can be improved if the node is able to take a decision about whether to use or not to use network coding under the current condition of the network. This work presents a scheme for finding out a threshold value below which network coding should be used and above the threshold normal forwarding operation should be adopted by the nodes. The performance of the proposed algorithm on Cross topology under different network coding\u00a0\u2026", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Global Software Development: Challen ges and Opportunities in Nigeria\n", "abstract": " To God be all the glory. I am grateful to our Chancellor, Dr. David Oyedepo and the Management Team of this University led by our amiable VC, Professor C. K. Ayo for allowing me to deliver this public lecture today. Today\u2018s lecture investigates the possibilities of sub-Saharan Africa as a sourcing destination in the software field. To find out the reasons why sub-Saharan African countries in general and Nigeria in particular are not considered a destination for global software development projects. In the study that led to this lecture, a set of professionals from Europe and Africa were interviewed. Results indicate that there are many disadvantages and difficulties impeding Nigeria from becoming a preferred sourcing destination. The main ones are the absence of a strong software industry and the concerns about legislative, fiscal and commercial premises. On the other hand, it is observed that there are also relevant added values and competitive advantages in Nigeria (English-speaking country, same time zone and cost) and, therefore, it can become a potential target for software development outsourcing in the medium and long term.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "A low-cost solar cell charger prototype for smartphone's battery charging\n", "abstract": " In this paper, the design and development of a low-cost solar cell charger prototype for smartphones is presented. The prototype is the result from a scientific science fair in Mexico. The main idea behind this project is to contribute to the reduction of the global climate change by means of decreasing the consumption of energy derived from the growing use of smart phones. In addition, a basic control circuit is presented as well as the final prototype as a proof of concept.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Solving sudokus via metaheuristics and AC3\n", "abstract": " The Sudoku puzzle consists in filling a square matrix with 9 rows and 9 columns, divided into 9 3\u00d73 regions, so that each column, row, and region contains different digits from 1 to 9. Such a puzzle belongs to the NP-complete class of problems, existing different exact and approximate methods able to solve it. This paper reports recent results for solving Sudokus achieved by combining metaheuristics and a filtering technique coming from the constraint programming domain named AC3.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Enhancing Security in the Software Development Lifecycle (SDLC)\n", "abstract": " The Software Development Life Cycle (SDLC) cares for all steps to have a sound implementation of projects. So many projects are tested to be delivering but with the test of time, security challenges arise. In cases where projects have executed required tasks for decades, software evolution expands the scope and security requirements increase beyond what the developer initially cared for.   This work explores the critical security incorporations that ensure a better security of software so that at any level of evolution, security challenges do not arise. There is always focus on security of design but this work is on information security in the software development life cycle to avoid tampering, endeavour integrity and authentication of information.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Knowledge management and creativity in software engineering the foundations of agility\n", "abstract": " Software development is a knowledge intensive activity and its success depends on knowledge and creativity of the developers. In the last years the traditional perspective on software development is changing and agile methods have received considerable attention. Among other attributes, the agilists claim that fostering knowledge sharing and creativity is one of the keys to response to common problems and challenges of software development today. The development of new software products requires the generation of novel and useful ideas. The purpose of this paper is to provide an understanding of knowledge management and creativity in relation with new software engineering trends. The implications of these findings are considered, and some possible directions for future research are suggested.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Effect of network hierarchy in a typical campus area network (CAN) of a university\n", "abstract": " This paper presents the results of a practical implementation of the hierarchical network design. The aim of this paper is to briefly show the effect of hierarchy in a campus network by taking the case study of a University network that has no hierarchy implemented. We simulated the original network and subjected the network to run for a period of 30 min with all the deployed services fully running to obtain the values of our determining metric (HTTP page response time). We then implemented the hierarchy into the network and carried out the same test to get new values which were finally compared and we recorded a reduction in the HTTP page response time. We were able to show how the network hierarchy affects the download time and a simple way of integrating hierarchy into an already existing network.       Key words: Networking, local area network, campus area network, small campus design.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Forecasting Nigeria Foreign Exchange Rates Using Artificial Neural Network\n", "abstract": " Artificial neural networks (ANNs) are computing models for information processing and pattern identification. They grow out of research interest in modeling biological neural systems, especially human brains. An ANN is a network of many simp le computing units called neurons or cells, which are highly interconnected and organized in layers. Each neuron performs the simple task of information processing by converting received inputs into processed outputs. In past two decades, ANN has been appl ied in Economics, Finance and other sectors. The foreign exchange market assists international trade and investment by enabling currency conversion. In this study we applied a time delayed neural network model for foreca s ting dail y foreign exchange rate of a US Dollar to Naira for Nigeria by using Artificial Neural Network (ANN) methodology on the basis of daily data for September 2011 t o February 2012. We compared ANN with Single Exponential Smoothening (SES) and Autoregressive - Integrated - Moving - Average (A RIMA) models, the ANN forecasting tool proved to be more accurate than the SES and ARIMA as it had a smaller root mean squared error of 0.6995 as compared to the root mean squared error of the SES which was 0.9890 and ARIMA which was 0.7880. More research work can be carried out by comparing ANN with other available forecasting tools. Key words: Artificial Neural Networks, Forecasting, Foreign Exchange Rate, Single Exponential Smoothening", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Computational Science and Its Applications-ICCSA 2011: International Conference, Santander, Spain, June 20-23, 2011. Proceedings, Part III\n", "abstract": " The five-volume set LNCS 6782-6786 constitutes the refereed proceedings of the International Conference on Computational Science and Its Applications, ICCSA 2011, held in Santander, Spain, in June 2011. The five volumes contain papers presenting a wealth of original research results in the field of computational science, from foundational issues in computer science and mathematics to advanced applications in virtually all sciences making use of computational techniques. The topics of the fully refereed papers are structured according to the five major conference themes: geographical analysis, urban modeling, spatial statistics; cities, technologies and planning; computational geometry and applications; computer aided modeling, simulation, and analysis; and mobile communications.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "A software metric for python language\n", "abstract": " There are many metrics for evaluating the quality of codes written in different programming languages. However, no efforts have been done to propose metrics for Python, which is an important and useful language especially for the software development for the embedded systems. In this present work, we are trying to investigate all the factors, which are responsible for increasing the complexity of code written in Python language. Accordingly, we have proposed a unified metric for this language. Practical applicability of the metric is demonstrated on a case study.", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Measurement of Cognitive Functional Sizes of Software\n", "abstract": " One of the major issues in software engineering is the measurement. Since traditional measurement theory has problem in defining empirical observations on software entities in terms of their measured quantities, Morasca tried to solve this problem by proposing Weak Measurement theory. Further, in calculating complexity of software, the emphasis is mostly given to the computational complexity, algorithm complexity, functional complexity, which basically estimates the time, efforts, computability and efficiency. On the other hand, understandability and compressibility of the software which involves the human interaction are neglected in existing complexity measures. Recently, cognitive complexity (CC) to calculate the architectural and operational complexity of software was proposed to fill this gap. In this paper, we evaluated CC against the principle of weak measurement theory. We find that, the approach for\u00a0\u2026", "num_citations": "1\n", "authors": ["1208"]}
{"title": "Application of ICT By Small And Medium Enterprises In Ogun State Nigeria\n", "abstract": " Small and medium enterprises (SMEs) have emerged as promising opportunities to eliminate and reduce unemployment globally. Increasing levels of technological advancement has revolutionized the dynamics of the business terrain. However, SMEs in developing countries are yet to fully explore the benefits of Information and Communications Technology (ICT). Survey data was collected from 75 SME ICT users in Abeokuta and Otta through a structured questionnaire using stratified random sampling technique. Results of regression analysis revealed that demographic variable (Staff Strength) significantly influences ICT application among SMEs while SME service delivery had no influence. Also, analysis of variance on the categories of SMEs was not a determinant factor on the use of ICT. The outcome of this study has implications for owners of SMEs, stakeholders, government and academic researchers in developing countries as it can provide patterns to help bridge the existing digital divide especially among Nigerian SMEs.", "num_citations": "1\n", "authors": ["1208"]}