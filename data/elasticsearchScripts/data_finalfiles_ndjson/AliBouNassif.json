{"title": "Towards an Early Software Estimation Using Log-Linear Regression and a Multilayer Perceptron Model\n", "abstract": " Software estimation is a tedious and daunting task in project management and software development. Software estimators are notorious in predicting software effort and they have been struggling in the past decades to provide new models to enhance software estimation. The most critical and crucial part of software estimation is when estimation is required in the early stages of the software life cycle where the problem to be solved has not yet been completely revealed. This paper presents a novel log-linear regression model based on the use case point model (UCP) to calculate the software effort based on use case diagrams. A fuzzy logic approach is used to calibrate the productivity factor in the regression model. Moreover, a multilayer perceptron (MLP) neural network model was developed to predict software effort based on the software size and team productivity. Experiments show that the proposed approach\u00a0\u2026", "num_citations": "185\n", "authors": ["415"]}
{"title": "Performance analysis of hyperledger fabric platforms\n", "abstract": " Blockchain is a key technology that has the potential to decentralize the way we store, share, and manage information and data. One of the more recent blockchain platforms that has emerged is Hyperledger Fabric, an open source, permissioned blockchain that was introduced by IBM, first as Hyperledger Fabric v0.6, and then more recently, in 2017, IBM released Hyperledger Fabric v1.0. Although there are many blockchain platforms, there is no clear methodology for evaluating and assessing the different blockchain platforms in terms of their various aspects, such as performance, security, and scalability. In addition, the new version of Hyperledger Fabric was never evaluated against any other blockchain platform. In this paper, we will first conduct a performance analysis of the two versions of Hyperledger Fabric, v0.6 and v1.0. The performance evaluation of the two platforms will be assessed in terms of execution time, latency, and throughput, by varying the workload in each platform up to 10,000 transactions. Second, we will analyze the scalability of the two platforms by varying the number of nodes up to 20 nodes in each platform. Overall, the performance analysis results across all evaluation metrics, scalability, throughput, execution time, and latency, demonstrate that Hyperledger Fabric v1.0 consistently outperforms Hyperledger Fabric v0.6. However, Hyperledger Fabric v1.0 platform performance did not reach the performance level in current traditional database systems under high workload scenarios.", "num_citations": "172\n", "authors": ["415"]}
{"title": "Data mining techniques in social media: A survey\n", "abstract": " Today, the use of social networks is growing ceaselessly and rapidly. More alarming is the fact that these networks have become a substantial pool for unstructured data that belong to a host of domains, including business, governments and health. The increasing reliance on social networks calls for data mining techniques that is likely to facilitate reforming the unstructured data and place them within a systematic pattern. The goal of the present survey is to analyze the data mining techniques that were utilized by social media networks between 2003 and 2015. Espousing criterion-based research strategies, 66 articles were identified to constitute the source of the present paper. After a careful review of these articles, we found that 19 data mining techniques have been used with social media data to address 9 different research objectives in 6 different industrial and services domains. However, the data mining\u00a0\u2026", "num_citations": "142\n", "authors": ["415"]}
{"title": "Dimensionality Reduction with IG-PCA and Ensemble Classifier for Network Intrusion Detection\n", "abstract": " Handling redundant and irrelevant features in high-dimension datasets has caused a long-term challenge for network anomaly detection. Eliminating such features with spectral information not only speeds up the classification process but also helps classifiers make accurate decisions during attack recognition time, especially when coping with large-scale and heterogeneous data. A novel hybrid dimensionality reduction technique is proposed for intrusion detection combining the approaches of information gain (IG) and principal component analysis (PCA) with an ensemble classifier based on support vector machine (SVM), Instance-based learning algorithms (IBK), and multilayer perceptron (MLP). The performance of this IG-PCA-Ensemble method was evaluated based on three well-known datasets, namely ISCX 2012, NSL-KDD, and Kyoto 2006+. Experimental results show that the proposed hybrid\u00a0\u2026", "num_citations": "129\n", "authors": ["415"]}
{"title": "Estimating software effort based on use case point model using sugeno fuzzy inference system\n", "abstract": " Software effort estimation is one of the most important tasks in software engineering. Software developers conduct software estimation in the early stages of the software life cycle to derive the required cost and schedule for a project. In the requirements stage, where most software estimation is conducted, the available information is usually imprecise or incomplete. In this paper, a new regression model is created for software effort estimation based on use case point model. Furthermore, a Sugeno Fuzzy Inference System (FIS) approach is applied on this model to improve the estimation. Results show that an improvement of 11% can be achieved in MMRE after applying the Sugeno fuzzy logic approach.", "num_citations": "77\n", "authors": ["415"]}
{"title": "Software effort estimation in the early stages of the software life cycle using a cascade correlation neural network model\n", "abstract": " Software cost estimation is a crucial element in project management. Failing to use a proper cost estimation method might lead to project failures. According to the Standish Chaos Report, 65% of software projects are delivered over budget or after the delivery deadline. Conducting software cost estimation in the early stages of the software life cycle is important and this would be helpful to project managers to bid on projects. In this paper, we propose a novel model to predict software effort from use case diagrams using a cascade correlation neural network approach. The proposed model was evaluated based on the MMER and PRED criteria using 214 industrial and 26 educational projects against a multiple linear regression model and the Use Case Point model. The results show that the proposed cascade correlation neural network can be used with promising results as an alternative approach to predict software\u00a0\u2026", "num_citations": "66\n", "authors": ["415"]}
{"title": "E-learning: Challenges and research opportunities using machine learning & data analytics\n", "abstract": " With the proliferation of technology, the field of e-learning has garnered significant attention in recent times. This is because it has allowed users from around the world to learn and access new information. This has added to the growing amount of collected data that is already being generated through different devices and sensors employed around the world. This has led to the need to analyze collected data and extract useful information from it. Machine learning (ML) and data analytics (DA) are proposed techniques that can help extract information and find valuable patterns within the collected data. In this paper, the field of e-learning is investigated in terms of definitions and characteristics. Moreover, the various challenges facing the different participants within this process are discussed. In addition, some of the works proposed in the literature to tackle these challenges are presented. Then, a brief survey about\u00a0\u2026", "num_citations": "65\n", "authors": ["415"]}
{"title": "Estimating Software Effort Using an ANN Model Based on Use Case Points\n", "abstract": " In this paper, we propose a novel Artificial Neural Network (ANN) to predict software effort from use case diagrams based on the Use Case Point (UCP) model. The inputs of this model are software size, productivity and complexity, while the output is the predicted software effort. A multiple linear regression model with three independent variables (same inputs of the ANN) and one dependent variable (effort) is also introduced. Our data repository contains 240 data points in which, 214 are industrial and 26 are educational projects. Both the regression and ANN models were trained using 168 data points and tested using 72 data points. The ANN model was evaluated using the MMER and PRED criteria against the regression model, as well as the UCP model that estimates effort from use cases. Results show that the ANN model is a competitive model with respect to other regression models and can be used as an\u00a0\u2026", "num_citations": "56\n", "authors": ["415"]}
{"title": "Emotion Recognition using Hybrid Gaussian Mixture Model and Deep Neural Network\n", "abstract": " This paper aims at recognizing emotions for a text-independent and speaker-independent emotion recognition system based on a novel classifier, which is a hybrid of a cascaded Gaussian mixture model and deep neural network (GMM-DNN). This hybrid classifier has been assessed for emotion recognition on \u201cEmirati speech database (Arabic United Arab Emirates Database)\u201d with six different emotions. The sequential GMM-DNN classifier has been contrasted with support vector machines (SVMs) and multilayer perceptron (MLP) classifiers, and its performance accuracy is indexed at 83.97%, while the other two perform at 80.33% and 69.78% using SVMs and MLP, respectively. These results demonstrate that the hybrid classifier significantly gives higher emotion recognition accuracy than SVMs and MLP classifiers. Our GMM-DNN model yields the results similar to those obtained by human judges in a subjective\u00a0\u2026", "num_citations": "52\n", "authors": ["415"]}
{"title": "Data mining techniques in intrusion detection systems: A systematic literature review\n", "abstract": " The continued ability to detect malicious network intrusions has become an exercise in scalability, in which data mining techniques are playing an increasingly important role. We survey and categorize the fields of data mining and intrusion detection systems, providing a systematic treatment of methodologies and techniques. We apply a criterion-based approach to select 95 relevant articles from 2007 to 2017. We identified 19 separate data mining techniques used for intrusion detection, and our analysis encompasses rich information for future research based on the strengths and weaknesses of these techniques. Furthermore, we observed a research gap in establishing the effectiveness of classifiers to identify intrusions in modern network traffic when trained with aging data sets. Our review points to the need for more empirical experiments addressing real-time solutions for big data against contemporary attacks.", "num_citations": "52\n", "authors": ["415"]}
{"title": "Regression model for software effort estimation based on the use case point method\n", "abstract": " It is very important to conduct software estimation in the early stages of the software life cycle, because it helps managers bid on projects and allocate resources efficiently. This paper presents a novel regression model to estimate the software effort based on the use case point size metric. The use case point model takes use case diagrams as input and gives the software size in use case points as output. The proposed effort equation takes into consideration the non-linear relationship between software size and software effort, as well as the influences of project complexity and productivity. Results show that the software effort estimation accuracy can be improved by 16.5% using PRED (25) and 25% using PRED (35).", "num_citations": "46\n", "authors": ["415"]}
{"title": "Bayesian Optimization with Machine Learning Algorithms Towards Anomaly Detection\n", "abstract": " Network attacks have been very prevalent as their rate is growing tremendously. Both organization and individuals are now concerned about their confidentiality, integrity and availability of their critical information which are often impacted by network attacks. To that end, several previous machine learning-based intrusion detection methods have been developed to secure network infrastructure from such attacks. In this paper, an effective anomaly detection framework is proposed utilizing Bayesian Optimization technique to tune the parameters of Support Vector Machine with Gaussian Kernel (SVM-RBF), Random Forest (RF), and k-Nearest Neighbor (k-NN) algorithms. The performance of the considered algorithms is evaluated using the ISCX 2012 dataset. Experimental results show the effectiveness of the proposed framework in term of accuracy rate, precision, low-false alarm rate, and recall.", "num_citations": "41\n", "authors": ["415"]}
{"title": "A comparison between decision trees and decision tree forest models for software development effort estimation\n", "abstract": " Accurate software effort estimation has been a challenge for many software practitioners and project managers. Underestimation leads to disruption in the project's estimated cost and delivery. On the other hand, overestimation causes outbidding and financial losses in business. Many software estimation models exist; however, none have been proven to be the best in all situations. In this paper, a decision tree forest (DTF) model is compared to a traditional decision tree (DT) model, as well as a multiple linear regression model (MLR). The evaluation was conducted using ISBSG and Desharnais industrial datasets. Results show that the DTF model is competitive and can be used as an alternative in software effort prediction.", "num_citations": "36\n", "authors": ["415"]}
{"title": "Systematic ensemble model selection approach for educational data mining\n", "abstract": " A plethora of research has been done in the past focusing on predicting student\u2019s performance in order to support their development. Many institutions are focused on improving the performance and the education quality; and this can be achieved by utilizing data mining techniques to analyze and predict students\u2019 performance and to determine possible factors that may affect their final marks. To address this issue, this work starts by thoroughly exploring and analyzing two different datasets at two separate stages of course delivery (20% and 50% respectively) using multiple graphical, statistical, and quantitative techniques. The feature analysis provides insights into the nature of the different features considered and helps in the choice of the machine learning algorithms and their parameters. Furthermore, this work proposes a systematic approach based on Gini index and p-value to select a suitable ensemble\u00a0\u2026", "num_citations": "35\n", "authors": ["415"]}
{"title": "Software Estimation in the Early Stages of the Software Life Cycle\n", "abstract": " Software estimation is imperative in software engineering. Many projects fail because of inaccurate size or effort estimation. The most critical and crucial part of software estimation is when estimation is required in the early stages of the software life cycle where the problem to be solved has not yet been completely revealed. Early software size estimation helps projects to be managed efficiently and helps managers estimate the effort, schedule and cost of the project. This in turn, allows the managers to bid effectively on software projects. This paper demonstrates the function points model and presents some methods used to measure the size of software in the early stages. A comparison between these methods highlights the strengths and weaknesses of each method. After displaying software size estimation methods, some methods will be presented to demonstrate how the effort of software can be estimated. Some techniques based on Artificial Intelligence are presented to illustrate how the accuracy of estimation can be improved.", "num_citations": "33\n", "authors": ["415"]}
{"title": "Software Size and Effort Estimation from Use Case Diagrams Using Regression and Soft Computing Models\n", "abstract": " In this research, we propose a novel model to predict software size and effort from use case diagrams. The main advantage of our model is that it can be used in the early stages of the software life cycle, and that can help project managers efficiently conduct cost estimation early, thus avoiding project overestimation and late delivery among other benefits. Software size, productivity, complexity and requirements stability are the inputs of the model. The model is composed of six independent sub-models which include non-linear regression, linear regression with a logarithmic transformation, Radial Basis Function Neural Network (RBFNN), Multilayer Perceptron Neural Network (MLP), General Regression Neural Network (GRNN) and a Treeboost model. Several experiments were conducted to train and test the model based on the size of the training and testing data points. The neural network models were evaluated against regression models as well as two other models that conduct software estimation from use case diagrams. Results show that our model outperforms other relevant models based on five evaluation criteria. While the performance of each of the six sub-models varies based on the size of the project dataset used for evaluation, it was concluded that the non-linear regression model outperforms the linear regression model. As well, the GRNN model exceeds other neural network models. Furthermore, experiments demonstrated that the Treeboost model can be efficiently used to predict software effort.", "num_citations": "31\n", "authors": ["415"]}
{"title": "Multi-Stage Optimized Machine Learning Framework for Network Intrusion Detection\n", "abstract": " Cyber-security garnered significant attention due to the increased dependency of individuals and organizations on the Internet and their concern about the security and privacy of their online activities. Several previous machine learning (ML)-based network intrusion detection systems (NIDSs) have been developed to protect against malicious online behavior. This paper proposes a novel multi-stage optimized ML-based NIDS framework that reduces computational complexity while maintaining its detection performance. This work studies the impact of oversampling techniques on the models\u2019 training sample size and determines the minimal suitable training sample size. Furthermore, it compares between two feature selection techniques, information gain and correlation-based, and explores their effect on detection performance and time complexity. Moreover, different ML hyper-parameter optimization techniques\u00a0\u2026", "num_citations": "29\n", "authors": ["415"]}
{"title": "Business intelligence solutions in healthcare a case study: Transforming OLTP system to BI solution\n", "abstract": " Healthcare environment is growing to include not only the traditional information systems, but also a business intelligence platform. For executive leaders, consultants, and analysts, there is no longer a need to spend hours in design and develop of typical reports or charts, the entire solution can be completed through using Business Intelligence \u201cBI\u201d software. This paper discusses current state-of-the-art B.I components (tools) and outlines hospitals advances in their businesses by using B.I solutions through focusing on inter-relationship of business needs and the IT technologies. We also present a case study that illustrates of transforming a traditional online transactional processing (OLTP) system towards building an online analytical processing (OLAP) solution.", "num_citations": "26\n", "authors": ["415"]}
{"title": "Novel cascaded Gaussian mixture model-deep neural network classifier for speaker identification in emotional talking environments\n", "abstract": " This research is an effort to present an effective approach to enhance text-independent speaker identification performance in emotional talking environments based on novel classifier called cascaded Gaussian Mixture Model-Deep Neural Network (GMM-DNN). Our current work focuses on proposing, implementing and evaluating a new approach for speaker identification in emotional talking environments based on cascaded Gaussian mixture model-deep neural network as a classifier. The results point out that the cascaded GMM-DNN classifier improves speaker identification performance at various emotions using two distinct speech databases: Emirati speech database (Arabic United Arab Emirates dataset) and \u201cspeech under simulated and actual stress\u201d English dataset. The proposed classifier outperforms classical classifiers such as multilayer perceptron and support vector machine in each dataset\u00a0\u2026", "num_citations": "25\n", "authors": ["415"]}
{"title": "Fuzzy-ExCOM Software Project Risk Assessment\n", "abstract": " A software development project is considered to be risky due to the uncertainty of the information (customer requirements), the complexity of the process, and the intangible nature of the product. Under these conditions, risk management in software development projects is mandatory, but often it is difficult and expensive to implement. Expert COCOMO is an efficient approach to software project risk management, which leverages existing knowledge and expertise from previous effort estimation activities to assess the risks in new software projects. However, the original method has limitation because it cannot effectively deal with imprecise and uncertain inputs in the form of linguistic terms such as: Very Low (VL), Low (L), Nominal (N), High (H), Very High (VH) and Extra High (XH). This paper introduces the fuzzy-ExCOM methodology that combines the advantages of a fuzzy technique with Expert COCOMO\u00a0\u2026", "num_citations": "24\n", "authors": ["415"]}
{"title": "Calibrating use case points\n", "abstract": " An approach to calibrate the complexity weights of the use cases in the Use Case Points (UCP) model is put forward. The size metric used is the Use Case Points (UCP) which can be calculated from the use case diagram along with its use case scenario as described in the UCP model. The approach uses a neural network with fuzzy logic to tune the complexity weights.", "num_citations": "23\n", "authors": ["415"]}
{"title": "A Regression Model with Mamdani Fuzzy Inference System for Early Software Effort Estimation Based on Use Case Diagrams\n", "abstract": " Effective software effort estimation is one of the biggest challenges in software engineering. One of these challenges occurs when it is required to estimate software effort in the early stages of the software life cycle, as software requirements in this stage are usually incomplete. As Unified Modeling Language (UML) model became more prominent in software requirements and design processes, software estimators became more interested to use UML model and especially the use case diagrams to estimate software. In this paper, a novel regression model based on the use case point method is created for software effort estimation. Moreover, a Mamdani Fuzzy Inference System (FIS) approach is applied on this model to enhance the accuracy of estimation. Results show that an overall improvement of 10% can be achieved after applying the proposed approach.", "num_citations": "23\n", "authors": ["415"]}
{"title": "Reliability models applied to mobile applications\n", "abstract": " Smart phones have become the most used electronic devices. They carried out most of the functionalities of desktops, allowing various useful applications that suit the users' needs. Therefore, instead of the operator, the user has become the number one controller of the device and its applications and thus its reliability becomes an emergent need. We aim to investigate and evaluate the efficacy of Software Reliability Growth Models (SRGMs) when applied to Smart phone application failure data and check whether they achieve the same success as in the desktop/laptop area. We selected three of the most used SRGMs and applied them to three different Smart phone applications. None of the selected models were able to account for the data satisfactorily. Their failure is traced back to the specific features of mobile applications compared to desktop applications. Thus, a suitable model for Smart phone applications is\u00a0\u2026", "num_citations": "22\n", "authors": ["415"]}
{"title": "Multi-split Optimized Bagging Ensemble Model Selection for Multi-class Educational Data Mining\n", "abstract": " Predicting students\u2019 academic performance has been a research area of interest in recent years, with many institutions focusing on improving the students\u2019 performance and the education quality. The analysis and prediction of students\u2019 performance can be achieved using various data mining techniques. Moreover, such techniques allow instructors to determine possible factors that may affect the students\u2019 final marks. To that end, this work analyzes two different undergraduate datasets at two different universities. Furthermore, this work aims to predict the students\u2019 performance at two stages of course delivery (20% and 50% respectively). This analysis allows for properly choosing the appropriate machine learning algorithms to use as well as optimize the algorithms\u2019 parameters. Furthermore, this work adopts a systematic multi-split approach based on Gini index and p-value. This is done by optimizing a\u00a0\u2026", "num_citations": "19\n", "authors": ["415"]}
{"title": "A Hybrid Intelligent Model for Software Cost Estimation\n", "abstract": " Accurate software development effort estimation is critical to the success of software projects. Although many techniques and algorithmic models have been developed and implemented by practitioners, accurate software development effort prediction is still a challenging endeavor in the field of software engineering, especially in handling uncertain and imprecise inputs and collinear characteristics. In this paper, a hybrid in-telligent model combining a neural network model integrated with fuzzy model (neuro-fuzzy model) has been used to improve the accuracy of estimating software cost. The performance of the proposed model is assessed by designing and conducting evaluation with published project and industrial data. Results have shown that the proposed model demonstrates the ability of improving the estimation accuracy by 18% based on the Mean Magnitude of Relative Error (MMRE) criterion.", "num_citations": "18\n", "authors": ["415"]}
{"title": "Clustering enabled classification using ensemble feature selection for intrusion detection\n", "abstract": " Machine learning has been leveraged to increase the effectiveness of intrusion detection systems (IDSs). The focus of this approach, however, has largely be on detecting known attack patterns based on outdated datasets. In this paper, we propose an ensemble feature selection method along with an anomaly detection method that combines unsupervised and supervised machine learning techniques to classify network traffic to identify previously unseen attack patterns. To that end, three different feature selection techniques are used as part of an ensemble model that selects 8 common features. Moreover, k-Means clustering is used to first partition the training instances into k clusters using the Manhattan distance. A classification model is then built based on the resulting clusters, which represent a density region of normal or anomaly instances. This in turn helps determine the effectiveness of the clustering in\u00a0\u2026", "num_citations": "16\n", "authors": ["415"]}
{"title": "Emirati-accented speaker identification in each of neutral and shouted talking environments\n", "abstract": " This work is devoted to capturing Emirati-accented speech database (Arabic United Arab Emirates database) in each of neutral and shouted talking environments in order to study and enhance text-independent Emirati-accented \u201cspeaker identification performance in shouted environment\u201d based on each of \u201cfirst-order circular suprasegmental hidden Markov models (CSPHMM1s), second-order circular suprasegmental hidden Markov models (CSPHMM2s), and third-order circular suprasegmental hidden Markov models (CSPHMM3s)\u201d as classifiers. In this research, our database was collected from 50 Emirati native speakers (25 per gender) uttering eight common Emirati sentences in each of neutral and shouted talking environments. The extracted features of our collected database are called \u201cMel-Frequency Cepstral Coefficients (MFCCs)\u201d. Our results show that average Emirati-accented speaker\u00a0\u2026", "num_citations": "15\n", "authors": ["415"]}
{"title": "Machine learning towards intelligent systems: applications, challenges, and opportunities\n", "abstract": " The emergence and continued reliance on the Internet and related technologies has resulted in the generation of large amounts of data that can be made available for analyses. However, humans do not possess the cognitive capabilities to understand such large amounts of data. Machine learning (ML) provides a mechanism for humans to process large amounts of data, gain insights about the behavior of the data, and make more informed decision based on the resulting analysis. ML has applications in various fields. This review focuses on some of the fields and applications such as education, healthcare, network security, banking and finance, and social media. Within these fields, there are multiple unique challenges that exist. However, ML can provide solutions to these challenges, as well as create further research opportunities. Accordingly, this work surveys some of the challenges facing the aforementioned\u00a0\u2026", "num_citations": "13\n", "authors": ["415"]}
{"title": "Deep learning for Arabic subjective sentiment analysis: Challenges and research opportunities\n", "abstract": " The fields of machine learning and Web\u00a0technologies have witnessed significant development in the last years. This caused a ceaseless and rapid growth in sharing of the views and experience regarding services or products over the Internet in different domains. Therefore, a torrential flow of online data is available for analytical studies. Sentiment Analysis (SA) is a subtask of Natural Language Processing (NLP) that aims to analyze huge data for detecting people opinions and emotions. This field has gained growing interest by public and private sectors that led to the occurrence of many challenges, especially that related to the Arabic language. The purpose of this study is to conduct a systematic review from year 2000 until June, 2020 to analyze the status of deep Learning for Arabic NLP (ANLP) task in Arabic Subjective Sentiment Analysis (ASSA) to highlight the challenges and propose research opportunities in\u00a0\u2026", "num_citations": "13\n", "authors": ["415"]}
{"title": "Short Term Power Demand Prediction Using Stochastic Gradient Boosting\n", "abstract": " Power prediction demand is vital in power system and delivery engineering fields. By efficiently predicting the power demand, we can forecast the total energy to be consumed in a certain city or district. Thus, exact resources required to produce the demand power can be allocated. In this paper, a Stochastic Gradient Boosting (aka Treeboost) model is used to predict the short term power demand for the Emirate of Sharjah in the United Arab Emirates (UAE). Results show that the proposed model gives promising results in comparison to the model used by Sharjah Electricity and Water Authority (SEWA).", "num_citations": "12\n", "authors": ["415"]}
{"title": "Analyzing the non-functional requirements in the desharnais dataset for software effort estimation\n", "abstract": " Studying the quality requirements (aka Non-Functional Requirements (NFR)) of a system is crucial in Requirements Engineering. Many software projects fail because of neglecting or failing to incorporate the NFR during the software life development cycle. This paper focuses on analyzing the importance of the quality requirements attributes in software effort estimation models based on the Desharnais dataset. The Desharnais dataset is a collection of eighty one software projects of twelve attributes developed by a Canadian software house. The analysis includes studying the influence of each of the quality requirements attributes, as well as the influence of all quality requirements attributes combined when calculating software effort using regression and Artificial Neural Network (ANN) models. The evaluation criteria used in this investigation include the Mean of the Magnitude of Relative Error (MMRE), the Prediction Level (PRED), Root Mean Squared Error (RMSE), Mean Error and the Coefficient of determination (R2). Results show that the quality attribute Language is the most statistically significant when calculating software effort. Moreover, if all quality requirements attributes are eliminated in the training stage and software effort is predicted based on software size only, the value of the error (MMRE) is doubled.", "num_citations": "12\n", "authors": ["415"]}
{"title": "Machine Learning for Cloud Security: A Systematic Review\n", "abstract": " The popularity and usage of Cloud computing is increasing rapidly. Several companies are investing in this field either for their own use or to provide it as a service for others. One of the results of Cloud development is the emergence of various security problems for both industry and consumer. One of the ways to secure Cloud is by using Machine Learning (ML). ML techniques have been used in various ways to prevent or detect attacks and security gaps on the Cloud. In this paper, we provide a Systematic Literature Review (SLR) of ML and Cloud security methodologies and techniques. We analyzed 63 relevant studies and the results of the SLR are categorized into three main research areas: (i) the different types of Cloud security threats, (ii) ML techniques used, and (iii) the performance outcomes. We have defined 11 Cloud security areas. Moreover, distributed denial-of-service (DDoS) and data privacy are the\u00a0\u2026", "num_citations": "10\n", "authors": ["415"]}
{"title": "Arabic audio clips: Identification and discrimination of authentic Cantillations from imitations\n", "abstract": " This paper introduces a thorough study of classical and deep learning algorithms implemented for multi-class speaker identification and verification of Qur\u2019anic audio clips. Thirty different reciters and twelve imitators, of top reciters, were evaluated in the study. In addition to identifying the reciter, our objective is to first evaluate different classifiers performing the stated recognition, compare classical vs. deep-based classifiers, and finally benchmark automatic against human expert listeners\u2019 accuracy in identifying authentic reciters from imitators. Using different multimedia outlets over the internet, several reciters became more popular than others for their distinct cantillation style. Towards the development of a practical classifying system, a significant dataset of 15810 audio clips is constructed for thirty reciters in addition to 397 clips for top imitators. A combination of perceptual and acoustic features was extracted in\u00a0\u2026", "num_citations": "6\n", "authors": ["415"]}
{"title": "CASA-based speaker identification using cascaded GMM-CNN classifier in noisy and emotional talking conditions\n", "abstract": " This work aims at intensifying text-independent speaker identification performance in real application situations such as noisy and emotional talking conditions. This is achieved by incorporating two different modules: a Computational Auditory Scene Analysis (CASA) based pre-processing module for noise reduction and \u201ccascaded Gaussian Mixture Model \u2013 Convolutional Neural Network (GMM-CNN) classifier for speaker identification\u201d followed by emotion recognition. This research proposes and evaluates a novel algorithm to improve the accuracy of speaker identification in emotional and highly-noise susceptible conditions. Experiments demonstrate that the proposed model yields promising results in comparison with other classifiers when \u201cSpeech Under Simulated and Actual Stress (SUSAS) database, Emirati Speech Database (ESD), the Ryerson Audio-Visual Database of Emotional Speech and Song\u00a0\u2026", "num_citations": "5\n", "authors": ["415"]}
{"title": "Utilizing Third-Order Hidden Markov Models for Emotional Talking Condition Recognition\n", "abstract": " It is well known that the performance of emotional talking condition recognition is imperfect. This work aims at enhancing the performance of emotional talking condition recognition based on \"Third-Order Hidden Markov Models (HMM3s)\" as classifiers. Our work has been tested on \"Emotional Prosody Speech and Transcripts (EPST)\" database. The extracted features of EPST database are Mel-Frequency Cepstral Coefficients (MFCCs). Our results give average talking recognition performance of 71.8%. The results of this work show that HMM3s are superior to First-Order Hidden Markov Models (HMM1s) and Second-Order Hidden Markov Models (HMM2s) by 14.0% and 5.7%, respectively, for emotional talking condition recognition. The average talking recognition performance attained based on HMM3s is very close to that obtained using \"subjective assessment by human judges\".", "num_citations": "5\n", "authors": ["415"]}
{"title": "Data Mining with Big Data in Intrusion Detection Systems: A Systematic Literature Review\n", "abstract": " Cloud computing has become a powerful and indispensable technology for complex, high performance and scalable computation. The exponential expansion in the deployment of cloud technology has produced a massive amount of data from a variety of applications, resources and platforms. In turn, the rapid rate and volume of data creation has begun to pose significant challenges for data management and security. The design and deployment of intrusion detection systems (IDS) in the big data setting has, therefore, become a topic of importance. In this paper, we conduct a systematic literature review (SLR) of data mining techniques (DMT) used in IDS-based solutions through the period 2013-2018. We employed criterion-based, purposive sampling identifying 32 articles, which constitute the primary source of the present survey. After a careful investigation of these articles, we identified 17 separate DMTs deployed in an IDS context. This paper also presents the merits and disadvantages of the various works of current research that implemented DMTs and distributed streaming frameworks (DSF) to detect and/or prevent malicious attacks in a big data environment.", "num_citations": "4\n", "authors": ["415"]}
{"title": "Emirati-Accented Speaker Identification in Stressful Talking Conditions\n", "abstract": " This research is dedicated to improving \u201ctext-independent Emirati-accented speaker identification performance in stressful talking conditions\u201d using three distinct classifiers: \u201cFirst-Order Hidden Markov Models (HMM1s), Second-Order Hidden Markov Models (HMM2s), and Third-Order Hidden Markov Models (HMM3s).\u201d The database that has been used in this work was collected from 25 per gender Emirati native speakers uttering eight widespread Emirati sentences in each of neutral, shouted, slow, loud, soft, and fast talking conditions. The extracted features of the captured database are called \u201cMel-Frequency Cepstral Coefficients (MFCCs).\u201d Based on HMM1s, HMM2s, and HMM3s, average Emirati-accented \u201cspeaker identification accuracy in stressful conditions\u201d is 58.6%, 61.1%, and 65.0%, respectively. The achieved \u201caverage speaker identification accuracy in stressful conditions based on HMM3s\u201d is so similar\u00a0\u2026", "num_citations": "4\n", "authors": ["415"]}
{"title": "Three-stage speaker verification architecture in emotional talking environments\n", "abstract": " Speaker verification performance in neutral talking environment is usually high, while it is sharply decreased in emotional talking environments. This performance degradation in emotional environments is due to the problem of mismatch between training in neutral environment while testing in emotional environments. In this work, a three-stage speaker verification architecture has been proposed to enhance speaker verification performance in emotional environments. This architecture is comprised of three cascaded stages: gender identification stage followed by an emotion identification stage followed by a speaker verification stage. The proposed framework has been evaluated on two distinct and independent emotional speech datasets: in-house dataset and \u201cEmotional Prosody Speech and Transcripts\u201d dataset. Our results show that speaker verification based on both gender information and emotion\u00a0\u2026", "num_citations": "4\n", "authors": ["415"]}
{"title": "Reliability prediction of smartphone Applications through failure data analysis\n", "abstract": " Smart phones have become the most used electronic devices. They carry out most of the functionalities of desktops, offering various useful applications that suit the user's needs. Therefore, instead of being an operator, the user has become the main controller of the device and its applications. Therefore, its reliability becomes an emergent requirement. In this paper, we shortly highlight the shortcomings of Software Reliability Growth Models (SRGMs) when applied to Smartphone applications and suggest future directions for reliability prediction in the mobile area.", "num_citations": "4\n", "authors": ["415"]}
{"title": "Measuring the usage of SaaS applications based on utilized features\n", "abstract": " Software as a Service (SaaS) is an online delivery of software to customers as a service. The interest in adopting SaaS has been rapidly increasing due to the advantages of SaaS. Current SaaS vendors such as Salesforce. com charge their customers based on the type of the edition and on the number of users. Many customers are not satisfied with the current pricing model and are requesting to pay according to the actual usage of the SaaS application. SaaS vendors are looking to implement a metering solution that measures the computational resources such as the CPU, memory and transactional usage as well as the utilized features of each SaaS user. This paper focuses on implementing a crucial element of the metering system which is measuring the SaaS applications based on the features utilized by each user. This is also called the Feature-Based Approach.", "num_citations": "3\n", "authors": ["415"]}
{"title": "Systematic Literature Review of Dialectal Arabic: Identification and Detection\n", "abstract": " It is becoming increasingly difficult to know who is working on what and how in computational studies of Dialectal Arabic. This study comes to chart the field by conducting a systematic literature review that is intended to give insight into the most and least popular research areas, dialects, machine learning approaches, neural network input features, data types, datasets, system evaluation criteria, publication venues, and publication trends. It is a review that is guided by the norms of systematic reviews. It has taken account of all the research that adopted a computational approach to dialectal Arabic identification and detection and that was published between 2000 and 2020. It collected, analyzed, and collated this research, discovered its trends, and identified research gaps. It revealed, inter alia, that our research effort has not been directed evenly between speech and text or between the vernaculars; there is some\u00a0\u2026", "num_citations": "2\n", "authors": ["415"]}
{"title": "A Systematic Literature Review on Machine Learning in Object Detection Security\n", "abstract": " This paper is a Systematic literature review on the topic of machine learning in object detection security, where the work done covers a number of 73 research papers related to this topic, and answers three different research questions, while providing charts, tables, and statistics to summarize the data and give the reader and easy to read summarized overview of the papers related to this topic.", "num_citations": "2\n", "authors": ["415"]}
{"title": "EEG Wheelchair for People of Determination\n", "abstract": " The aim of this paper is to design and construct an electroencephalograph (EEG) based brain-controlled wheelchair to provide a communication bridge from the nervous system to the external technical device for people of determination or individuals suffering from partial or complete paralysis. EEG is a technique that reads the activity of the brain by capturing brain signals non- invasively using a special EEG headset. The signals acquired go through pre-processing, feature extraction and classification. This technique allows human thoughts alone to be converted to control the wheelchair. The commands used are moving to the right, left, forward, and backward and stop. The brain signals are acquired using the Emotiv Epoc headset. Discrete Wavelet Transform is used for feature extraction and Support Vector Machine (SVM) is used for classification.", "num_citations": "2\n", "authors": ["415"]}
{"title": "A Systematic Literature Review on Metaheuristic Optimization Techniques in WSNs\n", "abstract": " Metaheuristic algorithms are recognized for developing new algorithms and optimizing various aspects in Wireless Sensor Networks (WSNs). Evaluating a multitude of possible modes is required, in most complicated problems, to obtain an exact solution. Metaheuristic algorithms can obtain solutions in acceptable time constraints. These algorithms play an operational role in solving such problems by optimizing the different metrics such as coverage rate and energy consumption of the networks. These metrics have valuable impact on network lifetime as well. This systematic review focuses on the published work from 2010 to 2020 in metaheuristic optimization in WSN. Furthermore, the systematic review will answer multiple questions that will be discussed in the methodology section.", "num_citations": "2\n", "authors": ["415"]}
{"title": "Identifying Patterns of Breast Cancer Genetic Signatures using Unsupervised Machine Learning\n", "abstract": " Deploying machine learning to improve medical diagnosis is a promising area. The purpose of this study is to identify and analyze unique genetic signatures for breast cancer grades using publicly available gene expression microarray data. The classification of cancer types is based on unsupervised feature learning. Unsupervised clustering use matrix algebra based on similarity measures which made it suitable for analyzing gene expression. The main advantage of the proposed approach is the ability to use gene expression data from different grades of breast cancer to generate features that automatically identify and enhance the cancer diagnosis. In this paper, we tested different similarity measures in order to find the best way that identifies the sets of genes with a common function using expression microarray data.", "num_citations": "2\n", "authors": ["415"]}
{"title": "Comparative study on the performance of heuristic optimization techniques in robotic path planning\n", "abstract": " This work presents a comparative study between the three popular optimization techniques namely the Genetic Algorithm (GA), Particle Swarm Optimization technique (PSO) and the Artificial Bee Colony (ABC) in the robotic path planning field. Path planning techniques suffer from a well-known trade-off between path quality and swiftness. Researchers had to always trade-off between shorter paths and higher computational execution time. However, with the invention of heuristic optimization techniques such as GA, PSO and ABC, there is an expect that these optimization techniques can overcome this trade-off. Thus, this paper investigates the performance of the three optimization techniques in robotic path planning problems.", "num_citations": "2\n", "authors": ["415"]}
{"title": "Speaker Verification in Emotional Talking Environments based on Third-Order Circular Suprasegmental Hidden Markov Model\n", "abstract": " Speaker verification accuracy in emotional talking environments is not high as it is in neutral ones. This work aims at accepting or rejecting the claimed speaker using his/her voice in emotional environments based on the \u201cThird-Order Circular Suprasegmental Hidden Markov Model (CSPHMM3)\u201d as a classifier. An Emirati-accented (Arabic) speech database with \u201cMel-Frequency Cepstral Coefficients\u201d as the extracted features has been used to evaluate our work. Our results demonstrate that speaker verification accuracy based on CSPHMM3 is greater than that based on the \u201cstate-of-the-art classifiers and models such as Gaussian Mixture Model (GMM), Support Vector Machine (SVM), and Vector Quantization (VQ)\".", "num_citations": "2\n", "authors": ["415"]}
{"title": "Speaker identification in stressful talking environments based on convolutional neural network\n", "abstract": " Speaker identification accuracy in stressful environments is deficient compared to neutral environment. This research aims at employing and assessing an up-to-date classifier to reinforce and enhance the degraded text-independent speaker identification accuracy in stressful environments. The classifier is based on exploiting supervised Convolutional Neural Network (CNN) using three distinct speech databases: Arabic Emirati-accented database, \u201cSpeech Under Simulated and Actual Stress (SUSAS) English database, and Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)\u201d English datasets with the concatenated Mel-Frequency Cepstral Coefficients (MFCCs), MFCCs-delta, and MFCCs-delta-delta as the extracted features. Using Emirati-accented corpus, CNN surpasses all the shallow classifiers where the results demonstrate that CNN yields average accuracy of 81.6\u00a0\u2026", "num_citations": "1\n", "authors": ["415"]}
{"title": "Novel hybrid DNN approaches for speaker verification in emotional and stressful talking environments\n", "abstract": " In this work, we conducted an empirical comparative study of the performance of text-independent speaker verification in emotional and stressful environments. This work combined deep models with shallow architecture, which resulted in novel hybrid classifiers. Four distinct hybrid models were utilized: deep neural network-hidden Markov model (DNN-HMM), deep neural network-Gaussian mixture model (DNN-GMM), Gaussian mixture model-deep neural network (GMM-DNN), and hidden Markov model-deep neural network (HMM-DNN). All models were based on novel implemented architecture. The comparative study used three distinct speech datasets: a private Arabic dataset and two public English databases, namely Speech Under Simulated and Actual Stress (SUSAS) and Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS). The test results of the aforementioned hybrid models\u00a0\u2026", "num_citations": "1\n", "authors": ["415"]}
{"title": "Machine Learning for Anomaly Detection: A Systematic Review\n", "abstract": " Anomaly detection has been used for decades to identify and extract anomalous components from data. Many techniques have been used to detect anomalies. One of the increasingly significant techniques is Machine Learning (ML), which plays an important role in this area. In this research paper, we conduct a Systematic Literature Review (SLR) which analyzes ML models that detect anomalies in their application. Our review analyzes the models from four perspectives; the applications of anomaly detection, ML techniques, performance metrics for ML models, and the classification of anomaly detection. In our review, we have identified 290 research articles, written from 2000-2020, that discuss ML techniques for anomaly detection. After analyzing the selected research articles, we present 43 different applications of anomaly detection found in the selected research articles. Moreover, we identify 29 distinct ML\u00a0\u2026", "num_citations": "1\n", "authors": ["415"]}
{"title": "Predicting the power of a combined cycle power plant using machine learning methods\n", "abstract": " The gas turbine is the most important part of the combined cycle power plant that generates the total electric power from the fuel to provide it to the houses, schools, and other facilities in the country. Thus, it is important to predict the power to increase and maximize profit. This paper compares four machine learning algorithms which are Multiple linear Regression, Multilayer perceptron, K-Nearest Neighbors, and Random Forest Algorithm. The dataset consists of 9,568 observations and four inputs which are ambient temperature, ambient pressure, relative humidity, and exhaust vacuum that will be used to train the prediction of the total electric power consumption which is the output. The best result was shown by using the Random Forest Algorithm with the mean absolute error of 2.3013 and root mean square error with 3.3061.", "num_citations": "1\n", "authors": ["415"]}
{"title": "Systematic Literature Review: Metaheuristics-based Approach for Workflow Scheduling in Cloud\n", "abstract": " Workflow scheduling is one of the fundamental challenges of cloud computing, which aims to execute the workflows while considering the Quality of Service (QoS) requirements. This paper provides a thorough analysis of the different studies that have been conducted on workflow scheduling in cloud computing in last ten years. A thorough statistical analysis is provided in this review which was conducted by extracting specific information from 59 papers published between the years 2010 and 2020. Moreover, a classification of the proposed methods based on the type of scheduling algorithm applied in each scheme is presented. Finally, future direction in the domain of workflow scheduling in cloud is stated.", "num_citations": "1\n", "authors": ["415"]}
{"title": "A Systematic Literature Review for Software Portability Measurement: Preliminary Results\n", "abstract": " Software developers agree that software portability is a desirable attribute for their software quality. Software portability is mostly acquired by ad-hoc techniques when trying to port existing products. There is a lack of unified measuring approach of software portability in most computing platforms. This paper presents preliminary results of a systematic literature review, conducted to collect evidence on measuring software portability. The evidence was gathered from selected studies and based on a set of meaningful and focused questions. 49 studies of these were selected for data extraction performed against the research questions. We provide an overview of used\\proposed measurement metrics of software portability. Our results suggested that there are scattered efforts to understand measurement of software portability, and no census has been achieved.", "num_citations": "1\n", "authors": ["415"]}
{"title": "Can we rely on smartphone applications?\n", "abstract": " Smartphones are becoming necessary tools in the daily lives of millions of users who rely on these devices and their applications. There are thousands of applications for smartphone devices such as the iPhone, Blackberry, and Android, thus their reliability has become paramount for their users. This work aims to answer two related questions: (1) Can we assess the reliability of mobile applications by using the traditional reliability models? (2) Can we model adequately the failure data collected from many users? Firstly, it has been proved that the three most used software reliability models have fallen short of the mark when applied to smartphone applications; their failures were traced back to specific features of mobile applications. Secondly, it has been demonstrated that the Weibull and Gamma distribution models can adequately fit the observed failure data, thus providing better means to predict the\u00a0\u2026", "num_citations": "1\n", "authors": ["415"]}