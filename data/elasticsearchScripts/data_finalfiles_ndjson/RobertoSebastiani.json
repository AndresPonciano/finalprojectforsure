{"title": "Lazy satisfiability modulo theories\n", "abstract": " Satisfiability Modulo Theories (SMT) is the problem of deciding the satisfiability of a first-order formula with respect to some decidable first-order theory T (SMT (T)). These problems are typically not handled adequately by standard automated theorem provers. SMT is being recognized as increasingly important due to its applications in many domains in different communities, in particular in formal verification. An amount of papers with novel and very efficient techniques for SMT has been published in the last years, and some very efficient SMT tools are now available.Typical SMT (T) problems require testing the satisfiability of formulas which are Boolean combinations of atomic propositions and atomic expressions in T, so that heavy Boolean reasoning must be efficiently combined with expressive theory-specific reasoning. The dominating approach to SMT (T), called lazy approach, is based on the integration of a\u00a0\u2026", "num_citations": "318\n", "authors": ["1791"]}
{"title": "Building decision procedures for modal logics from propositional decision procedures\u2014the case study of modal K\n", "abstract": " The goal of this paper is to propose a new technique for developing decision procedures for propositional modal logics. The basic idea is that propositional modal decision procedures should be developed on top of propositional decision procedures. As a case study, we describe an algorithm, based on an implementation of the Davis-Putnam-Longemann-Loveland procedure, which tests satisfiability in modal K. The algorithm is compared with a tableau based decision procedure. The experimental results show that our algorithm outperforms this system. The testing is performed following a newly developed methodology which, among other things, allows us to classify problems according to an easy to hard pattern.", "num_citations": "172\n", "authors": ["1791"]}
{"title": "Bounded model checking for timed systems\n", "abstract": " Enormous progress has been achieved in the last decade in the verification of timed systems, making it possible to analyze significant real-world protocols. An open challenge is the identification of fully symbolic verification techniques, able to deal effectively with the finite state component as well as with the timing aspects. In this paper we propose a new, symbolic verification technique that extends the Bounded Model Checking (BMC) approach for the verification of timed systems. The approach is based on the following ingredients. First, a BMC problem for timed systems is reduced to the satisfiability of a math-formula, i.e., a boolean combination of propositional variables and linear mathematical relations over real variables (used to represent clocks). Then, an appropriate solver, called MathSAT, is used to check the satisfiability of the math-formula. The solver is based on the integration of SAT techniques\u00a0\u2026", "num_citations": "159\n", "authors": ["1791"]}
{"title": "Verifying industrial hybrid systems with MathSAT\n", "abstract": " Industrial systems of practical relevance can be often characterized in terms of discrete control variables and real-valued physical variables, and can therefore be modeled as hybrid automata. Unfortunately, continuity of the physical behaviour over time, or triangular constraints, must often be assumed, which yield an undecidable class of hybrid automata. In this paper, we propose a technique for bounded reachability of linear hybrid automata, based on the reduction of a bounded reachability problem to a MathSAT problem, ie satisfiability of a boolean combination of propositional variables and mathematical constraints. The MathSAT solver can be used to check the existence (or absence) of paths of bounded length. The approach is very similar in spirit to SAT-based bounded model checking; furthermore, the ability to reason directly about real variables gives computational leverage over discretization-based\u00a0\u2026", "num_citations": "140\n", "authors": ["1791"]}
{"title": "OptiMathSAT: A tool for optimization modulo theories\n", "abstract": " Optimization Modulo Theories () is an extension of SMT which allows for finding models that optimize given objectives. OptiMathSAT is an OMT solver which allows for solving a list of optimization problems on SMT formulas with linear objective functions\u2014on the Boolean, the rational and the integer domains, and on their combination thereof\u2014including (partial weighted) MaxSMT . Multiple and heterogeneous objective functions can be combined together and handled either independently, or lexicographically, or in linear or min\u2013max /max\u2013min combinations. OptiMathSAT provides an incremental interface, it supports both an extended version of the SMT-LIBv2 language and a subset of the FlatZinc language, and can be interfaced via an API. In this paper we describe OptiMathSAT and its usage in full detail.", "num_citations": "125\n", "authors": ["1791"]}
{"title": "A SAT-based decision procedure for ALC\n", "abstract": " Abstract(K (m)-satisfiability) can be defined in terms of a de-cision procedure for propositional satisfiability (SAT).", "num_citations": "112\n", "authors": ["1791"]}
{"title": "Efficient satisfiability modulo theories via delayed theory combination\n", "abstract": " The problem of deciding the satisfiability of a quantifier-free formula with respect to a background theory, also known as Satisfiability Modulo Theories (SMT), is gaining increasing relevance in verification: representation capabilities beyond propositional logic allow for a natural modeling of real-world problems (e.g., pipeline and RTL circuits verification, proof obligations in software systems).               In this paper, we focus on the case where the background theory is the combination T                         1\u222aT                         2 of two simpler theories. Many SMT procedures combine a boolean model enumeration with a decision procedure for T                         1\u222aT                         2, where conjunctions of literals can be decided by an integration schema such as Nelson-Oppen, via a structured exchange of interface formulae (e.g., equalities in the case of convex theories, disjunctions of equalities otherwise).               We\u00a0\u2026", "num_citations": "107\n", "authors": ["1791"]}
{"title": "Efficient interpolant generation in satisfiability modulo theories\n", "abstract": " The problem of computing Craig Interpolants for propositional (SAT) formulas has recently received a lot of interest, mainly for its applications in formal verification. However, propositional logic is often not expressive enough for representing many interesting verification problems, which can be more naturally addressed in the framework of Satisfiability Modulo Theories, SMT.               Although some works have addressed the topic of generating interpolants in SMT, the techniques and tools that are currently available have some limitations, and their performace still does not exploit the full power of current state-of-the-art SMT solvers.               In this paper we try to close this gap. We present several techniques for interpolant generation in SMT which overcome the limitations of the current generators mentioned above, and which take full advantage of state-of-the-art SMT technology. These novel techniques can\u00a0\u2026", "num_citations": "103\n", "authors": ["1791"]}
{"title": "A Lazy and Layered SMT() Solver for Hard Industrial Verification Problems\n", "abstract": " Rarely verification problems originate from bit-level descriptions. Yet, most of the verification technologies are based on bit blasting, i.e., reduction to boolean reasoning.               In this paper we advocate reasoning at higher level of abstraction, within the theory of bit vectors (), where structural information (e.g. equalities, arithmetic functions) is not blasted into bits.Our approach relies on the lazy Satisfiability Modulo Theories (SMT) paradigm. We developed a satisfiability procedure for reasoning about bit vectors that carefully leverages on the power of boolean SAT solver to deal with components that are more naturally \u201cboolean\u201d, and activates bit-vector reasoning whenever possible. The procedure has two distinguishing features. First, it relies on the on-line integration of a SAT solver with an incremental and backtrackable solver for  that enables dynamical optimization of the reasoning about bit vectors; for\u00a0\u2026", "num_citations": "100\n", "authors": ["1791"]}
{"title": "Satisfiability modulo the theory of costs: Foundations and applications\n", "abstract": " We extend the setting of Satisfiability Modulo Theories (SMT) by introducing a theory of costs , where it is possible to model and reason about resource consumption and multiple cost functions, e.g., battery, time, and space. We define a decision procedure that has all the features required for the integration withint the lazy SMT schema: incrementality, backtrackability, construction of conflict sets, and deduction. This naturally results in an SMT solver for the disjoint union of  and any other theory .               This framework has two important applications. First, we tackle the problem of Optimization Modulo Theories: rather than checking the existence of a satisfying assignment, as in SMT, we require a satisfying assignment that minimizes a given cost function. We build on the decision problem for SMT with costs, i.e., finding a satisfying assigniment with cost within an admissibility range, and propose two\u00a0\u2026", "num_citations": "99\n", "authors": ["1791"]}
{"title": "M ath SAT: Tight Integration of SAT and Mathematical Decision Procedures\n", "abstract": " Recent improvements in propositional satisfiability techniques (SAT) made it possible to tackle successfully some hard real-world problems (e.g., model-checking, circuit testing, propositional planning) by encoding into SAT. However, a purely Boolean representation is not expressive enough for many other real-world applications, including the verification of timed and hybrid systems, of proof obligations in software, and of circuit design at RTL level. These problems can be naturally modeled as satisfiability in linear arithmetic logic (LAL), that is, the Boolean combination of propositional variables and linear constraints over numerical variables. In this paper we present MathSAT, a new, SAT-based decision procedure for LAL, based on the (known approach) of integrating a state-of-the-art SAT solver with a dedicated mathematical solver for LAL. We improve MathSAT in two different directions. First, the top\u00a0\u2026", "num_citations": "98\n", "authors": ["1791"]}
{"title": "\u201cmore deterministic\u201d vs.\u201csmaller\u201d B\u00fcchi automata for efficient LTL model checking\n", "abstract": " The standard technique for LTL model checking () consists on translating the negation of the LTL specification, \u03d5, into a B\u00fcchi automaton A                                    \u03d5                 , and then on checking if the product M \u00d7A                                    \u03d5                  has an empty language. The efforts to maximize the efficiency of this process have so far concentrated on developing translation algorithms producing B\u00fcchi automata which are \u201cas small as possible\u201d, under the implicit conjecture that this fact should make the final product smaller. In this paper we build on a different conjecture and present an alternative approach in which we generate instead B\u00fcchi automata which are \u201cas deterministic as possible\u201d, in the sense that we try to reduce as much as we are able to the presence of non-deterministic decision states in A                                    \u03d5                 . We motivate our choice and present some empirical tests to\u00a0\u2026", "num_citations": "94\n", "authors": ["1791"]}
{"title": "Efficient theory combination via boolean search\n", "abstract": " Many approaches to deciding the satisfiability of quantifier-free formulae with respect to a background theory T\u2014also known as Satisfiability Modulo Theory, or SMT (T)\u2014rely on the integration between an enumerator of truth assignments and a decision procedure for conjunction of literals in T. When the background theory T is the combination T 1\u222a T 2 of two simpler theories, the approach is typically instantiated by means of a theory combination schema (eg Nelson\u2013Oppen, Shostak). In this paper we propose a new approach to SMT (T 1\u222a T 2), where the enumerator of truth assignments is integrated with two decision procedures, one for T 1 and one for T 2, acting independently from each other. The key idea is to search for a truth assignment not only to the atoms occurring in the formula, but also to all the equalities between variables which are shared between the theories. This approach is simple and expressive\u00a0\u2026", "num_citations": "91\n", "authors": ["1791"]}
{"title": "An incremental and layered procedure for the satisfiability of linear arithmetic logic\n", "abstract": " In this paper we present a new decision procedure for the satisfiability of Linear Arithmetic Logic (LAL), i.e. boolean combinations of propositional variables and linear constraints over numerical variables. Our approach is based on the well known integration of a propositional SAT procedure with theory deciders, enhanced in the following ways.               First, our procedure relies on an incremental solver for linear arithmetic, that is able to exploit the fact that it is repeatedly called to analyze sequences of increasingly large sets of constraints. Reasoning in the theory of LA interacts with the boolean top level by means of a stack-based interface, that enables the top level to add constraints, set points of backtracking, and backjump, without restarting the procedure from scratch at every call. Sets of inconsistent constraints are found and used to drive backjumping and learning at the boolean level, and theory\u00a0\u2026", "num_citations": "90\n", "authors": ["1791"]}
{"title": "Optimization in SMT with (\u211a) Cost Functions\n", "abstract": " In the contexts of automated reasoning and formal verification, important decision problems are effectively encoded into Satisfiability Modulo Theories (SMT). In the last decade efficient SMT solvers have been developed for several theories of practical interest (e.g., linear arithmetic, arrays, bit-vectors). Surprisingly, very little work has been done to extend SMT to deal with optimization problems; in particular, we are not aware of any work on SMT solvers able to produce solutions which minimize cost functions over arithmetical variables. This is unfortunate, since some problems of interest require this functionality.               In this paper we start filling this gap. We present and discuss two general procedures for leveraging SMT to handle the minimization of (\u211a) cost functions, combining SMT with standard minimization techniques. We have implemented the procedures within the MathSAT SMT solver. Due to\u00a0\u2026", "num_citations": "84\n", "authors": ["1791"]}
{"title": "Act, and the rest will follow: Exploiting determinism in planning as satisfiability\n", "abstract": " In this paper we focus on Planning as Satis ability (SAT). We build from the simple consideration that the values of uents at a certain time point derive deterministically from the initial situation and the sequence of actions performed till that point. Thus, the choice of actions to perform is the only source of nondeterminism. This is a rather trivial consideration, but which has important positive consequences if implemented in current planners via SAT. In fact, it produces a dramatic size reduction of the space of the truth assignments searched in by the SAT decider used to solve the nal SAT problem. To justify this claim, we repeat many of the experiments reported in (Ernst, Millstein, & Weld 1997), and show that the CPU time requested to solve a problem can go down up to 4 orders of magnitude.", "num_citations": "84\n", "authors": ["1791"]}
{"title": "Efficient generation of Craig interpolants in satisfiability modulo theories\n", "abstract": " The problem of computing Craig interpolants has recently received a lot of interest. In this article, we address the problem of efficient generation of interpolants for some important fragments of first-order logic, which are amenable for effective decision procedures, called satisfiability modulo theory (SMT) solvers. We make the following contributions. First, we provide interpolation procedures for several basic theories of interest: the theories of linear arithmetic over the rationals, difference logic over rationals and integers, and UTVPI over rationals and integers. Second, we define a novel approach to interpolate combinations of theories that applies to the delayed theory combination approach. Efficiency is ensured by the fact that the proposed interpolation algorithms extend state-of-the-art algorithms for satisfiability modulo theories. Our experimental evaluation shows that the MathSAT SMT solver can produce\u00a0\u2026", "num_citations": "72\n", "authors": ["1791"]}
{"title": "The mathsat 3 system\n", "abstract": " Satisfiability Modulo Theories (SMT) can be seen as an extended form of propositional satisfiability, where propositions are either simple boolean propositions or quantifier-free atomic constraints in a specific theory.", "num_citations": "72\n", "authors": ["1791"]}
{"title": "Optimization modulo theories with linear rational costs\n", "abstract": " In the contexts of automated reasoning (AR) and formal verification (FV), important decision problems are effectively encoded into Satisfiability Modulo Theories (SMT). In the last decade, efficient SMT solvers have been developed for several theories of practical interest (e.g., linear arithmetic, arrays, and bit vectors). Surprisingly, little work has been done to extend SMT to deal with optimization problems; in particular, we are not aware of any previous work on SMT solvers able to produce solutions that minimize cost functions over arithmetical variables. This is unfortunate, since some problems of interest require this functionality. In the work described in this article we start filling this gap. We present and discuss two general procedures for leveraging SMT to handle the minimization of linear rational cost functions, combining SMT with standard minimization techniques. We have implemented the procedures within the\u00a0\u2026", "num_citations": "67\n", "authors": ["1791"]}
{"title": "A simple and flexible way of computing small unsatisfiable cores in SAT modulo theories\n", "abstract": " Finding small unsatisfiable cores for SAT problems has recently received a lot of interest, mostly for its applications in formal verification. Surprisingly, the same problem in the context of SAT Modulo Theories (SMT) has instead received very little attention in the literature; in particular, we are not aware of any work aiming at producing small unsatisfiable cores in SMT.             The purpose of this paper is to start filling the gap in this area, by proposing a novel approach for computing small unsat cores in SMT. The main idea is to combine an SMT solver with an external propositional core extractor: the SMT solver produces the theory lemmas found during the search; the core extractor is then called on the boolean abstraction of the original SMT problem and of the theory lemmas. This results in an unsatisfiable core for the original SMT problem, once the remaining theory lemmas have been removed.             The\u00a0\u2026", "num_citations": "67\n", "authors": ["1791"]}
{"title": "A new general method to generate random modal formulae for testing decision procedures\n", "abstract": " The recent emergence of heavily-optimized modal decision procedures has highlighted the key role of empirical testing in this domain. Unfortunately, the introduction of extensive empirical tests for modal logics is recent, and so far none of the proposed test generators is very satisfactory. To cope with this fact, we present a new random generation method that provides benefits over previous methods for generating empirical tests. It fixes and much generalizes one of the best-known methods, the random CNF_ [] m test, allowing for generating a much wider variety of problems, covering in principle the whole input space. Our new method produces much more suitable test sets for the current generation of modal decision procedures. We analyze the features of the new method by means of an extensive collection of empirical tests.", "num_citations": "67\n", "authors": ["1791"]}
{"title": "Building decision procedures for modal logics from propositional decision procedures: The case study of modal K (m)\n", "abstract": " The goal of this paper is to propose a new technique for developing decision procedures for propositional modal logics. The basic idea is that propositional modal decision procedures should be developed on top of propositional decision procedures. As a case study, we consider satisfiability in modal K (m), that is modal K with m modalities, and develop an algorithm, called K SAT, on top of an implementation of the Davis\u2013Putnam\u2013Longemann\u2013Loveland procedure. K SAT is thoroughly tested and compared with various procedures and in particular with the state-of-the-art tableau-based system K RIS. The experimental results show that K SAT outperforms K RIS and the other systems of orders of magnitude, highlight an intrinsic weakness of tableau-based decision procedures, and provide partial evidence of a phase transition phenomenon for K (m).", "num_citations": "64\n", "authors": ["1791"]}
{"title": "An analysis of empirical testing for modal decision procedures\n", "abstract": " Recent years have seen the emergence of a new generation of heavily-optimised modal decision procedures. Several systems based on such procedures are now available and have proved to be much more effective than the previous generation of modal decision procedures. As both computational complexity and algorithm complexity are generally unchanged, neither is useful in analysing and comparing these new systems and their various optimisations. Instead, empirical testing has been widely used, both for comparison and as a tool for tuning systems and identifying their strengths and weaknesses. However, the very effectiveness of the new systems has revealed serious weaknesses in existing empirical test suites and methodologies. This paper provides a detailed survey of empirical testing methodologies, analyses the current state of the art and presents new results obtained with a recently\u00a0\u2026", "num_citations": "60\n", "authors": ["1791"]}
{"title": "Symbolic systems, explicit properties: on hybrid approaches for LTL symbolic model checking\n", "abstract": " In this work we study hybrid approaches to LTL symbolic model checking; that is, approaches that use explicit representations of the property automaton, whose state space is often quite manageable, and symbolic representations of the system, whose state space is typically exceedingly large. We compare the effects of using, respectively, (i) a purely symbolic representation of the property automaton, (ii) a symbolic representation, using logarithmic encoding, of explicitly compiled property automaton, and (iii) a partitioning of the symbolic state space according to an explicitly compiled property automaton. We apply this comparison to three model-checking algorithms: the doubly-nested fixpoint algorithm of Emerson and Lei, the reduction of emptiness to reachability of Biere et al., and the singly-nested fixpoint algorithm of Bloem et al.\u00a0for weak automata. The emerging picture from our study is quite clear\u00a0\u2026", "num_citations": "58\n", "authors": ["1791"]}
{"title": "More evaluation of decision procedures for modal logics\n", "abstract": " This paper follows on previous papers which presented and evaluated various decision procedures for modal logics. It con rms previous experimental results in showing that SAT based decision procedures, ie, the procedures built on top of decision procedures for propositional satis ability, are more efcient than tableau based decision procedures. It also con rms previous evidence of an easy-hard-easy pattern in the satis ability curve for modal K. Finally, it provides further experimental results, suggesting that SAT based decision procedures are also more e cient than the decision procedures based on Ohlbach's translation method. Our results contradict some of the results presented in previous papers.", "num_citations": "58\n", "authors": ["1791"]}
{"title": "Computing small unsatisfiable cores in satisfiability modulo theories\n", "abstract": " The problem of finding small unsatisfiable cores for SAT formulas has recently received a lot of interest, mostly for its applications in formal verification. However, propositional logic is often not expressive enough for representing many interesting verification problems, which can be more naturally addressed in the framework of Satisfiability Modulo Theories, SMT. Surprisingly, the problem of finding unsatisfiable cores in SMT has received very little attention in the literature.", "num_citations": "57\n", "authors": ["1791"]}
{"title": "Delayed theory combination vs. Nelson-Oppen for satisfiability modulo theories: a comparative analysis\n", "abstract": " Abstract Many approaches for Satisfiability Modulo Theory (SMT \\mathcal(T)) rely on the integration between a SAT solver and a decision procedure for sets of literals in the background theory T(T-solver). When T is the combination T_1\u222aT_2 of two simpler theories, the approach is typically handled by means of Nelson-Oppen\u2019s (NO) theory combination schema in which two specific T-solver deduce and exchange (disjunctions of) interface equalities. In recent papers we have proposed a new approach to (T_1\u222aT_2), called Delayed Theory Combination (Dtc). Here part or all the (possibly very expensive) task of deducing interface equalities is played by the SAT solver itself, at the potential cost of an enlargement of the boolean search space. In principle this enlargement could be up to exponential in the number of interface equalities generated. In this paper we show that this estimate was too pessimistic. We present\u00a0\u2026", "num_citations": "56\n", "authors": ["1791"]}
{"title": "Applying the Davis-Putnam procedure to non-clausal formulas\n", "abstract": " Traditionally, the satisfiability problem for propositional logics deals with formulas in Conjunctive Normal Form (CNF). A typical way to deal with non-CNF formulas requires (i) converting them into CNF, and (ii) applying solvers usually based on the Davis-Putnam (DP) procedure. A well known problem of this solution is that the CNF conversion may introduce many new variables, thus greatly widening the space of assignments in which the DP procedure has to search in order to find solutions.               In this paper we present two variants of the DP procedure which overcome the problem outlined above. The idea underlying these variants is that splitting should occur only for the variables in the original formula. The CNF conversion methods employed ensure their correctness and completeness. As a consequence, we get two decision procedures for non-CNF formulas (i) which can exploit all the present and\u00a0\u2026", "num_citations": "56\n", "authors": ["1791"]}
{"title": "Applying GSATto Non-Clausal Formulas\n", "abstract": " In this paper we describe how to modify GSAT so that it can be applied to non-clausal formulas. The idea is to use a particular``score''function which gives the number of clauses of the CNF conversion of a formula which are false under a given truth assignment. Its value is computed in linear time, without constructing the CNF conversion itself. The proposed methodology applies to most of the variants of GSAT proposed so far.", "num_citations": "56\n", "authors": ["1791"]}
{"title": "Axiom pinpointing in lightweight description logics via horn-sat encoding and conflict analysis\n", "abstract": " The recent quest for tractable logic-based languages arising from the field of bio-medical ontologies has raised a lot of attention on lightweight (i.e. less expressive but tractable) description logics, like  and its family. To this extent, automated reasoning techniques in these logics have been developed for computing not only concept subsumptions, but also to pinpoint the set of axioms causing each subsumption. In this paper we build on previous work from the literature and we propose and investigate a simple and novel approach for axiom pinpointing for the logic . The idea is to encode the classification of an ontology into a Horn propositional formula, and to exploit the power of Boolean Constraint Propagation and Conflict Analysis from modern SAT solvers to compute concept subsumptions and to perform axiom pinpointing. A preliminary empirical evaluation confirms the potential of the approach.", "num_citations": "52\n", "authors": ["1791"]}
{"title": "Automated reasoning in modal and description logics via SAT encoding: the case study of k (m)/alc-satisfiability\n", "abstract": " In the last two decades, modal and description logics have been applied to numerous areas of computer science, including knowledge representation, formal verification, database theory, distributed computing and, more recently, semantic web and ontologies. For this reason, the problem of automated reasoning in modal and description logics has been thoroughly investigated. In particular, many approaches have been proposed for efficiently handling the satisfiability of the core normal modal logic K (m), and of its notational variant, the description logic ALC. Although simple in structure, K (m)/ALC is computationally very hard to reason on, its satisfiability being PSPACE-complete.", "num_citations": "52\n", "authors": ["1791"]}
{"title": "Encoding rtl constructs for mathsat: a preliminary report\n", "abstract": " Formal checking at Register-Transfer Level (RTL) is currently a fundamental step in the design of hardware circuits. Most tools for formal checking, however, work at the boolean level, which is not expressive enough to capture the abstract, high level (e.g., structural, word level) information of RTL designs. Tools for formal checking are thus confronted with problems which are \u201cflattened\u201d down to boolean level, so that a predominant part of their computational effort is wasted in performing useless boolean search on the bitwise encoding of integer data and arithmetical operations. In this paper we present a way of encoding RTL constructs into SMT formulas, that is, boolean combinations of boolean variables and quantifier-free constraints in Integer Linear Arithmetic. Such formulas can be handled by the MathSAT tool (and others) directly, without flattening to boolean level, so that to reduce drastically the computational\u00a0\u2026", "num_citations": "48\n", "authors": ["1791"]}
{"title": "SAT vs. Translation based decision procedures for modal logics: a comparative evaluation\n", "abstract": " This paper follows on previous papers which present and evaluate various decision procedures for modal logics. We consider new test sets and systems that have been recently proposed in the literature. This new experimental analysis confirm previous experimental results in showing that SAT based decision procedures, i.e., the procedures built on top of decision procedures for propositional satisfiability, are more efficient than tableau based decision procedures. They also confirm previous evidence of an easy-hard-easy pattern in the satisfiability curve for modal K. Finally, on these tests, SAT based decision procedures are also more efficient than the recently proposed decision procedures based on translation methods. These results contradict some of the claims presented in previous papers by other authors.", "num_citations": "47\n", "authors": ["1791"]}
{"title": "Structured learning modulo theories\n", "abstract": " Modeling problems containing a mixture of Boolean and numerical variables is a long-standing interest of Artificial Intelligence. However, performing inference and learning in hybrid domains is a particularly daunting task. The ability to model these kinds of domains is crucial in \u201clearning to design\u201d tasks, that is, learning applications where the goal is to learn from examples how to perform automatic de novo design of novel objects. In this paper we present Structured Learning Modulo Theories, a max-margin approach for learning in hybrid domains based on Satisfiability Modulo Theories, which allows to combine Boolean reasoning and optimization over continuous linear arithmetical constraints. The main idea is to leverage a state-of-the-art generalized Satisfiability Modulo Theory solver for implementing the inference and separation oracles of Structured Output SVMs. We validate our method on artificial and real\u00a0\u2026", "num_citations": "42\n", "authors": ["1791"]}
{"title": "Pushing the envelope of optimization modulo theories with linear-arithmetic cost functions\n", "abstract": " In the last decade we have witnessed an impressive progress in the expressiveness and efficiency of Satisfiability Modulo Theories (SMT) solving techniques. This has brought previously-intractable problems at the reach of state-of-the-art SMT solvers, in particular in the domain of SW and HW verification. Many SMT-encodable problems of interest, however, require also the capability of finding models that are optimal wrt. some cost functions. In previous work, namely Optimization Modulo Theory with Linear Rational Cost Functions \u2013 OMT(                   ), we have leveraged SMT solving to handle the minimization of cost functions on linear arithmetic over the rationals, by means of a combination of SMT and LP minimization techniques.                 In this paper we push the envelope of our OMT approach along three directions: first, we extend it to work with linear arithmetic on the mixed integer/rational\u00a0\u2026", "num_citations": "35\n", "authors": ["1791"]}
{"title": "Applying SMT in symbolic execution of microcode\n", "abstract": " Microcode is a critical component in modern microprocessors, and substantial effort has been devoted in the past to verify its correctness. A prominent approach, based on symbolic execution, traditionally relies on the use of boolean SAT solvers as a backend engine. In this paper, we investigate the application of Satisfiability Modulo Theories (SMT) to the problem of microcode verification. We integrate MathSAT, an SMT solver for the theory of Bit Vectors, within the flow of microcode verification, and experimentally evaluate the effectiveness of some optimizations. The results demonstrate the potential of SMT technologies over pure boolean SAT.", "num_citations": "34\n", "authors": ["1791"]}
{"title": "A modular approach to MaxSAT modulo theories\n", "abstract": " In this paper we present a novel \u201cmodular\u201d approach for (weighted partial) MaxSAT Modulo Theories. The main idea is to combine a lazy SMT solver with a purely-propositional (weighted partial) MaxSAT solver, by making them exchange information iteratively: the former produces an increasing set of theory lemmas which are used by the latter to progressively refine an approximation of the final subset of the soft clauses, which is eventually returned as output.                 The approach has several practical features. First, it is independent from the theories addressed. Second, it is simple to implement and to update, since both SMT and MaxSAT solvers can be used as blackboxes. Third, it can be interfaced with external MaxSAT and SMT solvers in a plug-and-play manner, so that to benefit for free of tools which are or will be made available.                 We have implemented our approach on top of the\u00a0\u2026", "num_citations": "33\n", "authors": ["1791"]}
{"title": "Interpolant generation for UTVPI\n", "abstract": " The problem of computing Craig interpolants in SMT has recently received a lot of interest, mainly for its applications in formal verification. Efficient algorithms for interpolant generation have been presented for some theories of interest \u2013including that of equality and uninterpreted functions (), linear arithmetic over the rationals (), and some fragments of linear arithmetic over the integers ()\u2013 and they are successfully used within model checking tools.               In this paper we address the problem of computing interpolants in the theory of Unit-Two-Variable-Per-Inequality (). This theory is a very useful fragment of , since it is expressive enough to encode many hardware and software verification queries while still admitting a polynomial time decision procedure. We present an efficient graph-based algorithm for interpolant generation in , which exploits the power of modern\u00a0\u2026", "num_citations": "29\n", "authors": ["1791"]}
{"title": "GSTE is partitioned model checking\n", "abstract": " Verifying whether an \u03c9-regular property is satisfied by a finite-state system is a core problem in model checking. Standard techniques build an automaton with the complementary language, compute its product with the system, and then check for emptiness. Generalized symbolic trajectory evaluation (GSTE) has been recently proposed as an alternative approach, extending the computationally efficient symbolic trajectory evaluation (STE) to general \u03c9-regular properties. In this paper, we show that the GSTE algorithms are essentially a partitioned version of standard symbolic model-checking (SMC) algorithms, where the partitioning is driven by the property under verification. We export this technique of property-driven partitioning to SMC and show that it typically does speed up SMC algorithms.", "num_citations": "28\n", "authors": ["1791"]}
{"title": "Efficient interpolant generation in satisfiability modulo linear integer arithmetic\n", "abstract": " The problem of computing Craig interpolants in SAT and SMT has recently received a lot of interest, mainly for its applications in formal verification. Efficient algorithms for interpolant generation have been presented for some theories of interest ---including that of equality and uninterpreted functions, linear arithmetic over the rationals, and their combination--- and they are successfully used within model checking tools. For the theory of linear arithmetic over the integers (LA(Z)), however, the problem of finding an interpolant is more challenging, and the task of developing efficient interpolant generators for the full theory LA(Z) is still the objective of ongoing research. In this paper we try to close this gap. We build on previous work and present a novel interpolation algorithm for SMT(LA(Z)), which exploits the full power of current state-of-the-art SMT(LA(Z)) solvers. We demonstrate the potential of our approach with an extensive experimental evaluation of our implementation of the proposed algorithm in the MathSAT SMT solver.", "num_citations": "26\n", "authors": ["1791"]}
{"title": "Formal specification and development of a safety-critical train management system\n", "abstract": " In this paper we describe the on-going specification and development of Ansald\u2019s Radio Block Center (RBC), a component of the next-generation European Rail Traffic Management System (ERTMS). The RBC will be responsible of managing the movement of trains equipped with radio communication. Its development process is critical: the rBC is a large-scale and complex system, it must provide several novel services at different levels of functionality, it must guarantee interoperability according to European standards, and, last but not least, a high level of safety. We have addressed these issues by devising a development based on formal specifications. ERTMS scenarios have been formalized in order to provide a better understanding of the interoperability requirements. The architecture of the RBC has been formally specified such that the system can be incrementally built as an overlay system\u00a0\u2026", "num_citations": "26\n", "authors": ["1791"]}
{"title": "Efficient weighted model integration via smt-based predicate abstraction\n", "abstract": " Weighted model integration (WMI) is a recent formalism generalizing weighted model counting (WMC) to run probabilistic inference over hybrid domains, characterized by both discrete and continuous variables and relationships between them. Albeit powerful, the original formulation of WMI suffers from some theoretical limitations, and it is computationally very demanding as it requires to explicitly enumerate all possible models to be integrated over. In this paper we present a novel general notion of WMI, which fixes the theoretical limitations and allows for exploiting the power of SMT-based predicate abstraction techniques. A novel algorithm combines a strong reduction in the number of models to be integrated over with their efficient enumeration. Experimental results on synthetic and real-world data show drastic computational improvements over the original WMI formulation as well as existing alternatives for hybrid inference.", "num_citations": "24\n", "authors": ["1791"]}
{"title": "To Ackermann-ize or Not to Ackermann-ize? On Efficiently Handling Uninterpreted Function Symbols in \n", "abstract": " Satisfiability Modulo Theories  is the problem of deciding the satisfiability of a formula with respect to a given background theory . When  is the combination of two simpler theories  and , a standard and general approach is to handle the integration of  and  by performing some form of search on the equalities between the shared variables.             A frequent and very relevant sub-case of  is when  is the theory of Equality and Uninterpreted Functions . For this case, an alternative approach is to eliminate first all uninterpreted function symbols by means of Ackermann\u2019s expansion, and then to solve the resulting  problem.             In this paper we build on the empirical observation that there is no absolute winner between these two alternative approaches, and that the performance gaps between them are often dramatic, in either direction.             We\u00a0\u2026", "num_citations": "24\n", "authors": ["1791"]}
{"title": "Integrating boolean and mathematical solving: Foundations, basic algorithms, and requirements\n", "abstract": " In the last years we have witnessed an impressive advance in the efficiency of boolean solving techniques, which has brought large previously intractable problems at the reach of state-of-the-art solvers. Unfortunately, simple boolean expressions are not expressive enough for representing many real-world problems, which require handling also integer or real values and operators. On the other hand, mathematical solvers, like computer-algebra systems or constraint solvers, cannot handle efficiently problems involving heavy boolean search, or do not handle them at all. In this paper we present the foundations and the basic algorithms for a new class of procedures for solving boolean combinations of mathematical propositions, which combine boolean and mathematical solvers, and we highlight the main requirements that boolean and mathematical solvers must fulfill in order to achieve the maximum\u00a0\u2026", "num_citations": "20\n", "authors": ["1791"]}
{"title": "Integrating SAT solvers with math reasoners: Foundations and basic algorithms\n", "abstract": " This report has been submitted forpublication outside of ITC and will probably be copyrighted if accepted for publication. It has been issued as a Technical Report forearly dissemination of its contents. In view of the transfert of copy right tothe outside publisher, its distribution outside of ITC priorto publication should be limited to peer communications and specificrequests. After outside publication, material will be available only inthe form authorized by the copyright owner.", "num_citations": "19\n", "authors": ["1791"]}
{"title": "Advanced SMT techniques for weighted model integration\n", "abstract": " Weighted model integration (WMI) is a recent formalism generalizing weighted model counting (WMC) to run probabilistic inference over hybrid domains, characterized by both discrete and continuous variables and relationships between them. WMI is computationally very demanding as it requires to explicitly enumerate all possible truth assignments to be integrated over. Component caching strategies which proved extremely effective for WMC are difficult to apply in this formalism because of the tight coupling induced by the arithmetic constraints. In this paper we present a novel formulation of WMI, which allows to exploit the power of SMT-based predicate abstraction techniques in designing efficient inference procedures. A novel algorithm combines a strong reduction in the number of models to be integrated over with their efficient enumeration. Experimental results on synthetic and real-world data show drastic\u00a0\u2026", "num_citations": "18\n", "authors": ["1791"]}
{"title": "Solving sat and maxsat with a quantum annealer: Foundations and a preliminary report\n", "abstract": " Quantum annealers (QA) are specialized quantum computers that minimize objective functions over discrete variables by physically exploiting quantum effects. Current QA platforms allow for the optimization of quadratic objectives defined over binary variables, that is, they solve quadratic unconstrained binary optimization (QUBO) problems. In the last decade, QA systems as implemented by D-Wave have scaled with Moore-like growth. Current architectures provide 2048 sparsely-connected qubits, and continued exponential growth is anticipated.                 We explore the feasibility of such architectures for solving SAT and MaxSAT problems as QA systems scale. We develop techniques for effectively encoding SAT and MaxSAT into QUBO problems compatible with sparse QA architectures. We provide the theoretical foundations for this mapping, and present encoding techniques that combine offline\u00a0\u2026", "num_citations": "18\n", "authors": ["1791"]}
{"title": "Automated Reasoning in  via SMT\n", "abstract": " Reasoning techniques for qualified number restrictions (QNRs) in Description Logics (DLs) have been investigated in the past but they mostly do not make use of the arithmetic knowledge implied by QNRs. In this paper we propose and investigate a novel approach for concept satisfiability in acyclic  ontologies. It is based on the idea of encoding an  ontology into a formula in Satisfiability Modulo the Theory of Costs (SMT), which is a specific and computationally much cheaper subcase of Linear Arithmetic under the Integers, and to exploit the power of modern SMT solvers to compute every concept-satisfiability query on a given ontology. We implemented and tested our approach, which includes a very effective individuals-partitioning technique, on a wide set of synthesized benchmark formulas, comparing the approach with the main state-of-the-art DL reasoners available. Our empirical\u00a0\u2026", "num_citations": "18\n", "authors": ["1791"]}
{"title": "Axiom pinpointing in large EL+ ontologies via SAT and SMT techniques\n", "abstract": " The quest for tractable logic-based languages arising from the field of bio-medical ontologies has raised a lot of attention on lightweight (ie less expressive but tractable) description logics, like EL and its family. To this extent, automated reasoning techniques in these logics have been developed for computing not only concept subsumptions, but also to pinpoint the (minimal) sets of axioms causing each subsumption. This task, called axiom pinpointing, allows the user for debugging possibly-huge ontologies, by identifying the minimal subsets of axioms in the ontology which cause undesired inferences. In this work we present a novel approach for axiom pinpointing in the logic EL+ and its sub-logics. In a nutshell, the basic idea is to first encode the full classification of the input ontology T into a polynomial-size Horn propositional formula \u03c6all T; then, for each subsumption inference ai under analysis, a sequence of sets of literals of \u03c6all T\u2014corresponding to the complete sequence of minimal sets of axioms in the original ontology T from which ai can be inferred\u2014is enumerated, by exploiting an ad-hoc combination of modern SAT and SMT techniques.", "num_citations": "15\n", "authors": ["1791"]}
{"title": "Solving SAT (and MaxSAT) with a quantum annealer: Foundations, encodings, and preliminary results\n", "abstract": " Quantum annealers (QAs) are specialized quantum computers that minimize objective functions over discrete variables by physically exploiting quantum effects. Current QA platforms allow for the optimization of quadratic objectives defined over binary variables (qubits), also known as Ising problems. In the last decade, QA systems as implemented by D-Wave have scaled with Moore-like growth. Current architectures provide 2048 sparsely-connected qubits, and continued exponential growth is anticipated, together with increased connectivity.We explore the feasibility of such architectures for solving SAT and MaxSAT problems as QA systems scale. We develop techniques for effectively encoding SAT \u2013and, with some limitations, MaxSAT\u2013 into Ising problems compatible with sparse QA architectures. We provide the theoretical foundations for this mapping, and present encoding techniques that combine offline\u00a0\u2026", "num_citations": "14\n", "authors": ["1791"]}
{"title": "Encoding the Satisfiability of Modal and Description Logics into SAT: The Case Study of K(m)/\n", "abstract": " In the last two decades, modal and description logics have been applied to numerous areas of computer science, including artificial intelligence, formal verification, database theory, and distributed computing. For this reason, the problem of automated reasoning in modal and description logics has been throughly investigated.               In particular, many approaches have been proposed for efficiently handling the satisfiability of the core normal modal logic K                                            m                 , and of its notational variant, the description logic . Although simple in structure, K                                            m                 / is computationally very hard to reason on, its satisfiability being PSPACE-complete.               In this paper we explore the idea of encoding K                                            m                 /-satisfiability into SAT, so that to be handled by state-of-the-art SAT tools. We propose an efficient encoding, and we\u00a0\u2026", "num_citations": "14\n", "authors": ["1791"]}
{"title": "On optimization modulo theories, MaxSMT and sorting networks\n", "abstract": " Abstract Optimization Modulo Theories (OMT) is an extension of SMT which allows for finding models that optimize given objectives.(Partial weighted) MaxSMT\u2013or equivalently OMT with Pseudo-Boolean objective functions, OMT+ PB\u2013is a very-relevant strict subcase of OMT. We classify existing approaches for MaxSMT or OMT+ PB in two groups: MaxSAT-based approaches exploit the efficiency of state-of-the-art MaxSAT solvers, but they are specific-purpose and not always applicable; OMT-based approaches are general-purpose, but they suffer from intrinsic inefficiencies on MaxSMT/OMT+ PB problems. We identify a major source of such inefficiencies, and we address it by enhancing OMT by means of bidirectional sorting networks. We implemented this idea on top of the OptiMathSAT OMT solver. We run an extensive empirical evaluation on a variety of problems, comparing MaxSAT-based and OMT-based\u00a0\u2026", "num_citations": "13\n", "authors": ["1791"]}
{"title": "SAT-based decision procedures for normal modal logics: a theoretical framework\n", "abstract": " Tableau systems are very popular in AI for their simplicity and versatility. In recent papers we showed that tableau-based procedures are intrinsically inefficient, and proposed an alternative approach of building decision procedures on top of SAT decision procedure. We called this approach \u201cSAT-based\u201d. In extensive empirical tests on the case study of modal K, a SAT-based procedure drastically outperformed state-of-the-art tableau-based systems. In this paper we provide the theoretical foundations for developing SAT-based decision procedures for many different modal logics.", "num_citations": "13\n", "authors": ["1791"]}
{"title": "Stochastic local search for SMT: combining theory solvers with walksat\n", "abstract": " A dominant approach to Satisfiability Modulo Theories (SMT) relies on the integration of a Conflict-Driven-Clause-Learning (CDCL) SAT solver and of a decision procedure able to handle sets of atomic constraints in the underlying theory  ( ). In pure SAT, however, Stochastic Local-Search (SLS) procedures sometimes are competitive with CDCL SAT solvers on satisfiable instances. Thus, it is a natural research question to wonder whether SLS can be exploited successfully also inside SMT tools.               In this paper we investigate this issue. We first introduce a general procedure for integrating a SLS solver of the WalkSAT family with a . Then we present a group of techniques aimed at improving the synergy between these two components. Finally we implement all these techniques into a novel SLS-based SMT solver for the theory of linear arithmetic over the rationals, combining\u00a0\u2026", "num_citations": "12\n", "authors": ["1791"]}
{"title": "A new system and methodology for generating random modal formulae\n", "abstract": " Previous methods for generating random modal formulae (for the multi-modal logic K                    (m)                 ) result either in flawed test sets or formulae that are too hard for current modal decision procedures and, also, unnatural. We present here a new system and generation methodology which results in unflawed test sets and more-natural formulae that are better suited for current decision procedures.", "num_citations": "11\n", "authors": ["1791"]}
{"title": "Formal specification and validation of a vital communication protocol\n", "abstract": " Formal methods have a great potential of application as powerful specification and early debugging methods in the development of industrial systems. In certain application fields, formal methods are even becoming part of standards. However, the application of formal methods in the development of industrial products is by no means trivial. Indeed, formal methods can be costly, slow down the process of development, and require changes on the development cycle, and training. This paper describes a project developed by Ansaldo Segnalamento Ferroviario with the collaboration of IRST. Formal methods have been successfully applied to the development of an industrial communication protocol for distributed, safety critical systems. The project used a formal language to specify the protocol, and model checking techniques to validate the model.", "num_citations": "10\n", "authors": ["1791"]}
{"title": "A general purpose reasoner for abstraction\n", "abstract": " The goal of the work described in this paper is the development of a system, called ABSFOL, which allows the user to state declaratively abstractions and to use them according to the desired control strategy. ABSFOL has been successfully tested on many examples. So far we have failed to find an interesting abstraction whose implementation requires a major programming effort.", "num_citations": "9\n", "authors": ["1791"]}
{"title": "The pywmi framework and toolbox for probabilistic inference using weighted model integration\n", "abstract": " Weighted Model Integration (WMI) is a popular technique for probabilistic inference that extends Weighted Model Counting (WMC)--the standard inference technique for inference in discrete domains--to domains with both discrete and continuous variables. However, existing WMI solvers each have different interfaces and use different formats for representing WMI problems. Therefore, we introduce pywmi (http://pywmi. org), an open source framework and toolbox for probabilistic inference using WMI, to address these shortcomings. Crucially, pywmi fixes a common internal format for WMI problems and introduces a common interface for WMI solvers. To assist users in modeling WMI problems, pywmi introduces modeling languages based on SMT-LIB. v2 or MiniZinc and parsers for both. To assist users in comparing WMI solvers, pywmi includes implementations of several state-of-the-art solvers, a fast approximate WMI solver, and a command-line interface to solve WMI problems. Finally, to assist developers in implementing new solvers, pywmi provides Python implementations of commonly used subroutines.", "num_citations": "8\n", "authors": ["1791"]}
{"title": "From KSAT to Delayed Theory Combination: Exploiting DPLL Outside the SAT Domain\n", "abstract": " In the last two decades we have witnessed an impressive advance in the efficiency of propositional satisfiability techniques (SAT), which has brought large and previously-intractable problems at the reach of state-of-the-art SAT solvers. Most of this success is motivated by the impressive level of efficiency reached by current implementations of the DPLL procedure. Plain propositional logic, however, is not the only application domain for DPLL. In fact, DPLL has also been successfully used as a boolean-reasoning kernel for automated reasoning tools in much more expressive logics.               In this talk I overview a 12-year experience on integrating DPLL with logic-specific decision procedures in various domains. In particular, I present and discuss three main achievements which have been obtained in this context: the DPLL-based procedures for modal and description logics, the lazy approach to Satisfiability\u00a0\u2026", "num_citations": "6\n", "authors": ["1791"]}
{"title": "Property-driven partitioning for abstraction refinement\n", "abstract": " Partitioning and abstraction have been studied extensively both in hardware and in software verification. The abstraction is typically partitioned according to the system design in the case of hardware or the control graph in the case of software. In this work we build on previous work on Property-Driven Partitioning (PDP), a hybrid Symbolic Model-Checking (SMC) technique for \u03c9-regular properties in which the state space is partitioned according to the states of the property automaton. We investigate a new paradigm for abstraction refinement in SMC, which combines abstraction and PDP: each PDP partition may contain a different abstraction, so that it can be refined independently from the others; in case of a spurious counterexample \u03c0, the system is refined only in those partitions that are necessary to rule out \u03c0. We performed a preliminary experimental evaluation comparing standard Counterexample\u00a0\u2026", "num_citations": "6\n", "authors": ["1791"]}
{"title": "Building efficient decision procedures on top of SAT solvers\n", "abstract": " Many verification problems can be naturally represented as satisfiability problems in some decidable fragments of first order logic. Efficient decision procedures for such problems can be obtained by combining technology for propositional satisfiability and solvers able to deal with the theory component.             We provide a unifying and abstract, theory-independent perspective on the various integration schemas and techniques. Within this framework, we survey, analyze and classify the most effective integration techniques and optimizations for the development of decision procedures. We also discuss the relative benefits and drawbacks of the various techniques, and we analyze the features for SAT solvers and theory-specific solvers which make them more suitable for an integration.", "num_citations": "6\n", "authors": ["1791"]}
{"title": "The MathSat solver\u2013a progress report\n", "abstract": " Many problems of practical relevance are conveniently expressed as boolean combinations of propositional variables and mathematical constraints. The development of decision procedures able to check the satisfiability of such formulas is therefore being devoted an increasing interest.The MATHSAT family of deciders is based on the extension of a DPLL propositional satisfiability procedure, used as an assignment enumerator. MATHSAT pioneers a lazy and layered approach, where propositional reasoning is tightly integrated with solvers of increasing expressive power (eg to reason about equality and linear arithmetic) in such a way that \u201cmore expensive\u201d layers are called less frequently. In this paper, we show the advances in the development of MATHSAT. We discuss the implications related to the use of MINISAT, a new-generation propositional SAT solver; the role of an incremental mathematical reasoner; the role of static learning; and the extension to integer variables. We show that the new version of MATHSAT is significantly more efficient than the previous one.", "num_citations": "6\n", "authors": ["1791"]}
{"title": "Optimization modulo the theory of floating-point numbers\n", "abstract": " Optimization Modulo Theories (OMT) is an important extension of SMT which allows for finding models that optimize given objective functions, typically consisting in linear-arithmetic or pseudo-Boolean terms. However, many SMT and OMT applications, in particular from SW and HW verification, require handling bit-precise representations of numbers, which in SMT are handled by means of the theory of Bit-Vectors () for the integers and that of Floating-Point Numbers () for the reals respectively. Whereas an approach for OMT with (unsigned)  has been proposed by Nadel & Ryvchin, unfortunately we are not aware of any existing approach for OMT with .               In this paper we fill this gap. We present a novel OMT approach, based on the novel concept of attractor and dynamic attractor, which extends the work of Nadel & Ryvchin to signed  and, most importantly, to . We have implemented some\u00a0\u2026", "num_citations": "5\n", "authors": ["1791"]}
{"title": "Theory and Applications of Satisfiability Testing--SAT 2012: 15th International Conference, Trento, Italy, June 17-20, 2012, Proceedings\n", "abstract": " This book constitutes the refereed proceedings of the 15th International Conference on Theory and Applications of Satisfiability Testing, SAT 2012, held in Trento, Italy, in June 2012. The 29 revised full papers, 7 tool papers, and 16 poster papers presented together with 2 invited talks were carefully reviewed and selected from 112 submissions (88 full, 10 tool and 14 poster papers). The papers are organized in topical sections on stochastic local search, theory, quantified Boolean formulae, applications, parallel and portfolio approaches, CDCL SAT solving, MAX-SAT, cores interpolants, complexity analysis, and circuits and encodings.", "num_citations": "5\n", "authors": ["1791"]}
{"title": "Symbolic systems, explicit properties: on hybrid approaches for LTL symbolic model checking\n", "abstract": " In this work we study hybrid approaches to LTL symbolic model checking; that is, approaches that use explicit representations of the property automaton, whose state space is often quite manageable, and symbolic representations of the system, whose state space is typically exceedingly large. We compare the effects of using, respectively, (i) a purely symbolic representation of the property automaton, (ii) a symbolic representation, using logarithmic encoding, of explicitly compiled property automaton, and (iii) a partitioning of the symbolic state space according to an explicitly compiled property automaton. We apply this comparison to three model-checking algorithms: the doubly-nested fixpoint algorithm of Emerson and Lei, the reduction of emptiness to reachability of Biere et\u00a0al., and the singly-nested fixpoint algorithm of Bloem et\u00a0al. for weak automata. The emerging picture from our study is quite clear\u00a0\u2026", "num_citations": "4\n", "authors": ["1791"]}
{"title": "Integrating SAT solvers with domain-specific reasoners\n", "abstract": " Integrating SAT solvers with domain-specific reasoners (poster session) | Symbolic computation and automated reasoning ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleBooksSymbolic computation and automated reasoningIntegrating SAT solvers with domain-specific reasoners (poster session) chapter Integrating SAT solvers with domain-specific reasoners (poster session) Share on Authors: Fausto Giunchiglia View Profile , Roberto Sebastiani View Profile , Paolo Traverso View Profile Authors Info & Affiliations Publication: Symbolic computation and automated reasoningApril 2001 Pages 249\u2013250 0citation 0 Downloads Metrics \u2026", "num_citations": "4\n", "authors": ["1791"]}
{"title": "From MiniZinc to Optimization Modulo Theories, and Back\n", "abstract": " Abstract Optimization Modulo Theories (OMT) is an extension of SMT that allows for finding models that optimize objective functions. In this paper we aim at bridging the gap between Constraint Programming (CP) and OMT, in both directions. First, we have extended the OMT solver OptiMathSAT with a FlatZinc interface\u2013which can also be used as FlatZinc-to-OMT encoder for other OMT solvers. This allows OMT tools to be used in combination with mzn2fzn on the large amount of CP problems coming from the MiniZinc community. Second, we have introduced a tool for translating SMT and OMT problems on the linear arithmetic and bit-vector theories into MiniZinc. This allows MiniZinc solvers to be used on a large amount of SMT/OMT problems. We have discussed the main issues we had to cope with in either directions. We have performed an extensive empirical evaluation comparing three state-of-the-art OMT\u00a0\u2026", "num_citations": "3\n", "authors": ["1791"]}
{"title": "On the Benefits of Enhancing Optimization Modulo Theories with Sorting Networks for MaxSMT.\n", "abstract": " Optimization Modulo Theories (OMT) is an extension of SMT, which combines SMT with optimization, finding models that make given objectives optimal. OMT has been extended to be incremental and to handle multiple objective functions either independently or with their linear, lexicographic, Pareto, min-max/max-min combinations. OMT applications can be found not only in the domains of Formal Verification, Automated Reasoning and Planning with Resources, but also Machine Learning and Requirement Engineering.(Partial weighted) MAXSMT\u2013or, alternatively, OMT with Pseudo-Boolean objective functions\u2013is a very-relevant subcase of OMT. Unfortunately, using general OMT algorithm for MAXSMT suffers from some intrinsic inefficiencies in some cases. In this paper we identify the sources of such inefficiencies and address them by enhancing general OMT by means of sorting networks. We implemented this idea on top of the OPTIMATHSAT OMT solver and evaluated them empirically on problems coming from Machine Learning and Requirement Engineering. The empirical results support the effectiveness of this idea.", "num_citations": "3\n", "authors": ["1791"]}
{"title": "Hybrid SRL with optimization modulo theories\n", "abstract": " Generally speaking, the goal of constructive learning could be seen as, given an example set of structured objects, to generate novel objects with similar properties. From a statistical-relational learning (SRL) viewpoint, the task can be interpreted as a constraint satisfaction problem, i.e. the generated objects must obey a set of soft constraints, whose weights are estimated from the data. Traditional SRL approaches rely on (finite) First-Order Logic (FOL) as a description language, and on MAX-SAT solvers to perform inference. Alas, FOL is unsuited for con- structive problems where the objects contain a mixture of Boolean and numerical variables. It is in fact difficult to implement, e.g. linear arithmetic constraints within the language of FOL. In this paper we propose a novel class of hybrid SRL methods that rely on Satisfiability Modulo Theories, an alternative class of for- mal languages that allow to describe, and reason over, mixed Boolean-numerical objects and constraints. The resulting methods, which we call Learning Mod- ulo Theories, are formulated within the structured output SVM framework, and employ a weighted SMT solver as an optimization oracle to perform efficient in- ference and discriminative max margin weight learning. We also present a few examples of constructive learning applications enabled by our method.", "num_citations": "3\n", "authors": ["1791"]}
{"title": "Automated Reasoning on TBoxes with Qualified Number Restrictions via SMT\n", "abstract": " The problem of reasoning with qualified number restrictions in Description Logics (DLs) has been investigated since the very first research steps in automated reasoning for DLs. Moreover, developing techniques for optimized reasoning with qualified number restrictions and has gained further importance since qualified number restrictions have been added to the forthcoming standard OWL 2 for Semantic Web applications. On the one hand, however, actual DL reasoning techniques, often lack of efficiency in handling those features, especially when the number of restrictions or the values involved are high. On the other hand the manifold problem of reasoning including numerical constraints is a well-established and thoroughly investigate problem in the SMT community, in which a lot of effort is continuously spent in order to enhance the efficiency of reasoning techniques for such kind of problems. In this paper we propose and investigate a novel approach for concept satisfiability in acyclic ALCQ ontologies. The idea is to encode an ALCQ ontology into a formula in Satisfiability Modulo the Theory of Costs (SMT(C)), which is a specific and computationally much cheaper subcase of Linear Arithmetic under the Integers (LA(Z)), and to exploit the power of modern SMT solvers to compute every concept-satisfiability query on a given ontology. We have implemented and tested our approach (called ALCQ2SMT_C) and some optimizations on a wide set of synthesized benchmark formulas, comparing the approach with the main state-of-the-art tools available. Our empirical evaluation confirms the potential of the approach.", "num_citations": "3\n", "authors": ["1791"]}
{"title": "Model checking syllabi and student careers\n", "abstract": " Model checking has been conceived as a powerful tool for hardware, software and protocol verification, which has its main application fields in the development of hi-tech and safety-critical systems. We present here a completely novel application in the field of university administration processes, in which model checking is applied to the verification of the coherence of syllabi and to the automated synthesis/simulation of correct student careers under given requirements.", "num_citations": "3\n", "authors": ["1791"]}
{"title": "From Tableau-based to SAT-based procedures-preliminary report\n", "abstract": " Tableau systems are very popular in AI for their simplicity and versatility. In recent papers we showed that tableau-based procedures are intrinsically inefficient, and proposed an alternative approach of building decision procedures on top of SAT decision procedure. We called this approach \u2018SAT based\u2019. In extensive empirical tests on the case study of modal K, a SAT-based procedure drastically outperformed a state-of-the-art tableau-based system. In this paper we provide the theoretical foundations for developing SAT-based decision procedures for many different modal logics", "num_citations": "3\n", "authors": ["1791"]}
{"title": "Proving theorems by using abstraction interactively\n", "abstract": " ion Interactively Roberto Sebastiani 1, Adolfo Villafiorita 1, Fausto Giunchiglia 2; 3 1 Mechanized Reasoning Group, DIST, University of Genoa, Italy 2 Mechanized Reasoning Group, IRST, 38050 Povo Trento, Italy. 3 University of Trento, Via Inama 5, 38100 Trento, Italy. rseba@ dist. unige. it adolfo@ dist. unige. it fausto@ irst. it Abstract In this paper we show how an interactive use of abstraction in theorem proving can improve the comprehension and reduce the complexity of many significant problems. For such a task we present a fully mechanized example of the very well-known map colouring problem. 1 Introduction By\" abstraction\" we informally mean the process by which, starting from a given representation of a problem (called\" ground space\"), we construct a new and simpler representation (called\" abstract space\"), we find a solution for it and hence we use such a simplified solution as an outline for the solution of the original problem. The abstract space is obtained...", "num_citations": "3\n", "authors": ["1791"]}
{"title": "Proof planning by abstraction\n", "abstract": " Devising powerful heuristics or shifting the control to humans have probably been the two most common solutions to keep the search space in theorem proving manageable. In this paper we take advantage of both, by using abstraction [GW92b] as a tool to plan proofs by induction and by proving its eectiveness in ABSFOL (an interactive theorem prover built on top of GETFOL [GT91]). 1 Introduction The complexity of problems in logic is a limit to the results that can be achieved by theorem provers; hence the need of developing powerful heuristics, or of shifting the control to humans. We have chosen both solutions, by developing and using an interactive theorem prover which implements abstraction. ABSFOL [GW92a, GSVW96, Vil93] is a theorem prover built on top of GETFOL [GT91] 1; ABSFOL provides tools for using abstractions and inherits from GETFOL all the tools for building proofs. Abstraction is a powerful heuristic which captures the idea of simplication of a problem: when reasoni...", "num_citations": "3\n", "authors": ["1791"]}
{"title": "Are You Satisfied by This Partial Assignment?\n", "abstract": " Many procedures for SAT and SAT-related problems -- in particular for those requiring the complete enumeration of satisfying truth assignments -- rely their efficiency on the detection of partial assignments satisfying an input formula. In this paper we analyze the notion of partial-assignment satisfiability -- in particular when dealing with non-CNF and existentially-quantified formulas -- raising a flag about the ambiguities and subtleties of this concept, and investigating their practical consequences. This may drive the development of more effective assignment-enumeration algorithms.", "num_citations": "2\n", "authors": ["1791"]}
{"title": "Research and Advanced Technology for Digital Libraries: 14th European Conference, ECDL 2010, Glasgow, UK, September 6-10, 2010, Proceedings\n", "abstract": " In the 14 years since its? rst edition back in 1997, the European Conference on Research and Advanced Technology for Digital Libraries (ECDL) has become the reference meeting for an interdisciplinary community of researchers and practitioners whose professional activities revolve around the theme of d-th ital libraries. This volume contains the proceedings of ECDL 2010, the 14 conference in this series, which, following Pisa (1997), Heraklion (1998), Paris (1999), Lisbon (2000), Darmstadt (2001), Rome (2002), Trondheim (2003), Bath (2004), Vienna (2005), Alicante (2006), Budapest (2007), Aarhus (2008), and Corfu (2009), was held in Glasgow, UK, during September 6\u201310, 2010. th Asidefrombeingthe14 edition of ECDL, this was also the last, at least with this name since starting with 2011, ECDL will be renamed (so as to avoid acronym con? icts with the European Computer Driving Licence) to TPLD, standing for the Conference on Theory and Practice of Digital Libraries. We hope you all will join us for TPDL 2011 in Berlin! For ECDL 2010 separate calls for papers, posters and demos were issued,-sulting in the submission to the conference of 102 full papers, 40 posters and 13 demos. This year, for the full papers, ECDL experimented with a novel, two-tier reviewing model, with the aim of further improving the quality of the resu-ing program. A? rst-tier Program Committee of 87 members was formed, and a further Senior Program Committee composed of 15 senior members of the DL community was set up.", "num_citations": "2\n", "authors": ["1791"]}
{"title": "Stochastic local search for smt: a preliminary report\n", "abstract": " A popular approach to SMT is based on the integration of a DPLL SAT solver and of a decision procedure able to handle sets of atomic constraints in the underlying theory T (T-solver). In pure SAT, however, stochastic local-search (SLS) procedures sometimes outperform DPLL on satisfiable instances, in particular when dealing with unstructured problems. Therefore, it is a natural research question to wonder whether SLS can be exploited successfully also inside SMT tools. The purpose of this paper is to start investigating this issue. First, we present an algorithm integrating a Boolean SLS solver (based on the WalkSAT paradigm) with a T-solver, resulting in a basic SLS-based SMT solver. Second, we introduce a group of techniques aimed at improving the synergy between the Boolean and the T-specific component, and discuss the differences between the integration of T-solvers with a DPLL-based and a SLS-based SAT solver. Finally, we perform a preliminary experimental evaluation of our implementation (based on the integration of the UBCSAT SLS platform with the LA(Q)-solver of MathSAT) by comparing it against MathSAT, a state-of-the-art DPLL-based SMT solver, on both structured industrial problems coming from the SMT-LIB and randomly-generated unstructured problems. From this preliminary analysis we have that the performance of the SLS-based tool (i) is far from that of the DPLL-based one on SMT-LIB problems and (ii) is comparable on random problems.", "num_citations": "2\n", "authors": ["1791"]}
{"title": "On efficiently integrating boolean and theory-specific solving procedures\n", "abstract": " Efficient decision procedures have been conceived in different communities for a very heterogeneous collection of expressive decidable theories. However, despite in the last years we have witnessed an impressive advance in the efficiency of SAT procedures, techniques for efficiently integrating boolean reasoning and theory-specific decision procedures have been deeply investigated only recently, producing impressive performance improvements when applied. The goal of this paper is to analyze, classify and represent within a uniform framework the most effective techniques which have been proposed in various communities in order to maximize the efficiency of boolean reasoning within decision procedures.", "num_citations": "2\n", "authors": ["1791"]}
{"title": "MathSAT5 (nonlinear) at the SMT competition 2019\n", "abstract": " MathSAT5 [1] is a lazy SMT solver [2] based on the DPLL (T) architecture [3], and it uses MiniSAT [4] as the underlying SAT solver. It supports most of the SMTLIB [5] theories and provides many SMT functionalities (eg unsatisfiable cores [6], interpolation, ALLSMT). It does not offer support for quantifiers. In the last couple of years, the support for nonlinear arithmetic and transcendental functions has been added to MathSAT, based on incremental linearization. The main idea of incremental linearization is that of trading the use of expensive, exact solvers for nonlinear arithmetic for much less expensive solvers for linear arithmetic and uninterpreted functions. The approach is based on an abstractionrefinement loop that uses SMT (UFLA) as abstract domain. The uninterpreted functions are used to model nonlinear multiplications, which are incrementally axiomatized, by means of linear constraints, with a lemma-on-demand [7] approach.", "num_citations": "1\n", "authors": ["1791"]}
{"title": "Planning with Strategic Goals\n", "abstract": " Strategic goals and strategic planning have received much attention in Management Sciences literature since the 60s. In this work, we are interested in putting strategic planning on a formal, algorithmic footing by offering a formal reasoning technique for automatic generation and selection of strategic plans. Towards this end, in previous work [1] we have introduced the concept of strategic goals and dimensional refinement operators that define strategic goals in terms of domain dimensions from the data warehouses literature. Examples of dimensions for a strategic goal such as \"Increase sales in Europe over 2 years\" might include time, geography and product type. Here, we propose a formalization of strategic goals and their dimensional refinements that allows one to express a strategic goal model as a planning space that can be achieved across different dimensions. Subsequently, we use automated reasoning\u00a0\u2026", "num_citations": "1\n", "authors": ["1791"]}
{"title": "OpenMath and SMT-LIB\n", "abstract": " OpenMath and SMT-LIB are languages with very different origins, but both \"represent mathematics\". We describe SMT-LIB for the OpenMath community and consider adaptations for both languages to support the growing SC-Square initiative.", "num_citations": "1\n", "authors": ["1791"]}
{"title": "Automated Reasoning\n", "abstract": " This volume contains the papers presented at the 9th International Joint Conference on Automated Reasoning, IJCAR 2018, held during July 14\u201317, 2018 in Oxford, UK, as part of the Federated Logic Conference, FLoC 2018. There were 125 abstracts submitted to IJCAR, resulting in 108 complete submissions. Each submission was assigned to three Program Committee members and received at least three reviews. The committee accepted 46 papers in total, 38 full papers and eight system descriptions. In addition, the program included two invited talks by Erika Abraham and Martin Giese, and accommodated a number of FLoC central events.IJCAR is the premier international joint conference on all aspects of automated reasoning, including foundations, implementations, and applications, comprising several leading conferences and workshops. It was first held in Sienna, Italy, in 2001, uniting CADE, the\u00a0\u2026", "num_citations": "1\n", "authors": ["1791"]}
{"title": "Colors Make Theories hard\n", "abstract": " The satisfiability problem for conjunctions of quantifier-free literals in first-order theories  of interest\u2013\u201c -solving\u201d for short\u2013has been deeply investigated for more than three decades from both theoretical and practical perspectives, and it is currently a core issue of state-of-the-art SMT solving. Given some theory  of interest, a key theoretical problem is to establish the computational (in)tractability of -solving, or to identify intractable fragments of  .                 In this paper we investigate this problem from a general perspective, and we present a simple and general criterion for establishing the NP-hardness of -solving, which is based on the novel concept of \u201ccolorer\u201d for a theory .                 As a proof of concept, we show the effectiveness and simplicity of this novel criterion by easily producing very simple proofs of the NP-hardness for many theories of interest for SMT, or of some of their fragments.", "num_citations": "1\n", "authors": ["1791"]}
{"title": "Automated Reasoning in Modal and Description Logics via SAT Encoding: the Case Study of K (m)/ALC-Satisfiability\n", "abstract": " In the last two decades, modal and description logics have been applied to numerous areas of computer science, including knowledge representation, formal verification, database theory, distributed computing and, more recently, semantic web and ontologies. For this reason, the problem of automated reasoning in modal and description logics has been thoroughly investigated. In particular, many approaches have been proposed for efficiently handling the satisfiability of the core normal modal logic K (m), and of its notational variant, the description logic ALC. Although simple in structure, K (m)/ALC is computationally very hard to reason on, its satisfiability being PSPACE-complete. In this paper we start exploring the idea of performing automated reasoning tasks in modal and description logics by encoding them into SAT, so that to be handled by state-of-the-art SAT tools; as with most previous approaches, we\u00a0\u2026", "num_citations": "1\n", "authors": ["1791"]}
{"title": "Debugging large EL+ ontologies via SAT and SMT techniques\n", "abstract": " The quest for tractable logic-based languages arising from the field of bio-medical ontologies has raised a lot of attention on lightweight (ie less expressive but tractable) description logics, like EL and its family. To this extent, automated reasoning techniques in these logics have been developed for computing not only concept subsumptions, but also to pinpoint the (minimal) sets of axioms causing each subsumption. This task, called axiom pinpointing, allows the user for debugging possibly-huge ontologies, by identifying the minimal subsets of axioms in the ontology which cause undesired inferences. In this work we present a novel approach for axiom pinpointing in the logic EL+ and its sub-logics. In a nutshell, the basic idea is to first encode the full classification of the input ontology T into a polynomial-size Horn propositional formula \u03c6all T; then, for each subsumption inference ai under analysis, a sequence of sets of literals of \u03c6all T\u2014corresponding to the complete sequence of minimal sets of axioms in the original ontology T from which ai can be inferred\u2014is enumerated, by exploiting an ad-hoc combination of modern SAT and SMT techniques.", "num_citations": "1\n", "authors": ["1791"]}
{"title": "System description: MathSAT 3.4\n", "abstract": " MATHSAT is built according to the standard \u201conline\u201d lazy integration schema used in many SMT tools (see, eg,[1, 8, 5]). In short: after some preprocessing to the input formula \u03c6, a DPLL-based SAT solver is used as an enumerator of (possibly partial) truth assignments for (the boolean abstraction of) \u03c6; the consistency in T of (the set of atomic constraints corresponding to) each assignment is checked by a solver T-SOLVER. This is done until either one T-consistent assignment is found, or all assignments have been checked. In order to optimize the synergy between the SAT solver and T-solver, MATHSAT implements techniques like (weakened) early pruning, T-propagation, T-backjumping, T-learning. clustering, pure-literal filtering and T-literal filtering (see [1, 4, 5]).", "num_citations": "1\n", "authors": ["1791"]}
{"title": "Integration of automated reasoning and computer algebra systems\n", "abstract": " Editorial: Integration of automated reasoning and computer algebra systems: Journal of Symbolic Computation: Vol 39, No 5 ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Journal of Symbolic Computation Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsJournal of Symbolic ComputationVol. , No. Editorial: Integration of automated reasoning and computer algebra systems article Editorial: Integration of automated reasoning and computer algebra systems Share on Authors: Olga Caprotti profile image Olga Caprotti University of Helsinki, Department of Mathematics and Statistics, PO Box 68 (Gustaf H\u00e4llstr\u00f6min katu 2b), FI-00014, University of \u2026", "num_citations": "1\n", "authors": ["1791"]}
{"title": "Una Nuova Classe di Procedure di Decisione per le Logiche Modali e Terminologiche. Teoria, Implementazione e Testing\n", "abstract": " 2 1. Introduzione e Moses, 1992; Donini et al., 1992] 2. Si tratta quindi di problemi di elevatissima complessit a computazionale, che mettono a dura prova l'e cienza degli algoritmi. Si noti, per confronto, che la soddisfacibilit a nella logica proposizionale e\\solo\" NP-complete Cook, 1971].In generale, rifacendoci alla terminologia corrente, parleremo di\\ragionamento automatico\" intendendo tutte le varie operazioni su espressioni logiche, quali deduzione, inferenza, refutazione, sussunzione, valutazione, veri ca di validit a/soddisfacibilit a, model checking, ecc. Il ragionamento automatico in logica proposizionale e del primo ordine e stato lungamente oggetto di studio, a causa delle applicazioni ai sistemi digitali ed alle basi di dati. Di conseguenza esistono un gran numero di sistemi di ragionamento automatico molto e cienti per tali logiche (ad esempio, Bryant, 1992; Crawford e Auton, 1996; McCune, 1990]). Per quanto riguarda lo studio di metodi di ragionamento automatico in altre logiche (ad esempio, logiche modali, terminologiche, dinamiche, temporali), la ricerca di procedure di ragionamento ecienti rappresenta invece un problema ancora aperto. Al riguardo, nella letteratura distinguiamo\\storicamente\" due fasi. In una prima fase, protratta no a tempi relativamente recenti, tale studio era relegato a lavori in logica pura, intelligenza arti ciale e rappresentazione della conoscenza. In questo senso, la ricerca si era dedicata prevalentemente allo studio di formalismi generali, trascurando lo studio dell'e cienza degli algoritmi che ne derivavano 3. L'ideazione di un gran numero di formalismi/algoritmi basati su tableau 4 Smullyan, 1968](\\tableau\u00a0\u2026", "num_citations": "1\n", "authors": ["1791"]}
{"title": "Experimental analysis of the computational cost of satisfiability checking in logics for commonsense reasoning\n", "abstract": " Many reasoning tasks in logics for commonsense reasoning have been shown to be computationally intractable in the worst case. However, However, realistic applications of KR require the ability to handle large knowledge bases, which require ecient and reliable algorithms. A rst step in the development of algorithms which are ecient in the averagecase is to single out those cases which appear in practice to require more computational resources. The goal of our investigation is to perform experimental studies on sophisticated KR formalisms, similar to those performed for classical logic. In particular, in this paper we analyze modal and non-monotonic logics.", "num_citations": "1\n", "authors": ["1791"]}
{"title": "The MathSAT 4 SMT Solver (Tool Paper)\n", "abstract": " We present MathSAT 4, a state-of-the-art SMT solver. Math-SAT 4 handles several useful theories:(combinations of) equality and uninterpreted functions, difference logic, linear arithmetic, and the theory of bit-vectors. It was explicitly designed for being used in formal verification, and thus provides functionalities which extend the applicability of SMT in this setting. In particular: model generation (for counterexample reconstruction), model enumeration (for predicate abstraction), an incremental interface (for BMC), and computation of unsatisfiable cores and Craig interpolants (for abstraction refinement).", "num_citations": "1\n", "authors": ["1791"]}