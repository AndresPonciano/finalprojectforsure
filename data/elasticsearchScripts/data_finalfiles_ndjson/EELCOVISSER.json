{"title": "The spoofax language workbench: rules for declarative specification of languages and IDEs\n", "abstract": " Spoofax is a language workbench for efficient, agile development of textual domain-specific languages with state-of-the-art IDE support. Spoofax integrates language processing techniques for parser generation, meta-programming, and IDE development into a single environment. It uses concise, declarative specifications for languages and IDE services. In this paper we describe the architecture of Spoofax and introduce idioms for high-level specifications of language semantics using rewrite rules, showing how analyses can be reused for transformations, code generation, and editor services such as error marking, reference resolving, and content completion. The implementation of these services is supported by language-parametric editor service classes that can be dynamically loaded by the Eclipse IDE, allowing new languages to be developed and used side-by-side in the same Eclipse environment.", "num_citations": "513\n", "authors": ["1605"]}
{"title": "Stratego: A language for program transformation based on rewriting strategies system description of stratego 0.5\n", "abstract": " Program transformation is used in many areas of software engineering. Examples include compilation, optimization, synthesis, refactoring, migration, normalization and improvement [15]. Rewrite rules are a natural formalism for expressing single program transformations. However, using a standard strategy for normalizing a program with a set of rewrite rules is not adequate for implementing program transformation systems. It may be necessary to apply a rule only in some phase of a transformation, to apply rules in some order, or to apply a rule only to part of a program. These restrictions may be necessary to avoid non-termination or to choose a specific path in a non-con uent rewrite system.               Stratego is a language for the specification of program transformation systems based on the paradigm of rewriting strategies. It supports the separation of strategies from transformation rules, thus allowing\u00a0\u2026", "num_citations": "468\n", "authors": ["1605"]}
{"title": "DSL Engineering-Designing, Implementing and Using Domain-Specific Languages.\n", "abstract": " DSL Engineering - Designing, implementing and using domain-specific languages \u2014 TU Delft Research Portal Skip to main navigation Skip to search Skip to main content TU Delft Research Portal Logo Help & FAQ Home Researchers Research Units Research output Activities Datasets Press / Media Prizes Projects Search by expertise, name or affiliation DSL Engineering - Designing, implementing and using domain-specific languages M. V\u00f6lter, S Benz, C Dietrich, B Engelmann, M Helander, LCL Kats, E Visser, GH Wachsmuth Software Engineering Research output: Book/Report \u203a Book \u203a Scientific Overview Original language English Place of Publication Stuttgart, Germany Publisher M Volter / DSLBook.org Number of pages 560 ISBN (Print) Niet aanwezig Publication status Published - 2013 Publication series Name Publisher M Volter / DSLBook.org Access to Document http://www.dslbook.org/ Cite this APA \u2026", "num_citations": "465\n", "authors": ["1605"]}
{"title": "Stratego/XT 0.17. A language and toolset for program transformation\n", "abstract": " Stratego/XT is a language and toolset for program transformation. The Stratego language provides rewrite rules for expressing basic transformations, programmable rewriting strategies for controlling the application of rules, concrete syntax for expressing the patterns of rules in the syntax of the object language, and dynamic rewrite rules for expressing context-sensitive transformations, thus supporting the development of transformation components at a high level of abstraction. The XT toolset offers a collection of flexible, reusable transformation components, and tools for generating such components from declarative specifications. Complete program transformation systems are composed from these components.This paper gives an overview of Stratego/XT 0.17, including a description of the Stratego language and XT transformation tools; a discussion of the implementation techniques and software engineering\u00a0\u2026", "num_citations": "444\n", "authors": ["1605"]}
{"title": "Program transformation with Stratego/XT\n", "abstract": " Stratego/XT is a framework for the development of transformation systems aiming to support a wide range of program transformations. The framework consists of the transformation language Stratego and the XT collection of transformation tools. Stratego is based on the paradigm of rewriting under the control of programmable rewriting strategies. The XT tools provide facilities for the infrastructure of transformation systems including parsing and pretty-printing. The framework addresses the entire range of the development process; from the specification of transformations to their composition into transformation systems. This chapter gives an overview of the main ingredients involved in the composition of transformation systems with Stratego/XT, where we distinguish the abstraction levels of rules, strategies, tools, and systems.", "num_citations": "415\n", "authors": ["1605"]}
{"title": "Syntax definition for language prototyping\n", "abstract": " The first exercise in this compiler construction course consists of writing a parser for BibTEX using the latest implementation of parser combinators. The purpose of this exercise is to refresh your memory of parsing; parsers being basic ingredients of compilers. BibTEX is a data format for describing bibliographic data, ie, data about books, scientific articles in journals, theses, etc. A bib database can be queried to get entries that are cited in a document and the entries obtained can be typeset in a variety of ways. This makes the bibliographic data portable and independent from a specific document or document style. An example entry is", "num_citations": "367\n", "authors": ["1605"]}
{"title": "Building program optimizers with rewriting strategies\n", "abstract": " We describe a language for defining term rewriting strategies, and its application to the production of program optimizers. Valid transformations on program terms can be described by a set of rewrite rules; rewriting strategies are used to describe when and how the various rules should be applied in order to obtain the desired optimization effects. Separating rules from strategies in this fashion makes it easier to reason about the behavior of the optimizer as a whole, compared to traditional monolithic optimizer implementations. We illustrate the expressiveness of our language by using it to describe a simple optimizer for an ML-like intermediate representation.The basic strategy language uses operators such as sequential composition, choice, and recursion to build transformers from a set of labeled unconditional rewrite rules. We also define an extended language in which the side-conditions and contextual rules that\u00a0\u2026", "num_citations": "313\n", "authors": ["1605"]}
{"title": "Concrete syntax for objects: domain-specific language embedding and assimilation without restrictions\n", "abstract": " Application programmer's interfaces give access to domain knowledge encapsulated in class libraries without providing the appropriate notation for expressing domain composition. Since object-oriented languages are designed for extensibility and reuse, the language constructs are often sufficient for expressing domain abstractions at the semantic level. However, they do not provide the right abstractions at the syntactic level. In this paper we describe MetaBorg, a method for providingconcrete syntax for domain abstractions to application programmers. The method consists ofembedding domain-specific languages in a general purpose host language andassimilating the embedded domain code into the surrounding host code. Instead of extending the implementation of the host language, the assimilation phase implements domain abstractions in terms of existing APIs leaving the host language undisturbed\u00a0\u2026", "num_citations": "280\n", "authors": ["1605"]}
{"title": "WebDSL: A Case Study in Domain-Specific Language Engineering\n", "abstract": " The goal of domain-specific languages (DSLs) is to increase the productivity of software engineers by abstracting from low-level boilerplate code. Introduction of DSLs in the software development process requires a smooth workflow for the production of DSLs themselves. This requires technology for designing and implementing DSLs, but also a methodology for using that technology. That is, a collection of guidelines, design patterns, and reusable DSL components that show developers how to tackle common language design and implementation issues. This paper presents a case study in domain-specific language engineering. It reports on a project in which the author designed and built WebDSL, a DSL for web applications with a rich data model, using several DSLs for DSL engineering: SDF for syntax definition and Stratego/XT for code generation. The paper follows the stages in the development of\u00a0\u2026", "num_citations": "254\n", "authors": ["1605"]}
{"title": "Disambiguation filters for scannerless generalized LR parsers\n", "abstract": " In this paper we present the fusion of generalized LR parsing and scannerless parsing. This combination supports syntax definitions in which all aspects (lexical and context-free) of the syntax of a language are defined explicitly in one formalism. Furthermore, there are no restrictions on the class of grammars, thus allowing a natural syntax tree structure. Ambiguities that arise through the use of unrestricted grammars are handled by explicit disambiguation constructs, instead of implicit defaults that are taken by traditional scanner and parser generators. Hence, a syntax definition becomes a full declarative description of a language. Scannerless generalized LR parsing is a viable technique that has been applied in various industrial and academic projects.", "num_citations": "217\n", "authors": ["1605"]}
{"title": "Scannerless generalized-LR parsing\n", "abstract": " Current deterministic parsing techniques have a number of problems. These include the limitations of parser generators for deterministic languages and the complex interface between scanner and parser. Scannerless parsing is a parsing technique in which lexical and context-free syntax are integrated into one grammar and are all handled by a single context-free analysis phase. This approach has a number of advantages including discarding of the scanner and lexical disambiguation by means of the context in which a lexical token occurs. Scannerless parsing generates a number of interesting problems as well. Integrated grammars do not t the requirements of the conventional deterministic parsing techniques. A plain context-free grammar formalism leads to unwieldy grammars, if all lexical information is included. Lexical disambiguation needs to be reformulated for use in context-free parsing. The scannerless generalized-LR parsing approach presented in this paper solves these problems. Grammar normalization is used to support an expressive grammar formalism without complicating the underlying machinery. Follow restrictions are used to express longest match lexical disambiguation. Reject productions are used to express the prefer keywords rule for lexical disambiguation. The SLR (1) parser generation algorithm is adapted to implement disambiguation by general priority and associativity declarations and to interpret follow restrictions. Generalized-LR parsing is used to provide dynamic lookahead and to support parsing of arbitrary context-free grammars including ambiguous ones. An adaptation of the GLR algorithm supports the\u00a0\u2026", "num_citations": "207\n", "authors": ["1605"]}
{"title": "Meta-programming with concrete object syntax\n", "abstract": " Meta programs manipulate structured representations, i.e., abstract syntax trees, of programs. The conceptual distance between the concrete syntax meta-programmers use to reason about programs and the notation for abstract syntax manipulation provided by general purpose (meta-) programming languages is too great for many applications. In this paper it is shown how the syntax definition formalism SDF can be employed to fit any meta-programming language with concrete syntax notation for composing and analyzing object programs. As a case study, the addition of concrete syntax to the program transformation language Stratego is presented. The approach is then generalized to arbitrary meta-languages.", "num_citations": "201\n", "authors": ["1605"]}
{"title": "A survey of rewriting strategies in program transformation systems\n", "abstract": " Program transformation is used in a wide range of applications including compiler construction, optimization, program synthesis, refactoring, software renovation, and reverse engineering. Complex program transformations are achieved through a number of consecutive modifications of a program. Transformation rules define basic modifications. A transformation strategy is an algorithm for choosing a path in the rewrite relation induced by a set of rules. This paper surveys the support for the definition of strategies in program transformation systems. After a discussion of kinds of program transformation and choices in program representation, the basic elements of a strategy system are discussed and the choices in the design of a strategy language are considered. Several styles of strategy systems as provided in existing languages are then analyzed.", "num_citations": "192\n", "authors": ["1605"]}
{"title": "Generation of formatters for context-free languages\n", "abstract": " Good documentation is important for the production of reusable and maintainable software. For the production of accurate documentation it is necessary that the original program text is not copied manually to obtain a typeset version. Apart from being tedious, this will invariably introduce errors. The production of tools that support the production of legible and accurate documentation is a software engineering challenge in itself. We present an algebraic approach to the generation of tools that produce typographically effective presentations of computer programs. A specification of a formatter is generated from the context-free grammar of a (programming) language. These generated formatters translate abstract syntax trees of programs into box expressions. Box expressions are  translated by language-independent interpreters of the box language into ASCII or TEX. The formatting rules that are generated can easily\u00a0\u2026", "num_citations": "180\n", "authors": ["1605"]}
{"title": "A survey of strategies in rule-based program transformation systems\n", "abstract": " Program transformation is the mechanical manipulation of a program in order to improve it relative to some cost function and is understood broadly as the domain of computation where programs are the data. The natural basic building blocks of the domain of program transformation are transformation rules expressing a \u2018one-step\u2019 transformation on a fragment of a program. The ultimate perspective of research in this area is a high-level, language parametric, rule-based program transformation system, which supports a wide range of transformations, admitting efficient implementations that scale to large programs. This situation has not yet been reached, as trade-offs between different goals need to be made. This survey gives an overview of issues in rule-based program transformation systems, focusing on the expressivity of rule-based program transformation systems and in particular on transformation strategies\u00a0\u2026", "num_citations": "139\n", "authors": ["1605"]}
{"title": "Program transformation with scoped dynamic rewrite rules\n", "abstract": " The applicability of term rewriting to program transformation is limited by the lack of control over rule application and by the context-free nature of rewrite rules. The first problem is addressed by languages supporting user-definable rewriting strategies. The second problem is addressed by the extension of rewriting strategies with scoped dynamic rewrite rules. Dynamic rules are defined at run-time and can access variables available from their definition context. Rules defined within a rule scope are automatically retracted at the end of that scope. In this paper, we explore the design space of dynamic rules, and their application to transformation problems. The technique is formally defined by extending the operational semantics underlying the program transformation language Stratego, and illustrated by means of several program transformations in Stratego, including constant propagation, bound variable renaming\u00a0\u2026", "num_citations": "129\n", "authors": ["1605"]}
{"title": "A core language for rewriting\n", "abstract": " System S is a calculus providing the basic abstractions of term rewriting: matching and building terms, term traversal, combining computations and handling failure. The calculus forms a core language for implementation of a wide variety of rewriting languages, or more generally, languages for specifying tree transformations. In this paper we show how a conventional rewriting language based on conditional term rewriting can be implemented straightforwardly in System S. Subsequently we show how this implementation can be extended with features such as matching conditions, negative conditions, default rules, non-strictness annotations and alternative evaluation strategies.We thank Bas Luttik and Andrew Tolmach for many discussions on rewriting strategies and their applications. Jan Bergstra pointed out the problems of non-determinism and conditional rules in languages such as ASF+SDF. Eu-genio Moggi\u00a0\u2026", "num_citations": "102\n", "authors": ["1605"]}
{"title": "Pure and declarative syntax definition: paradise lost and regained\n", "abstract": " Syntax definitions are pervasive in modern software systems, and serve as the basis for language processing tools like parsers and compilers. Mainstream parser generators pose restrictions on syntax definitions that follow from their implementation algorithm. They hamper evolution, maintainability, and compositionality of syntax definitions. The pureness and declarativity of syntax definitions is lost. We analyze how these problems arise for different aspects of syntax definitions, discuss their consequences for language engineers, and show how the pure and declarative nature of syntax definitions can be regained.", "num_citations": "101\n", "authors": ["1605"]}
{"title": "Nix: A Safe and Policy-Free System for Software Deployment.\n", "abstract": " Existing systems for software deployment are neither safe nor sufficiently flexible. Primary safety issues are the inability to enforce reliable specification of component dependencies, and the lack of support for multiple versions or variants of a component. This renders deployment operations such as upgrading or deleting components dangerous and unpredictable. A deployment system must also be flexible (ie, policy-free) enough to support both centralised and local package management, and to allow a variety of mechanisms for transferring components. In this paper we present Nix, a deployment system that addresses these issues through a simple technique of using cryptographic hashes to compute unique paths for component instances.", "num_citations": "94\n", "authors": ["1605"]}
{"title": "Declaratively programming the mobile web with mobl\n", "abstract": " A new generation of mobile touch devices, such as the iPhone, iPad and Android devices, are equipped with powerful, modern browsers. However, regular websites are not optimized for the specific features and constraints of these devices, such as limited screen estate, unreliable Internet access, touch-based interaction patterns, and features such as GPS. While recent advances in web technology enable web developers to build web applications that take advantage of the unique properties of mobile devices, developing such applications exposes a number of problems, specifically: developers are required to use many loosely coupled languages with limited tool support and application code is often verbose and imperative. We introduce mobl, a new language designed to declaratively construct mobile web applications. Mobl integrates languages for user interface design, styling, data modeling, querying and\u00a0\u2026", "num_citations": "92\n", "authors": ["1605"]}
{"title": "Code generation by model transformation: a case study in transformation modularity\n", "abstract": " The realization of model-driven software development requires effective techniques for implementing code generators for domain-specific languages. This paper identifies techniques for improving separation of concerns in the implementation of generators. The core technique is code generation by model transformation, that is, the generation of a structured representation (model) of the target program instead of plain text. This approach enables the transformation of code after generation, which in turn enables the extension of the target language with features that allow better modularity in code generation rules. The technique can also be applied to \u2018internal code generation\u2019 for the translation of high-level extensions of a DSL to lower-level constructs within the same DSL using model-to-model transformations. This paper refines our earlier description of code generation by model transformation with an\u00a0\u2026", "num_citations": "91\n", "authors": ["1605"]}
{"title": "Using filters for the disambiguation of context-free grammars\n", "abstract": " An ambiguous context-free grammar defines a language in which some sentences have multiple interpretations. For conciseness, ambiguous contextfree grammars are frequently used to define even completely unambiguous languages and numerous disambiguation methods exist for specifying which interpretation is the intended one for each sentence. The existing methods can be divided in \u2018parser specific\u2019methods that describe how some parsing technique deals with ambiguous sentences and \u2018logical\u2019methods that describe the intended interpretation without reference to a specific parsing technique.We propose a framework of filters to describe and compare a wide range of disambiguation problems in a parser-independent way. A filter is a function that selects from a set of parse trees (the canonical representation of the interpretations of a sentence) the intended trees. The framework enables us to define several general properties of disambiguation methods. The expressive power of filters is illustrated by several case studies. Finally, a start is made with the study of efficient implementation techniques for filters by exploiting the commutativity of parsing steps and filter steps for certain classes of filters.", "num_citations": "81\n", "authors": ["1605"]}
{"title": "Strategic pattern matching\n", "abstract": " Stratego is a language for the specification of transformation rules and strategies for applying them. The basic actions of transformations are matching and building instantiations of first-order term patterns. The language supports concise formulation of generic and data type-specific term traversals. One of the unusual features of Stratego is the separation of scope from matching, allowing sharing of variables through traversals. The combination of first-order patterns with strategies forms an expressive formalism for pattern matching. In this paper we discuss three examples of strategic pattern matching: (1) Contextual rules allow matching and replacement of a pattern at an arbitrary depth of a subterm of the root pattern. (2) Recursive patterns can be used to characterize concisely the structure of languages that form a restriction of a larger language. (3) Overlays serve to hide the representation of a language in\u00a0\u2026", "num_citations": "79\n", "authors": ["1605"]}
{"title": "Declarative Name Binding and Scope Rules\n", "abstract": " In textual software languages, names are used to reference elements like variables, methods, classes, etc. Name resolution analyses these names in order to establish references between definition and use sites of elements. In this paper, we identify recurring patterns for name bindings in programming languages and introduce a declarative metalanguage for the specification of name bindings in terms of namespaces, definition sites, use sites, and scopes. Based on such declarative name binding specifications, we provide a language-parametric algorithm for static name resolution during compile-time. We discuss the integration of the algorithm into the Spoofax Language Workbench and show how its results can be employed in semantic editor services like reference resolution, constraint checking, and content completion.", "num_citations": "74\n", "authors": ["1605"]}
{"title": "A theory of name resolution\n", "abstract": " We describe a language-independent theory for name binding and resolution, suitable for programming languages with complex scoping rules including both lexical scoping and modules. We formulate name resolution as a two-stage problem. First a language-independent scope graph is constructed using language-specific rules from an abstract syntax tree. Then references in the scope graph are resolved to corresponding declarations using a language-independent resolution process. We introduce a resolution calculus as a concise, declarative, and languageindependent specification of name resolution. We develop a resolution algorithm that is sound and complete with respect to the calculus. Based on the resolution calculus we develop language-independent definitions of \u03b1-equivalence and rename refactoring. We illustrate the approach using a small example language with modules. In addition\u00a0\u2026", "num_citations": "70\n", "authors": ["1605"]}
{"title": "Preventing injection attacks with syntax embeddings\n", "abstract": " Software written in one language often needs to construct sentences in another language, such as SQL queries, XML output, or shell command invocations. This is almost always done using unhygienic string manipulation, the concatenation of constants and client-supplied strings. A client can then supply specially crafted input that causes the constructed sentence to be interpreted in an unintended way, leading to an injection attack. We describe a more natural style of programming that yields code that is impervious to injections by construction. Our approach embeds the grammars of the guest languages (eg, SQL) into that of the host language (eg, Java) and automatically generates code that maps the embedded language to constructs in the host language that reconstruct the embedded sentences, adding escaping functions where appropriate. This approach is generic, meaning that it can be applied with relative\u00a0\u2026", "num_citations": "70\n", "authors": ["1605"]}
{"title": "Stratego/XT 0.16: components for transformation systems\n", "abstract": " Stratego/XT is a language and toolset for program transformation. The Stratego language provides rewrite rules for expressing basic transformations, programmable rewriting strategies for controlling the application of rules, concrete syntax for expressing the patterns of rules in the syntax of the object language, and dynamic rewrite rules for expressing context-sensitive transformations, thus supporting the development of transformation components at a high level of abstraction. The XT toolset offers a collection of flexible, reusable transformation components, as well as declarative languages for deriving new components. Complete program transformation systems are composed from these components. In this paper we give an overview of Stratego/XT 0.16.", "num_citations": "70\n", "authors": ["1605"]}
{"title": "Design of the CodeBoost transformation system for domain-specific optimisation of C++ programs\n", "abstract": " The use of a high-level, abstract coding style can greatly increase developer productivity. For numerical software, this can result in drastically reduced run-time performance. High-level, domain-specific optimisations can eliminate much of the overhead caused by an abstract coding style, but current compilers have poor support for domain-specific optimisation. We present CodeBoost, a source-to-source transformation tool for domain-specific optimisation of C++ programs. CodeBoost performs parsing, semantic analysis and pretty-printing, and transformations can be implemented either in the Stratego program transformation language, or as user-defined rewrite rules embedded within the C++ program. CodeBoost has been used with great success to optimise numerical applications written in the Sophus high-level coding style. We discuss the overall design of the CodeBoost transformation framework, and take a\u00a0\u2026", "num_citations": "70\n", "authors": ["1605"]}
{"title": "WebDSL: a domain-specific language for dynamic web applications\n", "abstract": " WebDSL is a domain-specific language for the implementation of dynamic web applications with a rich datamodel. It consists of a core language with constructs to define entities, pages and business logic. Higher-level abstractions, modeling access control and workflow, are defined in a modular fashion as extensions of the core language.", "num_citations": "69\n", "authors": ["1605"]}
{"title": "Heterogeneous coupled evolution of software languages\n", "abstract": " As most software artifacts, meta-models can evolve. Their evolution requires conforming models to co-evolve along with them. Coupled evolution supports this. Its applicability is not limited to the modeling domain. Other domains are for example evolving grammars or database schemas. Existing approaches to coupled evolution focus on a single, homogeneous domain. They solve the co-evolution problems locally and repeatedly. In this paper we present a systematic, heterogeneous approach to coupled evolution. It provides an automatically derived domain specific transformation language; a means of executing transformations at the top level; a derivation of the coupled bottom level transformation; and it allows for generic abstractions from elementary transformations. The feasibility of the architecture is evaluated by applying it to data model evolution.", "num_citations": "69\n", "authors": ["1605"]}
{"title": "Code generation by model transformation\n", "abstract": " The realization of model-driven software development requires effective techniques for implementing code generators. In this paper, we present a case study of code generation by model transformation  with Stratego, a high-level transformation language based on the paradigm of rewrite rules with programmable strategies that integrates model-to-model, model-to-code, and code-to-code transformations. The use of concrete object syntax guarantees syntactic correctness of code patterns, and enables the subsequent transformation of generated code. The composability of strategies supports two dimensions of transformation modularity. Vertical modularity is achieved by designing a generator as a pipeline of model-to-model transformations that gradually transforms a high-level input model to an implementation. Horizontal modularity is achieved by supporting the definition of plugins which implement all\u00a0\u2026", "num_citations": "69\n", "authors": ["1605"]}
{"title": "Metaborg in action: Examples of domain-specific language embedding and assimilation using stratego/xt\n", "abstract": " General-purpose programming languages provide limited facilities for expressing domain-specific concepts in a natural manner. All domain concepts need to be captured using the same generic syntactic and semantic constructs. Generative programming methods and program transformation techniques can be used to overcome this lack of abstraction in general-purpose languages. In this tutorial we describe the MetaBorg method for embedding domain-specific languages, tailored syntactically and semantically to the application domain at hand, in a general-purpose language. MetaBorg is based on Stratego/XT, a language and toolset for the implementation of program transformation systems, which is used for the definition of syntactic embeddings and assimilation of the embedded constructs into the surrounding code. We illustrate MetaBorg with three examples. JavaSwul is a custom designed language for\u00a0\u2026", "num_citations": "68\n", "authors": ["1605"]}
{"title": "Imposing a memory management discipline on software deployment\n", "abstract": " The deployment of software components frequently fails because dependencies on other components are not declared explicitly or are declared imprecisely. This results in an incomplete reproduction of the environment necessary for proper operation, or in interference between incompatible variants. In this paper, we show that these deployment hazards are similar to pointer hazards in memory models of programming languages and can be countered by imposing a memory management discipline on software deployment. Based on this analysis, we have developed a generic, platform and language independent, discipline for deployment that allows precise dependency verification; exact identification of component variants; computation of complete closures containing all components on which a component depends; maximal sharing of components between such closures; and concurrent installation of revisions\u00a0\u2026", "num_citations": "66\n", "authors": ["1605"]}
{"title": "A language designer's workbench: a one-stop-shop for implementation and verification of language designs\n", "abstract": " The realization of a language design requires multiple artifacts that redundantly encode the same information. This entails significant effort for language implementors, and often results in late detection of errors in language definitions. In this paper we present a proof-of-concept language designer's workbench that supports generation of IDEs, interpreters, and verification infrastructure from a single source. This constitutes a first milestone on the way to a system that fully automates language implementation and verification.", "num_citations": "64\n", "authors": ["1605"]}
{"title": "Language independent traversals for program transformation\n", "abstract": " Many language processing operations have a generic underlying algorithm. However, these generic algorithms either have to be implemented specifically for the language under consideration or the language needs to be encoded in a generic format that the generic algorithm works on. Stratego is a language for program transformation that supports both specific and generic views of data types.A Stratego program defines a transformation on first-order ground terms. Transformation rules define single transformation steps. Transformation rules are combined into transformation strategies by means of combinators that determine where and in what order rules are applied. These combinators include: primitives for traversal to the direct subterms of a node, allowing the definition of many kinds of full term traversals; full control over recursion in traversals; patterns as first-class citizens; generic term construction and deconstruction.", "num_citations": "60\n", "authors": ["1605"]}
{"title": "Declarative, formal, and extensible syntax definition for AspectJ\n", "abstract": " Aspect-Oriented Programming (AOP) is attracting attention from both research and industry, as illustrated by the ever-growing popularity of AspectJ, the de facto standard AOP extension of Java. From a compiler construction perspective AspectJ is interesting as it is a typical example of compositional language, ie a language composed of a number of separate languages with different syntactical styles: in addition to plain Java, AspectJ includes a language for defining pointcuts and one for defining advices. Language composition represents a non-trivial challenge for conventional parsing techniques. First, combining several languages with different lexical syntax leads to considerable complexity in the lexical states to processed. Second, as new language features for AOP are being explored, many research proposals are concerned with further extending the AspectJ language, resulting in a need for an extensible\u00a0\u2026", "num_citations": "59\n", "authors": ["1605"]}
{"title": "Scoped dynamic rewrite rules\n", "abstract": " The applicability of term rewriting to program transformation is limited by the lack of control over rule application and by the context-free nature of rewrite rules. The first problem is addressed by languages supporting user-definable rewriting strategies. This paper addresses the second problem by extending rewriting strategies with scoped dynamic rewrite rules. Dynamic rules are generated at run-time and can access variables available from their definition context. Rules generated within a rule scope are automatically retracted at the end of that scope. The technique is illustrated by means of several program tranformations: bound variable renaming, function inlining, and dead function elimination.", "num_citations": "59\n", "authors": ["1605"]}
{"title": "Program transformation mechanics. A classification of mechanisms for program transformation with a survey of existing transformation systems\n", "abstract": " Transformation techniques are spreading from application in compilers to general use in generative programming and document processing. Since transformation requires operations such as pattern matching, generic structure traversal, and querying, which are not normally provided by general-purpose programming languages, many tools have been developed to provide higher-level support for the implementation of transformations. These tools come in many flavors each with their own merits and based on different paradigms, which makes comparison difficult. In this paper, we consider transformation from the point of view of mechanics and develop a classification of transformation mechanisms that provides a reference for comparing tools developed for different applications, using different implementations, and in different programming paradigms. To do so we distinguish three fundamental aspects of transformation mechanisms: scope, direction, and stages. We apply this classification in a discussion of design patterns for transformation, characterization of several typical transformations, and a systematic comparison of eleven representative transformation tools.", "num_citations": "56\n", "authors": ["1605"]}
{"title": "Generalized type-based disambiguation of meta programs with concrete object syntax\n", "abstract": " In meta programming with concrete object syntax, object-level programs are composed from fragments written in concrete syntax. The use of small program fragments in such quotations and the use of meta-level expressions within these fragments (anti-quotation) often leads to ambiguities. This problem is usually solved through explicit disambiguation, resulting in considerable syntactic overhead. A few systems manage to reduce this overhead by using type information during parsing. Since this is hard to achieve with traditional parsing technology, these systems provide specific combinations of meta and object languages, and their implementations are difficult to reuse. In this paper, we generalize these approaches and present a language independent method for introducing concrete object syntax without explicit disambiguation. The method uses scannerless generalized-LR parsing to parse meta\u00a0\u2026", "num_citations": "54\n", "authors": ["1605"]}
{"title": "Composing source-to-source data-flow transformations with rewriting strategies and dependent dynamic rewrite rules\n", "abstract": " Data-flow transformations used in optimizing compilers are also useful in other programming tools such as code generators, aspect weavers, domain-specific optimizers, and refactoring tools. These applications require source-to-source transformations rather than transformations on a low-level intermediate representation. In this paper we describe the composition of source-to-source data-flow transformations in the program transformation language Stratego. The language supports the high-level specification of transformations by means of rewriting strategy combinators that allow a natural modeling of data- and control-flow without committing to a specific source language. Data-flow facts are propagated using dynamic rewriting rules. In particular, we introduce the concept of dependent dynamic rewrite rules for modeling the dependencies of data-flow facts on program entities such as variables. The\u00a0\u2026", "num_citations": "52\n", "authors": ["1605"]}
{"title": "Specification of Rewriting Strategies\u2217\n", "abstract": " User-definable strategies for the application of rewrite rules provide a means to construct transformation systems that apply rewrite rules in a controlled way. This paper describes a strategy language and its interpretation. The language is used to control the rewriting of terms using labeled rewrite rules. Rule labels are atomic strategies. Compound strategies are formed by means of sequential composition, nondeterministic choice, left choice, fixed point recursion, and two primitives for expressing term traversal. Several complex strategies such as bottom-up and top-down application and (parallel) innermost and (parallel) outermost reduction can be defined in terms of these primitives. The paper contains two case studies of the application of strategies.", "num_citations": "52\n", "authors": ["1605"]}
{"title": "Reconstructing complex metamodel evolution\n", "abstract": " Metamodel evolution requires model migration. To correctly migrate models, evolution needs to be made explicit. Manually describing evolution is error-prone and redundant. Metamodel matching offers a solution by automatically detecting evolution, but is only capable of detecting primitive evolution steps. In practice, primitive evolution steps are jointly applied to form a complex evolution step, which has the same effect on a metamodel as the sum of its parts, yet generally has a different effect in migration. Detection of complex evolution is therefore needed. In this paper, we present an approach to reconstruct complex evolution between two metamodel versions, using a matching result as input. It supports operator dependencies and mixed, overlapping, and incorrectly ordered complex operator components. It also supports interference between operators, where the effect of one operator is partially or\u00a0\u2026", "num_citations": "47\n", "authors": ["1605"]}
{"title": "DynSem: A DSL for dynamic semantics specification\n", "abstract": " The formal semantics of a programming language and its implementation are typically separately defined, with the risk of divergence such that properties of the formal semantics are not properties of the implementation. In this paper, we present DynSem, a domain-specific language for the specification of the dynamic semantics of programming languages that aims at supporting both formal reasoning and efficient interpretation. DynSem supports the specification of the operational semantics of a language by means of statically typed conditional term reduction rules. DynSem supports concise specification of reduction rules by providing implicit build and match coercions based on reduction arrows and implicit term constructors. DynSem supports modular specification by adopting implicit propagation of semantic components from I-MSOS, which allows omitting propagation of components such as environments and stores from rules that do not affect those. DynSem supports the declaration of native operators for delegation of aspects of the semantics to an external definition or implementation. DynSem supports the definition of auxiliary meta-functions, which can be expressed using regular reduction rules and are subject to semantic component propagation. DynSem specifications are executable through automatic generation of a Java-based AST interpreter.", "num_citations": "46\n", "authors": ["1605"]}
{"title": "Declarative access control for WebDSL: Combining language integration and separation of concerns\n", "abstract": " In this paper, we present the extension of WebDSL, a domain-specific language for web application development, with abstractions for declarative definition of access control. The extension supports the definition of a wide range of access control policies concisely and transparently as a separate concern. In addition to regulating the access to pages and actions, access control rules are used to infer navigation options not accessible to the current user, preventing the presentation of inaccessible links. The extension is an illustration of a general approach to the design of domain-specific languages for different technical domains to support separation of concerns in application development, while preserving linguistic integration. This approach is realized by means of a transformational semantics that weaves separately defined aspects into an integrated implementation.", "num_citations": "46\n", "authors": ["1605"]}
{"title": "A constraint language for static semantic analysis based on scope graphs\n", "abstract": " In previous work, we introduced scope graphs as a formalism for describing program binding structure and performing name resolution in an AST-independent way. In this paper, we show how to use scope graphs to build static semantic analyzers. We use constraints extracted from the AST to specify facts about binding, typing, and initialization. We treat name and type resolution as separate building blocks, but our approach can handle language constructs---such as record field access---for which binding and typing are mutually dependent. We also refine and extend our previous scope graph theory to address practical concerns including ambiguity checking and support for a wider range of scope relationships. We describe the details of constraint generation for a model language that illustrates many of the interesting static analysis issues associated with modules and records.", "num_citations": "45\n", "authors": ["1605"]}
{"title": "Integration of data validation and user interface concerns in a DSL for web applications\n", "abstract": " Data validation rules constitute the constraints that data input and processing must adhere to in addition to the structural constraints imposed by a data model. Web modeling tools do not make all types of data validation explicit in their models, hampering full code generation and model expressivity. Web application frameworks do not offer a consistent interface for data validation. In this paper, we present a solution for the integration of declarative data validation rules with user interface models in the domain of web applications, unifying syntax, mechanisms for error handling, and semantics of validation checks, and covering value well-formedness, data invariants, input assertions, and action assertions. We have implemented the approach in WebDSL, a domain-specific language for the definition of web applications.", "num_citations": "45\n", "authors": ["1605"]}
{"title": "Language design with the spoofax language workbench\n", "abstract": " IDEs are essential for programming language developers, and state-of-the-art IDE support is mandatory for programming languages to be successful. Although IDE features for mainstream programming languages are typically implemented manually, this often isn't feasible for programming languages that must be developed with significantly fewer resources. The Spoofax language workbench is a platform for developing textual programming languages with state-of-the-art IDE support. Spoofax is a comprehensive environment that integrates syntax definition, name binding, type analysis, program transformation, code generation, and declarative specification of IDE components. It also provides high-level languages for each of these aspects. These languages are highly declarative, abstracting over the implementation of IDE features and letting engineers focus on language design.", "num_citations": "42\n", "authors": ["1605"]}
{"title": "Declaratively defining domain-specific language debuggers\n", "abstract": " Tool support is vital to the effectiveness of domain-specific languages. With language workbenches, domain-specific languages and their tool support can be generated from a combined, high-level specification. This paper shows how such a specification can be extended to describe a debugger for a language. To realize this, we introduce a meta-language for coordinating the debugger that abstracts over the complexity of writing a debugger by hand. We describe the implementation of a language-parametric infrastructure for debuggers that can be instantiated based on this specification. The approach is implemented in the Spoofax language workbench and validated through realistic case studies with the Stratego transformation language and the WebDSL web programming language.", "num_citations": "42\n", "authors": ["1605"]}
{"title": "A pure object-oriented embedding of attribute grammars\n", "abstract": " Attribute grammars are a powerful specification paradigm for many language processing tasks, particularly semantic analysis of programming languages. Recent attribute grammar systems use dynamic scheduling algorithms to evaluate attributes by need. In this paper, we show how to remove the need for a generator, by embedding a dynamic approach in a modern, object-oriented programming language to implement a small, lightweight attribute grammar library. The Kiama attribution library has similar features to current generators, including cached, uncached, circular, higher-order and parameterised attributes, and implements new techniques for dynamic extension and variation of attribute equations. We use the Scala programming language because of its combination of object-oriented and functional features, support for domain-specific notations and emphasis on scalability. Unlike generators with\u00a0\u2026", "num_citations": "41\n", "authors": ["1605"]}
{"title": "Warm fusion in Stratego: A case study in generation of program transformation systems\n", "abstract": " Stratego is a domain-specific language for the specification of program transformation systems. The design of Stratego is based on the paradigm of rewriting strategies: user-definable programs in a little language of strategy operators determine where and in what order transformation rules are (automatically) applied to a program. The separation of rules and strategies supports modularity of specifications. Stratego also provides generic features for specification of program traversals.               In this paper we present a case study of Stratego as applied to a non-trivial problem in program transformation. We demonstrate the use of Stratego in eliminating intermediate data structures from (also known as deforesting) functional programs via the warm fusion algorithm of Launchbury and Sheard. This algorithm has been specified in Stratego and embedded in a fully automatic transformation system for kernel\u00a0\u2026", "num_citations": "41\n", "authors": ["1605"]}
{"title": "Declarative specification of template-based textual editors\n", "abstract": " Syntax discoverability has been a crucial advantage of structure editors for new users of a language. Despite this advantage, structure editors have not been widely adopted. Based on immediate parsing and analyses, modern textual code editors are also increasingly syntax-aware: structure and textual editors are converging into a new editing paradigm that combines text and templates. Current text-based language workbenches require redundant specification of the ingredients for a template-based editor, which is detrimental to the quality of syntactic completion, as consistency and completeness of the definition cannot be guaranteed.", "num_citations": "40\n", "authors": ["1605"]}
{"title": "A family of syntax definition formalisms\n", "abstract": " In the next chapters we present the design and speci cation of a family of syntax de nition formalisms. The kernel of this family of formalisms is formed by context-free grammars. A number of orthogonal extensions to the kernel is de ned. Many of these extensions are de ned in terms of the primitives of the kernel by means of normalization functions. This provides a framework for constructing new formalisms by adapting and extending previous ones. Included in the family are the following extensions of context-free grammars: uniform de nition of lexical and context-free syntax, variables, disambiguation by priorities, follow restrictions and reject productions, a rich set of regular expressions de ned in terms of context-free productions, character classes, aliases, parameterized modules with hidden imports and renamings. The accumulation of these extensions is the syntax de nition formalism SDF2. This chapter provides an introduction to SDF2 and gives an overview of the design and speci cation of the family of formalisms.", "num_citations": "39\n", "authors": ["1605"]}
{"title": "Strategies for source-to-source constant propagation\n", "abstract": " Data-flow optimizations are usually implemented on low-level intermediate representations. This is not appropriate for source-to-source optimizations, which reconstruct a source level program after transformation. In this paper we show how constant propagation, a well known data-flow optimization problem, can be implemented on abstract syntax trees in Stratego, a rewriting system extended with programmable rewriting strategies for the control over the application of rules and dynamic rewrite rules for the propagation of information.", "num_citations": "37\n", "authors": ["1605"]}
{"title": "Decorated attribute grammars: Attribute evaluation meets strategic programming\n", "abstract": " Attribute grammars are a powerful specification formalism for tree-based computation, particularly for software language processing. Various extensions have been proposed to abstract over common patterns in attribute grammar specifications. These include various forms of copy rules to support non-local dependencies, collection attributes, and expressing dependencies that are evaluated to a fixed point. Rather than implementing extensions natively in an attribute evaluator, we propose attribute decorators that describe an abstract evaluation mechanism for attributes, making it possible to provide such extensions as part of a library of decorators. Inspired by strategic programming, decorators are specified using generic traversal operators. To demonstrate their effectiveness, we describe how to employ decorators in name, type, and flow analysis.", "num_citations": "36\n", "authors": ["1605"]}
{"title": "Natural and flexible error recovery for generated modular language environments\n", "abstract": " Integrated Development Environments (IDEs) increase programmer productivity, providing rapid, interactive feedback based on the syntax and semantics of a language. Unlike conventional parsing algorithms, scannerless generalized-LR parsing supports the full set of context-free grammars, which is closed under composition, and hence can parse languages composed from separate grammar modules. To apply this algorithm in an interactive environment, this article introduces a novel error recovery mechanism. Our approach is language independent, and relies on automatic derivation of recovery rules from grammars. By taking layout information into consideration it can efficiently suggest natural recovery suggestions.", "num_citations": "35\n", "authors": ["1605"]}
{"title": "Static consistency checking of web applications with WebDSL\n", "abstract": " Modern web application development frameworks provide web application developers with high-level abstractions to improve their productivity. However, their support for static verification of applications is limited. Inconsistencies in an application are often not detected statically, but appear as errors at run-time. The reports about these errors are often obscure and hard to trace back to the source of the inconsistency. A major part of this inadequate consistency checking can be traced back to the lack of linguistic integration of these frameworks. Parts of an application are defined with separate domain-specific languages, which are not checked for consistency with the rest of the application. Examples include regular expressions, query languages and XML-based languages for definition of user interfaces. We give an overview and analysis of typical problems arising in development with frameworks for web application\u00a0\u2026", "num_citations": "35\n", "authors": ["1605"]}
{"title": "Growing a language environment with editor libraries\n", "abstract": " Large software projects consist of code written in a multitude of different (possibly domain-specific) languages, which are often deeply interspersed even in single files. While many proposals exist on how to integrate languages semantically and syntactically, the question of how to support this scenario in integrated development environments (IDEs) remains open: How can standard IDE services, such as syntax highlighting, outlining, or reference resolving, be provided in an extensible and compositional way, such that an open mix of languages is supported in a single file?", "num_citations": "33\n", "authors": ["1605"]}
{"title": "Providing rapid feedback in generated modular language environments: adding error recovery to scannerless generalized-LR parsing\n", "abstract": " Integrated development environments (IDEs) increase programmer productivity, providing rapid, interactive feedback based on the syntax and semantics of a language. A heavy burden lies on developers of new languages to provide adequate IDE support. Code generation techniques provide a viable, efficient approach to semi-automatically produce IDE plugins. Key components for the realization of plugins are the language's grammar and parser. For embedded languages and language extensions, constituent IDE plugin modules and their grammars can be combined. Unlike conventional parsing algorithms, scannerless generalized-LR parsing supports the full set of context-free grammars, which is closed under composition, and hence can parse language embeddings and extensions composed from separate grammar modules. To apply this algorithm in an interactive environment, this paper introduces a\u00a0\u2026", "num_citations": "33\n", "authors": ["1605"]}
{"title": "WebWorkFlow: an object-oriented workflow modeling language for web applications\n", "abstract": " Workflow languages are designed for the high-level description of processes and are typically not suitable for the generation of complete applications. In this paper, we present WebWorkFlow, an object-oriented workflow modeling language for the high-level description of workflows in web applications. Workflow descriptions define procedures operating on domain objects. Procedures are composed using sequential and concurrent process combinators. WebWorkFlow is an embedded language, extending WebDSL, a domain-specific language for web application development, with workflow abstractions. The extension is implemented by means of model-to-model transformations. Rather than providing an exclusive workflow language, WebWorkFlow supports interaction with the underlying WebDSL language. WebWorkFlow supports most of the basic workflow control patterns.", "num_citations": "33\n", "authors": ["1605"]}
{"title": "Parse table composition\n", "abstract": " Module systems, separate compilation, deployment of binary components, and dynamic linking have enjoyed wide acceptance in programming languages and systems. In contrast, the syntax of languages is usually defined in a non-modular way, cannot be compiled separately, cannot easily be combined with the syntax of other languages, and cannot be deployed as a component for later composition. Grammar formalisms that do support modules use whole program compilation.                 Current extensible compilers focus on source-level extensibility, which requires users to compile the compiler with a specific configuration of extensions. A compound parser needs to be generated for every combination of extensions. The generation of parse tables is expensive, which is a particular problem when the composition configuration is not fixed to enable users to choose language extensions.                 In this\u00a0\u2026", "num_citations": "31\n", "authors": ["1605"]}
{"title": "A language independent task engine for incremental name and type analysis\n", "abstract": " IDEs depend on incremental name and type analysis for responsive feedback for large projects. In this paper, we present a language-independent approach for incremental name and type analysis. Analysis consists of two phases. The first phase analyzes lexical scopes and binding instances and creates deferred analysis tasks. A task captures a single name resolution or type analysis step. Tasks might depend on other tasks and are evaluated in the second phase. Incrementality is supported on file and task level. When a file changes, only this file is recollected and only those tasks are reevaluated, which are affected by the changes in the collected data. The analysis does neither re-parse nor re-traverse unchanged files, even if they are affected by changes in other files. We implemented the approach as part of the Spoofax Language Workbench and evaluated it for the WebDSL web programming language.", "num_citations": "30\n", "authors": ["1605"]}
{"title": "A Pure embedding of attribute grammars\n", "abstract": " Attribute grammars are a powerful specification paradigm for many language processing tasks, particularly semantic analysis of programming languages. Recent attribute grammar systems use dynamic scheduling algorithms to evaluate attributes on demand. In this paper, we show how to remove the need for a generator, by embedding a dynamic approach in a modern, object-oriented and functional programming language. The result is a small, lightweight attribute grammar library that is part of our larger Kiama language processing library. Kiama\u2019s attribute grammar library supports a range of advanced features including cached, uncached, higher order, parameterised and circular attributes. Forwarding is available to modularise higher order attributes and decorators abstract away from the details of attribute value propagation. Kiama also implements new techniques for dynamic extension and variation of\u00a0\u2026", "num_citations": "30\n", "authors": ["1605"]}
{"title": "Software Development Environments on the Web: A Research Agenda\n", "abstract": " Software is rapidly moving from the desktop to the Web. The Web provides a generic user interface that allows ubiquitous access, instant collaboration, integration with other online services, and avoids installation and configuration on desktop computers. For software development, the Web presents a shift away from developer workstations as a silo, and has the promise of closer collaboration and improved feedback through innovations in Web-based interactive development environments (IDEs). Moving IDEs to the Web is not just a matter of porting desktop IDEs; a fundamental reconsideration of the IDE architecture is necessary in order to realize the full potential that the combination of modern IDEs and the Web can offer. This paper discusses research challenges and opportunities in this area, guided by a pilot study of a web IDE implementation.", "num_citations": "30\n", "authors": ["1605"]}
{"title": "Preventing injection attacks with syntax embeddings\n", "abstract": " Software written in one language often needs to construct sentences in another language, such as SQL queries, XML output, or shell command invocations. This is almost always done using unhygienic string manipulation, the concatenation of constants and client-supplied strings. A client can then supply specially crafted input that causes the constructed sentence to be interpreted in an unintended way, leading to an injection attack. We describe a more natural style of programming that yields code that is impervious to injections by construction. Our approach embeds the grammars of the guest languages (e.g. SQL) into that of the host language (e.g. Java) and automatically generates code that maps the embedded language to constructs in the host language that reconstruct the embedded sentences, adding escaping functions where appropriate. This approach is generic, meaning that it can be applied with\u00a0\u2026", "num_citations": "30\n", "authors": ["1605"]}
{"title": "Software deployment in a dynamic cloud: From device to service orientation in a hospital environment\n", "abstract": " Hospital environments are currently primarily device-oriented: software services are installed, often manually, on specific devices. For instance, an application to view MRI scans may only be available on a limited number of workstations. The medical world is changing to a service-oriented environment, which means that every software service should be available on every device. However, these devices have widely varying capabilities, ranging from powerful workstations to PDAs, and high-bandwidth local machines to low-bandwidth remote machines. To support running applications in such an environment, we need to treat the hospital machines as a cloud, where components of the application are automatically deployed to machines in the cloud with the required capabilities and connectivity. In this paper, we suggest an architecture for applications in such a cloud, in which components are reliably and\u00a0\u2026", "num_citations": "30\n", "authors": ["1605"]}
{"title": "Timeline variability: The variability of binding time of variation points\n", "abstract": " Timeline variability is the ability of a software system to have variation points bound at different moments of the system\u2019s life-cycle.Virtually every non-trivial software system exhibits variability: the property that the set of features\u2014characteristics of the system that are relevant to some stakeholder\u2014can be changed at certain points in the system\u2019s life-cycle. The parts of the system that implement the ability to make such changes are called variation points. Selecting some variant supported by a variation point is called binding the variant. Every variation point has at least one associated binding time: the moment in the system\u2019s life-cycle at which the variation point can be bound. A more detailed exposition of this terminology can be found in, eg,[6, 2]. For example, the decision to build an operating system kernel with multiprocessor support, or to build a \u201clight\u201d or \u201cprofessional\u201d version of a word processor, might be implemented at build time. On the other hand, the decision to include support for some brand of hard drive in an operating system, or to use some particular language for spell checking in a word processor, might be made at runtime. Generally, one would like variation points to be as flexible as possible with regard to binding time. That is, ideally one wants to have the ability to bind a variation point at build time, installation time, runtime, and so on. This leads to the notion of timeline variability: that certain features can be bound at several stages of the life-cycle. We do not formalise the term timeline here. Intuitively, we use if to refer to the set of distinguished moments during the build and deployment process where a user can potentially select\u00a0\u2026", "num_citations": "29\n", "authors": ["1605"]}
{"title": "Capturing timeline variability with transparent configuration environments\n", "abstract": " Virtually every non-trivial software system exhibits variability: the property that the set of features\u2014characteristics of the system that are relevant to some stakeholder\u2014can be changed at certain points in the system\u2019s deployment lifecycle. Some features can be bound only at specific moments in the life-cycle, while some can be bound at several distinct moments (timeline variability). This leads to inconsistent configuration interfaces; variability decisions are generally made through different interfaces depending on the moment in the life-cycle. In this paper we propose to formalize variability into a feature model that takes timeline issues into account and to derive from such feature models configuration interfaces that abstract over the life-cycle.", "num_citations": "29\n", "authors": ["1605"]}
{"title": "Rewriting strategies for instruction selection\n", "abstract": " Instruction selection (mapping IR trees to machine instructions) can be expressed by means of rewrite rules. Typically, such sets of rewrite rules are highly ambiguous. Therefore, standard rewriting engines based on fixed, exhaustive strategies are not appropriate for the execution of instruction selection. Code generator generators use special purpose implementations employing dynamic programming. In this paper we show how rewriting strategies for instruction selection can be encoded concisely in Stratego, a language for program transformation based on the paradigm of programmable rewriting strategies. This embedding obviates the need for a language dedicated to code generation, and makes it easy to combine code generation with other optimizations.", "num_citations": "29\n", "authors": ["1605"]}
{"title": "Domain-specific languages for composable editor plugins\n", "abstract": " Modern IDEs increase developer productivity by incorporating many different kinds of editor services. These can be purely syntactic, such as syntax highlighting, code folding, and an outline for navigation; or they can be based on the language semantics, such as in-line type error reporting and resolving identifier declarations. Building all these services from scratch requires both the extensive knowledge of the sometimes complicated and highly interdependent APIs and extension mechanisms of an IDE framework, and an in-depth understanding of the structure and semantics of the targeted language. This paper describes Spoofax/IMP, a meta-tooling suite that provides high-level domain-specific languages for describing editor services, relieving editor developers from much of the framework-specific programming. Editor services are defined as composable modules of rules coupled to a modular SDF grammar\u00a0\u2026", "num_citations": "28\n", "authors": ["1605"]}
{"title": "An algorithm for layout preservation in refactoring transformations\n", "abstract": " Transformations and semantic analysis for source-to-source transformations such as refactorings are most effectively implemented using an abstract representation of the source code. An intrinsic limitation of transformation techniques based on abstract syntax trees is the loss of layout, i.e. comments and whitespace. This is especially relevant in the context of refactorings, which produce source code for human consumption. In this paper, we present an algorithm for fully automatic source code reconstruction for source-to-source transformations. The algorithm preserves the layout and comments of the unaffected parts and reconstructs the indentation of the affected parts, using a set of clearly defined heuristic rules to handle comments.", "num_citations": "27\n", "authors": ["1605"]}
{"title": "Building interpreters with rewriting strategies\n", "abstract": " Programming language semantics based on pure rewrite rules suffers from the gap between the rewriting strategy implemented in rewriting engines and the intended evaluation strategy. This paper shows how programmable rewriting strategies can be used to implement interpreters for programming languages based on rewrite rules. The advantage of this approach is that reduction rules are first class entities that can be reused in different strategies, even in other kinds of program transformations such as optimizers. The approach is illustrated with several interpreters for the lambda calculus based on implicit and explicit (parallel) substitution, different strategies including normalization, eager evaluation, lazy evaluation, and lazy evaluation with updates. An extension with pattern matching and choice shows that such interpreters can easily be extended.", "num_citations": "27\n", "authors": ["1605"]}
{"title": "Turning dynamic typing into static typing by program specialization in a compiler front-end for Octave\n", "abstract": " Array processing languages such as APL, Matlab and Octave rely on dynamic typechecking by the interpreter rather than static typechecking and are designed for user convenience with a syntax close to mathematical notation. Functions and operators are highly overloaded. The price to be paid for this flexibility is computational performance, since the run-time system is responsible for type checking, array shape determination, function call dispatching, and handling possible run-time errors. In order to produce efficient code, an Octave compiler should address those issues at compile-time as much as possible. In particular, static type and shape inferencing can improve the quality of the generated code. We discuss how overloading in dynamically typed Octave programs can be resolved by program specialization. We discuss the typing issues in compilation of Octave programs and give an overview of the\u00a0\u2026", "num_citations": "26\n", "authors": ["1605"]}
{"title": "Guiding visitors: Separating navigation from computation\n", "abstract": " Traversals over the object structure are widely used in object-oriented programming, in particular in language processing applications. The visitor pattern separates computation from traversal by specifying the computations that should be performed at each object in a separate visitor class. This makes the implementation of different computations reusing the same traversal scheme possible. However, navigation through the object structure is fixed in the accept methods implemented by the objects that are traversed. This makes it difficult to use other navigation orders. In this paper, we introduce the Guide pattern that describes the separation of navigation from computation and object structure using a double-dispatching iterator. The pattern makes it possible to implement a whole range of navigation schemes for an object-structure. Using a selfdispatching approach based on reflective method lookup such navigation schemes can be made reusable for whole classes of object-structures (implementing a common interface). The efficiency of this approach is provided by caching method lookups. We extend the approach to generic navigation through arbitrary object-structures using reflective field lookup. This results in a generalization of the Walkabout class of Palsberg and Jay with a huge performance improvement in Java, making the Walkabout usable in practice.", "num_citations": "26\n", "authors": ["1605"]}
{"title": "Integrated language definition testing: enabling test-driven language development\n", "abstract": " The reliability of compilers, interpreters, and development environments for programming languages is essential for effective software development and maintenance. They are often tested only as an afterthought. Languages with a smaller scope, such as domain-specific languages, often remain untested. General-purpose testing techniques and test case generation methods fall short in providing a low-threshold solution for test-driven language development. In this paper we introduce the notion of a language-parametric testing language (LPTL) that provides a reusable, generic basis for declaratively specifying language definition tests. We integrate the syntax, semantics, and editor services of a language under test into the LPTL for writing test inputs. This paper describes the design of an LPTL and the tool support provided for it, shows use cases using examples, and describes our implementation in the form of\u00a0\u2026", "num_citations": "25\n", "authors": ["1605"]}
{"title": "Combining aspect-oriented and strategic programming\n", "abstract": " Properties such as logging, persistence, debugging, tracing, distribution, performance monitoring and exception handling occur in most programming paradigms and are normally very difficult or even impossible to modularize with traditional modularization mechanisms because they are cross-cutting. Recently, aspect-oriented programming has enjoyed recognition as a practical solution for separating these concerns. In this paper we describe an extension to the Stratego term rewriting language for capturing such properties. We show our aspect language offers a concise, practical and adaptable solution for dealing with unanticipated algorithm extension for forward data-flow propagation and dynamic type checking of terms. We briefly discuss some of the challenges faced when designing and implementing an aspect extension for and in a rule-based term rewriting system.", "num_citations": "25\n", "authors": ["1605"]}
{"title": "A case study in optimizing parsing schemata by disambiguation filters\n", "abstract": " Disambiguation methods for context-free grammars enable concise specification of programming languages by ambiguous grammars. A disambiguation filter is a function that selects a subset from a set of parse trees the possible parse trees for an ambiguous sentence. The framework of filters provides a declarative description of disambiguation methods independent of parsing. Although filters can be implemented straightforwardly as functions that prune the parse forest produced by some generalized parser, this can be too inefficient for practical applications. In this paper the optimization of parsing schemata, a framework for high-level description of parsing algorithms, by disambiguation filters is considered in order to find efficient parsing algorithms for declaratively specified disambiguation methods. As a case study the optimization of the parsing schema of Earley\u2019s parsing algorithm by two filters is investigated. The main result is a technique for generation of efficient LR-like parsers for ambiguous grammars disambiguated by means of priorities.", "num_citations": "25\n", "authors": ["1605"]}
{"title": "Scopes as types\n", "abstract": " Scope graphs are a promising generic framework to model the binding structures of programming languages, bridging formalization and implementation, supporting the definition of type checkers and the automation of type safety proofs. However, previous work on scope graphs has been limited to simple, nominal type systems. In this paper, we show that viewing scopes as types enables us to model the internal structure of types in a range of non-simple type systems (including structural records and generic classes) using the generic representation of scopes. Further, we show that relations between such types can be expressed in terms of generalized scope graph queries. We extend scope graphs with scoped relations and queries. We introduce Statix, a new domain-specific meta-language for the specification of static semantics, based on scope graphs and constraints. We evaluate the scopes as types approach\u00a0\u2026", "num_citations": "24\n", "authors": ["1605"]}
{"title": "Mixing source and bytecode: a case for compilation by normalization\n", "abstract": " Language extensions increase programmer productivity by providing concise, often domain-specific syntax, and support for static verification of correctness, security, and style constraints. Language extensions can often be realized through translation to the base language, supported by preprocessors and extensible compilers. However, various kinds of extensions require further adaptation of a base compiler's internal stages and components, for example to support separate compilation or to make use of low-level primitives of the platform (eg, jump instructions or unbalanced synchronization). To allow for a more loosely coupled approach, we propose an open compiler model based on normalization steps from a high-level language to a subset of it, the core language. We developed such a compiler for a mixed Java and (core) bytecode language, and evaluate its effectiveness for composition mechanisms such as\u00a0\u2026", "num_citations": "24\n", "authors": ["1605"]}
{"title": "Grammar engineering support for precedence rule recovery and compatibility checking\n", "abstract": " A wide range of parser generators are used to generate parsers for programming languages. The grammar formalisms that come with parser generators provide different approaches for defining operator precedence. Some generators (e.g. YACC) support precedence declarations, others require the grammar to be unambiguous, thus encoding the precedence rules. Even if the grammar formalism provides precedence rules, a particular grammar might not use it. The result is grammar variants implementing the same language. For the C language, the GNU Compiler uses YACC with precedence rules, the C-Transformers uses SDF without priorities, while the SDF library does use priorities. For PHP, Zend uses YACC with precedence rules, whereas PHP-front uses SDF with priority and associativity declarations.The variance between grammars raises the question if the precedence rules of one grammar are\u00a0\u2026", "num_citations": "23\n", "authors": ["1605"]}
{"title": "Robust real-time synchronization between textual and graphical editors\n", "abstract": " In modern Integrated Development Environments (IDEs), textual editors are interactive and can handle intermediate, incomplete, or otherwise erroneous texts while still providing editor services such as syntax highlighting, error marking, outline views, and hover help. In this paper, we present an approach for the robust synchronization of interactive textual and graphical editors. The approach recovers from errors during parsing and text-to-model synchronization, preserves textual and graphical layout in the presence of erroneous texts and models, and provides synchronized editor services such as selection sharing and navigation between editors. It was implemented for synchronizing textual editors generated by the Spoofax language workbench and graphical editors generated by the Graphical Modeling Framework.", "num_citations": "22\n", "authors": ["1605"]}
{"title": "Designing syntax embeddings and assimilations for language libraries\n", "abstract": " Language libraries extend regular libraries with domain-specific notation. More precisely, a language library is a combination of a domain-specific language embedded in the general-purpose host language, a regular library implementing the underlying functionality, and an assimilation transformation that maps embedded DSL fragments to host language code. While the basic architecture for realizing language libraries is the same for all applications, there are many design choices to be made in the design of a particular combination of library, guest language syntax, host language, and assimilation. In this paper, we give an overview of the design space for syntax embeddings and assimilations for the realization of language libraries.", "num_citations": "22\n", "authors": ["1605"]}
{"title": "Service configuration management\n", "abstract": " The deployment of services---sets of running programs that provide some useful facility on a system or network---is typically implemented through a manual, time-consuming and error-prone process. For instance, system administrators must deploy the necessary software components, edit configuration files, start or stop processes, and so on. This is often done in an ad hoc style with no reproducibility, violating proper configuration management practices. In this paper we show that build management, software deployment and service deployment can be integrated into a single formalism. We do this in the context of the Nix software deployment system, and show that its advantages---co-existence of versions and variants, atomic upgrades and rollbacks, and component closure---extend naturally to service deployment. The approach also elegantly extends to distributed services. In addition, we show that the Nix\u00a0\u2026", "num_citations": "22\n", "authors": ["1605"]}
{"title": "Fusing a transformation language with an open compiler\n", "abstract": " Program transformation systems provide powerful analysis and transformation frameworks as well as concise languages for language processing, but instantiating them for every subject language is an arduous task, most often resulting in half-completed frontends. Compilers provide mature frontends with robust parsers and type checkers, but solving language processing problems in general-purpose languages without transformation libraries is tedious. Reusing these frontends with existing transformation systems is therefore attractive. However, for this reuse to be optimal, the functional logic found in the frontend should be exposed to the transformation system \u2013 simple data serialization of the abstract syntax tree is not enough, since this fails to expose important compiler functionality, such as import graphs, symbol tables and the type checker.In this paper, we introduce a novel and general technique for\u00a0\u2026", "num_citations": "21\n", "authors": ["1605"]}
{"title": "Spoofax: An interactive development environment for program transformation with Stratego/XT\n", "abstract": " Spoofax: An Interactive Development Environment for Program Transformation with Stratego/XT \u2014 TU Delft Research Portal Skip to main navigation Skip to search Skip to main content TU Delft Research Portal Logo Help & FAQ Home Researchers Research Units Research output Activities Datasets Press / Media Prizes Projects Search by expertise, name or affiliation Spoofax: An Interactive Development Environment for Program Transformation with Stratego/XT KT Kalleberg, E Visser Software Engineering Research output: Chapter in Book/Conference proceedings/Edited volume \u203a Conference contribution \u203a Scientific \u203a peer-review Overview Original language Undefined/Unknown Title of host publication Proceedings of the Seventh Workshop on Language Descriptions, Tools and Applications (LDTA 2007) Editors Adrian Johnstone, Tony Sloane Place of Publication Amsterdam Publisher Elsevier Pages 47-50 \u2026", "num_citations": "21\n", "authors": ["1605"]}
{"title": "CodeBoost: A framework for the transformation of C++ programs\n", "abstract": " Often we are faced with the need to make trivial, albeit tedious, changes to program code. It may be things like making variable names more readable, add code that will provide execution profile information, or change the style of a program from from expression oriented to object oriented in order to improve run-time efficiency. Such source-to-source transformations can be aided by, or even completely automatised, with the aid of a suitable program transformation tool. Here we present the CodeBoost framework for the implementation of source-to-source transformation of C++ programs. It is implemented using OpenC++ for the syntax analysis and using Stratego for de ning the program transformations. Stratego allows", "num_citations": "21\n", "authors": ["1605"]}
{"title": "Natural and flexible error recovery for generated parsers\n", "abstract": " Parser generators are an indispensable tool for rapid language development. However, they often fall short of the finesse of a hand-crafted parser, built with the language semantics in mind. One area where generated parsers have provided unsatisfactory results is that of error recovery. Good error recovery is both natural, giving recovery suggestions in line with the intention of the programmer; and flexible, allowing it to be adapted according to language insights and language changes. This paper describes a novel approach to error recovery, taking into account not only the context-free grammar, but also indentation usage. We base our approach on an extension of the SGLR parser that supports fine-grained error recovery rules and can be used to parse complex, composed languages. We take a divide-and-conquer approach to error recovery: using indentation, erroneous regions of code are identified\u00a0\u2026", "num_citations": "20\n", "authors": ["1605"]}
{"title": "Fusing logic and control with local transformations: An example optimization\n", "abstract": " Abstract programming supports the separation of logical concerns from issues of control in program construction. While this separation of concerns leads to reduced code size and increased reusability of code, its main disadvantage is the computational overhead it incurs. Fusion techniques can be used to combine the reusability of abstract programs with the efficiency of specialized programs.In this paper we illustrate some of the ways in which rewriting strategies can be used to separate the definition of program transformation rules from the strategies under which they are applied. Doing so supports the generic definition of program transformation components. Fusion techniques for strategies can then be used to specialize such generic components.We show how the generic innermost rewriting strategy can be optimized by fusing it with the rules to which it is applied. Both the optimization and the programs to\u00a0\u2026", "num_citations": "20\n", "authors": ["1605"]}
{"title": "Icedust: Incremental and eventual computation of derived values in persistent object graphs\n", "abstract": " Derived values are values calculated from base values. They can be expressed in object-oriented languages by means of getters calculating the derived value, and in relational or logic databases by means of (materialized) views. However, switching to a different calculation strategy (for example caching) in object-oriented programming requires invasive code changes, and the databases limit expressiveness by disallowing recursive aggregation. In this paper, we present IceDust, a data modeling language for expressing derived attribute values without committing to a calculation strategy. IceDust provides three strategies for calculating derived values in persistent object graphs: Calculate-on-Read, Calculate-on-Write, and Calculate-Eventually. We have developed a path-based abstract interpretation that provides static dependency analysis to generate code for these strategies. Benchmarks show that different strategies perform better in different scenarios. In addition we have conducted a case study that suggests that derived value calculations of systems used in practice can be expressed in IceDust.", "num_citations": "19\n", "authors": ["1605"]}
{"title": "Separation of Concerns and Linguistic Integration in WebDSL.\n", "abstract": " Web application development is a complex task, in which developers must address many concerns, such as user interface, data model, access control, data validation, and search. Current technology typically requires multiple languages and programming paradigms to cover these aspects. Using such domain-specific languages improves developer expressivity and lets them separate concerns. However, coupling these technologies is often less than optimal. It results in little or no consistency checking between concerns as well as wildly different language styles and paradigms\u2014from XML-style transformation languages like Extensible Style Sheet Language Transformation, to aspect languages like cascading style sheets, to object-oriented languages like Java and Java Script. WebDSL is a domain-specific language for constructing Web information systems. The language comprises sublanguages that address\u00a0\u2026", "num_citations": "19\n", "authors": ["1605"]}
{"title": "PIL: A platform independent language for retargetable DSLs\n", "abstract": " Intermediate languages are used in compiler construction to simplify retargeting compilers to multiple machine architectures. In the implementation of domain-specific languages (DSLs), compilers typically generate high-level source code, rather than low-level machine instructions. DSL compilers target a software platform, i.e. a programming language with a set of libraries, deployable on one or more operating systems. DSLs enable targeting multiple software platforms if its abstractions are platform independent. While transformations from DSL to each targeted platform are often conceptually very similar, there is little reuse between transformations due to syntactic and API differences of the target platforms, making supporting multiple platforms expensive. In this paper, we discuss the design and implementation of PIL, a Platform Independent Language, an intermediate language providing a layer of\u00a0\u2026", "num_citations": "19\n", "authors": ["1605"]}
{"title": "Retrofitting the AutoBayes program synthesis system with concrete syntax\n", "abstract": " AutoBayes is a fully automatic, schema-based program synthesis system for statistical data analysis applications. Its core component is a schema library, ie, a collection of generic code templates with associated applicability constraints which are instantiated in a problem-specific way during synthesis. Currently, AutoBayes is implemented in Prolog; the schemas thus use abstract syntax (ie, Prolog terms) to formulate the templates. However, the conceptual distance between this abstract representation and the concrete syntax of the generated programs makes the schemas hard to create and maintain. In this paper we describe how AutoBayes is retrofitted with concrete syntax. We show how it is integrated into Prolog and describe how the seamless interaction of concrete syntax fragments with AutoBayes\u2019s remaining \u201clegacy\u201d meta-programming kernel based on abstract syntax is achieved. We apply the approach to\u00a0\u2026", "num_citations": "19\n", "authors": ["1605"]}
{"title": "First-class rules and generic traversal\n", "abstract": " In this paper we present a functional language supporting first-class rules and generic traversal. This is achieved by generalizing the pattern matching constructs of standard functional languages. The case construct that ties rules together and prevents their reuse, is replaced by separate, firstclass, pattern matching rules and a choice combinator that deals with pattern match failure. Generic traversal is achieved through application pattern matching in which a constructor application is generically divided into a prefix and a suffix, thus giving generic access to the subterms of a constructor term. Many highly generic term traversals can be defined in a type-safe way using this feature.", "num_citations": "16\n", "authors": ["1605"]}
{"title": "CodeBoost-A Framework for Transforming C++ Programs\n", "abstract": " Often we are faced with the need to make trivial, albeit tedious, changes to program code. It may be things like making variable names more readable, add code that will provide execution profile information, or change the style of a program from from expression oriented to object oriented in order to improve run-time efficiency. Such source-to-source transformations can be aided by, or even completely automatised, with the aid of a suitable program transformation tool. Here we present the CodeBoost framework for the implementation of source-to-source transformation of C++ programs. It is implemented using OpenC++ for the syntax analysis and using Stratego for defining the program transformations. Stratego allows for the easy expression of context sensitive transformations, a central point when using transformations to improve execution speeds of code. We also discuss two example applications.", "num_citations": "16\n", "authors": ["1605"]}
{"title": "Intrinsically-typed definitional interpreters for linear, session-typed languages\n", "abstract": " An intrinsically-typed definitional interpreter is a concise specification of dynamic semantics, that is executable and type safe by construction. Unfortunately, scaling intrinsically-typed definitional interpreters to more complicated object languages often results in definitions that are cluttered with manual proof work. For linearly-typed languages (including session-typed languages) one has to prove that the interpreter, as well as all the operations on semantic components, treat values linearly. We present new methods and tools that make it possible to implement intrinsically-typed definitional interpreters for linearly-typed languages in a way that hides the majority of the manual proof work. Inspired by separation logic, we develop reusable and composable abstractions for programming with linear operations using dependent types. Using these abstractions, we define interpreters for linear lambda calculi with strong\u00a0\u2026", "num_citations": "15\n", "authors": ["1605"]}
{"title": "Scopes describe frames: A uniform model for memory layout in dynamic semantics\n", "abstract": " Semantic specifications do not make a systematic connection between the names and scopes in the static structure of a program and memory layout, and access during its execution. In this paper, we introduce a systematic approach to the alignment of names in static semantics and memory in dynamic semantics, building on the scope graph framework for name resolution. We develop a uniform memory model consisting of frames that instantiate the scopes in the scope graph of a program. This provides a language-independent correspondence between static scopes and run-time memory layout, and between static resolution paths and run-time memory access paths. The approach scales to a range of binding features, supports straightforward type soundness proofs, and provides the basis for a language-independent specification of sound reachability-based garbage collection.", "num_citations": "14\n", "authors": ["1605"]}
{"title": "Principled Syntactic Code Completion using Placeholders\n", "abstract": " Principled syntactic code completion enables developers to change source code by inserting code templates, thus increasing developer efficiency and supporting language exploration. However, existing code completion systems are ad-hoc and neither complete nor sound. They are not complete and only provide few code templates for selected programming languages. They also are not sound and propose code templates that yield invalid programs when inserted. This paper presents a generic framework that automatically derives complete and sound syntactic code completion from the syntax definition of arbitrary languages. A key insight of our work is to provide an explicit syntactic representation for incomplete programs using placeholders. This enables us to address the following challenges for code completion separately:(i) completing incomplete programs by replacing placeholders with code templates,(ii\u00a0\u2026", "num_citations": "14\n", "authors": ["1605"]}
{"title": "Automated evaluation of syntax error recovery\n", "abstract": " Evaluation of parse error recovery techniques is an open problem. The community lacks objective standards and methods to measure the quality of recovery results. This paper proposes an automated technique for recovery evaluation that offers a solution for two main problems in this area. First, a representative testset is generated by a mutation based fuzzing technique that applies knowledge about common syntax errors. Secondly, the quality of the recovery results is automatically measured using an oracle-based evaluation technique. We evaluate the validity of our approach by comparing results obtained by automated evaluation with results obtained by manual inspection. The evaluation shows a clear correspondence between our quality metric and human judgement.", "num_citations": "14\n", "authors": ["1605"]}
{"title": "Domain-specific language engineering\n", "abstract": " Domain-Specific Language Engineering - A Case Study in Agile DSL Development Page 1 Domain-Speci c Language Engineering A Case Study in Agile DSL Development Eelco Visser Software Engineering Research Group Delft University of Technology Netherlands July 2, 2007 GTTSE'07 Summerschool Page 2 Domain-Speci c Language Engineering Speci cally \u2022 Design and implementation of a domain-specific language for building web applications Generally \u2022 A systematic approach to designing domain-specific languages? Outline \u2022 0: The domain-specific language engineering experiment \u2022 1: Capturing programming patterns \u2022 2: Scrap your boilertemplate \u2022 3: More Sugar, please! Page 3 Part I Domain-Speci c Language Engineering (Introduction) Page 4 Domain-Speci c Languages: The Momentum Many approaches \u2022 Domain-specific languages \u2022 Model-driven architecture \u2022 Software factories \u2022 Language \u2026", "num_citations": "14\n", "authors": ["1605"]}
{"title": "The Stratego Tutorial\n", "abstract": " Stratego is a language for the specication of transformation rules and strategies for applying them. Specications consist of a collection of modules that dene the signature of the object language (s) of the transformation, transformation rules and strategies. The Stratego compiler translates specications to C code. Together with a provided run-time system these generated programs can be used to apply the specied transformations. This documents gives a tutorial for Stratego. It introduces the constructs of the language, presents common architectures for transformation systems, outlines the library of specications that comes with the language, explains several example specications and a instructions for installation and usage of the implementation.", "num_citations": "14\n", "authors": ["1605"]}
{"title": "Scalable incremental building with dynamic task dependencies\n", "abstract": " Incremental build systems are essential for fast, reproducible software builds. Incremental build systems enable short feedback cycles when they capture dependencies precisely and selectively execute build tasks efficiently. A much overlooked feature of build systems is the expressiveness of the scripting language, which directly influences the maintainability of build scripts. In this paper, we present a new incremental build algorithm that allows build engineers to use a full-fledged programming language with explicit task invocation, value and file inspection facilities, and conditional and iterative language constructs. In contrast to prior work on incrementality for such programmable builds, our algorithm scales with the number of tasks affected by a change and is independent of the size of the software project being built. Specifically, our algorithm accepts a set of changed files, transitively detects and re-executes\u00a0\u2026", "num_citations": "13\n", "authors": ["1605"]}
{"title": "FlowSpec: declarative dataflow analysis specification\n", "abstract": " We present FlowSpec, a declarative specification language for the domain of dataflow analysis. FlowSpec has declarative support for the specification of control flow graphs of programming languages, and dataflow analyses on these control flow graphs. We define the formal semantics of FlowSpec, which is rooted in Monotone Frameworks. We also discuss a prototype implementation of the language, built in the Spoofax Language Workbench. Finally, we evaluate the expressiveness and conciseness of the language with two case studies. These case studies are analyses for Green-Marl, an industrial, domain-specific language for graph processing. The first case study is a classical dataflow analysis, scaled to this full language. The second case study is a domain-specific analysis of Green-Marl.", "num_citations": "13\n", "authors": ["1605"]}
{"title": "Unifying and generalizing relations in role-based data modeling and navigation\n", "abstract": " Object-oriented programming languages support concise navigation of relations represented by references. However, relations are not first-class citizens and bidirectional navigation is not supported. The relational paradigm provides first-class relations, but with bidirectional navigation through verbose queries. We present a systematic analysis of approaches to modeling and navigating relations. By unifying and generalizing the features of these approaches, we developed the design of a data modeling language that features first-class relations, n-ary relations, native multiplicities, bidirectional relations and concise navigation.", "num_citations": "13\n", "authors": ["1605"]}
{"title": "Generating database migrations for evolving web applications\n", "abstract": " WebDSL is a domain-specific language for the implementation of dynamic web applications with a rich data model. It provides developers with object-oriented data modeling concepts but abstracts over implementation details for persisting application data in relational databases. When the underlying data model of an application evolves, persisted application data has to be migrated. While implementing migration at the database level breaks the abstractions provided by WebDSL, an implementation at the data model level requires to intermingle migration with application code. In this paper, we present a domain-specific language for the coupled evolution of data models and application data. It allows to specify data model evolution as a separate concern at the data model level and can be compiled to migration code at the database level. Its linguistic integration with WebDSL enables static checks for evolution\u00a0\u2026", "num_citations": "13\n", "authors": ["1605"]}
{"title": "The stratego library\n", "abstract": " Permission is granted to make and distribute verbatim copies of this manual provided the copyright notice and this permission notice are preserved on all copies. Permission is granted to copy and distribute modied versions of this manual under the conditions for verbatim copying, provided that they are marked clearly as modied versions, that the author&# 039; s names and title are unchanged (though subtitles and additional authors &# 039; names may be added), and that other clearly marked sections held under separate copyright are reproduced under the conditions given within them, and that the entire resulting derived work is distributed under the terms of a permission notice identical to this one. Permission is granted to copy and distribute translations of this manual into another language, under the above conditions for modied versions, except that this permission notice may be stated in a translation approved by the Free Software Foundation. Address:", "num_citations": "13\n", "authors": ["1605"]}
{"title": "A language generic solution for name binding preservation in refactorings\n", "abstract": " The implementation of refactorings for new languages requires considerable effort from the language developer. We aim at reducing that effort by using language generic techniques. This paper focuses on behavior preservation, in particular the preservation of static name bindings. To detect name binding violations, we implement a technique that reuses the name analysis defined in the compiler front end. Some languages offer the possibility to access variables using qualified names. As a refinement to violation detection, we show that name analysis can be defined as a reusable traversal strategy that can be applied to restore name bindings by creating qualified names. These techniques offer an efficient and reliable solution; the semantics of the language is implemented only once, with the compiler being the single source of truth. We evaluate our approach by implementing a language generic rename\u00a0\u2026", "num_citations": "12\n", "authors": ["1605"]}
{"title": "Strategies for fusing logic and control via local, application-specific transformations\n", "abstract": " Abstract programming supports the separation of logical concerns from issues of control in program construction. While this separation of concerns leads to reduced code size and increased reusability of code, its main disadvantage is the computational overhead it incurs. Fusion techniques can be used to combine the reusability of abstract programs with the efficiency of specialized programs. Stratego is a language for program transformation based on the paradigm of rewriting strategies. In Stratego, transformation rules define basic transformation steps and user-definable strategies control the application of rules to a program. Since the problem-specific rules and the highly generic strategies which apply them are kept separate, these elements can be combined in a mix-and-match fashion to produce a variety of program transformations. In some instances this separation of concerns leads to inefficient implementations.In this paper we show how such inefficiencies can be remedied using fusion. Furthermore, we show how fusion can be implemented using rewriting strategies by studying in detail the application of rewriting strategies to the fusion of the generic innermost strategy with sets of arbitrary-butspecific rewrite rules. Both the optimization and the programs to which the optimization applies are specified in Stratego. The contributions of this work are twofold. In the first place, we show how to optimize and reason about rewriting strategies, which opens up a new area of strategy optimization. In the second place, we demonstrate how such optimizations can be implemented effectively using local, application-specific transformations. These\u00a0\u2026", "num_citations": "12\n", "authors": ["1605"]}
{"title": "Testing domain-specific languages\n", "abstract": " The Spoofax testing language provides a new approach to testing domain-specific languages as they are developed. It allows test cases to be written using fragments of the language under test, providing full IDE support for writing test cases and supporting tests for language syntax, semantics, and editor services.", "num_citations": "11\n", "authors": ["1605"]}
{"title": "Generating Editors for Embedded Languages. Integrating SGLR into IMP\n", "abstract": " Integrated Development Environments (IDEs) increase productivity by providing a rich user interface and rapid feedback for a specific language. Creating an editor for a specific language is not a trivial undertaking, and is a cumbersome task even when working with an extensible framework such as Eclipse. A new IBM-guided effort, the IMP framework, relieves the IDE developer from a significant portion of the required work by providing various abstractions for this. For embedded languages, such as embedded regular expressions, SQL queries, or code generation templates, its LALR parser generator falls short, however. Scannerless parsing with SGLR enables concise, modular definition of such languages. In this paper, we present an integration of SGLR into IMP, demonstrating that a scannerless parser can be successfully integrated into an IDE. Given an SDF syntax definition, the sdf2imp tool automatically generates an editor plugin based on the IMP API, complete with syntax checking, syntax highlighting, outline view, and code folding. Using declarative domain-specific languages, these services can be customized, and using the IMP metatooling framework it can be extended with other features.", "num_citations": "11\n", "authors": ["1605"]}
{"title": "A bootstrapped compiler for strategies\n", "abstract": " Stratego is a language for the speci cation of program transformation based on rewriting strategies. The Stratego compiler is based on program transformation; it transforms a high-level Stratego speci cation via several intermediate representations to C. Several optimizations are performed on the intermediate representations. The compiler is bootstrapped, ie, it is speci ed in Stratego itself. In this paper we give an overview of the Stratego compiler: architecture; issues in the compilation of strategies; some high-lights of the speci cation; and experience with using strategies for writing program transformations.", "num_citations": "11\n", "authors": ["1605"]}
{"title": "From Box to TeX: an algebraic approach to the construction of documentation tools\n", "abstract": " We define a translation from an intermediate box language for pretty printing to TE X. This translation can be used as a back-end for pretty printers in documentation tools for programming languages. The translation is formulated in an executable algebraic specification formalism. An important aspect of the translation is the transformation of boxes according to a set of equations. These equations preserve the text formatting semantics of boxes which is also defined algebraically. New in this approach is that algebraic transformations of box terms are used to circumvent the limitations of the typesetter. The TEX generator, which translates the box language to TEX code, is a component of documentation tools generated for the programming environments developed with the ASF+ SDF meta-environment, but can also be used as a separate tool. As a case study, the construction of a typesetter for the process specification formalism PSF is shown. Keywords: typesetting, pretty printing, box la...", "num_citations": "11\n", "authors": ["1605"]}
{"title": "IceDust 2: derived bidirectional relations and calculation strategy composition\n", "abstract": " Derived values are values calculated from base values. They can be expressed with views in relational databases, or with expressions in incremental or reactive programming. However, relational views do not provide multiplicity bounds, and incremental and reactive programming require significant boilerplate code in order to encode bidirectional derived values. Moreover, the composition of various strategies for calculating derived values is either disallowed, or not checked for producing derived values which will be consistent with the derived values they depend upon. In this paper we present IceDust2, an extension of the declarative data modeling language IceDust with derived bidirectional relations with multiplicity bounds and support for statically checked composition of calculation strategies. Derived bidirectional relations, multiplicity bounds, and calculation strategies all influence runtime behavior of changes to data, leading to hundreds of possible behavior definitions. IceDust2 uses a product-line based code generator to avoid explicitly defining all possible combinations, making it easier to reason about correctness. The type system allows only sound composition of strategies and guarantees multiplicity bounds. Finally, our case studies validate the usability of IceDust2 in applications.", "num_citations": "10\n", "authors": ["1605"]}
{"title": "Polymorphic syntax definition\n", "abstract": " Context-free grammars are used in several algebraic specification formalisms instead of first-order signatures for the definition of the structure of algebras, because grammars provide better notation than signatures. The rigidity of these first-order structures enforces a choice between strongly typed structures with little genericity or generic operations over untyped structures. In two-level signatures level 1 defines the algebra of types used at level 0 providing the possibility to define polymorphic abstract data types. Two-level grammars are the grammatical counterpart of two-level signatures. This paper discusses the correspondence between context-free grammars and first-order signatures, the extension of this correspondence to two-level grammars and signatures, examples of the usage of two-level grammars for polymorphic syntax definition, a restriction of the class of two-level grammars for which the parsing\u00a0\u2026", "num_citations": "10\n", "authors": ["1605"]}
{"title": "PIE: A Domain-Specific Language for Interactive Software Development Pipelines\n", "abstract": " Context. Software development pipelines are used for automating essential parts of software engineering processes, such as build automation and continuous integration testing. In particular, interactive pipelines, which process events in a live environment such as an IDE, require timely results for low-latency feedback, and persistence to retain low-latency feedback between restarts. Inquiry. Developing an incrementalized and persistent version of a pipeline is one way to reduce feedback latency, but requires implementation of dependency tracking, cache invalidation, and other complicated and error-prone techniques. Therefore, interactivity complicates pipeline development if timeliness and persistence become responsibilities of the pipeline programmer, rather than being supported by the underlying system. Systems for programming incremental and persistent pipelines exist, but do not focus on ease of development, requiring a high degree of boilerplate, increasing development and maintenance effort. Approach. We develop Pipelines for Interactive Environments (PIE), a Domain-Specific Language (DSL), API, and runtime for developing interactive software development pipelines, where ease of development is a focus. The PIE DSL is a statically typed and lexically scoped language. PIE programs are compiled to programs implementing the API, which the PIE runtime executes in an incremental and persistent way. Knowledge. PIE provides a straightforward programming model that enables direct and concise expression of pipelines without boilerplate, reducing the development and maintenance effort of pipelines. Compiled pipeline\u00a0\u2026", "num_citations": "9\n", "authors": ["1605"]}
{"title": "Library-based model-driven software development with SugarJ\n", "abstract": " SugarJ is a Java-based programming language that provides extensible surface syntax, static analyses, and IDE support. SugarJ extensions are organized as libraries; conventional import statements suffice to activate and compose language extensions. We demonstrate how programmers can use SugarJ to modularly extend Java's syntax, semantic analyses and IDE support.", "num_citations": "9\n", "authors": ["1605"]}
{"title": "The Stratego Reference Manual\n", "abstract": " Stratego is a language for the specification of transformation rules and strategies for applying them. Specifications consist of a collection of modules that define the signature of the object language (s) of the transformation, transformation rules and strategies. The Stratego compiler translates specifications to C code. Together with a provided run-time system these generated programs can be used to apply the specified transformations.", "num_citations": "9\n", "authors": ["1605"]}
{"title": "Multi-level specifications\n", "abstract": " Algebraic speci cation and functional programming are closely related paradigms. The foundation of both paradigms is equational logic. Values are represented by terms and a program or speci cation consists of a list of equations over these terms Two terms that are equal according to a speci cation (by means of equational logic) have the same meaning and can replace each other in any context, a property called referential transparency.The paradigms di er in the aim of a program or speci cation. An algebraic specication de nes a class of algebras that satisfy its equations. A functional program on the other hand de nes a method to compute a value from an initial value by executing the equations as rewrite rules. However, this di erence is mainly one of emphasis; functional programs can be seen as algebraic speci cations that satisfy certain restrictions. Almost all speci cations in this book can be executed as rewrite systems. In spite of that, there are many technical di erences between actual formalisms. These di erences can be divided into semantics and type system.", "num_citations": "9\n", "authors": ["1605"]}
{"title": "Migrating custom DSL implementations to a language workbench (tool demo)\n", "abstract": " We present a tool architecture that supports migrating custom domain-specific language (DSL) implementations to a language workbench. We demonstrate an implementation of this architecture for models in the domains of defining component interfaces (IDL) and modeling system behavior (OIL) which are developed and used at a digital printer manufacturing company. Increasing complexity and the lack of DSL syntax and IDE support for existing implementations in Python based on XML syntax hindered their evolution and adoption. A reimplementation in Spoofax using modular language definition enables composition between IDL and OIL and introduces more concise DSL syntax and IDE support. The presented tool supports migrating to new implementations while being backward compatible with existing syntax and related tooling.", "num_citations": "7\n", "authors": ["1605"]}
{"title": "Understanding software through linguistic abstraction\n", "abstract": " In this essay, I argue that linguistic abstraction should be used systematically as a tool to capture our emerging understanding of domains of computation. Moreover, to enable that systematic application, we need to capture our understanding of the domain of linguistic abstraction itself in higher-level meta languages. The argument is illustrated with examples from the SDF, Stratego, Spoofax, and WebDSL projects in which I explore these ideas.", "num_citations": "7\n", "authors": ["1605"]}
{"title": "Adaptive code reuse by aspects, cloning and renaming\n", "abstract": " Effective code reuse is desirable, but difficult to achieve in practice, since it is often necessary to adapt code before it can be reused successfully. The good old solution to code reuse is simple: copy, paste, then edit as needed. This is a brilliant idea, except for the maintenance problems it causes. In this paper we introduce a language extension for declaratively performing adaptive code reuse at compile-time. We decompose reuse into two operations; clone existing code, and adapt it to new requirements. The clone and adapt technique allows flexible code reuse, untangled from subtyping and other irrelevant features, and without the maintenance nightmare of copy&paste programming. 1", "num_citations": "7\n", "authors": ["1605"]}
{"title": "Mobl: the new language of the mobile web\n", "abstract": " Mobl is a new language designed to declaratively construct mobile web applications. Mobl integrates languages for user interface design, styling, data modeling, querying and application logic into a single, unified language that is flexible, expressive, enables early detection of errors, and has good IDE support.", "num_citations": "6\n", "authors": ["1605"]}
{"title": "Interactive disambiguation of meta programs with concrete object syntax\n", "abstract": " In meta-programming with concrete object syntax, meta programs can be written using the concrete syntax of manipulated programs. Quotations of concrete syntax fragments and anti-quotations for meta-level expressions and variables are used to manipulate the abstract representation of programs. These small, isolated fragments are often ambiguous and must be explicitly disambiguated with quotation tags or types, using names from the non-terminals of the object language syntax. Discoverability of these names has been an open issue, as they depend on the (grammar) implementation and are not part of the concrete syntax of a language. Based on advances in interactive development environments, we introduce interactive disambiguation to address this issue, providing real-time feedback and proposing quick fixes in case of ambiguities.", "num_citations": "6\n", "authors": ["1605"]}
{"title": "The Stratego Compiler\n", "abstract": " Permission is granted to make and distribute verbatim copies of this manual provided the copyright notice and this permission notice are preserved on all copies. Permission is granted to copy and distribute modied versions of this manual under the conditions for verbatim copying, provided that they are marked clearly as modied versions, that the author&# 039; s names and title are unchanged (though subtitles and additional authors &# 039; names may be added), and that other clearly marked sections held under separate copyright are reproduced under the conditions given within them, and that the entire resulting derived work is distributed under the terms of a permission notice identical to this one. Permission is granted to copy and distribute translations of this manual into another language, under the above conditions for modied versions, except that this permission notice may be stated in a translation approved by the Free Software Foundation. Address:", "num_citations": "6\n", "authors": ["1605"]}
{"title": "Character classes\n", "abstract": " Character classes are used in syntax de nition formalisms as compact representations of sets of characters. A character class is a list of characters and ranges of characters. For instance, A-Z0-9] describes the set containing all uppercase characters and all digits. One set of characters can be represented in many ways with character classes. In this paper an algebraic speci cation of character classes is presented. We de ne a normalization of character classes that results in unique, most compact normal forms such that equality of character classes becomes syntactic equality of their normal forms.", "num_citations": "6\n", "authors": ["1605"]}
{"title": "Asf+Sdf'95: a workshop on Generating Tools from Algebraic Specifications\n", "abstract": " Asf+Sdf'95: a workshop on Generating Tools from Algebraic Specifications University of Amsterdam University of Amsterdam UvA Terms of use Contact UvA-DARE (Digital Academic Repository) Home Advanced Search Browse My selection Search UvA-DARE Author MGJ van den Brand A. van Deursen TB Dinesh JFTh. Kamperman E. Visser [Unknown] (editors) Year 1995 Title Asf+Sdf'95: a workshop on Generating Tools from Algebraic Specifications Publisher CWI Series Technical Report, P9504 Document type Report Faculty Faculty of Science (FNWI) Institute Informatics Institute (IVI) Language Undefined/Unknown Persistent Identifier https://hdl.handle.net/11245/1.118070 Disclaimer/Complaints regulations If you believe that digital publication of certain material infringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. In case of a legitimate complaint, the Library will \u2026", "num_citations": "6\n", "authors": ["1605"]}
{"title": "Multi-purpose syntax definition with SDF3\n", "abstract": " SDF3 is a syntax definition formalism that extends plain context-free grammars with features such as constructor declarations, declarative disambiguation rules, character-level grammars, permissive syntax, layout constraints, formatting templates, placeholder syntax, and modular composition. These features support the multi-purpose interpretation of syntax definitions, including derivation of type schemas for abstract syntax tree representations, scannerless generalized parsing of the full class of context-free grammars, error recovery, layout-sensitive parsing, parenthesization and formatting, and syntactic completion. This paper gives a high level overview of SDF3 by means of examples and provides a guide to the literature for further details.", "num_citations": "5\n", "authors": ["1605"]}
{"title": "Towards language-parametric semantic editor services based on declarative type system specifications (Brave new idea paper)\n", "abstract": " Editor services assist programmers to more effectively write and comprehend code. Implementing editor services correctly is not trivial. This paper focuses on the specification of semantic editor services, those that use the semantic model of a program. The specification of refactorings is a common subject of study, but many other semantic editor services have received little attention. We propose a language-parametric approach to the definition of semantic editor services, using a declarative specification of the static semantics of the programming language, and constraint solving. Editor services are specified as constraint problems, and language specifications are used to ensure correctness. We describe our approach for the following semantic editor services: reference resolution, find usages, goto subclasses, code completion, and the extract definition refactoring. We do this in the context of Statix, a constraint language for the specification of type systems. We investigate the specification of editor services in terms of Statix constraints, and the requirements these impose on a suitable solver.", "num_citations": "5\n", "authors": ["1605"]}
{"title": "A scalable infrastructure for teaching concepts of programming languages in Scala with WebLab: An experience report\n", "abstract": " In this paper, we report on our experience in teaching a course on concepts of programming languages at TU Delft based on Krishnamurthi\u2019s PAPL book with the definitional interpreter approach using Scala as meta-language and using the WebLab learning management system. In particular, we discuss our experience with encoding of definitional interpreters in Scala using case classes, pattern matching, and recursive functions; offering this material in the web-based learning management system WebLab; automated grading and feedback of interpreter submissions using unit tests; testing tests to force students to formulate tests, instead of just implementing interpreters; generation of tests based on a reference implementation to reduce the effort of producing unit tests; and the construction of a product line of interpreters in order to maximize reuse and consistency between reference implementations.", "num_citations": "5\n", "authors": ["1605"]}
{"title": "Bootstrapping  Domain-Specific  Meta-Languages in  Language  Workbenches\n", "abstract": " It is common practice to bootstrap compilers of programming languages. By using the compiled language to implement the compiler, compiler developers can code in their own high-level language and gain a large-scale test case. In this paper, we investigate bootstrapping of compiler-compilers as they occur in language workbenches. Language workbenches support the development of compilers through the application of multiple collaborating domain-specific meta-languages for defining a language's syntax, analysis, code generation, and editor support. We analyze the bootstrapping problem of language workbenches in detail, propose a method for sound bootstrapping based on fixpoint compilation, and show how to conduct breaking meta-language changes in a bootstrapped language workbench. We have applied sound bootstrapping to the Spoofax language workbench and report on our experience.", "num_citations": "5\n", "authors": ["1605"]}
{"title": "Separation of concerns in language definition\n", "abstract": " Effectively applying linguistic abstraction to emerging domains of computation requires the ability to rapidly develop software languages. However, a software language is a complex software system in its own right and can take significant effort to design and implement. We are currently investigating a radical separation of concerns in language definition by designing high-level declarative meta-languages specialized to the various concerns of language definition that can be used as the single source of production quality (incremental) semantic operations and as a model for reasoning about language properties.", "num_citations": "5\n", "authors": ["1605"]}
{"title": "The Nix Build Farm: A declarative approach to continuous integration\n", "abstract": " There are many tools to support continuous integration (the process of automatically and continuously building a project from a version management repository). However, they do not have good support for variability in the build environment: dependencies such as compilers, libraries or testing tools must typically be installed manually on all machines on which automated builds are performed. The Nix package manager solves this problem: it has a purely functional language for describing package build actions and their dependencies, allowing the build environment for projects to be produced automatically and deterministically. We have used Nix to build a continuous integration tool, the Nix build farm, that is in use to continuously build and release a large set of projects.", "num_citations": "5\n", "authors": ["1605"]}
{"title": "Strategic Graph Rewriting Transforming and Traversing Terms with References\n", "abstract": " Some transformations and many analyses on programs are either difficult or unnatural to express using terms. In particular, analyses that involve type contexts, call-or control flow graphs are not easily captured in term rewriting systems. In this paper, we describe an extension to the System S term rewriting system that adds references. We show how references are used for graph rewriting, how we can express more transformations with graph-like structures using only local matching, and how references give a representation that is more natural for structures that are inherently graph-like. Furthermore, we discuss trade-offs of this extension, such as changed traversal termination and unexpected impact of reference rebinding. 1", "num_citations": "5\n", "authors": ["1605"]}
{"title": "Transformations for abstractions\n", "abstract": " The transformation language Stratego provides high-level abstractions for implementation of a wide range of transformations. Our aim is to integrate transformation in the software development process and make it available to programmers. This requires the transformations provided by the programming environment to be extensible. This paper presents a case study in the implementation of extensible programming environments using Stratego, by developing a small collection of language extensions and several typical transformations for these languages.", "num_citations": "5\n", "authors": ["1605"]}
{"title": "The Asf+ Sdf Meta-environment documentation tools for free\n", "abstract": " Introduction Algebraic specifications can be used for the specification of various aspects of programming languages. The executability of the specifications provides not only a mechanism for rapid prototyping, but also tools that can be connected to a programming environment for the language specified. Over the last 10 years, the programming environments group at CWI and UvA in Amsterdam has conducted research on the generation of programming environments from formal specifications. The main results of this research are:", "num_citations": "5\n", "authors": ["1605"]}
{"title": "Specializing a meta-interpreter: JIT compilation of Dynsem specifications on the Graal VM\n", "abstract": " DynSem is a domain-specific language for concise specification of the dynamic semantics of programming languages, aimed at rapid experimentation and evolution of language designs. DynSem specifications can be executed to interpret programs in the language under development. To enable fast turnaround during language development, we have developed a meta-interpreter for DynSem specifications, which requires minimal processing of the specification. In addition to fast development time, we also aim to achieve fast run times for interpreted programs.", "num_citations": "4\n", "authors": ["1605"]}
{"title": "Towards Zero-Overhead Disambiguation of Deep Priority Conflicts\n", "abstract": " Context Context-free grammars are widely used for language prototyping and implementation. They allow formalizing the syntax of domain-specific or general-purpose programming languages concisely and declaratively. However, the natural and concise way of writing a context-free grammar is often ambiguous. Therefore, grammar formalisms support extensions in the form of declarative disambiguation rules to specify operator precedence and associativity, solving ambiguities that are caused by the subset of the grammar that corresponds to expressions.", "num_citations": "4\n", "authors": ["1605"]}
{"title": "Deep priority conflicts in the wild: a pilot study\n", "abstract": " Context-free grammars are suitable for formalizing the syntax of programming languages concisely and declaratively. Thus, such grammars are often found in reference manuals of programming languages, and used in language workbenches for language prototyping. However, the natural and concise way of writing a context-free grammar is often ambiguous.", "num_citations": "4\n", "authors": ["1605"]}
{"title": "The spoofax name binding language\n", "abstract": " In textual software languages, names are used to identify program elements such as variables, methods, and classes. Name analysis algorithms resolve names in order to establish references between definitions and uses of names. In this poster, we present the Spoofax Name Binding Language (NBL), a declarative meta-language for the specification of name binding and scope rules, which departs from the programmatic encodings of name binding provided by regular approaches. NBL aspires to become the universal language for name binding, which can be used next to BNF definitions in reference manuals, as well as serve the generation of implementations.", "num_citations": "4\n", "authors": ["1605"]}
{"title": "Encapsulating software platform logic by aspect-oriented programming: A case study in using aspects for language portability\n", "abstract": " Software platforms such as the Java Virtual Machine or the CLR. NET virtual machine have their own ecosystem of a core programming language or instruction set, libraries, and developer community. Programming languages can target multiple software platforms to increase interoperability or to boost performance. Introducing a new compiler backend for a language is the first step towards targeting a new platform, translating the language to the platform's language or instruction set. Programs written in modern languages generally make extensive use of APIs, based on the runtime system of the software platform, introducing additional portability concerns. They may use APIs that are implemented by platform-specific libraries. Libraries may perform platform-specific operations, make direct native calls, or make assumptions about performance characteristics of operations or about the file system. This paper\u00a0\u2026", "num_citations": "4\n", "authors": ["1605"]}
{"title": "Performing systematic literature reviews with Researchr: Tool demonstration\n", "abstract": " This paper describes the workflow for performing systematic literature reviews with the researchr digital library environment.", "num_citations": "4\n", "authors": ["1605"]}
{"title": "Weaving web applications with WebDSL\n", "abstract": " WebDSL is a domain-specific language for the development of web applications that integrates data-models, user-interface models, actions, validation, access control, and workflow. The compiler verifies the consistency of applications and generates complete implementations in Java or Python. We illustrate the key concepts of the language with a small web application.", "num_citations": "4\n", "authors": ["1605"]}
{"title": "Stratego/XT tutorial\n", "abstract": " 2. Installation 2.1. What do I Need? 2.2. Instructions II. The XT Transformation Tools 3. Architecture", "num_citations": "4\n", "authors": ["1605"]}
{"title": "From context-free grammars with priorities to character class grammars\n", "abstract": " In this paper we introduce a grammar transformation that translates a context-free grammar with priorities to a character class grammar that does only generate trees without priority con icts. The transformed grammar has the property that each production corresponds to a production in the original grammar and that no extra productions are used. The parse trees over the transformed grammar are therefore isomorphic to parse trees over the original grammar.", "num_citations": "4\n", "authors": ["1605"]}
{"title": "Combinatory algebraic specification & compilation of list matching\n", "abstract": " This thesis contains an algebraic specification in ASF+ SDF of a component of a compiler for term rewrite systems (TRSs). The component transforms TRSs with rewrite rules over terms with associative lists to equivalent TRSs without rules over lists. The specification of the component is written in an extension of ASF+ SDF called Combinatory Algebraic Specification.In this chapter we give a short introduction to ASF+ SDF and the ASF+ SDF compiler project. Then we formulate the goals of this thesis and introduce the solutions for them. The chapter is concluded with a discussion of literate programming in ASF+ SDF.", "num_citations": "4\n", "authors": ["1605"]}
{"title": "Syntax and Static Semantics of Eiffel A Case Study in Algebraic Specification Techniques\n", "abstract": " An algebraic specication of the syntax and static semantics as dened in [Mey92] in the specication formalism ASF+ SDF is presented. In support of the actual typechecking modules several reusable, general purpose modules, a mechanism based on-calculus to reuse these modules, and a language to manipulate symbol tables are designed. Through this language the symbol table can be hidden from the specication of typecheck functions; the symbol table behaves like a global environment for these functions.", "num_citations": "4\n", "authors": ["1605"]}
{"title": "Flowspec: A declarative specification language for intra-procedural flow-sensitive data-flow analysis\n", "abstract": " Data-flow analysis is the static analysis of programs to estimate their approximate run-time behavior or approximate intermediate run-time values. It is an integral part of modern language specifications and compilers. In the specification of static semantics of programming languages, the concept of data-flow allows the description of well-formedness such as definite assignment of a local variable before its first use. In the implementation of compiler back-ends, data-flow analyses inform optimizations. Data-flow analysis has an established theoretical foundation. What lags behind is implementations of data-flow analysis in compilers, which are usually ad-hoc. This makes such implementations difficult to extend and maintain. In previous work researchers have proposed higher-level formalisms suitable for whole-program analysis in a separate tool, incremental analysis within editors, or bound to a specific intermediate\u00a0\u2026", "num_citations": "3\n", "authors": ["1605"]}
{"title": "From definitional interpreter to symbolic executor\n", "abstract": " Symbolic execution is a technique for automatic software validation and verification. New symbolic executors regularly appear for both existing and new languages and such symbolic executors are generally manually (re) implemented each time we want to support a new language. We propose to automatically generate symbolic executors from language definitions, and present a technique for mechanically (but as yet, manually) deriving a symbolic executor from a definitional interpreter. The idea is that language designers define their language as a monadic definitional interpreter, where the monad of the interpreter defines the meaning of branch points. Developing a symbolic executor for a language is a matter of changing the monadic interpretation of branch points. In this paper, we illustrate the technique on a language with recursive functions and pattern matching, and use the derived symbolic executor to\u00a0\u2026", "num_citations": "3\n", "authors": ["1605"]}
{"title": "Scopes and frames improve meta-interpreter specialization\n", "abstract": " DynSem is a domain-specific language for concise specification of the dynamic semantics of programming languages, aimed at rapid experimentation and evolution of language designs. To maintain a short definition-to-execution cycle, DynSem specifications are meta-interpreted. Meta-interpretation introduces runtime overhead that is difficult to remove by using interpreter optimization frameworks such as the Truffle/Graal Java tools; previous work has shown order-of-magnitude improvements from applying Truffle/Graal to a meta-interpreter, but this is still far slower than what can be achieved with a language-specific interpreter. In this paper, we show how specifying the meta-interpreter using scope graphs, which encapsulate static name binding and resolution information, produces much better optimization results from Truffle/Graal. Furthermore, we identify that JIT compilation is hindered by large numbers of calls between small polymorphic rules and we introduce rule cloning to derive larger monomorphic rules at run time as a countermeasure. Our contributions improve the performance of DynSem-derived interpreters to within an order of magnitude of a handwritten language-specific interpreter.", "num_citations": "3\n", "authors": ["1605"]}
{"title": "Migrating business logic to an incremental computing DSL: a case study\n", "abstract": " To provide empirical evidence to what extent migration of business logic to an incremental computing language (ICL) is useful, we report on a case study on a learning management system. Our contribution is to analyze a real-life project, how migrating business logic to an ICL affects information system validatability, performance, and development effort.", "num_citations": "3\n", "authors": ["1605"]}
{"title": "Declarative specification of indentation rules: a tooling perspective on parsing and pretty-printing layout-sensitive languages\n", "abstract": " In layout-sensitive languages, the indentation of an expression or statement can influence how a program is parsed. While some of these languages (eg, Haskell and Python) have been widely adopted, there is little support for software language engineers in building tools for layout-sensitive languages. As a result, parsers, pretty-printers, program analyses, and refactoring tools often need to be handwritten, which decreases the maintainability and extensibility of these tools. Even state-of-the-art language workbenches have little support for layout-sensitive languages, restricting the development and prototyping of such languages.", "num_citations": "3\n", "authors": ["1605"]}
{"title": "When Frameworks Let You Down: Platform-Imposed Constraints on the Design and Evolution of Domain-Specific Languages\n", "abstract": " Application frameworks encapsulate knowledge of a particular domain in a reusable library. However, based on a general-purpose language, these do not provide notational constructs for the particular domain, and are limited to the static checks of the host language. Verification of correctness, security, and style constraints, and optimizations in terms of the application domain are not possible or very hard. It is common practice to build a Domain-Specific Language (DSL) as a thin abstraction layer over a framework, providing domain-specific notations and enabling analysis and reasoning at the level of these constructs (5; 6). Using an established application framework as the platform for a DSL helps in the understanding the domain, and supports reuse of the domain knowledge gathered by the framework developers. By means of a reference application, a small application implemented using the framework, it is possible to identify the basic operations that are important for the domain, and map these to language constructs. Rather than designing a complete DSL \u201con paper,\u201d before its implementation, it is good practice to incrementally build higher-level abstractions on top of the basic operations through a process of inductive design (7). This enables quick turn-around time for the development of the DSL and the subsequent gradual extension as new applications are found, and new insights into the domain are acquired.Application frameworks abstract over a lower-level platform. For instance, the Java Persistence API (JPA) abstracts over persistence operations in relational databases. As frameworks are designed for direct use by programmers\u00a0\u2026", "num_citations": "3\n", "authors": ["1605"]}
{"title": "Domain-Specific Language Engineering: A Case Study in Agile DSL Development (Mark I)\n", "abstract": " The goal of domain-specific languages (DSLs) is to increase the productivity of software engineers by abstracting from low-level boilerplate code. Introduction of DSLs in the software development process requires a smooth workflow for the production of DSLs themselves. This tutorial gives an overview of all aspects of DSL engineering: domain analysis, language design, syntax definition, code generation, deployment, and evolution, discussing research challenges on the way. The concepts are illustrated with DSLs for web applications built using several DSLs for DSL engineering: SDF for syntax definition, Stratego/XT for code generation, and Nix for software deployment.", "num_citations": "3\n", "authors": ["1605"]}
{"title": "Domain-specific language engineering. A case study in agile DSL development\n", "abstract": " CiteSeerX \u2014 Domain-specific language engineering. A case study in agile DSL development Documents Authors Tables Log in Sign up MetaCart DMCA Donate CiteSeerX logo Documents: Advanced Search Include Citations Authors: Advanced Search Include Citations Tables: DMCA Domain-specific language engineering. A case study in agile DSL development (2007) Cached Download as a PDF Download Links [swerl.tudelft.nl] Save to List Add to Collection Correct Errors Monitor Changes by Eelco Visser , Eelco Visser Citations: 3 - 0 self Summary Citations Active Bibliography Co-citation Clustered Documents Version History Share Facebook Twitter Reddit Bibsonomy OpenURL Abstract SERG Keyphrases domain-specific language engineering case study agile dsl development Powered by: Apache Solr About CiteSeerX Submit and Index Documents Privacy Policy Help Data Source Contact Us Developed \u2026", "num_citations": "3\n", "authors": ["1605"]}
{"title": "Stratego/XT 0.17\n", "abstract": " (Stratego/XT 0.16 - A Language and Toolset for Program Transformation) Page 1 Stratego/XT Kalleberg Rob Vermaas Eelco Visser Department of Information & Computing Sciences Utrecht University, The Netherlands www.stratego-language.org IBM Research January 6, 2006 Stratego/XT Project Mission Statement Create a high-level, language parametric, rule-based program transformation system, which supports a wide range of transformations, admitting efficient implementations that scale to large programs. Outline Introduction \u2022 Program transformation \u2022 Architecture of transformation systems Techniques \u2022 Rewrite rules \u2022 Concrete syntax \u2022 Rewriting strategies \u2022 Annotations \u2022 Dynamic rules Examples \u2022 Conditional lifting \u2022 Expression blocks \u2022 Unnecessary cast elimination \u2022 Constant propagation \u2022 JavaJava assimilation \u2026", "num_citations": "3\n", "authors": ["1605"]}
{"title": "Intrinsically typed compilation with nameless labels\n", "abstract": " To avoid compilation errors it is desirable to verify that a compiler is type correct\u2014i.e., given well-typed source code, it always outputs well-typed target code. This can be done intrinsically by implementing it as a function in a dependently typed programming language, such as Agda. This function manipulates data types of well-typed source and target programs, and is therefore type correct by construction. A key challenge in implementing an intrinsically typed compiler is the representation of labels in bytecode. Because label names are global, bytecode typing appears to be inherently a non-compositional, whole-program property. The individual operations of the compiler do not preserve this property, which requires the programmer to reason about labels, which spoils the compiler definition with proof terms.  In this paper, we address this problem using a new nameless and co-contextual representation of typed\u00a0\u2026", "num_citations": "2\n", "authors": ["1605"]}
{"title": "Safe-by-design in engineering: An overview and comparative analysis of engineering disciplines\n", "abstract": " In this paper, we provide an overview of how Safe-by-Design is conceived and applied in practice in a large number of engineering disciplines. We discuss the differences, commonalities, and possibilities for mutual learning found in those practices and identify several ways of putting those disciplinary outlooks in perspective. The considered engineering disciplines in the order of historically grown technologies are construction engineering, chemical engineering, aerospace engineering, urban engineering, software engineering, bio-engineering, nano-engineering, and finally cyber space engineering. Each discipline is briefly introduced, the technology at issue is described, the relevant or dominant hazards are examined, the social challenge(s) are observed, and the relevant developments in the field are described. Within each discipline the risk management strategies, the design principles promoting safety or safety awareness, and associated methods or tools are discussed. Possible dilemmas that the designers in the discipline face are highlighted. Each discipline is concluded by discussing the opportunities and bottlenecks in addressing safety. Commonalities and differences between the engineering disciplines are investigated, specifically on the design strategies for which empirical data have been collected. We argue that Safe-by-Design is best considered as a specific elaboration of Responsible Research and Innovation, with an explicit focus on safety in relation to other important values in engineering such as well-being, sustainability, equity, and affordability. Safe-by-Design provides for an intellectual venue where social science and\u00a0\u2026", "num_citations": "2\n", "authors": ["1605"]}
{"title": "Knowing when to ask: sound scheduling of name resolution in type checkers derived from declarative specifications\n", "abstract": " There is a large gap between the specification of type systems and the implementation of their type checkers, which impedes reasoning about the soundness of the type checker with respect to the specification. A vision to close this gap is to automatically obtain type checkers from declarative programming language specifications. This moves the burden of proving correctness from a case-by-case basis for concrete languages to a single correctness proof for the specification language. This vision is obstructed by an aspect common to all programming languages: name resolution. Naming and scoping are pervasive and complex aspects of the static semantics of programming languages. Implementations of type checkers for languages with name binding features such as modules, imports, classes, and inheritance interleave collection of binding information (i.e., declarations, scoping structure, and imports) and\u00a0\u2026", "num_citations": "2\n", "authors": ["1605"]}
{"title": "Constructing Hybrid Incremental Compilers for Cross-Module Extensibility with an Internal Build System\n", "abstract": " Context: Compilation time is an important factor in the adaptability of a software project. Fast recompilation enables cheap experimentation with changes to a project, as those changes can be tested quickly. Separate and incremental compilation has been a topic of interest for a long time to facilitate fast recompilation. Inquiry: Despite the benefits of an incremental compiler, such compilers are usually not the default. This is because incrementalization requires cross-cutting, complicated, and error-prone techniques such as dependency tracking, caching, cache invalidation, and change detection. Especially in compilers for languages with cross-module definitions and integration, correctly and efficiently implementing an incremental compiler can be a challenge. Retrofitting incrementality into a compiler is even harder. We address this problem by developing a compiler design approach that reuses parts of an existing non-incremental compiler to lower the cost of building an incremental compiler. It also gives an intuition into compiling difficult-to-incrementalize language features through staging. Approach: We use the compiler design approach presented in this paper to develop an incremental compiler for the Stratego term-rewriting language. This language has a set of features that at first glance look incompatible with incremental compilation. Therefore, we treat Stratego as our critical case to demonstrate the approach on. We show how this approach decomposes the original compiler and has a solution to compile Stratego incrementally. The key idea on which we build our incremental compiler is to internally use an incremental build system to\u00a0\u2026", "num_citations": "2\n", "authors": ["1605"]}
{"title": "PixieDust: Declarative Incremental User Interface Rendering Through Static Dependency Tracking\n", "abstract": " Modern web applications are interactive. Reactive programming languages and libraries are the state-of-the-art approach for declara-tively specifying these interactive applications. However, programs written with these approaches contain error-prone boilerplate code for e ciency reasons. In this paper we present PixieDust, a declarative user-interface language for browser-based applications. PixieDust uses static de-pendency analysis to incrementally update a browser-DOM at run-time, without boilerplate code. We demonstrate that applications in PixieDust contain less boilerplate code than state-of-the-art ap-proaches, while achieving on-par performance.", "num_citations": "2\n", "authors": ["1605"]}
{"title": "A theory of name resolution with extended coverage and proofs\n", "abstract": " We describe a language-independent theory for name binding and resolution, suitable for programming languages with complex scoping rules including both lexical scoping and modules. We formulate name resolution as a two stage problem. First a language-independent scope graph is constructed using language-specific rules from an abstract syntax tree. Then references in the scope graph are resolved to corresponding declarations using a language-independent resolution process. We introduce a resolution calculus as a concise, declarative, and language-independent specification of name resolution. We develop a resolution algorithm that is sound and complete with respect to the calculus. Based on the resolution calculus we develop language-independent definitions of alpha-equivalence and rename refactoring. We illustrate the approach using a small example language with modules. In addition, we show how our approach provides a model for a range of name binding patterns in existing languages.", "num_citations": "2\n", "authors": ["1605"]}
{"title": "Language-parametric name resolution based on declarative name binding and scope rules\n", "abstract": " In textual software languages, names are used to reference elements like variables, methods, classes, etc. Name resolution analyses these names in order to establish references between definition and use sites of elements. In this paper, we identify reoccurring patterns for name bindings in programming languages and introduce a declarative metalanguage for the specification of name bindings in terms of namespaces, definition sites, use sites, and scopes. Based on such declarative name binding specifications, we provide a language-parametric algorithm for static name resolution during compile-time. We discuss the integration of the algorithm into the Spoofax Language Workbench and show how its results can be employed in semantic editor services like reference resolution, constraint checking, and content completion.", "num_citations": "2\n", "authors": ["1605"]}
{"title": "Implementing Refactorings in the Spoofax Language Workbench\n", "abstract": " Spoofax is a language workbench for efficient development of textual domain-specific languages together with state-of-the-art IDE support. Spoofax integrates language and IDE development into a single environment, using concise, declarative specifications for languages and IDE services. We are extending Spoofax with a framework for the implementation of refactorings. The current paper gives an overview of the framework and demonstrates the implementation of refactorings for languages developed using Spoofax.", "num_citations": "2\n", "authors": ["1605"]}
{"title": "Gradually typing strategies\n", "abstract": " The Stratego language supports program transformation by means of term rewriting with programmable rewriting strategies. Stratego's traversal primitives support concise definition of generic tree traversals. Stratego is a dynamically typed language because its features cannot be captured fully by a static type system. While dynamic typing makes for a flexible programming model, it also leads to unintended type errors, code that is harder to maintain, and missed opportunities for optimization.", "num_citations": "1\n", "authors": ["1605"]}
{"title": "Towards language-parametric semantic editor services based on declarative type system specifications\n", "abstract": " New programming languages often lack good IDE support, as developing advanced semantic editor services takes additional effort. In previous work we discussed the operational requirements of a constraint solver that leverages the declarative type system specification of a language to provide language-parametric semantic editor services. In this work we describe the implementation of our solver as a two stage process: inference and search. An editor-service specific search strategy determines how and where the search is conducted, and when it terminates. We are currently implementing and evaluating this idea.", "num_citations": "1\n", "authors": ["1605"]}
{"title": "A constraint language for static semantic analysis based on scope graphs with proofs\n", "abstract": " In previous work, we introduced scope graphs as a formalism for describing program binding structure and performing name resolution in an AST-independent way. In this paper, we show how to use scope graphs to build static semantic analyzers. We use constraints extracted from the AST to specify facts about binding, typing, and initialization. We treat name and type resolution as separate building blocks, but our approach can handle language constructs\u2014such as record field access\u2014for which binding and typing are mutually dependent. We also refine and extend our previous scope graph theory to address practical concerns including ambiguity checking and support for a wider range of scope relationships. We describe the details of constraint generation for a model language that illustrates many of the interesting static analysis issues associated with modules and records.", "num_citations": "1\n", "authors": ["1605"]}
{"title": "Special issue on generative programming and component engineering (selected papers from GPCE 2004/2005)\n", "abstract": " Generative and component approaches have the potential to revolutionize software development in a similar way as automation and components revolutionized manufacturing. Generative Programming (developing programs that synthesize other programs), Component Engineering (raising the level of modularization and analysis in application design), and Domain-Specific Languages (elevating program specifications to compact domain-specific notations that are easier to write and maintain) are key technologies for automating program development. GPCE arose as a joint conference, merging the prior conference on Generative and Component-Based Software Engineering (GCSE) and the Workshop on Semantics, Applications, and Implementation of Program Generation (SAIG). The goal of GPCE is to provide a meeting place for researchers and practitioners interested in cutting edge approaches to software development. The conference aims to foster further cross-fertilization between the software engineering research community on the one hand, and the programming languages community on the other, in addition to supporting the original research goals of both the GCSE and the SAIG communities.This special issue features a selection of the best papers of the 2004 and 2005 editions of the conference, which appeared as Volumes 3286 and 3676 of Lectures Notes in Computer Science published by Springer-Verlag. Out of the 52 papers presented at the two conferences, the authors of 10 papers were invited to submit a revised article for this special issue. Of these submissions four articles were eventually selected for publication. In\u00a0\u2026", "num_citations": "1\n", "authors": ["1605"]}
{"title": "Automated software testing and release with nix build farms\n", "abstract": " \u25ba Main features:\u25ba Enforce correct dependency specifications.\u25ba Support concurrent variants/versions.\u25ba Safe and automatic garbage collection of unused components.\u25ba Transparent source/binary deployment model.\u25ba Atomic upgrades/rollbacks.\u25ba Simple component language with variability support.\u25ba Mechanism, not policy; lots of different deployment policies can be defined using basic Nix mechanisms (eg, channels).\u25ba Not just for software deployment but also service deployment.", "num_citations": "1\n", "authors": ["1605"]}
{"title": "Adding concrete syntax to a prolog-based program synthesis system\n", "abstract": " Program generation and transformation systems work on two language levels, the object-level (i.e., the language of the manipulated programs), and the meta-level (i.e., the implementation language of the system itself). The meta-level representations of object-level program fragments are usually built in an essentially syntax-free fashion using the operations provided by the meta-language. However, syntax matters and a large conceptual distance between the two languages makes it difficult to maintain and extend such systems. Here we describe how an existing Prolog-based system can gradually be retrofitted with concrete object-level syntax using the approach outlined in [5], thus shrinking this distance.", "num_citations": "1\n", "authors": ["1605"]}
{"title": "A C++ transformation framework\n", "abstract": " CodeBoost is a tool for source-to-source transformation and optimisation of C++ programs. It is intended to be used as a test-bed for various high-level optimisations; the traditional textbook optimisations are assumed to be handled by the C++ compiler. The CodeBoost optimiser will attempt to bridge the gap between a human-friendly coding style and current compiler/optimiser implementations. The C++ transformation framework may be useful for other projects as well\u2014it has already been used in an experimental instrumentation and profiling tool.CodeBoost is part of the Sophus project [3, 2], which explores the use of high-level abstractions for numerical applications. This has great advantages in terms of easier programming and maintenance, but slower performance has hindered the adoption of these techniques in HPC. Current compilers have proven unable to optimise sufficiently, partly due to low demand for such optimisations, and partly because some of the most effective optimisations are in conflict with the C++ standard [4, 1]. The CodeBoost optimiser gives the user control over the optimisation process. New optimisations can be added easily, and optimisations can be applied (and re-applied) in any order. Because the output is readable C++ code, it is easy to see the effects of the transformations. Three different optimisations are currently on the way, and more are planned for the future.", "num_citations": "1\n", "authors": ["1605"]}
{"title": "Configuration Space Exploration for Digital Printing Systems\n", "abstract": " Within the printing industry, much of the variety in printed applications comes from the variety in finishing. Finishing comprises the processing of sheets of paper after being printed, e.g. to form books. The configuration space of finishers, i.e. all possible configurations given the available features and hardware capabilities, are large. Current control software minimally assists operators in finding useful configurations. Using a classical modelling and integration approach to support a variety of configuration spaces is suboptimal with respect to operatability, development time, and maintenance burden.                 In this paper, we explore the use of a modeling language for finishers to realize optimizing decision making over configuration parameters in a systematic way and to reduce development time by generating control software from models.                 We present CSX, a domain-specific language for high\u00a0\u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Stateful Entities: Object-oriented Cloud Applications as Distributed Dataflows\n", "abstract": " Programming stateful cloud applications remains a very painful experience. Instead of focusing on the business logic, programmers spend most of their time dealing with distributed systems considerations, with the most important being consistency, load balancing, failure management, recovery, and scalability. At the same time, we witness an unprecedented adoption of modern dataflow systems such as Apache Flink, Google Dataflow, and Timely Dataflow. These systems are now performant and fault-tolerant, and they offer excellent state management primitives. With this line of work, we aim at investigating the opportunities and limits of compiling general-purpose programs into stateful dataflows. Given a set of easy-to-follow code conventions, programmers can author stateful entities, a programming abstraction embedded in Python. We present a compiler pipeline named StateFlow, to analyze the abstract syntax tree of a Python application and rewrite it into an intermediate representation based on stateful dataflow graphs. StateFlow compiles that intermediate representation to a target execution system: Apache Flink and Beam, AWS Lambda, Flink's Statefun, and Cloudburst. Through an experimental evaluation, we demonstrate that the code generated by StateFlow incurs minimal overhead. While developing and deploying our prototype, we came to observe important limitations of current dataflow systems in executing cloud applications at scale.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Scope States (Artifact)\n", "abstract": " Compilers that can type check compilation units in parallel can make more efficient use of multi-core architectures, which are nowadays widespread. Developing parallel type checker implementations is complicated by the need to handle concurrency and synchronization of parallel compilation units. This artifact contains benchmarks and sources for a new framework for implementing hierarchical type checkers that provides implicit parallel execution in the presence of dynamic and mutual dependencies between compilation units. The resulting type checkers can be written without explicit handling of communication or synchronization between different compilation units. We achieve this by providing type checkers with an API for name resolution based on scope graphs, a language-independent formalism that supports a wide range of binding patterns. Our framework is implemented in Java using the actor paradigm. We evaluated our approach by parallelizing the solver for Statix, a meta-language for type checkers based on scope graphs, using our framework. Benchmarks show that the approach results in speedups for the parallel Statix solver of up to 5.0 x on 8 cores for real-world code bases.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Scope States: Guarding Safety of Name Resolution in Parallel Type Checkers\n", "abstract": " Compilers that can type check compilation units in parallel can make more efficient use of multi-core architectures, which are nowadays widespread. Developing parallel type checker implementations is complicated by the need to handle concurrency and synchronization of parallel compilation units. Dependencies between compilation units are induced by name resolution, and a parallel type checker needs to ensure that units have defined all relevant names before other units do a lookup. Mutually recursive references and implicitly discovered dependencies between compilation units preclude determining a static compilation order for many programming languages. In this paper, we present a new framework for implementing hierarchical type checkers that provides implicit parallel execution in the presence of dynamic and mutual dependencies between compilation units. The resulting type checkers can be written without explicit handling of communication or synchronization between different compilation units. We achieve this by providing type checkers with an API for name resolution based on scope graphs, a language-independent formalism that supports a wide range of binding patterns. We introduce the notion of scope state to ensure safe name resolution. Scope state tracks the completeness of a scope, and is used to decide whether a scope graph query between compilation units must be delayed. Our framework is implemented in Java using the actor paradigm. We evaluated our approach by parallelizing the solver for Statix, a meta-language for type checkers based on scope graphs, using our framework. This parallelizes every Statix\u00a0\u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Safety and Completeness of Disambiguation corresponds to Termination and Confluence of Reordering\n", "abstract": " Associativity and priority are well known techniques to disambiguate expression grammars. In recent work we develop a direct semantics for disambiguation by associativity and priority rules and prove that a safe and complete disambiguation relation produces a safe and complete disambiguation. The proof approach relies on a correspondence between disambiguation and term rewriting such that safety of disambiguation corresponds to termination of the rewrite system and completeness of disambiguation correspond to confluence of the rewrite system. In this extended abstract we illustrate that approach using diagrams.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Evolution of the WebDSL runtime: Reliability engineering of the WebDSL web programming language\n", "abstract": " Web applications are ideal for implementing information systems; they can organize and persist the data in a database, do not require installation on client machines, and can be instantly updated everywhere. However, web programming is complex due to its heterogeneous nature, causing web frameworks to suffer from insufficient or leaky abstraction, weak static consistency checking, and security features that are not enforced. We developed the WebDSL web programming language, which supports direct expression of intent, strong static consistency checking, linguistic abstractions for web programming concerns, and automatically enforces security features for web applications. We have used WebDSL for over 10 years to create information systems for academic workflows with thousands of users. Based on our experiences with these applications, we improved the WebDSL compiler and runtime to increase\u00a0\u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Evolution of the WebDSL Runtime\n", "abstract": " Web applications are ideal for implementing information systems; they can organize and persist the data in a database, do not require installation on client machines, and can be instantly updated everywhere. However, web programming is complex due to its heterogeneous nature, causing web frameworks to suffer from insufficient or leaky abstraction, weak static consistency checking, and security features that are not enforced. We developed the WebDSL web programming language, which supports direct expression of intent, strong static consistency checking, linguistic abstractions for web programming concerns, and automatically enforces security features for web applications. We have used WebDSL for over 10 years to create information systems for academic workflows with thousands of users. Based on our experiences with these applications, we improved the WebDSL compiler and runtime to increase robustness, performance, and security of applications. In this experience report, we reflect on the lessons learned and improvements made to the language runtime.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "A research agenda for formal methods in the Netherlands\n", "abstract": " On September 3 and 4, 2018, we organized a meeting on formal methods research in the Netherlands. Goal of the meeting was to create a Dutch formal methods community, to increase awareness of each other\u2019s activities, and to find common grounds for collaborations. All researchers working on formal methods in the Netherlands were invited to contribute a 2-page abstract with their vision on the future of formal methods research. This document bundles these visions.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Toward a Language-Parametric Code Completion Editor Service\n", "abstract": " Code completion is an editor service that suggests keywords and identifiers that are relevant at the caret location in the editor, from which the user can choose to either insert one or continue typing. This reduces coding errors and aids in discovering the possibilities in a language or API. Providing a code completion editor service for a new programming language requires development effort in addition to the effort required for defining the language. The goal of this work is to automatically produce an intelligent editor-agnostic code completion editor service that is parameterized only by the declarative specification of the language. We implement our approach in the Spoofax language workbench, which enables language developers to provide a declarative specification of their new programming language. We will use the declarative specification to produce a platform-agnostic code completion editor service for Spoofax languages automatically.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Towards Incremental Compilation for Stratego\n", "abstract": " Stratego is a transformation language based on term rewriting with programmable rewriting strategies. A program in Stratego consists of named rewrite rules and strategies. When definitions have the same name, they contribute to the same rule. This works across files, thereby allowing extensibility.Due to this distribution of rules over modules, the Stratego compiler has always been a whole program compiler. Large Stratego programs are slow to compile as a result. In this work we present our approach to incremental compilation of Stratego. The approach may be useful for incremental compilation of other languages with similar cross-file features.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "The semantics of name resolution in grace\n", "abstract": " Grace is a dynamic object oriented programming language designed to aid programming education. We present a formal model of and give an operational semantics for its object model and name resolution algorithm. Our main contributions are a systematic model of Grace\u2019s name resolution using scope graphs, relating linguistic features to other languages, and an operationalization of this model in the form of an operational semantics which is readable and executable. The semantics are extensively tested against a reference Grace implementation.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "IceDust 2: Derived Bidirectional Relations and Calculation Strategy Composition (Artifact)\n", "abstract": " This artifact is based on IceDust2, a data modeling language with derived values. The provided package is designed to support the claims of the companion paper: in particular, it allows users to compile and run IceDust2 specifications. Instructions for building the IceDust2 compiler from source in Spoofax are also provided.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Conf. Researchr. Org: towards a domain-specific content management system for managing large conference websites\n", "abstract": " Federated conferences such as SPLASH are complex organizations composed of many parts (co-located conferences, symposia, and workshops), and are put together by many different people and committees. Developing the website for such a conference requires a considerable effort, and is often reinvented for each edition of a conference using software that provides little to no support for the domain. In this paper, we give a high-level overview of the design of Conf. Researchr. Org, a domain-specific content management system developed to support the production of large conference web sites, which is being used for the federated conferences of ACM SIGPLAN.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Dagstuhl Reports, Vol. 5, Issue 2 ISSN 2192-5283\n", "abstract": " In this report, the program, research issues, and results of Dagstuhl Seminar 15061 \u201cNon-Zero-Sum-Games and Control\u201d are described. The area of non-zero-sum games is addressed in a wide range of topics: multi-player games, partial-observation games, quantitative game models, and\u2013as a special focus\u2013connections with control engineering (supervisory control).", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Language-Independent Type-Dependent Name Resolution\n", "abstract": " We extend and combine two existing declarative formalisms, the scope graphs of Neron et al. and type constraint systems, to build a language-independent theory that can describe both name and type resolution for realistic languages with complex scope and typing rules. Unlike conventional static semantics presentations, our approach maintains a clear separation between scoping and typing concerns, while still being able to handle language constructs, such as class field access, for which name and type resolution are necessarily intertwined. We define a constraint scheme that can express both typing and name binding constraints, and give a formal notion of constraint satisfiability together with a sound algorithm for finding solutions in important special cases. We describe the details of constraint generation for a model language that illustrates many of the interesting resolution issues associated with modules, classes, and records. Our constraint generator and solver have been implemented in the Spoofax Language Workbench.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "A search for time dependent neutrino emission from microquasars with the ANTARES telescope\n", "abstract": " A search for time dependent neutrino emission from microquasars with the ANTARES telescope IRIS nascondi/visualizza icone a destra nascondi/visualizza menu in alto Aiuto Sfoglia Scorri i prodotti per: Autore Titolo Riviste Serie Login IRIS Archivio della ricerca di Trieste Catalogo Prodotti Ricerca UNITS 1 Contributo in Rivista(Articolo Rivista) 1.1 Articolo in Rivista A search for time dependent neutrino emission from microquasars with the ANTARES telescope Italiano Italiano English A search for time dependent neutrino emission from microquasars with the ANTARES telescope / Trovato, A; S., Adri\u00e1n-Mart\u00ednez; A., Albert; M., Andr\u00e9; M., Anghinolfi; G., Anton; M., Ardid; T., Astraatmadja; Aubert, J. -J.; B., Baret; J., Barrios; S., Basa; V., Bertin; S., Biagi; C., Bigongiari; C., Bogazzi; B., Bouhou; Bouwhuis, MC; J., Brunner; J., Busto; A., Capone; L., Caramete; C., C\u00e2rloganu; J., Carr; S., Cecchini; Z., Charif; P., Charvis; T., \u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "LWC 2014: The Spoofax Language Workbench\n", "abstract": " The Spoofax language workbench [4] is a platform for the development of textual software languages with state-of-the-art IDE support. Spoofax provides a comprehensive environment that integrates syntax definition, name binding, type analysis, program transformation, code generation, and declarative specification of IDE components. It supports agile language design by allowing incremental, iterative development of languages and showing editors for the language under development alongside its definition.Spoofax provides high-level DSLs for language design. Spoofax\u2019testing language [3] enables test-driven language design. The syntax definition formalism SDF3 [6] supports modular definition of languages. The name binding language NaBL [5] enables declarative definitions of name binding and scope rules of languages. The new type system specification language TS allows for declarative definitions of static typing rules of languages. The Stratego transformation language [1] unifies model transformation and code generation. Spoofax derives full-featured Eclipse editor plugins from such high-level language specifications. Spoofax itself is integrated into Eclipse by bootstrapping its language design DSLs.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "First search for neutrinos in correlation with gamma-ray bursts with the ANTARES neutrino telescope\n", "abstract": " First search for neutrinos in correlation with gamma-ray bursts with the ANTARES neutrino telescope IRIS nascondi/visualizza icone a destra nascondi/visualizza menu in alto Aiuto Sfoglia Scorri i prodotti per: Autore Titolo Riviste Serie Login IRIS Archivio della ricerca di Trieste Catalogo Prodotti Ricerca UNITS 1 Contributo in Rivista(Articolo Rivista) 1.1 Articolo in Rivista First search for neutrinos in correlation with gamma-ray bursts with the ANTARES neutrino telescope Italiano Italiano English First search for neutrinos in correlation with gamma-ray bursts with the ANTARES neutrino telescope / Antares, Collaboration; S., Adri\u00e1n-Mart\u00ednez; I., Al Samarai; A., Albert; M., Andr\u00e9; M., Anghinolfi; G., Anton; S., Anvar; M., Ardid; T., Astraatmadja; Aubert, J. -J.; B., Baret; S., Basa; V., Bertin; S., Biagi; C., Bigongiari; C., Bogazzi; M., Bou-Cabo; B., Bouhou; Bouwhuis, MC; J., Brunner; J., Busto; A., Capone; C., C\u00e2rloganu; J., Carr; S., \u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Measurement of atmospheric neutrino oscillations with the ANTARES neutrino telescope\n", "abstract": " Measurement of atmospheric neutrino oscillations with the ANTARES neutrino telescope IRIS nascondi/visualizza icone a destra nascondi/visualizza menu in alto Aiuto Sfoglia Scorri i prodotti per: Autore Titolo Riviste Serie Login IRIS Archivio della ricerca di Trieste Catalogo Prodotti Ricerca UNITS 1 Contributo in Rivista(Articolo Rivista) 1.1 Articolo in Rivista Measurement of atmospheric neutrino oscillations with the ANTARES neutrino telescope Italiano Italiano English Measurement of atmospheric neutrino oscillations with the ANTARES neutrino telescope / Antares, Collaboration; S., Adri\u00e1n-Mart\u00ednez; I., Al Samarai; A., Albert; M., Andr\u00e9; M., Anghinolfi; G., Anton; S., Anvar; M., Ardid; T., Astraatmadja; Aubert, J. -J.; B., Baret; S., Basa; V., Bertin; S., Biagi; C., Bigongiari; C., Bogazzi; M., Bou-Cabo; B., Bouhou; Bouwhuis, MC; J., Brunner; J., Busto; A., Capone; C., C\u00e2rloganu; J., Carr; S., Cecchini; Z., Charif; Ph., Charvis; T., \u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Natural and flexible error recovery...\n", "abstract": " Integrated development environments (IDEs) increase programmer productivity, providing rapid, interactive feedback based on the syntax and semantics of a language. Unlike conventional parsing algorithms, scannerless generalized-LR parsing supports the full set of context-free grammars, which is closed under composition, and hence can parse languages composed from separate grammar modules. To apply this algorithm in an interactive environment, this paper introduces a novel error recovery mechanism. Our approach is language-independent, and relies on automatic derivation of recovery rules from", "num_citations": "0\n", "authors": ["1605"]}
{"title": "ICMT 2011 Special Section\n", "abstract": " This JOT special section contains two carefully selected papers from the fourth edition of The International Conference on Model Transformation (ICMT 2011) held on June 27-28, 2011 in Z\u00fcrich, Switzerland.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "ONWARD! 2011\n", "abstract": " Advancing Computing as a Science & Profession about the Cover: cognitive computing, say the authors of our cover story, seeks a profound, reliable understanding of the mechanism of the mind toward developing intelligent machines. exploring the brain of the macaque monkey, their research ponders the previous work, ultimately advocating a middle path more faithful to neuroscience than to a purely abstractionist connectionist model.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Theory and Practice of Model Transformations: 4th International Conference, ICMT 2011, Zurich, Switzerland, June 27-28, 2011, Proceedings\n", "abstract": " This book constitutes the refereed proceedings of the 4th International Conference, ICMT 2011, held in Zurich, Switzerland in June 2011. The 14 revised full papers were carefully revised and selected from 51 submissions. The scope of the contributions ranges from theoretical and methodological topics to implementation issues and applications. Topics addressed are such as transformation paradigms and languages, transformation algorithms and strategies, implementation and tools, as well as applications and case studies.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Proceedings of the 4th international conference on Theory and practice of model transformations\n", "abstract": " Proceedings of the 4th international conference on Theory and practice of model transformations | Guide Proceedings ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Browse Browse Digital Library Collections More HomeBrowse by TitleProceedingsICMT'11 ABSTRACT No abstract available. Comments Login options Check if you have access through your login credentials or your institution to get full access on this article. Sign in Full Access Get this Publication Information Contributors Published in Guide Proceedings cover image ICMT'11: Proceedings of the 4th international conference on Theory and practice of model transformations June 2011 228 pages ISBN:9783642217319 Editors: Jordi Cabot , \u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Special issue on Partial Evaluation and Program Manipulation (selected papers from PEPM 2007)\n", "abstract": " Editorial: Special issue on Partial Evaluation and Program Manipulation (selected papers from PEPM 2007): Science of Computer Programming: Vol 76, No 6 ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search Science of Computer Programming Periodical Home Latest Issue Archive Authors Affiliations Award Winners More HomeBrowse by TitlePeriodicalsScience of Computer ProgrammingVol. 76, No. 6Editorial: Special issue on Partial Evaluation and Program Manipulation (selected papers from PEPM 2007) article Editorial: Special issue on Partial Evaluation and Program Manipulation (selected papers from PEPM 2007) Share on Authors: Ganesan Ramalingam profile image G. Ramalingam View Profile \u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Theory and Practice of Model Transformations\n", "abstract": " This volume contains the papers presented at the International Conference on Model Transformation (ICMT 2011) held during June 27\u201328, 2011 in Z\u00fcrich, Switzerland.Modeling is a key element in reducing the complexity of software systems during their development and maintenance. Model transformations are essential for elevating models from documentation elements to first-class artifacts of the development process. Model transformation includes model-to-text transformation to generate code from models, text-to-model transformations to parse textual representations to model representations, model extraction to derive higher-level models from legacy code, and model-to-model transformations to normalize, weave, optimize, and refactor models, as well as to translate between modeling languages.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "WIR 2011\n", "abstract": " Provides a schedule of conference events and a listing of which papers were presented in each session.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "PDS: Pull Deployment of Services\n", "abstract": " In hospital environments various services are used to assist medical staff in performing their tasks, such as retrieving patient records or viewing X-Ray images. Such environments are mostly device-oriented. For example, in order to view an X-Ray image, a doctor must use a dedicated workstation assigned for this purpose. Device-orientation has several undesirable implications:\u2022 Overcapacity and suboptimal usage. System resources are only used while accessing a service on a device.\u2022 Inflexibility in reacting to events. If a device breaks, a service may become completely inaccessible.\u2022 Deployment of services is a complicated and time-consuming process, because deploying components is performed in a semi-automatic and ad-hoc fashion. Goal Hospitals are moving from device-orientation to service-", "num_citations": "0\n", "authors": ["1605"]}
{"title": "When Frameworks Let You Down\n", "abstract": " Platform-Imposed Constraints on the Design and Evolution of Domain-Specific Languages Page 1 When Frameworks Let You Down Platform-Imposed Constraints on the Design and Evolution of Domain-Specific Languages Danny M. Groenewegen, Zef Hemel, Lennart CL Kats, Eelco Visser Page 2 When Frameworks Let You Down Platform-Imposed Constraints on the Design and Evolution of Domain-Specific Languages Danny M. Groenewegen, Zef Hemel, Lennart CL Kats, Eelco Visser Page 3 Framework DSL Page 4 Framework DSL Page 5 DSL based on Framework DSL Evolution \u2192 DSL Engineering Effort \u2191 Page 6 When Frameworks Let You Down Platform-Imposed Constraints on the Design and Evolution of Domain-Specific Languages Danny M. Groenewegen, Zef Hemel, Lennart CL Kats, Eelco Visser Page 7 Page 8 Page 9 \u2193 Page 10 DSL based on Framework DSL Evolution \u2192 DSL Engineering Effort \u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Program Transformation with Dynamic Rewrite Rules\n", "abstract": " The area of program transformation is concerned with the manipulation of the source code of programs. Since textual transformations tend to be hard to get correct, transformations are usually carried out on structured representations of programs, such as abstract syntax trees. Term rewrite rules provide a good formalism for describing simple transformations on trees. The Stratego [1] program transformation language is based on term rewriting, but extends the formalism with programmmable rewriting strategies and scoped dynamic rewrite rules.A collection of useful rewrite rules for the abstract syntax of a programming language is usually non-terminating and non-confluent. For any particular transformation a choice needs to be made from the collection of rules and the order in which they are applied. Programmable rewriting strategies [4] are programs in a domain-specific strategy language that provides combinators for combining single rewrite rules into complex transformation algorithms. While strategies provide control over the application of rules, they do not solve the problem of context-sensitivity in program transformation. Programs contain many kinds of binding relations between declarations or definitions and uses of those definitions indicated by means of identifiers. Examples include variable assignment and use, function definitions and calls, modules and imports. Program transformations need to take into account the binding relations of programs, which cannot usually be expressed with first-order rewrite rules. In Stratego, first-order terms are used to represent the abstract syntax trees of programs, using names (strings) for the\u00a0\u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Strategic Graph Rewriting\n", "abstract": " Some transformations and many analyses on programs are either difficult or unnatural to express using terms. In particular, analyses that involve type contexts, call-or control flow graphs are not easily captured in term rewriting systems. In this paper, we describe an extension to the System S term rewriting system that adds references. We show how references are used for graph rewriting, how we can express more transformations with graph-like structures using only local matching, and how references give a representation that is more natural for structures that are inherently graph-like. Furthermore, we discuss trade-offs of this extension, such as changed traversal termination and unexpected impact of reference rebinding.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Dynamic Rewrite Rules\n", "abstract": " The area of program transformation is concerned with the manipulation of the source code of programs. Since textual transformations tend to be hard to get correct, transformations are usually carried out on structured representations of programs, such as abstract syntax trees. Term rewrite rules provide a good formalism for describing simple transformations on trees. The Stratego [6, 1] program transformation language is based on term rewriting, but extends the formalism with programmmable rewriting strategies", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Design and use of aspects in rule-based programming\n", "abstract": " Recently, aspect-oriented programming has enjoyed recognition as a practical solution for an important class of separate and cross-cutting concerns. This paper shows aspects to be useful in the context of rule-based programming languages by demonstrating an adaptable term type checker and after-the-fact algorithm extension. It briefly discusses some of the challenges faced when designing and implementing an aspect extension for and in a rule-based term rewriting system.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "The Stratego/XT BibTEX Tools\u2014tool documentation\u2014\n", "abstract": " This paper provides documentation for the Stratego/XT BibTEX Tools, a collection of tools for processing BibTEX bibliography files. The main tools in the collection are bib-to-html for generating a sectioned publication list from a BibTEX file according to selection criteria and a layout template, and aux-to-bib for extracting a BibTEX file based on the citations in a LATEX document.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "and Dependent Dynamic Rewrite Rules\n", "abstract": " Data-flow transformations used in optimizing compilers are also use-ful in other programming tools such as code generators, aspect weavers, domain-specific optimizers, and refactoring tools. These applications require source-tosource transformations rather than transformations on a low-level intermediate representation. In this paper we describe the composition of source-to-source data-flow transformations in the program transformation language Stratego. The language supports the high-level specification of transformations by means of rewriting strategy combinators that allow a natural modeling of data-and control-flow without committing to a specific source language. Data-flow facts are prop-agated using dynamic rewriting rules. In particular, we introduce the concept of dependent dynamic rewrite rules for modeling the dependencies of data-flow facts on program entities such as variables. The approach supports the combination of analysis and transformation, the combination of multiple transformations, the combination with other types of transformations, and the correct treatment of variable binding constructs and lexical scope to avoid free variable capture.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Proceedings of the Sixth Stratego Users Day\n", "abstract": " These are the proceedings of the Sixth Stratego User Days, which were held on May 3-4, 2005 at Utrecht University. The User Days were preceded by a full day tutorial on May 2. The workshop and tutorial were supported by the Software Technology Group of the Institute for Information and Computing Sciences.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Towards Extensible Program Transformation Systems\n", "abstract": " The work on the Stratego program transformation language can be divided into two tracks. The first is concerned with high-level constructs for the support of concise and generic specification of program transformations [3, 5]. This has produced features such as generic traversal strategies, first-class pattern matching, and scoped and dependent dynamic rewrite rules. Together these features provide a rich language for concisely implementing a wide variety of program transformations including data-flow transformations, code generation, compilation, and partial evaluation.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Reusable and Adaptable Strategies for Generative Programming\n", "abstract": " We propose a technique for transforming part of the object-oriented programs into structurally reusable components by our new refactoring \u201cExtract Component\u201d to realize the generative reuse of the existing programs. Our refactoring can identify and extract components composed of classes from existing OO programs, and modify the surrounding parts of extracted components in original programs. We have developed a tool that performs our technique automatically and extracts JavaBeans components from Java programs.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Stratego/XT An Annotated Bibliography\n", "abstract": " Stratego is a modular language for the specification of fully automatic program transformation systems based on the paradigm of rewriting strategies. This document presents an annotated bibliography of Stratego and closely related projects. The document is organized into sections each dealing with aspects such as language design, implementation and applications.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "REPORT SEN-E0328 DECEMBER 23, 2003\n", "abstract": " We describe a form of method-call interception (MCI) that allows the programmer to superimpose extra functionality onto method calls at run-time. We provide a reference semantics and a reference implementation for corresponding language constructs. The setup applies to class-based, statically typed, compiled languages such as Java. The semantics of MCI is used to direct a language implementation with a number of valuable properties: simplicity of the implementational model and run-time adaptation capabilities and static type safety and separate compilation and reasonable performance. Our implementational development employs sourcecode instrumentation. We start from a naive implementational model, which is subsequently refined to optimise program execution. The implementation is assessed via benchmarks.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "REPORT SEN-E0324 DECEMBER 23, 2003\n", "abstract": " In previous work, we introduced the notion of functional strategies: first-class generic functions that can traverse terms of any type while mixing uniform and type-specific behaviour. Functional strategies transpose the notion of term rewriting strategies (with coverage of traversal) to the functional programming paradigm. Meanwhile, a number of Haskell-based models and combinator suites were proposed to support generic programming with functional strategies. In the present paper, we provide a compact and matured reconstruction of functional strategies. We capture strategic polymorphism by just two primitive combinators. This is done without commitment to a specific functional language. We analyse the design space for implementational models of functional strategies. For completeness, we also provide an operational reference model for implementing functional strategies (in Haskell). We demonstrate the generality of our approach by reconstructing representative fragments of the Strafunski library for functional strategies.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Software Deployment II\n", "abstract": " \u2022 No mechanisms for announcing software as it becomes available\u2022 No unified tool for end-user to browse or find software\u2022 No information about configuration of consumer site or visualization of software dependency information\u2022 Result: software is difficult to install since it cannot adapt to the underlying system, nor can the end-user understand its requirements.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Master Program Software Technology\u2014An Overview\u2014\n", "abstract": " Master Program Software Technology \u2014 An Overview \u2014 Page 1 Master Program Software Technology \u2014 An Overview \u2014 Eelco Visser Center for Software Technology Utrecht University visser@cs.uu.nl September 5, 2002 Page 2 Master Program Software Technology: An Overview \u2022 Rest of this course \u2022 Curriculum \u2022 Broadening your horizon \u2022 Facilities \u2022 Graduating: how does it work? \u2022 Who is who Page 3 Part 1: IST (this course) \u2022 Website \u2013 http://www.cs.uu.nl/groups/ST/twiki/bin/view/Ist/WebHome \u2013 http://www.cs.uu.nl/education/vak.php?vak=st&jaar=2002 \u2022 Purpose \u2013 Overview of the main (language oriented) themes in master program \u2013 Impression of research projects of center \u2013 Advanced Haskell programming techniques \u2022 Grade \u2013 Lecturer for each part will set assignments \u2013 Average from the grades of the assignments Page 4 IST Schedule lect. topic lecturer 3 Embedding domain-specific languages in Haskell \u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Meta-programming with Concrete Object\n", "abstract": " Meta programs manipulate structured representations, i. e., abstract syntax trees, of programs. The conceptual distance between the concrete syntax meta-programmers use to reason about programs and the notation for abstract syntax manipulation provided by general pur-pose (meta-) programming languages is too great for many applications. In this paper it is shown how the syntax definition formalism SDF can be employed to fit any meta-programming language with concrete syntax notation for composing and analyzing object programs. As a case study, the addition of concrete syntax to the program transformation language Stratego is presented. The approach is then generalized to ar-bitrary meta-languages.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Transformation Based on Rewriting Strategies\n", "abstract": " Program transformation is used in many areas of software engineering. Examples include compilation, optimization, synthesis, refactoring, migration, normaliza-tion and improvement (15). Rewrite rules are a natural formalism for expressing single program transformations. However, using a standard strategy for normal-izing a program with a set of rewrite rules is not adequate for implementing program transformation systems. It may be necessary to apply a rule only in some phase of a transformation, to apply rules in some order, or to apply a rule only to part of a program. These restrictions may be necessary to avoid non-termination or to choose as pecific path in a non-confluent rewrite system.Stratego is a language for the specification of program transformation sys-tems based on the paradigm of rewriting strategies. It supports the separation of strategies from transformation rules, thus allowing careful control over the application of these rules. As a result of this separation, transformation rules are", "num_citations": "0\n", "authors": ["1605"]}
{"title": "SEN-R0116 May 31, 2001\n", "abstract": " R'SXST\u00c7\u00c9\u00f1e \u00c4gF\u00ea\u00c7\u00c9\u00c7oBED VQWXYacbs d) vcwXwi\u00d6c\u00f3s ru \u00f2aQ \u00d6X \u00d6cVXhXyi\u00c4c\u00c5aa r\u00f4 qXb \u00c9\u00d6\u00d1C\u00dc \u00e1'\u00e0\u00ea\u00e23\u00e0Q \u00eb\u00ec\u00ed \u00ee \u00f1\u00f3\u00ef\u00f3\u00f2T\u00f4\u00b6 \u00f1\u00f3d3 e\u00b6 \u00f2\u00f3\u00f1\u00f3\u00f2C fg\u00eb hji k lmonqpEr ied3 sut% mw vQmxlt% munzyr|{% p% k \u00f6g\u00f5g\u00fa'\u00f9 \u00fb\u00fc\u00f6\u00d6\u2020 \u00d6\u00f9\u00a3\u00a2 \u00a7 |\u2022 q\u00a2 o\u00b6 \u00e2\u00a2 u\u00df%\u00ae \u00eb\u00a9| \u00dfw\u00a9| \u00a7 % \u00a7 |\u2022 z\u2122 \u00f3\u00a9 o\u00ae \u00e5\u2122) u\u2122 \u00f3\u2260\u2260\u00a9| \u00c6x\u2122 \u00c9\u2022 z\u00a9|\u00ae \u00e5\u00d8\u221e \u00ec\u00a2 s\u00b6\u00b1\u2122 \u00f3\u2264\u00ae\u00ae\u2265 \u00eb\u00a9 o\u2022 z\u00a2 s%\u00a2 z\u221e \u00ec\u00a2 u\u2260\u2122 \u00f3 \u00a7 % \u00b5e\u00a2 u\u00df% g\u2265%\u00a2 o\u2022 q\u00a2 s\u2122 \u00f3\u00c6%\u00ae \u00e5\u00a9| \u00d8\u00df% \u00d8\u00df%\u2202 w o\u2122 \u00f3\u00b5 \u00a7 c\u2122 \u00f3\u00dfE\u00a2 u\u00df%\u00ae \u00e5\u00b6\u00a9| \u00df%\u00a5 \u00e9 o\u2122 \u00f3\u00df%\u00ae \u00e5\u2022 z\u00d8\u00c6%\u2211%\u00ae \u00e5\u00d8\u00df%\u2202 u\u2122 \u00f3\u00b5 \u00a7 x\u2122 \u00f3\u00df%\u00a2 u\u00df%\u00ae \u00e5\u00b6)\u00a9| u\u2022 z\u2122 \u00f3\u00b6 \u00e2\u00b6 4\u2122\u2022 q\u2202 \u00f3\u00a9| \u00df% \u00d8u\u00a9|\u00ae \u00e5\u00d8\u2122 \u00f3\u00df%\u00a9|\u2260 \u03c0 \u00c6x\u2122 \u00f3\u2211% \u00df%%\u00a9 \u00c9\u2022 q\u00d8\u00a2 u\u00b6)\u00a9 o\u2022 z\u00a2\u00a2 z\u222b'\u00a7 E\u2260 \u00d8o\u00d8 \u00a7 % E\u00a9\u00b6\u00b1\u00a2 u\u00b6 $ \u00d8\u00df6\u00ae \u00e5E\u00a2%\u00a2 \u00e5\u221e'\u00a2 u\u2260\u2122 \u00f3 \u00a7 % \u00b5\u00a2 u\u00dfEs \u00a7 |\u2022 z\u2122 Eu\u00a2 o\u00b6 \u00e2\u00b6 \u00e2\u00aa\u00ba \u00f62\u2260 \u00d8\u2202 \u00f3E\u00ae\u2265 \u00eb\u00a2 o\u00d8\u2202 \u00f3%\u00ae\u2202 \u00f3\u00a2 u\u00df%\u00a2 u\u2022 z\u00a9|\u00ae \u00e5\u00d8\u221e \u00ec\u00a2 C \u00d8\u00df%\u2264\u00ae\u2022 z\u00a9|\u00b6 \u00e2\u00ae \u00e5\u2022 z\u2211% u\u00ae \u00e5\u2211 E\u2022 q\u00a2\u00a3\u00b6 \u00e2\u2211 E \u00a7 % \u00a7 c\u2122\u2022 z\u00ae \u00e5\u00b6 \u03a9\u00ae \u00e5% \u00d8\u00b6\u00a9 \u00a7 E \u00a7 \u2022 z\u2122 \u00f3\u00a9| uC\u2265 \u00d8\u00ae \u00e5\u00ef\u00a9| \u00df\u00ef\u2122 \u00f3\u00df%\u2260 \u00d8\u00df%\u00a2 \u00e6 \u00a7 %\u00a9| u\u00f8o\u00a9|\u2202 \u00f3\u00a2 C \u00c6E\u00a9\u00b6\u00b1\u00a2 u\u00bf 4\u00a9 \u00dfE\u00a5 \u00ef\u00b6 \u00e2\u00a2 z\u221e \u00ec\u00a2 u\u2022 z\u00a9|\u2260 3\u2202 \u00f3\u00a2 u\u00dfE\u00a2 u\u2022 z\u00a9\u00ae \u00e5\u2122\u2022 z\u00b6 \u03a9\u00ae \u00e5%\u00a9|\u00ae\u00b6 \u00e2\u00d8\u00b5e \u00a7 %\u2260 \u00d8\u2264\u00a1\u00a3\u00ae \u00e5%\u00a2\u2022 u\u2122 \u00f3\u00dfE\u00b6 \u00e2\u00ae \u00e5\u2022 z\u2211% u\u00ae \u00e5\u00d8\u2122 \u00f3\u00df\u00ac\u00a9| \u00df% Pu\u2122 \u00f3\u00b5e \u00a7 c\u2122 \u00f3\u00b6\u00b1\u00d8\u00ae \u00e5\u00d8\u2122 \u00f3\u00df\u00ac\u2122 \u00f3\u2264 g u\u2122 \u00f3\u00b5 \u00a7 x\u2122 \u00f3\u00df%\u00a2 u\u00df% w \u00a7 %\u00a9| u\u00f8o\u00a9|\u2202 \u00f3\u00a2 u\u00b6\u00b1\u00aa\u221a \u00f9%\u00a2\u2022 \u00d8\u00df%\u2264 \u0192\u2022 z\u00a9\u00b6\u00b1\u00ae \u00e5\u2022 z\u2211% u\u00ae \u00e5\u2211%\u2022 z\u00a2 C\u00a2 o\u00df%\u00b6 \u00e2\u2211%\u2022 z\u00a2 u\u00b6\u00a9\u00b1\u221e'\u00a9| \u00d8\u2260\u00a9| \u00c6% \u00d8\u2260 \u00d8\u00ae\u00a1\u00bf \u00a7 c\u2122\u2022 z\u00ae \u00e5\u00a9 \u00c6E\u00d8\u2260 \u00d8\u00ae\u00a1|\u00bf X\u00a9 \u00dfE)\u00a9\u2026\u00a9 \u00a7 E\u00ae \u00e5\u00a9 \u00c6E\u00d8\u2260 \u00d8\u00ae\u00a1\u2022\u2122 \u00f3\u2264 \u00d6 u\u2122 \u00f3\u00b5 \u00a7 x\u2122 \u00f3\u00df%\u00a2 u\u00dfE\u00ae \u00e5\u00b6 g\u2265 g\u00d8\u00ae \u00e5E\u2122 \u00f3\u2211%\u2030 u\u00a2 u\u00dfE\u00ae \u00e5\u2022 q\u00a9|\u2260 \u00d8u\u00a2 uw\u2122 \u00c9\u2022 zu%\u00a2 o\u00b6 \u00e2\u00ae \u00e5\u2022 z\u00a9|\u00ae \u00e5\u00d8\u2122 \u00f3\u00df\u2122 \u00f3\u2264 \u00d6\u00ae \u00e5%\u00a2%\u00a2 z\u221e \u00ec\u00a2 u\u2260\u2122 \u00f3 \u00a7 % \u00b5\u00a2 u\u00df% 3 \u00a7 \u2022 z\u2122 cu\u00a2 u\u00b6 \u00e2\u00b6\u00b1\u00aa e\u00b6 \u00f1\u00f3\u00f1\u00f3\u00ed4 h\u00c9\u00d6\u2248\u2206 \u00c9\u00ed\u00f3ie\u00e8\u00c7\u00e3% l\u00e1 {E \u00ab\u00c9yr| k\u00e2k\u00b1\u00e1q\u00bb o\u00e4urul\u00e1\u00ed\u00f3 {\u00e9 \u00ea'\u2026 k lmui j \u00c0a\u00aa\u00ea\u00c3\u00f3\u00aa\u00ea\u00c3\u00f3\u00bf Q \u00c0a\u00aa\u00ea\u00d5\u00f3\u00aa\u00ea\u00c3\u00f3\u00bf Q \u00c0a\u00aa\u00ea\u00d5\u00f3\u00aa\u00ea\u00d5\u00f3\u00bf T \u00c03\u00aa\u00ea\u00d5\u00f3\u00aa\u00ea\u0152\u00f3\u00a0\u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Proceedings of the second stratego users day\n", "abstract": " Stratego and the underlying system S are as yet untyped. We propose a type system which covers the essence of system S. In addition to system S, a generic traversal primitive for folding the children of a term is considered. This primitive is essential for type-changing traversal strategies. The type system which we propose is based on certain signature-independent generic types. We also have to introduce a few constructs which enable us to rephrase untyped Stratego programs in a typeful manner. 1.1 Preamble We know how to type simple rewrite rules in Stratego. Let us think of a standard rst-order many-sorted type system. We can also learn from other rewriting frameworks how to provide types for (some) rewriting strategies in Stratego. The type system of ELAN, for example, is pretty close to what we need for Stratego if we want to cover strategy combinators like+,+, and;. The hard part of typing Stratego or the underlying system S is to cover the generic traversal primitives like 2 (). Therefore, we will focus on generic strategies, especially on concepts required for a corresponding type system. The extended abstract is largely driven by examples. 1.2 Examples In Figure 1.1, we illustrate four examples (I){(IV) of intentionally generic traversals. In (I), all naturals in the given tree are incremented as modelled by the rewrite rule N! succ (N). We need to turn this rule into a traversal strategy because the rule on its own is not conuent and terminating when considered as rewrite system. The strategy should be generic, that is, it should be applicable 1 CWI, Kruislaan 413, NL-1098 SJ Amsterdam, Vrije Universiteit, De Boelelaan 1081a, NL-1081 HV\u00a0\u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Warm Fusion in Stratego\n", "abstract": " \u0116tratego is a domain-specific language for the specification of program transformation systems. The design of \u0116tratego is based on the paradigm of rewriting strategies: user-definable programs in a little language of strategy operators determine where and in what order transformation rules are (automatically) applied to a program. The separation of rules and strategies supports modularity of specifications. \u0116tratego also provides generic features for specification of program traversals.In this paper we present a case study of \u0116tratego as applied to a non-trivial problem in program transformation. We demonstrate the use of \u0116tratego in eliminating intermediate data structures from (also known as deforesting) functional programs via the warm fusion algorithm of Launchbury and \u0116heard. This algorithm has been specified in \u0116tratego and embedded in a fully automatic transformation system for kernel Haskell. The entire\u00a0\u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Reduction-Based Optimizer-Initial Version\n", "abstract": " We describe a language for defining term rewriting strategies, and its application to the production of program optimizers. Valid transformations on program terms can be described by a set of rewrite rules rewriting strategies are used to describe when and how the various rules should be applied in order to obtain the desired optimization effects. Separating rules from strategies in this fashion makes it easier to reason about the behavior of the optimizer as a whole, compared to traditional monolithic optimizer implementations. We illustrate the expressiveness of our language by using it to describe a simple optimizer for an ML-like intermediate representation. The basic strategy language uses operators such as sequential composition, choice, and recursion to build transformers from a set of labeled unconditional rewrite rules. We also define an extended language in which the side-conditions and contextual rules that arise in realistic optimizer specifications can themselves be expressed as strategy-driven rewrites. We show that the features of the basic and extended languages can be expressed by breaking down the rewrite rules into their primitive building blocks, namely matching and building terms in restricted environments. This primitive representation forms the basis of a simple implementation that generates efficient C code.Descriptors:", "num_citations": "0\n", "authors": ["1605"]}
{"title": "2nd International Workshop on the Theory and Practice of Algebraic Specifications, Amsterdam 1997\n", "abstract": " User-definable strategies for the application of rewrite rules provide a means to construct transformation systems that apply rewrite rules in a controlled way. This paper describes a strategy language and its interpretation. The language is used to control the rewriting of terms using labeled rewrite rules. Rule labels are atomic strategies. Compound strategies are formed by means of sequential composition, nondeterministic choice, left choice, fixed point recursion, and two primitives for expressing term traversal. Several complex strategies such as bottom-up and top-down application and (parallel) innermost and (parallel) outermost reduction can be defined in terms of these primitives. The paper contains two case studies of the application of strategies.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Solving type equations in multi-level specifications (preliminary version)\n", "abstract": " In rst-order algebraic speci cation functions have types of the form s1 sn! s0, where the si are type constants. Such types exclude higher-order and polymorphic functions. In multi-level algebraic specication the structure of types used in function declarations is speci ed as an algebraic data type. If only free constructors are used in the types used in function declarations, type assignment is an extension of the Hindley/Milner algorithm to multiple levels of types. By means of equations over types, sophisticated type systems can be modeled in a simple and uniform language. The type assignment for arbitrary multi-level specications requires E-uni cation. Although this is undecidable in general, it is decidable for restricted sets of equations. In an earlier paper, the modular applicative multi-level equational speci cation formalism MLS is de ned. The typechecker supports only free type constructors.In this paper we introduce multi-level speci cation by means of a series of MLS examples and discuss the extension with an E-uni cation procedure instead of syntactic uni cation of the type assignment function for MLS such that it supports type de nitions, de ned type operators and recursive types.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Session details: Extensible and domain-specific languages\n", "abstract": " Session details: Extensible and domain-specific languages | Proceedings of the 12th international conference on Generative programming: concepts & experiences ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search gpce Conference Proceedings Upcoming Events Authors Affiliations Award Winners More HomeConferencesGPCEProceedingsGPCE '13Session details: Extensible and domain-specific languages section Session details: Extensible and domain-specific languages Share on Session Chair: Eelco Visser Delft University of Technology Delft University of Technology View Profile Authors Info & Affiliations GPCE '13: Proceedings of the 12th international conference on Generative programming: \u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "External links\n", "abstract": " Lennart CL Kats - researchr profile publications researchr explore Tags Journals Conferences Authors Profiles Groups calendar New Conferences Events Deadlines search You are not signed in Sign in Sign up All Publications Unidentified publications Filter by Year Filter by Type Filter by Topic Filter by Venue Filter by Co-author Filter by Top terms Download BibTeX Compact BibTeX RSS HTML YAML Compact YAML External Links Homepage DBLP ACM LinkedIn The Spoofax project Profile Name lennartclkats Statistics Publications: 37 Edited: 0 Credit: 636 Aliases LCL Kats Kats, Lennart Kats, Lennie Kats, LCL Kats, Lennart CL Kats Lennart Kats Lennart CL Kats Researchr Researchr is a web site for finding, collecting, sharing, and reviewing scientific publications, for researchers by researchers. Sign up for an account to create a profile with publication list, tag and review your related work, and share \u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "WG211/M2Visser\n", "abstract": " The work on the Stratego program transformation language can be divided into two tracks. The first is concerned with high-level constructs for the support of concise and generic specification of program transformations [3, 5]. This has produced features such as generic traversal strategies, first-class pattern matching, and scoped and dependent dynamic rewrite rules. Together these features provide a rich language for concisely implementing a wide variety of program transformations including data-flow transformations, code generation, compilation, and partial evaluation.The second track is concerned with the support for language embeddings [1, 2, 4]. Language embeddings are useful for adding domain-specific syntax to a general-purpose programming language. Applications include heterogeneous staged meta-programming (eg, generating Java in Stratego) and syntactic abstractions for domains (eg, Swul\u00a0\u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Separation of Concerns and Linguistic Integration in the WebDSL Web Programming Language\n", "abstract": " September/October 2010 IEEE SoftwarE 3 errors in data models, Seam\u2019s data modeling API puts additional constraints on data model code, which the Java type checker doesn\u2019t enforce. For instance, the Java compiler doesn\u2019t detect inconsistencies in the Java annotations. Therefore, such inconsistencies appear only when the application is in use, often resulting in long, difficult-to-interpret stack traces.Developers define user interfaces using JSF combined with HTML, CSS, and Java Script. JSF pages contain references to business logic and the data model that a compiler doesn\u2019t check; the system reports such errors only at runtime. Data model and logic references are expressed in Expression Language (EL), which looks like Java syntactically but has different semantics. For instance, the EL expression e. name, rather than accessing the e variable\u2019s name field (the expected Java behavior), calls the e variable\u2019s getName () method. Similarly, the== operator, rather than performing an equality check on the basis of references as Java does, uses the equals method to compare objects. To define access control rules, developers use a specialized JBoss Rules language that contains references to the data model and user interface. Again, inconsistencies surface only at runtime.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Journal of Computer Languages\n", "abstract": " Data-flow analysis is the static analysis of programs to estimate their approximate run-time behavior or approximate intermediate run-time values. It is an integral part of modern language specifications and compilers. In the specification of static semantics of programming languages, the concept of data-flow allows the description of well-formedness such as definite assignment of a local variable before its first use. In the implementation of compiler back-ends, data-flow analyses inform optimizations. Data-flow analysis has an established theoretical foundation. What lags behind is implementations of dataflow analysis in compilers, which are usually ad-hoc. This makes such implementations difficult to extend and maintain. In previous work researchers have proposed higher-level formalisms suitable for whole-program analysis in a separate tool, incremental analysis within editors, or bound to a specific intermediate representation.In this paper, we present FLOWSPEC, an executable formalism for specification of data-flow analysis. FLOWSPEC is a domain-specific language that enables direct and concise specification of data-flow analysis for programming languages, designed to express flow-sensitive, intra-procedural analyses. We define the formal semantics of", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Bootstrapping, Default Formatting, and Skeleton Editing in the Spoofax Language Workbench\n", "abstract": " Language workbenches are tools that help language designers to design and implement (domain-specific) programming languages, aiming to produce a full featured programming environment from a high-level language description. A recent paper, resulting from a series of language workbench challenge workshops, describes a collection of benchmark problems for language workbench research [6]. In this paper, we describe solutions to two of these benchmark problems in the Spoofax Language Workbench [7], ie default formatting in Section 3 and skeleton editing in Section 4. In addition, we introduce a new benchmark problem\u2014bootstrapping of meta-languages in a workbench\u2014and describe the support for bootstrapping we developed for Spoofax in Section 2.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Live Language Development\n", "abstract": " We would like to see live programming applied to language development, to get live language development. With live language development, a language developer gets fast feedback when they change their language, enabling experimentation with language design and development. In this paper, we describe what live language development is and why it is useful, and we analyze what is needed to achieve live language development. Moreover, we describe our work in progress in supporting live language development in the Spoofax language workbench.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Towards Live Language Development\n", "abstract": " We would like to see live programming applied to language development, to get live language development. With live language development, a language developer gets fast feedback when they change their language, enabling experimentation with language design and development. In this paper, we describe what live language development is and why it is useful, and we analyze what is needed to achieve live language development. Moreover, we describe our work in progress in supporting live language development in the Spoofax language workbench.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "A Core Language for Rewriting\n", "abstract": " System S is a calculus providing the basic abstractions of term rewriting: matching and building terms, term traversal, combining computations and handling failure. The calculus forms a core language for implementation of a wide variety of rewriting languages, or more generally, languages for specifying tree transformations. In this paper we show how a conventional rewriting language based on conditional term rewriting can be implemented straightforwardly in System S. Subsequently we show how this implementation can be extended with features such as matching conditions, negative conditions, default rules, non-strictness annotations and alternative evaluation strategies.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "XT: a bundle of program transformation tools\n", "abstract": " XT bundles existing and newly developed program transformation libraries and tools into an open framework that supports component-based development of program transformations. We discuss the roles of XT\u2019s constituents in the development process of program transformation tools, as well as some experiences with building program transformation systems with XT.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Meta-Environment: a Component-Based Language Development Environment\n", "abstract": " Meta-Environment is an interactive development environment for the automatic generation of interactive systems for constructing language denitions and generating tools for them. Over the years, this system has been used in a variety of academic and commercial projects ranging from formal program manipulation to conversion of COBOL systems. Since the existing implementation of the Meta-Environment started exhibiting more and more characteristics of a legacy system, we decided to build a completely new, component-based, version. We demonstrate this new system and stress its open architecture.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "A Domain-Specific Language for Dynamic Web Applications\n", "abstract": " http://www.webdsl.org Core WebDSL Base WebDSL WebDSL + Access Control Procedural WebWorkFlow Java/Python Web Application WebWork Page 1 http://www.webdsl.org Core WebDSL Core Data Model Core User Interface Base WebDSL Data Model User Interface WebDSL + Access Control Data Model User Interface Access Control Procedural WebWorkFlow Data Model User Interface Access Control Procedure Events Java/Python Web Application WebWorkFlow Data Model User Interface Access Control Procedure Events Workflow Danny M. Groenewegen, Zef Hemel, Lennart CL Kats, Eelco Visser References E. Visser. WebDSL: A case study in domain-specific language engineering. GTTSE (2008) Z. Hemel, LCL Kats, and E. Visser. Code Generation by Model Transformation. ICMT (2008) E. Visser, DSLs for the Web (talk). OOPSLA (2008) LCL Kats, M. Bravenboer, and E. Visser. Mixing Source and \u2026", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Fast and Safe Linguistic Abstraction for the Masses\n", "abstract": " Language workbenches support the high-level definition of (domain-specific) programming languages and the automatic derivation of implementations from such definitions. The mission of language workbench research is to increase the level of abstraction of language definitions and expand the range of tools that can be generated automatically from language definitions. In this note, I give an overview of research into language workbenches at TU Delft and the perspective of future research.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "IceDust Calculation Strategy Composition Performance in Web Applications\n", "abstract": " Derived values are values calculated from base values. They can be expressed in object-oriented languages by means of getters calculating the derived value, and in relational or logic databases by means of (materialized) views. However, switching to a different calculation strategy (for example caching) in object-oriented programming requires invasive code changes, and the databases limit expressiveness by disallowing recursive aggregation.IceDust is a data modeling language for expressing derived attribute values without committing to a calculation strategy. IceDust provides four strategies for calculating derived values in persistent object graphs: on-demand, incremental, eventual, and on-demand incremental. The first three were introduced at ECOOP last year [2]. The new strategy is inspired by Adapton [1]: it flags caches dirty transitively on writes, and only recomputes caches on reads (Figure 1). At this ECOOP we present IceDust 2 [3], which enables calculation strategy composition. For every field with a derived value a strategy can be selected. The IceDust 2 type system restricts composition to only sound composition, ensuring derived values are up to date when read (except for eventual calculation). Moreover, we have extended IceDust with inline attributes. The expressions of these attributes are inlined on their use site (and thus cannot be recursive). This allows us to control the granularity of caching in IceDust. The four strategies and inlining provide us with many possible options for calculating derived values in IceDust applications. In this extended abstract we benchmark various options for a single application under peak load.", "num_citations": "0\n", "authors": ["1605"]}
{"title": "Procedural WebWorkFlow\n", "abstract": " How WebDSL Addresses These A set of integrated core Domain Specific Languages More high-level DSLs built on top (access control, workflow) Generates Seam application with Java, JSF and XML Order of magnitude reduction in application code Abstractions transformed to core DSLs Interaction between DSLs of different abstraction levels Implemented as a model transformation pipeline", "num_citations": "0\n", "authors": ["1605"]}