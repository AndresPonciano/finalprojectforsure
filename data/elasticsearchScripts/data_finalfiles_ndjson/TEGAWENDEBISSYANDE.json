{"title": "Popularity, interoperability, and impact of programming languages in 100,000 open source projects\n", "abstract": " Programming languages have been proposed even before the era of the modern computer. As years have gone, computer resources have increased and application domains have expanded, leading to the proliferation of hundreds of programming languages, each attempting to improve over others or to address new programming paradigms. These languages range from procedural languages like C, object-oriented languages like Java, and functional languages such as ML and Haskell. Unfortunately, there is a lack of large scale and comprehensive studies that examine the \"popularity\", \"interoperability\", and \"impact\" of various programming languages. To fill this gap, this study investigates a hundred thousands of open source software projects from GitHub to answer various research questions on the \"popularity\", \"interoperability\" and \"impact\" of various languages measured in different ways (e.g., in terms of\u00a0\u2026", "num_citations": "129\n", "authors": ["344"]}
{"title": "Towards an autonomous vision-based unmanned aerial system against wildlife poachers\n", "abstract": " Poaching is an illegal activity that remains out of control in many countries. Based on the 2014 report of the United Nations and Interpol, the illegal trade of global wildlife and natural resources amounts to nearly $213 billion every year, which is even helping to fund armed conflicts. Poaching activities around the world are further pushing many animal species on the brink of extinction. Unfortunately, the traditional methods to fight against poachers are not enough, hence the new demands for more efficient approaches. In this context, the use of new technologies on sensors and algorithms, as well as aerial platforms is crucial to face the high increase of poaching activities in the last few years. Our work is focused on the use of vision sensors on UAVs for the detection and tracking of animals and poachers, as well as the use of such sensors to control quadrotors during autonomous vehicle following and autonomous landing. View Full-Text", "num_citations": "85\n", "authors": ["344"]}
{"title": "Machine learning-based malware detection for Android applications: History matters!\n", "abstract": " Machine Learning-based malware detection is a promising scalable method for identifying suspicious applications. In particular, in today\u2019s mobile computing realm where thousands of applications are daily poured into markets, such a technique could be valuable to guarantee a strong filtering of malicious apps. The success of machine-learning approaches however is highly dependent on (1) the quality of the datasets that are used for training and of (2) the appropriateness of the tested datasets with regards to the built classifiers. Unfortunately, there is scarce mention of these aspects in the evaluation of existing state-of-the-art approaches in the literature.In this paper, we consider the relevance of history in the construction of datasets, to highlight its impact on the performance of the malware detection scheme. Typically, we show that simply picking a random set of known malware to train a malware detector, as it is done in most assessment scenarios from the literature, yields significantly biased results. In the process of assessing the extent of this impact through various experiments, we were also able to confirm a number of intuitive assumptions about Android malware. For instance, we discuss the existence of Android malware lineages and how they could impact the performance of malware detection in the wild.", "num_citations": "77\n", "authors": ["344"]}
{"title": "An empirical study of adoption of software testing in open source projects\n", "abstract": " Testing is an indispensable part of software development efforts. It helps to improve the quality of software systems by finding bugs and errors during development and deployment. Huge amount of resources are spent on testing efforts. However, to what extent are they used in practice? In this study, we investigate the adoption of testing in open source projects. We study more than 20,000 non-trivial software projects and explore the correlation of test cases with various project development characteristics including: project size, development team size, number of bugs, number of bug reporters, and the programming languages of these projects.", "num_citations": "72\n", "authors": ["344"]}
{"title": "Adoption of software testing in open source projects--A preliminary study on 50,000 projects\n", "abstract": " In software engineering, testing is a crucial activity that is designed to ensure the quality of program code. For this activity, development teams spend substantial resources constructing test cases to thoroughly assess the correctness of software functionality. What is however the proportion of open source projects that include test cases? What kind of projects are more likely to include test cases? In this study, we explore 50,000 projects and investigate the correlation between the presence of test cases and various project development characteristics, including the lines of code and the size of development teams.", "num_citations": "45\n", "authors": ["344"]}
{"title": "Assessing the generalizability of code2vec token embeddings\n", "abstract": " Many Natural Language Processing (NLP) tasks, such as sentiment analysis or syntactic parsing, have benefited from the development of word embedding models. In particular, regardless of the training algorithms, the learned embeddings have often been shown to be generalizable to different NLP tasks. In contrast, despite recent momentum on word embeddings for source code, the literature lacks evidence of their generalizability beyond the example task they have been trained for. In this experience paper, we identify 3 potential downstream tasks, namely code comments generation, code authorship identification, and code clones detection, that source code token embedding models can be applied to. We empirically assess a recently proposed code token embedding model, namely code2vec's token embeddings. Code2vec was trained on the task of predicting method names, and while there is potential for\u00a0\u2026", "num_citations": "30\n", "authors": ["344"]}
{"title": "Data model evolution using object-nosql mappers: Folklore or state-of-the-art?\n", "abstract": " In big data software engineering, the schema flexibility of NoSQL document stores is a major selling point: When the document store itself does not actively manage a schema, the data model is maintained within the application. Just like object-relational mappers for relational databases, object-NoSQL mappers are part of professional software development with NoSQL document stores. Some mappers go beyond merely loading and storing Java objects: Using dedicated evolution annotations, developers may conveniently add, remove, or rename attributes from stored objects, and also conduct more complex transformations. In this paper, we analyze the dissemination of this technology in Java open source projects. While we find evidence on GitHub that evolution annotations are indeed being used, developers do not employ them so much for evolving the data model, but to solve different tasks instead. Our\u00a0\u2026", "num_citations": "19\n", "authors": ["344"]}
{"title": "Orion: a software project search engine with integrated diverse software artifacts\n", "abstract": " What projects contain more than 10, 000 lines of code developed by less than 10 people and are still actively maintained with a high bug-fixing rate? To address the challenges for answering such enquiries, we develop an integrated search engine architecture that combines information from different types of software repositories from multiple sources. Our search engine facilitates the construction and execution of complex search queries using a uniform interface that transparently correlates different artifacts of project development and maintenance, such as source code information, version control systems metadata, bug tracking systems elements, and metadata on developer activities and interactions extracted from hosting platforms. We have built an extensible system with an initial capability of over 100, 000 projects collected from the web, featuring various software development artifacts. Using scenarios, we\u00a0\u2026", "num_citations": "16\n", "authors": ["344"]}
{"title": "Leveraging the cultural model for opportunistic networking in Sub-Saharan Africa\n", "abstract": " The immense potential of ICT for improving users\u2019 livelihood has been discussed in a large body of literature and many instantiations in our daily life demonstrate this reality. In developing areas, such as Sub-Saharan Africa, ICT for development has become the frontrunner initiative that decision makers are pushing to bring millions of people out of poverty. Unfortunately, the majority of Africans, who live in rural areas, fail to identify with the existing various solutions.               We propose the Tool\u00e9 approach, which aims at vulgarizing new technologies for facilitating and automating the collection and synthesis of agricultural information. The originality of Tool\u00e9 lies in the fact that it attempts to build on the cultural values of peasants. The architecture on top of which Tool\u00e9 was built relies on cheap, yet powerful, devices and on readily available peer-to-peer protocols to deliver services whose inherent costs make\u00a0\u2026", "num_citations": "15\n", "authors": ["344"]}
{"title": "Blockchain consensus protocols\n", "abstract": " There is currently a big rush in the research and practice communities to investigate the blockchain technology towards leveraging its security, immutability and transparency features to create new services or improve existing ones. In developing countries, which are seen as a fertile ground for field testing disruptive technologies, blockchain is viewed as the \u201ctrust machine\u201d that is necessary for accelerating development. Unfortunately, the internal working of blockchain as well as its constraints are often overlooked in the design of services. This, in conjunction with a poor regulatory framework, slows down any concrete attempt to build upon the technology. In this paper, we contribute towards accelerating the concrete adoption of blockchain by making explicit the constraints that affect their practical use in the context of developing countries such as African sub-saharan countries. Overall we recommend that\u00a0\u2026", "num_citations": "13\n", "authors": ["344"]}
{"title": "Ubipan: A bluetooth extended personal area network\n", "abstract": " Most mobile devices are now Bluetooth-enabled. This wireless technology makes it possible to transfer files or stream contents between pieces of equipment. The possibly many devices that are in reach of each other and thus connected constitute a Personal Area Network (PAN). The problem remains that because of radio range setting up such connections is only possible for devices in a limited area. This paper presents the UbiPAN network infrastructure, the goal of which is to overcome this limitation. It relies on the combination of the IP network, SIP and Bluetooth. This original approach thus has been validated through a file exchange scenario between remote devices that have been seamlessly interconnected.", "num_citations": "13\n", "authors": ["344"]}
{"title": "Harvesting fix hints in the history of bugs\n", "abstract": " In software development, fixing bugs is an important task that is time consuming and cost-sensitive. While many approaches have been proposed to automatically detect and patch software code, the strategies are limited to a set of identified bugs that were thoroughly studied to define their properties. They thus manage to cover a niche of faults such as infinite loops. We build on the assumption that bugs, and the associated user bug reports, are repetitive and propose a new approach of fix recommendations based on the history of bugs and their associated fixes. In our approach, once a bug is reported, it is automatically compared to all previously fixed bugs using information retrieval techniques and machine learning classification. Based on this comparison, we recommend top-{\\em k} fix actions, identified from past fix examples, that may be suitable as hints for software developers to address the new bug.", "num_citations": "11\n", "authors": ["344"]}
{"title": "Ubigate: A gateway to transform discovery information into presence information\n", "abstract": " Pervasive computing involves various entities which need to coordinate tasks and share resources through different service discovery protocols. However, the multiplicity and the incompatibility of those protocols have made interconnectivity problematic. Moreover, most service discovery protocols require a strong participation of users to genuinely play their part. Consequently, service discovery in a pervasive environment has become a challenge that researchers as well as practitioners have tried to overcome through various approaches. Nevertheless, existing solutions mostly consist of designing new protocols which usually address specific application needs while participating in the increase of heterogeneity.", "num_citations": "10\n", "authors": ["344"]}
{"title": "An analysis of 35+ million jobs of travis ci\n", "abstract": " Travis CI handles automatically thousands of builds every day to, amongst other things, provide valuable feedback to thousands of open-source developers. In this paper, we investigate Travis CI to firstly understand who is using it, and when they start to use it. Secondly, we investigate how the developers use Travis CI and finally, how frequently the developers change the Travis CI configurations. We observed during our analysis that the main users of Travis CI are corporate users such as Microsoft. And the programming languages used in Travis CI by those users do not follow the same popularity trend than on GitHub, for example, Python is the most popular language on Travis CI, but it is only the third one on GitHub. We also observe that Travis CI is set up on average seven days after the creation of the repository and the jobs are still mainly used (60%) to run tests. And finally, we observe that 7.34% of the\u00a0\u2026", "num_citations": "8\n", "authors": ["344"]}
{"title": "Vulnerabilities of government websites in a developing country\u2013the case of Burkina Faso\n", "abstract": " Slowly, but consistently, the digital gap between developing and developed countries is being closed. Everyday, there are initiatives towards relying on ICT to simplify the interaction between citizens and their governments in developing countries. E-government is thus becoming a reality: in Burkina Faso, all government bodies are taking part in this movement with web portals dedicated to serving the public. Unfortunately, in this rush to promote government actions within this trend of digitization, little regards is given to the security of such web sites. In many cases, government highly critical web sites are simply produced in a product line fashion using Content Management Systems which the webmasters do not quite master.               We discuss in this study our findings on empirically assessing the security of government websites in Burkina Faso. By systematically scanning these websites for simple and\u00a0\u2026", "num_citations": "8\n", "authors": ["344"]}
{"title": "Contributions for improving debugging of kernel-level services in a monolithic operating system\n", "abstract": " Despite the existence of an overwhelming amount of research on the quality of system software, Operating Systems are still plagued with reliability issues mainly caused by defects in kernel-level services such as device drivers and file systems. Studies have indeed shown that each release of the Linux kernel contains between 600 and 700 faults, and that the propensity of device drivers to contain errors is up to seven times higher than any other part of the kernel. These numbers suggest that kernel-level service code is not sufficiently tested and that many faults remain unnoticed or are hard to fix by non-expert programmers who account for the majority of service developers. This thesis proposes a new approach to the debugging and testing of kernel level services focused on the interaction between the services and the core kernel. The approach tackles the issue of safety holes in the implementation of kernel API functions. For Linux, we have instantiated the Diagnosys automated approach which relies on static analysis of kernel code to identify, categorize and expose the different safety holes of API functions which can turn into runtime faults when the functions are used in service code by developers with limited knowledge on the intricacies of kernel code. To illustrate our approach, we have implemented Diagnosys for Linux 2.6.32 and shown its benefits in supporting developers in their testing and debugging tasks.", "num_citations": "6\n", "authors": ["344"]}
{"title": "Secure, Transparent and Uniform Mobile Money for Internet-Underserved Areas Using Sporadically-Synchronized Blockchain\n", "abstract": " This position paper presents the design and outline of the implementation of a mobile money scheme that adapts to the realities of Internet-underserved Areas while exploiting the benefits of Internet protocols. In particular, we implement security and transparency in mobile money transactions using a lightweight permissioned Blockchain infrastructure. Nevertheless, due to network latency and potential connectivity issues, the design of the platform accepts semi-offline transactions: it leverages USSD, a 2nd Generation mobile protocol, only as a back-up channel to force writing of offline transactions to the permissioned ledger and ensure smooth synchronization of the blockchain.", "num_citations": "5\n", "authors": ["344"]}
{"title": "Towards Smart City Implementations in Sub-Saharan Africa\n", "abstract": " Technological progress, in relation with ubiquitous computing, has put forward the concept of ICT-based smart cities. This concept, which is related to the need of facilitating the daily life of citizens in the concerned cities, relies on the use of existing infrastructures of communication to develop adapted digital services. As such, the implementation of mobile services in the framework of smart cities is equally important in developed countries than in the least developed countries. In the latter (more particularly in sub-Saharan Africa), it is however to be noted that the most advanced technologies of communication are not always available. It thus prevents the immediate deployment of digital systems that are available in developed countries. Obviously, the provision of mobile services dedicated to sub-Saharan areas requires the consideration of the ambient environment in terms of social and technological\u00a0\u2026", "num_citations": "5\n", "authors": ["344"]}
{"title": "Sensing in the urban technological deserts: A position paper for smart cities in least developed countries\n", "abstract": " The technological progress in recent years has allowed to produce sensors, on macroscopic and microscopic scales, that are now essential to ubiquitous computing. This paradigm has made the concept of smart cities a reality that is now in synchrony with the needs and requirements for living in this era. Whether it concerns commuters in public transportations or users of existential services such as hospitals, the implementation of smart cities is equally important in developed countries than in the least developed countries. Unfortunately, in the latter, sensors and the associated technologies are not readily available to implement smart cities. It is therefore necessary to identify surrogate ways of sensing the ambient environment. In this position paper, we discuss the situation in least developed countries and the obstacles to common implementations of smart cities. We also provide a preliminary enumeration of how\u00a0\u2026", "num_citations": "4\n", "authors": ["344"]}
{"title": "Towards securing communications in infrastructure-poor areas\n", "abstract": " Structured P2P networks have proven to be effective in the exchange of data between nodes whose identity and content are generally indexed in a DHT. For years, such DHT networks have allowed, among other users, third world inhabitants, such as African people, to exchange information among them and with the rest of the world without relying on a centralized infrastructure. Unfortunately, more than ever, reliability of communication across the Internet is threatened by various attacks, including usurpation of identity, eavesdropping or traffic modification. Thus, in order to overcome these security issues and allow peers to securely exchange data, we propose a new key management scheme that enables to handle public keys in the absence of a central coordination which would be required in a traditional PKI.", "num_citations": "4\n", "authors": ["344"]}
{"title": "Zebra: Building efficient network message parsers for embedded systems\n", "abstract": " Supporting standard text-based protocols in embedded systems is challenging because of the often limited computational resources that embedded systems provide. To overcome this issue, a promising approach is to build parsers directly in the hardware. Unfortunately, developing such parsers is a daunting task for most developers as it is at the crossroads of several areas of expertise, such as low-level network programming or hardware design. In this letter, we propose Zebra, a generative approach that drastically eases the development of hardware parsers and their use in network applications. To validate our approach, we used Zebra to generate hardware parsers for widely used protocols, including HTTP, SMTP, SIP, and RTSP. Our experiments show that Zebra-based parsers are up to 11 times faster than software-based parsers.", "num_citations": "4\n", "authors": ["344"]}
{"title": "Typhoon: a middleware for epidemic propagation of software updates\n", "abstract": " Applications for mobiles devices are subject to very frequent updates for fixing security vulnerabilities, ensuring compatibility with new hardware and APIs or enhancing functionalities. Getting the new version of an application involves the download of a significant amount of data, which is not practical through low-bandwidth/high-cost links. As a consequence, mobile device users often fail to update their applications.", "num_citations": "4\n", "authors": ["344"]}
{"title": "A study of potential component leaks in android apps\n", "abstract": " [en] We discuss the capability of a new feature set for malware detection based on potential component leaks (PCLs). PCLs are defined as sensitive data-flows that involve Android inter-component communications. We show that PCLs are common in Android apps and that malicious applications indeed manipulate significantly more PCLs than benign apps. Then, we evaluate a machine learning-based approach relying on PCLs. Experimental validation show high performance with 95% precision for identifying malware, demonstrating that PCLs can be used for discriminating malicious apps from benign apps.By further investigating the generalization ability of this feature set, we highlight an issue often overlooked in the Android malware detection community: Qualitative aspects of training datasets have a strong impact on a malware detector\u2019s performance. Furthermore, this impact cannot be overcome by simply increasing the Quantity of training material.", "num_citations": "3\n", "authors": ["344"]}
{"title": "e-Infrastructure and e-Services for Developing Countries: 5th International Conference, AFRICOMM 2013, Blantyre, Malawi, November 25-27, 2013, Revised Selected Papers\n", "abstract": " This book constitutes the thoroughly refereed proceedings of the 5th International Conference on e-Infrastructure and e-Services for Developing Countries, AFRICOMM 2013, held in Blantyre, Malawi, in November 2013. The 32 revised full papers presented were carefully reviewed and selected from 94 submissions. The papers discuss issues and trends, resent research, innovation advances and on-the-field experiences related to e-governance, e-infrastructure, and e-business with a focus on developing countries.", "num_citations": "3\n", "authors": ["344"]}
{"title": "Multipath Key Exchange Scheme Based on the Diffie-Hellman Protocol and the Shamir Threshold.\n", "abstract": " In the Internet, as well as in any open autonomous distributed systems, threats to secure communications are pervasive. We contribute towards adressing them by proposing, in this paper, a new multipath key exchange approach, which does not rely on any centrally trusted coordinator. This approach is thus suitable for use in distributed systems such as widespread P2P networks or booming wireless mesh networks (eg, for the Internetof-Things). We design a new algorithm based upon an extension of both the Diffie-Hellman protocol and the Shamir threshold scheme. In order to overcome man-in-the-middle attacks inherent to the Diffie-Hellman key exchange model, our proposed approach guarantees secure key exchange by exploring disjoint transmission paths and the Shamir threshold scheme. The public key is used as the root of a polynomial of degree k\u2212 1, and n points of this polynomial are generated and transmitted from source to destination, each point through a disjoint path. Upon reception of at least k points among n, the receiver is able to reconstruct the complete key. In addition, this paper demonstrates how the disjoint paths constructions and the routing algorithms are designed to work regardless of the network topology.", "num_citations": "2\n", "authors": ["344"]}
{"title": "End-to-End key exchange through disjoint paths in P2P networks\n", "abstract": " Due to their inherent features, P2P networks have proven to be effective in the exchange of data between autonomous peers. Unfortunately, these networks are subject to various security threats that cannot be addressed readily since traditional security infrastructures, which are centralized, cannot be applied to them. Furthermore, communication reliability across the Internet is threatened by various attacks, including usurpation of identity, eavesdropping or traffic modification. Thus, in order to overcome these security issues and allow peers to securely exchange data, we propose a new key management scheme over P2P networks. Our approach introduces a new method that enables a secret key exchange through disjoint paths in the absence of a trusted central coordination point which would be required in traditional centralized security systems.", "num_citations": "2\n", "authors": ["344"]}
{"title": "Orion: A Software Project Search Engine with Integrated Diverse Software Artifacts.(2013). Research Collection School Of Information Systems\n", "abstract": " What projects contain more than 10,000 lines of code developed by less than 10 people and are still actively maintained with a high bug-fixing rate? To address the challenges for answering such enquiries, we develop an integrated search engine architecture that combines information from different types of software repositories from multiple sources. Our search engine facilitates the construction and execution of complex search queries using a uniform interface that transparently correlates different artifacts of project development and maintenance, such as source code information, version control systems metadata, bug tracking systems elements, and metadata on developer activities and interactions extracted from hosting platforms. We have built an extensible system with an initial capability of over 100,000 projects collected from the web, featuring various software development artifacts. Using scenarios, we illustrate the benefits of such a search engine for different kinds of project seekers.", "num_citations": "2\n", "authors": ["344"]}
{"title": "KnowledgeZooClient: constructing knowledge graph for Android\n", "abstract": " In this work, we describe the design and implementation of a reusable tool named KnowledgeZooClient targeting the construction, as a crowd-sourced effort, of a knowledge graph for Android apps. KnowledgeZooClient is made up of two modules: (1) the Metadata Extraction Module (MEM), which aims at extracting metadata from Android apps and (2) the Metadata Integration Module (MIM) for importing and integrating extracted metadata into a graph database. The usefulness of KnowledgeZooClient is demonstrated via an exclusive knowledge graph called KnowledgeZoo, which contains information on over 500,000 apps already and still keeps growing. Interested users can already benefit from KnowledgeZoo by writing advanced search queries so as to collect targeted app samples.", "num_citations": "1\n", "authors": ["344"]}
{"title": "Y Nut, a Phonetic-based Learning System for Spoken Languages\n", "abstract": " Communication between humans is of importance for our societies. It requires constant learning of new languages, e.g., by travellers whose extended stay in foreign locations facilitate learning. When a language possesses a written form, much of the meaning necessary for its learning is directly provided by the text. In spoken languages however, the meaning is only vehicled by the sounds. Nonetheless, learning spoken languages can take advantage of linguistic contents available in audio or video media which abound on the Internet and the social networks. We open a discussion and describe a system that enables to enrich a phonetic database so as to ease learning of basic expressions of spoken languages. Such a system could be useful for the survival of the plethora of spoken languages in Africa. The purpose of such a system is to provide within a reasonable period, automatic syntactic translation\u00a0\u2026", "num_citations": "1\n", "authors": ["344"]}