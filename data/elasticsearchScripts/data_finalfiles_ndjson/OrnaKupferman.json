{"title": "Model checking of safety properties\n", "abstract": " Of special interest in formal verification are safety properties, which assert that the system always stays within some allowed region. Proof rules for the verification of safety properties have been developed in the proof-based approach to verification, making verification of safety properties simpler than verification of general properties. In this paper we consider model checking of safety properties. A computation that violates a general linear property reaches a bad cycle, which witnesses the violation of the property. Accordingly, current methods and tools for model checking of linear properties are based on a search for bad cycles. A symbolic implementation of such a search involves the calculation of a nested fixed-point expression over the system's state space, and is often infeasible. Every computation that violates a safety property has a finite prefix along which the property is violated. We use this fact in\u00a0\u2026", "num_citations": "546\n", "authors": ["1788"]}
{"title": "Weak alternating automata are not that weak\n", "abstract": " Automata on infinite words are used for specification and verification of nonterminating programs. Different types of automata induce different levels of expressive power, of succinctness, and of complexity. Alternating automata have both existential and universal branching modes and are particularly suitable for specification of programs. In a weak alternating automata the state space is partitioned into partially ordered sets, and the automaton can proceed from a certain set only to smaller sets. Reasoning about weak alternating automata is easier than reasoning about alternating automata with no restricted structure. Known translations of alternating automata to weak alternating automata involve determinization, and therefore involve a double-exponential blow-up. In this paper we describe a quadratic translation, which circumvents the need for determinization, of B\u00fcchi and co-B\u00fcchi alternating automata to weak\u00a0\u2026", "num_citations": "329\n", "authors": ["1788"]}
{"title": "Safraless decision procedures\n", "abstract": " The automata-theoretic approach is one of the most fundamental approaches to developing decision procedures in mathematical logics. To decide whether a formula in a logic with the tree-model property is satisfiable, one constructs an automaton that accepts all (or enough) tree models of the formula and then checks that the language of this automaton is nonempty. The standard approach translates formulas into alternating parity tree automata, which are then translated, via Safra's determinization construction, into nondeterministic parity automata. This approach is not amenable to implementation because of the difficulty of implementing Safra's construction and the nonemptiness test for nondeterministic parity tree automata. In this paper, we offer an alternative to the standard automata-theoretic approach. The crux of our approach is avoiding the use of Safra's construction and of nondeterministic parity tree\u00a0\u2026", "num_citations": "268\n", "authors": ["1788"]}
{"title": "Concurrent reachability games\n", "abstract": " We consider concurrent two-player games with reachability objectives. In such games, at each round, player 1 and player 2 independently and simultaneously choose moves, and the two choices determine the next state of the game. The objective of player 1 is to reach a set of target states; the objective of player 2 is to prevent this. These are zero-sum games, and the reachability objective is one of the most basic objectives: determining the set of states from which player 1 can win the game is a fundamental problem in control theory and system verification. There are three types of winning states, according to the degree of certainty with which player 1 can reach the target. From type-1 states, player 1 has a deterministic strategy to always reach the target. From type-2 states, player 1 has a randomized strategy to reach the target with probability 1. From type-3 states, player 1 has for every real \u03b5> 0 a randomized\u00a0\u2026", "num_citations": "261\n", "authors": ["1788"]}
{"title": "Synthesis with incomplete informatio\n", "abstract": " In program synthesis, we transform a specification into a system that is guaranteed to satisfy the specification. When the system is open, then at each moment it reads input signals and writes output signals, which depend on the input signals and the history of the computation so far. The specification considers all possible input sequences. Thus, if the specification is linear, it should hold in every computation generated by the interaction, and if the specification is branching, it should hold in the tree that embodies all possible input sequences.             Often, the system cannot read all the input signals generated by its environment. For example, in a distributed setting, it might be that each process can read input signals of only part of the underlying processes. Then, we should transform a specification into a system whose output depends only on the readable parts of the input signals and the history of the\u00a0\u2026", "num_citations": "219\n", "authors": ["1788"]}
{"title": "Module checking revisited\n", "abstract": " When we verify the correctness of an open system with respect to a desired requirement, we should take into consideration the different environments with which the system may interact. Each environment induces a different behavior of the system, and we want all these behaviors to satisfy the requirement. Module checking is an algorithmic method that checks, given an open system (modeled as a finite structure) and a desired requirement (specified by a temporal-logic formula), whether the open system satisfies the requirement with respect to all environments. In this paper we extend the module-checking method with respect to two orthogonal issues. Both issues concern the fact that often we are not interested in satisfaction of the requirement with respect to all environments, but only with respect to these that meet some restriction. We consider the case where the environment has incomplete information\u00a0\u2026", "num_citations": "210\n", "authors": ["1788"]}
{"title": "Vacuity detection in temporal model checking\n", "abstract": " One of the advantages of temporal-logic model-checking tools is their ability to accompany a negative answer to the correctness query by a counterexample to the satisfaction of the specification in the system. On the other hand, when the answer to the correctness query is positive, most model-checking tools provide no witness for the satisfaction of the specification. In the last few years there has been growing awareness as to the importance of suspecting the system or the specification of containing an error also in the case model checking succeeds. The main justification of such suspects are possible errors in the modeling of the system or of the specification. Many such errors can be detected by further automatic reasoning about the system and the environment. In particular, Beer et al. described a method for the detection of vacuous satisfaction  of temporal logic specifications and the generation of\u00a0\u2026", "num_citations": "176\n", "authors": ["1788"]}
{"title": "Model checking of safety properties\n", "abstract": " Of special interest in formal verification are safety properties, which assert that the system always stays within some allowed region.A computation that violates a general linear property reaches a bad cycle, which witnesses the violation of the property. Accordingly, current methods and tools for model checking of linear properties are based on a search for bad cycles. A symbolic implementation of such a search involves the calculation of a nested fixed-point expression over the system\u2019s state space, and is often very difficult. Every computation that violates a safety property has a finite prefix along which the property is violated. We use this fact in order to base model checking of safety properties on a search for finite bad prefixes. Such a search can be performed using a simple forward or backward symbolic reachability check. A naive methodology that is based on such a search involves a construction of an\u00a0\u2026", "num_citations": "156\n", "authors": ["1788"]}
{"title": "Weak alternating automata and tree automata emptiness\n", "abstract": " Aufomata on infinite words and trees are used for qxcification and uerification of nonterminating programs. The verification and the satis $ ability problems of specifications can be reduced to the nonemptinessproblem of such automata. In a weak automaton, the state space is partitioned into partially ordered sets, and the automaton can proceed from a certain set only to smaller sets. Reasoning about weak automata is easier than reasoning about automata with no restricted structure. In particular, the nonemptinessproblem for weak alternating automata over a singleton alphabet can be solved in linear time. Known translations of alternating automata to weak alternating automata involve determinization, and therefore involve a double exponential blow-up. In this paper we describe simple and efficient translations, ulhich circumvent the need for determinization, of parity and Rabin alternating word automata to weak\u00a0\u2026", "num_citations": "148\n", "authors": ["1788"]}
{"title": "Rational synthesis\n", "abstract": " Synthesis is the automated construction of a system from its specification. The system has to satisfy its specification in all possible environments. Modern systems often interact with other systems, or agents. Many times these agents have objectives of their own, other than to fail the system. Thus, it makes sense to model system environments not as hostile, but as composed of rational agents; i.e., agents that act to achieve their own objectives.               We introduce the problem of synthesis in the context of rational agents (rational synthesis, for short). The input consists of a temporal-logic formula specifying the system, temporal-logic formulas specifying the objectives of the agents, and a solution concept definition. The output is an implementation T of the system and a profile of strategies, suggesting a behavior for each of the agents. The output should satisfy two conditions. First, the composition of T\u00a0\u2026", "num_citations": "139\n", "authors": ["1788"]}
{"title": "Lattice automata\n", "abstract": " Several verification methods involve reasoning about multi-valued systems, in which an atomic proposition is interpreted at a state as a lattice element, rather than a Boolean value. The automata-theoretic approach for reasoning about Boolean-valued systems has proven to be very useful and powerful. We develop an automata-theoretic framework for reasoning about multi-valued objects, and describe its application. The basis to our framework are lattice automata on finite and infinite words, which assign to each input word a lattice element. We study the expressive power of lattice automata, their closure properties, the blow-up involved in related constructions, and decision problems for them. Our framework and results are different and stronger then those known for semi-ring and weighted automata. Lattice automata exhibit interesting features from a theoretical point of view. In particular, we study the\u00a0\u2026", "num_citations": "135\n", "authors": ["1788"]}
{"title": "Coverage metrics for formal verification\n", "abstract": " In formal verification, we verify that a system is correct with respect to a specification. Even when the system is proven to be correct, there is still a question of how complete the specification is, and whether it really covers all the behaviors of the system. The challenge of making the verification process as exhaustive as possible is even more crucial in simulation-based verification, where the infeasible task of checking all input sequences is replaced by checking a test suite consisting of a finite subset of them. It is very important to measure the exhaustiveness of the test suite, and indeed, there has been an extensive research in the simulation-based verification community on coverage metrics, which provide such a measure. It turns out that no single measure can be absolute, leading to the development of numerous coverage metrics whose usage is determined by industrial verification methodologies. On the\u00a0\u2026", "num_citations": "130\n", "authors": ["1788"]}
{"title": "A practical approach to coverage in model checking\n", "abstract": " In formal verification, we verify that a system is correct with respect to a specification. When verification succeeds and the system is proven to be correct, there is still a question of how complete the specification is, and whether it really covers all the behaviors of the system. In this paper we study coverage metrics for model checking from a practical point of view. Coverage metrics are based on modifications we apply to the system in order to check which parts of it were actually relevant for the verification process to succeed. We suggest several definitions of coverage, suitable for specifications given in linear temporal logic or by automata on infinite words. We describe two algorithms for computing the parts of the system that are not covered by the specification. The first algorithm is built on top of automata-based model-checking algorithms. The second algorithm reduces the coverage problem to the model\u00a0\u2026", "num_citations": "129\n", "authors": ["1788"]}
{"title": "Safraless compositional synthesis\n", "abstract": " In automated synthesis, we transform a specification into a system that is guaranteed to satisfy the specification. In spite of the rich theory developed for system synthesis, little of this theory has been reduced to practice. This is in contrast with model-checking theory, which has led to industrial development and use of formal verification tools. We see two main reasons for the lack of practical impact of synthesis. The first is algorithmic: synthesis involves determinization of automata on infinite words, and a solution of parity games with highly complex state spaces; both problems have been notoriously resistant to efficient implementation. The second is methodological: current theory of synthesis assumes a single comprehensive specification. In practice, however, the specification is composed of a set of properties, which is typically evolving \u2013 properties may be added, deleted, or modified.               In this work we address\u00a0\u2026", "num_citations": "114\n", "authors": ["1788"]}
{"title": "Modular model checking\n", "abstract": " In modular verification the specification of a module consists of two parts. One part describes the guaranteed behavior of the module. The other part describes the assumed behavior of the system in which the module is interacting. This is called the assume-guarantee paradigm. In this paper we consider assume-guarantee specifications in which the guarantee is specified by branching temporal formulas. We distinguish between two approaches. In the first approach, the assumption is specified by branching temporal formulas. In the second approach, the assumption is specified by linear temporal logic. We consider guarantees in \u2200CTL and \u2200CTL; the universal fragments of CTL and CTL, and assumptions in LTL, \u2200CTL, and \u2200CTL. We describe a reduction of modular model checking to standard model checking. Using the reduction, we show that modular model checking is PSPACE-complete for \u2200CTL and\u00a0\u2026", "num_citations": "114\n", "authors": ["1788"]}
{"title": "The Complexity of the Graded \u03bc-Calculus\n", "abstract": " In classical logic, existential and universal quantifiers express that there exists at least one individual satisfying a formula, or that all individuals satisfy a formula. In many logics, these quantifiers have been generalized to express that, for a non-negative integer n, at least n individuals or all but n individuals satisfy a formula. In modal logics, graded modalities generalize standard existential and universal modalities in that they express, e.g., that there exist at least n accessible worlds satisfying a certain formula. Graded modalities are useful expressive means in knowledge representation; they are present in a variety of other knowledge representation formalisms closely related to modal logic.               A natural question that arises is how the generalization of the existential and universal modalities affects the satisfiability problem for the logic and its computational complexity, especially when the numbers in the\u00a0\u2026", "num_citations": "111\n", "authors": ["1788"]}
{"title": "Temporal specifications with accumulative values\n", "abstract": " Recently, there has been an effort to add quantitative objectives to formal verification and synthesis. We introduce and investigate the extension of temporal logics with quantitative atomic assertions. At the heart of quantitative objectives lies the accumulation of values along a computation. It is often the accumulated sum, as with energy objectives, or the accumulated average, as with mean-payoff objectives. We investigate the extension of temporal logics with the prefix-accumulation assertions Sum(v) \u2265 c and Avg(v) \u2265 c, where v is a numeric (or Boolean) variable of the system, c is a constant rational number, and Sum(v) and Avg(v) denote the accumulated sum and average of the values of v from the beginning of the computation up to the current point in time. We also allow the path-accumulation assertions LimInfAvg(v)\u2265 c and LimSupAvg(v)\u2265 c, referring to the average value along an entire infinite computation\u00a0\u2026", "num_citations": "110\n", "authors": ["1788"]}
{"title": "Freedom, weakness, and determinism: From linear-time to branching-time\n", "abstract": " Model checking is a method for the verification of systems with respect to their specifications. Symbolic model-checking, which enables the verification of large systems, proceeds by calculating fixed-point expressions over the system's set of states. The /spl mu/-calculus is a branching-time temporal logic with fixed-point operators. As such, it is a convenient logic for symbolic model-checking tools. In particular, the alternation-free fragment of /spl mu/-calculus has a restricted syntax, making the symbolic evaluation of its formulas computationally easy. Formally, it takes time that is linear in the size of the system. On the other hand, specifiers find the /spl mu/-calculus inconvenient. In addition, specifiers often prefer to use Linear-time formalisms. Such formalisms, however, cannot in general be translated to the alternation-free CL-calculus, and their symbolic evaluation involves nesting of fixed-points, resulting in time\u00a0\u2026", "num_citations": "104\n", "authors": ["1788"]}
{"title": "Vacuity detection in temporal model checking\n", "abstract": " One of the advantages of temporal-logic model-checking tools is their ability to accompany a negative answer to the correctness query by a counterexample to the satisfaction of the specification in the system. On the other hand, when the answer to the correctness query is positive, most model-checking tools provide no witness for the satisfaction of the specification. In the last few years there has been growing awareness to the importance of suspecting the system or the specification of containing an error also in the case model checking succeeds. The main justification of such suspects are possible errors in the modeling of the system or of the specification. Many such errors can be detected by further automatic reasoning about the system and the environment. In particular, Beer et al. described a method for the detection of vacuous satisfaction of temporal logic specifications and the generation of\u00a0\u2026", "num_citations": "100\n", "authors": ["1788"]}
{"title": "Coverage metrics for temporal logic model checking\n", "abstract": " In formal verification, we verify that a system is correct with respect to a specification. Even when the system is proven to be correct, there is still a question of how complete the specification is, and whether it really covers all the behaviors of the system. In this paper we study coverage metrics for model checking.Coverage metrics are based on modifications we apply to the system in order to check which parts of it were actually relevant for the verification process to succeed. We introduce two principles that we believe should be part of any coverage metric for model checking: a distinction between state-based and logicbased coverage, and a distinction between the system and its environment. We suggest several coverage metrics that apply these principles, and we describe two algorithms for finding the uncovered parts of the system under these definitions. The first algorithm is a symbolic implementation of\u00a0\u2026", "num_citations": "99\n", "authors": ["1788"]}
{"title": "An automata-theoretic approach to reasoning about infinite-state systems\n", "abstract": " We develop an automata-theoretic framework for reasoning about infinite-state sequential systems. Our framework is based on the observation that states of such systems, which carry a finite but unbounded amount of information, can be viewed as nodes in an infinite tree, and transitions between states can be simulated by finite-state automata. Checking that the system satisfies a temporal property can then be done by an alternating two-way tree automaton that navigates through the tree. As has been the case with finite-state systems, the automata-theoretic framework is quite versatile. We demonstrate it by solving several versions of the model-checking problem for \u03bc-calculus specifications and prefix-recognizable systems, and by solving the realizability and synthesis problems for \u03bc-calculus specifications with respect to prefix-recognizable environments.", "num_citations": "95\n", "authors": ["1788"]}
{"title": "Church's problem revisited\n", "abstract": " In program synthesis, we transform a specification into a system that is guaranteed to satisfy the specification. When the system is open, then at each moment it reads input signals and writes output signals, which depend on the input signals and the history of the computation so far. The specification considers all possible input sequences. Thus, if the specification is linear, it should hold in every computation generated by the interaction, and if the specification is branching, it should hold in the tree that embodies all possible input sequences. Often, the system cannot read all the input signals generated by its environment. For example, in a distributed setting, it might be that each process can read input signals of only part of the underlying processes. Then, we should transform a specification into a system whose output depends only on the readable parts of the input signals and the history of the computation. This is\u00a0\u2026", "num_citations": "95\n", "authors": ["1788"]}
{"title": "What's decidable about weighted automata?\n", "abstract": " Weighted automata map input words to values, and have numerous applications in computer science. A result by Krob from the 90s implies that the universality problem is decidable for weighted automata over the tropical semiring with weights in N\u222a{\u221e} and is undecidable when the weights are in Z\u222a{\u221e}. We continue the study of the borders of decidability in weighted automata over the tropical semiring. We give a complete picture of the decidability and complexity of various decision problems for them, including non-emptiness, universality, equality, and containment. For the undecidability results, we provide direct proofs, which stay in the terrain of state machines. This enables us to tighten the results and apply them to a very simple class of automata. In addition, we provide a toolbox of algorithms and techniques for weighted automata, on top of which we establish the complexity bounds.", "num_citations": "91\n", "authors": ["1788"]}
{"title": "From liveness to promptness\n", "abstract": " Liveness temporal properties state that something \u201cgood\u201d eventually happens, e.g., every request is eventually granted. In Linear Temporal Logic (LTL), there is no a priori bound on the \u201cwait time\u201d for an eventuality to be fulfilled. That is, F                         \u03b8 asserts that \u03b8 holds eventually, but there is no bound on the time when \u03b8 will hold. This is troubling, as designers tend to interpret an eventuality F                         \u03b8 as an abstraction of a bounded eventuality F                         \u2264k                                                  \u03b8, for an unknown k, and satisfaction of a liveness property is often not acceptable unless we can bound its wait time. We introduce here prompt-LTL, an extension of LTL with the prompt-eventually operator F                                            p                 . A system S satisfies a prompt-LTL formula \u03c6 if there is some bound k on the wait time for all prompt-eventually subformulas of \u03c6 in all computations of S. We study various\u00a0\u2026", "num_citations": "85\n", "authors": ["1788"]}
{"title": "Synthesis with rational environments\n", "abstract": " Synthesis is the automated construction of a system from its specification. The system has to satisfy its specification in all possible environments. The environment often consists of agents that have objectives of their own. Thus, it makes sense to soften the universal quantification on the behavior of the environment and take the objectives of its underlying agents into an account. Fisman et al. introduced rational synthesis: the problem of synthesis in the context of rational agents. The input to the problem consists of temporal logic formulas specifying the objectives of the system and the agents that constitute the environment, and a solution concept (e.g., Nash equilibrium). The output is a profile of strategies, for the system and the agents, such that the objective of the system is satisfied in the computation that is the outcome of the strategies, and the profile is stable according to the solution concept\u00a0\u2026", "num_citations": "84\n", "authors": ["1788"]}
{"title": "Sanity checks in formal verification\n", "abstract": " One of the advantages of temporal-logic model-checking tools is their ability to accompany a negative answer to the correctness query by a counterexample to the satisfaction of the specification in the system. On the other hand, when the answer to the correctness query is positive, most model-checking tools provide no additional information. In the last few years there has been growing awareness to the importance of suspecting the system or the specification of containing an error also in the case model checking succeeds. The main justification of such suspects are possible errors in the modeling of the system or of the specification. The goal of sanity checks is to detect such errors by further automatic reasoning. Two leading sanity checks are vacuity and coverage. In vacuity, the goal is to detect cases where the system satisfies the specification in some unintended trivial way. In coverage, the goal is to\u00a0\u2026", "num_citations": "79\n", "authors": ["1788"]}
{"title": "Verification of fair transition systems\n", "abstract": " In program verification, we check that an implementation meets its specification. Both the specification and the implementation describe the possible behaviors of the program, though at different levels of abstraction. We distinguish between two approaches to implementation of specifications. The first approach is trace-based implementation, where we require every computation of the implementation to correlate to some computation of the specification. The second approach is tree-based implementation, where we require every computation tree embodied in the implementation to correlate to some computation tree embodied in the specification. The two approaches to implementation are strongly related to the linear-time versus branching-time dichotomy in temporal logic.             In this work we examine the trace-based and the tree-based approaches from a complexity-theoretic point of view. We consider\u00a0\u2026", "num_citations": "79\n", "authors": ["1788"]}
{"title": "Once and for all\n", "abstract": " It has long been known that past-time operators add no expressive power to linear temporal logics. In this paper, we consider the extension of branching temporal logics with past-time operators. Two possible views regarding the nature of past in a branching-time model induce two different such extensions. In the first view, past is branching and each moment in time may have several possible futures and several possible pasts. In the second view, past is linear and each moment in time may have several possible futures and a unique past. Both views assume that past is finite. We discuss the practice of these extensions as specification languages, characterize their expressive power, and examine the complexity of their model-checking and satisfiability problems.", "num_citations": "76\n", "authors": ["1788"]}
{"title": "What causes a system to satisfy a specification?\n", "abstract": " Even when a system is proven to be correct with respect to a specification, there is still a question of how complete the specification is, and whether it really covers all the behaviors of the system. Coverage metrics attempt to check which parts of a system are actually relevant for the verification process to succeed. Recent work on coverage in model checking suggests several coverage metrics and algorithms for finding parts of the system that are not covered by the specification. The work has already proven to be effective in practice, detecting design errors that escape early verification efforts in industrial settings. In this article, we relate a formal definition of causality given by Halpern and Pearl to coverage. We show that it gives significant insight into unresolved issues regarding the definition of coverage and leads to potentially useful extensions of coverage. In particular, we introduce the notion of responsibility\u00a0\u2026", "num_citations": "72\n", "authors": ["1788"]}
{"title": "B\u00fcchi complementation made tighter\n", "abstract": " The complementation problem for nondeterministic word automata has numerous applications in formal verification. In particular, the language-containment problem, to which many verification problems is reduced, involves complementation. For automata on finite words, which correspond to safety properties, complementation involves determinization. The 2n blow-up that is caused by the subset construction is justified by a tight lower bound. For B\u00fcchi automata on infinite words, which are required for the modeling of liveness properties, optimal complementation constructions are quite complicated, as the subset construction is not sufficient. From a theoretical point of view, the problem is considered solved since 1988, when Safra came up with a determinization construction for B\u00fcchi automata, leading to a 2O(n log n) complementation construction, and Michel came up with a matching lower bound. A careful\u00a0\u2026", "num_citations": "70\n", "authors": ["1788"]}
{"title": "Extended temporal logic revisited\n", "abstract": " A key issue in the design of a model-checking tool is the choice of the formal language with which properties are specified. It is now recognized that a good language should extend linear temporal logic with the ability to specify all \u03c9-regular properties. Also, designers, who are familiar with finite-state machines, prefer extensions based on automata than these based on fixed points or propositional quantification. Early extensions of linear temporal logic with automata use nondeterministic B\u00fcchi automata. Their drawback has been inability to refer to the past and the asymmetrical structure of nondeterministic automata. In this work we study an extension of linear temporal logic, called ETL2a, that uses two-way alternating automata as temporal connectives. Twoway automata can traverse the input word back and forth and they are exponentially more succinct than one-way automata. Alternating automata\u00a0\u2026", "num_citations": "68\n", "authors": ["1788"]}
{"title": "A space-efficient on-the-fly algorithm for real-time model checking\n", "abstract": " In temporal-logic model checking, we verify the correctness of a program with respect to a desired behavior by checking whether a structure that models the program satisfies a temporal-logic formula that specifies the behavior. The main practical limitation of model checking is caused by the size of the state space of the program, which grows exponentially with the number of concurrent components. This problem, known as the state-explosion problem, becomes more difficult when we consider real-time model checking, where the program and the specification involve quantitative references to time. In particular, when use timed automata to describe real-time programs and we specify timed behaviors in the logic TCTL, a real-time extension of the temporal logic CTL with clock variables, then the state space under consideration grows exponentially not only with the number of concurrent components, but also\u00a0\u2026", "num_citations": "67\n", "authors": ["1788"]}
{"title": "An automata-theoretic approach to modular model checking\n", "abstract": " In modular verification the specification of a module consists of two part. One part describes the guaranteed behavior of the module. The other part describes the assumed behavior of the system in which the module is interacting. This is called the assume-guarantee paradigm. In this paper we consider assume-guarantee specifications in which the guarantee is specified by branching temporal formulas. We distinguish between two approaches. In the first approach, the assumption is specified by branching temporal formulas too. In the second approach, the assumption is specified by linear temporal logic. We consider guarantees in \u2200CTL, and \u2200CTL*. We develop two fundamental techniques: building maximal models for \u2200CTL and \u2200CTL* formulas and using alternating automata to obtain space-efficient algorithms for fair model checking. Using these techniques we classify the complexity of satisfiability, validity\u00a0\u2026", "num_citations": "65\n", "authors": ["1788"]}
{"title": "On object systems and behavioral inheritance\n", "abstract": " We consider state-based behavior in object-oriented analysis and design, as it arises, for example, in specifying behavior in the UML using statecharts. We first provide a rigorous and analyzable model of object systems and their reactivity. The definition is for basic one-thread systems, but can be extended in appropriate ways to more elaborate models. We then address the notion of inheritance and behavioral conformity and the resulting substitutability of classes, whereby inheriting should retain the system's original behaviors. Inheritance is a central issue of crucial importance to the modeling, design, and verification of object-oriented systems, and the many deep and unresolved questions around it cannot be addressed without a precise definition of the systems under consideration. We use our definition to give a clear and rigorous picture of what exactly is meant by behavioral conformity and how computationally\u00a0\u2026", "num_citations": "61\n", "authors": ["1788"]}
{"title": "\u03bc-calculus synthesis\n", "abstract": " In system synthesis, we transform a specification into a system that is guaranteed to satisfy the specification. When the system is open, it interacts with an environment via input and output signals and its behavior depends on this interaction. An open system should satisfy its specification in all possible environments. In addition to the input signals that the system can read, an environment can also have internal signals that the system cannot read. In the above setting, of synthesis with incomplete information, we should transform a specification that refers to both readable and unreadable signals into a system whose behavior depends only on the readable signals. In this work we solve the problem of synthesis with incomplete information for specifications in \u03bc-calculus. Since many properties of systems are naturally specified by means of fixed points, the \u03bc-calculus is an expressive and important specification\u00a0\u2026", "num_citations": "60\n", "authors": ["1788"]}
{"title": "Pushdown specifications\n", "abstract": " Traditionally, model checking is applied to finite-state systems and regular specifications. While researchers have successfully extended the applicability of model checking to infinite-state systems, almost all existing work still consider regular specification formalisms. There are, however, many interesting non-regular properties one would like to model check.             In this paper we study model checking of pushdown specifications. Our specification formalism is nondeterministic pushdown parity tree automata (PD-NPT). We show that the model-checking problem for regular systems and PD-NPT specifications can be solved in time exponential in the system and the specification. Our model-checking algorithm involves a new solution to the nonemptiness problem of nondeterministic pushdown tree automata, where we improve the best known upper bound from a triple-exponential to a single exponential. We\u00a0\u2026", "num_citations": "59\n", "authors": ["1788"]}
{"title": "On the complexity of verifying concurrent transition systems\n", "abstract": " In implementation verification, we check that an implementation is correct with respect to a specification by checking whether the behaviors of a transition system that models the program's implementation correlate with the behaviors of a transition system that models its specification. In this paper, we investigate the effect of concurrency on the complexity of implementation verification. We consider trace-based and tree-based approaches to the verification of concurrent transition systems, with and without fairness. Our results show that in almost all cases the complexity of the problem is exponentially harder than that of the sequential case. Thus, as in the model-checking verification methodology, the state-explosion problem cannot be avoided.", "num_citations": "58\n", "authors": ["1788"]}
{"title": "Discounting in LTL\n", "abstract": " In recent years, there is growing need and interest in formalizing and reasoning about the quality of software and hardware systems. As opposed to traditional verification, where one handles the question of whether a system satisfies, or not, a given specification, reasoning about quality addresses the question of how well the system satisfies the specification. One direction in this effort is to refine the \u201ceventually\u201d operators of temporal logic to discounting operators: the satisfaction value of a specification is a value in [0,1], where the longer it takes to fulfill eventuality requirements, the smaller the satisfaction value is.               In this paper we introduce an augmentation by discounting of Linear Temporal Logic (LTL), and study it, as well as its combination with propositional quality operators. We show that one can augment LTL with an arbitrary set of discounting functions, while preserving the decidability of the\u00a0\u2026", "num_citations": "55\n", "authors": ["1788"]}
{"title": "From linear time to branching time\n", "abstract": " Model checking is a method for the verification of systems with respect to their specifications. Symbolic model-checking, which enables the verification of large systems, proceeds by calculating fixed-point expressions over the system's set of states. The \u03bc-calculus is a branching-time temporal logic with fixed-point operators. As such, it is a convenient logic for symbolic model-checking tools. In particular, the alternation-free fragment of \u03bc-calculus has a restricted syntax, making the symbolic evaluation of its formulas computationally easy. Formally, it takes time that is linear in the size of the system. On the other hand, specifiers find the \u03bc-calculus inconvenient. In addition, specifiers often prefer to use linear-time formalisms. Such formalisms, however, cannot in general be translated to the alternation-free \u03bc-calculus, and their symbolic evaluation involves nesting of fixed-points, resulting in time complexity that is\u00a0\u2026", "num_citations": "52\n", "authors": ["1788"]}
{"title": "A theory of mutations with applications to vacuity, coverage, and fault tolerance\n", "abstract": " The quality of formal specifications and the circuits they are written for can be evaluated through checks such as vacuity and coverage. Both checks involve mutations to the specification or the circuit implementation. In this context, we study and prove properties of mutations to finite-state systems. Since faults can be viewed as mutations, our theory of mutations can also be used in a formal approach to fault injection. We demonstrate theoretically and with experimental results how relations and orders amongst mutations can be used to improve specifications and reason about coverage of fault tolerant circuits.", "num_citations": "51\n", "authors": ["1788"]}
{"title": "A framework for inherent vacuity\n", "abstract": " Vacuity checking is traditionally performed after model checking has terminated successfully. It ensures that all the elements of the specification have played a role in its satisfaction by the design. Vacuity checking gets as input both design and specification, and is based on an in-depth investigation of the relation between them. Vacuity checking has been proven to be very useful in detecting errors in the modeling of the design or the specification. The need to check the quality of specifications is even more acute in property-based design, where the specification is the only input, serving as a basis to the development of the system. Current work on property assurance suggests various sanity checks, mostly based on satisfiability, non-validity, and realizability, but lacks a general framework for reasoning about the quality of specifications.               We describe a framework for inherent vacuity, which carries the\u00a0\u2026", "num_citations": "51\n", "authors": ["1788"]}
{"title": "Reasoning about online algorithms with weighted automata\n", "abstract": " We describe an automata-theoretic approach for the competitive analysis of online algorithms. Our approach is based on weighted automata, which assign to each input word a cost in R\u22650. By relating the \u201cunbounded look ahead\u201d of optimal offline algorithms with nondeterminism, and relating the \u201cno look ahead\u201d of online algorithms with determinism, we are able to solve problems about the competitive ratio of online algorithms, and the memory they require, by reducing them to questions about determinization and approximated determinization of weighted automata.", "num_citations": "50\n", "authors": ["1788"]}
{"title": "Memoryful branching-time logic\n", "abstract": " Traditional branching-time logics such as CTL* are memoryless: once a path in the computation tree is quantified at a given node, the computation that led to that node is forgotten. Recent work in planning suggests that CTL* cannot easily express temporal goals that refer to whole computations. Such goals require memoryful quantification of paths. With such a memoryful quantification, Epsi holds at a node s of a computation tree if there is a path pi starting at the root of the tree and going through s such that pi satisfies the linear-time formula psi. We define the memoryful branching-time logic mCTL* and study its expressive power and algorithmic properties. We show that mCTL* is as expressive, but exponentially more succinct, than CTL*, and that the ability of mCTL* to refer to the present is essential for this equivalence. From the algorithmic point of view, while the satisfiability problem for mCTL* is 2EXPTIME\u00a0\u2026", "num_citations": "48\n", "authors": ["1788"]}
{"title": "On the complexity of parity word automata\n", "abstract": " Different types of nondeterministic automata on infinite words differ in their succinctness and in the complexity for their nonemptiness problem. A simple translation of a parity automaton to an equivalent B\u00fcchi automaton is quadratic: a parity automaton with n states, m transitions, and index k may result in a B\u00fcchi automaton of size O((n + m)k). The best known algorithm for the nonemptiness problem of parity automata goes through B\u00fcchi automata, leading to a complexity of O((n + m)k). In this paper we show that while the translation of parity automata to B\u00fcchi automata cannot be improved, the special structure of the acceptance condition of parity automata can be used in order to solve the nonemptiness problem directly, with a dynamic graph algorithm of complexity O((n + m) log k).", "num_citations": "48\n", "authors": ["1788"]}
{"title": "On the complexity of branching modular model checking\n", "abstract": " In modular verification the specification of a module consists of two parts. One part describes the guaranteed behavior of the module. The other part describes the assumed behavior of the system in which the module is interacting. This is called the assume-guarantee paradigm. In this paper we consider assume-guarantee specifications in which the assumptions and the guarantees are specified by universal branching temporal formulas (i.e., all path quantifiers are universal). Verifying modules with respect to such specifications is called the branching modular model-checking problem. We consider both \u2200CTL and \u2200CTL*, the universal fragments of CTL and CTL*.We develop two fundamental techniques: building maximal models for \u2200CTL and \u2200CTL* formulas and using alternating automata to obtain space-efficient algorithms for fair model checking. Using these techniques we classify the complexity of\u00a0\u2026", "num_citations": "48\n", "authors": ["1788"]}
{"title": "Complementation constructions for nondeterministic automata on infinite words\n", "abstract": " The complementation problem for nondeterministic automata on infinite words has numerous applications in formal verification. In particular, the language-containment problem, to which many verification problems are reduced, involves complementation. Traditional optimal complementation constructions are quite complicated and have not been implemented. Recently, we have developed an analysis techniques for runs of co-B\u00fcchi and generalized co-B\u00fcchi automata and used the analysis to describe simpler optimal complementation constructions for B\u00fcchi and generalized B\u00fcchi automata. In this work, we extend the analysis technique to Rabin and Streett automata, and use the analysis to describe novel and simple complementation constructions for them.", "num_citations": "46\n", "authors": ["1788"]}
{"title": "Relating linear and branching model checking\n", "abstract": " The difference in the complexity of branching and linear model checking has been viewed as an argument in favor of the branching paradigm. In particular, the computational advantage of CTL model checking over LTL model checking makes CTL a popular choice, leading to efficient model-checking tools for this logic. Can we use these tools in order to verify linear properties? In this paper we relate branching and linear model checking. With each LTL formula \u03c8, we associate a CTL formula \u03c8                                A                that is obtained from \u03c8 by preceding each temporal operator by the universal path quantifier A. We first describe a number of attempts to utilize the tight syntactic relation between \u03c8 and \u03c8                                A                in order to use CTL model-checking tools in the process of checking the formula \u03c8. Neither attempt, however, suggests a method that is guaranteed to perform better than usual\u00a0\u2026", "num_citations": "42\n", "authors": ["1788"]}
{"title": "Augmenting branching temporal logics with existential quantification over atomic propositions\n", "abstract": " In temporal-logic model checking, we verify the correctness of a program with respect to a desired behavior by checking whether a structure that models the program satisfies a temporal logic formula that specifies this behavior. One of the ways to overcome the expressiveness limitation of temporal logics is to augment them with quantification over atomic propositions. In this paper we consider the extension of branching temporal logics with existential quantification over atomic propositions. Once we add existential quantification to a branching temporal logic, it becomes sensitive to unwinding. That is, unwinding a structure into an infinite tree does not preserve the set of formulas it satisfies. Accordingly, we distinguish between two semantics, two practices as specification languages, and two versions of the model-checking problem for such a logic. One semantics refers to the structure that models the program\u00a0\u2026", "num_citations": "39\n", "authors": ["1788"]}
{"title": "Model checking for branching-time temporal logics\n", "abstract": " Consider the following procedure which gets as input two variables x and y and calculates their minimum in the output variable min: procedure minimum (x; y; min); if (x 6= 97) and (xy) then min:= x else min:= ySome readers may suspect that even though the procedure is called minimum, it does not really calculate the minimum of x and y. To increase these readers' belief in the correctness of the procedure, we can show them that it works correctly with hx; yi= h3; 7i. We can even suggest them to test the procedure with respect to random inputs. If we are lucky, all their random input pairs hx; yi will be such that x 6= 97 or y x. Naturally, each such test will increase the readers' belief in the correctness of the procedure and, after several successful tests, most readers will get convinced that the procedure is correct. Of course, an intelligent reader could have come with a counter-example to the correctness of the procedure1, but as long as we assume that our readers are fully automatic (as computers that test procedures are), the best they can do is to test the procedure again and again. Doing so, they either come across an unexpected behavior of the procedure and conclude that it is buggy or, they decide, after su ciently (according to their standards) many tests that the procedure is correct. This is a very unpleasant reality. To see how unpleasant it is one only has to change the procedure name from minimum to, say, max elevator weight. Indeed, our world is full of merciless bugs. While testing has once been considered a satisfying method to trace them and to get rid of them while they are still small and under control, today's rapid", "num_citations": "39\n", "authors": ["1788"]}
{"title": "Formalizing and reasoning about quality\n", "abstract": " Traditional formal methods are based on a Boolean satisfaction notion: a reactive system satisfies, or not, a given specification. We generalize formal methods to also address the quality of systems. As an adequate specification formalism we introduce the linear temporal logic LTL[]. The satisfaction value of an LTL[] formula is a number between 0 and 1, describing the quality of the satisfaction. The logic generalizes traditional LTL by augmenting it with a (parameterized) set  of arbitrary functions over the interval [0,1]. For example,  may contain the maximum or minimum between the satisfaction values of subformulas, their product, and their average.               The classical decision problems in formal methods, such as satisfiability, model checking, and synthesis, are generalized to search and optimization problems in the quantitative setting. For example, model checking asks for the quality in which a\u00a0\u2026", "num_citations": "37\n", "authors": ["1788"]}
{"title": "Improved model checking of hierarchical systems\n", "abstract": " We present a unified game-based approach for branching-time model checking of hierarchical systems. Such systems are exponentially more succinct than standard state-transition graphs, as repeated sub-systems are described only once. Early work on model checking of hierarchical systems shows that one can do better than a naive algorithm that \u201cflattens\u201d the system and removes the hierarchy. Given a hierarchical system S and a branching-time specification \u03c8 for it, we reduce the model-checking problem (does S satisfy \u03c8?) to the problem of solving a hierarchical game obtained by taking the product of S with an alternating tree automaton A \u03c8 for \u03c8. Our approach leads to clean, uniform, and improved model-checking algorithms for a variety of branching-time temporal logics. In particular, by improving the algorithm for solving hierarchical parity games, we are able to solve the model-checking problem for the \u03bc\u00a0\u2026", "num_citations": "37\n", "authors": ["1788"]}
{"title": "On verifying fault tolerance of distributed protocols\n", "abstract": " Distributed systems are composed of processes connected in some network. Distributed systems may suffer from faults: processes may stop, be interrupted, or be maliciously attacked. Fault-tolerant protocols are designed to be resistant to faults. Proving the resistance of protocols to faults is a very challenging problem, as it combines the parameterized setting that distributed systems are based-on, with the need to consider a hostile environment that produces the faults. Considering all the possible fault scenarios for a protocol is very difficult. Thus, reasoning about fault-tolerance protocols utterly needs formal methods.               In this paper we describe a framework for verifying the fault tolerance of (synchronous or asynchronous) distributed protocols. In addition to the description of the protocol and the desired behavior, the user provides the fault type (e.g., fail-stop, Byzantine) and its distribution (e.g., at most\u00a0\u2026", "num_citations": "37\n", "authors": ["1788"]}
{"title": "Automata theory and model checking\n", "abstract": " We study automata on infinite words and their applications in system specification and verification. We first introduce B\u00fcchi automata and survey their closure properties, expressive power, and determinization. We then introduce additional acceptance conditions and the model of alternating automata. We compare the different classes of automata in terms of expressive power and succinctness, and describe decision problems for them. Finally, we describe the automata-theoretic approach to system specification and verification.", "num_citations": "36\n", "authors": ["1788"]}
{"title": "From complementation to certification\n", "abstract": " In the automata-theoretic approach to model checking we check the emptiness of the product of a system S with an automaton  for the complemented specification. This gives rise to two automata-theoretic problems: complementation of word automata, which is used in order to generate , and the emptiness problem, to which model checking is reduced. Both problems have numerous other applications, and have been extensively studied for nondeterministic B\u00fcchi word automata (NBW). Nondeterministic generalized B\u00fcchi word automata (NGBW) have become popular in specification and verification and are now used in applications traditionally assigned to NBW. This is due to their richer acceptance condition, which leads to automata with fewer states and a simpler underlying structure.               In this paper we analyze runs of NGBW and use the analysis in order to describe a new\u00a0\u2026", "num_citations": "36\n", "authors": ["1788"]}
{"title": "Robust satisfaction\n", "abstract": " In order to check whether an open system satisfies a desired property, we need to check the behavior of the system with respect to an arbitrary environment. In the most general setting, the environment is another open system. Given an open system M and a property \u03c8, we say that M robustly satisfies \u03c8 iff for every open system M\u2019, which serves as an environment to M, the composition M\u2225M\u2019 satisfies \u03c8. The problem of robust model checking is then to decide, given M and \u03c8, whether M robustly satisfies \u03c8. In this paper we study the robust-model-checking problem. We consider systems modeled by nondeterministic Moore machines, and properties specified by branching temporal logic (for linear temporal logic, robust satisfaction coincides with usual satisfaction). We show that the complexity of the problem is Exptime-complete for Ctl and the \u03bc-calculus, and is 2Exptime-complete for Ctl*. We partition\u00a0\u2026", "num_citations": "35\n", "authors": ["1788"]}
{"title": "Recent challenges and ideas in temporal synthesis\n", "abstract": " In automated synthesis, we transform a specification into a system that is guaranteed to satisfy the specification against all environments. While model-checking theory has led to industrial development and use of formal-verification tools, the integration of synthesis in the industry is slow. This has to do with theoretical limitations, like the complexity of the problem, algorithmic limitations, like the need to determinize automata on infinite words and solve parity games, methodological reasons, like the lack of satisfactory compositional synthesis algorithms, and practical reasons: current algorithms produce systems that satisfy the specification, but may do so in a peculiar way and may be larger or less well-structured than systems constructed manually.                 The research community has managed to suggest some solutions to these limitations, and bring synthesis algorithms closer to practice. Significant\u00a0\u2026", "num_citations": "34\n", "authors": ["1788"]}
{"title": "Temporal synthesis for bounded systems and environments\n", "abstract": " Temporal synthesis is the automated construction of a system from its temporal specification. It is by now realized that requiring the synthesized system to satisfy the specifications against all possible environments may be too demanding, and, dually, allowing all systems may be not demanding enough. In this work we study bounded temporal synthesis, in which bounds on the sizes of the state space of the system and the environment are additional parameters to the synthesis problem. This study is motivated by the fact that such bounds may indeed change the answer to the synthesis problem, as well as the theoretical and computational aspects of the synthesis problem. In particular, a finer analysis of synthesis, which takes system and environment sizes into account, yields deeper insight into the quantificational structure of the synthesis problem and the relationship between strong synthesis -- there exists a system such that for all environments, the specification holds, and weak synthesis -- for all environments there exists a system such that the specification holds. We first show that unlike the unbounded setting, where determinacy of regular games implies that strong and weak synthesis coincide, these notions do not coincide in the bounded setting. We then turn to study the complexity of deciding strong and weak synthesis. We show that bounding the size of the system or both the system and the environment, turns the synthesis problem into a search problem, and one cannot expect to do better than brute-force search. In particular, the synthesis problem for bounded systems and environment is -complete (in terms of the bounds, for a\u00a0\u2026", "num_citations": "33\n", "authors": ["1788"]}
{"title": "Model checking linear properties of prefix-recognizable systems\n", "abstract": " We develop an automata-theoretic framework for reasoning about linear properties of infinite- state sequential systems. Our framework is based on the observation that states of such systems, which carry a finite but unbounded amount of information, can be viewed as nodes in an infinite tree, and transitions between states can be simulated by finite-state automata. Checking that the system satisfies a temporal property can then be done by an alternating two-way automaton that navigates through the tree. We introduce path automata on trees. The input to a path automaton is a tree, but the automaton cannot split to copies and it can read only a single path of the tree. In particular, two- way nondeterministic path automata enable exactly the type of navigation that is required in order to check linear properties of infinite-state sequential systems.               We demonstrate the versatility of the automata-theoretic\u00a0\u2026", "num_citations": "32\n", "authors": ["1788"]}
{"title": "Augmenting branching temporal logics with existential quantification over atomic propositions\n", "abstract": " In temporal-logic model checking, we verify the correctness of a program with respect to a desired behaviour by checking whether a structure that models the program satisfies a temporal logic formula that specifies this s behaviour. One of the ways to overcome the expressiveness limitation of temporal logics is to augment them with quantification over atomic propositions. In this paper we consider the extension of branching temporal logics with existential quantification over atomic propositions. Once we add existential quantification to a branching temporal logic, it becomes sensitive to unwinding. That is, unwinding a structure into an infinite tree does not preserve the set of formulas it satisfies. Accordingly, we distinguish between two semantics, two practices as specification languages, and two versions of the model-checking problem for such a logic. One semantics refers to the structure that models the program\u00a0\u2026", "num_citations": "32\n", "authors": ["1788"]}
{"title": "The weakness of self-complementation\n", "abstract": " Model checking is a method for the verification of systems with respect to their specifications. Symbolic model-checking, which enables the verification of large systems, proceeds by evaluating fixed-point expressions over the system\u2019s set of states. Such evaluation is particularly simple and efficient when the expressions do not contain alternation between least and greatest fixed-point operators; namely, when they belong to the alternation-free \u03bc-calculus (AFMC). Not all specifications, however, can be translated to AFMC, which is exactly as expressive as weak monadic second-order logic (WS2S). Rabin showed that a set T of trees can be expressed in WS2S if and only if both T and its complement can be recognized by nondeterministic B\u00fcchi tree automata. For the \u201conly if\u201d direction, Rabin constructed, given two nondeterministic B\u00fcchi tree automata U and U\u223c that recognize T and its complement, a WS2S\u00a0\u2026", "num_citations": "32\n", "authors": ["1788"]}
{"title": "From quantity to quality\n", "abstract": " In temporal-logic model checking, we verify the correctness of a program with respect to a desired behavior by checking whether a structure that models the program satisfies a temporal-logic formula that specifies the behavior. The model-checking problem for the branching-time temporal logic CTL can be solved in linear running time, and model-checking tools for CTL are used successfully in industrial applications. The development of programs that must meet rigid real-time constraints has brought with it a need for real-time temporal logics that enable quantitative reference to time. Early research on real-time temporal logics uses the discrete domain of the integers to model time. Present research on real-time temporal logics focuses on continuous time and uses the dense domain of the reals to model time. There, model checking becomes significantly more complicated. For example, the model-checking\u00a0\u2026", "num_citations": "32\n", "authors": ["1788"]}
{"title": "Alternation removal in B\u00fcchi automata\n", "abstract": " Alternating automata play a key role in the automata-theoretic approach to specification, verification, and synthesis of reactive systems. Many algorithms on alternating automata, and in particular, their nonemptiness test, involve removal of alternation: a translation of the alternating automaton to an equivalent nondeterministic one. For alternating B\u00fcchi automata, the best known translation uses the \u201cbreakpoint construction\u201d and involves an O(3                   n                 ) state blow-up. The translation was described by Miyano and Hayashi in 1984, and is widely used since, in both theory and practice. Yet, the best known lower bound is only\u00a02                   n                 .               In this paper we develop and present a complete picture of the problem of alternation removal in alternating B\u00fcchi automata. In the lower bound front, we show that the breakpoint construction captures the accurate essence of alternation removal\u00a0\u2026", "num_citations": "31\n", "authors": ["1788"]}
{"title": "Resets vs. aborts in linear temporal logic\n", "abstract": " There has been a major emphasis recently in the semiconductor industry on designing industrial-strength property specification languages. Two major languages are ForSpec and Sugar 2.0, which are both extensions of Pnueli\u2019s LTL. Both ForSpec and Sugar 2.0 directly support reset/abort signals, in which a check for a property \u03a8 may be terminated and declared successful by a reset/abort signal, provided the check has not yet failed. ForSpec and Sugar 2.0, however, differ in their definition of failure. The definition of failure in ForSpec is syntactic, while the definition in Sugar 2.0 is semantic. In this work we examine the implications of this distinction between the two approaches, which we refer to as the reset approach (for ForSpec) and the abort approach (for Sugar 2.0). In order to focus on the reset/abort issue, we do not consider the full languages, which are quite rich, but rather the extensions of LTL with\u00a0\u2026", "num_citations": "31\n", "authors": ["1788"]}
{"title": "Coverage metrics for temporal logic model checking\n", "abstract": " In formal verification, we verify that a system is correct with respect to a specification. Even when the system is proved to be correct, there is still a question of how complete the specification is, and whether it really covers all the behaviors of the system. In this paper we study coverage metrics for model checking. Coverage metrics are based on modifications we apply to the system in order to check which parts of it were actually relevant for the verification process to succeed. We introduce two principles that we believe should be part of any coverage metric for model checking: a distinction between state-based and logic-based coverage, and a distinction between the system and its environment. We suggest several coverage metrics that apply these principles, and we describe two algorithms for finding the non-covered parts of the system under these definitions. The first algorithm is a symbolic implementation\u00a0\u2026", "num_citations": "30\n", "authors": ["1788"]}
{"title": "Latticed simulation relations and games\n", "abstract": " Multi-valued Kripke structures are Kripke structures in which the atomic propositions and the transitions are not Boolean and can take values from some set. In particular, latticed Kripke structures, in which the elements in the set are partially ordered, are useful in abstraction, query checking, and reasoning about multiple view-points. The challenges that formal methods involve in the Boolean setting are carried over, and in fact increase, in the presence of multi-valued systems and logics. We lift to the latticed setting two basic notions that have been proven useful in the Boolean setting. We first define latticed simulation between latticed Kripke structures. The relation maps two structures M1 and M2 to a lattice element that essentially denotes the truth value of the statement \"every behavior of M1 is also a behavior of M2\". We show that latticed-simulation is logically characterized by the universal fragment of latticed \u00b5\u00a0\u2026", "num_citations": "29\n", "authors": ["1788"]}
{"title": "Network-formation games with regular objectives\n", "abstract": " Classical network-formation games are played on a directed graph. Players have reachability objectives: each player has to select a path from his source to target vertices. Each edge has a cost, shared evenly by the players using it. We introduce and study network-formation games with regular objectives. In our setting, the edges are labeled by alphabet letters and the objective of each player is a regular language over the alphabet of labels.Unlike the case of reachability objectives, here the paths selected by the players need not be simple, thus a player may traverse some edges several times. Edge costs are shared by the players with the share being proportional to the number of times the edge is traversed. We study the existence of a pure Nash equilibrium (NE), the inefficiency of a NE compared to a social-optimum solution, and computational complexity problems in this setting.", "num_citations": "28\n", "authors": ["1788"]}
{"title": "Formally reasoning about quality\n", "abstract": " In recent years, there has been a growing need and interest in formally reasoning about the quality of software and hardware systems. As opposed to traditional verification, in which one considers the question of whether a system satisfies a given specification or not, reasoning about quality addresses the question of how well the system satisfies the specification. We distinguish between two approaches to specifying quality. The first, propositional quality, extends the specification formalism with propositional quality operators, which prioritize and weight different satisfaction possibilities. The second, temporal quality, refines the \u201ceventually\u201d operators of the specification formalism with discounting operators, whose semantics takes into an account the delay incurred in their satisfaction. In this article, we introduce two quantitative extensions of Linear Temporal Logic (LTL), one by propositional quality operators and one\u00a0\u2026", "num_citations": "28\n", "authors": ["1788"]}
{"title": "Repairing multi-player games\n", "abstract": " Synthesis is the automated construction of systems from their specifications. Modern systems often consist of interacting components, each having its own objective. The interaction among the components is modeled by a multi-player game. Strategies of the components induce a trace in the game, and the objective of each component is to force the game into a trace that satisfies its specification. This is modeled by augmenting the game with omega-regular winning conditions. Unlike traditional synthesis games, which are zero-sum, here the objectives of the components do not necessarily contradict each other. Accordingly, typical questions about these games concern their stability-whether the players reach an equilibrium, and their social welfare-maximizing the set of (possibly weighted) specifications that are satisfied. We introduce and study repair of multi-player games. Given a game, we study the possibility of modifying the objectives of the players in order to obtain stability or to improve the social welfare. Specifically, we solve the problem of modifying the winning conditions in a given concurrent multi-player game in a way that guarantees the existence of a Nash equilibrium. Each modification has a value, reflecting both the cost of strengthening or weakening the underlying specifications, as well as the benefit of satisfying specifications in the obtained equilibrium. We seek optimal modifications, and we study the problem for various omega-regular objectives and various cost and benefit functions. We analyze the complexity of the problem in the general setting as well as in one with a fixed number of players. We also study two additional\u00a0\u2026", "num_citations": "28\n", "authors": ["1788"]}
{"title": "Nondeterminism in the presence of a diverse or unknown future\n", "abstract": " Choices made by nondeterministic word automata depend on both the past (the prefix of the word read so far) and the future (the suffix yet to be read). In several applications, most notably synthesis, the future is diverse or unknown, leading to algorithms that are based on deterministic automata. Hoping to retain some of the advantages of nondeterministic automata, researchers have studied restricted classes of nondeterministic automata. Three such classes are nondeterministic automata that are good for trees (GFT; i.e., ones that can be expanded to tree automata accepting the derived tree languages, thus whose choices should satisfy diverse futures), good for games (GFG; i.e., ones whose choices depend only on the past), and determinizable by pruning (DBP; i.e., ones that embody equivalent deterministic automata). The theoretical properties and relative merits of the different classes are still open\u00a0\u2026", "num_citations": "28\n", "authors": ["1788"]}
{"title": "On bounded specifications\n", "abstract": " Bounded model checking methodologies check the correctness of a system with respect to a given specification by examining computations of a bounded length. Results from set-theoretic topology imply that sets in \u03a3\u03c9 that are both open and closed (clopen sets) are precisely bounded sets: membership of a word in a clopen set can be determined by examining a bounded prefix of it. Clopen sets correspond to specifications that are both safety and co-safety. In this paper we study bounded specifications from this perspective. We consider both the linear and the branching frameworks. In the linear framework, we show that when clopen specifications are given by word automata or temporal logic formulas, we can identify a bound and translate the specification to bounded formalisms such as cycle-free automata and bounded LTL. In the branching framework, we show that while clopen sets of trees with infinite\u00a0\u2026", "num_citations": "28\n", "authors": ["1788"]}
{"title": "Profile trees for B\u00fcchi word automata, with application to determinization\n", "abstract": " The determinization of B\u00fcchi automata is a celebrated problem, with applications in synthesis, probabilistic verification, and multi-agent systems. Since the 1960s, there has been a steady progress of constructions: by McNaughton, Safra, Piterman, Schewe, and others. Despite the proliferation of solutions, they are all essentially ad-hoc constructions, with little theory behind them other than proofs of correctness. Since Safra, all optimal constructions employ trees as states of the deterministic automaton, and transitions between states are defined operationally over these trees. The operational nature of these constructions complicates understanding, implementing, and reasoning about them, and should be contrasted with complementation, where a solid theory in terms of automata run dag s underlies modern constructions. In 2010, we described a profile-based approach to B\u00fcchi complementation, where a profile is\u00a0\u2026", "num_citations": "27\n", "authors": ["1788"]}
{"title": "On the behavioral inheritance of state-based objects\n", "abstract": " We consider the inheritance of state based behavior in object oriented analysis and design, as it arises, for example, in specifying behavior in the UML using statecharts. We concentrate on behavioral conformity and the resulting substitutability of classes, whereby the inheritance mechanism is to retain original behaviors. There are many deep and unresolved questions around this issue, which cannot be addressed without a clear and rigorous picture of what exactly is meant by behavioral conformity, and how computationally complex it is to detect. We first define a basic propositional level computational model for object oriented designs, and then define substitutability and inheritance in the linear and branching paradigms. We relate these to trace containment and R. Milner's (1971) notion of simulation and deduce the complexity of some of the relevant algorithmic problems. The paper thus sets the stage for further\u00a0\u2026", "num_citations": "27\n", "authors": ["1788"]}
{"title": "From liveness to promptness\n", "abstract": " Liveness temporal properties state that something \u201cgood\u201d eventually happens, e.g., every request is eventually granted. In Linear Temporal Logic (LTL), there is no a priori bound on the \u201cwait time\u201d for an eventuality to be fulfilled. That is, F\u03b8 asserts that \u03b8 holds eventually, but there is no bound on the time when \u03b8 will hold. This is troubling, as designers tend to interpret an eventuality F                 \u03b8 as an abstraction of a bounded eventuality F                 \u2009\u2264\u2009k                                  \u03b8, for an unknown k, and satisfaction of a liveness property is often not acceptable unless we can bound its wait time. We introduce here prompt-LTL, an extension of LTL with the prompt-eventually operator F                                    p                 . A system S satisfies a prompt-LTL formula \u03d5 if there is some bound k on the wait time for all prompt-eventually subformulas of \u03d5 in all computations of S. We study various problems related to prompt-LTL\u00a0\u2026", "num_citations": "26\n", "authors": ["1788"]}
{"title": "An improved algorithm for the membership problem for extended regular expressions\n", "abstract": " Extended regular expressions (ERE) define regular languages using union, concatenation, repetition, intersection, and complementation operators. The fact ERE allow intersection and complementation makes them exponentially more succinct than regular expressions. The membership problem for extended regular expressions is to decide, given an expression r and a word w, whether w belongs to the language defined by r. Since regular expressions are useful for describing patterns in strings, the membership problem has numerous applications. In many such applications, the words w are very long and patterns are conveniently described using ERE, making efficient solutions to the membership problem of great practical interest.               In this paper we introduce alternating automata with synchronized universality and negation and use them in order to obtain a simple and efficient algorithm for solving\u00a0\u2026", "num_citations": "26\n", "authors": ["1788"]}
{"title": "Relating word and tree automata\n", "abstract": " In the automata-theoretic approach to verification, we translate specifications to automata. Complexity considerations motivate the distinction between different types of automata. Already in the 60's, it was known that deterministic Buchi word automata are less expressive than nondeterministic Buchi word automata. The proof is easy and can be stated in a few lines. In the late 60's, Rabin proved that Buchi tree automata are less expressive than Rabin tree automata. This proof is much harder. In this work we relate the expressiveness gap between deterministic and nondeterministic Buchi word automata and the expressiveness gap between Buchi and Rabin tree automata. We consider tree automata that recognize derived languages. For a word language L, the derived language of L, denoted L/spl Delta/, is the set of all trees all of whose paths are in L. Since often we want to specify that all the computations of the\u00a0\u2026", "num_citations": "26\n", "authors": ["1788"]}
{"title": "On the construction of fine automata for safety properties\n", "abstract": " Of special interest in formal verification are safety properties, which assert that the system always stays within some allowed region. Each safety property \u03c8 can be associated with a set of bad prefixes: a set of finite computations such that an infinite computation violates \u03c8 iff it has a prefix in the set. By translating a safety property to an automaton for its set of bad prefixes, verification can be reduced to reasoning about finite words: a system is correct if none of its computations has a bad prefix. Checking the latter circumvents the need to reason about cycles and simplifies significantly methods like symbolic fixed-point based verification, bounded model checking, and more.               A drawback of the translation lies in the size of the automata: while the translation of a safety LTL formula \u03c8 to a nondeterministic B\u00fcchi automaton is exponential, its translation to a tight bad-prefix automaton \u2014 one that accepts all\u00a0\u2026", "num_citations": "24\n", "authors": ["1788"]}
{"title": "Typeness for \u03c9-Regular Automata\n", "abstract": " We introduce and study three notions of typeness for automata on infinite words. For an acceptance-condition class \u03b3 (that is, \u03b3 is weak, B\u00fcchi, co-B\u00fcchi, Rabin, or Streett), deterministic \u03b3                         -typeness asks for the existence of an equivalent \u03b3-automaton on the same deterministic structure, nondeterministic \u03b3-typeness asks for the existence of an equivalent \u03b3-automaton on the same structure, and \u03b3-powerset-typeness asks for the existence of an equivalent \u03b3-automaton on the (deterministic) powerset structure \u2013 one obtained by applying the subset construction. The notions are helpful in studying the complexity and complication of translations between the various classes of automata. For example, we prove that deterministic B\u00fcchi automata are co-B\u00fcchi type; it follows that a translation from deterministic B\u00fcchi to deterministic co-B\u00fcchi automata, when exists, involves no blow up. On the other hand\u00a0\u2026", "num_citations": "24\n", "authors": ["1788"]}
{"title": "Rigorous approximated determinization of weighted automata\n", "abstract": " A nondeterministic weighted finite automaton (WFA) maps an input word to a numerical value. Applications of weighted automata include formal verification of quantitative properties, as well as text, speech, and image processing. Many of these applications require the WFAs to be deterministic, or work substantially better when the WFAs are deterministic. Unlike NFAs, which can always be determinized, not all WFAs have an equivalent deterministic weighted automaton (DWFA). In Mohri (1997)[22], Mohri describes a determinization construction for a subclass of WFA. He also describes a property of WFAs (the twins property), such that all WFAs that satisfy the twins property are determinizable and the algorithm terminates on them. Unfortunately, many natural WFAs cannot be determinized. In this paper we study approximated determinization of WFAs. We describe an algorithm that, given a WFA A and an\u00a0\u2026", "num_citations": "23\n", "authors": ["1788"]}
{"title": "Unifying B\u00fcchi complementation constructions\n", "abstract": " Complementation of B\\\"uchi automata, required for checking automata containment, is of major theoretical and practical interest in formal verification. We consider two recent approaches to complementation. The first is the rank-based approach of Kupferman and Vardi, which operates over a DAG that embodies all runs of the automaton. This approach is based on the observation that the vertices of this DAG can be ranked in a certain way, termed an odd ranking, iff all runs are rejecting. The second is the slice-based approach of K\\\"ahler and Wilke. This approach tracks levels of \"split trees\" - run trees in which only essential information about the history of each run is maintained. While the slice-based construction is conceptually simple, the complementing automata it generates are exponentially larger than those of the recent rank-based construction of Schewe, and it suffers from the difficulty of symbolically encoding levels of split trees. In this work we reformulate the slice-based approach in terms of run DAGs and preorders over states. In doing so, we begin to draw parallels between the rank-based and slice-based approaches. Through deeper analysis of the slice-based approach, we strongly restrict the nondeterminism it generates. We are then able to employ the slice-based approach to provide a new odd ranking, called a retrospective ranking, that is different from the one provided by Kupferman and Vardi. This new ranking allows us to construct a deterministic-in-the-limit rank-based automaton with a highly restricted transition function. Further, by phrasing the slice-based approach in terms of ranks, our approach affords a simple symbolic\u00a0\u2026", "num_citations": "22\n", "authors": ["1788"]}
{"title": "On locally checkable properties\n", "abstract": " The large computational price of formal verification of general \u03c9-regular properties has led to the study of restricted classes of properties, and to the development of verification methodologies for them. Examples that have been widely accepted by the industry include the verification of safety properties, and bounded model checking. We introduce and study another restricted class of properties \u2013 the class of locally checkable properties. For an integer k \u22651, a language L\u2009\u2286\u2009\u03a3                 \u03c9                is k-checkable if there is a language R\u2009\u2286\u2009\u03a3                 k                (of \u201callowed subwords\u201d) such that a word w belongs to L iff all the subwords of w of length k belong to R. A property is locally checkable if its language is k-checkable for some k. Locally checkable properties, which are a special case of safety properties, are common in the specification of systems. In particular, one can often bound an eventuality\u00a0\u2026", "num_citations": "22\n", "authors": ["1788"]}
{"title": "Coverage of implementations by simulating specifications\n", "abstract": " In formal verification, we verify that an implementation is correct with respect to a specification. When verification succeeds and the implementation is proven to be correct, there is still a question of how complete the specification is, and whether it really covers all the behaviors of the implementation. In this paper we study coverage for simulation-based formal verification, where both the implementation and the specification are modelled by labeled state-transition graphs, and an implementation I satisfies a specification S if S simulates I. Our measure of coverage is based on small modifications we apply to I. A part of I is covered by S if the mutant implementation in which this part is modified is no longer simulated by S. Thus, \u201cmutation coverage\u201d tells us which parts of the implementation were actually essential for the success of the verification. We describe two algorithms for finding the parts of the\u00a0\u2026", "num_citations": "22\n", "authors": ["1788"]}
{"title": "How Deterministic are Good-For-Games Automata?\n", "abstract": " In GFG automata, it is possible to resolve nondeterminism in a way that only depends on the past and still accepts all the words in the language. The motivation for GFG automata comes from their adequacy for games and synthesis, wherein general nondeterminism is inappropriate. We continue the ongoing effort of studying the power of nondeterminism in GFG automata. Initial indications have hinted that every GFG automaton embodies a deterministic one. Today we know that this is not the case, and in fact GFG automata may be exponentially more succinct than deterministic ones. We focus on the typeness question, namely the question of whether a GFG automaton with a certain acceptance condition has an equivalent GFG automaton with a weaker acceptance condition on the same structure. Beyond the theoretical interest in studying typeness, its existence implies efficient translations among different acceptance conditions. This practical issue is of special interest in the context of games, where the Buchi and co-Buchi conditions admit memoryless strategies for both players. Typeness is known to hold for deterministic automata and not to hold for general nondeterministic automata. We show that GFG automata enjoy the benefits of typeness, similarly to the case of deterministic automata. In particular, when Rabin or Streett GFG automata have equivalent Buchi or co-Buchi GFG automata, respectively, then such equivalent automata can be defined on a substructure of the original automata. Using our typeness results, we further study the place of GFG automata in between deterministic and nondeterministic ones. Specifically, considering\u00a0\u2026", "num_citations": "21\n", "authors": ["1788"]}
{"title": "The blow-up in translating LTL to deterministic automata\n", "abstract": " The translation of LTL formulas to nondeterministic automata involves an exponential blow-up, and so does the translation of nondeterministic automata to deterministic ones. This yields a  upper bound for the translation of LTL to deterministic automata. A lower bound for the translation was studied in [KV05a], which describes a  lower bound, leaving the problem of the exact blow-up open. In this paper we solve this problem and tighten the lower bound to .", "num_citations": "21\n", "authors": ["1788"]}
{"title": "Typeness for \u03c9-regular automata\n", "abstract": " We introduce and study three notions of typeness for automata on infinite words. For an acceptance-condition class \u03b3 (that is, \u03b3 is weak, B\u00fcchi, co-B\u00fcchi, Rabin, or Streett), deterministic \u03b3-typeness asks for the existence of an equivalent \u03b3-automaton on the same deterministic structure, nondeterministic \u03b3-typeness asks for the existence of an equivalent \u03b3-automaton on the same structure, and \u03b3-powerset-typeness asks for the existence of an equivalent \u03b3-automaton on the (deterministic) powerset structure \u2013 one obtained by applying the subset construction. The notions are helpful in studying the complexity and complication of translations between the various classes of automata. For example, we prove that deterministic B\u00fcchi automata are co-B\u00fcchi type; it follows that a translation from deterministic B\u00fcchi to deterministic co-B\u00fcchi automata, when exists, involves no blow up. On the other hand, we prove that\u00a0\u2026", "num_citations": "21\n", "authors": ["1788"]}
{"title": "An automata-theoretic approach to infinite-state systems\n", "abstract": " In this paper we develop an automata-theoretic framework for reasoning about infinite-state sequential systems. Our framework is based on the observation that states of such systems, which carry a finite but unbounded amount of information, can be viewed as nodes in an infinite tree, and transitions between states can be simulated by finite-state automata. Checking that a system satisfies a temporal property can then be done by an alternating two-way tree automaton that navigates through the tree. We show how this framework can be used to solve the model-checking problem for \u03bc-calculus and LTL specifications with respect to pushdown and prefix-recognizable systems. In order to handle model checking of linear-time specifications, we introduce and study path automata on trees. The input to a path automaton is a tree, but the automaton cannot split to copies and it can read only a single path of the tree\u00a0\u2026", "num_citations": "20\n", "authors": ["1788"]}
{"title": "Formalizing and reasoning about quality\n", "abstract": " Traditional formal methods are based on a Boolean satisfaction notion: a reactive system satisfies, or not, a given specification. We generalize formal methods to also address the quality of systems. As an adequate specification formalism we introduce the linear temporal logic LTL [F]. The satisfaction value of an LTL [F] formula is a number between 0 and 1, describing the quality of the satisfaction. The logic generalizes traditional LTL by augmenting it with a (parameterized) set F of arbitrary functions over the interval [0, 1]. For example, F may contain the maximum or minimum between the satisfaction values of subformulas, their product, and their average. The classical decision problems in formal methods, such as satisfiability, model checking, and synthesis, are generalized to search and optimization problems in the quantitative setting. For example, model checking asks for the quality in which a specification is satisfied, and synthesis returns a system satisfying the specification with the highest quality. Reasoning about quality gives rise to other natural questions, like the distance between specifications. We formalize these basic questions and study them for LTL [F]. By extending the automata-theoretic approach for LTL to a setting that takes quality into an account, we are able to solve the above problems and show that reasoning about LTL [F] has roughly the same complexity as reasoning about traditional LTL. 1", "num_citations": "19\n", "authors": ["1788"]}
{"title": "Avoiding determinization\n", "abstract": " Automata on infinite objects are extensively used in system specification, verification, and synthesis. Applications that involve determinization of automata on infinite words have been doomed to belong to the second category. This has to do with the intricacy of Safra's optimal determinization construction, the fact that the state space that results from determinization is awfully complex and is not amenable to optimizations and a symbolic implementation, and the fact that determinization requires the introduction of acceptance conditions that are more complex than the Buchi acceptance condition. Examples of applications that involve determinization and belong to the unfortunate second category include model checking of omega-regular properties, decidability of branching temporal logics, and synthesis and control of open systems. We offer an alternative to the standard automata-theoretic approach. The crux of our\u00a0\u2026", "num_citations": "19\n", "authors": ["1788"]}
{"title": "From complementation to certification\n", "abstract": " In the automata-theoretic approach to model checking we check the emptiness of the product of a system S with an automaton A\u00ac \u03c8 for the complemented specification. This gives rise to two automata-theoretic problems: complementation of word automata, which is used in order to generate A\u00ac \u03c8, and the emptiness problem, to which model checking is reduced. Both problems have numerous other applications, and have been extensively studied for nondeterministic B\u00fcchi word automata (NBW). Nondeterministic generalized B\u00fcchi word automata (NGBW) have become popular in specification and verification and are now used in applications traditionally assigned to NBW. This is due to their richer acceptance condition, which leads to automata with fewer states and a simpler underlying structure. In this paper we analyze runs of NGBW and use the analysis in order to describe a new complementation construction\u00a0\u2026", "num_citations": "19\n", "authors": ["1788"]}
{"title": "\u220f 2\u2229 \u03a3 2\u2261 AFMC\n", "abstract": " The \u03bc-calculus is an expressive specification language in which modal logic is extended with fixpoint operators, subsuming many dynamic, temporal, and description logics. Formulas of \u03bc-calculus are classified according to their alternation depth, which is the maximal length of a chain of nested alternating least and greatest fixpoint operators. Alternation depth is the major factor in the complexity of \u03bc-calculus model-checking algorithms. A refined classification of \u03bc-calculus formulas distinguishes between formulas in which the outermost fixpoint operator in the nested chain is a least fixpoint operator (\u03a3                         i formulas, where i is the alternation depth) and formulas where it is a greatest fixpoint operator (\u220f                         i formulas). The alternation-free \u03bc-calculus (AFMC) consists of \u03bc-calculus formulas with no alternation between least and greatest fixpoint operators. Thus, AFMC is a natural closure of \u03a3\u00a0\u2026", "num_citations": "19\n", "authors": ["1788"]}
{"title": "Trading probability for fairness\n", "abstract": " Behavioral properties of open systems can be formalized as objectives in two-player games. Turn-based games model asynchronous interaction between the players (the system and its environment) by interleaving their moves. Concurrent games model synchronous interaction: the players always move simultaneously. Infinitary winning criteria are considered: B\u00fcchi, co-B\u00fcchi, and more general parity conditions. A generalization of determinacy for parity games to concurrent parity games demands probabilistic (mixed) strategies: either player 1 has a mixed strategy to win with probability 1 (almost-sure winning), or player 2 has a mixed strategy to win with positive probability.               This work provides efficient reductions of concurrent probabilistic B\u00fcchi and co-B\u00fcchi games to turn-based games with B\u00fcchi condition and parity winning condition with three priorities, respectively. From a theoretical point of\u00a0\u2026", "num_citations": "19\n", "authors": ["1788"]}
{"title": "Dynamic resource allocation games\n", "abstract": " In resource allocation games, selfish players share resources that are needed in order to fulfill their objectives. The cost of using a resource depends on the load on it. In the traditional setting, the players make their choices concurrently and in one-shot. That is, a strategy for a player is a subset of the resources. We introduce and study dynamic resource allocation games. In this setting, the game proceeds in phases. In each phase each player chooses one resource. A scheduler dictates the order in which the players proceed in a phase, possibly scheduling several players to proceed concurrently. The game ends when each player has collected a set of resources that fulfills his objective. The cost for each player then depends on this set as well as on the load on the resources in it \u2013 we consider both congestion and cost-sharing games. We argue that the dynamic setting is the suitable setting for many\u00a0\u2026", "num_citations": "18\n", "authors": ["1788"]}
{"title": "Co-ing B\u00fcchi made tight and useful\n", "abstract": " We solve the longstanding open problems of the blowup involved in the translations (when possible) of a nondeterministic Buchi word automaton (NBW) to a nondeterministic co-Buchi word automaton (NCW) and to a deterministic co-Buchi word automaton (DCW). For the NBW to NCW translation, the currently known upper bound is 2 O(n   log   n)  and the lower bound is 1.5n. We improve the upper bound to n2 n  and describe a matching lower bound of 2 Omega(n) . For the NBW to DCW translation, the currently known upper bound is 2 O(m   log   n) . We improve it to 2 O(n) , which is asymptotically tight. Both of our upper-bound constructions are based on a simple subset construction, do not involve intermediate automata with richer acceptance conditions, and can be implemented symbolically. We point to numerous applications of the new constructions. In particular, they imply a simple subset-construction\u00a0\u2026", "num_citations": "18\n", "authors": ["1788"]}
{"title": "Finding shortest witnesses to the nonemptiness of automata on infinite words\n", "abstract": " In the automata-theoretic approach to formal verification, the satisfiability and the model-checking problems for linear temporal logics are reduced to the nonemptiness problem of automata on infinite words. Modifying the nonemptiness algorithm to return a shortest witness to the nonemptiness (that is, a word of the form uv                                            \u03c9                  that is accepted by the automaton and for which |uv| is minimal) has applications in synthesis and counterexample analysis. Unlike shortest accepting runs, which have been studied in the literature, the definition of shortest witnesses is semantic and is independent on the specification formalism of the property or the system. In particular, its robustness makes it appropriate for analyzing counterexamples of concurrent systems.               We study the problem of finding shortest witnesses in automata with various types of concurrency. We show that while\u00a0\u2026", "num_citations": "18\n", "authors": ["1788"]}
{"title": "Max and sum semantics for alternating weighted automata\n", "abstract": " In the traditional Boolean setting of formal verification, alternating automata are the key to many algorithms and tools. In this setting, the correspondence between disjunctions/conjunctions in the specification and nondeterministic/universal transitions in the automaton for the specification is straightforward. A recent exciting research direction aims at adding a quality measure to the satisfaction of specifications of reactive systems. The corresponding automata-theoretic framework is based on weighted automata, which map input words to numerical values. In the weighted setting, nondeterminism has a minimum semantics \u2013 the weight that an automaton assigns to a word is the cost of the cheapest run on it. For universal branches, researchers have studied a (dual) maximum semantics. We argue that a summation semantics is of interest too, as it captures the intuition that one has to pay for the cost of all\u00a0\u2026", "num_citations": "17\n", "authors": ["1788"]}
{"title": "A measured collapse of the modal \u03bc-calculus alternation hierarchy\n", "abstract": " The \u03bc-calculus model-checking problem has been of great interest in the context of concurrent programs. Beyond the need to use symbolic methods in order to cope with the state-explosion problem, which is acute in concurrent settings, several concurrency related problems are naturally solved by evaluation of \u03bc-calculus formulas. The complexity of a naive algorithm for model checking a \u03bc-calculus formula \u03c8 is exponential in the alternation depth d of \u03c8. Recent studies of the \u03bc-calculus and the related area of parity games have led to algorithms exponential only in . No symbolic version, however, is known for the improved algorithms, sacrificing the main practical attraction of the \u03bc-calculus.               The \u03bc-calculus can be viewed as a fragment of first-order fixpoint logic. One of the most fundamental theorems in the theory of fixpoint logic is the Collapse Theorem, which asserts that, unlike the case for the \u03bc\u00a0\u2026", "num_citations": "17\n", "authors": ["1788"]}
{"title": "Relating word and tree automata\n", "abstract": " In the automata-theoretic approach to verification, we translate specifications to automata. Complexity considerations motivate the distinction between different types of automata. Already in the 60s, it was known that deterministic B\u00fcchi word automata are less expressive than nondeterministic B\u00fcchi word automata. The proof is easy and can be stated in a few lines. In the late 60s, Rabin proved that B\u00fcchi tree automata are less expressive than Rabin tree automata. This proof is much harder. In this work we relate the expressiveness gap between deterministic and nondeterministic B\u00fcchi word automata and the expressiveness gap between B\u00fcchi and Rabin tree automata. We consider tree automata that recognize derived languages. For a word language L, the derived language of L, denoted L\u25b3, is the set of all trees all of whose paths are in L. Since often we want to specify that all the computations of the program\u00a0\u2026", "num_citations": "16\n", "authors": ["1788"]}
{"title": "Promptness in \u03c9-Regular Automata\n", "abstract": " Liveness properties of on-going reactive systems assert that something good will happen eventually. In satisfying liveness properties, there is no bound on the \u201cwait time\u201d, namely the time that may elapse until an eventuality is fulfilled. The traditional \u201cunbounded\u201d semantics of liveness properties nicely corresponds to the classical semantics of automata on infinite objects. Indeed, acceptance is defined with respect to the set of states the run visits infinitely often, with no bound on the number of transitions taken between successive visits.               In many applications, it is important to bound the wait time in liveness properties. Bounding the wait time by a constant is not always possible, as the bound may not be known in advance. It may also be very large, resulting in large specifications. Researchers have studied prompt eventualities, where the wait time is bounded, but the bound is not known in advance. We\u00a0\u2026", "num_citations": "15\n", "authors": ["1788"]}
{"title": "Latticed simulation relations and games\n", "abstract": " Multi-valued Kripke structures are Kripke structures in which the atomic propositions and the transitions are not Boolean and can take values from some set. In particular, latticed Kripke structures, in which the elements in the set are partially ordered, are useful in abstraction, query checking, and reasoning about multiple view-points. The challenges that formal methods involve in the Boolean setting are carried over, and in fact increase, in the presence of multi-valued systems and logics. We lift to the latticed setting two basic notions that have been proven useful in the Boolean setting. We first define latticed simulation between latticed Kripke structures. The relation maps two structures M                 1 and M                 2 to a lattice element that essentially denotes the truth value of the statement \u201cevery behavior of M                 1 is also a behavior of M                 2\u201d. We show that latticed-simulation is logically\u00a0\u2026", "num_citations": "15\n", "authors": ["1788"]}
{"title": "An Abstraction-Refinement Methodologyfor Reasoning about Network Games\n", "abstract": " Network games (NGs) are played on directed graphs and are extensively used in network design and analysis. Search problems for NGs include finding special strategy profiles such as a Nash equilibrium and a globally-optimal solution. The networks modeled by NGs may be huge. In formal verification, abstraction has proven to be an extremely effective technique for reasoning about systems with big and even infinite state spaces. We describe an abstraction-refinement methodology for reasoning about NGs. Our methodology is based on an abstraction function that maps the state space of an NG to a much smaller state space. We search for a global optimum and a Nash equilibrium by reasoning on an under-and an over-approximation defined on top of this smaller state space. When the approximations are too coarse to find such profiles, we refine the abstraction function. We extend the abstraction-refinement methodology to labeled networks, where the objectives of the players are regular languages. Our experimental results demonstrate the effectiveness of the methodology. View Full-Text", "num_citations": "14\n", "authors": ["1788"]}
{"title": "Hierarchical network formation games\n", "abstract": " Classical network-formation games (NFGs) are played on directed graphs, and are used in network design and analysis. Edges in the network are associated with costs and players have reachability objectives, which they try to fulfill at a minimal cost. When several players use the same edge, they share its cost. The theoretical and practical aspects of NFGs have been extensively studied and are well understood. All studies of NFGs, however, consider an explicit representation of the network. In practice, networks are often built in a hierarchical manner. Technically, some of the vertices in the network are boxes, associated with nested sub-networks, where a sub-network may be \u201ccalled\u201d by several boxes in the network. This makes hierarchical networks exponentially more succinct than traditional \u201cflat\u201d networks.                 We introduce hierarchical network formation games (HNFGs) and study theoretical and\u00a0\u2026", "num_citations": "14\n", "authors": ["1788"]}
{"title": "Synthesis from component libraries with costs\n", "abstract": " Synthesis is the automated construction of a system from its specification. In real life, hardware and software systems are rarely constructed from scratch. Rather, a system is typically constructed from a library of components. Lustig and Vardi formalized this intuition and studied LTL synthesis from component libraries. In real life, designers seek optimal systems. In this paper we add optimality considerations to the setting. We distinguish between quality considerations (for example, size \u2013 the smaller a system is, the better it is), and pricing (for example, the payment to the company who manufactured the component). We study the problem of designing systems with minimal quality-cost and price. A key point is that while the quality cost is individual \u2013 the choices of a designer are independent of choices made by other designers that use the same library, pricing gives rise to a resource-allocation game\u00a0\u2026", "num_citations": "14\n", "authors": ["1788"]}
{"title": "What triggers a behavior?\n", "abstract": " We introduce and study trigger querying. Given a model M and a temporal behavior \\vartheta, trigger querying is the problem of finding the set of scenarios that trigger \\vartheta in M. That is, if a computation of M has a prefix that follows the scenario, then its suffix satisfies \\vartheta. Trigger querying enables one to find, for example, given a program with a function f, the scenarios that lead to calling f with some parameter value, or to find, given a hardware design with signal err, the scenarios after which the signal err ought to be eventually raised. We formalize trigger querying using the temporal operator \\mapsto (triggers), which is the most useful operator in modern industrial specification languages. A regular expression r triggers an LTL formula \\vartheta in a system M, denoted M {\\text{M | = r }} \\mapsto \\vartheta, if for every computation \\pi of M and index i \\geqslant 0, if the prefix of \\pi up to position i is a word in the\u00a0\u2026", "num_citations": "12\n", "authors": ["1788"]}
{"title": "\u03c9-regular languages are testable with a constant number of queries\n", "abstract": " We continue the study of combinatorial property testing. For a property \u03c8, an \u025b-test for \u03c8, for 0< \u025b\u2a7d 1, is a randomized algorithm that given an input x, returns \u201cyes\u2019\u2019if x satisfies \u03c8, and returns \u201cno\u2019\u2019with high probability if x is \u025b-far from satisfying \u03c8, where \u025b-far essentially means that an \u025b-fraction of x needs to be changed in order for it to satisfy \u03c8. In (Proceedings of the 40th IEEE Symposium on Foundations of Computer Science, 1999, pp. 645\u2013655), Alon et al. show that regular languages are \u025b-testable with a constant (depends on \u03c8 and \u025b and independent of x) number of queries. We extend the result in (Proceedings of the 40th IEEE Symposium on Foundations of Computer Science, 1999, pp. 645\u2013655) to \u03c9-regular languages: given a nondeterministic B\u00fcchi automaton A on infinite words and a small \u025b> 0, we describe an algorithm that gets as input an infinite lasso-shape word of the form x\u00b7 y \u03c9, for finite words x\u00a0\u2026", "num_citations": "12\n", "authors": ["1788"]}
{"title": "Synthesis of uninitialized systems\n", "abstract": " The sequential synthesis problem, which is closely related to Church\u2019s solvability problem, asks, given a specification in the form of a binary relation between input and output streams, for the construction of a finite-state stream transducer that converts inputs to appropriate outputs. For efficiency reasons, practical sequential hardware is often designed to operate without prior initialization. Such hardware designs can be modeled by uninitialized state machines, which are required to satisfy their specification if started from any state. In this paper we solve the sequential synthesis problem for uninitialized systems, that is, we construct uninitialized finite-state stream transducers. We consider specifications given by LTL formulas, deterministic, nondeterministic, universal, and alternating B\u00fcchi automata. We solve this uninitialized synthesis problem by reducing it to the well-understood initialized synthesis problem\u00a0\u2026", "num_citations": "12\n", "authors": ["1788"]}
{"title": "Counting with automata\n", "abstract": " Classical models of computations, such as Turing machines and automata, have been enriched with existential and universal branching to capture concurrency. Unlike the models used in the study of real concurrent systems, in these types of branching no cooperation takes place between the spawned precesses, except when time comes to decide whether the input should be accepted. It turned out that this weak cooperation is sufficient to make nondeterministic and universal automata exponentially more succinct than deterministic automata, and to make their combination, namely alternating automata, doubly exponentially more succinct than deterministic automata CKS81]. Nevertheless, as studied in DH94], enriching automata with real concurrency, where the spawned processes can cooperate all along the computation, results in even more succinct automata. In particular, concurrent alternating automata are triply exponentially more succinct than deterministic automata. One of the natural examples of the power of concurrency is the ability to count to n with logn concurrent processes, with the i'th processor being responsible to the value of the i'th bit in the boolean representation of n. In this work we study the cost of counting within the other types of concurrency.We first study the number of states required for an automaton to count to n, namely to accept the unary language f1ng. It is easy to see that nondeterministic automata need O (n) states to count to n. For other types of automata, the problem was stated in MF71], and was studied in Bir93, Bir96] for alternating and two-way automata. Here we complete the picture with results about\u00a0\u2026", "num_citations": "12\n", "authors": ["1788"]}
{"title": "Minimizing GFG transition-based automata\n", "abstract": " While many applications of automata in formal methods can use nondeterministic automata, some applications, most notably synthesis, need deterministic or good-for-games automata. The latter are nondeterministic automata that can resolve their nondeterministic choices in a way that only depends on the past. The minimization problem for nondeterministic and deterministic B\u00fcchi and co-B\u00fcchi word automata are PSPACE-complete and NP-complete, respectively. We describe a polynomial minimization algorithm for good-for-games co-B\u00fcchi word automata with transition-based acceptance. Thus, a run is accepting if it traverses a set of designated transitions only finitely often. Our algorithm is based on a sequence of transformations we apply to the automaton, on top of which a minimal quotient automaton is defined.", "num_citations": "11\n", "authors": ["1788"]}
{"title": "Quantitative assume guarantee synthesis\n", "abstract": " In assume-guarantee synthesis, we are given a specification , describing an assumption on the environment and a guarantee for the system, and we construct a system that interacts with an environment and is guaranteed to satisfy G whenever the environment satisfies A. While assume-guarantee synthesis is 2EXPTIME-complete for specifications in LTL, researchers have identified the  fragment of LTL, which supports assume-guarantee reasoning and for which synthesis has an efficient symbolic solution. In recent years we see a transition to quantitative synthesis, in which the specification formalism is multi-valued and the goal is to generate high-quality systems, namely ones that maximize the satisfaction value of the specification.                 We study quantitative assume-guarantee synthesis. We start with specifications in , an extension of LTL by quality operators. The satisfaction value of an  formula is a\u00a0\u2026", "num_citations": "11\n", "authors": ["1788"]}
{"title": "Translating to co-B\u00fcchi made tight, unified, and useful\n", "abstract": " We solve the longstanding open problems of the blow-up involved in the translations, when possible, of a nondeterministic B\u00fcchi word automaton (NBW) to a nondeterministic co-B\u00fcchi word automaton (NCW) and to a deterministic co-B\u00fcchi word automaton (DCW). For the NBW to NCW translation, the currently known upper bound is 2O(n log n) and the lower bound is 1.5n. We improve the upper bound to n2n and describe a matching lower bound of 2\u03a9(n). For the NBW to DCW translation, the currently known upper bound is 2O(n log n). We improve it to 2O(n), which is asymptotically tight. Both of our upper-bound constructions are based on a simple subset construction, do not involve intermediate automata with richer acceptance conditions, and can be implemented symbolically. We continue and solve the open problems of translating nondeterministic Streett, Rabin, Muller, and parity word automata to NCW and\u00a0\u2026", "num_citations": "11\n", "authors": ["1788"]}
{"title": "Formal analysis of online algorithms\n", "abstract": " In [2], we showed how viewing online algorithms as reactive systems enables the application of ideas from formal verification to the competitive analysis of online algorithms. Our approach is based on weighted automata, which assign to each input word a cost in . By relating the \u201cunbounded look ahead\u201d of optimal offline algorithms with nondeterminism, and relating the \u201cno look ahead\u201d of online algorithms with determinism, we were able to solve problems about the competitive ratio of online algorithms and the memory they require.               In this paper we improve the application in three important and technically challenging aspects. First, we allow the competitive analysis to take into account assumptions about the environment. Second, we allow the online algorithm to have a bounded lookahead. Third, we describe a symbolic version of the model-checking algorithm and demonstrate its applicability\u00a0\u2026", "num_citations": "11\n", "authors": ["1788"]}
{"title": "Synthesis of trigger properties\n", "abstract": " In automated synthesis, we transform a specification into a system that is guaranteed to satisfy the specification. In spite of the rich theory developed for temporal synthesis, little of this theory has been reduced to practice. This is in contrast with model-checking theory, which has led to industrial development and use of formal verification tools. We address this problem here by considering a certain class of PSL properties; this class covers most of the properties used in practice by system designers. We refer to this class as the class of trigger properties.             We show that the synthesis problem for trigger properties is more amenable to implementation than that of general PSL properties. While the problem is still 2EXPTIME-complete, it can be solved using techniques that are significantly simpler than the techniques used in general temporal synthesis. Not only can we avoid the use of Safra\u2019s determinization\u00a0\u2026", "num_citations": "11\n", "authors": ["1788"]}
{"title": "Synthesis of Controllable Nash Equilibria in Quantitative Objective Game.\n", "abstract": " In Rational Synthesis, we consider a multi-agent system in which some of the agents are controllable and some are not. All agents have objectives, and the goal is to synthesize strategies for the controllable agents so that their objectives are satisfied, assuming rationality of the uncontrollable agents. Previous work on rational synthesis considers objectives in LTL, namely ones that describe on-going behaviors, and in Objective-LTL, which allows ranking of LTL formulas. In this paper, we extend rational synthesis to LTL [F]\u2013an extension of LTL by quality operators. The satisfaction value of an LTL [F] formula is a real value in [0, 1], where the higher the value is, the higher is the quality in which the computation satisfies the specification. The extension significantly strengthens the framework of rational synthesis and enables a study its game-and social-choice theoretic aspects. In particular, we study the price of stability and price of anarchy of the rational-synthesis game and use them to explain the cooperative and non-cooperative settings of rational synthesis. Our algorithms make use of strategy logic and decision procedures for it. Thus, we are able to handle the richer quantitative setting using existing tools. In particular, we show that the cooperative and non-cooperative versions of quantitative rational synthesis are 2EXPTIME-complete and in 3EXPTIME, respectively\u2013not harder than the complexity known for their Boolean analogues.", "num_citations": "10\n", "authors": ["1788"]}
{"title": "Latticed-LTL synthesis in the presence of noisy inputs\n", "abstract": " In the classical synthesis problem, we are given a specification \u03c8 over sets of input and output signals, and we synthesize a finite-state transducer that realizes \u03c8: with every sequence of input signals, the transducer associates a sequence of output signals so that the generated computation satisfies \u03c8. In recent years, researchers consider extensions of the classical Boolean setting to a multi-valued one. We study a multi-valued setting in which the truth values of the input and output signals are taken from a finite lattice, and so is the satisfaction value of specifications. We consider specifications in latticed linear temporal logic (LLTL). In LLTL, conjunctions and disjunctions correspond to the meet and join operators of the lattice, respectively, and the satisfaction values of formulas are taken from the lattice too. The lattice setting arises in practice, for example in specifications involving priorities or in systems with\u00a0\u2026", "num_citations": "10\n", "authors": ["1788"]}
{"title": "Aborts vs resets in linear temporal logic\n", "abstract": " There has been a major emphasis recently in the semiconductor industry on designing industrial-strength property specification languages (PSLs). Two major languages are ForSpec and Sugar 2.0, which are both extensions of Pnueli\u2019s LTL. Both ForSpec and Sugar 2.0 directly support reset/abort signals, in which a check for a property \u03c8 may be terminated and declared successful by an reset/abort signal, provided the check has not yet failed. ForSpec and Sugar 2.0, however, differ in their definition of failure. The definition of failure in ForSpec is syntactic, while the definition in Sugar 2.0 is semantic. In this work we examine the implications of this distinction between the two approaches, which we refer to as the reset approach (for ForSpec) and the abort approach (for Sugar 2.0). In order to focus on the reset/abort issue, we do not consider the full languages, which are quite rich, but rather the extensions of LTL with the reset/abort constructs. We show that the distinction between syntactic and semantic failure has a dramatic impact on the complexity of using the language in a model-checking tool. We prove that Reset-LTL enjoys the \u201cfast-compilation property\u201d: there is a linear translation of Reset-LTL formulas into alternating B\u00fcchi automata, which implies a linear translation of Reset-LTL formulas into a symbolic representation of nondeterministic B \u00fcchi automata. In contrast, the translation of Abort-LTL formulas into alternating B\u00fcchi automata is nonelementary (ie, cannot be bounded by a stack of exponentials of a bounded height); each abort yields an exponential blow-up in the translation. This complexity bounds also apply to model checking\u00a0\u2026", "num_citations": "10\n", "authors": ["1788"]}
{"title": "Register-bounded synthesis\n", "abstract": " Traditional synthesis algorithms return, given a specification over finite sets of input and output Boolean variables, a finite-state transducer all whose computations satisfy the specification. Many real-life systems have an infinite state space. In particular, behaviors of systems with a finite control yet variables that range over infinite domains, are specified by automata with infinite alphabets. A register automaton has a finite set of registers, and its transitions are based on a comparison of the letters in the input with these stored in its registers. Unfortunately, reasoning about register automata is complex. In particular, the synthesis problem for specifications given by register automata, where the goal is to generate correct register transducers, is undecidable. We study the synthesis problem for systems with a bounded number of registers. Formally, the register-bounded realizability problem is to decide, given a specification register automaton A over infinite input and output alphabets and numbers k_s and k_e of registers, whether there is a system transducer T with at most k_s registers such that for all environment transducers T'with at most k_e registers, the computation T| T', generated by the interaction of T with T', satisfies the specification A. The register-bounded synthesis problem is to construct such a transducer T, if exists. The bounded setting captures better real-life scenarios where bounds on the systems and/or its environment are known. In addition, the bounds are the key to new synthesis algorithms, and, as recently shown in [A. Khalimov et al., 2018], they lead to decidability. Our contributions include a stronger specification formalism\u00a0\u2026", "num_citations": "9\n", "authors": ["1788"]}
{"title": "Minimizing expected cost under hard boolean constraints, with applications to quantitative synthesis\n", "abstract": " In Boolean synthesis, we are given an LTL specification, and the goal is to construct a transducer that realizes it against an adversarial environment. Often, a specification contains both Boolean requirements that should be satisfied against an adversarial environment, and multi-valued components that refer to the quality of the satisfaction and whose expected cost we would like to minimize with respect to a probabilistic environment. In this work we study, for the first time, mean-payoff games in which the system aims at minimizing the expected cost against a probabilistic environment, while surely satisfying an -regular condition against an adversarial environment. We consider the case the -regular condition is given as a parity objective or by an LTL formula. We show that in general, optimal strategies need not exist, and moreover, the limit value cannot be approximated by finite-memory strategies. We thus focus on computing the limit-value, and give tight complexity bounds for synthesizing -optimal strategies for both finite-memory and infinite-memory strategies. We show that our game naturally arises in various contexts of synthesis with Boolean and multi-valued objectives. Beyond direct applications, in synthesis with costs and rewards to certain behaviors, it allows us to compute the minimal sensing cost of -regular specifications -- a measure of quality in which we look for a transducer that minimizes the expected number of signals that are read from the input.", "num_citations": "9\n", "authors": ["1788"]}
{"title": "Congestion games with multisets of resources and applications in synthesis\n", "abstract": " In classical congestion games, players' strategies are subsets of resources. We introduce and study multiset congestion games, where players' strategies are multisets of resources. Thus, in each strategy a player may need to use each resource a different number of times, and his cost for using the resource depends on the load that he and the other players generate on the resource. Beyond the theoretical interest in examining the effect of a repeated use of resources, our study enables better understanding of non-cooperative systems and environments whose behavior is not covered by previously studied models. Indeed, congestion games with multiset-strategies arise, for example, in production planing and network formation with tasks that are more involved than reachability. We study in detail the application of synthesis from component libraries: different users synthesize systems by gluing together components from a component library. A component may be used in several systems and may be used several times in a system. The performance of a component and hence the system's quality depends on the load on it. Our results reveal how the richer setting of multisets congestion games affects the stability and equilibrium efficiency compared to standard congestion games. In particular, while we present very simple instances with no pure Nash equilibrium and prove tighter and simpler lower bounds for equilibrium inefficiency, we are also able to show that some of the positive results known for affine and weighted congestion games apply to the richer setting of multisets.", "num_citations": "9\n", "authors": ["1788"]}
{"title": "The sensing cost of monitoring and synthesis\n", "abstract": " In [2], we introduced sensing as a new complexity measure for the complexity of regular languages. Intuitively , the sensing cost quantifies the detail in which a random input word has to be read by a deterministic automaton in order to decide its membership in the language. In this paper, we consider sensing in two principal applications of deterministic automata. The first is monitoring: we are given a computation in an on-line manner, and we have to decide whether it satisfies the specification. The second is synthesis: we are given a sequence of inputs in an on-line manner and we have to generate a sequence of outputs so that the resulting computation satisfies the specification. In the first, our goal is to design a monitor that handles all computations and minimizes the expected average number of sensors used in the monitoring process. In the second, our goal is to design a transducer that realizes the specification for all input sequences and minimizes the expected average number of sensors used for reading the inputs. We argue that the two applications require new and different frameworks for reasoning about sensing, and develop such frameworks. We focus on safety languages. We show that for monitoring, minimal sensing is attained by a monitor based on the minimal deterministic automaton for the language. For synthesis , however, the setting is more challenging: minimizing the sensing may require exponentially bigger transducers, and the problem of synthesizing a minimally-sensing transducer is EXPTIME-complete even for safety specifications given by deterministic automata.", "num_citations": "9\n", "authors": ["1788"]}
{"title": "Making weighted containment feasible: A heuristic based on simulation and abstraction\n", "abstract": " Weighted automata map input words to real numbers and are useful in reasoning about quantitative systems and specifications. The containment problem for weighted automata asks, given two weighted automata  and , whether for all words w, the value that  assigns to w is less than or equal to the value  assigns to w. The problem is of great practical interest, yet is known to be undecidable. Efforts to approximate weighted containment by weighted variants of the simulation pre-order still have to cope with large state spaces. One of the leading approaches for coping with large state spaces is abstraction. We introduce an abstraction-refinement paradigm for weighted automata and show that it nicely combines with weighted simulation, giving rise to a feasible approach for the containment problem. The weighted-simulation pre-order we define is based on a quantitative two-player game, and the\u00a0\u2026", "num_citations": "9\n", "authors": ["1788"]}
{"title": "Reasoning about finite-state switched systems\n", "abstract": " A switched system is composed of components. The components do not interact with one another. Rather, they all interact with the same environment, which switches one of them on at each moment in time. In standard concurrency, a component restricts the environment of the other components, thus the concurrent system has fewer behaviors than its components. On the other hand, in a switched system, a component suggests an alternative to the other components, thus the switched system has richer behaviors than its components.               We study finite-state switched systems, where each of the underlying components is a finite-state transducer. While the main challenge, namely compositionality, is similar in standard concurrent systems and in switched systems, the problems and solutions are different. In the verification front, we suggest and study an assume-guarantee paradigm for switched systems\u00a0\u2026", "num_citations": "9\n", "authors": ["1788"]}
{"title": "Good-enough synthesis\n", "abstract": " We introduce and study good-enough synthesis (ge-synthesis)\u2013a variant of synthesis in which the system is required to satisfy a given specification \u03c8 only when it interacts with an environments for which a satisfying interaction exists. Formally, an input sequence x is hopeful if there exists some output sequence y such that the induced computation x \u2297 y satisfies \u03c8, and a system ge-realizes \u03c8 if it generates a computation that satisfies \u03c8 on all hopeful input sequences. ge-synthesis is particularly relevant when the notion of correctness is multi-valued (rather than Boolean), and thus we seek systems of the highest possible quality, and when synthesizing autonomous systems, which interact with unexpected environments and are often only expected to do their best. We study ge-synthesis in Boolean and multi-valued settings. In both, we suggest and solve various definitions of ge-synthesis, corresponding to different\u00a0\u2026", "num_citations": "8\n", "authors": ["1788"]}
{"title": "Spanning the spectrum from safety to liveness\n", "abstract": " Of special interest in formal verification are safety specifications, which assert that the system stays within some allowed region, in which nothing \u201cbad\u201d happens. Equivalently, a computation violates a safety specification if it has a \u201cbad prefix\u201d\u2014a prefix all whose extensions violate the specification. The theoretical properties of safety specifications as well as their practical advantages with respect to general specifications have been widely studied. Safety is binary: a specification is either safety or not safety. We introduce a quantitative measure for safety. Intuitively, the safety level of a language L measures the fraction of words not in L that have a bad prefix. In particular, a safety language has safety level 1 and a liveness language has safety level 0. Thus, our study spans the spectrum between traditional safety and liveness. The formal definition of safety level is based on probability and measures the\u00a0\u2026", "num_citations": "8\n", "authors": ["1788"]}
{"title": "High-quality synthesis against stochastic environments\n", "abstract": " In the classical synthesis problem, we are given an LTL formula psi over sets of input and output signals, and we synthesize a transducer that realizes psi. One weakness of automated synthesis in practice is that it pays no attention to the quality of the synthesized system. Indeed, the classical setting is Boolean: a computation satisfies a specification or does not satisfy it. Accordingly, while the synthesized system is correct, there is no guarantee about its quality. In recent years, researchers have considered extensions of the classical Boolean setting to a quantitative one. The logic LTL[F] is a multi-valued logic that augments LTL with quality operators. The satisfaction value of an LTL[F] formula is a real value in [0,1], where the higher the value is, the higher is the quality in which the computation satisfies the specification. Decision problems for LTL become search or optimization problems for LFL[F]. In particular, in the synthesis problem, the goal is to generate a transducer that satisfies the specification in the highest possible quality. Previous work considered the worst-case setting, where the goal is to maximize the quality of the computation with the minimal quality. We introduce and solve the stochastic setting, where the goal is to generate a transducer that maximizes the expected quality of a computation, subject to a given distribution of the input signals. Thus, rather than being hostile, the environment is assumed to be probabilistic, which corresponds to many realistic settings. We show that the problem is 2EXPTIME-complete, like classical LTL synthesis, and remains so in two extensions we consider: one that maximizes the expected quality while\u00a0\u2026", "num_citations": "8\n", "authors": ["1788"]}
{"title": "Properties and Utilization of Capacitated Automata (Invited Talk)\n", "abstract": " We study capacitated automata (CAs), where transitions correspond to resources and may have bounded capacities. Each transition in a CA is associated with a (possibly infinite) bound on the number of times it may be traversed. We study CAs from two points of view. The first is that of traditional automata theory, where we view CAs as recognizers of formal languages and examine their expressive power, succinctness, and determinization. The second is that of resource-allocation theory, where we view CAs as a rich description of a flow network and study their utilization.", "num_citations": "8\n", "authors": ["1788"]}
{"title": "On relative and probabilistic finite counterability\n", "abstract": " A counterexample to the satisfaction of a linear property  in a system  is an infinite computation of  that violates . When  is a safety property, a counterexample to its satisfaction need not be infinite. Rather, it is a bad-prefix for : a finite word all whose extensions violate . The existence of finite counterexamples is very helpful in practice. Liveness properties do not have bad-prefixes and thus do not have finite counterexamples. We extend the notion of finite counterexamples to non-safety properties. We study counterable languages\u2014ones that have at least one bad-prefix. Thus, a language is counterable iff it is not liveness. Three natural problems arise: (1) given a language, decide whether it is counterable, (2) study the length of minimal bad-prefixes for counterable languages, and (3) develop algorithms for detecting bad-prefixes for counterable languages. We solve the problems for languages\u00a0\u2026", "num_citations": "7\n", "authors": ["1788"]}
{"title": "Timed network games\n", "abstract": " Network games are widely used as a model for selfish resource-allocation problems. In the classical model, each player selects a path connecting her source and target vertex. The cost of traversing an edge depends on the number of players that traverse it. Thus, it abstracts the fact that different users may use a resource at different times and for different durations, which plays an important role in defining the costs of the users in reality. For example, when transmitting packets in a communication network, routing traffic in a road network, or processing a task in a production system, the traversal of the network involves an inherent delay, and so sharing and congestion of resources crucially depends on time. We study timed network games, which add a time component to network games. Each vertex v in the network is associated with a cost function, mapping the load on v to the price that a player pays for staying in v for one time unit with this load. In addition, each edge has a guard, describing time intervals in which the edge can be traversed, forcing the players to spend time on vertices. Unlike earlier work that add a time component to network games, the time in our model is continuous and cannot be discretized. In particular, players have uncountably many strategies, and a game may have uncountably many pure Nash equilibria. We study properties of timed network games with cost-sharing or congestion cost functions: their stability, equilibrium inefficiency, and complexity. In particular, we show that the answer to the question whether we can restrict attention to boundary strategies, namely ones in which edges are traversed only at the\u00a0\u2026", "num_citations": "7\n", "authors": ["1788"]}
{"title": "Regular sensing\n", "abstract": " The size of deterministic automata required for recognizing regular and \u03c9-regular languages is a well-studied measure for the complexity of languages. We introduce and study a new complexity measure, based on the sensing required for recognizing the language. Intuitively, the sensing cost quantifies the detail in which a random input word has to be read in order to decide its membership in the language. We show that for finite words, size and sensing are related, and minimal sensing is attained by minimal automata. Thus, a unique minimal-sensing deterministic automaton exists, and is based on the language's right-congruence relation. For infinite words, the minimal sensing may be attained only by an infinite sequence of automata. We show that the optimal limit cost of such sequences can be characterized by the language's right-congruence relation, which enables us to find the sensing cost of \u03c9-regular languages in polynomial time.", "num_citations": "7\n", "authors": ["1788"]}
{"title": "When does abstraction help?\n", "abstract": " Abstraction is a leading technique for coping with large state spaces. Abstraction over-approximates the transitions of the original system or the automaton that models it and may introduce nondeterminism. In applications where determinism is essential, we say that an abstraction function is helpful if, after determining and minimizing the abstract automaton, we end up with fewer states than the original automaton. We show that abstraction functions are not always helpful; in fact, they may introduce an exponential blow-up. We study the problem of deciding whether a given abstraction function is helpful for a given deterministic automaton and show that it is PSPACE-complete.", "num_citations": "7\n", "authors": ["1788"]}
{"title": "Automatic generation of quality specifications\n", "abstract": " The logic  extends  by quality operators. The satisfaction value of an  formula in a computation refines the 0/1 value of  formulas to a real value in [0,1]. The higher the value is, the better is the quality of the computation. The quality operator \u2207\u2009                   \u03bb                 , for a quality constant \u03bb\u2009\u2208\u2009[0,1], enables the designer to prioritize different satisfaction possibilities. Formally, the satisfaction value of a sub-formula \u2207\u2009                   \u03bb                                          \u03d5 is \u03bb times the satisfaction value of \u03d5. For example, the  formula  has value 1 in computations in which every request is immediately followed by a grant, value  if grants to some requests involve a delay, and value 0 if some request is not followed by a grant.               The design of an  formula typically starts with an  formula on top of which the designer adds the parameterized \u2207 operators. In the Boolean setting, the problem of\u00a0\u2026", "num_citations": "7\n", "authors": ["1788"]}
{"title": "Parityizing Rabin and Streett\n", "abstract": " The parity acceptance condition for $ omega $-regular languages is a special case of the Rabin and Streett acceptance conditions. While the parity acceptance condition is as expressive as the richer conditions, in both the deterministic and nondeterministic settings, Rabin and Streett automata are more succinct, and their translation to parity automata may blow-up the state space. The appealing properties of the parity condition, mainly the fact it is dualizable and allows for memoryless strategies, make such a translation useful in various decision procedures. In this paper we study languages that are recognizable by an automaton on top of which one can define both a Rabin and a Streett condition for the language. We show that if the underlying automaton is deterministic, then we can define on top of it also a parity condition for the language. We also show that this relation does not hold in the nondeterministic setting. Finally, we use the construction of the parity condition in the deterministic case in order to solve the problem of deciding whether a given Rabin or Streett automaton has an equivalent parity automaton on the same structure, and show that it is PTIME-complete in the deterministic setting and is PSPACE-complete in the nondeterministic setting.", "num_citations": "7\n", "authors": ["1788"]}
{"title": "Tightening the exchange rates between automata\n", "abstract": " Automata on infinite objects were the key to the solution of several fundamental decision problems in mathematics and logic. Today, automata on infinite objects are used for formal specification and verification of reactive systems. The practical importance of automata in formal methods has motivated a re-examination of the blow up that translations among different types of automata involve. For most translations, the situation is satisfying, in the sense that even if there is a gap between the upper and the lower bound, it is small. For some highly practical cases, however, the gap between the upper and the lower bound is exponential or even larger. The article surveys several such frustrating cases, studies features that they share, and describes recent efforts (with partial success) to close the gaps.", "num_citations": "7\n", "authors": ["1788"]}
{"title": "What causes a system to satisfy a specification?\n", "abstract": " Even when a system is proven to be correct with respect to a specification, there is still a question of how complete the specification is, and whether it really covers all the behaviors of the system. Coverage metrics attempt to check which parts of a system are actually relevant for the verification process to succeed. Recent work on coverage in model checking suggests several coverage metrics and algorithms for finding parts of the system that are not covered by the specification. The work has already proven to be effective in practice, detecting design errors that escape early verification efforts in industrial settings. In this paper, we relate a formal definition of causality given by Halpern and Pearl [2001] to coverage. We show that it gives significant insight into unresolved issues regarding the definition of coverage and leads to potentially useful extensions of coverage. In particular, we introduce the notion of responsibility, which assigns to components of a system a quantitative measure of their relevance to the satisfaction of the specification.", "num_citations": "7\n", "authors": ["1788"]}
{"title": "\u03c9-regular languages are testable with a constant number of queries\n", "abstract": " We continue the study of combinatorial property testing. For a property \u03c8, an \u025b-test for \u03c8, for 0 < \u025b \u2264 1, is a randomized algorithm that given an input x, returns \u201cyes\u201d if x satisfies \u03c8, and returns \u201cno\u201d with high probability if x is \u025b-far from satisfying \u03c8, where \u025b-far essentially means that an \u025b-fraction of x needs to be changed in order for it to satisfy \u03c8. In [AKNS99], Alon et al. show that regular languages are \u025b-testable with a constant (depends on \u03c8 and \u025b and independent of x) number of queries. We extend the result in [AKNS99] to \u03c9-regular languages: given a nondeterministic B\u00fcchi automaton A on infinite words and a small \u025b > 0, we describe an algorithm that gets as input an infinite lasso-shape word of the form x \u00b7 y                      \u03c9, for finite words x and y, samples only a constant number of letters in x and y, returns \u201cyes\u201d if w \u2208 L(A), and returns \u201cno\u201d with probability 2/3 if w is \u025b-far from L(A). We also discuss the\u00a0\u2026", "num_citations": "7\n", "authors": ["1788"]}
{"title": "On high-quality synthesis\n", "abstract": " In the synthesis problem, we are given a specification  over input and output signals, and we synthesize a system that realizes : with every sequence of input signals, the system associates a sequence of output signals so that the generated computation satisfies . The above classical formulation of the problem is Boolean. First, correctness is Boolean: a computation satisfies the specification  or does not satisfy it. Then, other important and interesting measures like the size of the synthesized system, its robustness, price, and so on, are ignored. The paper surveys recent efforts to address and formalize different aspects of quality of synthesized systems. We start with multi-valued specification formalisms, which refine the notion of correctness and enable the designer to specify quality, and continue to the quality measure of sensing: the detail in which the inputs should be read in order to generate a\u00a0\u2026", "num_citations": "6\n", "authors": ["1788"]}
{"title": "A framework for ranking vacuity results\n", "abstract": " Vacuity detection is a method for finding errors in the model-checking process when the specification is found to hold in the model. Most vacuity algorithms are based on checking the effect of applying mutations on the specification. It has been recognized that vacuity results differ in their significance. While in many cases such results are valued as highly informative, there are also cases where a vacuity result is viewed by users as \u201cinteresting to know\u201d at the most, or even as meaningless. As of today, no attempt has been made to formally justify this phenomenon.               We suggest and study a framework for ranking vacuity results, based on the probability of the mutated specification to hold on a random computation. For example, two natural mutations of the specification G(req\u2009\u2192\u2009F ready) are G(\u00acreq) and GF ready. It is agreed that vacuity information about satisfying the first mutation is more alarming\u00a0\u2026", "num_citations": "6\n", "authors": ["1788"]}
{"title": "Coping with selfish on-going behaviors\n", "abstract": " A rational and selfish environment may have an incentive to cheat the system it interacts with. Cheating the system amounts to reporting a stream of inputs that is different from the one corresponding to the real behavior of the environment. The system may cope with cheating by charging penalties to cheats it detects. In this paper, we formalize this setting by means of weighted automata and their resilience to selfish environments. Automata have proven to be a successful formalism for modeling the on-going interaction between a system and its environment. In particular, weighted finite automata (WFAs), which assign a cost to each input word, are useful in modeling an interaction that has a quantitative outcome. Consider a WFA A over the alphabet \u03a3. At each moment in time, the environment may cheat A by reporting a letter different from the one it actually generates. A penalty function \u03b7: \u03a3\u00d7 \u03a3\u2192 R\u2a7e 0 maps each\u00a0\u2026", "num_citations": "6\n", "authors": ["1788"]}
{"title": "Flow games\n", "abstract": " In the traditional maximal-flow problem, the goal is to transfer maximum flow in a network by directing, in each vertex in the network, incoming flow into outgoing edges. While the problem has been extensively used in order to optimize the performance of networks in numerous application areas, it corresponds to a setting in which the authority has control on all vertices of the network. Today's computing environment involves parties that should be considered adversarial. We introduce and study {\\em flow games}, which capture settings in which the authority can control only part of the vertices. In these games, the vertices are partitioned between two players: the authority and the environment. While the authority aims at maximizing the flow, the environment need not cooperate. We argue that flow games capture many modern settings, such as partially-controlled pipe or road systems or hybrid software-defined communication networks. We show that the problem of finding the maximal flow as well as an optimal strategy for the authority in an acyclic flow game is -complete, and is already -hard to approximate. We study variants of the game: a restriction to strategies that ensure no loss of flow, an extension to strategies that allow non-integral flows, which we prove to be stronger, and a dynamic setting in which a strategy for a vertex is chosen only once flow reaches the vertex. We discuss additional variants and their applications, and point to several interesting open problems.", "num_citations": "5\n", "authors": ["1788"]}
{"title": "Eulerian paths with regular constraints\n", "abstract": " Labeled graphs, in which edges are labeled by letters from some alphabet Sigma, are extensively used to model many types of relations associated with actions, costs, owners, or other properties. Each path in a labeled graph induces a word in Sigma^*--the one obtained by concatenating the letters along the edges in the path. Classical graph-theory problems give rise to new problems that take these words into account. We introduce and study the constrained Eulerian path problem. The input to the problem is a Sigma-labeled graph G and a specification L\\subseteq Sigma^*. The goal is to find an Eulerian path in G that satisfies L. We consider several classes of the problem, defined by the classes of G and L. We focus on the case L is regular and show that while the problem is in general NP-complete, even for very simple graphs and specifications, there are classes that can be solved efficiently. Our results extend work on Eulerian paths with edge-order constraints. We also study the constrained Chinese postman problem, where edges have costs and the goal is to find a cheapest path that contains each edge at least once and satisfies the specification. Finally, we define and study the Eulerian language of a graph, namely the set of words along its Eulerian paths.", "num_citations": "5\n", "authors": ["1788"]}
{"title": "Co-B\u00fcching them all\n", "abstract": " We solve the open problems of translating, when possible, all common classes of nondeterministic word automata to deterministic and nondeterministic co-B\u00fcchi word automata. The handled classes include B\u00fcchi, parity, Rabin, Streett and Muller automata. The translations follow a unified approach and are all asymptotically tight.               The problem of translating B\u00fcchi automata to equivalent co-B\u00fcchi automata was solved in [2], leaving open the problems of translating automata with richer acceptance conditions. For these classes, one cannot easily extend or use the construction in [2]. In particular, going via an intermediate B\u00fcchi automaton is not optimal and might involve a blow-up exponentially higher than the known lower bound. Other known translations are also not optimal and involve a doubly exponential blow-up.               We describe direct, simple, and asymptotically tight constructions, involving\u00a0\u2026", "num_citations": "5\n", "authors": ["1788"]}
{"title": "Improved model checking of hierarchical systems\n", "abstract": " We present a unified game-based approach for branching-time model checking of hierarchical systems. Such systems are exponentially more succinct than standard state-transition graphs, as repeated sub-systems are described only once. Early work on model checking of hierarchical systems shows that one can do better than a naive algorithm that \u201cflattens\u201d the system and removes the hierarchy.               Given a hierarchical system  and a branching-time specification \u03c8 for it, we reduce the model-checking problem (does  satisfy \u03c8?) to the problem of solving a hierarchical game obtained by taking the product of  with an alternating tree automaton  for \u03c8. Our approach leads to clean, uniform, and improved model-checking algorithms for a variety of branching-time temporal logics. In particular, by improving the algorithm for solving hierarchical parity games, we are able to solve the model-checking\u00a0\u2026", "num_citations": "5\n", "authors": ["1788"]}
{"title": "The quest for a tight translation of b\u00fcchi to co-b\u00fcchi automata\n", "abstract": " The B\u00fcchi acceptance condition specifies a set \u03b1 of states, and a run is accepting if it visits \u03b1 infinitely often. The co-B\u00fcchi acceptance condition is dual, thus a run is accepting if it visits \u03b1 only finitely often. Nondeterministic B\u00fcchi automata over words (NBWs) are strictly more expressive than nondeterministic co-B\u00fcchi automata over words (NCWs). The problem of the blow-up involved in the translation (when possible) of an NBW to an NCW has been open for several decades.               Until recently, the best known upper bound was 2O(n log n) and the best lower bound was n. We describe the quest to the tight 2\u0398(n) bound.", "num_citations": "5\n", "authors": ["1788"]}
{"title": "On the relative succinctness of nondeterministic B\u00fcchi and co-B\u00fcchi word automata\n", "abstract": " The practical importance of automata on infinite objects has motivated a re-examination of the complexity of automata-theoretic constructions. One such construction is the translation, when possible, of nondeterministic B\u00fcchi word automata (NBW) to nondeterministic co-B\u00fcchi word automata (NCW). Among other applications, it is used in the translation (when possible) of LTL to the alternation-free \u03bc-calculus. The best known upper bound for the translation of NBW to NCW is exponential (given an NBW with n states, the best translation yields an equivalent NCW with 2                            O(n logn) states). On the other hand, the best known lower bound is trivial (no NBW with n states whose equivalent NCW requires even n\u2009+\u20091 states is known). In fact, only recently was it shown that there is an NBW whose equivalent NCW requires a different structure.               In this paper we improve the lower bound by\u00a0\u2026", "num_citations": "5\n", "authors": ["1788"]}
{"title": "Multi-player flow games\n", "abstract": " In the traditional maximum-flow problem, the goal is to transfer maximum flow in a network by directing, in each vertex in the network, incoming flow to outgoing edges. The problem corresponds to settings in which a central authority has control on all vertices of the network. Today\u2019s computing environment, however, involves systems with no central authority. In particular, in many applications of flow networks, the vertices correspond to decision-points controlled by different and selfish entities. For example, in communication networks, routers may belong to different companies, with different destination objectives. This suggests that the maximum-flow problem should be revisited, and examined from a game-theoretic perspective. We introduce and study multi-player flow games (MFGs, for short). Essentially, the vertices of an MFG are partitioned among the players, and a player that owns a vertex directs the flow\u00a0\u2026", "num_citations": "4\n", "authors": ["1788"]}
{"title": "Stochastization of weighted automata\n", "abstract": " Nondeterministic weighted finite automata (WFAs) map input words to real numbers. Each transition of a WFA is labeled by both a letter from some alphabet and a weight. The weight of a run is the sum of the weights on the transitions it traverses, and the weight of a word is the minimal weight of a run on it. In probabilistic weighted automata (PWFAs), the transitions are further labeled by probabilities, and the weight of a word is the expected weight of a run on it. We define and study stochastization of WFAs: given a WFA , stochastization turns it into a PWFA  by labeling its transitions by probabilities. The weight of a word in  can only increase with respect to its weight in , and we seek stochastizations in which  -approximates  for the minimal possible factor . That is, the weight of every word in  is at most  times its weight in . We show that stochastization is useful in reasoning about the\u00a0\u2026", "num_citations": "4\n", "authors": ["1788"]}
{"title": "Prime languages\n", "abstract": " We say that a deterministic finite automaton (DFA) A is composite if there are DFAs A 1,\u2026, A t such that L (A)=\u22c2 i= 1 t L (A i) and the index of every A i is strictly smaller than the index of A. Otherwise, A is prime. We study the problem of deciding whether a given DFA is composite, the number of DFAs required in a decomposition, decompositions that are based on abstractions, methods to prove primality, and structural properties of DFAs that make the problem simpler or are retained in a decomposition. We also provide an algebraic view of the problem and demonstrate its usefulness for the special case of permutation DFAs.", "num_citations": "4\n", "authors": ["1788"]}
{"title": "Variations on safety\n", "abstract": " Of special interest in formal verification are safety properties, which assert that the system always stays within some allowed region, in which nothing \u201cbad\u201d happens. Equivalently, a property is a safety property if every violation of it occurs after a finite execution of the system. Thus, a computation violates the property if it has a \u201cbad prefix\u201d, all whose extensions violate the property. The theoretical properties of safety properties as well as their practical advantages with respect to general properties have been widely studied. The paper surveys several extensions and variations of safety. We start with bounded and checkable properties \u2013 fragments of safety properties that enable an even simpler reasoning. We proceed to a reactive setting, where safety properties require the system to stay in a region of states that is both allowed and from which the environment cannot force it out. Finally, we describe a\u00a0\u2026", "num_citations": "4\n", "authors": ["1788"]}
{"title": "An abstraction-refinement framework for trigger querying\n", "abstract": " Trigger querying is the problem of finding, given a system M and an LTL formula \u03c6, the set of scenarios that trigger \u03c6 in M; that is, the language L of finite computations of M such that all infinite computations that have a prefix in L continue with a suffix that satisfies \u03c6. Trigger querying significantly extends query checking, which seeks propositional solutions, and is an extremely useful methodology for system exploration and understanding. The weakness of trigger querying lies in the fact that the size of the solution is linear in the size of the system. For trigger querying to become feasible in practice, we must offer solutions to cope with systems of big, and possibly infinite, state spaces. In this paper we describe an abstraction-refinement framework for trigger querying. Instead of reasoning about the system M, we reason about an abstraction of it and return to the user two languages that under- and over\u00a0\u2026", "num_citations": "4\n", "authors": ["1788"]}
{"title": "Environment-friendly safety\n", "abstract": " Of special interest in verification are safety properties, which assert that the system always stays within some allowed region. For closed systems, the theoretical properties of safety properties as well as their practical advantages with respect to general properties are well understood. For open (a.k.a. reactive) systems, whose behavior depends on their on-going interaction with the environment, the common practice is to use the definition and algorithms of safety for closed systems, ignoring the distinction between input and output signals. In a recent work, Ehlers and Finkbeiner introduced reactive safety \u2013 a definition of safety for the setting of open systems. Essentially, reactive safety properties require the system to stay in a region of states that is both allowed and from which the environment cannot force it out. In this paper we continue their study and extend it to other families of properties. In the setting of\u00a0\u2026", "num_citations": "4\n", "authors": ["1788"]}
{"title": "Minimizing deterministic lattice automata\n", "abstract": " Traditional automata accept or reject their input, and are therefore Boolean. In contrast, weighted automata map each word to a value from a semiring over a large domain. The special case of lattice automata, in which the semiring is a finite lattice, has interesting theoretical properties as well as applications in formal methods. A minimal deterministic automaton captures the combinatoric nature and complexity of a formal language. Deterministic automata are used in run-time monitoring, pattern recognition, and modeling systems. Thus, the minimization problem for deterministic automata is of great interest, both theoretically and in practice.               For traditional automata on finite words, a minimization algorithm, based on the Myhill-Nerode right congruence on the set of words, generates in polynomial time a canonical minimal deterministic automaton. A polynomial algorithm is known also for weighted\u00a0\u2026", "num_citations": "4\n", "authors": ["1788"]}
{"title": "Branching-depth hierarchies\n", "abstract": " We study the distinguishing and expressive power of branching temporal logics with bounded nesting depth of path quantifiers. We define the fragments CTL\u2217i and CTLi of CTL\u2217 and CTL, where at most i nestings of path quantifiers are allowed. We show that for all i \u2265 1, the logic CTL\u2217i+1 has more distinguishing and expressive power than CTL\u2217i; thus the branching-depth hierarchy is strict. We describe equivalence relations Hi that capture CTL\u2217i: two states in a Kripke structure are Hi-equivalent iff they agree on exactly all CTL\u2217i formulas. While H1 corresponds to trace equivalence, the limit of the sequence H1, H2,\u2026 is Milner's bisimulation. These results are not surprising, but they give rise to several interesting observations and problems. In particular, while CTL\u2217 and CTL have the same distinguishing power, this is not the case for CTL\u2217i and CTLi. We define the branching depth of a structure as the minimal\u00a0\u2026", "num_citations": "4\n", "authors": ["1788"]}
{"title": "Fair equivalence relations\n", "abstract": " Equivalence between designs is a fundamental notion in verification. The linear and branching approaches to verification induce different notions of equivalence. When the designs are modeled by fair state-transition systems, equivalence in the linear paradigm corresponds to fair trace equivalence, and in the branching paradigm corresponds to fair bisimulation.               In this work we study the expressive power of various types of fairness conditions. For the linear paradigm, it is known that the B\u00fcchi condition is sufficiently strong (that is, a fair system that uses Rabin or Streett fairness can be translated to an equivalent B\u00fcchi system). We show that in the branching paradigm the expressiveness hierarchy depends on the types of fair bisimulation one chooses to use. We consider three types of fair bisimulation studied in the literature: 3-bisimulation, gamebisimulation, and V-bisimulation. We show that while\u00a0\u2026", "num_citations": "4\n", "authors": ["1788"]}
{"title": "The Complexity of the Graded-Calculus\n", "abstract": " In classical logic, existential and universal quantifiers express that there exists at least one individual satisfying a formula, or that all individuals satisfy a formula. In many logics, these quantifiers have been generalized to express that, for a non-negative integer \u0432, at least \u0432 individuals or all but \u0432 individuals satisfy a formula. In modal logics, graded modalities generalize standard existential and universal modalities in that they express, eg, that there exist at least \u0432 accessible worlds satisfying a certain formula. Graded modalities are useful expressive means in knowledge representation; they are present in a variety of other knowledge representation formalisms closely related to modal logic. A natural question that arises is how the generalization of the existential and universal modalities affects the satisfiability problem for the logic and its computational complexity, especially when the numbers in the graded modalities are coded in binary. In this paper we study the graded-calculus, which extends graded modal logic with fixed-point operators, or, equivalently, extends classical-calculus with graded modalities. We prove that the satisfiability problem for graded-calculus is EXPTIME-complete\u2013not harder than the satisfiability problem for-calculus, even when the numbers in the graded modalities are coded in binary.", "num_citations": "4\n", "authors": ["1788"]}
{"title": "On synthesis of specifications with arithmetic\n", "abstract": " Variable automata with arithmetic enable the specification of reactive systems with variables over an infinite domain of numeric values and whose operation involves arithmetic manipulation of these values\u00a0[9]. We study the synthesis problem for such specifications. While the problem is in general undecidable, we define a fragment, namely semantically deterministic variable automata with arithmetic, for which the problem is decidable. Essentially, an automaton is semantically deterministic if the restrictions on the possible assignments to the variables that are accumulated along its runs resolve its nondeterministic choices. We show that semantically deterministic automata can specify many interesting behaviors \u2013 many more than deterministic ones, and that the synthesis problem for them can be reduced to a solution of a two-player game. For automata with simple guards, the game has a finite state space, and the\u00a0\u2026", "num_citations": "3\n", "authors": ["1788"]}
{"title": "Perspective games\n", "abstract": " We introduce and study perspective games, which model multi-agent systems in which agents can view only the parts of the system that they own. As in standard multi-player turn-based games, the vertices of the game graph are partitioned among the players. Starting from an initial vertex, the players jointly generate a computation, with each player deciding the successor vertex whenever the generated computation reaches a vertex she owns. A perspective strategy for a player depends only on the history of visits in her vertices. Thus, unlike observation-based models of partial visibility, where uncertainty is longitudinal - players partially observe all vertices in the history, uncertainty in the perspective model is transverse - players fully observe part of the vertices in the history. Perspective games are not determined, and we study the problem of deciding whether a player has a winning perspective strategy. In the pure\u00a0\u2026", "num_citations": "3\n", "authors": ["1788"]}
{"title": "Minimizing deterministic lattice automata\n", "abstract": " Traditional automata accept or reject their input and are therefore Boolean. In contrast, weighted automata map each word to a value from a semiring over a large domain. The special case of lattice automata, in which the semiring is a finite lattice, has interesting theoretical properties as well as applications in formal methods. A minimal deterministic automaton captures the combinatorial nature and complexity of a formal language. Deterministic automata are used in runtime monitoring, pattern recognition, and modeling systems. Thus, the minimization problem for deterministic automata is of great interest, both theoretically and in practice. For deterministic traditional automata on finite words, a minimization algorithm, based on the Myhill-Nerode right congruence on the set of words, generates in polynomial time a canonical minimal deterministic automaton. A polynomial algorithm is known also for deterministic\u00a0\u2026", "num_citations": "3\n", "authors": ["1788"]}
{"title": "Parameterized weighted containment\n", "abstract": " Partially specified systems and specifications are used in formal methods such as stepwise design and query checking. Existing methods consider a setting in which systems and their correctness are Boolean. In recent years, there has been growing interest and need for quantitative formal methods, where systems may be weighted and specifications may be multivalued. Weighted automata, which map input words to a numerical value, play a key role in quantitative reasoning. Technically, every transition in a weighted automaton A has a cost, and the value A assigns to a finite word w is the sum of the costs on the transitions traversed along the most expensive accepting run of A on w. We study parameterized weighted containment: given three weighted automata A, B, and C, with B being partial, the goal is to find an assignment to the missing costs in B so that we end up with B\u2032 for which B\u2032\u2264 C, where \u2264 is the\u00a0\u2026", "num_citations": "3\n", "authors": ["1788"]}
{"title": "Synthesis with clairvoyance\n", "abstract": " We consider the problem of automatically synthesizing, from a linear temporal logic (LTL) specification, a system that is guaranteed to satisfy the specification with respect to all environments. Algorithms for solving the synthesis problem reduce it to the solution of a game played between the system and its environment, in which the system and environment alternate between generating outputs and inputs respectively. Typically, the system is required to generate an output right after receiving the current input. If a solution to the game exists, the specification is said to be realizable.               In this paper, we consider the role of clairvoyance in synthesis, in which the system can \u201clook into the future,\u201d basing its output upon future inputs. An infinite look-ahead transforms the realizability problem into a problem known as universal satisfiability. A thesis we explore in this paper is that the notion of clairvoyance is\u00a0\u2026", "num_citations": "3\n", "authors": ["1788"]}
{"title": "Existence of reduction hierarchies\n", "abstract": " In the automata-theoretic approach to verification, we model programs and specifications by automata on infinite words. Correctness of a program with respect to a specification can then be reduced to the language-containment problem. In a concurrent setting, the program is typically a parallel composition of many coordinating processes, and the language-containment problem that corresponds to verification is    where P 1, P 2, ..., P n are automata that model the underlying coordinating processes, and T is the task they should perform. In 1994, Kurshan suggested the heuristic of Reduction Hierarchies for circumventing the exponential blow-up introduced by conventional methods that solve the problem (\u2020). In the reduction-hierarchy heuristic, we solve the problem (\u2020) by solving a sequence of easier problems, which involve only automata of tractable sizes. Complexity\u00a0\u2026", "num_citations": "3\n", "authors": ["1788"]}
{"title": "Certifying Inexpressibility.\n", "abstract": " Different classes of automata on infinite words have different expressive power. Deciding whether a given language L\u2286 \u03a3 \u03c9 can be expressed by an automaton of a desired class can be reduced to deciding a game between Prover and Refuter: in each turn of the game, Refuter provides a letter in \u03a3, and Prover responds with an annotation of the current state of the run (for example, in the case of B\u00fcchi automata, whether the state is accepting or rejecting, and in the case of parity automata, what the color of the state is). Prover wins if the sequence of annotations she generates is correct: it is an accepting run iff the word generated by Refuter is in L. We show how a winning strategy for Refuter can serve as a simple and easy-to-understand certificate to inexpressibility, and how it induces additional forms of certificates. Our framework handles all classes of deterministic automata, including ones with structural restrictions like weak automata. In addition, it can be used for refuting separation of two languages by an automaton of the desired class, and for finding automata that approximate L and belong to the desired class.", "num_citations": "2\n", "authors": ["1788"]}
{"title": "Canonicity in GFG and transition-based automata\n", "abstract": " Minimization of deterministic automata on finite words results in a {\\em canonical\\/} automaton. For deterministic automata on infinite words, no canonical minimal automaton exists, and a language may have different minimal deterministic B\\\"uchi (DBW) or co-B\\\"uchi (DCW) automata. In recent years, researchers have studied {\\em good-for-games\\/} (GFG) automata -- nondeterministic automata that can resolve their nondeterministic choices in a way that only depends on the past. Several applications of automata in formal methods, most notably synthesis, that are traditionally based on deterministic automata, can instead be based on GFG automata. The {\\em minimization\\/} problem for DBW and DCW is NP-complete, and it stays NP-complete for GFG B\\\"uchi and co-B\\\"uchi automata. On the other hand, minimization of GFG co-B\\\"uchi automata with {\\em transition-based\\/} acceptance (GFG-tNCWs) can be solved in polynomial time. In these automata, acceptance is defined by a set  of transitions, and a run is accepting if it traverses transitions in  only finitely often. This raises the question of canonicity of minimal deterministic and GFG automata with transition-based acceptance. In this paper we study this problem. We start with GFG-tNCWs and show that the safe components (that is, these obtained by restricting the transitions to these not in ) of all minimal GFG-tNCWs are isomorphic, and that by saturating the automaton with transitions in  we get isomorphism among all minimal GFG-tNCWs. Thus, a canonical form for minimal GFG-tNCWs can be obtained in polynomial time. We continue to DCWs with transition-based acceptance (tDCWs\u00a0\u2026", "num_citations": "2\n", "authors": ["1788"]}
{"title": "Unary prime languages\n", "abstract": " A regular language L of finite words is composite if there are regular languages L\u2081, L\u2082,\u2026, L_t such that L=\u22c2 _ {i= 1}^ t L_i and the index (number of states in a minimal DFA) of every language L_i is strictly smaller than the index of L. Otherwise, L is prime. Primality of regular languages was introduced and studied in [O. Kupferman and J. Mosheiff, 2015], where the complexity of deciding the primality of the language of a given DFA was left open, with a doubly-exponential gap between the upper and lower bounds. We study primality for unary regular languages, namely regular languages with a singleton alphabet. A unary language corresponds to a subset of \u2115, making the study of unary prime languages closer to that of primality in number theory. We show that the setting of languages is richer. In particular, while every composite number is the product of two smaller numbers, the number t of languages necessary to decompose a composite unary language induces a strict hierarchy. In addition, a primality witness for a unary language L, namely a word that is not in L but is in all products of languages that contain L and have an index smaller than L\u2019s, may be of exponential length. Still, we are able to characterize compositionality by structural properties of a DFA for L, leading to a LogSpace algorithm for primality checking of unary DFAs.", "num_citations": "2\n", "authors": ["1788"]}
{"title": "Capacitated automata and systems\n", "abstract": " Capacitated automata (CAs), introduced by Kupferman and Tamir at 2014, are a variant of finite-state automata in which each transition is associated with a (possibly infinite) capacity that bounds the number of times the transition may be traversed in a single run. We continue the study of the theoretical properties of CA and solve problems that were left open by Kupferman and Tamir. We show that union and intersection of CAs involve an exponential blow-up and that determinization and complementation involve a doubly-exponential blow-up. This blow-up is carried over to the complexity of the universality and containment problems, which we show to be EXPSPACE-complete. On the positive side, capacities do not increase the complexity when used in the deterministic setting. Also, the containment problem for nondeterministic CAs is PSPACE-complete when capacities are used only in the left-hand side\u00a0\u2026", "num_citations": "2\n", "authors": ["1788"]}
{"title": "Sensing as a complexity measure\n", "abstract": " The size of deterministic automata required for recognizing regular and -regular languages is a well-studied measure for the complexity of languages. We introduce and study a new complexity measure, based on the sensing required for recognizing the language. Intuitively, the sensing cost quantifies the detail in which a random input word has to be read in order to decide its membership in the language. We study the sensing cost of regular and -regular languages, as well as applications of the study in practice, especially in the monitoring and synthesis of reactive systems.", "num_citations": "2\n", "authors": ["1788"]}
{"title": "LTL with Arithmetic and its Applications in Reasoning about Hierarchical Systems.\n", "abstract": " The computational bottleneck in model-checking applications is the blow-up involved in the translation of systems to their mathematical model. This blow up is especially painful in systems with variables over an infinite domain, and in composite systems described by means of their underlying components. We introduce and study linear temporal logic with arithmetic (LTLA, for short), where formulas include variables that take values in Z, and in which linear arithmetic over these values is supported. We develop an automata-theoretic approach for reasoning about LTLA formulas and use it in order to solve, in PSPACE, the satisfiability problem for the existential fragment of LTLA and the model-checking problem for its universal fragment. We show that these results are tight, as a single universallyquantified variable makes the satisfiability problem for LTLA undecidable. In addition to reasoning about systems with variables over Z, we suggest applications of LTLA in reasoning about hierarchical systems, which consist of subsystems that can call each other in a hierarchical manner. We use the values in Z in order to describe the nesting depth of components in the system. A naive model-checking algorithm for hierarchical systems flattens them, which involves an exponential blow up. We suggest a model-checking algorithm that avoids the flattening and avoids a blow up in the number of components.", "num_citations": "2\n", "authors": ["1788"]}
{"title": "Timed network games with clocks\n", "abstract": " Network games are widely used as a model for selfish resource-allocation problems. In the classical model, each player selects a path connecting her source and target vertices. The cost of traversing an edge depends on the {\\em load}; namely, number of players that traverse it. Thus, it abstracts the fact that different users may use a resource at different times and for different durations, which plays an important role in determining the costs of the users in reality. For example, when transmitting packets in a communication network, routing traffic in a road network, or processing a task in a production system, actual sharing and congestion of resources crucially depends on time. In \\cite{AGK17}, we introduced {\\em timed network games}, which add a time component to network games. Each vertex  in the network is associated with a cost function, mapping the load on  to the price that a player pays for staying in  for one time unit with this load. Each edge in the network is guarded by the time intervals in which it can be traversed, which forces the players to spend time in the vertices. In this work we significantly extend the way time can be referred to in timed network games. In the model we study, the network is equipped with {\\em clocks}, and, as in timed automata, edges are guarded by constraints on the values of the clocks, and their traversal may involve a reset of some clocks. We argue that the stronger model captures many realistic networks. The addition of clocks breaks the techniques we developed in \\cite{AGK17} and we develop new techniques in order to show that positive results on classic network games carry over to the stronger timed\u00a0\u2026", "num_citations": "2\n", "authors": ["1788"]}
{"title": "Erratum for \u201cWhat causes a system to satisfy a specification?\u201d\n", "abstract": " On page 10 of \u201cWhat Causes a System to Satisfy a Specification?\u201d[Chockler et al. 2008](first paragraph, just before Definition 2.3), we describe Boolean circuits as a special case of binary causal models where each gate of the circuit is a variable of the model. In other words, the inner gates of the circuit are also variables, whose values are computed based on the values of the inputs in the current context. While this is indeed the most general definition of Boolean circuits as causal models, it is in fact not the definition we use in the remainder of the article. Starting with Definition 2.3, we assume that the set of variables consists of the set of inputs to the circuit, and the output; there are no variables corresponding to the inner gates of the circuit. Thus, the particular structure of the circuit is immaterial; all we care about is the input and output. Thus, the only equation of interest is the one defining output in terms of the input\u00a0\u2026", "num_citations": "2\n", "authors": ["1788"]}
{"title": "Lower bounds on witnesses for nonemptiness of universal co-B\u00fcchi automata\n", "abstract": " The nonemptiness problem for nondeterministic automata on infinite words can be reduced to a sequence of reachability queries. The length of a shortest witness to the nonemptiness is then polynomial in the automaton. Nonemptiness algorithms for alternating automata translate them to nondeterministic automata. The exponential blow-up that the translation involves is justified by lower bounds for the nonemptiness problem, which is exponentially harder for alternating automata. The translation to nondeterministic automata also entails a blow-up in the length of the shortest witness. A matching lower bound here is known for cases where the translation involves a 2                   O(n) blow up, as is the case for finite words or B\u00fcchi automata.               Alternating co-B\u00fcchi automata and witnesses to their nonemptiness have applications in model checking (complementing a nondeterministic B\u00fcchi word\u00a0\u2026", "num_citations": "2\n", "authors": ["1788"]}
{"title": "On the duality between vacuity and coverage\n", "abstract": " Sanity checks such as vacuity and coverage are used to evaluate the quality of both implementations and specifications. We show formally that vacuity and coverage are dual concepts, studying them in a setting in which both the implementation and the specification are given by circuits. To formalize the duality, we present a range of mutations that one can apply to a circuit and partition them into mutations that add, remove, and modify behaviors. Many mutations correspond to physical and design faults, such as ones in which signals are ignored, flipped, delayed, or stuck at a value, and combinations thereof. For most of the mutations, we exhibit corresponding mutations also in the case where the specification is given as a temporal logic formula. We introduce and study the notion of dual mutations. A mutation \u00b5 that adds or modifies behaviors is dual to a mutation \u00b5 that removes or modifies behaviors if, for all implementations I and specifications S, satisfaction of S by a mutant implementation I\u00b5, obtained from I by applying \u00b5, is related to satisfaction by I of a mutant specification S\u00b5, obtained from S by applying \u00b5. Thus, the low coverage of I by S, which causes I\u00b5 to satisfy S, is related to the vacuous satisfaction of S by I, which causes I to satisfy S\u00b5. The notion of dual mutations also applies in a setting in which the specification is a temporal logic formula.Beyond the clean theoretical picture that the duality suggests, it offers important applications. First, we obtain new coverage metrics and new definitions of vacuity that have so far been used only in one of the sanity checks. Second, when low coverage is detected with a mutation, a tighter specification\u00a0\u2026", "num_citations": "2\n", "authors": ["1788"]}
{"title": "Multi-valued logics, automata, simulations, and games\n", "abstract": " Multi-valued systems are systems in which the atomic propositions and the transitions are not Boolean and can take values from some set. Latticed systems, in which the elements in the set are partially ordered, are useful in abstraction, query checking, and reasoning about multiple view-points. For example, abstraction involves systems in which an atomic proposition can take values from {true, unknown, false}, and these values can be partially ordered according to a \u201cbeing more true\u201d order (true\u2009\u2265\u2009unknown\u2009\u2265\u2009false) or according to a \u201cbeing more informative\u201d order (true\u2009\u2265\u2009unknown and false\u2009\u2265\u2009unknown). For Boolean temporal logics, researchers have developed a rich and beautiful theory that is based on viewing formulas as descriptors of languages of infinite words or trees. This includes a relation between temporal-logic formulas and automata on infinite objects, a theory of simulation relation\u00a0\u2026", "num_citations": "2\n", "authors": ["1788"]}
{"title": "On the succinctness of nondeterminism\n", "abstract": " Much is known about the differences in expressiveness and succinctness between nondeterministic and deterministic automata on infinite words. Much less is known about the relative succinctness of the different classes of nondeterministic automata. For example, while the best translation from a nondeterministic B\u00fcchi automaton to a nondeterministic co-B\u00fcchi automaton is exponential, and involves determinization, no super-linear lower bound is known. This annoying situation, of not being able to use the power of nondeterminism, nor to show that it is powerless, is shared by more problems, with direct applications in formal verification.               In this paper we study a family of problems of this class. The problems originate from the study of the expressive power of deterministic B\u00fcchi automata: Landweber characterizes languages L\u2009\u2286\u2009\u03a3                   \u03c9                  that are recognizable by deterministic B\u00fcchi\u00a0\u2026", "num_citations": "2\n", "authors": ["1788"]}
{"title": "<![IGNORE []]\n", "abstract": " The \u03bc-calculus is an expressive specification language in which modal logic is extended with fixpoint operators, subsuming many dynamic, temporal, and description logics. Formulas of \u03bc-calculus are classified according to their alternation depth, which is the maximal length of a chain of nested alternating least and greatest fixpoint operators. Alternation depth is the major factor in the complexity of \u03bc-calculus model-checking algorithms. A refined classification of \u03bc-calculus formulas distinguishes between formulas in which the outermost fixpoint operator in the nested chain is a least fixpoint operator (formulas, where is the alternation depth) and formulas where it is a greatest fixpoint operator (formulas). The alternation-free \u03bc-calculus (AFMC) consists of \u03bc-calculus formulas with no alternation between least and greatest fixpoint operators. Thus, AFMC is a natural closure of, which is contained in both and. In this work\u00a0\u2026", "num_citations": "2\n", "authors": ["1788"]}
{"title": "Causality and responsibility in temporal logic model checking\n", "abstract": " The goal of formal verification is to verify that a system satisfies a specification. Even when the system is proven to be correct with respect to the specification, there is still a question of how complete the specification is, and whether it really covers all the behaviors of the system. Coverage metrics are based on modifications we apply to the system in order to check which parts of it were actually relevant for the verification process to succeed. Recent work on coverage in model checking suggests several coverage metrics and algorithms for finding parts of the system that are not covered by the specification. The work has already proven to be effective in practice, detecting design errors that escape early verification efforts in industrial settings. Roughly speaking, coverage considers the question of what causes the system to satisfy the specification. The philosophy literature has long been struggling with the problem of\u00a0\u2026", "num_citations": "2\n", "authors": ["1788"]}
{"title": "Games with Full, Longitudinal, and Transverse Observability\n", "abstract": " Design and control of multi-agent systems correspond to the synthesis of winning strategies in games that model the interaction between the agents. In games with full observability, the strategies of players depend on the full history of the play. In games with partial observability, strategies depend only on observable components of the history. We survey two approaches to partial observability in two-player turn-based games with behavioral winning conditions. The first is the traditional longitudinal observability, where in all vertices, the players observe the assignment only to an observable subset of the atomic propositions. The second is the recently studied transverse observability, where players observe the assignment to all the atomic propositions, but only in vertices they own.", "num_citations": "1\n", "authors": ["1788"]}
{"title": "Perspective games with notifications\n", "abstract": " A reactive system has to satisfy its specification in all environments. Accordingly, design of correct reactive systems corresponds to the synthesis of winning strategies in games that model the interaction between the system and its environment. The game is played on a graph whose vertices are partitioned among the players. The players jointly generate a path in the graph, with each player deciding the successor vertex whenever the path reaches a vertex she owns. The objective of the system player is to force the computation induced by the generated infinite path to satisfy a given specification. The traditional way of modelling uncertainty in such games is observation-based. There, uncertainty is longitudinal: the players partially observe all vertices in the history. Recently, researchers introduced perspective games, where uncertainty is transverse: players fully observe the vertices they own and have no information about the behavior of the computation between visits in such vertices. We introduce and study perspective games with notifications: uncertainty is still transverse, yet a player may be notified about events that happen between visits in vertices she owns. We distinguish between structural notifications, for example about visits in some vertices, and behavioral notifications, for example about the computation exhibiting a certain behavior. We study the theoretic properties of perspective games with notifications, and the problem of deciding whether a player has a winning perspective strategy. Such a strategy depends only on the visible history, which consists of both visits in vertices the player owns and notifications during visits in other\u00a0\u2026", "num_citations": "1\n", "authors": ["1788"]}
{"title": "Coverage and Vacuity in Network Formation Games\n", "abstract": " The frameworks of coverage and vacuity in formal verification analyze the effect of mutations applied to systems or their specifications. We adopt these notions to network formation games, analyzing the effect of a change in the cost of a resource. We consider two measures to be affected: the cost of the Social Optimum and extremums of costs of Nash Equilibria. Our results offer a formal framework to the effect of mutations in network formation games and include a complexity analysis of related decision problems. They also tighten the relation between algorithmic game theory and formal verification, suggesting refined definitions of coverage and vacuity for the latter.", "num_citations": "1\n", "authors": ["1788"]}
{"title": "Flow logic\n", "abstract": " Flow networks have attracted a lot of research in computer science. Indeed, many questions in numerous application areas can be reduced to questions about flow networks. Many of these applications would benefit from a framework in which one can formally reason about properties of flow networks that go beyond their maximal flow. We introduce Flow Logics: modal logics that treat flow functions as explicit first-order objects and enable the specification of rich properties of flow networks. The syntax of our logic BFL* (Branching Flow Logic) is similar to the syntax of the temporal logic CTL*, except that atomic assertions may be flow propositions, like  or , for , which refer to the value of the flow in a vertex, and that first-order quantification can be applied both to paths and to flow functions. We present an exhaustive study of the theoretical and practical aspects of BFL*, as well as extensions and fragments of it. Our extensions include flow quantifications that range over non-integral flow functions or over maximal flow functions, path quantification that ranges over paths along which non-zero flow travels, past operators, and first-order quantification of flow values. We focus on the model-checking problem and show that it is PSPACE-complete, as it is for CTL*. Handling of flow quantifiers, however, increases the complexity in terms of the network to , even for the LFL and BFL fragments, which are the flow-counterparts of LTL and CTL. We are still able to point to a useful fragment of BFL* for which the model-checking problem can be solved in polynomial time. Finally, we introduce and study the query-checking problem for BFL*, where\u00a0\u2026", "num_citations": "1\n", "authors": ["1788"]}
{"title": "A parametrized analysis of algorithms on hierarchical graphs\n", "abstract": " Hierarchical graphs are used in order to describe systems with a sequential composition of sub-systems. A hierarchical graph consists of a vector of subgraphs. Vertices in a subgraph may \u201ccall\u201d other subgraphs. The reuse of subgraphs, possibly in a nested way, causes hierarchical graphs to be exponentially more succinct than equivalent flat graphs. Early research on hierarchical graphs and the computational price of their succinctness suggests that there is no strong correlation between the complexity of problems when applied to flat graphs and their complexity in the hierarchical setting. That is, the complexity in the hierarchical setting is higher, but all \u201cjumps\u201d in complexity up to an exponential one are exhibited, including no jumps in some problems. We continue the study of the complexity of algorithms for hierarchical graphs, with the following contributions: (1) In many applications, the subgraphs have a small\u00a0\u2026", "num_citations": "1\n", "authors": ["1788"]}
{"title": "Timed Vacuity\n", "abstract": " Vacuity is a leading sanity check in model-checking, applied when the system is found to satisfy the specification. The check detects situations where the specification passes in a trivial way, say when a specification that requires every request to be followed by a grant is satisfied in a system with no requests. Such situations typically reveal problems in the modelling of the system or the specification, and indeed vacuity detection is a part of most industrial model-checking tools. Existing research and tools for vacuity concern discrete-time systems and specification formalisms. We introduce real-time vacuity, which aims to detect problems with real-time modelling. Real-time logics are used for the specification and verification of systems with a continuous-time behavior. We study vacuity for the branching real-time logic TCTL, and focus on vacuity with respect to the time constraints in the specification. Specifically, the\u00a0\u2026", "num_citations": "1\n", "authors": ["1788"]}
{"title": "Synthesis from component libraries with costs\n", "abstract": " Synthesis is the automated construction of a system from its specification. In real life, hardware and software systems are rarely constructed from scratch. Rather, a system is typically constructed from a library of components. Lustig and Vardi formalized this intuition and studied LTL synthesis from component libraries. In real life, designers seek optimal systems. In this paper we add optimality considerations to the setting. We distinguish between quality considerations (for example, size \u2013 the smaller a system is, the better it is), and pricing (for example, the payment to the company who manufactured the component). We study the problem of designing systems with minimal quality-cost and price. A key point is that while the quality cost is individual \u2013 the choices of a designer are independent of choices made by other designers that use the same library, pricing gives rise to a resource-allocation game \u2013 designers that\u00a0\u2026", "num_citations": "1\n", "authors": ["1788"]}
{"title": "Spanning-tree games\n", "abstract": " We introduce and study a game variant of the classical spanning-tree problem. Our spanning-tree game is played between two players, min and max, who alternate turns in jointly constructing a spanning tree of a given connected weighted graph G. Starting with the empty graph, in each turn a player chooses an edge that does not close a cycle in the forest that has been generated so far and adds it to that forest. The game ends when the chosen edges form a spanning tree in G. The goal of min is to minimize the weight of the resulting spanning tree and the goal of max is to maximize it. A strategy for a player is a function that maps each forest in G to an edge that is not yet in the forest and does not close a cycle. We show that while in the classical setting a greedy approach is optimal, the game setting is more complicated: greedy strategies, namely ones that choose in each turn the lightest (min) or heaviest (max) legal edge, are not necessarily optimal, and calculating their values is NP-hard. We study the approximation ratio of greedy strategies. We show that while a greedy strategy for min guarantees nothing, the performance of a greedy strategy for max is satisfactory: it guarantees that the weight of the generated spanning tree is at least w (MST (G))/2, where w (MST (G)) is the weight of a maximum spanning tree in G, and its approximation ratio with respect to an optimal strategy for max is 1.5+ 1/w (MST (G)), assuming weights in [0, 1]. We also show that these bounds are tight. Moreover, in a stochastic setting, where weights for the complete graph K_n are chosen at random from [0, 1], the expected performance of greedy strategies is\u00a0\u2026", "num_citations": "1\n", "authors": ["1788"]}
{"title": "The unfortunate-flow problem\n", "abstract": " In the traditional maximum-flow problem, the goal is to transfer maximum flow in a network by directing, in each vertex in the network, incoming flow into outgoing edges. The problem is one of the most fundamental problems in TCS, with application in numerous domains. The fact a maximal-flow algorithm directs the flow in all the vertices of the network corresponds to a setting in which the authority has control in all vertices. Many applications in which the maximal-flow problem is applied involve an adversarial setting, where the authority does not have such a control. We introduce and study the unfortunate flow problem, which studies the flow that is guaranteed to reach the target when the edges that leave the source are saturated, yet the most unfortunate decisions are taken in the vertices. When the incoming flow to a vertex is greater than the outgoing capacity, flow is lost. The problem models evacuation scenarios where traffic is stuck due to jams in junctions and communication networks where packets are dropped in overloaded routers. We study the theoretical properties of unfortunate flows, show that the unfortunate-flow problem is co-NP-complete and point to polynomial fragments. We introduce and study interesting variants of the problem: integral unfortunate flow, where the flow along edges must be integral, controlled unfortunate flow, where the edges from the source need not be saturated and may be controlled, and no-loss controlled unfortunate flow, where the controlled flow must not be lost.", "num_citations": "1\n", "authors": ["1788"]}
{"title": "Examining classical graph-theory problems from the viewpoint of formal-verification methods (invited talk)\n", "abstract": " The talk surveys a series of works that lift the rich semantics and structure of graphs, and the experience of the formal-verification community in reasoning about them, to classical graph-theoretical problems.", "num_citations": "1\n", "authors": ["1788"]}
{"title": "Inherent Vacuity in Lattice Automata\n", "abstract": " Vacuity checking is traditionally performed after model checking has terminated successfully. It ensures that all the elements of the specification have played a role in its satisfaction by the system. The need to check the quality of specifications is even more acute in property-based design, where the specification is the only input, serving as a basis to the development of the system. Inherent vacuity adapts the theory of vacuity in model checking to the setting of property-based design. Essentially, a specification is inherently vacuous if it can be mutated into a simpler equivalent specification, which is known, in the case of specifications in linear temporal logic, to coincide with the fact the specification is satisfied vacuously in all systems.               A recent development in formal methods is an extension of the Boolean setting to a multi-valued one. In particular, instead of Boolean automata, which\u00a0\u2026", "num_citations": "1\n", "authors": ["1788"]}
{"title": "From reachability to temporal specifications in cost-sharing games\n", "abstract": " Multi-agents cost-sharing games are commonly used for modeling settings in which different entities share resources. For example, the setting in which entities need to route messages in a network is modeled by a network-formation game: the network is modeled by a graph, and each agent has to select a path satisfying his reachability objective. In practice, the objectives of the entities are often more involved than reachability. The need to specify and reason about rich specifications has been extensively studied in the context of verification and synthesis of reactive systems. This paper suggests and analyzes a generalization of cost-sharing games that captures such rich specifications. In particular, we study network-formation games with regular objectives. In these games, the edges of the graph are labeled by alphabet letters and the objective of each player is a regular language over the alphabet of labels\u00a0\u2026", "num_citations": "1\n", "authors": ["1788"]}
{"title": "Attention-Based Coverage Metrics\n", "abstract": " Over the last decade, extensive research has been conducted on coverage metrics for model checking. The most common coverage metrics are based on mutations, where one examines the effect of small modifications of the system on the satisfaction of the specification. While it is commonly accepted that mutation-based coverage provides adequate means for assessing the exhaustiveness of the model-checking procedure, the incorporation of coverage checks in industrial model checking tools is still very partial. One reason for this is the typically overwhelming number of non-covered mutations, which requires the user to somehow filter those that are most likely to point to real errors or overlooked behaviors.               We address this problem and propose to filter mutations according to the attention the designer has paid to the mutated components in the model. We formalize the attention intuition using a\u00a0\u2026", "num_citations": "1\n", "authors": ["1788"]}
{"title": "Weighted safety\n", "abstract": " Safety properties, which assert that the system always stays within some allowed region, have been extensively studied and used. In the last years, we see more and more research on quantitative formal methods, where systems and specifications are weighted. We introduce and study safety in the weighted setting. For a value v\u2009\u2208\u2009\u211a , we say that a weighted language L:\u03a3*\u2009\u2192\u2009\u211a is v-safe if every word with cost at least v has a prefix all whose extensions have cost at least v. The language L is then weighted safe if L is v-safe for some v.               Given a regular weighted language L, we study the set of values v\u2009\u2208\u2009\u211a for which L is v-safe. We show that this set need not be closed upwards or downwards and we relate the v-safety of L with the safety of the (Boolean) language of words whose cost in L is at most v. We show that the latter need not be regular but is always context free. Given a deterministic weighted automaton \u00a0\u2026", "num_citations": "1\n", "authors": ["1788"]}
{"title": "Approximating deterministic lattice automata\n", "abstract": " Traditional automata accept or reject their input, and are therefore Boolean. Lattice automata generalize the traditional setting and map words to values taken from a lattice. In particular, in a fully-ordered lattice, the elements are 0,1,\u2026,n\u2009\u2212\u20091, ordered by the standard \u2264 order. Lattice automata, and in particular lattice automata defined with respect to fully-ordered lattices, have interesting theoretical properties as well as applications in formal methods. Minimal deterministic automata capture the combinatorial nature and complexity of a formal language. Deterministic automata have many applications in practice.               In [13], we studied minimization of deterministic lattice automata. We proved that the problem is in general NP-complete, yet can be solved in polynomial time in the case the lattices are fully-ordered. The multi-valued setting makes it possible to combine reasoning about lattice automata with\u00a0\u2026", "num_citations": "1\n", "authors": ["1788"]}
{"title": "Concurrency counts\n", "abstract": " One of the natural examples to the power of concurrency is the ability to count to n with log n concurrent processes. In this work we study the cost of counting within weaker types of concurrency, where no cooperation takes place between the concurrent processes, except when time comes to decide whether the input should be accepted. We first study the number of states required for deterministic, nondeterministic, universal, and alternating automata to count to n, namely to accept the unary language {1n}. We then study settings in which the task of counting should be accomplished before the whole input is read (eg, in the language \u03a3n\u00b7 0\u00b7 \u03a3\u2217). We show that then, the weaker types of concurrency are not helpful. Our results explain the strength of synchronized concurrent systems, where synchronization between the underlying components is allowed, and imply that semi-extended regular expressions, which can be efficiently translated to partially input-synchronized alternating automata, cannot be efficiently translated to alternating automata.", "num_citations": "1\n", "authors": ["1788"]}
{"title": "From quantity to quality\n", "abstract": " In temporal-logic model checking, we verify the correctness of a program with respect to a desired behavior by checking whether a structure that models the program satisfies a temporal-logic formula that specifies the behavior. The model-checking problem for the branching-time temporal logic CTL can be solved in linear running time, and model-checking tools for CTL are used successfully in industrial applications. The development of programs that must meet rigid real-time constraints has brought with it a need for real-time temporal logics that enable quantitative reference to time. Early research on real-time temporal logics uses the discrete domain of the integers to model time. Present research on real-time temporal logics focuses on continuous time and uses the dense domain of the reals to model time. There, model checking becomes significantly more complicated. For example, the model-checking problem\u00a0\u2026", "num_citations": "1\n", "authors": ["1788"]}
{"title": "Once and for all [temporal logic]\n", "abstract": " It has long been known that past-time operators add no expressive power to linear temporal logics. In this paper, we consider the extension of branching temporal logics with past-time operators. Two possible views regarding the nature of past in a branching-time model induce two different such extensions. In the first view, past is branching and each moment in time may have several possible futures and several possible pasts. In the second view, past is linear and each moment in time may have several possible futures and a unique past. Both views assume that past is finite. We discuss the practice of these extensions as specification languages, characterize their expressive power, and examine the complexity of their model-checking and satisfiability problems.", "num_citations": "1\n", "authors": ["1788"]}
{"title": "Typeness for?-regular automata\n", "abstract": " We introduce and study three notions of typeness for automata on infinite words. For an acceptance-condition class 7 (that is, 7 is weak, B\u00fcchi, co-Biichi, Rabin, or Streett), deterministic\"/-typeness asks for the existence of an equivalent 7-automaton on the same deterministic structure, nondeterministic-y-typeness asks for the existence of an equivalent 7-automaton on the same structure, and'y-powerset-typeness asks for the existence of an equivalent 7-automaton on the (deterministic) powerset structureone obtained by applying the subset construction. The notions are helpful in studying the complexity and complication of translations between the various classes of automata. For example, we prove that deterministic Buchi automata are co-Biichi type; it follows that a translation from deterministic Buchi to deterministic co-Biichi automata, when exists, involves no blow up. On the other hand, we prove that\u00a0\u2026", "num_citations": "1\n", "authors": ["1788"]}
{"title": "Formalizing Quality of Reactive Systems\n", "abstract": " Temporal-logic model-checking is a successful paradigm for checking whether reactive systems satisfy specifications about their on-going behavior. The model-checking paradigm is Boolean, addressing the yes/no satisfiability question. We introduce and study a generalization of temporal logic and the model-checking paradigm, addressing a quality question. We define LTLv\u2013an extension of linear temporal logic with quality operators. The operators enable the specifier to prioritize different satisfying possibilities, to associate components of the specification with their criticality level, and to discount the influence of components on which we have low confidence. We develop a (weighted) automata-theoretic approach for reasoning about LTLv specifications, solve its model-checking problem, and study its theoretical aspects.", "num_citations": "1\n", "authors": ["1788"]}