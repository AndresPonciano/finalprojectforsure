{"title": "Synthesizing software verifiers from proof rules\n", "abstract": " Automatically generated tools can significantly improve programmer productivity. For example, parsers and dataflow analyzers can be automatically generated from declarative specifications in the form of grammars, which tremendously simplifies the task of implementing a compiler. In this paper, we present a method for the automatic synthesis of software verification tools. Our synthesis procedure takes as input a description of the employed proof rule, e.g., program safety checking via inductive invariants, and produces a tool that automatically discovers the auxiliary assertions required by the proof rule, e.g., inductive loop invariants and procedure summaries. We rely on a (standard) representation of proof rules using recursive equations over the auxiliary assertions. The discovery of auxiliary assertions, i.e., solving the equations, is based on an iterative process that extrapolates solutions obtained for finitary\u00a0\u2026", "num_citations": "280\n", "authors": ["667"]}
{"title": "Automatic discovery and quantification of information leaks\n", "abstract": " Information-flow analysis is a powerful technique for reasoning about the sensitive information exposed by a program during its execution. We present the first automatic method for information-flow analysis that discovers what information is leaked and computes its comprehensive quantitative interpretation. The leaked information is characterized by an equivalence relation on secret artifacts, and is represented by a logical assertion over the corresponding program variables. Our measurement procedure computes the number of discovered equivalence classes and their sizes. This provides a basis for computing a set of quantitative properties, which includes all established information-theoretic measures in quantitative information-flow. Our method exploits an inherent connection between formal models of qualitative information-flow and program verification techniques. We provide an implementation of our\u00a0\u2026", "num_citations": "247\n", "authors": ["667"]}
{"title": "Invgen: An efficient invariant generator\n", "abstract": " In this paper we present InvGen, an automatic linear arithmetic invariant generator for imperative programs. InvGen\u2019s unique feature is in its use of dynamic analysis to make invariant generation order of magnitude more efficient.", "num_citations": "175\n", "authors": ["667"]}
{"title": "On solving universally quantified horn clauses\n", "abstract": " Program proving can be viewed as solving for unknown relations (such as loop invariants, procedure summaries and so on) that occur in the logical verification conditions of a program, such that the verification conditions are valid. Generic logical tools exist that can solve such problems modulo certain background theories, and therefore can be used for program analysis. Here, we extend these techniques to solve for quantified relations. This makes it possible to guide the solver by constraining the form of the proof, allowing it to converge when it otherwise would not. We show how to simulate existing abstract domains in this way, without having to directly implement program analyses or make certain heuristic choices, such as the terms and predicates that form the parameters of the abstract domain. Moreover, the approach gives the flexibility to go beyond these domains and experiment quickly with various\u00a0\u2026", "num_citations": "134\n", "authors": ["667"]}
{"title": "Predicate abstraction and refinement for verifying multi-threaded programs\n", "abstract": " Automated verification of multi-threaded programs requires explicit identification of the interplay between interacting threads, so-called environment transitions, to enable scalable, compositional reasoning. Once the environment transitions are identified, we can prove program properties by considering each program thread in isolation, as the environment transitions keep track of the interleaving with other threads. Finding adequate environment transitions that are sufficiently precise to yield conclusive results and yet do not overwhelm the verifier with unnecessary details about the interleaving with other threads is a major challenge. In this paper we propose a method for safety verification of multi-threaded programs that applies (transition) predicate abstraction-based discovery of environment transitions, exposing a minimal amount of information about the thread interleaving. The crux of our method is an abstraction\u00a0\u2026", "num_citations": "117\n", "authors": ["667"]}
{"title": "Constraint solving for interpolation\n", "abstract": " Interpolation is an important component of recent methods for program verification. It provides a natural and effective means for computing separation between the sets of \u2018good\u2019 and \u2018bad\u2019 states. The existing algorithms for interpolant generation are proof-based: They require explicit construction of proofs, from which interpolants can be computed. Construction of such proofs is a difficult task. We propose an algorithm for the generation of interpolants for the combined theory of linear arithmetic and uninterpreted function symbols that does not require a priori constructed proofs to derive interpolants. It uses a reduction of the problem to constraint solving in linear arithmetic, which allows application of existing highly optimized Linear Programming solvers in black-box fashion. We provide experimental evidence of the practical applicability of our algorithm.", "num_citations": "112\n", "authors": ["667"]}
{"title": "Solving existentially quantified horn clauses\n", "abstract": " Temporal verification of universal (i.e., valid for all computation paths) properties of various kinds of programs, e.g., procedural, multi-threaded, or functional, can be reduced to finding solutions for equations in form of universally quantified Horn clauses extended with well-foundedness conditions. Dealing with existential properties (e.g., whether there exists a particular computation path), however, requires solving forall-exists quantified Horn clauses, where the conclusion part of some clauses contains existentially quantified variables. For example, a deductive approach to CTL verification reduces to solving such clauses. In this paper we present a method for solving forall-exists quantified Horn clauses extended with well-foundedness conditions. Our method is based on a counterexample-guided abstraction refinement scheme to discover witnesses for existentially quantified variables. We also present an\u00a0\u2026", "num_citations": "110\n", "authors": ["667"]}
{"title": "Approximation and randomization for quantitative information-flow analysis\n", "abstract": " Quantitative information-flow analysis (QIF) is an emerging technique for establishing information-theoretic confidentiality properties. Automation of QIF is an important step towards ensuring its practical applicability, since manual reasoning about program security has been shown to be a tedious and expensive task. Existing automated techniques for QIF fall short of providing full coverage of all program executions, especially in the presence of unbounded loops and data structures, which are notoriously difficult to analyze automatically. In this paper we propose a blend of approximation and randomization techniques to bear on the challenge of sufficiently precise, yet efficient computation of quantitative information flow properties. Our approach relies on a sampling method to enumerate large or unbounded secret spaces, and applies both static and dynamic program analysis techniques to deliver necessary over\u00a0\u2026", "num_citations": "89\n", "authors": ["667"]}
{"title": "HSF (C): A software verifier based on Horn clauses\n", "abstract": " HSF(C) is a tool that automates verification of safety and liveness properties for C programs. This paper describes the verification approach taken by HSF(C) and provides instructions on how to install and use the tool.", "num_citations": "88\n", "authors": ["667"]}
{"title": "Program Verification as Satisfiability Modulo Theories.\n", "abstract": " A key driver of SMT over the past decade has been an interchange format, SMT-LIB, and a growing set of benchmarks sharing this common format. SMT-LIB captures very well an interface that is suitable for many tasks that reduce to solving first-order formulas modulo theories. Here we propose to extend these benefits into the domain of symbolic software model checking. We make a case that SMT-LIB can be used, and to a limited extent adapted, for exchanging symbolic software model checking benchmarks. We believe this layer facilitates dividing innovations in modeling, developing program logics and frontends, from developing algorithms for solving constraints over recursive predicates.", "num_citations": "87\n", "authors": ["667"]}
{"title": "A constraint-based approach to solving games on infinite graphs\n", "abstract": " We present a constraint-based approach to computing winning strategies in two-player graph games over the state space of infinite-state programs. Such games have numerous applications in program verification and synthesis, including the synthesis of infinite-state reactive programs and branching-time verification of infinite-state programs. Our method handles games with winning conditions given by safety, reachability, and general Linear Temporal Logic (LTL) properties. For each property class, we give a deductive proof rule that---provided a symbolic representation of the game players---describes a winning strategy for a particular player. Our rules are sound and relatively complete. We show that these rules can be automated by using an off-the-shelf Horn constraint solver that supports existential quantification in clause heads. The practical promise of the rules is demonstrated through several case studies\u00a0\u2026", "num_citations": "79\n", "authors": ["667"]}
{"title": "Automatically verifying reachability and well-formedness in P4 Networks\n", "abstract": " P4 allows a new level of dynamism for routers beyond Open-Flow 1.4 by allowing headers and tables to be modified by software in the field. Without care, P4 can unleash a new wave of software bugs. Existing tools (eg, VeriFlow, Net-Plumber, Hassel, NoD) cannot model changes to forwarding behaviors without reprogramming tool internals or having users manually add new forwarding models. Further, a P4 network can introduce a new class of bugs (not tested for by existing tools) wherein the P4 network creates malformed packets.To attack these two problems, we provide an operational semantics for P4 constructs and use it to compile P4 to Datalog so that the verification model can be automatically updated as the network changes. We demonstrate this vision by compiling the mTag example in the P4 specification (and a new sTag security example) on a sample network and by automatically detecting forwarding bugs. Efficiently verifying (across all table entries and packet headers) that a P4 network only delivers well-formed packets takes a few seconds.", "num_citations": "78\n", "authors": ["667"]}
{"title": "Separation logic+ superposition calculus= heap theorem prover\n", "abstract": " Program analysis and verification tools crucially depend on the ability to symbolically describe and reason about sets of program behaviors. Separation logic provides a promising foundation for dealing with heap manipulating programs, while the development of practical automated deduction/satisfiability checking tools for separation logic is a challenging problem. In this paper, we present an efficient, sound and complete automated theorem prover for checking validity of entailments between separation logic formulas with list segment predicates. Our theorem prover integrates separation logic inference rules that deal with list segments and a superposition calculus to deal with equality/aliasing between memory locations. The integration follows a modular combination approach that allows one to directly incorporate existing advanced techniques for first-order reasoning with equality, as well as account for\u00a0\u2026", "num_citations": "74\n", "authors": ["667"]}
{"title": "Model checking duration calculus: A practical approach\n", "abstract": " Model checking of real-time systems against Duration Calculus (DC) specifications requires the translation of DC formulae into automata-based semantics. The existing algorithms provide a limited DC coverage and do not support compositional verification. We propose a translation algorithm that advances the applicability of model checking tools to realistic applications. Our algorithm significantly extends the subset of DC that can be checked automatically. The central part of the algorithm is the automatic decomposition of DC specifications into sub-properties that can be verified independently. The decomposition is based on a novel distributive law for DC. We implemented the algorithm in a tool chain for the automated verification of systems comprising data, communication, and real-time aspects. We applied the tool chain to verify safety properties in an industrial case study from the European Train\u00a0\u2026", "num_citations": "74\n", "authors": ["667"]}
{"title": "Threader: A constraint-based verifier for multi-threaded programs\n", "abstract": " We present a tool that implements Owicki-Gries and rely-guarantee methods for the compositional verification of multi-threaded programs. Our tool computes the requisite auxiliary assertions automatically using an abstraction and refinement procedure. Our procedure is based on a Horn clause encoding of refinement queries and facilitates the discovery of thread-modular proofs when such proofs exist. We present the tool and its evaluation on a collection of benchmarks, including a direct comparison of the effectiveness of the proof rules.", "num_citations": "73\n", "authors": ["667"]}
{"title": "Scaling network verification using symmetry and surgery\n", "abstract": " On the surface, large data centers with about 100,000 stations and nearly a million routing rules are complex and hard to verify. However, these networks are highly regular by design; for example they employ fat tree topologies with backup routers interconnected by redundant patterns. To exploit these regularities, we introduce network transformations: given a reachability formula and a network, we transform the network into a simpler to verify network and a corresponding transformed formula, such that the original formula is valid in the network if and only if the transformed formula is valid in the transformed network. Our network transformations exploit network surgery (in which irrelevant or redundant sets of nodes, headers, ports, or rules are ``sliced'' away) and network symmetry (say between backup routers). The validity of these transformations is established using a formal theory of networks. In particular, using\u00a0\u2026", "num_citations": "71\n", "authors": ["667"]}
{"title": "Crystalnet: Faithfully emulating large production networks\n", "abstract": " Network reliability is critical for large clouds and online service providers like Microsoft. Our network is large, heterogeneous, complex and undergoes constant churns. In such an environment even small issues triggered by device failures, buggy device software, configuration errors, unproven management tools and unavoidable human errors can quickly cause large outages. A promising way to minimize such network outages is to proactively validate all network operations in a high-fidelity network emulator, before they are carried out in production. To this end, we present CrystalNet, a cloud-scale, high-fidelity network emulator. It runs real network device firmwares in a network of containers and virtual machines, loaded with production configurations. Network engineers can use the same management tools and methods to interact with the emulated network as they do with a production network. CrystalNet can\u00a0\u2026", "num_citations": "66\n", "authors": ["667"]}
{"title": "Separation logic modulo theories\n", "abstract": " Logical reasoning about program behaviours often requires dealing with heap structures as well as scalar data types. Advances in Satisfiability Modulo Theories (SMT) offer efficient procedures for dealing with scalar values, yet they lack expressive support for dealing with heap structures. In this paper, we present an approach that integrates separation logic\u2013a prominent logic for reasoning about linked data structures on the heap\u2013and existing SMT solving technology. Our model-based approach communicates heap aliasing information between theory and separation logic reasoning, providing an efficient decision procedure for discharging verification conditions in program analysis and verification.", "num_citations": "58\n", "authors": ["667"]}
{"title": "Solving constrained Horn clauses using interpolation\n", "abstract": " We present an interpolation-based method for symbolically solving systems of constrained Horn clauses. The method can be used to solve for unknown predicates in the verification conditions of programs. Thus, it has a variety of applications, including including model checking of recursive and threaded programs. The method is implemented in tool called Duality, which we evaluate using device driver verification benchmarks.", "num_citations": "58\n", "authors": ["667"]}
{"title": "Solving recursion-free horn clauses over LI+ UIF\n", "abstract": " Verification of programs with procedures, multi-threaded programs, and higher-order functional programs can be effectively automated using abstraction and refinement schemes that rely on spurious counterexamples for abstraction discovery. The analysis of counterexamples can be automated by a series of interpolation queries, or, alternatively, as a constraint solving query expressed by a set of recursion free Horn clauses. (A set of interpolation queries can be formulated as a single constraint over Horn clauses with linear dependency structure between the unknown relations.) In this paper we present an algorithm for solving recursion free Horn clauses over a combined theory of linear real/rational arithmetic and uninterpreted functions. Our algorithm performs resolution to deal with the clausal structure and relies on partial solutions to deal with (non-local) instances of functionality axioms.", "num_citations": "47\n", "authors": ["667"]}
{"title": "Compositional termination proofs for multi-threaded programs\n", "abstract": " Automated verification of multi-threaded programs is difficult. Direct treatment of all possible thread interleavings by reasoning about the program globally is a prohibitively expensive task, even for small programs. Rely-guarantee reasoning is a promising technique to address this challenge by reducing the verification problem to reasoning about each thread individually with the help of assertions about other threads. In this paper, we propose a proof rule that uses rely-guarantee reasoning for compositional verification of termination properties. The crux of our proof rule lies in its compositionality wrt. the thread structure of the program and wrt. the applied termination arguments \u2013 transition invariants. We present a method for automating the proof rule using an abstraction refinement procedure that is based on solving recursion-free Horn clauses. To deal with termination, we extend an existing Horn-clause\u00a0\u2026", "num_citations": "39\n", "authors": ["667"]}
{"title": "Constraint solving for interpolation\n", "abstract": " Interpolation is an important component of recent methods for program verification. It provides a natural and effective means for computing the separation between the sets of \u2018good\u2019 and \u2018bad\u2019 states. The existing algorithms for interpolant generation are proof-based: They require explicit construction of proofs, from which interpolants can be computed. Construction of such proofs is a difficult task. We propose an algorithm for the generation of interpolants for the combined theory of linear arithmetic and uninterpreted function symbols that does not require a priori constructed proofs to derive interpolants. It uses a reduction of the problem to constraint solving in linear arithmetic, which allows application of existing highly optimized Linear Programming solvers in a black-box fashion. We provide experimental evidence of the practical applicability of our algorithm.", "num_citations": "35\n", "authors": ["667"]}
{"title": "Operational semantics for declarative networking\n", "abstract": " Declarative Networking has been recently promoted as a high-level programming paradigm to more conveniently describe and implement systems that run in a distributed fashion over a computer network. It has already been used to implement various networked systems, e.g., network overlays, Byzantine fault tolerance protocols, and distributed hash tables. Declarative Networking relies upon a rule-based programming language that resembles Datalog and allows one to declaratively specify the flow of networking events. However, the presence of asynchronous communication, distribution, and imperative modification of the program state in Declarative Networking applications have been an obstacle for defining its semantics. Currently, the reference semantics is determined by the runtime environment only, which hinders further application development and makes any efforts to develop program analysis\u00a0\u2026", "num_citations": "34\n", "authors": ["667"]}
{"title": "Higher-order program verification as satisfiability modulo theories with algebraic data-types\n", "abstract": " We report on work in progress on automatic procedures for proving properties of programs written in higher-order functional languages. Our approach encodes higher-order programs directly as first-order SMT problems over Horn clauses. It is straight-forward to reduce Hoare-style verification of first-order programs into satisfiability of Horn clauses. The presence of closures offers several challenges: relatively complete proof systems have to account for closures; and in practice, the effectiveness of search procedures depend on encoding strategies and capabilities of underlying solvers. We here use algebraic data-types to encode closures and rely on solvers that support algebraic data-types. The viability of the approach is examined using examples from the literature on higher-order program verification.", "num_citations": "29\n", "authors": ["667"]}
{"title": "Computing relational fixed points using interpolation\n", "abstract": " We present a interpolation-based method for symbolically comput-ing relational post-fixed points. The method can be used to solve for unknown predicates in the verification conditions of programs. Thus, it has a variety of applications, including including model checking of recursive and threaded programs. The method is im-plemented in tool called Duality, which we evaluate using device driver verification benchmarks.", "num_citations": "27\n", "authors": ["667"]}
{"title": "Cardinalities and universal quantifiers for verifying parameterized systems\n", "abstract": " Parallel and distributed systems rely on intricate protocols to manage shared resources and synchronize, ie, to manage how many processes are in a particular state. Effective verification of such systems requires universally quantification to reason about parameterized state and cardinalities tracking sets of processes, messages, failures to adequately capture protocol logic. In this paper we present Tool, an automatic invariant synthesis method that integrates cardinality-based reasoning and universal quantification. The resulting increase of expressiveness allows Tool to verify, for the first time, a representative collection of intricate parameterized protocols.", "num_citations": "19\n", "authors": ["667"]}
{"title": "Constraint solving for program verification: Theory and practice by example\n", "abstract": " Program verification relies on the construction of auxiliary assertions describing various aspects of program behaviour, e.g., inductive invariants, resource bounds, and interpolants for characterizing reachable program states, ranking functions for approximating number of execution steps until program termination, or recurrence sets for demonstrating non-termination. Recent advances in the development of constraint solving tools offer an unprecedented opportunity for the efficient automation of this task. This paper presents a series of examples illustrating algorithms for the automatic construction of such auxiliary assertions by utilizing constraint solvers as the basic computing machinery.", "num_citations": "19\n", "authors": ["667"]}
{"title": "Distributed and predictable software model checking\n", "abstract": " We present a predicate abstraction and refinement-based algorithm for software verification that is designed for the distributed execution on compute nodes that communicate via message passing, as found in today\u2019s compute clusters. A successful adaptation of predicate abstraction and refinement from sequential to distributed setting needs to address challenges imposed by the inherent non-determinism present in distributed computing environments. In fact, our experiments show that up to an order of magnitude variation of the running time is common when a naive distribution scheme is applied, often resulting in significantly worse running time than the non-distributed version. We present an algorithm that overcomes this pitfall by making deterministic the counterexample selection in spite of the distribution, and still efficiently exploits distributed computational resources. We demonstrate that our\u00a0\u2026", "num_citations": "17\n", "authors": ["667"]}
{"title": "Threader: a verifier for multi-threaded programs\n", "abstract": " Threader is a tool that automates verification of safety and termination properties for multi-threaded C programs. The distinguishing feature of Threader is its use of reasoning that is compositional with regards to the thread structure of the verified program. This paper describes the verification approach taken by Threader and provides instructions on how to install and use the tool.", "num_citations": "15\n", "authors": ["667"]}
{"title": "Cardinality abstraction for declarative networking applications\n", "abstract": " Declarative Networking is a recent, viable approach to make distributed programming easier, which is becoming increasingly popular in systems and networking community. It offers the programmer a declarative, rule-based language, called P2, for writing distributed applications in an abstract, yet expressive way. This approach, however, imposes new challenges on analysis and verification methods when they are applied to P2 programs. Reasoning about P2 computations is beyond the scope of existing tools since it requires handling of program states defined in terms of collections of relations, which store the application data, together with multisets of tuples, which represent communication events in-flight. In this paper, we propose a cardinality abstraction technique that can be used to analyze and verify P2 programs. It keeps track of the size of relations (together with projections thereof) and multisets\u00a0\u2026", "num_citations": "15\n", "authors": ["667"]}
{"title": "Aligators for arrays (tool paper)\n", "abstract": " This paper presents Aligators, a tool for the generation of universally quantified array invariants. Aligators leverages recurrence solving and algebraic techniques to carry out inductive reasoning over array content. The Aligators\u2019 loop extraction module allows treatment of multi-path loops by exploiting their commutativity and serializability properties. Our experience in applying Aligators on a collection of loops from open source software projects indicates the applicability of recurrence and algebraic solving techniques for reasoning about arrays.", "num_citations": "14\n", "authors": ["667"]}
{"title": "A multi-modal framework for achieving accountability in multi-agent systems\n", "abstract": " We present a multi-modal, model-theoretic framework for achieving accountability in multi-agent systems through formal proof. Our framework provides modalities for knowledge, provability, and time. With these modalities, we formalise the two main aspects of accountability, which are: soundness (accountability proper), ie, for correct agents, the provability of their correctness by themselves; and completeness (auditability), ie, for faulty agents, the eventual provability of their faultiness by others. In our framework, the accountability proof of a particular system is reduced to the proof of a few key lemmata, which the system designer needs to establish for a considered system.", "num_citations": "14\n", "authors": ["667"]}
{"title": "Temporal verification with transition invariants\n", "abstract": " Program verification increases the degree of confidence that a program will perform correctly. Manual verification is an error-prone and tedious task. Its automation is highly desirable. The verification methodology reduces the reasoning about temporal properties of program computations to testing the validity of implication between auxiliary first-order assertions. The synthesis of such auxiliary assertions is the main challenge for automated tools. There already exist successful tools for the verification of safety properties. These properties require that some \"bad'; states never appear during program computations. The tools construct invariants, which are auxiliary assertions for safety. Invariants are computed symbolically by applying techniques of abstract interpretation. Liveness properties require that some \"good'; states will eventually appear in every computation. The synthesis of auxiliary assertions for the verification of liveness properties is the next challenge for automated verification tools. This dissertation argues that transition invariants can provide a new basis for the development of automated methods for the verification of liveness properties. We support this thesis as follows. We introduce a new notion of auxiliary assertions called transition invariant. We apply this notion to propose a proof rule for the verification of liveness properties. We provide a viable approach for the automated synthesis of transition invariants by abstract interpretation, which automates the proof rule. For this purpose, we introduce a transition predicate abstraction. This abstraction does not have an inherent limitation to preserve only safety properties. Most liveness\u00a0\u2026", "num_citations": "14\n", "authors": ["667"]}
{"title": "Fast bgp simulation of large datacenters\n", "abstract": " Frequent configuration churn caused by maintenance, upgrades, hardware and firmware failures regularly leads to costly outages. Preventing network outages caused by misconfigurations is important for ensuring high network availability. Dealing with production datacenters with thousands of routers is a major challenge. Network verification inspects the forwarding tables of routers. These tables are determined by the so-called control plane, which is given by the steady state of the routing protocols. The ability to simulate routing protocols given router configuration files and thus obtain the control plane is a key enabling technology. In this paper, we present FastPlane, an efficient BGP simulator. BGP support is mandated by modern datacenter designs, which choose BGP as the routing protocol. The key to FastPlane\u2019s performance is our insight into the routing policy of cloud datacenters that allows the usage of a\u00a0\u2026", "num_citations": "13\n", "authors": ["667"]}
{"title": "Reduction for compositional verification of multi-threaded programs\n", "abstract": " Automated verification of multi-threaded programs requires keeping track of a very large number of possible interactions between the program threads. Different reasoning methods have been proposed that alleviate the explicit enumeration of all thread interleavings, e.g., Lipton's theory of reduction or Owicki-Gries method for compositional reasoning, however their synergistic interplay has not yet been fully explored. In this paper we explore the applicability of the theory of reduction for pruning of equivalent interleavings for the automated verification of multi-threaded programs with infinite-state spaces. We propose proof rules for safety and termination of multi-threaded programs that integrate into an Owicki-Gries based compositional verifier. The verification conditions of our method are Horn clauses, thus facilitating automation by using off-the-shelf Horn clause solvers. We present preliminary experimental results\u00a0\u2026", "num_citations": "11\n", "authors": ["667"]}
{"title": "SL-COMP: Competition of solvers for separation logic\n", "abstract": " SL-COMP aims at bringing together researchers interested on improving the state of the art of the automated deduction methods for Separation Logic (SL). The event took place twice until now and collected more than 1K problems for different fragments of SL. The input format of problems is based on the SMT-LIB format and therefore fully typed; only one new command is added to SMT-LIB's list, the command for the declaration of the heap's type. The SMT-LIB theory of SL comes with ten logics, some of them being combinations of SL with linear arithmetics. The competition's divisions are defined by the logic fragment, the kind of decision problem (satisfiability or entailment) and the presence of quantifiers. Until now, SL-COMP has been run on the StarExec platform, where the benchmark set and the binaries of participant solvers are freely available. The benchmark set is also available with the competition's documentation on a public repository in GitHub.", "num_citations": "10\n", "authors": ["667"]}
{"title": "Symbolic polytopes for quantitative interpolation and verification\n", "abstract": " Proving quantitative properties of programs, such as bounds on resource usage or information leakage, often leads to verification conditions that involve cardinalities of sets. Existing approaches for dealing with such verification conditions operate by checking cardinality bounds for given formulas. However, they cannot synthesize formulas that satisfy given cardinality constraints, which limits their applicability for inferring cardinality-based inductive arguments.                 In this paper we present an algorithm for synthesizing formulas for given cardinality constraints, which relies on the theory of counting integer points in symbolic polytopes. We cast our algorithm in terms of a cardinality-constrained interpolation procedure, which we put to work in a solver for recursive Horn clauses with cardinality constraints based on abstraction refinement. We implement our technique and describe its evaluation on a number\u00a0\u2026", "num_citations": "9\n", "authors": ["667"]}
{"title": "Automation of quantitative information-flow analysis\n", "abstract": " Quantitative information-flow analysis (QIF) is an emerging technique for establishing information-theoretic confidentiality properties. Automation of QIF is an important step towards ensuring its practical applicability, since manual reasoning about program security has been shown to be a tedious and expensive task. In this chapter we describe a approximation and randomization techniques to bear on the challenge of sufficiently precise, yet efficient computation of quantitative information flow properties.", "num_citations": "9\n", "authors": ["667"]}
{"title": "Binary reachability analysis of higher order functional programs\n", "abstract": " A number of recent approaches for proving program termination rely on transition invariants - a termination argument that can be constructed incrementally using abstract interpretation. These approaches use binary reachability analysis to check if a candidate transition invariant holds for a given program. For imperative programs, its efficient implementation can be obtained by a reduction to reachability analysis, for which practical tools are available. In this paper, we show how a binary reachability analysis can be put to work for proving termination of higher order functional programs.", "num_citations": "8\n", "authors": ["667"]}
{"title": "A model checker based on abstraction refinement\n", "abstract": " Abstraction plays an important role for verification of computer programs. We want to construct the right abstraction automatically. There is a promising approach to do it, called {\\it predicate abstraction}. An insufficiently precise abstraction can be {\\it automatically refined}. There is an automated model checking method described in [Ball, Podelski, Rajamani TACAS02] which combines both techniques, eg, predicate abstraction and abstraction refinement. The quality of the method is expressed by a completeness property relative to a powerful but unrealistic oracle-guided algorithm.\\par In this work we want to generalize the results from [Ball, Podelski, Rajamani TACAS02] and introduce new abstraction functions with different precision. We implement the new abstraction functions in a model checker and practically evaluate their effectiveness in verifying various computer programs.", "num_citations": "7\n", "authors": ["667"]}
{"title": "Cardinalities and universal quantifiers for verifying parameterized systems\n", "abstract": " Parallel and distributed systems rely on intricate protocols to manage shared resources and synchronize, ie, to manage how many processes are in a particular state. Effective verification of such systems requires universally quantification to reason about parameterized state and cardinalities tracking sets of processes, messages, failures to adequately capture protocol logic. In this paper we present# \u03a0, an automatic invariant synthesis method that integrates cardinalitybased reasoning and universal quantification. The resulting increase of expressiveness allows# \u03a0 to verify, for the first time, a representative collection of intricate parameterized protocols.", "num_citations": "6\n", "authors": ["667"]}
{"title": "Recursive games for compositional program synthesis\n", "abstract": " Compositionality, i.e., the use of procedure summarization instead of code inlining, is key to scaling automated verification to large code bases. In this paper, we present a way to exploit compositionality in the context of program synthesis.               The goal in our synthesis problem is to instantiate missing expressions in a procedural program so that the resulting program satisfies a safety or termination requirement in spite of an adversarial environment. The problem is modeled as a game between two players \u2014 the program and the environment \u2014 that take turns changing the program\u2019s state and stack. The objective of the program is to ensure that all executions of this recursive game satisfy the requirement. Synthesis involves the modular computation of a strategy under which the program meets this objective. Our solution is based on the notion of game summaries, which generalize traditional procedure\u00a0\u2026", "num_citations": "6\n", "authors": ["667"]}
{"title": "An epistemic perspective on consistency of concurrent computations\n", "abstract": " Consistency properties of concurrent computations, e.g., sequential consistency, linearizability, or eventual consistency, are essential for devising correct concurrent algorithms. In this paper, we present a logical formalization of such consistency properties that is based on a standard logic of knowledge. Our formalization provides a declarative perspective on what is imposed by consistency requirements and provides some interesting unifying insight on differently looking properties.", "num_citations": "6\n", "authors": ["667"]}
{"title": "Efficient CTL verification via horn constraints solving\n", "abstract": " The use of temporal logics has long been recognised as a fundamental approach to the formal specification and verification of reactive systems. In this paper, we take on the problem of automatically verifying a temporal property, given by a CTL formula, for a given (possibly infinite-state) program. We propose a method based on encoding the problem as a set of Horn constraints. The method takes a program, modeled as a transition system, and a property given by a CTL formula as input. It first generates a set of forall-exists quantified Horn constraints and well-foundedness constraints by exploiting the syntactic structure of the CTL formula. Then, the generated set of constraints are solved by applying an off-the-shelf Horn constraints solving engine. The program is said to satisfy the property if and only if the generated set of constraints has a solution. We demonstrate the practical promises of the method by applying it on a set of challenging examples. Although our method is based on a generic Horn constraint solving engine, it is able to outperform state-of-art methods specialised for CTL verification.", "num_citations": "4\n", "authors": ["667"]}
{"title": "Generalised interpolation by solving recursion-free Horn clauses\n", "abstract": " In this paper we present InterHorn, a solver for recursion-free Horn clauses. The main application domain of InterHorn lies in solving interpolation problems arising in software verification. We show how a range of interpolation problems, including path, transition, nested, state/transition and well-founded interpolation can be handled directly by InterHorn. By detailing these interpolation problems and their Horn clause representations, we hope to encourage the emergence of a common back-end interpolation interface useful for diverse verification tools.", "num_citations": "4\n", "authors": ["667"]}
{"title": "Formal verification of distributed algorithms (dagstuhl seminar 13141)\n", "abstract": " The Dagstuhl Seminar 13141\" Formal Verification of Distributed Algorithms\" brought together researchers from the areas of distributed algorithms, model checking, and semi-automated proofs with the goal to establish a common base for approaching the many open problems in verification of distributed algorithms. In order to tighten the gap between the involved communities, who have been quite separated in the past, the program contained tutorials on the basics of the concerned fields. In addition to technical talks, we also had several discussion sessions, whose goal was to identify the most pressing research challenges. This report describes the program and the outcomes of the seminar.", "num_citations": "3\n", "authors": ["667"]}
{"title": "Non-monotonic refinement of control abstraction for concurrent programs\n", "abstract": " Verification based on abstraction refinement is a successful technique for checking program properties. Conventional abstraction refinement schemes increase precision of the abstraction monotonically, and therefore cannot recover from overly precise refinement decisions. This problem is exacerbated in the context of multi-threaded programs, where keeping track of all control locations in concurrent threads is the inevitably discovered abstraction and is prohibitively expensive. In contrast to the conventional (partition refinement-based) approaches, non-monotonic abstraction refinement schemes rely on re-partitioning and have promising potential for avoiding excess of precision. In this paper, we propose a non-monotonic refinement scheme for the control abstraction (of concurrent programs). Our approach employs a constraint solver to discover re-partitioning at each refinement step. An experimental\u00a0\u2026", "num_citations": "2\n", "authors": ["667"]}
{"title": "Towards automatic synthesis of software verification tools\n", "abstract": " Automatically generated tools can significantly improve programmer productivity. For example, parsers can be automatically generated from declarative specifications in form of grammars, which tremendously simplifies the task of implementing a compiler. In this talk, we present a method for the automatic synthesis of software verification tools. Our synthesis procedure takes as input a description of the employed proof rule, eg, program safety checking via inductive invariants, and produces a tool that automatically discovers the auxiliary assertions required by the proof rule, eg, inductive loop invariants and procedure summaries. We rely on a (standard) representation of proof rules using recursive equations over the auxiliary assertions. The discovery of auxiliary assertions, ie, solving the equations, is based on an iterative process that extrapolates solutions obtained for finitary unrollings of equations. We show how\u00a0\u2026", "num_citations": "1\n", "authors": ["667"]}
{"title": "Computer Science-Theory and Applications: Fourth International Computer Science Symposium in Russia, CSR 2009, Novosibirsk, Russia, August 18-23, 2009, Proceedings\n", "abstract": " This book constitutes the refereed proceedings of the Fourth International Computer Science Symposium in Russia, CSR 2009, held in Novosibirsk, Russia, August 18-23, 2009. The 29 revised papers presented together with 4 invited papers were carefully reviewed and selected from 66 submissions. All major areas in computer science are addressed. The theory track deals with algorithms, protocols, and data structures; complexity and cryptography; formal languages, automata and their applications to computer science; computational models and concepts; proof theory and applications of logic to computer science.", "num_citations": "1\n", "authors": ["667"]}
{"title": "Verification, Model Checking, and Abstract Interpretation\n", "abstract": " This volume contains the papers presented at VMCAI 2007: Verification, Model Checking and Abstract Interpretation held January 14\u201316, 2007 in Nice. VMCAI provides a forum for researchers from the communities of verification, model checking, and abstract interpretation, facilitating interaction, cross-fertilization, and advancement of hybrid methods that combine the three areas. This years VMCAI was held in conjunction with POPL, allowing further cross-fertilization between programming language research and the areas covered by VMCAI. There were 85 submissions to VMCAI 2007. Each submission was reviewed by at least three Program Committee members. The committee decided to accept 21 papers. The program also includes invited talks by Tom Reps, Moshe Vardi, and Hongseok Yang and tutorials by Ken McMillan, Madhusudan Parthasarathy, and Peter Revesz.", "num_citations": "1\n", "authors": ["667"]}