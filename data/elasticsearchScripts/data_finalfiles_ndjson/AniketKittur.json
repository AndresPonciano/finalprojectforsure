{"title": "An assessment of intrinsic and extrinsic motivation on task performance in crowdsourcing markets\n", "abstract": " Crowdsourced labor markets represent a powerful new paradigm for accomplishing work. Understanding the motivating factors that lead to high quality work could have significant benefits. However, researchers have so far found that motivating factors such as increased monetary reward generally increase workers\u2019 willingness to accept a task or the speed at which a task is completed, but do not improve the quality of the work. We hypothesize that factors that increase the intrinsic motivation of a task\u2013such as framing a task as helping others\u2013may succeed in improving output quality where extrinsic motivators such as increased pay do not. In this paper we present an experiment testing this hypothesis along with a novel experimental design that enables controlled experimentation with intrinsic and extrinsic motivators in Amazon\u2019s Mechanical Turk, a popular crowdsourcing task market. Results suggest that intrinsic motivation can indeed improve the quality of workers\u2019 output, confirming our hypothesis. Furthermore, we find a synergistic interaction between intrinsic and extrinsic motivators that runs contrary to previous literature suggesting \u201ccrowding out\u201d effects. Our results have significant practical and theoretical implications for crowd work.", "num_citations": "385\n", "authors": ["1196"]}
{"title": "The cognitive atlas: toward a knowledge foundation for cognitive neuroscience\n", "abstract": " Cognitive neuroscience aims to map mental processes onto brain function, which begs the question of what ``mental processes'' exist and how they relate to the tasks that are used to manipulate and measure them. This topic has been addressed informally in prior work, but we propose that cumulative progress in cognitive neuroscience requires a more systematic approach to representing the mental entities that are being mapped to brain function and the tasks used to manipulate and measure mental processes. We describe a new open collaborative project that aims to provide a knowledge base for cognitive neuroscience, called the Cognitive Atlas (accessible online at http://www.cognitiveatlas.org), and outline how this project has the potential to drive novel discoveries about both mind and brain.", "num_citations": "263\n", "authors": ["1196"]}
{"title": "Don't bite the newbies: how reverts affect the quantity and quality of Wikipedia work\n", "abstract": " Reverts are important to maintaining the quality of Wikipedia. They fix mistakes, repair vandalism, and help enforce policy. However, reverts can also be damaging, especially to the aspiring editor whose work they destroy. In this research we analyze 400,000 Wikipedia revisions to understand the effect that reverts had on editors. We seek to understand the extent to which they demotivate users, reducing the workforce of contributors, versus the extent to which they help users improve as encyclopedia editors. Overall we find that reverts are powerfully demotivating, but that their net influence is that more quality work is done in Wikipedia as a result of reverts than is lost by chasing editors away. However, we identify key conditions--most specifically new editors being reverted by much more experienced editors-under which reverts are particularly damaging. We propose that reducing the damage from reverts might be\u00a0\u2026", "num_citations": "232\n", "authors": ["1196"]}
{"title": "Instrumenting the crowd: using implicit behavioral measures to predict task performance\n", "abstract": " Detecting and correcting low quality submissions in crowdsourcing tasks is an important challenge. Prior work has primarily focused on worker outcomes or reputation, using approaches such as agreement across workers or with a gold standard to evaluate quality. We propose an alternative and complementary technique that focuses on the way workers work rather than the products they produce. Our technique captures behavioral traces from online crowd workers and uses them to predict outcome measures such quality, errors, and the likelihood of cheating. We evaluate the effectiveness of the approach across three contexts including classification, generation, and comprehension tasks. The results indicate that we can build predictive models of task performance based on behavioral traces alone, and that these models generalize to related tasks. Finally, we discuss limitations and extensions of the approach.", "num_citations": "196\n", "authors": ["1196"]}
{"title": "Crowdsourcing, collaboration and creativity\n", "abstract": " While many organizations turn to human computation labor markets for jobs with black-or-white solutions, there is vast potential in asking these workers for original thought and innovation.", "num_citations": "187\n", "authors": ["1196"]}
{"title": "The polymath project: lessons from a successful online collaboration in mathematics\n", "abstract": " Although science is becoming increasingly collaborative, there are remarkably few success stories of online collaborations between professional scientists that actually result in real discoveries. A notable exception is the Polymath Project, a group of mathematicians who collaborate online to solve open mathematics problems. We provide an in-depth descriptive history of Polymath, using data analysis and visualization to elucidate the principles that led to its success, and the difficulties that must be addressed before the project can be scaled up. We find that although a small percentage of users created most of the content, almost all users nevertheless contributed some content that was highly influential to the task at hand. We also find that leadership played an important role in the success of the project. Based on our analysis, we present a set of design suggestions for how future collaborative mathematics sites can\u00a0\u2026", "num_citations": "115\n", "authors": ["1196"]}
{"title": "CrowdScape: interactively visualizing user behavior and output\n", "abstract": " Crowdsourcing has become a powerful paradigm for accomplishing work quickly and at scale, but involves significant challenges in quality control. Researchers have developed algorithmic quality control approaches based on either worker outputs (such as gold standards or worker agreement) or worker behavior (such as task fingerprinting), but each approach has serious limitations, especially for complex or creative work. Human evaluation addresses these limitations but does not scale well with increasing numbers of workers. We present CrowdScape, a system that supports the human evaluation of complex crowd work through interactive visualization and mixed initiative machine learning. The system combines information about worker behavior with worker outputs, helping users to better understand and harness the crowd. We describe the system and discuss its utility through grounded case studies. We\u00a0\u2026", "num_citations": "104\n", "authors": ["1196"]}
{"title": "Kinetica: Naturalistic multi-touch data visualization\n", "abstract": " Over the last several years there has been an explosion of powerful, affordable, multi-touch devices. This provides an outstanding opportunity for novel data visualization techniques that leverage new interaction methods and minimize their barriers to entry. In this paper we describe an approach for multivariate data visualization that uses physics-based affordances that are easy to intuit, constraints that are easy to apply and visualize, and a consistent view as data is manipulated in order to promote data exploration and interrogation. We provide a framework for exploring this problem space, and an example proof of concept system called Kinetica. We describe the results of a user study that suggest users of Kinetica were able to explore multiple dimensions of data at once, identify outliers, and discover trends with minimal training.", "num_citations": "90\n", "authors": ["1196"]}
{"title": "A Solution to the Binding Problem for Compositional Connectionism.\n", "abstract": " Achieving compositional connectionism means finding a way to represent role-filler bindings in a connectionist system without sacrificing role-filler independence. Role-filler binding schemes based on varieties of conjunctive coding (the most common approach in the connectionist literature) fail to preserve role-filler independence. At the same time, dynamic binding of roles to fillers (eg, by synchrony of firing) represents bindings without sacrificing independence, but is inadequate for storing bindings in long-term memory. An appropriate combination of dynamic binding (for representation in working memory) and conjunctive coding (for long-term storage and token formation) provides a platform for compositional connectionism, and has proven successful in simulating numerous aspects of human perception and cognition.", "num_citations": "71\n", "authors": ["1196"]}
{"title": "Distributed sensemaking: improving sensemaking by leveraging the efforts of previous users\n", "abstract": " We examine the possibility of distributed sensemaking: improving a user's sensemaking by leveraging previous users' work without those users directly collaborating or even knowing one another. We asked users to engage in sensemaking by organizing and annotating web search results into\" knowledge maps,\" either with or without previous users' maps to work from. We also recorded gaze patterns as users examined others' knowledge maps. Our findings show the conditions under which distributed sensemaking can improve sensemaking quality; that a user's sensemaking process is readily apparent to a subsequent user via a knowledge map; and that the organization of content was more useful to subsequent users than the content itself, especially when those users had differing goals. We discuss the role distributed sensemaking can play in schema induction by helping users make a mental model of an\u00a0\u2026", "num_citations": "63\n", "authors": ["1196"]}
{"title": "The Knowledge Accelerator: Big picture thinking in small pieces\n", "abstract": " Crowdsourcing offers a powerful new paradigm for online work. However, real world tasks are often interdependent, requiring a big picture view of the difference pieces involved. Existing crowdsourcing approaches that support such tasks--ranging from Wikipedia to flash teams--are bottlenecked by relying on a small number of individuals to maintain the big picture. In this paper, we explore the idea that a computational system can scaffold an emerging interdependent, big picture view entirely through the small contributions of individuals, each of whom sees only a part of the whole. To investigate the viability, strengths, and weaknesses of this approach we instantiate the idea in a prototype system for accomplishing distributed information synthesis and evaluate its output across a variety of topics. We also contribute a set of design patterns that may be informative for other systems aimed at supporting big picture\u00a0\u2026", "num_citations": "56\n", "authors": ["1196"]}
{"title": "Accelerating innovation through analogy mining\n", "abstract": " The availability of large idea repositories (eg, the US patent database) could significantly accelerate innovation and discovery by providing people with inspiration from solutions to analogous problems. However, finding useful analogies in these large, messy, real-world repositories remains a persistent challenge for either human or automated methods. Previous approaches include costly hand-created databases that have high relational structure (eg, predicate calculus representations) but are very sparse. Simpler machine-learning/information-retrieval similarity metrics can scale to large, natural-language datasets, but struggle to account for structural similarity, which is central to analogy. In this paper we explore the viability and value of learning simpler structural representations, specifically,\" problem schemas\", which specify the purpose of a product and the mechanisms by which it achieves that purpose. Our\u00a0\u2026", "num_citations": "48\n", "authors": ["1196"]}
{"title": "Alloy: Clustering with crowds and computation\n", "abstract": " Crowdsourced clustering approaches present a promising way to harness deep semantic knowledge for clustering complex information. However, existing approaches have difficulties supporting the global context needed for workers to generate meaningful categories, and are costly because all items require human judgments. We introduce Alloy, a hybrid approach that combines the richness of human judgments with the power of machine algorithms. Alloy supports greater global context through a new\" sample and search\" crowd pattern which changes the crowd's task from classifying a fixed subset of items to actively sampling and querying the entire dataset. It also improves efficiency through a two phase process in which crowds provide examples to help a machine cluster the head of the distribution, then classify low-confidence examples in the tail. To accomplish this, Alloy introduces a modular\" cast and\u00a0\u2026", "num_citations": "43\n", "authors": ["1196"]}
{"title": "Solvent: A mixed initiative system for finding analogies between research papers\n", "abstract": " Scientific discoveries are often driven by finding analogies in distant domains, but the growing number of papers makes it difficult to find relevant ideas in a single discipline, let alone distant analogies in other domains. To provide computational support for finding analogies across domains, we introduce SOLVENT, a mixed-initiative system where humans annotate aspects of research papers that denote their background (the high-level problems being addressed), purpose (the specific problems being addressed), mechanism (how they achieved their purpose), and findings (what they learned/achieved), and a computational model constructs a semantic representation from these annotations that can be used to find analogies among the research papers. We demonstrate that this system finds more analogies than baseline information-retrieval approaches; that annotators and annotations can generalize beyond\u00a0\u2026", "num_citations": "41\n", "authors": ["1196"]}
{"title": "TopicViz: Interactive topic exploration in document collections\n", "abstract": " Existing methods for searching and exploring large document collections focus on surface-level matches to user queries, ignoring higher-level semantic structure. In this paper we show how topic modeling-a technique for identifying latent themes across a large collection of documents-can support semantic exploration. We present TopicViz: an interactive environment which combines traditional search and citation-graph exploration with a force-directed layout that links documents to the latent themes discovered by the topic model. We describe usage scenarios in which TopicViz supports rapid sensemaking on large document collections.", "num_citations": "33\n", "authors": ["1196"]}
{"title": "Analogy mining for specific design needs\n", "abstract": " Finding analogical inspirations in distant domains is a powerful way of solving problems. However, as the number of inspirations that could be matched and the dimensions on which that matching could occur grow, it becomes challenging for designers to find inspirations relevant to their needs. Furthermore, designers are often interested in exploring specific aspects of a product--for example, one designer might be interested in improving the brewing capability of an outdoor coffee maker, while another might wish to optimize for portability. In this paper we introduce a novel system for targeting analogical search for specific needs. Specifically, we contribute an analogical search engine for expressing and abstracting specific design needs that returns more distant yet relevant inspirations than alternate approaches.", "num_citations": "31\n", "authors": ["1196"]}
{"title": "Costs and benefits of structured information foraging\n", "abstract": " People spend an enormous amount of time searching for and saving information online. Existing tools capture only a small portion of the cognitive processing a user engages in while making sense of a new domain. In this paper we introduce a novel interface for capturing online information in a structured but lightweight way. We use this interface as a platform to experimentally characterize the costs and benefits of structuring information during the sensemaking process. Our results contribute empirical knowledge relevant to theories of information seeking and sensemaking, and practical implications for the development of tools to capture and share online information.", "num_citations": "30\n", "authors": ["1196"]}
{"title": "SearchLens: Composing and capturing complex user interests for exploratory search\n", "abstract": " Whether figuring out where to eat in an unfamiliar city or deciding which apartment to live in, consumer generated data (ie reviews and forum posts) are often an important influence in online decision making. To make sense of these rich repositories of diverse opinions, searchers need to sift through a large number of reviews to characterize each item based on aspects that they care about. We introduce a novel system, SearchLens, where searchers build up a collection of\" Lenses\" that reflect their different latent interests, and compose the Lenses to find relevant items across different contexts. Based on the Lenses, SearchLens generates personalized interfaces with visual explanations that promotes transparency and enables deeper exploration. While prior work found searchers may not wish to put in effort specifying their goals without immediate and sufficient benefits, results from a controlled lab study suggest\u00a0\u2026", "num_citations": "29\n", "authors": ["1196"]}
{"title": "Crowdlines: Supporting synthesis of diverse information sources through crowdsourced outlines\n", "abstract": " Learning about a new area of knowledge is challenging for novices partly because they are not yet aware of which topics are most important. The Internet contains a wealth of information for learning the underlying structure of a domain, but relevant sources often have diverse structures and emphases, making it hard to discern what is widely considered essential knowledge vs. what is idiosyncratic. Crowdsourcing offers a potential solution because humans are skilled at evaluating high-level structure, but most crowd micro-tasks provide limited context and time. To address these challenges, we present Crowdlines, a system that uses crowdsourcing to help people synthesize diverse online information. Crowdworkers make connections across sources to produce a rich outline that surfaces diverse perspectives within important topics. We evaluate Crowdlines with two experiments. The first experiment shows that a high context, low structure interface helps crowdworkers perform faster, higher quality synthesis, while the second experiment shows that a tournament-style (parallelized) crowd workflow produces faster, higher quality, more diverse outlines than a linear (serial/iterative) workflow.", "num_citations": "29\n", "authors": ["1196"]}
{"title": "Standing on the schemas of giants: socially augmented information foraging\n", "abstract": " People spend an enormous amount of time searching for complex information online; for example, consumers researching new purchases or patients learning about their conditions. As they search, people build up rich mental schemas about their target domains; which, if effectively shared, could accelerate learning for others with similar interests. In this paper we introduce a novel approach for integrating the schemas individuals develop as they gather information online and surfacing them for others with similar interests. Through a controlled experiment we show that having access to others' schemas while foraging for information helps new users to induce more useful, prototypical, and better-structured schemas than gathering information alone.", "num_citations": "28\n", "authors": ["1196"]}
{"title": "Questimator: Generating knowledge assessments for arbitrary topics\n", "abstract": " Formative assessments allow learners to quickly identify knowledge gaps. In traditional educational settings, expert instructors can create assessments, but in informal learning environments, it is difficult for novice learners to self assess because they don\u2019t know what they don\u2019t know. This paper introduces Questimator, an automated system that generates multiple-choice assessment questions for any topic contained within Wikipedia. Given a topic, Questimator traverses the Wikipedia graph to find and rank related topics, and uses article text to form questions, answers and distractor options. In a study with 833 participants from Mechanical Turk, we found that participants\u2019 scores on Questimator-generated quizzes correlated well with their scores on existing online quizzes on topics ranging from philosophy to economics. Also Questimator generates questions with comparable discriminatory power as existing online quizzes. Our results suggest Questimator may be useful for assessing learning in topics for which there is no existing quiz.", "num_citations": "24\n", "authors": ["1196"]}
{"title": "Feature-vs. relation-defined categories: Probab (alistic) ly not the same\n", "abstract": " Relational categories underlie many uniquely human cognitive processes including analogy, problem solving, and scientific discovery. Despite their ubiquity and importance, the field of category learning has focused almost exclusively on categories based on features. Classification of featurebased categories is typically modeled by calculating similarity to stored representations, an approach that successfully models the learning of both probabilistic and deterministic category structures. In contrast, we hypothesize that relational category learning is analogous to schema induction, and relies on finding common relational structures. This hypothesis predicts that relational category acquisition should function well for deterministic categories but suffer catastrophically when faced with probabilistic categories, which contain no constant relations. We report support for this prediction, along with evidence that the schemas induced in the deterministic condition drive categorization of novel and even category-ambiguous exemplars.", "num_citations": "22\n", "authors": ["1196"]}
{"title": "Learning from history: predicting reverted work at the word level in wikipedia\n", "abstract": " Wikipedia's remarkable success in aggregating millions of contributions can pose a challenge for current editors, whose hard work may be reverted unless they understand and follow established norms, policies, and decisions and avoid contentious or proscribed terms. We present a machine learning model for predicting whether a contribution will be reverted based on word level features. Unlike previous models relying on editor-level characteristics, our model can make accurate predictions based only on the words a contribution changes. A key advantage of the model is that it can provide feedback on not only whether a contribution is likely to be rejected, but also the particular words that are likely to be controversial, enabling new forms of intelligent interfaces and visualizations. We examine the performance of the model across a variety of Wikipedia articles.", "num_citations": "19\n", "authors": ["1196"]}
{"title": "Topicviz: Semantic navigation of document collections\n", "abstract": " When people explore and manage information, they think in terms of topics and themes. However, the software that supports information exploration sees text at only the surface level. In this paper we show how topic modeling -- a technique for identifying latent themes across large collections of documents -- can support semantic exploration. We present TopicViz, an interactive environment for information exploration. TopicViz combines traditional search and citation-graph functionality with a range of novel interactive visualizations, centered around a force-directed layout that links documents to the latent themes discovered by the topic model. We describe several use scenarios in which TopicViz supports rapid sensemaking on large document collections.", "num_citations": "19\n", "authors": ["1196"]}
{"title": "Unakite: Scaffolding Developers' Decision-Making Using the Web\n", "abstract": " Developers spend a significant portion of their time searching for solutions and methods online. While numerous tools have been developed to support this exploratory process, in many cases the answers to developers' questions involve trade-offs among multiple valid options and not just a single solution. Through interviews, we discovered that developers express a desire for help with decision-making and understanding trade-offs. Through an analysis of Stack Overflow posts, we observed that many answers describe such trade-offs. These findings suggest that tools designed to help a developer capture information and make decisions about trade-offs can provide crucial benefits for both the developers and others who want to understand their design rationale. In this work, we probe this hypothesis with a prototype system named Unakite that collects, organizes, and keeps track of information about trade-offs and\u00a0\u2026", "num_citations": "17\n", "authors": ["1196"]}
{"title": "Supporting mobile sensemaking through intentionally uncertain highlighting\n", "abstract": " Patients researching medical diagnoses, scientist exploring new fields of literature, and students learning about new domains are all faced with the challenge of capturing information they find for later use. However, saving information is challenging on mobile devices, where the small screen and font sizes combined with the inaccuracy of finger based touch screens makes it time consuming and stressful for people to select and save text for future use. Furthermore, beyond the challenge of simply selecting a region of bounded text on a mobile device, in many learning and data exploration tasks the boundaries of what text may be relevant and useful later are themselves uncertain for the user. In contrast to previous approaches which focused on speeding up the selection process by making the identification of hard boundaries faster, we introduce the idea of intentionally supporting uncertain input in the context of\u00a0\u2026", "num_citations": "14\n", "authors": ["1196"]}
{"title": "Biological citizen publics: Personal genetics as a site of public engagement with science\n", "abstract": " Low-cost genetic sequencing, coupled with novel social media platforms and visualization techniques, present a new frontier for scientific participation, whereby people can learn, share, and act on data embedded within their own bodies. Our study of 23andMe, a popular genetic testing service, reveals how users make sense of and contextualize their genetic results, critique and evaluate the underlying research, and reflect on the broader implications of genetic testing. We frame user groups as citizen science publicsgroups that coalesce around scientific issues and work towards resolving shared concerns. Our findings show that personal genetics serves as a site for public engagement with science, whereby communities of biological citizens creatively interpret, debate, and act on professional research. We conclude with design trajectories at the intersection of genetics and creativity support tools: platforms for\u00a0\u2026", "num_citations": "14\n", "authors": ["1196"]}
{"title": "TouchViz: (multi) touching multivariate data\n", "abstract": " In this paper we describe TouchViz, an information visualization system for tablets that encourages rich interaction, exploration, and play through references to physical models. TouchViz turns data into physical objects that experience forces and respond to the user. We describe the design of the system and conduct a user study to explore its use, finding that it supports many different models of data exploration and encourages users to have fun exploring data.", "num_citations": "14\n", "authors": ["1196"]}
{"title": "Ideals aren't always typical: Dissociating goodness-of-exemplar from typicality judgments\n", "abstract": " Items that are rated good examples of a category have generally been assumed to be highly typical as well. However, most previous studies have used categories defined by simple features in which exemplar goodness and typicality are strongly related. We report a study using categories based on the relationships between features instead of the features themselves, allowing manipulation of relational ideals independent of featural central tendencies. Goodness-of-exemplar (GOE) judgments were based on relational ideals, whereas typicality judgments were based on a mix of ideals and featural central tendencies. These results indicate that exemplar goodness and typicality can lead to two distinct forms of graded category structure, and should not be treated as equivalent.", "num_citations": "14\n", "authors": ["1196"]}
{"title": "Bento Browser: Complex Mobile Search Without Tabs\n", "abstract": " People engaged in complex searches such as planning a vacation or understanding their medical symptoms are often overwhelmed by opening and managing many tabs. These challenges are exacerbated as search moves to smartphones and mobile devices where screen real-estate is limited and tasks are frequently suspended, resumed, and interleaved. Rather than continue to utilize tab-based browsing for complex search, we introduce a new way of browsing through a scaffolded interface. The list of search results serves as a mutable workspace, where a user can track progress on a specific information query. The search query serves as a gateway into this workspace, accessed through a task-subtask hierarchy. We instantiate this in the Bento mobile search system and investigate its effectiveness in three studies. We find converging evidence that users were able to make progress on their complex\u00a0\u2026", "num_citations": "12\n", "authors": ["1196"]}
{"title": "NICE: Social translucence through UI intervention\n", "abstract": " Social production systems such as Wikipedia rely on attracting and motivating volunteer contributions to be successful. One strong demotivating factor can be when an editor's work is discarded, or\" reverted\", by others. In this paper we demonstrate evidence of this effect and design a novel interface aimed at improving communication between the reverting and reverted editors. We deployed the interface in a controlled experiment on the live Wikipedia site, and report on changes in the behavior of 487 contributors who were reverted by editors using our interface. Our results suggest that simple interface modifications (such as informing Wikipedians that the editor they are reverting is a newcomer) can have substantial positive effects in protecting against contribution loss in newcomers and improving the quality of work done by more experienced contributors.", "num_citations": "12\n", "authors": ["1196"]}
{"title": "Using ideal observers in higher-order human category learning\n", "abstract": " Ideal observer models have proven useful in investigating assumptions about human information processing in a variety of perceptual tasks. However, these models have not been applied in the area of higher-order category learning. We describe a simple Bayesian ideal observer and apply it to empirical data on category learning. We describe an experiment in which we found that acquisition of family resemblance categories was drastically impaired if the categories were defined by relations between features rather than by the features themselves. An ideal observer was used to test whether this effect could be accounted for by inherent information differences between the conditions. A comparison of participants\u2019 performance to the model found a significant difference in efficiency of learning even after accounting for information differences between conditions. This analysis illustrates how ideal observer methods can provide useful tools for analyzing higher-order category learning.", "num_citations": "12\n", "authors": ["1196"]}
{"title": "Sensemaking in a Senseless World: 2018 Workshop Abstract\n", "abstract": " Sensemaking is a common activity in the analysis of a large or complex amount of information. This active area of HCI research asks how DO people come to understand such difficult sets of information? The information workplace is increasing dominated by high velocity, high volume, complex information streams. At the same time, understanding how sensemaking operates has become an urgent need in an era of increasingly unreliable news and information sources. While there has been a huge amount of work in this space, the research involved is scattered over a number of different domains with differing approaches. This workshop will focus on the most recent work in sensemaking, the activities, technologies and behaviors that people do when making sense of their complex information spaces. In the second part of the workshop we will work to synthesize a cross-disciplinary view of how sensemaking works\u00a0\u2026", "num_citations": "11\n", "authors": ["1196"]}
{"title": "Methods and software for visualizing data by applying physics-based tools to data objectifications\n", "abstract": " Methods and corresponding software for allowing a user to manipulate and interactively explore data intuitively by objectifying the data and allowing the user to apply any one or more simulated physical tools to the objectified data. The data can be any suitable type of data, including multivariate data and graph (network) data. In some embodiments, the method displays user-selected charts, such as histograms, scattergrams, and network graphs, in which objectified data points, or simulated physical objects, are attracted to their proper charted locations. In some embodiments, the user can apply one or more simulated physical tools and/or other tools, such as physical-barrier-type filter tools (eg, sieves) and/or optical filter lens tools, to the simulated physical objects to filter the data. In some embodiments, the user can apply multiple tools, with each tool leaving a visual trace that allows the user to easily retrace their\u00a0\u2026", "num_citations": "11\n", "authors": ["1196"]}
{"title": "The cognitive atlas: employing interaction design processes to facilitate collaborative ontology creation\n", "abstract": " The Cognitive Atlas is a collaborative knowledge-building project that aims to develop an ontology that characterizes the current conceptual framework among researchers in cognitive science and neuroscience. The project objectives from the beginning focused on usability, simplicity, and utility for end users. Support for Semantic Web technologies was also a priority in order to support interoperability with other neuroscience projects and knowledge bases. Current off-the-shelf semantic web or semantic wiki technologies, however, do not often lend themselves to simple user interaction designs for non-technical researchers and practitioners; the abstract nature and complexity of these systems acts as point of friction for user interaction, inhibiting usability and utility. Instead, we take an alternate interaction design approach driven by user centered design processes rather than a base set of semantic technologies\u00a0\u2026", "num_citations": "9\n", "authors": ["1196"]}
{"title": "Regulating behavior in online communities\n", "abstract": " In thriving communities, a rough consensus eventually emerges about the range of behaviors the managers and most members consider acceptable, what we will call normative behaviors, and another range of behaviors that are beyond the pale. A Rape In Cyberspace, the newspaper report by Julian Dibbell (1993), describes a classic example of unacceptable behavior in LamdaMoo, an early virtual environment. Mr. Bungle, an avatar in the online community, wrote a program that forced two avatars controlled by other participants to have virtual sex with him and with each other, and to do brutal things to their own bodies. In describing the event online the next day, one of the victims begged \u201c\"I am requesting that Mr. Bungle be toaded for raping Starsinger and I [stet],\u201d where \u201ctoad\u201d is the command that would turn Bungle\u2019s avatar into a toad, annihilating the character\u2019s original description and attributes. Within 24 hours, 50 other characters also called for his toading. Three days later the community had a real-time discussion of the issue. An system administrator who observed this discussion eventually ran the toad command to eliminate the Mr. Bungle character. Although LamdaMoo did not have a policy against cyberrape, when one occurred in its midst, this action instigated widespread discussion and crystallized a view among many inhabitants of what were correct and incorrect types of behavior in this community.", "num_citations": "9\n", "authors": ["1196"]}
{"title": "Mesh: Scaffolding Comparison Tables for Online Decision Making\n", "abstract": " While there is an enormous amount of information online for making decisions such as choosing a product, restaurant, or school, it can be costly for users to synthesize that information into confident decisions. Information for users' many different criteria needs to be gathered from many different sources into a structure where they can be compared and contrasted. The usefulness of each criterion for differentiating potential options can be opaque to users, and evidence such as reviews may be subjective and conflicting, requiring users to interpret each under their personal context. We introduce Mesh, which scaffolds users to iteratively build up a better understanding of both their criteria and options by evaluating evidence gathered across sources in the context of consumer decision-making. Mesh bridges the gap between decision support systems that typically have rigid structures and the fluid and dynamic process\u00a0\u2026", "num_citations": "8\n", "authors": ["1196"]}
{"title": "When the Tab Comes Due: Challenges in the Cost Structure of Browser Tab Usage\n", "abstract": " Tabs have become integral to browsing the Web yet have changed little since their introduction nearly 20 years ago. In contrast, the internet has gone through dramatic changes, with users increasingly moving from navigating to websites to exploring information across many sources to support online sensemaking. This paper investigates how tabs today are overloaded with a diverse set of functionalities and issues users face when managing them. We interviewed ten information workers asking about their tab management strategies and walk through each open tab on their work computers four times over two weeks. We uncovered competing pressures pushing for keeping tabs open (ranging from interaction to emotional costs) versus pushing for closing them (such as limited attention and resources). We then surveyed 103 participants to estimate the frequencies of these pressures at scale. Finally, we developed\u00a0\u2026", "num_citations": "4\n", "authors": ["1196"]}
{"title": "Scaling Creative Inspiration with Fine-Grained Functional Facets of Product Ideas\n", "abstract": " Web-scale repositories of products, patents and scientific papers offer an opportunity for creating automated systems that scour millions of ideas and assist users in discovering inspirations and solutions. Yet the common representation of ideas is in the form of raw textual descriptions, lacking important structure that is required for supporting creative innovation. Prior work has pointed to the importance of functional structure -- capturing the mechanisms and purposes of inventions -- for allowing users to discover structural connections across ideas and creatively adapt existing technologies. However, the use of functional representations was either coarse and limited in expressivity, or dependent on curated knowledge bases with poor coverage and significant manual effort from users. To help bridge this gap and unlock the potential of large-scale idea mining, we propose a novel computational representation that automatically breaks up products into fine-grained functional facets. We train a model to extract these facets from a challenging real-world corpus of invention descriptions, and represent each product as a set of facet embeddings. We design similarity metrics that support granular matching between functional facets across ideas, and use them to build a novel functional search capability that enables expressive queries for mechanisms and purposes. We construct a graph capturing hierarchical relations between purposes and mechanisms across an entire corpus of products, and use the graph to help problem-solvers explore the design space around a focal problem and view related problem perspectives. In empirical user studies, our\u00a0\u2026", "num_citations": "4\n", "authors": ["1196"]}
{"title": "Beyond iTunes for Papers: Redefining the Unit of Interaction in Literature Review Tools\n", "abstract": " Conducting an effective literature review is an essential step in all scientific work. However, the process is difficult, particularly for interdisciplinary work. Here, we articulate a key avenue for improvement for literature review tools: supporting the appropriate unit of interaction, which we argue is a\" grounded claim\", a concise statement linked to key contextual details such as evidence. However, there are significant cognitive and interaction costs in creating them. We share insights from our development of a prototype literature review tool, the Knowledge Compressor, that aims to lower these costs.", "num_citations": "4\n", "authors": ["1196"]}
{"title": "Scaling up Analogy with Crowdsourcing and Machine Learning.\n", "abstract": " Despite tremendous advances in computational models of human analogy, a persistent challenge has been scaling up to find useful analogies in large, messy, real-world data. The availability of large idea repositories (eg, the US patent database) could significantly accelerate innovation and discovery in a way never previously possible. Previous approaches have been limited by relying on hand-created databases that have high relational structure but are very sparse (eg, predicate calculus representations). Traditional machine-learning/information-retrieval similarity metrics (eg, LSA) can scale to large, natural-language datasets; however, while these methods are good at detecting surface similarity, they struggle to account for structural similarity. In this paper, we propose to leverage crowdsourcing techniques to construct a dataset with rich \u201canalogy-tuning\u201d signals, used to guide machine learning models towards matches based on relations rather than surface features. We demonstrate our approach with a crowdsourced analogy identification task, whose results are used to train deep learning algorithms. Our initial results suggest that a deep learning model trained on positive/negative example analogies from the task can find more analogous matches than an LSA baseline, and that incorporating behavioral signals (such as queries used to retrieve an analogy) can further boost its performance.", "num_citations": "4\n", "authors": ["1196"]}
{"title": "System and Method of Using Task Fingerprinting to Predict Task Performance\n", "abstract": " A novel method of using task fingerprinting to predict outcome measures such quality, errors, and the likelihood of cheating, particularly as applied to crowd sourced tasks. The technique focuses on the way workers work rather than the products they produce. The technique captures behavioral traces from online crowd workers and uses them to build predictive models of task performance. The effectiveness of the approach is evaluated across three contexts including classification, generation, and comprehension tasks.", "num_citations": "4\n", "authors": ["1196"]}
{"title": "Analogy mining for specific design needs\n", "abstract": " Finding analogical inspirations in distant domains is a powerful way of solving problems. However, as the number of inspirations that could be matched and the dimensions on which that matching could occur grow, it becomes challenging for designers to find inspirations relevant to their needs. Furthermore, designers are often interested in exploring specific aspects of a product-- for example, one designer might be interested in improving the brewing capability of an outdoor coffee maker, while another might wish to optimize for portability. In this paper we introduce a novel system for targeting analogical search for specific needs. Specifically, we contribute a novel analogical search engine for expressing and abstracting specific design needs that returns more distant yet relevant inspirations than alternate approaches.", "num_citations": "3\n", "authors": ["1196"]}
{"title": "Compositional connectionism in cognitive science\n", "abstract": " Simon D. Levy & Ross Gayler (eds.), Compositional Connectionism in Cognitive Science - PhilPapers Sign in | Create an account PhilPapers PhilPeople PhilArchive PhilEvents PhilJobs PhilPapers home Syntax Advanced Search Syntax Advanced Search Syntax Advanced Search Compositional Connectionism in Cognitive Science Simon D. Levy & Ross Gayler (eds.) AAAI Press (2004) Abstract This article has no associated abstract. (fix it) Keywords No keywords specified (fix it) Categories Compositionality in Philosophy of Language (categorize this paper) Buy this book Find it on Amazon.com Options Edit this record Mark as duplicate Export citation Find it on Scholar Request removal from index Translate to english Revision history Download options PhilArchive copy Upload a copy of this paper Check publisher's policy Papers currently archived: 59,916 External links This entry has no external links. Add one. \u2026", "num_citations": "3\n", "authors": ["1196"]}
{"title": "System for Interactively Visualizing and Evaluating User Behavior and Output\n", "abstract": " The present invention discloses CrowdScape, a system that supports the human evaluation of complex crowd work through interactive visualization and mixed initiative machine learning. The system combines information about worker behavior with worker outputs and aggregate worker behavioral traces to allow the isolation of target worker clusters. This approach allows users to develop and test their mental models of tasks and worker behaviors, and then ground those models in worker outputs and majority or gold standard verifications.", "num_citations": "2\n", "authors": ["1196"]}
{"title": "TopicScape: Semantic Navigation of Document Collections\n", "abstract": " When people explore and manage information, they think in terms of topics and themes. However, the software that supports information exploration sees text at only the surface level. In this paper we show how topic modeling--a technique for identifying latent themes across large collections of documents--can support semantic exploration. We present TopicScape, an interactive environment for information exploration. TopicScape combines traditional search and citation-graph functionality with a range of novel interactive visualizations, centered around a force-directed layout that links documents to the latent themes discovered by the topic model. We describe several use scenarios in which TopicScape supports rapid sensemaking on large document collections.", "num_citations": "2\n", "authors": ["1196"]}
{"title": "Retrieval-induced forgetting in a multiple-trace memory model\n", "abstract": " Behavioral studies (eg, Anderson, Bjork, & Bjork, 1994) suggest that competition between relevant and irrelevant memory information is resolved in part through the inhibition of competing irrelevant information, an effect dubbed Retrieval-Induced Forgetting (RIF). Green and Kittur (2004) outlined MNEM, a model of human memory that exhibits many retrieval dynamics observed in empirical studies (eg, spacing and practice effects, forgetting over time, spontaneous recovery, serial position effects), but did not account for RIF. In this paper, we describe a modified version of MNEM that incorporates an inhibitory mechanism and simulates some basic RIF effects. Prior work that implicates a feature-specific inhibitory mechanism provides a context for the model and simulations.", "num_citations": "2\n", "authors": ["1196"]}
{"title": "Methods of Providing a Search-Ecosystem User Interface For Searching Information Using a Software-Based Search Tool and Software for Same\n", "abstract": " Methods of providing a search-ecosystem user interface that assist a user with searching information stored within a computer system and with managing results of the searching. In some embodiments, the methods include providing search-results items in an interactive workspace in which a user can manipulate the search-result items to make review more efficient. In some embodiments, the interactive workspace tracks user interactions with search-result items and visualizes such interaction to the user. In some embodiments, the methods include organizing search results using one or more task cards. In some embodiments, a user can add one or more additional sets of search results to a task card. In some embodiments, a user can share one or more task cards, interactive workspaces, and/or search-results items with one or more other users and allow such other user (s) to interact therewith. Other methods are\u00a0\u2026", "num_citations": "1\n", "authors": ["1196"]}
{"title": "UNAKITE: Support Developers for Capturing and Persisting Design Rationales When Solving Problems Using Web Resources\n", "abstract": " UNAKITE is a new system that supports developers in collecting, organizing, consuming, and persisting design rationales while solving problems using web resources. Understanding design rationale has widely been recognized as significant for the success of a software engineering project. However, it is currently both time and labor intensive for little immediate payoff for a developer to generate and embed a useful design rationale in their code. Under this cost structure, there is very little effective tool support to help developers keep track of design rationales. UNAKITE addresses this challenge for some design decisions by changing the cost structure: developers are incentivized to make decisions using UNAKITE\u2019s collecting and organizing mechanisms as it makes tracking and deciding between alternatives easier than before; the structure thus generated is automatically embedded in the code as the design rationale when the developer copies sample code into their existing code. In a preliminary usability study, developers found UNAKITE to be usable for capturing design rationales and effective for interpreting the rationale of others.", "num_citations": "1\n", "authors": ["1196"]}
{"title": "Biological citizen publics: Personal genetics as a site of scientific literacy and action\n", "abstract": " \u00a9 2015 ACM. Low-cost genetic sequencing, coupled with novel social media platforms and visualization techniques, present a new frontier for scientific participation, whereby people can learn, share, and act on data embedded within their own bodies. Our study of 23andMe, a popular genetic testing service, reveals how users make sense of and contextualize their genetic results, critique and evaluate the underlying research, and reflect on the broader implications of genetic testing. We frame user groups as citizen science publics - groups that coalesce around scientific issues and work towards resolving shared concerns. Our findings show that personal genetics serves as a site for public engagement with science, whereby communities of biological citizens creatively interpret, debate, and act on professional research. We conclude with design trajectories at the intersection of genetics and creativity support tools: platforms for aggregating hybrid knowledge; tools for creative reflection on professional science; and strategies for supporting collaborations across communities.", "num_citations": "1\n", "authors": ["1196"]}
{"title": "A multiple-trace memory model exhibiting realistic retrieval dynamics\n", "abstract": " A process model of human memory dynamics is proposed as an implementation of Kittur, Green, & Bjork\u2019s (2004) mathematical model. Both models are based on an ideal information processing approach, in which an item\u2019s accessibility is based on the predicted future need of that item. The proposed model is an adaptation of the multiple-trace architecture of Hintzman\u2019s MINERVA2 model (Hintzman 1984; 1986; 1988). We present simulations of complex spacing and practice dynamics encompassing the mechanics of Bjork and Bjork\u2019s (1992) New Theory of Disuse, which accounts for diverse phenomena such as massed vs. spaced practice and spontaneous recovery. In addition, we show how the model explains and simulates time-dependent serial position effects (such as the shift from recency to primacy with delay and time-invariant recency effects). The model\u2019s potential as a tool for exploring the relationship between the content of items in memory and more general memory dynamics is also discussed.", "num_citations": "1\n", "authors": ["1196"]}