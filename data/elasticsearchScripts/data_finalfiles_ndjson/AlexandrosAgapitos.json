{"title": "Evolving controllers for simulated car racing using object oriented genetic programming\n", "abstract": " Several different controller representations are compared on anon-trivial problem in simulated car racing, with respect tolearning speed and final fitness. The controller representations arebased either on Neural Networks or Genetic Programming, and alsodiffer in regards to whether they allow for stateful controllers orjust reactive ones. Evolved GP trees are analysed, and attempts aremade at explaining the performance differences observed.", "num_citations": "51\n", "authors": ["1736"]}
{"title": "Learning recursive functions with object oriented genetic programming\n", "abstract": " This paper describes the evolution of recursive functions within an Object-Oriented Genetic Programming (OOGP) system. We evolved general solutions to factorial, Fibonacci, exponentiation, even-n-Parity, and nth-3. We report the computational effort required to evolve these methods and provide a comparison between crossover and mutation variation operators, and also undirected random search. We found that the evolutionary algorithms performed much better than undirected random search, and thats mutation outperformed crossover on most problems.", "num_citations": "43\n", "authors": ["1736"]}
{"title": "Generating diverse opponents with multiobjective evolution\n", "abstract": " For computational intelligence to be useful in creating game agent AI, we need to focus on creating interesting and believable agents rather than just learn to play the games well. To this end, we propose a way to use multiobjective evolutionary algorithms to automatically create populations of non-player characters (NPCs), such as opponents and collaborators, that are interestingly diverse in behaviour space. Experiments are presented where a number of partially conflicting objectives are defined for racing game competitors, and multiobjective evolution of Genetic Programming-based controllers yield pareto fronts of interesting controllers.", "num_citations": "40\n", "authors": ["1736"]}
{"title": "Evolving efficient recursive sorting algorithms\n", "abstract": " Object Oriented Genetic Programming (OOGP) is applied to the task of evolving general recursive sorting algorithms. We studied the effects of language primitives and fitness functions on the success of the evolutionary process. For language primitives, these were the methods of a simple list processing package. Five different fitness functions based on sequence disorder were evaluated. The time complexity of the successfully evolved algorithms was measured experimentally in terms of the number of method invocations made, and for the best evolved individuals this was best approximated as O(n times log(n)). This is the first time that sorting algorithms of this complexity have been evolved.", "num_citations": "39\n", "authors": ["1736"]}
{"title": "Ubiquitous robotics in physical human action recognition: A comparison between dynamic anns and gp\n", "abstract": " Two different classifier representations based on dynamic artificial neural networks (ANNs) and genetic programming (GP) are being compared on a human action recognition task by an ubiquitous mobile robot. The classification methodologies used, process time series generated by an indoor ubiquitous 3D tracker which generates spatial points based on 23 reflectable markers attached on a human body. This investigation focuses mainly on class discrimination of normal and aggressive action recognition performed by an architecture which implements an interconnection between an ubiquitous 3D sensory tracker system and a mobile robot to perceive, process, and classify physical human actions. The 3D tracker and the robot are used as a perception-to-action architecture to process physical activities generated by human subjects. Both classifiers process the activity time series to eventually generate\u00a0\u2026", "num_citations": "33\n", "authors": ["1736"]}
{"title": "An investigation of fitness sharing with semantic and syntactic distance metrics\n", "abstract": " This paper investigates the efficiency of using semantic and syntactic distance metrics in fitness sharing with Genetic Programming (GP). We modify the implementation of fitness sharing to speed up its execution, and used two distance metrics in calculating the distance between individuals in fitness sharing: semantic distance and syntactic distance. We applied fitness sharing with these two distance metrics to a class of real-valued symbolic regression. Experimental results show that using semantic distance in fitness sharing helps to significantly improve the performance of GP more frequently, and results in faster execution times than with the syntactic distance. Moreover, we also analyse the impact of the fitness sharing parameters on GP performance helping to indicate appropriate values for fitness sharing using a semantic distance metric.", "num_citations": "30\n", "authors": ["1736"]}
{"title": "Evolving modular recursive sorting algorithms\n", "abstract": " A fundamental issue in evolutionary learning is the definition of the solution representation language. We present the application of Object Oriented Genetic Programming to the task of coevolving general recursive sorting algorithms along with their primitive representation alphabet. We report the computational effort required to evolve target solutions and provide a comparison between crossover and mutation variation operators, and also undirected random search. We found that the induction of evolved method signatures (typed parameters and return type) can be realized through an evolutionary fitness-driven process. We also found that the evolutionary algorithm outperformed undirected random search, and that mutation performed better than crossover in this problem domain. The main result is that modular sorting algorithms can be evolved.", "num_citations": "24\n", "authors": ["1736"]}
{"title": "Guidelines for defining benchmark problems in genetic programming\n", "abstract": " The field of Genetic Programming has recently seen a surge of attention to the fact that benchmarking and comparison of approaches is often done in non-standard ways, using poorly designed comparison problems. We raise some issues concerning the design of benchmarks, within the domain of symbolic regression, through experimental evidence. A set of guidelines is provided, aiming towards careful definition and use of artificial functions as symbolic regression benchmarks.", "num_citations": "23\n", "authors": ["1736"]}
{"title": "Experiments in program synthesis with grammatical evolution: A focus on integer sorting\n", "abstract": " We present the results of a series of investigations where we apply a form of grammar-based genetic programming to the problem of program synthesis in an attempt to evolve an Integer Sorting algorithm. The results confirm earlier research in the field on the difficulty of the problem given a primitive set of functions and terminals. The inclusion of a swap(i, j) function in combination with a nested for loop in the grammar enabled a successful solution to be found in every run. We suggest some future research directions to overcome the challenge of evolving sorting algorithms from primitive functions and terminals.", "num_citations": "20\n", "authors": ["1736"]}
{"title": "Multiobjective techniques for the use of state in genetic programming applied to simulated car racing\n", "abstract": " Multi-objective optimisation is applied to encourage the effective use of state variables in car controlling programs evolved using Genetic Programming. Three different metrics for measuring the use of state within a program are introduced. Comparisons are performed among multi- and single-objective fitness functions with respect to learning speed and final fitness of evolved individuals, and attempts are made at understanding whether there is a trade-off between good performance and stateful controllers in this problem domain.", "num_citations": "20\n", "authors": ["1736"]}
{"title": "Controlling overfitting in symbolic regression based on a bias/variance error decomposition\n", "abstract": " We consider the fundamental property of generalisation of data-driven models evolved by means of Genetic Programming (GP). The statistical treatment of decomposing the regression error into bias and variance terms provides insight into the generalisation capability of this modelling method. The error decomposition is used as a source of inspiration to design a fitness function that relaxes the sensitivity of an evolved model to a particular training dataset. Results on eight symbolic regression problems show that new method is capable on inducing better-generalising models than standard GP for most of the problems.", "num_citations": "19\n", "authors": ["1736"]}
{"title": "On the genetic programming of time-series predictors for supply chain management\n", "abstract": " Single and multi-step time-series predictors were evolved for forecasting minimum bidding prices in a simulated supply chain management scenario. Evolved programs were allowed to use primitives that facilitate the statistical analysis of historical data. An investigation of the relationships between the use of such primitives and the induction of both accurate and predictive solutions was made, with the statistics calculated based on three input data transformation methods: integral, differential, and rational. Results are presented showing which features work best for both single-step and multi-step predictions.", "num_citations": "19\n", "authors": ["1736"]}
{"title": "A preliminary investigation of overfitting in evolutionary driven model induction: Implications for financial modelling\n", "abstract": " This paper investigates the effects of early stopping as a method to counteract overfitting in evolutionary data modelling using Genetic Programming. Early stopping has been proposed as a method to avoid model overtraining, which has been shown to lead to a significant degradation of out-of-sample performance. If we assume some sort of performance metric maximisation, the most widely used early training stopping criterion is the moment within the learning process that an unbiased estimate of the performance of the model begins to decrease after a strictly monotonic increase through the earlier learning iterations. We are conducting an initial investigation on the effects of early stopping in the performance of Genetic Programming in symbolic regression and financial modelling. Empirical results suggest that early stopping using the above criterion increases the extrapolation abilities of symbolic\u00a0\u2026", "num_citations": "18\n", "authors": ["1736"]}
{"title": "Evolutionary learning of technical trading rules without data-mining bias\n", "abstract": " In this paper we investigate the profitability of evolved technical trading rules when controlling for data-mining bias. For the first time in the evolutionary computation literature, a comprehensive test for a rule\u2019s statistical significance using Hansen\u2019s Superior Predictive Ability is explicitly taken into account in the fitness function, and multi-objective evolutionary optimisation is employed to drive the search towards individual rules with better generalisation abilities. Empirical results on a spot foreign-exchange market index suggest that increased out-of-sample performance can be obtained after accounting for data-mining bias effects in a multi-objective fitness function, as compared to a single-criterion fitness measure that considers solely the average return.", "num_citations": "18\n", "authors": ["1736"]}
{"title": "Comparing the performance of the evolvable \u03c0Grammatical Evolution genotype-phenotype map to Grammatical Evolution in the dynamic Ms. Pac-Man environment\n", "abstract": " In this work, we examine the capabilities of two forms of mappings by means of Grammatical Evolution (GE) to successfully generate controllers by combining high-level functions in a dynamic environment. In this work we adopted the Ms. Pac-Man game as a benchmark test bed. We show that the standard GE mapping and Position Independent GE (\u03c0GE) mapping achieve similar performance in terms of maximising the score. We also show that the controllers produced by both approaches have an overall better performance in terms of maximising the score compared to a hand-coded agent. There are, however, significant differences in the controllers produced by these two approaches: standard GE produces more controllers with invalid code, whereas the opposite is seen with \u03c0GE.", "num_citations": "17\n", "authors": ["1736"]}
{"title": "Understanding grammatical evolution: Grammar design\n", "abstract": " A frequently overlooked consideration when using Grammatical Evolution (GE) is grammar design. This is because there is an infinite number of grammars that can specify the same syntax. There are, however, certain aspects of grammar design that greatly affect the speed of convergence and quality of solutions generated with GE. In this chapter, general guidelines for grammar design are presented. These are domain-independent, and can be used when applying GE to any problem. An extensive analysis of their effect and results across a large set of experiments are reported.", "num_citations": "15\n", "authors": ["1736"]}
{"title": "Deep evolution of image representations for handwritten digit recognition\n", "abstract": " A training protocol for learning deep neural networks, called greedy layer-wise training, is applied to the evolution of a hierarchical, feed-forward Genetic Programming based system for feature construction and object recognition. Results on a popular handwritten digit recognition benchmark clearly demonstrate that two layers of feature transformations improves generalisation compared to a single layer. In addition, we show that the proposed system outperforms several standard Genetic Programming systems, which are based on hand-designed features, and use different program representations and fitness functions.", "num_citations": "15\n", "authors": ["1736"]}
{"title": "A survey of statistical machine learning elements in genetic programming\n", "abstract": " Modern genetic programming (GP) operates within the statistical machine learning (SML) framework. In this framework, evolution needs to balance between approximation of an unknown target function on the training data and generalization, which is the ability to predict well on new data. This paper provides a survey and critical discussion of SML methods that enable GP to generalize.", "num_citations": "14\n", "authors": ["1736"]}
{"title": "Maximum margin decision surfaces for increased generalisation in evolutionary decision tree learning\n", "abstract": " Decision tree learning is one of the most widely used and practical methods for inductive inference. We present a novel method that increases the generalisation of genetically-induced classification trees, which employ linear discriminants as the partitioning function at each internal node. Genetic Programming is employed to search the space of oblique decision trees. At the end of the evolutionary run, a (1+1) Evolution Strategy is used to geometrically optimise the boundaries in the decision space, which are represented by the linear discriminant functions. The evolutionary optimisation concerns maximising the decision-surface margin that is defined to be the smallest distance between the decision-surface and any of the samples. Initial empirical results of the application of our method to a series of datasets from the UCI repository suggest that model generalisation benefits from the margin maximisation\u00a0\u2026", "num_citations": "14\n", "authors": ["1736"]}
{"title": "Genetic programming for the induction of seasonal forecasts: A study on weather derivatives\n", "abstract": " The last 10 years has seen the introduction and rapid growth of a market in weather derivatives, financial instruments whose payoffs are determined by the outcome of an underlying weather metric. These instruments allow organisations to protect themselves against the commercial risks posed by weather fluctuations and also provide investment opportunities for financial traders. The size of the market for weather derivatives is substantial, with a survey suggesting that the market size exceeded $45.2 Billion in 2005/2006 with most contracts being written on temperature-based metrics. A key problem faced by buyers and sellers of weather derivatives is the determination of an appropriate pricing model (and resulting price) for the financial instrument. A critical input into the pricing model is an accurate forecast of the underlying weather metric. In this study we induce seasonal forecasting temperature models\u00a0\u2026", "num_citations": "13\n", "authors": ["1736"]}
{"title": "Unsupervised problem decomposition using genetic programming\n", "abstract": " We propose a new framework based on Genetic Programming (GP) to automatically decompose problems into smaller and simpler tasks. The framework uses GP at two levels. At the top level GP evolves ways of splitting the fitness cases into subsets. At the lower level GP evolves programs that solve the fitness cases in each subset. The top level GP programs include two components. Each component receives a training case as the input. The components\u2019 outputs act as coordinates to project training examples onto a 2-D Euclidean space. When an individual is evaluated, K-means clustering is applied to group the fitness cases of the problem. The number of clusters is decided based on the density of the projected samples. Each cluster then invokes an independent GP run to solve its member fitness cases. The fitness of the lower level GP individuals is evaluated as usual. The fitness of the high-level GP\u00a0\u2026", "num_citations": "13\n", "authors": ["1736"]}
{"title": "Evolving a statistics class using object oriented evolutionary programming\n", "abstract": " Object Oriented Evolutionary Programming is used to evolve programs that calculate some statistical measures on a set of numbers. We compared this technique with a more standard functional representation. We also studied the effects of scalar and Pareto-based multi-objective fitness functions to the induction of multi-task programs. We found that the induction of a program residing in an OO representation space is more efficient, yielding less fitness evaluations, and that scalar fitness performed better than Pareto-based fitness in this problem domain.", "num_citations": "13\n", "authors": ["1736"]}
{"title": "Learning environment models in car racing using stateful genetic programming\n", "abstract": " For computational intelligence to be useful in creating game agent AI we need to focus on methods that allow the creation and maintenance of models for the environment, which the artificial agents inhabit. Maintaining a model allows an agent to plan its actions more effectively by combining immediate sensory information along with a memories that have been acquired while operating in that environment. To this end, we propose a way to build environment models for non-player characters in car racing games using stateful Genetic Programming. A method is presented, where general-purpose 2-dimensional data-structures are used to build a model of the racing track. Results demonstrate that model-building behaviour can be cooperatively coevolved with car-controlling behaviour in modular programs that make use of these models in order to navigate successfully around a racing track.", "num_citations": "11\n", "authors": ["1736"]}
{"title": "Choosing function sets with better generalisation performance for symbolic regression models\n", "abstract": " Supervised learning by means of Genetic Programming (GP) aims at the evolutionary synthesis of a model that achieves a balance between approximating the target function on the training data and generalising on new data. The model space searched by the Evolutionary Algorithm is populated by compositions of primitive functions defined in a function set. Since the target function is unknown, the choice of function set\u2019s constituent elements is primarily guided by the makeup of function sets traditionally used in the GP literature. Our work builds upon previous research of the effects of protected arithmetic operators (i.e. division, logarithm, power) on the output value of an evolved model for input data points not encountered during training. The scope is to benchmark the approximation/generalisation of models evolved using different function set choices across a range of 43 symbolic regression problems\u00a0\u2026", "num_citations": "10\n", "authors": ["1736"]}
{"title": "GP made faster with semantic surrogate modelling\n", "abstract": " Genetic Programming (GP) is known to be expensive in cases where the fitness evaluation is computationally demanding, i.e., object detection, programmatic compression, image processing applications. The paper introduces a method that reduces the amount of fitness evaluations that are required to obtain good solutions. We consider the supervised learning setting, where a training set of input vectors are collectively mapped to a vector of outputs, and then a loss function is used to map the vector of outputs to a scalar fitness value. Saving of fitness evaluations is achieved through the use of two components. The first component is surrogate model that predicts trees output for a particular input vector xi based on the similarity between xi and other input vectors in the training set for which the candidate solution has been already evaluated with. The second component, is a simple linear equation to control the size\u00a0\u2026", "num_citations": "10\n", "authors": ["1736"]}
{"title": "Evolving seasonal forecasting models with genetic programming in the context of pricing weather-derivatives\n", "abstract": " In this study we evolve seasonal forecasting temperature models, using Genetic Programming (GP), in order to provide an accurate, localised, long-term forecast of a temperature profile as part of the broader process of determining appropriate pricing model for weather-derivatives, financial instruments that allow organisations to protect themselves against the commercial risks posed by weather fluctuations. Two different approaches for time-series modelling are adopted. The first is based on a simple system identification approach whereby the temporal index of the time-series is used as the sole regressor of the evolved model. The second is based on iterated single-step prediction that resembles autoregressive and moving average models in statistical time-series modelling. Empirical results suggest that GP is able to successfully induce seasonal forecasting models, and that autoregressive models\u00a0\u2026", "num_citations": "10\n", "authors": ["1736"]}
{"title": "Early stopping criteria to counteract overfitting in genetic programming\n", "abstract": " Early stopping typically stops training the first time validation fitness disimproves. This may not be the best strategy given that validation fitness can subsequently increase or decrease. We examine the effects of stopping subsequent to the first disimprovement in validation fitness, on symbolic regression problems. Stopping points are determined using criteria which measure generalisation loss and training progress. Results suggest that these criteria can improve the generalistion ability of symbolic regression functions evolved using Grammar-based GP.", "num_citations": "10\n", "authors": ["1736"]}
{"title": "Adaptive distance metrics for nearest neighbour classification based on genetic programming\n", "abstract": " Nearest Neighbour (NN) classification is a widely-used, effective method for both binary and multi-class problems. It relies on the assumption that class conditional probabilities are locally constant. However, this assumption becomes invalid in high dimensions, and severe bias can be introduced, which degrades the performance of the method. The employment of a locally adaptive distance metric becomes crucial in order to keep class conditional probabilities approximately uniform, whereby better classification performance can be attained. This paper presents a locally adaptive distance metric for NN classification based on a supervised learning algorithm (Genetic Programming) that learns a vector of feature weights for the features composing an instance query. Using a weighted Euclidean distance metric, this has the effect of adaptive neighbourhood shapes to query locations, stretching the\u00a0\u2026", "num_citations": "8\n", "authors": ["1736"]}
{"title": "On the effect of function set to the generalisation of symbolic regression models\n", "abstract": " Supervised learning by means of Genetic Programming aims at the evolutionary synthesis of a model that achieves a balance between approximating the target function on the training data and generalising on new data. In this study we benchmark the approximation/generalisation of models evolved using different function set setups, across a range of symbolic regression problems. Results show that Koza's protected division and power should be avoided, and operators such as analytic quotient and sine should be used instead.", "num_citations": "7\n", "authors": ["1736"]}
{"title": "Regularised gradient boosting for financial time-series modelling\n", "abstract": " Gradient Boosting (GB) learns an additive expansion of simple basis-models. This is accomplished by iteratively fitting an elementary model to the negative gradient of a loss function with respect to the expansion\u2019s values at each training data-point evaluated at each iteration. For the case of squared-error loss function, the negative gradient takes the form of an ordinary residual for a given training data-point. Studies have demonstrated that running GB for hundreds of iterations can lead to overfitting, while a number of authors showed that by adding noise to the training data, generalisation is impaired even with relatively few basis-models. Regularisation is realised through the shrinkage of every newly-added basis-model to the expansion. This paper demonstrates that GB with shrinkage-based regularisation is still prone to overfitting in noisy datasets. We use a transformation based on a sigmoidal function\u00a0\u2026", "num_citations": "7\n", "authors": ["1736"]}
{"title": "Feature selection for speaker verification using genetic programming\n", "abstract": " We present a study examining feature selection from high performing models evolved using genetic programming (GP) on the problem of automatic speaker verification (ASV). ASV is a highly unbalanced binary classification problem in which a given speaker must be verified against everyone else. We evolve classification models for 10 individual speakers using a variety of fitness functions and data sampling techniques and examine the generalisation of each model on a 1:9 unbalanced set. A significant difference between train and test performance is found which may indicate overfitting in the models. Using only the best generalising models, we examine two methods for selecting the most important features. We compare the performance of a number of tuned machine learning classifiers using the full 275 features and a reduced set of 20 features from both feature selection methods. Results show that\u00a0\u2026", "num_citations": "7\n", "authors": ["1736"]}
{"title": "Recursion in tree-based genetic programming\n", "abstract": " Recursion is a powerful concept that enables a solution to a problem to be expressed as a relatively simple decomposition of the original problem into sub-problems of the same type. We survey previous research about the evolution of recursive programs in tree-based Genetic Programming. We then present an analysis of the fitness landscape of recursive programs, and report results on evolving solutions to a range of problems. We conclude with guidelines concerning the choice of fitness function and variation operators, as well as the handling of the halting problem. The main findings are as follows. The distribution of fitness changes initially as we look at programs of increasing size but once some threshold has been exceeded, it shows very little variation with size. Furthermore, the proportion of halting programs decreases as size increases. Recursive programs exhibit the property of weak causality\u00a0\u2026", "num_citations": "7\n", "authors": ["1736"]}
{"title": "Genetic programming with memory for financial trading\n", "abstract": " A memory-enabled program representation in strongly-typed Genetic Programming (GP) is compared against the standard representation in a number of financial time-series modelling tasks. The paper first presents a survey of GP systems that utilise memory. Thereafter, a number of simulations show that memory-enabled programs generalise better than their standard counterparts in most datasets of this problem domain.", "num_citations": "7\n", "authors": ["1736"]}
{"title": "Tackling overfitting in evolutionary-driven financial model induction\n", "abstract": " This chapter explores the issue of overfitting in grammar-based Genetic Programming. Tools such as Genetic Programming are well suited to problems in finance where we seek to learn or induce a model from data. Models that overfit the data upon which they are trained prevent model generalisation, which is an important goal of learning algorithms.             Early stopping is a technique that is frequently used to counteract overfitting, but this technique often fails to identify the optimal point at which to stop training. In this chapter, we implement four classes of stopping criteria, which attempt to stop training when the generalisation of the evolved model is maximised.             We show promising results using, in particular, one novel class of criteria, which measured the correlation between the training and validation fitness at each generation. These criteria determined whether or not to stop training depending on\u00a0\u2026", "num_citations": "7\n", "authors": ["1736"]}
{"title": "A QA-TSK fuzzy model vs evolutionary decision trees towards nonlinear action pattern recognition\n", "abstract": " A comparison among three linear methodologies, a novel auto-adjusted fuzzy quadruple TSK model (QA-TSK) and two evolutionary decision tree representations, is presented in this paper. The three architectures make use of a vast number of primitives utilised to reconfigure and evolve their internal structures of the classifier models so that to discriminate among spatial physical activities. Such primitives like statistical features employ a twofold role, initially to model the data set in a dimensionality reduction preprocessing and finally to exploit these attributes to recognise pattern actions. The performance statistics are being utilised for remote surveillance within a smart environment incorporating an ubiquitous 3D marker based tracker which acquires the timeseries data streams, whereas activity recognition statistics are being generated through an off-line process.", "num_citations": "7\n", "authors": ["1736"]}
{"title": "A gaussian groundplan projection area model for evolving probabilistic classifiers\n", "abstract": " In this paper, an investigation of evolvable probabilistic classifiers is conducted, along with a thorough comparison between a classical Gaussian distance model, and the induction of Gaussian-to-circle projection model. The newly introduced model refers to a distance fitness measure, based on the projection of Gaussian distributions with geometric circles. The projection architecture aims to model and classify physical aggressive behaviours, by using biomechanical primitives. The primitives are being used to model the dynamics of the aggressive activities, by evolving biomechanical classifiers, which can discriminate between three behaviours and six actions. Both evolutionary models have shown strong discrimination performances on recognising the individual actions of each behaviour. From the comparison, the proposed model outperformed the classical one with three ensemble programs.", "num_citations": "6\n", "authors": ["1736"]}
{"title": "Learning to recognise mental activities: genetic programming of stateful classifiers for brain-computer interfacing\n", "abstract": " Two families (stateful and stateless) of genetically programmed classifiers were tested on a five class brain-computer interface (BCI) data set of raw EEG signals. The ability of evolved classifiers to discriminate mental tasks from each other were analysed in terms of accuracy, precision and recall. A model describing the dynamics of state usage in stateful programs is introduced. An investigation of relationships between the model attributes and associated classification results was made. The results show that both stateful and stateless programs can be successfully evolved for this task, though stateful programs start from lower fitness and take longer to evolve.", "num_citations": "6\n", "authors": ["1736"]}
{"title": "Extending the bat foraging metaphor for optimisation algorithm design.\n", "abstract": " A particular feature of most species of bats is that they use echolocation, or \u2018active sensing\u2019, in which pulses of acoustic energy are emitted and the resulting echo is resolved into an \u2018image\u2019of their surrounding environment. This is used to detect objects and to locate food resources such as flying insects. Previous work has taken inspiration from the process of echolocation to develop the \u2018bat algorithm\u2019(Yang, 2010) and this has demonstrated good results on a wide range of optimisation problems. In this paper we build on this work in order to stimulate further interest in exploration of a bat foraging metaphor as an inspiration for the design of optimisation algorithms. This study provides a review of some recent relevant literature on bat foraging and uncovers several aspects of the foraging process which have not been given explicit consideration in bat algorithm design thus far. We also outline a general framework of foraging behaviour which distinguishes between the role of \u2018perception\u2019,\u2018memory\u2019, and the use of the \u2018social\u2019information available to a foraging bat. We demonstrate how some of these features can be integrated into an exemplar optimisation algorithm and test the performance of this algorithm on a series of benchmark problems. The study also provides several ideas for future work.", "num_citations": "5\n", "authors": ["1736"]}
{"title": "Mechanical feature attributes for modeling and pattern classification of physical activities\n", "abstract": " A rigorous investigation on the synergy of mechanical attributes to engineer tactics for measuring human activity in terms of forces, as well as to provide independency and discrimination clarity of action recognition using linear and non-linear classification methodologies from data mining and evolutionary computation, are the main objectives where this paper focuses on. Mechanical analysis is employed to mathematically describe and model human movement by using a number of mechanical features inspired mainly from kinematics dynamics. Such features employ a twofold role on the descriptive analysis of an activity, initially to provide statistics regarding inertial expressions, probable hazard levels, body-status of energy loss, and finally to exploit these attributes by decomposing the 3D time series data for pattern recognition in terms of actions and behaviours. The performance statistics are being utilized by a\u00a0\u2026", "num_citations": "5\n", "authors": ["1736"]}
{"title": "Ensemble Bayesian model averaging in genetic programming\n", "abstract": " This paper considers the general problem of function estimation via Genetic Programming (GP). Data analysts typically select a model from a population of models, and then proceed as if the selected model had generated the data. This approach ignores the uncertainty in model selection, leading to over-confident inferences and lack of generalisation. We adopt a coherent method for accounting for this uncertainty through a weighted averaging of all models competing in a population of GP. It is a principled statistical method for postprocessing a population of programs into an ensemble, which is based on Bayesian Model Averaging (BMA). Under two different formulations of BMA, the predictive probability density function (PDF) of a response variable is a weighted average of PDFs centered around the individual predictions of component models that take the form of either standalone programs or ensembles of\u00a0\u2026", "num_citations": "4\n", "authors": ["1736"]}
{"title": "A gp-moea/d approach for modelling total electron content over cyprus\n", "abstract": " Vertical Total Electron Content (vTEC) is an ionospheric characteristic used to derive the signal delay imposed by the ionosphere on near-vertical trans-ionospheric links. The major aim of this paper is to design a prediction model based on the main factors that influence the variability of this parameter on a diurnal, seasonal and long-term time-scale. The model should be accurate and general (comprehensive) enough for efficiently approximating the high variations of vTEC. However, good approximation and generalization are conflicting objectives. For this reason a Genetic Programming (GP) with Multi-objective Evolutionary Algorithm based on Decomposition characteristics (GP-MOEA/D) is designed and proposed for modeling vTEC over Cyprus. Experimental results show that the Multi-Objective GP-model, considering real vTEC measurements obtained over a period of 11 years, has produced a good approximation of the modeled parameter and can be implemented as a local model to account for the ionospheric imposed error in positioning. Particulary, the GP-MOEA/D approach performs better than a Single Objective Optimization GP, a GP with Non-dominated Sorting Genetic Algorithm-II (NSGA-II) characteristics and the previously proposed Neural Network-based approach in most cases.", "num_citations": "4\n", "authors": ["1736"]}
{"title": "Generalisation enhancement via input space transformation: A gp approach\n", "abstract": " This paper proposes a new approach to improve generalisation of standard regression techniques when there are hundreds or thousands of input variables. The input space X is composed of observational data of the form (x                                    i                 , y(x                                    i                 )), i\u2009=\u20091... n where each x                                    i                  denotes a k-dimensional input vector of design variables and y is the response. Genetic Programming (GP) is used to transform the original input space X into a new input space Z\u2009=\u2009(z                                    i                 , y(z                                    i                 )) that has smaller input vector and is easier to be mapped into its corresponding responses. GP is designed to evolve a function that receives the original input vector from each x                                    i                  in the original input space as input and return a new vector z                                    i                  as an output. Each\u00a0\u2026", "num_citations": "3\n", "authors": ["1736"]}
{"title": "Stateful program representations for evolving technical trading rules\n", "abstract": " A family of stateful program representations in grammar-based Genetic Programming are being compared against their stateless counterpart in the problem of binary classification of sequences of daily prices of a financial asset. Empirical results suggest that stateful classifiers learn as fast as stateless ones but generalise better to unseen data, rendering this form of program representation strongly appealing to the automatic programming of technical trading rules.", "num_citations": "3\n", "authors": ["1736"]}
{"title": "Speaker verification on unbalanced data with genetic programming\n", "abstract": " Automatic Speaker Verification (ASV) is a highly unbalanced binary classification problem, in which any given speaker must be verified against everyone else. We apply Genetic programming (GP) to this problem with the aim of both prediction and inference. We examine the generalisation of evolved programs using a variety of fitness functions and data sampling techniques found in the literature. A significant difference between train and test performance, which can indicate overfitting, is found in the evolutionary runs of all to-be-verified speakers. Nevertheless, in all speakers, the best test performance attained is always superior than just merely predicting the majority class. We examine which features are used in good-generalising individuals. The findings can inform future applications of GP or other machine learning techniques to ASV about the suitability of feature-extraction techniques.", "num_citations": "2\n", "authors": ["1736"]}
{"title": "Plant Propagation-Inspired Algorithms\n", "abstract": " Plants represent some 99% of the eukaryotic biomass of the planet and have been highly successful in colonising many habitants with differing resource potential. The success of plants in earning a living suggests that they have evolved robust resource capture mechanisms and reproductive strategies. In spite of the preponderance of plant life, surprisingly little inspiration has been drawn from plant activities for the design of optimisation algorithms.In this chapter we focus on one important aspect of plant activities, namely seed and plant dispersal. Mechanisms for seed and plant dispersal have evolved over time in order to create effective ways to disperse seeds into locations in which they can germinate and become established. These mechanisms are highly varied, ranging from morphological characteristics of seeds which can assist their aerial or animal-mediated dispersion, to co-evolved characteristics which reward animals or insects who disperse a plants seeds. At a conceptual level, dispersal can be considered as a search process, wherein the seed or plant is searching for good locations and therefore, inspiration from dispersal activities of plants can plausibly serve as the design inspiration for optimisation algorithms.", "num_citations": "2\n", "authors": ["1736"]}
{"title": "Genetic Programming Multitasking\n", "abstract": " In this paper, we present a new multitasking algorithm for Genetic Programming (GP). Our proposed algorithm (referred to as \u201cGP-Tasking\u201d) evolves population using multifaceted strategy. Each individual is trained with different training sets and evaluated with multiple fitness functions (where each fitness function represents one task). At the beginning of the run, GP-Tasking, randomly uses crossover operator to facilitate knowledge transfer between different tasks and store probability of constructive crossover operators between different tasks. This information is used to bias the crossover between tasks that have higher probability of producing fitter offspring. The novelty of GP Tasking, is that it uses one population in the same phenotype space but with different interpretations to explore multiple genotype spaces. GP-Tasking was evaluated with 3 sets of experiments where in each set we tested GP-Tasking ability to\u00a0\u2026", "num_citations": "1\n", "authors": ["1736"]}
{"title": "Applications of evolutionary computation\n", "abstract": " Evolutionary computation (EC) techniques are efficient, nature-inspired planning and optimization methods based on the principles of natural evolution and genetics. Owing to their efficiency and simple underlying principles, these methods can be used in the context of problem solving, optimization, and machine learning. A large and continuously increasing number of researchers and professionals make use of EC techniques in various application domains. This volume presents a careful selection of relevant EC examples combined with a thorough examination of the techniques used in EC. The papers in the volume illustrate the current state of the art in the application of EC and should help and inspire researchers and professionals to develop efficient EC methods for design and problem solving.All papers in this book were presented during EvoApplications 2013, which incorporates a range of tracks on\u00a0\u2026", "num_citations": "1\n", "authors": ["1736"]}
{"title": "Evolutionary prediction of total electron content over Cyprus\n", "abstract": " Total Electron Content (TEC) is an ionospheric characteristic used to derive the signal delay imposed by the ionosphere on trans-ionospheric links and subsequently overwhelm its negative impact in accurate position determination. In this paper, an Evolutionary Algorithm (EA), and particularly a Genetic Programming (GP) based model is designed. The proposed model is based on the main factors that influence the variability of the predicted parameter on a diurnal, seasonal and long-term time-scale. Experimental results show that the GP-model, which is based on TEC measurements obtained over a period of 11 years, has produced a good approximation of the modeled parameter and can be implemented as a local model to account for the ionospheric imposed error in positioning. The GP-based approach performs better than the existing Neural Network-based approach in several cases.", "num_citations": "1\n", "authors": ["1736"]}
{"title": "The evolution of recursive algorithms and object-oriented programs\n", "abstract": " British Library EThOS: The evolution of recursive algorithms and object-oriented programs New search | Advanced search | Search results Login / Register | About | Help | FAQ | Follow dividing line Use this URL to cite or link to this record in EThOS: https://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.510487 Title: The evolution of recursive algorithms and object-oriented programs Author: Agapitos, Alexandros ISNI: 0000 0004 2677 2068 Awarding Body: The University of Essex Current Institution: University of Essex Date of Award: 2009 Availability of Full Text: Full text unavailable from EThOS. Please contact the current institution\u2019s library for further details. Abstract: No abstract available Supervisor: Not available Sponsor: Not available Qualification Name: Thesis (Ph.D.) Qualification Level: Doctoral EThOS ID: uk.bl.ethos.510487 DOI: Not available Share: Terms and Conditions | Notice and Takedown Policy | Privacy \u2026", "num_citations": "1\n", "authors": ["1736"]}
{"title": "PROMOTING BETTER GENERALISATION IN MULTI-LAYER PERCEPTRONS USING A SIMULATED SYNAPTIC DOWNSCALING MECHANISM\n", "abstract": " A key concern when training a multi-layer perceptron (MLP) is that the final network should generalise well out-of-sample. A considerable literature has emerged which examines various aspects of this issue. In this study we draw inspiration from theories of memory consolidation in order to develop a new methodology for training MLPs in order to promote their generalisation capabilities. The synaptic homeostasis hypothesis [29, 30] proposes that a key role of sleep is to downscale synaptic strength to a baseline level that is energetically sustainable. As a consequence, the hypothesis suggests that sleep acts not to actively strengthen selected memories but rather to remove irrelevant memories. In turn, this lessens spurious learning, improves the signal to noise ratio in maintained memories, and therefore produces better generalisation capabilities. In this chapter we describe the synaptic homeostasis hypothesis and draw inspiration from it in order to design a \u2018wake-sleep\u2019training approach for MLPs. The approach is tested on a number of datasets.", "num_citations": "1\n", "authors": ["1736"]}