{"title": "Ensemble based systems in decision making\n", "abstract": " In matters of great importance that have financial, medical, social, or other implications, we often seek a second opinion before making a decision, sometimes a third, and sometimes many more. In doing so, we weigh the individual opinions, and combine them through some thought process to reach a final decision that is presumably the most informed one. The process of consulting \"several experts\" before making a final decision is perhaps second nature to us; yet, the extensive benefits of such a process in automated decision making applications have only recently been discovered by computational intelligence community. Also known under various other names, such as multiple classifier systems, committee of classifiers, or mixture of experts, ensemble based systems have shown to produce favorable results compared to those of single-expert systems for a broad range of applications and under a variety of\u00a0\u2026", "num_citations": "2902\n", "authors": ["1070"]}
{"title": "Learn++: An incremental learning algorithm for supervised neural networks\n", "abstract": " We introduce Learn++, an algorithm for incremental training of neural network (NN) pattern classifiers. The proposed algorithm enables supervised NN paradigms, such as the multilayer perceptron (MLP), to accommodate new data, including examples that correspond to previously unseen classes. Furthermore, the algorithm does not require access to previously used data during subsequent incremental learning sessions, yet at the same time, it does not forget previously acquired knowledge. Learn++ utilizes ensemble of classifiers by generating multiple hypotheses using training data sampled according to carefully tailored distributions. The outputs of the resulting classifiers are combined using a weighted majority voting procedure. We present simulation results on several benchmark datasets as well as a real-world classification task. Initial results indicate that the proposed algorithm works rather well in practice\u00a0\u2026", "num_citations": "994\n", "authors": ["1070"]}
{"title": "Incremental learning of concept drift in nonstationary environments\n", "abstract": " We introduce an ensemble of classifiers-based approach for incremental learning of concept drift, characterized by nonstationary environments (NSEs), where the underlying data distributions change over time. The proposed algorithm, named Learn ++ .NSE, learns from consecutive batches of data without making any assumptions on the nature or rate of drift; it can learn from such environments that experience constant or variable rate of drift, addition or deletion of concept classes, as well as cyclical drift. The algorithm learns incrementally, as other members of the Learn ++  family of algorithms, that is, without requiring access to previously seen data. Learn ++ .NSE trains one new classifier for each batch of data it receives, and combines these classifiers using a dynamically weighted majority voting. The novelty of the approach is in determining the voting weights, based on each classifier's time-adjusted accuracy\u00a0\u2026", "num_citations": "782\n", "authors": ["1070"]}
{"title": "The wavelet tutorial\n", "abstract": " Welcome to this introductory tutorial on wavelet transforms. The wavelet transform is a relatively new concept (about 10 years old), but yet there are quite a few articles and books written on them. However, most of these books and articles are written by math people, for the other math people; still most of the math people don't know what the other math people are talking about (a math professor of mine made this", "num_citations": "687\n", "authors": ["1070"]}
{"title": "Ensemble learning\n", "abstract": " Over the last couple of decades, multiple classifier systems, also called ensemble systems have enjoyed growing attention within the computational intelligence and machine learning community. This attention has been well deserved, as ensemble systems have proven themselves to be very effective and extremely versatile in a broad spectrum of problem domains and real-world applications. Originally developed to reduce the variance\u2014thereby improving the accuracy\u2014of an automated decision-making system, ensemble systems have since been successfully used to address a variety of machine learning problems, such as feature selection, confidence estimation, missing feature, incremental learning, error correction, class-imbalanced data, learning concept drift from nonstationary distributions, among others. This chapter provides an overview of ensemble systems, their properties, and how they can be\u00a0\u2026", "num_citations": "634\n", "authors": ["1070"]}
{"title": "Learning from streaming data with concept drift and imbalance: an overview\n", "abstract": " The primary focus of machine learning has traditionally been on learning from data assumed to be sufficient and representative of the underlying fixed, yet unknown, distribution. Such restrictions on the problem domain paved the way for development of elegant algorithms with theoretically provable performance guarantees. As is often the case, however, real-world problems rarely fit neatly into such restricted models. For instance class distributions are often skewed, resulting in the \u201cclass imbalance\u201d problem. Data drawn from non-stationary distributions is also common in real-world applications, resulting in the \u201cconcept drift\u201d or \u201cnon-stationary learning\u201d problem which is often associated with streaming data scenarios. Recently, these problems have independently experienced increased research attention, however, the combined problem of addressing all of the above mentioned issues has enjoyed\u00a0\u2026", "num_citations": "260\n", "authors": ["1070"]}
{"title": "Learn.NC: Combining Ensemble of Classifiers With Dynamically Weighted Consult-and-Vote for Efficient Incremental Learning of New Classes\n", "abstract": " We have previously introduced an incremental learning algorithm Learn ++ , which learns novel information from consecutive data sets by generating an ensemble of classifiers with each data set, and combining them by weighted majority voting. However, Learn ++  suffers from an inherent ldquooutvotingrdquo problem when asked to learn a new class omega new  introduced by a subsequent data set, as earlier classifiers not trained on this class are guaranteed to misclassify omega new  instances. The collective votes of earlier classifiers, for an inevitably incorrect decision, then outweigh the votes of the new classifiers' correct decision on omega new  instances-until there are enough new classifiers to counteract the unfair outvoting. This forces Learn ++  to generate an unnecessarily large number of classifiers. This paper describes Learn ++  .NC, specifically designed for efficient incremental learning of multiple\u00a0\u2026", "num_citations": "258\n", "authors": ["1070"]}
{"title": "Multiple classifier systems\n", "abstract": " Over the last decade, multiple classifier systems have been demonstrated to offer the means for enhancing the performance of pattern recognition systems. Multiple classifier system design involves the problem of classifier fusion. Recent developments in the methodology of multiple expert fusion are reviewed.", "num_citations": "204\n", "authors": ["1070"]}
{"title": "The story of wavelets\n", "abstract": " The theory and applications of wavelets have undoubtedly dominated the journals in all mathematical, engineering and related fields throughout the last decade. Few other theoretical developments in mathematical sciences have enjoyed this much attention and popularity, have been applied to such a diverse field of disciplines, and perhaps, have been so blindly misused. What was the missing piece in the great puzzle of signal processing, and how did the wavelets fill-in this missing piece? How did it all start, what development stages did it go through and what is the state of the art today? Have we reached the saturation, or do we have a long way to go? In this paper, we present three overviews in an attempt to answer these questions. In a historical overview, we look at the genesis of the wavelet theory as we take a short chronological journey through the wavelet times. In a technical overview, we look at the driving forces that played a key role in the development of the theory of wavelets, and try to find out what was so special that brought them to the center stage of scientific journals. In an application overview, we look at some of the most creative conventional and non-conventional applications of wavelets. On the conventional front, we discuss such applications as image compression, speech processing, and solution of partial differential equations. On the unconventional front, we look at various fields of applications including chemistry, neurophysiology, nondestructive evaluation, fractals, and economics. In particular, we discuss analyzing brain signals for the detection of Alzheimer's disease, analyzing ultrasonic weld inspection signals for\u00a0\u2026", "num_citations": "178\n", "authors": ["1070"]}
{"title": "Bootstrap-inspired techniques in computation intelligence\n", "abstract": " This article is about the success story of a seemingly simple yet extremely powerful approach that has recently reached a celebrity status in statistical and engineering sciences. The hero of this story - bootstrap resampling - is relatively young, but the story itself is a familiar one within the scientific community: a mathematician or a statistician conceives and formulates a theory that is first developed by fellow mathematicians and then brought to fame by other professionals, typically engineers, who point to many applications that can benefit from just such an approach. Signal processing boasts some of the finest examples of such stories, such as the classic story of Fourier transforms or the more contemporary tale of wavelet transforms.", "num_citations": "174\n", "authors": ["1070"]}
{"title": "COMPOSE: A Semisupervised Learning Framework for Initially Labeled Nonstationary Streaming Data\n", "abstract": " An increasing number of real-world applications are associated with streaming data drawn from drifting and nonstationary distributions that change over time. These applications demand new algorithms that can learn and adapt to such changes, also known as concept drift. Proper characterization of such data with existing approaches typically requires substantial amount of labeled instances, which may be difficult, expensive, or even impractical to obtain. In this paper, we introduce compacted object sample extraction (COMPOSE), a computational geometry-based framework to learn from nonstationary streaming data, where labels are unavailable (or presented very sporadically) after initialization. We introduce the algorithm in detail, and discuss its results and performances on several synthetic and real-world data sets, which demonstrate the ability of the algorithm to learn under several different scenarios of\u00a0\u2026", "num_citations": "154\n", "authors": ["1070"]}
{"title": "An ensemble-based incremental learning approach to data fusion\n", "abstract": " This paper introduces Learn++, an ensemble of classifiers based algorithm originally developed for incremental learning, and now adapted for information/data fusion applications. Recognizing the conceptual similarity between incremental learning and data fusion, Learn++ follows an alternative approach to data fusion, i.e., sequentially generating an ensemble of classifiers that specifically seek the most discriminating information from each data set. It was observed that Learn++ based data fusion consistently outperforms a similarly configured ensemble classifier trained on any of the individual data sources across several applications. Furthermore, even if the classifiers trained on individual data sources are fine tuned for the given problem, Learn++ can still achieve a statistically significant improvement by combining them, if the additional data sets carry complementary information. The algorithm can also identify\u00a0\u2026", "num_citations": "145\n", "authors": ["1070"]}
{"title": "Frequency invariant classification of ultrasonic weld inspection signals\n", "abstract": " Automated signal classification systems are finding increasing use in many applications for the analysis and interpretation of large volumes of signals. Such systems show consistency of response and help reduce the effect of variabilities associated with human interpretation. This paper deals with the analysis of ultrasonic NDE signals obtained during weld inspection of piping in boiling water reactors. The overall approach consists of three major steps, namely, frequency invariance, multiresolution analysis, and neural network classification. The data are first preprocessed whereby signals obtained using different transducer center frequencies are transformed to an equivalent reference frequency signal. Discriminatory features are then extracted using a multiresolution analysis technique, namely, the discrete wavelet transform (DWT). The compact feature vector obtained using wavelet analysis is classified using a\u00a0\u2026", "num_citations": "123\n", "authors": ["1070"]}
{"title": "Metagenome Fragment Classification Using \ud835\udc41-Mer Frequency Profiles\n", "abstract": " A vast amount of microbial sequencing data is being generated through large-scale projects in ecology, agriculture, and human health. Efficient high-throughput methods are needed to analyze the mass amounts of metagenomic data, all DNA present in an environmental sample. A major obstacle in metagenomics is the inability to obtain accuracy using technology that yields short reads. We construct the unique  \ud835\udc41-mer frequency profiles of 635 microbial genomes publicly available as of February 2008. These profiles  are used to train a naive Bayes classifier (NBC) that can be used to identify the genome of any fragment. We show that our method is comparable to BLAST for small 25 bp fragments but does not have the ambiguity of BLAST's tied top scores. We demonstrate that this approach is scalable to identify any fragment from hundreds of genomes. It also performs quite well at the strain, species, and genera levels and achieves strain resolution despite classifying ubiquitous genomic fragments (gene and nongene regions). Cross-validation analysis demonstrates that species-accuracy achieves 90%  for highly-represented species containing an average of 8 strains. We demonstrate that such a tool can be used on the Sargasso Sea dataset, and our analysis shows that NBC can be further enhanced.", "num_citations": "116\n", "authors": ["1070"]}
{"title": "An architecture for intelligent systems based on smart sensors\n", "abstract": " Based on requirements for a next-generation rocket test facility, elements of a prototype intelligent rocket test facility (IRTF) have been implemented. The preliminary results provide the basis for future advanced development and validation using rocket test stand facilities at Stennis Space Center (SSC). Key components include distributed smart sensor elements integrated using a knowledge-driven environment. One of the specific goals is to imbue sensors with the intelligence needed to perform self-diagnosis of health and to participate in a hierarchy of health determination at sensor, process, and system levels. We have identified issues important to further development of health-enabled networks, which should be of interest to others working with smart sensors and intelligent health management systems.", "num_citations": "98\n", "authors": ["1070"]}
{"title": "An ensemble based data fusion approach for early diagnosis of Alzheimer\u2019s disease\n", "abstract": " As the number of the elderly population affected by Alzheimer\u2019s disease (AD) rises rapidly, the need to find an accurate, inexpensive and non-intrusive diagnostic procedure that can be made available to community healthcare providers is becoming an increasingly urgent public health concern. Several recent studies have looked at analyzing electroencephalogram (EEG) signals through the use of wavelets and neural networks. While showing great promise, the final outcomes of these studies have been largely inconclusive. This is mostly due to inherent difficulty of the problem, but also \u2013 perhaps \u2013 due to inefficient use of the available information, as many of these studies have used a single EEG channel for the analysis. In this contribution, we describe an ensemble of classifiers based data fusion approach to combine information from two or more sources, believed to contain complementary information, for early\u00a0\u2026", "num_citations": "87\n", "authors": ["1070"]}
{"title": "Comparative multiresolution wavelet analysis of ERP spectral bands using an ensemble of classifiers approach for early diagnosis of Alzheimer's disease\n", "abstract": " Early diagnosis of Alzheimer's disease (AD) is becoming an increasingly important healthcare concern. Prior approaches analyzing event-related potentials (ERPs) had varying degrees of success, primarily due to smaller study cohorts, and the inherent difficulty of the problem. A new effort using multiresolution analysis of ERPs is described. Distinctions of this study include analyzing a larger cohort, comparing different wavelets and different frequency bands, using ensemble-based decisions and, most importantly, aiming the earliest possible diagnosis of the disease. Surprising yet promising outcomes indicate that ERPs in response to novel sounds of oddball paradigm may be more reliable as a biomarker than the more commonly used responses to target sounds.", "num_citations": "84\n", "authors": ["1070"]}
{"title": "Learn++. MF: A random subspace approach for the missing feature problem\n", "abstract": " We introduce Learn++.MF, an ensemble-of-classifiers based algorithm that employs random subspace selection to address the missing feature problem in supervised classification. Unlike most established approaches, Learn++.MF does not replace missing values with estimated ones, and hence does not need specific assumptions on the underlying data distribution. Instead, it trains an ensemble of classifiers, each on a random subset of the available features. Instances with missing values are classified by the majority voting of those classifiers whose training data did not include the missing features. We show that Learn++.MF can accommodate substantial amount of missing data, and with only gradual decline in performance as the amount of missing data increases. We also analyze the effect of the cardinality of the random feature subsets, and the ensemble size on algorithm performance. Finally, we discuss the\u00a0\u2026", "num_citations": "80\n", "authors": ["1070"]}
{"title": "Learn++: A classifier independent incremental learning algorithm for supervised neural networks\n", "abstract": " A versatile incremental learning algorithm is introduced for supervised neural network type classifiers. The proposed algorithm, called Learn++, exploits the synergistic expressive power of an ensemble of weak classifiers for learning additional information from new data. Learn++ is capable of learning new classes, without forgetting previously acquired knowledge, even when the previously used data is no longer available. Furthermore, Learn++ is independent of the specific type of the classifier, and adds the incremental learning capability to any supervised neural network classifier.", "num_citations": "76\n", "authors": ["1070"]}
{"title": "Analysis of complexity based EEG features for the diagnosis of Alzheimer's disease\n", "abstract": " As life expectancy increases, particularly in the developed world, so does the prevalence of Alzheimer's Disease (AD). AD is a neurodegenerative disorder characterized by neu-rofibrillary plaques and tangles in the brain that leads to neu-ronal death and dementia. Early diagnosis of AD is still a major unresolved health concern: several biomarkers are being investigated, among which the electroencephalogram (EEG) provides the only option for an electrophysiological information. In this study, EEG signals obtained from 161 subjects - 79 with AD, and 82 age-matched controls (CN) - are analyzed using several nonlinear signal complexity measures. These measures include: Hi-guchi fractal dimension (HFD), spectral entropy (SE), spectral centroid (SC), spectral roll-off (SR), and zero-crossing rate (ZCR). HFD is a quantitative measure of time series complexity derived from fractal theory. Among spectral measures\u00a0\u2026", "num_citations": "72\n", "authors": ["1070"]}
{"title": "Incremental learning in nonstationary environments with controlled forgetting\n", "abstract": " We have recently introduced an incremental learning algorithm, called Learn ++ .NSE, designed for Non-Stationary Environments (concept drift), where the underlying data distribution changes over time. With each dataset drawn from a new environment, Learn ++ .NSE generates a new classifier to form an ensemble of classifiers. The ensemble members are combined through a dynamically weighted majority voting, where voting weights are determined based on classifiers' age-adjusted accuracy on current and past environments. Unlike other ensemble-based concept drift algorithms, Learn ++ .NSE does not discard prior classifiers, allowing potentially cyclical environments to be learned more effectively. While Learn ++ .NSE has been shown to work well on a variety of concept drift problems, a potential shortcoming of this approach is the cumulative nature of the ensemble size. In this contribution, we expand our\u00a0\u2026", "num_citations": "70\n", "authors": ["1070"]}
{"title": "An ensemble approach for incremental learning in nonstationary environments\n", "abstract": " We describe an ensemble of classifiers based algorithm for incremental learning in nonstationary environments. In this formulation, we assume that the learner is presented with a series of training datasets, each of which is drawn from a different snapshot of a distribution that is drifting at an unknown rate. Furthermore, we assume that the algorithm must learn the new environment in an incremental manner, that is, without having access to previously available data. Instead of a time window over incoming instances, or an aged based forgetting \u2013 as used by most ensemble based nonstationary learning algorithms \u2013 a strategic weighting mechanism is employed that tracks the classifiers\u2019 performances over drifting environments to determine appropriate voting weights. Specifically, the proposed approach generates a single classifier for each dataset that becomes available, and then combines them through a\u00a0\u2026", "num_citations": "69\n", "authors": ["1070"]}
{"title": "Artificial intelligence methods for selection of an optimized sensor array for identification of volatile organic compounds\n", "abstract": " We have investigated two artificial intelligence (AI)-based approaches for the optimum selection of a sensor array for the identification of volatile organic compounds (VOCs). The array consists of quartz crystal microbalances (QCMs), each coated with a different polymeric material. The first approach uses a decision tree classification algorithm to determine the minimum number of features that are required to classify the training data correctly. The second approach employs the hill-climb search algorithm to search the feature space for the optimal minimum feature set that maximizes the performance of a neural network classifier. We also examined the value of simple statistical procedures that could be integrated into the search algorithm in order to reduce computation time. The strengths and limitations of each approach are discussed.", "num_citations": "66\n", "authors": ["1070"]}
{"title": "Learn++. mt: A new approach to incremental learning\n", "abstract": " An ensemble of classifiers based algorithm, Learn++, was recently introduced that is capable of incrementally learning new information from datasets that consecutively become available, even if the new data introduce additional classes that were not formerly seen. The algorithm does not require access to previously used datasets, yet it is capable of largely retaining the previously acquired knowledge. However, Learn++ suffers from the inherent \u201dout-voting\u201d problem when asked to learn new classes, which causes it to generate an unnecessarily large number of classifiers. This paper proposes a modified version of this algorithm, called Learn++.MT that not only reduces the number of classifiers generated, but also provides performance improvements. The out-voting problem, the new algorithm and its promising results on two benchmark datasets as well as on one real world application are presented.", "num_citations": "61\n", "authors": ["1070"]}
{"title": "Learning concept drift in nonstationary environments using an ensemble of classifiers based approach\n", "abstract": " We describe an ensemble of classifiers based approach for incrementally learning from new data drawn from a distribution that changes in time, i.e., data obtained from a nonstationary environment. Specifically, we generate a new classifier using each additional dataset that becomes available from the changing environment. The classifiers are combined by a modified weighted majority voting, where the weights are dynamically updated based on the classifierspsila current and past performances, as well as their age. This mechanism allows the algorithm to track the changing environment by weighting the most recent and relevant classifiers higher. However, it also utilizes old classifiers by assigning them appropriate voting weights should a cyclical environment renders them relevant again. The algorithm learns incrementally, i.e., it does not need access to previously used data. The algorithm is also independent\u00a0\u2026", "num_citations": "58\n", "authors": ["1070"]}
{"title": "Ensemble of SVMs for incremental learning\n", "abstract": " Support Vector Machines (SVMs) have been successfully applied to solve a large number of classification and regression problems. However, SVMs suffer from the catastrophic forgetting phenomenon, which results in loss of previously learned information. Learn\u2009+\u2009+\u2009 have recently been introduced as an incremental learning algorithm. The strength of Learn\u2009+\u2009+\u2009 lies in its ability to learn new data without forgetting previously acquired knowledge and without requiring access to any of the previously seen data, even when the new data introduce new classes. To address thecatastrophic forgetting problem and to add the incremental learning capability to SVMs, we propose using an ensemble of SVMs trained with Learn\u2009+\u2009+\u2009. Simulation results on real-world and benchmark datasets suggest that the proposed approach is promising.", "num_citations": "58\n", "authors": ["1070"]}
{"title": "Feature extraction techniques for ultrasonic signal classification\n", "abstract": " In this paper, we present two feature extraction techniques for the classification of ultrasonic NDE signals acquired from weld inspection regions of boiling water reactor piping of nuclear power plants. The classification system consists of a pre-processing block that extracts features from the incoming patterns, and of an artificial neural network that assigns the computed features to a particular class of defect present on the inspected pipe. The two techniques are respectively based on the discrete Gabor transform (DGT) and on the discrete wavelet transform (DWT); a third feature extraction technique, based on the clustering of the wavelet coefficients, is also presented. The results carried out by artificial neural networks trained and tested using the described feature extraction techniques, demonstrate the usefulness of the clustered DWT method with respect to the well known techniques of DGT and DWT.", "num_citations": "56\n", "authors": ["1070"]}
{"title": "Multimodal EEG, MRI and PET data fusion for Alzheimer's disease diagnosis\n", "abstract": " Alarmingly increasing prevalence of Alzheimer's disease (AD) due to the aging population in developing countries, combined with lack of standardized and conclusive diagnostic procedures, make early diagnosis of Alzheimer's disease a major public health concern. While no current medical treatment exists to stop or reverse this disease, recent dementia specific pharmacological advances can slow its progression, making early diagnosis all the more important. Several noninvasive biomarkers have been proposed, including P300 based EEG analysis, MRI volumetric analysis, PET based metabolic activity analysis, as alternatives to neuropsychological evaluation, the current gold standard of diagnosis. Each of these approaches, have shown some promising outcomes, however, a comprehensive data fusion analysis has not yet been conducted to investigate whether these different modalities carry\u00a0\u2026", "num_citations": "54\n", "authors": ["1070"]}
{"title": "Incremental learning of variable rate concept drift\n", "abstract": " We have recently introduced an incremental learning algorithm, Learn\u2009+\u2009+\u2009.NSE, for Non-Stationary Environments, where the data distribution changes over time due to concept drift. Learn\u2009+\u2009+\u2009.NSE is an ensemble of classifiers approach, training a new classifier on each consecutive batch of data that become available, and combining them through an age-adjusted dynamic error based weighted majority voting. Prior work has shown the algorithm\u2019s ability to track gradually changing environments as well as its ability to retain former knowledge in cases of cyclical or recurring data by retaining and appropriately weighting all classifiers generated thus far. In this contribution, we extend the analysis of the algorithm to more challenging environments experiencing varying drift rates; but more importantly we present preliminary results on the ability of the algorithm to accommodate addition or subtraction of\u00a0\u2026", "num_citations": "54\n", "authors": ["1070"]}
{"title": "An incremental learning algorithm with confidence estimation for automated identification of NDE signals\n", "abstract": " An incremental learning algorithm is introduced for learning new information from additional data that may later become available, after a classifier has already been trained using a previously available database. The proposed algorithm is capable of incrementally learning new information without forgetting previously acquired knowledge and without requiring access to the original database, even when new data include examples of previously unseen classes. Scenarios requiring such a learning algorithm are encountered often in nondestructive evaluation (NDE) in which large volumes of data are collected in batches over a period of time, and new defect types may become available in subsequent databases. The algorithm, named Learn++, takes advantage of synergistic generalization performance of an ensemble of classifiers in which each classifier is trained with a strategically chosen subset of the training\u00a0\u2026", "num_citations": "54\n", "authors": ["1070"]}
{"title": "Machine learning in transportation data analytics\n", "abstract": " The primary goal of this chapter is to provide a basic understanding of the machine learning methods for transportation-related applications. This chapter discusses how the machine learning methods can be utilized to improve performance of transportation data analytics tools. The chapter focuses on selected machine learning methods and importance of quality and quantity of available data. An example is provided along with the MATLAB code to present how the machine learning method can improve performance of data-driven transportation system by predicting a speed of the roadway section.", "num_citations": "53\n", "authors": ["1070"]}
{"title": "Fundamental concepts & an overview of the wavelet theory\n", "abstract": " Welcome to this introductory tutorial on wavelet transforms. The wavelet transform is a relatively new concept (about 10 years old), but yet there are quite a few articles and books written on them. However, most of these books and articles are written by math people, for the other math people; still most of the math people don't know what the other math people are talking about (a math professor of mine made this confession). In other words, majority of the literature available on wavelet transforms are of little help, if any, to those who are new to this subject (this is my personal opinion).When I first started working on wavelet transforms I have struggled for many hours and days to figure out what was going on in this mysterious world of wavelet transforms, due to the lack of introductory level text (s) in this subject. Therefore, I have decided to write this tutorial for the ones who are new to the topic. I consider myself quite\u00a0\u2026", "num_citations": "50\n", "authors": ["1070"]}
{"title": "Automated analysis of rotating probe multi-frequency eddy current data from steam generator tubes\n", "abstract": " An algorithm is presented for the automated analysis of rotating probe multifrequency eddy current data obtained from nuclear power plant steam generator tubes (SGT). The algorithm consists of four steps, namely, a preprocessing stage for conditioning the data, a decision tree based feature extraction stage for identifying relevant features for analysis, a neural network based classification stage for identifying signals from various defect types and benign structures, and finally a blind deconvolution based characterization stage for accurately estimating the size and orientation of the detected defects. This algorithm is optimized to maximize the probability of detection (POD), while keeping the number of false alarms (PFA) at a minimum. Initial results presented in this paper look very promising and demonstrate the effectiveness of the proposed algorithm.", "num_citations": "48\n", "authors": ["1070"]}
{"title": "Nearest hyperdisk methods for high-dimensional classification\n", "abstract": " In high-dimensional classification problems it is infeasible to include enough training samples to cover the class regions densely. Irregularities in the resulting sparse sample distributions cause local classifiers such as Nearest Neighbors (NN) and kernel methods to have irregular decision boundaries. One solution is to\" fill in the holes\" by building a convex model of the region spanned by the training samples of each class and classifying examples based on their distances to these approximate models. Methods of this kind based on affine and convex hulls and bounding hyperspheres have already been studied. Here we propose a method based on the bounding hyperdisk of each class-the intersection of the affine hull and the smallest bounding hypersphere of its training samples. We argue that in many cases hyperdisks are preferable to affine and convex hulls and hyperspheres: they bound the classes more\u00a0\u2026", "num_citations": "47\n", "authors": ["1070"]}
{"title": "Heuristic updatable weighted random subspaces for non-stationary environments\n", "abstract": " Learning in non-stationary environments is an increasingly important problem in a wide variety of real-world applications. In non-stationary environments data arrives incrementally, however the underlying generating function may change over time. While there is a variety of research into such environments, the research mainly consists of detecting concept drift (and then relearning the model), or developing classifiers which adapt to drift incrementally. We introduce Heuristic Up datable Weighted Random Subspaces (HUWRS), a new technique based on the Random Subspace Method that detects drift in individual features via the use of Hellinger distance, a distributional divergence metric. Through the use of subspaces, HUWRS allows for a more fine-grained approach to dealing with concept drift which is robust to feature drift even without class labels. We then compare our approach to two state of the art\u00a0\u2026", "num_citations": "45\n", "authors": ["1070"]}
{"title": "Local classifier weighting by quadratic programming\n", "abstract": " It has been widely accepted that the classification accuracy can be improved by combining outputs of multiple classifiers. However, how to combine multiple classifiers with various (potentially conflicting) decisions is still an open problem. A rich collection of classifier combination procedures-many of which are heuristic in nature-have been developed for this goal. In this brief, we describe a dynamic approach to combine classifiers that have expertise in different regions of the input space. To this end, we use local classifier accuracy estimates to weight classifier outputs. Specifically, we estimate local recognition accuracies of classifiers near a query sample by utilizing its nearest neighbors, and then use these estimates to find the best weights of classifiers to label the query. The problem is formulated as a convex quadratic optimization problem, which returns optimal nonnegative classifier weights with respect to the\u00a0\u2026", "num_citations": "40\n", "authors": ["1070"]}
{"title": "Multiple classifiers based incremental learning algorithm for learning in nonstationary environments\n", "abstract": " We describe an incremental learning algorithm designed to learn in challenging non-stationary environments, where the underlying data distribution that governs the classification problem changes at an unknown rate. The algorithm is based on a multiple classifier system that generates a new classifier every time a new dataset becomes available from the changing environment. We consider the particularly challenging form of this problem, where we assume that the previously generated data points are no longer available, even if some of those points may still be relevant in the new environment. The algorithm employs a strategic weighting mechanism to determine the error of each classifier on the current data distribution, and then combines the classifiers using a dynamically weighted majority voting. We describe the implementation details of algorithm, and track its performance as a function of the environment's\u00a0\u2026", "num_citations": "40\n", "authors": ["1070"]}
{"title": "Dynamically weighted majority voting for incremental learning and comparison of three boosting based approaches\n", "abstract": " We have previously introduced Learn++, an ensemble based incremental learning algorithm for acquiring new knowledge from data that later become available, even when such data introduce new classes. In this paper, we describe a modification to this algorithm, where the voting weights of the classifiers are updated dynamically based on the location of the test input in the feature space. The new algorithm provides improved performance, stronger immunity to catastrophic forgetting and finer balance to the stability-plasticity dilemma than its predecessor, particularly when new classes are introduced. The modified algorithm and its performance, as compared to Adaboost.Ml and the original Learn++, on real and benchmark datasets are presented.", "num_citations": "40\n", "authors": ["1070"]}
{"title": "An ensemble of classifiers approach for the missing feature problem\n", "abstract": " A new learning algorithm is introduced that can accommodate data with missing features. The algorithm uses an ensemble of classifiers approach. The classifiers in the ensemble are trained with random subsets of the total number of available features. The approach takes advantage of the basic assumption that an unknown subset of the features is in fact adequate for the classification, or in other words, that are redundant, and possibly irrelevant features in the data. This assumption is in general true for most practical applications. We empirically show that if a certain number of networks produce a particular classification performance using all of the features, then the same classification performance can be reached even if some features are missing, as long as the same number of usable networks can be generated with the missing features. The proposed approach has its roots in the incremental learning algorithm\u00a0\u2026", "num_citations": "40\n", "authors": ["1070"]}
{"title": "Identifying amyloid pathology\u2013related cerebrospinal fluid biomarkers for Alzheimer's disease in a multicohort study\n", "abstract": " Introduction The dynamic range of cerebrospinal fluid (CSF) amyloid \u03b2 (A\u03b21\u201342) measurement does not parallel to cognitive changes in Alzheimer's disease (AD) and cognitively normal (CN) subjects across different studies. Therefore, identifying novel proteins to characterize symptomatic AD samples is important.   Methods Proteins were profiled using a multianalyte platform by Rules Based Medicine (MAP\u2010RBM). Due to underlying heterogeneity and unbalanced sample size, we combined subjects (344 AD and 325 CN) from three cohorts: Alzheimer's Disease Neuroimaging Initiative, Penn Center for Neurodegenerative Disease Research of the University of Pennsylvania, and Knight Alzheimer's Disease Research Center at Washington University in St. Louis. We focused on samples whose cognitive and amyloid status was consistent. We performed linear regression (accounted for age, gender, number of\u00a0\u2026", "num_citations": "39\n", "authors": ["1070"]}
{"title": "Detection and identification of odorants using an electronic nose\n", "abstract": " Gas sensing systems for detection and identification of odorant molecules are of crucial importance in an increasing number of applications. Such applications include environmental monitoring, food quality assessment, airport security, and detection of hazardous gases. We describe a gas sensing system for detecting and identifying volatile organic compounds (VOC), and discuss the unique problems associated with the separability of signal patterns obtained by using such a system. We then present solutions for enhancing the separability of VOC patterns to enable classification. A new incremental learning algorithm that allows new odorants to be learned is also introduced.", "num_citations": "39\n", "authors": ["1070"]}
{"title": "Ensemble confidence estimates posterior probability\n", "abstract": " We have previously introduced the Learn\u2009+\u2009+\u2009 algorithm that provides surprisingly promising performance for incremental learning as well as data fusion applications. In this contribution we show that the algorithm can also be used to estimate the posterior probability, or the confidence of its decision on each test instance. On three increasingly difficult tests that are specifically designed to compare posterior probability estimates of the algorithm to that of the optimal Bayes classifier, we have observed that estimated posterior probability approaches to that of the Bayes classifier as the number of classifiers in the ensemble increase. This satisfying and intuitively expected outcome shows that ensemble systems can also be used to estimate confidence of their output.", "num_citations": "38\n", "authors": ["1070"]}
{"title": "The wavelet tutorial part iii\n", "abstract": " Although the time and frequency resolution problems are results of a physical phenomenon (the Heisenberg uncertainty principle) and exist regardless of the transform used, it is possible to analyze any signal by using an alternative approach called the multiresolution analysis (MRA). MRA, as implied by its name, analyzes the signal at different frequencies with different resolutions. Every spectral component is not resolved equally as was the case in the STFT.", "num_citations": "36\n", "authors": ["1070"]}
{"title": "Signal processing for metagenomics: extracting information from the soup\n", "abstract": " Traditionally, studies in microbial genomics have focused on single-genomes from cultured species, thereby limiting their focus to the small percentage of species that can be cultured outside their natural environment. Fortunately, recent advances in high-throughput sequencing and computational analyses have ushered in the new field of metagenomics, which aims to decode the genomes of microbes from natural communities without the need for cultivation. Although metagenomic studies have shed a great deal of insight into bacterial diversity and coding capacity, several computational challenges remain due to the massive size and complexity of metagenomic sequence data. Current tools and techniques are reviewed in this paper which address challenges in 1) genomic fragment annotation, 2) phylogenetic reconstruction, 3) functional classification of samples, and 4) interpreting complementary\u00a0\u2026", "num_citations": "35\n", "authors": ["1070"]}
{"title": "Hemodynamic response to repeated noxious cold pressor tests measured by functional near infrared spectroscopy on forehead\n", "abstract": " The objective of this research was to assess the utility of a simple near infrared spectroscopy (NIRS) technology for objective assessment of the hemodynamic response to acute pain. For this exploration, we used functional near infrared spectroscopy (fNIRS) to measure the hemodynamic response on the forehead during three trials of a cold pressor test (CPT) in 20 adults. To measure hemodynamic changes at the superficial tissues as well as the intracranial tissues, two configurations of \u2018far\u2019 and \u2018near\u2019 source-detector separations were used. We identified two features that were found to be fairly consistent across all subjects. The first feature was the change of total hemoglobin (THb) concentration in a given condition divided by the duration of that condition . Statistical analyses revealed that during the first CPT trial  significantly changed from its baseline value in all channels. Also, adaptation to\u00a0\u2026", "num_citations": "33\n", "authors": ["1070"]}
{"title": "Incremental learning in non-stationary environments with concept drift using a multiple classifier based approach\n", "abstract": " We outline an incremental learning algorithm designed for nonstationary environments where the underlying data distribution changes over time. With each dataset drawn from a new environment, we generate a new classifier. Classifiers are combined through dynamically weighted majority voting, where voting weights are determined based on classifiers\u00bf age and accuracy on current and past environments. The most recent and relevant classifiers are weighted higher, allowing the algorithm to appropriately adapt to drifting concepts. This algorithm does not discard prior classifiers, allowing efficient learning of potentially cyclical environments. The algorithm learns incrementally, i.e., without access to previous data. Finally, the algorithm can use any supervised classifier as its base model, including those not normally capable of incremental learning. We present the algorithm and its performance using different\u00a0\u2026", "num_citations": "32\n", "authors": ["1070"]}
{"title": "Incremental learning from unbalanced data\n", "abstract": " An ensemble based algorithm, Learn++. MT2, is introduced as an enhanced alternative to our previously reported incremental learning algorithm, Learn++. Both algorithms are capable of incrementally learning novel information from new datasets that consecutively become available, without requiring access to the previously seen data. In this contribution, we describe Learn++. MT2, which specifically targets incrementally learning from distinctly unbalanced data, where the amount of data that become available varies significantly from one database to the next. The problem of unbalanced data within the context of incremental learning is discussed first, followed by a description of the proposed solution. Initial, yet promising results indicate considerable improvement on the generalization performance and the stability of the algorithm.", "num_citations": "30\n", "authors": ["1070"]}
{"title": "The wavelet tutorial part i\n", "abstract": " Let's have a short review of the first part. We basically need Wavelet Transform (WT) to analyze non-stationary signals, ie, whose frequency response varies in time. I have written that Fourier Transform (FT) is not suitable for non-stationary signals, and I have shown examples of it to make it more clear. For a quick recall, let me give the", "num_citations": "30\n", "authors": ["1070"]}
{"title": "Adaptive noise cancellation schemes for magnetic flux leakage signals obtained from gas pipeline inspection\n", "abstract": " Nondestructive evaluation of the gas pipeline system is most commonly performed using magnetic flux leakage (MFL) techniques. A major segment of this network employs seamless pipes. The data obtained From MFL inspection of seamless pipes is contaminated by various sources of noise, including seamless pipe noise due to material properties of the pipe, lift-off variation of MFL sensor due to motion of the pipe and system noise due to on-board electronics. The noise can considerably reduce the detectability of defect signals in MFL data. This paper presents a new technique for improving the signal-to-noise-ratio in MFL data obtained from seamless pipes. The approach utilizes normalized least mean squares adaptive noise filtering coupled with wavelet shrinkage denoising to minimize the effects of various sources of noise. Results from application of the approach to data from field tests are presented. It is\u00a0\u2026", "num_citations": "29\n", "authors": ["1070"]}
{"title": "Multiresolution analysis for early diagnosis of Alzheimer's disease\n", "abstract": " Early diagnosis of Alzheimer's disease is a major concern due to large portions of the elderly population it affects and the lack of a standard and effective diagnosis procedure that is available to community healthcare providers. Several studies have been performed using wavelets or other signal processing methods to analyze EEG signals in an attempt to find a biomarker for Alzheimer's disease, which showed varying degrees of success. To date, in part due to lack of a large study cohort, the results of these studies remain largely inconclusive. In this paper, we describe a new effort using multiresolution wavelet analysis on event related potentials of the EEG to investigate whether such a link can be established. Several factors sets this study apart from similar prior efforts: We use a larger cohort, compare different mother wavelets, rather then using one generic wavelet, and most importantly, we specifically target\u00a0\u2026", "num_citations": "28\n", "authors": ["1070"]}
{"title": "Multiresolution wavelet analysis of ERPs for the detection of Alzheimer's disease\n", "abstract": " Alzheimer's disease, a neurological disorder usually seen in elderly people, is the most common of all cortical dementias. It can only be diagnosed with certainty via an autopsy. Neurologists usually diagnose Alzheimer's disease from symptoms; however, misdiagnosis can be a problem. Additional techniques to increase the accuracy of ante-mortem diagnoses would be useful. In this study, event related potentials (ERPs) of two groups of patients were acquired. One group had been diagnosed as having Alzheimer's disease and the other group as not having Alzheimer's disease. The ERPs were analyzed using multiresolution wavelet analysis techniques. The analyzed signals were then used to train a multilayer perceptron (MLP) neural network to distinguish the signals belonging to the two groups of patients. Initial results demonstrated the feasibility of this approach.", "num_citations": "27\n", "authors": ["1070"]}
{"title": "Majority vote and decision template based ensemble classifiers trained on event related potentials for early diagnosis of Alzheimer's disease\n", "abstract": " With the rapid increase in the population of elderly individuals affected by Alzheimer's disease, the need for an accurate, inexpensive and non-intrusive diagnostic biomarker that can be made available to community healthcare providers presents itself as a major public health concern. The feasibility of EEG as such a biomarker has gained a renewed attention as several recent studies, including our previous efforts, reported promising results. In this paper we present our preliminary results on using wavelet coefficients of event related potentials along with an ensemble of classifiers combined with majority vote and decision templates", "num_citations": "26\n", "authors": ["1070"]}
{"title": "Multiple classifier systems for multisensor data fusion\n", "abstract": " We have previously introduced Learn++, an ensemble of classifiers based algorithm capable of incremental learning from additional data, and pointed to its feasibility in data fusion applications. In this contribution, we provide additional details, updated results and insight on how such a system can be used in integrating complementary knowledge provided by different data sources obtained from different sensors. Essentially, the algorithm generates an ensemble of classifiers using data from each source, and combines these classifiers using a weighted voting procedure. The weights are determined based on the individual classifier\u2019s training performance as well as the observed or predicted reliability of each data source.", "num_citations": "25\n", "authors": ["1070"]}
{"title": "P50: A candidate ERP biomarker of prodromal Alzheimer\u05f3 s disease\n", "abstract": " IntroductionReductions of cerebrospinal fluid (CSF) amyloid-beta (A\u03b242) and elevated phosphorylated-tau (p-Tau) reflect in vivo Alzheimer\u05f3s disease (AD) pathology and show utility in predicting conversion from mild cognitive impairment (MCI) to dementia. We investigated the P50 event-related potential component as a noninvasive biomarker of AD pathology in non-demented elderly.Methods36 MCI patients were stratified into amyloid positive (MCI-AD, n=17) and negative (MCI-Other, n=19) groups using CSF levels of A\u03b242. All amyloid positive patients were also p-Tau positive. P50s were elicited with an auditory oddball paradigm.ResultsMCI-AD patients yielded larger P50s than MCI-Other. The best amyloid-status predictor model showed 94.7% sensitivity, 94.1% specificity and 94.4% total accuracy.DiscussionP50 predicted amyloid status in MCI patients, thereby showing a relationship with AD pathology\u00a0\u2026", "num_citations": "24\n", "authors": ["1070"]}
{"title": "Information-theoretic approaches to SVM feature selection for metagenome read classification\n", "abstract": " Analysis of DNA sequences isolated directly from the environment, known as metagenomics, produces a large quantity of genome fragments that need to be classified into specific taxa. Most composition-based classification methods use all features instead of a subset of features that may maximize classifier accuracy. We show that feature selection methods can boost performance of taxonomic classifiers. This work proposes three different filter-based feature selection methods that stem from information theory: (1) a technique that combines Kullback\u2013Leibler, Mutual Information, and distance information, (2) a text mining technique, TF-IDF, and (3) minimum redundancy-maximum-relevance (mRMR). The feature selection methods are compared by how well they improve support vector machine classification of genomic reads. Overall, the 6mer mRMR method performs well, especially on the phyla-level. If the\u00a0\u2026", "num_citations": "24\n", "authors": ["1070"]}
{"title": "Guest editorial learning in nonstationary and evolving environments\n", "abstract": " The papers in this special issue encompass a broad spectrum of scenarios and problems, including some of the new challenges and fundamental problems that are encountered in learning in nonstationary and evolving environments.", "num_citations": "23\n", "authors": ["1070"]}
{"title": "Semi-supervised learning in initially labeled non-stationary environments with gradual drift\n", "abstract": " Semi-supervised learning (SSL) in non-stationary environments has received relatively little attention in machine learning, despite a growing number of applications that can benefit from a properly configured SSL algorithm. Previous works in learning non-stationary data have analyzed such cases where both labeled and unlabeled instances are received at every time step and/or in regular intervals; however, to the best of our knowledge, no work has investigated the case where labeled instances are received only at the initial time step, followed by unlabeled instances provided in subsequent time steps. In this proof-of-concept work, we propose a new framework for learning in a non-stationary environment that provides only unlabeled data after the initial time step, to which we refer to as initially labeled environment. The proposed framework generates labels for previously unlabeled data at each time step to be\u00a0\u2026", "num_citations": "23\n", "authors": ["1070"]}
{"title": "Learn++: an incremental learning algorithm for multilayer perceptron networks\n", "abstract": " We introduce a supervised learning algorithm that gives neural network classification algorithms the capability of learning incrementally from new data without forgetting what has been learned in earlier training sessions. Schapire's (1990) boosting algorithm, originally intended for improving the accuracy of weak learners, has been modified to be used in an incremental learning setting. The algorithm is based on generating a number of hypotheses using different distributions of the training data and combining these hypotheses using a weighted majority voting. This scheme allows the classifier previously trained with a training database, to learn from new data when the original data is no longer available, even when new classes are introduced. Initial results on incremental training of multilayer perceptron networks on synthetic as well as real-world data are presented in this paper.", "num_citations": "22\n", "authors": ["1070"]}
{"title": "Functional near-infrared spectroscopy and electroencephalography: a multimodal imaging approach\n", "abstract": " Although neuroimaging has greatly expanded our knowledge about the brain-behavior relation, combining multiple neuroimaging modalities with complementing strengths can overcome some limitations encountered when using a single modality. Valuable candidates for a multimodal approach are functional near-infrared spectroscopy (fNIRS) and electroencephalography (EEG). fNIRS is an imaging technology that localizes hemodynamic changes within the cortex. However, hemodynamic activation is an intrinsically slow process. On the other hand, EEG has excellent time resolution by directly measuring the manifestation of the brain electrical activity at the scalp. Based on their complementary strengths, the integration of fNIRS and EEG may provide higher spatiotemporal resolution than either method alone. In this effort, we integrate fNIRS and EEG to evaluate the behavioral performance of six healthy\u00a0\u2026", "num_citations": "20\n", "authors": ["1070"]}
{"title": "An ensemble approach for data fusion with Learn++\n", "abstract": " We have recently introduced Learn++ as an incremental learning algorithm capable of learning additional data that may later become available. The strength of Learn++ lies with its ability to learn new data without forgetting previously acquired knowledge and without requiring access to any of the previously seen data, even when the new data introduce new classes. Learn++, inspired in part by AdaBoost, achieves incremental learning through generating an ensemble of classifiers for each new dataset that becomes available and then combining them through weighted majority voting with a distribution update rule modified for incremental learning of new classes. We have recently discovered that Learn++ also provides a practical and a general purpose approach for multisensor and/or multimodality data fusion. In this paper, we present Learn++ as an addition to the new breed of classifier fusion algorithms\u00a0\u2026", "num_citations": "20\n", "authors": ["1070"]}
{"title": "Attack strength vs. detectability dilemma in adversarial machine learning\n", "abstract": " As the prevalence and everyday use of machine learning algorithms, along with our reliance on these algorithms grow dramatically, so do the efforts to attack and undermine these algorithms with malicious intent, resulting in a growing interest in adversarial machine learning. A number of approaches have been developed that can render a machine learning algorithm ineffective through poisoning or other types of attacks. Most attack algorithms typically use sophisticated optimization approaches, whose objective function is designed to cause maximum damage to accuracy or performance of the algorithm with respect to some task. In this effort, we show that while such an objective function is indeed brutally effective in causing maximum damage on an embedded feature selection task, it often results in an attack mechanism that can be easily detected with an embarrassingly simple novelty or outlier detection\u00a0\u2026", "num_citations": "19\n", "authors": ["1070"]}
{"title": "An ensemble technique to handle missing data from sensors\n", "abstract": " Automated classification is often used in advanced systems to monitor system events. All data, and hence features from all sensors, must be present in order to make a meaningful classification. An ensemble approach, Learn++. MF, was recently introduced that allows classification with up to 10% of feature missing, where several classifiers are trained on random subsets of the available sensor data. Given an instance with missing features, only those classifiers trained with the available features are then used in classification. In this paper, we present a modified approach that accommodates up to 30% missing features along with the effect of varying algorithm parameters.", "num_citations": "17\n", "authors": ["1070"]}
{"title": "Ensemble of classifiers based incremental learning with dynamic voting weight update\n", "abstract": " An incremental learning algorithm based on weighted majority voting of an ensemble of classifiers is introduced for supervised neural networks, where the voting weights are updated dynamically based on the current test input of unknown class. The algorithm's dynamic voting weight update feature is an enhancement to our previously introduced incremental learning algorithm, Learn++. The algorithm is capable of incrementally learning new information from additional datasets that may later become available, even when the new datasets include instances from additional classes that were not previously seen. Furthermore, the algorithm retains formerly acquired knowledge without requiring access to datasets used earlier, attaining a delicate balance on the stability-plasticity dilemma. The algorithm creates additional ensembles of classifiers based on an iteratively updated distribution function on the training data\u00a0\u2026", "num_citations": "17\n", "authors": ["1070"]}
{"title": "Machine learning analysis of digital clock drawing test performance for differential classification of mild cognitive impairment subtypes versus Alzheimer\u2019s disease\n", "abstract": " Objective:To determine how well machine learning algorithms can classify mild cognitive impairment (MCI) subtypes and Alzheimer\u2019s disease (AD) using features obtained from the digital Clock Drawing Test (dCDT).Methods:dCDT protocols were administered to 163 patients diagnosed with AD(n = 59), amnestic MCI (aMCI; n = 26), combined mixed/dysexecutive MCI (mixed/dys MCI; n = 43), and patients without MCI (non-MCI; n = 35) using standard clock drawing command and copy procedures, that is, draw the face of the clock, put in all of the numbers, and set the hands for \u201c10 after 11.\u201d A digital pen and custom software recorded patient\u2019s drawings. Three hundred and fifty features were evaluated for maximum information/minimum redundancy. The best subset of features was used to train classification models to determine diagnostic accuracy.Results:Neural network employing information theoretic feature\u00a0\u2026", "num_citations": "16\n", "authors": ["1070"]}
{"title": "Model comparison for automatic characterization and classification of average ERPs using visual oddball paradigm\n", "abstract": " ObjectiveTo determine whether automated classifiers can be used for correctly identifying target categorization responses from averaged event-related potentials (ERPs) along with identifying appropriate features and classification models for computer-assisted investigation of attentional processes.MethodsERPs were recorded during a target categorization task. Automated classification of average target ERPs versus average non-target ERPs was performed by extracting different combinations of features from the P300 and N200 components, which were used to train six classifiers: Euclidean classifier (EC), Mahalanobis discriminant (MD), quadratic classifier (QC), Fisher linear discriminant (FLD), multi-layer perceptron neural network (MLP) and support vector machine (SVM).ResultsThe best classification performance (accuracy: 91\u201392%; sensitivity: 85\u201386%; specificity: 95\u201399%) was provided by QC, MLP, SVM\u00a0\u2026", "num_citations": "16\n", "authors": ["1070"]}
{"title": "Random feature subset selection for ensemble based classification of data with missing features\n", "abstract": " We report on our recent progress in developing an ensemble of classifiers based algorithm for addressing the missing feature problem. Inspired in part by the random subspace method, and in part by an AdaBoost type distribution update rule for creating a sequence of classifiers, the proposed algorithm generates an ensemble of classifiers, each trained on a different subset of the available features. Then, an instance with missing features is classified using only those classifiers whose training dataset did not include the currently missing features. Within this framework, we experiment with several bootstrap sampling strategies each using a slightly different distribution update rule. We also analyze the effect of the algorithm\u2019s primary free parameter (the number of features used to train each classifier) on its performance. We show that the algorithm is able to accommodate data with up to 30% missing features\u00a0\u2026", "num_citations": "16\n", "authors": ["1070"]}
{"title": "Ensemble based data fusion for early diagnosis of Alzheimer's disease\n", "abstract": " We describe an ensemble of classifiers based data fusion approach to combine information from two sources, believed to contain complimentary information, for early diagnosis of Alzheimer's disease. Specifically, we use the event related potentials recorded from the Pz and Cz electrodes of the EEG, which are further analyzed using multiresolution wavelet analysis. The proposed data fusion approach includes generating multiple classifiers trained with strategically selected subsets of the training data from each source, which are then combined through a weighted majority voting. Several factors set this study apart from similar prior efforts: we use a larger cohort, specifically target early diagnosis of the disease, use an ensemble based approach rather then a single classifier, and most importantly, we combine information from multiple sources, rather then using a single modality. We present promising results\u00a0\u2026", "num_citations": "16\n", "authors": ["1070"]}
{"title": "Wavelet analysis of event related potentials for early diagnosis of Alzheimer\u2019s disease\n", "abstract": " Alzheimer\u2019s disease, a neurological disorder claiming hundreds of thousands of lives every year, is the most common of all cortical dementias. Neurologists usually identify the disease from various symptoms; however, misdiagnosis is not uncommon. An autopsy is the only method for a definite diagnosis. Additional techniques to increase the accuracy of ante-mortem diagnoses are therefore necessary. In this study, evoked potentials of the electroencephalograms (EEGs) of a group of patients were analyzed, half of whom had been diagnosed with early Alzheimer\u2019s disease. The EEGs were analyzed and processed using multiresolution wavelet analysis techniques, and processed signals were then used to train a neural network to distinguish the signals that belonged to patients with Alzheimer\u2019s disease from those that belonged to patients without Alzheimer\u2019s disease. We discuss why wavelet analysis is\u00a0\u2026", "num_citations": "16\n", "authors": ["1070"]}
{"title": "Neural networks for ultrasonic detection of intergranular stress corrosion cracking\n", "abstract": " Accurate and consistent determination of flawed regions in piping is becoming increasingly important as nuclear power plants age and repair costs increase. Automatic signal classification schemes have the potential to provide consistent and accurate interpretation of inspection data. The feasibility of employing neural network based signal classification systems for the interpretation of ultrasonic weld inspection signals has been demonstrated as part of this work. A windows-based software package was developed. The analysis software uses two techniques, namely, principal component analysis and discrete wavelet transform (DWT) analysis for interpreting A-scan and C-scan image data. The analysis is frequency independent and uses spatial orientation information during processing. The C-scan images contained inspection data from intergranular stress corrosion cracking (IGSCC) samples and were generated using manually acquired data and data from automated scanners at inspection frequencies of 2.25 and 5 MHz. The neural network was trained with signals from the training database and validated by scanning austenitic pipe sections containing IGSCC that had been removed from service. All of the IGSCC was detected indicating the value of using neural networks for automated ultrasonic data analysis in the near future.", "num_citations": "16\n", "authors": ["1070"]}
{"title": "Quantifying the limited and gradual concept drift assumption\n", "abstract": " Nonstationary environments, where underlying distributions change over time, are becoming increasingly common in real-world applications. A specific example of such an environment is concept drift, where the joint probability distributions of observed data drift over time. Such environments call for a model that can update its parameters to adapt to the changing environment. An extreme case of this scenario, referred to as extreme verification latency, is where labeled data are only available at initialization, with unlabeled data becoming available in a streaming fashion thereafter. In such a scenario, the classifier must update its hypothesis based on only unlabeled data drawn from the drifting distributions. In our prior work, we described a framework, called COMPOSE, that works well in this type of environment, provided that the data distributions experience limited (or gradual) drift. Limited drift assumption is\u00a0\u2026", "num_citations": "15\n", "authors": ["1070"]}
{"title": "EEG and MRI data fusion for early diagnosis of Alzheimer's disease\n", "abstract": " The prevalence of Alzheimer's disease (AD) is rising alarmingly as the average age of our population increases. There is no treatment to halt or slow the pathology responsible for AD, however, new drugs are promising to reduce the rate of progression. On the other hand, the efficacy of these new medications critically depends on our ability to diagnose AD at the earliest stage. Currently AD is diagnosed through longitudinal clinical evaluations, which are available only at specialized dementia clinics, hence beyond financial and geographic reach of most patients. Automated diagnosis tools that can be made available to community hospitals would therefore be very beneficial. To that end, we have previously shown that the event related potentials obtained from different scalp locations can be effectively used for early diagnosis of AD using an ensemble of classifiers based decision fusion approach. In this study, we\u00a0\u2026", "num_citations": "15\n", "authors": ["1070"]}
{"title": "Margin-based discriminant dimensionality reduction for visual recognition\n", "abstract": " Nearest neighbour classifiers and related kernel methods often perform poorly in high dimensional problems because it is infeasible to include enough training samples to cover the class regions densely. In such cases, test samples often fall into gaps between training samples where the nearest neighbours are too distant to be good indicators of class membership. One solution is to project the data onto a discriminative lower dimensional subspace. We propose a gap-resistant nonparametric method for finding such subspaces: first the gaps are filled by building a convex model of the region spanned by each class - we test the affine and convex hulls and the bounding disk of the class training samples - then a set of highly discriminative directions is found by building and decomposing a scatter matrix of weighted displacement vectors from training examples to nearby rival class regions. The weights are chosen to\u00a0\u2026", "num_citations": "15\n", "authors": ["1070"]}
{"title": "A generalized likelihood ratio technique for automated analysis of bobbin coil eddy current data\n", "abstract": " This paper presents a generalized likelihood ratio technique for detection of defect locations from bobbin coil eddy current data. First a Neyman\u2013Pearson (NP) decision rule for detection of known random signals (in presence of noise) is discussed. The result is then generalized to the problem of detection of unknown random signals that are commonly found in bobbin coil eddy current data. The performance of the proposed detection technique is tested on several real world data sets collected from the steam generator tubes of nuclear power plants. The experimental results indicate that the method is quite promising and useful for automated processing and classification of eddy current data.", "num_citations": "15\n", "authors": ["1070"]}
{"title": "Active learning in nonstationary environments\n", "abstract": " Increasing number of practical applications that involve streaming nonstationary data have led to a recent surge in algorithms designed to learn from such data. One challenging version of this problem that has not received as much attention, however, is learning streaming nonstationary data when a small initial set of data are labeled, with unlabeled data being available thereafter. We have recently introduced the COMPOSE algorithm for learning in such scenarios, which we refer to as initially labeled nonstationary streaming data. COMPOSE works remarkably well, however it requires limited (gradual) drift, and cannot address special cases such as introduction of a new class or significant overlap of existing classes, as such scenarios cannot be learned without additional labeled data. Scenarios that provide occasional or periodic limited labeled data are not uncommon, however, for which many of COMPOSE's\u00a0\u2026", "num_citations": "14\n", "authors": ["1070"]}
{"title": "Discovering the unknown: improving detection of novel species and genera from short reads\n", "abstract": " High-throughput sequencing technologies enable metagenome profiling, simultaneous sequencing of multiple microbial species present within an environmental sample. Since metagenomic data includes sequence fragments (\u201creads\u201d) from organisms that are absent from any database, new algorithms must be developed for the identification and annotation of novel sequence fragments. Homology-based techniques have been modified to detect novel species and genera, but, composition-based methods, have not been adapted. We develop a detection technique that can discriminate between \u201cknown\u201d and \u201cunknown\u201d taxa, which can be used with composition-based methods, as well as a hybrid method. Unlike previous studies, we rigorously evaluate all algorithms for their ability to detect novel taxa.  First, we show that the integration of a detector with a composition-based method performs significantly better than homology-based methods for the detection of novel species and genera, with best performance at finer taxonomic resolutions. Most importantly, we evaluate all the algorithms by introducing an \u201cunknown\u201d class and show that the modified version of PhymmBL has similar or better overall classification performance than the other modified algorithms, especially for the species-level and ultrashort reads. Finally, we evaluate theperformance of several algorithms on a real acid mine drainage dataset.", "num_citations": "14\n", "authors": ["1070"]}
{"title": "Fuzzy ARTMAP network with evolutionary learning\n", "abstract": " Neural networks, particularly the multilayer perceptron, have been used extensively in automated signal classification systems with classification accuracy as the figure of merit. Three important issues that can enhance the utility of these systems are (i) incremental learning, (ii) confidence or reliability measures and (iii) performance improvement through continual learning. This paper investigates these issues using a fuzzy ARTMAP network. A hypothesis testing based algorithm is developed for computing reliability measures, which are fed back to the network for retraining and performance improvement. Implementation results on ultrasonic data are presented.", "num_citations": "14\n", "authors": ["1070"]}
{"title": "Learning under extreme verification latency quickly: Fast compose\n", "abstract": " One of the more challenging real-world problems in computational intelligence is to learn from non-stationary streaming data, also known as concept drift. Perhaps even a more challenging version of this scenario is when - following a small set of initial labeled data - the data stream consists of unlabeled data only. Such a scenario is typically referred to as learning in initially labeled nonstationary environment, or simply as extreme verification latency (EVL). In our prior work, we described a framework, called COMPOSE (COMPacted Object Sample Extraction) that works well in this type of environment, provided that the data distributions experience limited drift. The central premise behind COMPOSE is core support extraction, in which \u03b1-shapes or density estimation is used to extract the most representative instances - the core supports that typically lie in the center of the feature space for each class - to be used as\u00a0\u2026", "num_citations": "13\n", "authors": ["1070"]}
{"title": "Can AdaBoost.M1 Learn Incrementally? A Comparison to Learn\u2009+\u2009+\u2009 Under Different Combination Rules\n", "abstract": " We had previously introduced Learn\u2009+\u2009+\u2009, inspired in part by the ensemble based AdaBoost algorithm, for incrementally learning from new data, including new concept classes, without forgetting what had been previously learned. In this effort, we compare the incremental learning performance of Learn\u2009+\u2009+\u2009 and AdaBoost under several combination schemes, including their native, weighted majority voting. We show on several databases that changing AdaBoost\u2019s distribution update rule from hypothesis based update to ensemble based update allows significantly more efficient incremental learning ability, regardless of the combination rule used to combine the classifiers.", "num_citations": "13\n", "authors": ["1070"]}
{"title": "Combining classifiers for multisensor data fusion\n", "abstract": " Learn++ was recently introduced as an ensemble of classifiers based incremental learning algorithm, capable of retaining formerly acquired knowledge while learning novel information content from new datasets without requiring access to any of the previously seen data. In this contribution, we discuss the conceptual similarity between incremental learning and data fusion, the latter also requiring learning from new data, albeit composed of a different set of features. Following the technical description of the algorithm, we present our recent promising results on a realworld data fusion application of non-destructive evaluation for pipeline defect identification.", "num_citations": "13\n", "authors": ["1070"]}
{"title": "Stacked generalization for early diagnosis of Alzheimer's disease\n", "abstract": " The diagnosis of Alzheimer's disease (AD) at an early stage is a major concern due to growing number of elderly population affected by the disease, as well as the lack of a standard diagnosis procedure available to community clinics. Recent studies have used wavelets and other signal processing methods to analyze EEG signals in an attempt to find a non-invasive biomarker for AD. These studies had varying degrees of success, in part due to small cohort size. In this study, multiresolution wavelet analysis is performed on event related potentials of the EEGs of a relatively larger cohort of 44 patients. Particular emphasis was on diagnosis at the earliest stage and feasibility of implementation in a community health clinic setting. Extracted features were then used to train an ensemble of classifiers based stacked generalization approach. We describe the approach, and present our promising preliminary results", "num_citations": "12\n", "authors": ["1070"]}
{"title": "Inductive learning based on rough set theory for medical decision making\n", "abstract": " This paper proposes an algorithm that uses inductive learning and rough set theory (ILRS) to analyze the clinical data available in a patient file (records). A typical patient file has unstructured (both descriptive and quantitative) information that is also uncertain and sometimes incomplete. Successful clinical treatments depend on correct medical diagnosis which determines the correct set of variables or features causing a certain pathology. Clinical applications are by no means the only applications that require decision-making with reasoning from a large and incomplete amount of information. We show that the proposed ILRS technique is able to reduce the available number of features into a smaller core set that precisely describes the information system. We can also quantitatively evaluate the level of dependence of the considered pathology, or decision feature, on a given set of condition features or attributes\u00a0\u2026", "num_citations": "11\n", "authors": ["1070"]}
{"title": "Core support extraction for learning from initially labeled nonstationary environments using compose\n", "abstract": " Learning in nonstationary environments, also called concept drift, requires an algorithm to track and learn from streaming data, drawn from a nonstationary (drifting) distribution. When data arrive continuously, a concept drift algorithm is required to maintain an up-to-date hypothesis that evolves with the changing environment. A more difficult problem that has received less attention, however, is learning from so-called initially labeled nonstationary environments, where the the environment provides only unlabeled data after initialization. Since the labels to such data never become available, learning in such a setting is also referred to as extreme verification latency, where the algorithm must only use unlabeled data to keep the hypothesis current. In this contribution, we analyze COMPOSE, a framework recently proposed for learning in such environments. One of the central processes of COMPOSE is core support\u00a0\u2026", "num_citations": "11\n", "authors": ["1070"]}
{"title": "Reducing the effect of out-voting problem in ensemble based incremental support vector machines\n", "abstract": " Although Support Vector Machines (SVMs) have been successfully applied to solve a large number of classification and regression problems, they suffer from the catastrophic forgetting phenomenon. In our previous work, integrating the SVM classifiers into an ensemble framework using Learn++ (SVMLearn++) [1], we have shown that the SVM classifiers can in fact be equipped with the incremental learning capability. However, Learn++ suffers from an inherent out-voting problem: when asked to learn new classes, an unnecessarily large number of classifiers are generated to learn the new classes. In this paper, we propose a new ensemble based incremental learning approach using SVMs that is based on the incremental Learn++.MT algorithm. Experiments on the real-world and benchmark datasets show that the proposed approach can reduce the number of SVM classifiers generated, thus reduces the\u00a0\u2026", "num_citations": "11\n", "authors": ["1070"]}
{"title": "A framework for intelligent rocket test facilities with smart sensor elements\n", "abstract": " Smart sensors are a compelling addition to large-scale data acquisition networks due to the large number of issues they successfully address. For example, smart sensors simplify and speed installation configuration due to the basic information stored in their on-board TEDS that would otherwise need to be manually input to the data acquisition system. An emerging challenge is the development of smart systems, which rely on smart sensors to provide new levels of reliability. This paper reports on our on-going efforts to apply smart sensors to a rocket test facility. Key to our approach is the hierarchical organization of the intelligent rocket test facility as a system of three fundamental layers: system(s), processes, and smart sensors.", "num_citations": "11\n", "authors": ["1070"]}
{"title": "A virtual reality environment for multi-sensor data integration\n", "abstract": " Virtual reality (VR) has typically found applications in industrial design, rapid prototyping and advanced scientific visualization. In this paper, we investigate the use of VR for multi-sensor data integration. We attempt to demonstrate that multiple data types-graphical, functional and measurement can be effectively combined inside of a VR environment. This platform allows the user to rapidly sift through large and complex data sets and isolate features of interest. Furthermore, VR environments can be made to evolve based on system data and user input-this provides the ability to develop scenarios that can be used to make informed decisions. Results demonstrating the effectiveness of this approach are shown using the example of multi-sensor gas transmission pipeline inspection. This work is supported in part by the National Science Foundation award #0216348.", "num_citations": "11\n", "authors": ["1070"]}
{"title": "Algorithms for enhancing pattern separability, feature selection and incremental learning with applications to gas-sensing electronic nose systems\n", "abstract": " Three major issues in pattern recognition and data analysis have been addressed in this study and applied to the problem of identification of volatile organic compounds (VOC) for gas sensing applications. Various approaches have been proposed and discussed. These approaches are not only applicable to the VOC identification, but also to a variety of pattern recognition and data analysis problems. In particular,(1) enhancing pattern separability for challenging classification problems,(2) optimum feature selection problem, and (3) incremental learning for neural networks have been investigated.", "num_citations": "11\n", "authors": ["1070"]}
{"title": "Multiple Classifier Systems: 7th International Workshop, MCS 2007, Prague, Czech Republic, May 23-25, 2007, Proceedings\n", "abstract": " These proceedings are a record of the Multiple Classi? er Systems Workshop, MCS 2007, held at the Institute of Information Theory and Automation, Czech Academy of Sciences, Prague in May 2007. Being the seventh in a well-established series of meetings providing an international forum for the discussion of issues in multiple classi? er system design, the workshop achieved its objective of bringing together researchers from diverse communities (neural networks, pattern rec-nition, machine learning and statistics) concerned with this research topic. From more than 80 submissions, the Programme Committee selected 49-pers to create an interesting scienti? c programme. The special focus of MCS 2007 was on the application of multiple classi? er systems in biometrics. This part-ular application area exercises all aspects of multiple classi? er fusion, from-tramodal classi? er combination, through con? dence-based fusion, to multimodal biometric systems. The sponsorship of MCS 2007 by the European Union N-work of Excellence in Biometrics BioSecure and in Multimedia Understanding through Semantics, Computation and Learning MUSCLE and their assistance in selecting the contributions to the MCS 2007 programme consistent with this theme is gratefully acknowledged.", "num_citations": "10\n", "authors": ["1070"]}
{"title": "Ensemble techniques with weighted combination rules for early diagnosis of alzheimer's disease\n", "abstract": " As the population of our elderly suffering from Alzheimer's disease increases rapidly, the need for an accurate, inexpensive and non-intrusive diagnostic procedure that can be made available to local community clinics becomes an increasingly critical public health concern. We propose multiresolution analysis of the electroencephalogram (EEG) followed by an ensemble based classification designed to fuse data from different EEG channels. Several classifier combination rules, including competence based weighted combination have been implemented to evaluate their data fusion performance, with particular emphasis on diagnosing the disease at its earliest stages. Diagnostic performance of the proposed approach has been very promising.", "num_citations": "10\n", "authors": ["1070"]}
{"title": "Boosting based classification of event related potentials for early diagnosis of Alzheimer's disease\n", "abstract": " With the number of the elderly population affected by Alzheimer's disease (AD) rising, the need to find an accurate, inexpensive and non-intrusive procedure that can be made available to community healthcare providers for early diagnosis of Alzheimer's disease is becoming more and more urgent as a major health concern. Several recent studies have looked at analyzing electroencephalogram signals through the use of wavelets and neural networks. In this study, multiresolution wavelet analysis, coupled with the ensemble of classifiers based boosting algorithm is used on the P300 component of the event related potentials (ERP) to determine the feasibility of the approach as a diagnostic tool for early diagnosis of AD. The technique and its promising initial results are presented", "num_citations": "10\n", "authors": ["1070"]}
{"title": "Multiresolution wavelet analysis and ensemble of classifiers for early diagnosis of Alzheimer's disease\n", "abstract": " The diagnosis of Alzheimer's disease at an early stage is a major concern due to the growing number of the elderly population affected, as well as the lack of a standard and effective diagnosis procedure available to community healthcare providers. Recent studies have used wavelets and other signal processing methods to analyze EEG signals in an attempt to find a non-invasive biomarker for Alzheimer's disease and had varying degrees of success. These studies have traditionally used automated classifiers such as neural networks; however the use of an ensemble of classifiers has not been previously explored and may prove to be beneficial. In this study, multiresolution wavelet analysis is performed on event related potentials of the EEG which are then used with the ensemble of classifiers based Learn++ algorithm. We describe the approach, and present our promising preliminary results.", "num_citations": "10\n", "authors": ["1070"]}
{"title": "Automated segmentation and quantitative characterization of radiodense tissue in digitized mammograms\n", "abstract": " Mammography has emerged as a reliable non-invasive technique for the early detection of breast cancer\u2014the second leading cause of cancer-related mortality among American women. The radiographic appearance of the female breast consists of radiolucent (dark) regions due to fat and radiodense (light) regions due to connective and epithelial tissue. The amount of radiodense tissue can be used as a marker for predicting breast cancer risk. This paper presents the development of an algorithm for estimating the percentage of radiodense tissue in a digitized mammogram. The technique involves determining a dynamic threshold for segmenting radiodense indications in mammograms. Both the mammographic image and the threshold are modeled as Gaussian random variables. This work is intended to support a concurrent study at the Fox Chase Cancer Center (FCCC) exploring the association between\u00a0\u2026", "num_citations": "10\n", "authors": ["1070"]}
{"title": "Assessment strategies: feedback is too late!\n", "abstract": " The newly started Electrical and Computer Engineering program at Rowan University, USA, was visited by ABET's EAC for the first time in October 2000. As the authors prepared for their program evaluation under EC 2000, they explored novel mechanisms for assessing their curricular outcomes and \"closing the loop\" in an effort to develop ongoing methods for continuous program improvement. They were motivated by a strong desire to make the assessment process minimally intrusive, yet maximally effective. They have developed an assessment instrument called an X-File and a unique course called \"Clinic Consultant\"-both these mechanisms are closely related to each other. This paper describes their implementation efforts.", "num_citations": "10\n", "authors": ["1070"]}
{"title": "Adding adaptive intelligence to sensor systems with MASS\n", "abstract": " In sensor systems, tracking gradual drift in a non-stationary environment is a challenging problem. The problem, a phenomenon also known as concept drift, is made even more difficult if the streaming data only consists of unlabeled data after initialization. This scenario is typically referred to as extreme verification latency (EVL), and is common in many sensor applications. In our previous work, we introduced a framework called COMPOSE (COMPacted Object Sample Extraction), which can handle the extreme verification latency problem, provided that the drift is limited. In this paper, we introduce a derivative of COMPOSE called MASS (Modular Adaptive Sensor System) as a solution to extreme verification latency in streaming sensor data, regardless of the particular application. To analyze the performance of MASS, the classification accuracy and execution time were compared to several variations of COMPOSE\u00a0\u2026", "num_citations": "8\n", "authors": ["1070"]}
{"title": "Constrained state estimation in particle filters\n", "abstract": " Dynamical systems are often required to satisfy certain constraints arising from basic physical laws, mathematical properties or geometric considerations. Incorporating constraints improves the performance of state estimation and increases the accuracy compared to unconstrained estimation. Particle filters (PF) have gained popularity within the signal processing community, thanks to their asymptotically optimal estimation for nonlinear and non-Gaussian state-space models. However, their constrained formulation has emerged only very recently; and the developments to incorporate state constraints in particle filters have mainly relied on constraining all particles of the PF. This approach is termed Pointwise or Particle Density Truncation (PDT). In this paper, we show that PDT constrains the posterior density of the state rather than the conditional mean estimate, which leads to more stringent and possibly completely\u00a0\u2026", "num_citations": "8\n", "authors": ["1070"]}
{"title": "Diagnostic utility of EEG based biomarkers for Alzheimer's disease\n", "abstract": " Alzheimer's disease (AD) is a neurodegenerative disease whose definitive diagnosis is only possible via autopsy. Currently used diagnostic approaches include the traditional neuropsychological tests, and recently more objective biomarkers, such as those obtained from cerebral spinal fluid (CSF), magnetic imaging resonance (MRI), and positron emission tomography (PET). Electroencephalography (EEG), a lower cost and non-invasive alternative, has been previously tried but with mixed success. In this effort, we attempt a more comprehensive analysis and comparison of machine learning approaches using EEG based features to determine diagnostic utility of the EEG. We compared support vector machine (SVM), na\u00efve Bayes, multilayer perceptron (MLP), CART trees, k-nearest neighbor (kNN), and AdaBoost on various sets of features extracted from event related potentials (ERP) of the EEG. Our analysis\u00a0\u2026", "num_citations": "8\n", "authors": ["1070"]}
{"title": "A combined pattern separability and two-tiered classification approach for identification of binary mixtures of VOCs\n", "abstract": " Several classification techniques have been developed with varying degrees of success for automated identification of VOCs, however, the problem becomes considerably more challenging when more than one VOC is present. The reason is two-fold: first, the response of the sensors to certain VOCs may be too strong and mask the response of the sensors to other VOCs in the environment; and second the responses of the sensors to VOCs may not have enough separability information if the specificity of the sensors is not adequate. We propose the following procedures for these two issues in identification of binary mixtures of VOCs: a nonlinear cluster transformation technique or nonparametric discriminant analysis to increase pattern separability, followed by a two-tier classification to aid in identification of dominant and secondary VOCs separately. Results demonstrate the feasibility of the combined approach.", "num_citations": "8\n", "authors": ["1070"]}
{"title": "Confidence estimation using the incremental learning algorithm, Learn++\n", "abstract": " Pattern recognition problems span a broad range of applications, where each application has its own tolerance on classification error. The varying levels of risk associated with many pattern recognition applications indicate the need for an algorithm with the ability to measure its own confidence. In this work, the supervised incremental learning algorithm Learn++ [1], which exploits the synergistic power of an ensemble of classifiers, is further developed to add the capability of assessing its own confidence using a weighted exponential majority voting technique.", "num_citations": "8\n", "authors": ["1070"]}
{"title": "Isolated vowel recognition using linear predictive features and neural network classifier fusion\n", "abstract": " In this work, various linear predictive feature vectors were used to train three different automated neural networks type classifiers for the task of isolated vowel recognition. The features used included linear prediction filter coefficients, reflection coefficients, log area ratios, and the linear predictive cepstrum. The three neural network classifiers used are the multilayer perceptron, radial basis function and the probabilistic neural network. The linear predictive cepstrum of dimension 12 is the best feature especially when training is done on clean speech and testing is done on noisy speech. Three different classifier fusion strategies (linear fusion, majority voting and weighted majority voting) were found to improve the performance. Linear fusion with varying weights is the best method and is most robust to noise.", "num_citations": "8\n", "authors": ["1070"]}
{"title": "Open-ended design and performance evaluation of a biometric speaker identification system\n", "abstract": " It is very important that biometrics education, particularly at the undergraduate level, keeps pace with the rapidly growing global market. This paper describes a senior level project in speech biometrics that fits in a variety of courses in order to reach out to many students. The project has broad learning outcomes, namely, enhanced application of math skills, software implementation skills, interest in biometrics, ability to carry out open-ended design and communication skills. Assessment results based on the analysis of the success of the students (refereed publications and enrolling in graduate programs), student surveys related to the learning outcomes and a target versus control group survey show that the project was successful.", "num_citations": "7\n", "authors": ["1070"]}
{"title": "ERP based decision fusion for AD diagnosis across cohorts\n", "abstract": " As the average life expectancy increases, particularly in developing countries, prevalence of neurodegenerative diseases has also increased. This trend is especially alarming for Alzheimer's disease (AD); as there is no cure to stop or reverse the effects of AD. However, recent pharmacological advances can slow the progression of AD, but only if AD is diagnosed at early stages. We have previously introduced an ensemble of classifiers based approach for combining event related potentials obtained from different electrode locations as an effective approach for early diagnosis of AD. We further expand this approach and analyze its robustness and stability in two ways: comparing the diagnostic accuracy on hand selected and cleaned data vs. standard automated preprocessing, but more importantly, comparing the diagnostic accuracy on two different cohorts, whose data are collected under different settings: a\u00a0\u2026", "num_citations": "7\n", "authors": ["1070"]}
{"title": "A multiple classifier approach for multisensor data fusion\n", "abstract": " In many applications of pattern recognition and automated identification, it is not uncommon for data obtained from different sensors monitoring a physical phenomenon to provide complimentary information. In such applications, data fusion-a suitable combination of the complimentary information-can offer more insight into the phenomenon than any of the individual data sources. We have previously introduced Learn/sup ++/, an ensemble based approach, as an effective automated classification algorithm that is capable of learning incrementally. Recognizing the conceptual similarity between data fusion and incremental learning, our approach is then to employ an ensemble of classifiers generated by using all of the data sources available, and strategically combine their outputs. We have observed that the prediction ability of such a system was significantly and consistently better than that of a decision based on a\u00a0\u2026", "num_citations": "7\n", "authors": ["1070"]}
{"title": "Multiple Classifier Systems: 6th International Workshop, MCS 2005, Seaside, CA, USA, June 13-15, 2005, Proceedings\n", "abstract": " This book constitutes the refereed proceedings of the 6th International Workshop on Multiple Classifier Systems, MCS 2005, held in Seaside, CA, USA in June 2005. The 42 revised full papers presented were carefully reviewed and are organized in topical sections on boosting, combination methods, design of ensembles, performance analysis, and applications. They exemplify significant advances in the theory, algorithms, and applications of multiple classifier systems-bringing the different scientific communities together.", "num_citations": "7\n", "authors": ["1070"]}
{"title": "LEVELIW: Learning extreme verification latency with importance weighting\n", "abstract": " Nonstationary streaming data are characterized by changes in the underlying distribution between subsequent time steps. Learning in such environments becomes even more challenging when labeled data are available only at the initial time step, and the algorithm is provided unlabeled data thereafter, a scenario referred to as extreme verification latency. Our previously introduced COMPOSE framework works very well in such settings. COMPOSE is a semi-supervised approach that iteratively labels strategically chosen instances of the next time step using the instances it labeled in the previous time step. COMPOSE originally assumed a significant distribution overlap at consecutive time steps, allowing instances lying in the center of the feature space to be used as the most representative labeled instances from current time step to help label the new data at the next time step. Such an assumption is also inherent\u00a0\u2026", "num_citations": "6\n", "authors": ["1070"]}
{"title": "Introducing multidisciplinary novel content through laboratory exercises on real world applications\n", "abstract": " NOTE: The first page of text has been automatically extracted and included below in lieu of an abstract", "num_citations": "6\n", "authors": ["1070"]}
{"title": "A data fusion system for the nondestructive evaluation of non-piggable pipes\n", "abstract": " The objectives of this research project are:(1) To design sensor data fusion algorithms that can synergistically combine defect related information from heterogeneous sensors used in gas pipeline inspection for reliably and accurately predicting the condition of the pipe-wall.(2) To develop efficient data management techniques for signals obtained during multisensor interrogation of a gas pipeline. During this reporting period, Rowan University designed, developed and exercised multisensor data fusion algorithms for identifying defect related information present in magnetic flux leakage, ultrasonic testing, thermal imaging and acoustic emission nondestructive evaluation signatures of a test-specimen suite representative of benign and anomalous indications in gas transmission pipelines. Specifically, the algorithms presented in the earlier reports were augmented to predict information related to defect depth (severity).", "num_citations": "6\n", "authors": ["1070"]}
{"title": "Dynamic thresholding for automated analysis of bobbin probe eddy current data\n", "abstract": " An automated algorithm is presented for the analysis and classification of eddy current bobbin probe data obtained from nuclear power plant steam generator tubes (SGT). This algorithm attempts to find a balance between the two seemingly conflicting requirements of SGT eddy current data analysis, namely, detecting and identifying as many of the actual defects as possible, whilst limiting the number of false alarms to a minimum. Initial results presented in this paper look very promising.", "num_citations": "6\n", "authors": ["1070"]}
{"title": "Learn++: an incremental learning algorithm based on psycho-physiological models of learning\n", "abstract": " An incremental learning algorithm, Learn++, which allows supervised classification algorithms to learn from new data without forgetting previously acquired knowledge, is introduced. Learn++ is based on generating multiple classifiers using strategically chosen distributions of the training data and combining these classifiers through weighted majority voting. Learn++ shares various notions with psycho-physiological models of learning. The Learn++ algorithm, simulation results, and how the algorithm is related to various concepts in psycho-physiological learning models are discussed. The algorithm was tested on a variety of real world and synthetic datasets. Two sets of results are presented for optical handwritten digit recognition and gas sensing.", "num_citations": "6\n", "authors": ["1070"]}
{"title": "Vertical Integration of Biometrics Across the Curriculum: Case Study of Speaker, Face and Iris Recognition\n", "abstract": " Vertical integration is a powerful curricular tool that allows students to better appreciate the interconnections among the concepts acquired and learned in different courses. It can be used to bring a modern topic at all levels of the undergraduate curriculum with little additional resources. This paper gives a brief survey of various vertical integration efforts and describes one effort at integrating biometrics throughout the curriculum. The focus is on three senior level projects (speaker, face and iris recognition) that not only rely on vertical integration but also reinforce design, software skills and knowledge of STEM concepts. The freshman through junior levels are also described. The assessment results show that students acquire specific learning outcomes and perceive the value of vertical integration.", "num_citations": "5\n", "authors": ["1070"]}
{"title": "A freshman level module in biometric systems\n", "abstract": " It is very important and challenging to teach modern topics at the freshman level. This paper describes a biometrics module that fits into any introductory freshman engineering course. The project has broad learning outcomes, namely, enhanced application of math skills, software implementation skills, interest in biometrics and comprehension of ethical issues. Assessment results based on the analysis of student surveys related to the learning outcomes and vertical integration show that the project was successful.", "num_citations": "5\n", "authors": ["1070"]}
{"title": "Combined fNIRS and EEG for the assessment of cognitive impairments following traumatic brain injury\n", "abstract": " A commonly observed consequence of traumatic brain injury (TBI) is cognitive impairement, whose assessment represents a considerable challenge.. Furthermore, while several neurorehabilitation strategies are available, the choice of a successful treatment still relies on behavioral observation, and little information is available about the physiological changes produced at the brain level by the specific intervention. The integration of neuroimaging and electrophysiological measures may be more objective and effective in the evaluation of cognitive impairments. This study evaluates the applicability of functional near-infrared spectroscopy (fNIRS) in combination with EEG for assessment of TBI induced attention and working memory impairments. fNIRS is an optical neuroimaging technology that detects changes in the hemodynamic response within the cortex. fNIRS is safe, cost effective and portable, allowing easy\u00a0\u2026", "num_citations": "5\n", "authors": ["1070"]}
{"title": "Comparison of ensemble techniques for incremental learning of new concept classes under hostile non-stationary environments\n", "abstract": " We have recently introduced Learn ++ , an incremental learning algorithm, inspired by the multiple classifiers structure of AdaBoost. Both algorithms generate an ensemble of classifiers trained on bootstrapped replicates of the training data, and the classifiers are then combined through a voting process. Learn ++ , however, generates additional ensembles as new data become available, and uses a different distribution update rule to resample the data. While AdaBoost was originally designed to improve the performance of a weak classifier, whether it can still achieve incremental learning through its ensemble structure is still an open question. In this paper, we compare the incremental learning ability of AdaBoost.M1 and Learn ++  under very hostile nonstationary learning environments, which may introduce new concept classes. We also compare the algorithms under several combination rules to determine which\u00a0\u2026", "num_citations": "5\n", "authors": ["1070"]}
{"title": "Ensemble of classifiers approach for NDT data fusion\n", "abstract": " Several measurement modalities have been developed over the years for various nondestructive testing and evaluation (NDT and E) applications, such as ultrasonic, magnetic flux leakage, and eddy current testing, all of which have been used extensively in pipeline defect identification. While it is generally believed that different testing modalities provide complementary information, only a single testing modality is typically used for a given application. This is part due to lack of effective, computationally feasible data fusion algorithms that are applicable to NDT and E signals. Such an algorithm capable of data fusion can combine information from two or more different sources of data, giving more insight and confidence to the data analysis than a decision that would otherwise be based on either of the sources alone. Learn++, previously introduced as an incremental learning algorithm, was applied to a NDT and E\u00a0\u2026", "num_citations": "5\n", "authors": ["1070"]}
{"title": "An architecture for intelligent systems based on smart sensors\n", "abstract": " Based on requirements for a next-generation rocket test facility, elements of a prototype IRTF have been implemented. A key component is distributed smart sensor elements integrated using a knowledgeware environment. One of the specific goals is to imbue sensors with the intelligence needed to perform self-diagnosis of health and to participate in a hierarchy of health determination at sensor, process, and system levels. The preliminary results provide the basis for future advanced development and validation using rocket test facilities at Stennis Space Center (SSC) 1. We have identified issues important to further development of health-enabled networks, which should be of interest to others working with smart sensors and intelligent health management systems.", "num_citations": "5\n", "authors": ["1070"]}
{"title": "A multi-sensor data fusion system for assessing the integrity of gas transmission pipelines\n", "abstract": " Accurate and reliable characterization the pipe-wall condition of gas transmission pipelines requires inspection using more than one method of non-destructive testing. This paper describes a suite of sensor data fusion algorithms that aims to synergistically combine information that is present not in heterogeneous sensors (for example, magnetic, ultrasonic and thermal). The objective of the data fusion algorithms is to improve the accuracy and reliability of pipeline monitoring by providing the location, size and shape of pipe-wall anomalies.", "num_citations": "5\n", "authors": ["1070"]}
{"title": "Composing a new ECE program: The first five years\n", "abstract": " The authors have developed a new Electrical and Computer Engineering (ECE) program at Rowan University, NJ, USA. The first class graduated in May 2000. Features include: a continuous engineering clinic sequence; a mixture of two-, three- and four-credit courses; and technology focus electives. Project-based instruction is employed as a tool for motivating students and to demonstrate the relevancy of material. Multidisciplinary courses provide the opportunity for students in different disciplines to work together. Some of the approaches-and lessons learned-of interest to other start-ups and programs considering transformation.", "num_citations": "5\n", "authors": ["1070"]}
{"title": "Vulnerability of covariate shift adaptation against malicious poisoning attacks\n", "abstract": " Adversarial machine learning has recently risen to prominence due to increased concerns over the vulnerability of machine learning algorithms to malicious attacks. While the impact of malicious poisoning attacks on some popular algorithms, such as deep neural networks, has been well researched, the vulnerability of other approaches has not yet been properly established. In this effort, we explore the vulnerability of unconstrained least squares importance fitting (uLSIF), an algorithm used for computing the importance ratio for covariate shift domain adaptation problems. The uLSIF algorithm is an accurate and efficient technique to compute the importance ratio; however, we show that the approach is susceptible to a poisoning attack, where an intelligent adversary - having full or partial access to the training data - can inject well crafted malicious samples into the training data, resulting in an incorrect estimation of\u00a0\u2026", "num_citations": "4\n", "authors": ["1070"]}
{"title": "Big data and situation-aware technology for smarter healthcare\n", "abstract": " ConclusionThe application of information technologies to the medical domain raises opportunities for the development of new diagnostics and treatments, making it a critical area of investigation. The editors gratefully acknowledge the many high quality submissions received, and the generous effort of all reviewers. We hope this special issue serves to spark new discussion, exploration and collaboration.", "num_citations": "4\n", "authors": ["1070"]}
{"title": "Integrating BME into ECE curriculum: an alternate approach for meeting the nation's need for qualified BME professionals\n", "abstract": " NOTE: The first page of text has been automatically extracted and included below in lieu of an abstract", "num_citations": "4\n", "authors": ["1070"]}
{"title": "Dynamic segmentation of breast tissue in digitized mammograms\n", "abstract": " The percentage of radiodense tissue in a mammogram has been used as a marker for determining breast cancer risk. In this paper, we present an image segmentation technique for identifying tissue and non-tissue regions of a digitized X-ray image. This procedure constitutes a vital step prior to subsequent processing for estimating the amount of radiodense tissue. The process involves the generation of a segmentation mask developed by using discrete wavelet transform techniques. Initial results have been promising, demonstrating the feasibility of the approach.", "num_citations": "4\n", "authors": ["1070"]}
{"title": "Incremental learning of ultrasonic weld inspection signals\n", "abstract": " In this paper, we present LEARN++, a new algorithm that allows existing classifiers to learn incrementally from new data without forgetting previously acquired knowledge. LEARN++ is based on generating multiple classifiers, each trained with a different subset of the training data and then combining them to form an ensemble of classifiers using weighted majority voting. The fundamental contribution of the algorithm lies in the manner in which the training data is partitioned. The results demonstrate the feasibility and effectiveness of the approach in learning from new data.", "num_citations": "4\n", "authors": ["1070"]}
{"title": "Nonlinear cluster transformations for increasing pattern separability\n", "abstract": " The objective of classification is to generate a nonlinear multidimensional decision boundary that partitions the pattern space into prescribed classes. However, these algorithms are successful only when the data is well distributed in their domain. In practice, patterns from different classes can be closely packed with significant overlap. Prior to classification, the data is generally preprocessed so that the intercluster to intracluster distance ratio is maximized. This paper discusses limitations of conventional approaches for preprocessing based on Fisher's linear discriminant, and proposes an intuitive nonlinear cluster transformation (NCT) that can be used for increasing the intercluster distances within a set of data points. A generalized regression neural network (GRNN) is used to learn the functional mapping between original clusters and transformed clusters. The performance of this proposed method was tested on a\u00a0\u2026", "num_citations": "4\n", "authors": ["1070"]}
{"title": "Time scaling and frequency invariant multiresolution analysis of ultrasonic NDE Signals\n", "abstract": " Nuclear power plant pipes are periodically inspected for possible cracks that occur in the heat-affected zones of welds. Intergranular stress corrosion cracks (IGSCC) are the most common type of cracks encountered particularly in stainless steel piping. Three major factors are required for the formation and propagation of IGSCCs, the tensile stress on the inner diameter of the weld region, a corrosive environment and a sensitized grain structure. When these flaws are not detected early enough, the consequences can be disastrous, and therefore the detection of IGSCCs is of significant interest to the nuclear industry.", "num_citations": "4\n", "authors": ["1070"]}
{"title": "Adversarial poisoning of importance weighting in domain adaptation\n", "abstract": " Domain adaptation techniques such as importance weighting modify the training data to better represent a different test data distribution, a process that may be particularly vulnerable to a malicious attack in an adversarial machine learning scenario. In this work, we explore the level of such vulnerability of importance weighting to poisoning attacks. Importance weighting, like other domain adaptation approaches, assumes that the distributions of training and test data are different but related. An intelligent adversary, having full or partial access to the training data, can take advantage of the expected difference between the distributions, and can inject well crafted malicious samples into the training data, resulting in an incorrect estimation of the importance ratio. In this work, we demonstrate the vulnerability of one of the simplest yet most effective approaches for directly estimating the importance ratio, namely, modifying\u00a0\u2026", "num_citations": "3\n", "authors": ["1070"]}
{"title": "Non-negative matrix factorization for non-parametric and unsupervised image clustering and segmentation\n", "abstract": " We propose a new non-parametric level set model for automatic image clustering and segmentation based on non-negative matrix factorization (NMF). We show that NMF: (i) clusters the image into distinct homogeneous regions and (ii) provides the local spatial distribution of each region within the image. Furthermore, NMF has a controllable resolution and can discover homogeneous regions as small as one pixel. Coupled with the level-set approach, NMF is an efficient method for image segmentation. The proposed model is unsupervised and relies on local histogram modeling to define an energy functional, whose optimization leads to the final segmentation. A unique and desirable feature of the proposed method is that it does not incorporate any spurious model parameters; hence, the optimization is performed only w.r.t level set functions. We apply the proposed Non-parametrIc Unsupervised SegmentatioN\u00a0\u2026", "num_citations": "3\n", "authors": ["1070"]}
{"title": "Active analog circuit design: Laboratory project and assessment\n", "abstract": " It is very important that undergraduate teaching of analog circuits be rigorous, involve a laboratory component and stimulate student interest. This paper describes a three week module on active circuits that incorporates circuit design, analysis and testing. The lectures are integrated with the laboratory component and all appropriate concepts in mathematics are covered. Assessment results are based on running the project at three universities, namely, Rowan, Bucknell and Tennessee State. Quantitative results based on student surveys, a concept inventory test and faculty formulated rubrics demonstrate the accomplishment of the learning outcomes.", "num_citations": "3\n", "authors": ["1070"]}
{"title": "Project-based Design of a Biometric Face Recognition System\n", "abstract": " Biometrics is the science of recognizing and authenticating people using their physiological features. Interest in biometrics has increased significantly after the 9/11 attacks. Border and immigration control, restricted access to facilities and information systems, cybersecurity, crime investigations and forensic analysis are just a few of the primary application areas of biometrics used by commercial, government and law enforcement agencies [1]. The biometrics market has grown from $2.7 billion in 2007 to an expectation of $7.1 billion in 2012, with a compound annual growth rate of 21.3 percent [2]. There is much research interest in different biometric systems, notably, face recognition. Face recognition systems have advantages including ease of use and implementation, low cost and high user acceptance [3]. In addition, they can be easily integrated (no special hardware except for a Web camera) with many devices including desktops, laptops, cell phones, wireless access points, iPhones, iPads and PDAs.There is an acute need for biometrics education at the undergraduate and graduate levels. Many institutions world-wide have an established graduate program in biometrics and offer senior level undergraduate elective courses [4][5] in the area. The University of West Virginia offers a Bachelor of Science in Biometric Systems. The US Naval Academy has a Biometrics Research Laboratory with an aim to enhance undergraduate biometrics education [5] where a senior undergraduate elective course on Biometric Signal Processing is offered that integrates lecture and laboratory experiences. Configuring a new undergraduate program and/or a new\u00a0\u2026", "num_citations": "3\n", "authors": ["1070"]}
{"title": "Random feature subset selection for analysis of data with missing features\n", "abstract": " We discuss an ensemble-of-classifiers based algorithm for the missing feature problem. The proposed approach is inspired in part by the random subspace method, and in part by the incremental learning algorithm, Learn ++ . The premise is to generate an adequately large number of classifiers, each trained on a different and random combination of features, drawn from an iteratively updated distribution. To classify an instance with missing features, only those classifiers whose training data did not include the currently missing feature are used. These classifiers are combined by using a majority voting combination rule to obtain the final classification of the given instance. We had previously presented preliminary results on a similar approach, which could handle up to 10% missing data. In this study, we expand our work to include different types of rules to update the distribution, and also examine the effect of the\u00a0\u2026", "num_citations": "3\n", "authors": ["1070"]}
{"title": "Bootstrap-inspired techniques in computational intelligence\n", "abstract": " We start with a brief review of the bootstrap-based approaches used in computational intelligence, where the primary parameter of interest is the true prediction error of a classifier on previously unseen data. We then describe how bootstrap-inspired techniques enabled development of ensemble-based algorithms and describe some of the more popular examples of such algorithms. These algorithms, which generate an ensemble of classifiers by training each classifier on a different bootstrap sample of the training data, have the unique ability to create a strong classifier from a collection of weak classifiers that can barely do better than random guessing. Our primary focus in this article, however, is some of the more challenging problems of computational intelligence that can also be addressed by bootstrap-inspired techniques, including incremental learning, data fusion, and the missing feature problem. In incremental learning, the goal is to learn novel and supplementary information from new data that later become available, even in such hostile learning environments that introduce new classes. In data fusion, we are interested in integrating complementary information into an existing classifier\u2019s knowledge base, particularly when such information comes from different sources. Finally, in the missing feature problem, the challenge is to classify data whose certain features (predictors) used to train the classifier are missing. The central theme in addressing each of these problems using ensemble-based systems is to generate an ensemble of diverse classifiers, where each classifier is trained on a strategically selected bootstrap sample of the\u00a0\u2026", "num_citations": "3\n", "authors": ["1070"]}
{"title": "Neural and decision theoretic approaches for the automated segmentation of radiodense tissue in digitized mammograms\n", "abstract": " Mammography is the best method available as a non\u2010invasive technique for the early detection of breast cancer. The radiographic appearance of the female breast consists of radiolucent (dark) regions due to fat and radiodense (light) regions due to connective and epithelial tissue. The amount of radiodense tissue can be used as a marker for predicting breast cancer risk. Previously, we have shown that the use of statistical models is a reliable technique for segmenting radiodense tissue. This paper presents improvements in the model that allow for further development of an automated system for segmentation of radiodense tissue. The segmentation algorithm employs a two\u2010step process. In the first step, segmentation of tissue and non\u2010tissue regions of a digitized X\u2010ray mammogram image are identified using a radial basis function neural network. The second step uses a constrained Neyman\u2010Pearson algorithm\u00a0\u2026", "num_citations": "3\n", "authors": ["1070"]}
{"title": "Resampling Techniques for Learning Under Extreme Verification Latency with Class Imbalance\n", "abstract": " A common, yet rarely addressed, real-world problem in computational intelligence applications is learning from non-stationary streaming data, where the underlying distribution of the data changes over time. This problem, also referred to as concept drift, is made even more challenging if, after initially receiving a small set of labeled data, the streaming data only consists of unlabeled data, requiring the learner to adapt to changing underlying distribution without the benefit of labeled data. This particular scenario is typically referred to as learning in initially labeled nonstationary environment, or as extreme verification latency (EVL), pointing to the fact that the label verification of the test data is indefinitely delayed. In our prior work, we have noted that current EVL algorithms - including the algorithm COMPOSE that we have developed - are largely unable to track changing distributions if the data drawn from those\u00a0\u2026", "num_citations": "2\n", "authors": ["1070"]}
{"title": "Special issue on learning in nonstationary and evolving environments\n", "abstract": " Sauf mention contraire ci-dessus, le contenu de cette notice bibliographique peut \u00eatre utilis\u00e9 dans le cadre d\u2019une licence CC BY 4.0 Inist-CNRS/Unless otherwise stated above, the content of this bibliographic record may be used under a CC BY 4.0 licence by Inist-CNRS/A menos que se haya se\u00f1alado antes, el contenido de este registro bibliogr\u00e1fico puede ser utilizado al amparo de una licencia CC BY 4.0 Inist-CNRS", "num_citations": "2\n", "authors": ["1070"]}
{"title": "Configuration and assessment of a senior level course in biometric systems\n", "abstract": " It is very important that modern topics be covered at the senior undergraduate level in order that students benefit from (1) advanced STEM concepts,(2) project based learning,(3) a systems level perspective and (4) real world applications. This will help students that proceed to graduate school and who take up employment in government or industry. This paper describes a senior level undergraduate course in biometrics, a multidisciplinary area that is highly relevant to society and which has a rapidly growing global market. The course objectives, broad learning outcomes and curricular plan are described. Assessment results based on the analysis of a concept inventory test and student surveys (target versus control group) related to the learning outcomes show that the course was very successful.", "num_citations": "2\n", "authors": ["1070"]}
{"title": "Neural network-based taxonomic clustering for metagenomics\n", "abstract": " Metagenomic studies inherently involve sampling genetic information from an environment potentially containing thousands of distinctly different microbial organisms. This genetic information is sequenced producing many short fragments (<;500 base pair (bp)); each is tentatively a small representative of the DNA coding structure. Any of the fragments may belong to any of the organisms in the sample, but the relationship is unknown a priori. Furthermore, most of these organisms have not been identified and correspondingly are not represented in any of the publicly available search databases. Our goal is to be able to predict the taxonomic classification of an organism based on the fragments obtained from an environmental sample that may include many (some previously unidentified) organisms. To elucidate the diversity and composition of the sample, we first use a supervised naive Bayes classifier to score the\u00a0\u2026", "num_citations": "2\n", "authors": ["1070"]}
{"title": "Combining multichannel ERP data for early diagnosis of Alzheimer's Disease\n", "abstract": " As the average age of our population increases, the prevalence of Alzheimer's Disease (AD), the most common form of dementia, has grown sharply. Current diagnosis of AD primarily uses longitudinal clinical evaluations and/or invasive lumbar punctures for CSF analysis, available only at specialized hospitals, which are generally outside of financial and geographical reach of most patients. We expand on our previous work and describe an ensemble of classifiers based approach that combines decision and data fusion techniques for the early diagnosis of AD using event related potentials (ERP) obtained in response to different audio stimuli. In this contribution, we specifically examine various feature set combinations, obtained from different EEG electrode locations and in response to different stimulus tones to illustrate the accuracy of such a system for AD diagnosis at the earliest stage on a clinically significant\u00a0\u2026", "num_citations": "2\n", "authors": ["1070"]}
{"title": "The Role of the Engineering Clinic in Promoting an Agile ECE Learning Environment\n", "abstract": " NOTE: The first page of text has been automatically extracted and included below in lieu of an abstract", "num_citations": "2\n", "authors": ["1070"]}
{"title": "Comparison of Pz, Fz and Cz event related potentials for the early diagnosis of Alzheimer's disease\n", "abstract": " Comparison of Pz, Fz and Cz event related potentials for the early diagnosis of Alzheimer's disease \u2014 Rowan University Skip to main navigation Skip to search Skip to main content Rowan University Logo Home Profiles Research Units Core Facilities Grants/Projects Research Output Prizes Press / Media Search by expertise, name or affiliation Comparison of Pz, Fz and Cz event related potentials for the early diagnosis of Alzheimer's disease Nicholas Stepenosky, Apostolos Topalis, Jennifer L. Frymiare, John Kounios, Christopher Clark, Robi Polikar Electrical Engineering Research output: Chapter in Book/Report/Conference proceeding \u203a Conference contribution Overview Fingerprint Original language English (US) Title of host publication Proceedings of the 2005 Summer Bioengineering Conference, 2005 SBC Pages 1480-1481 Number of pages 2 State Published - Dec 1 2005 Event 2005 Summer \u2026", "num_citations": "2\n", "authors": ["1070"]}
{"title": "A modified Neyman-Pearson technique for radiodense tissue estimation in digitized mammograms\n", "abstract": " The percentage of radiodense tissue in the breast has been shown to be a reliable marker for breast cancer risk. In this paper, we present an image processing technique for estimating radiodense tissue in digitized mammograms. First, the mammogram is segmented into tissue and nontissue regions. This segmentation process involves the generation of a segmentation mask that is developed using a radial basis function neural network. Subsequently, the image is processed for estimating the amount of radiodense tissue. The estimation process involves the generation of a modified Neyman-Pearson threshold to segment the radiodense and radiolucent tissue. Typical research results are presented-these have been independently validated by a radiologist.", "num_citations": "2\n", "authors": ["1070"]}
{"title": "Incremental learning of NDE signals with confidence estimation\n", "abstract": " An incremental learning algorithm, Learn++, is introduced, for learning additional information from new data, even when new data include examples of previously unseen classes. Learn++ takes advantage of synergistic generalization performance of an ensemble of simple classifiers, each trained with a strategically chosen subset of the training database. As new data become available, new classifiers are generated, which are then combined through weighted majority voting. The weights are determined based on the estimated likelihood of each classifier to correctly classify an instance of unknown class. The voting procedure also allows Learn++ to estimate the confidence level in its own decision.", "num_citations": "2\n", "authors": ["1070"]}
{"title": "OpinionRank: Extracting Ground Truth Labels from Unreliable Expert Opinions with Graph-Based Spectral Ranking\n", "abstract": " As larger and more comprehensive datasets become standard in contemporary machine learning, it becomes increasingly more difficult to obtain reliable, trustworthy label information with which to train sophisticated models. To address this problem, crowdsourcing has emerged as a popular, inexpensive, and efficient data mining solution for performing distributed label collection. However, crowdsourced annotations are inherently untrustworthy, as the labels are provided by anonymous volunteers who may have varying, unreliable expertise. Worse yet, some participants on commonly used platforms such as Amazon Mechanical Turk may be adversarial, and provide intentionally incorrect label information without the end user's knowledge. We discuss three conventional models of the label generation process, describing their parameterizations and the model-based approaches used to solve them. We then propose OpinionRank, a model-free, interpretable, graph-based spectral algorithm for integrating crowdsourced annotations into reliable labels for performing supervised or semi-supervised learning. Our experiments show that OpinionRank performs favorably when compared against more highly parameterized algorithms. We also show that OpinionRank is scalable to very large datasets and numbers of label sources, and requires considerably less computational resources than previous approaches.", "num_citations": "1\n", "authors": ["1070"]}
{"title": "Comparative Analysis of Extreme Verification Latency Learning Algorithms\n", "abstract": " One of the more challenging real-world problems in computational intelligence is to learn from non-stationary streaming data, also known as concept drift. Perhaps even a more challenging version of this scenario is when -- following a small set of initial labeled data -- the data stream consists of unlabeled data only. Such a scenario is typically referred to as learning in initially labeled nonstationary environment, or simply as extreme verification latency (EVL). Because of the very challenging nature of the problem, very few algorithms have been proposed in the literature up to date. This work is a very first effort to provide a review of some of the existing algorithms (important/prominent) in this field to the research community. More specifically, this paper is a comprehensive survey and comparative analysis of some of the EVL algorithms to point out the weaknesses and strengths of different approaches from three different perspectives: classification accuracy, computational complexity and parameter sensitivity using several synthetic and real world datasets.", "num_citations": "1\n", "authors": ["1070"]}
{"title": "Targeted forgetting and false memory formation in continual learners through adversarial backdoor attacks\n", "abstract": " Artificial neural networks are well-known to be susceptible to catastrophic forgetting when continually learning from sequences of tasks. Various continual (or \"incremental\") learning approaches have been proposed to avoid catastrophic forgetting, but they are typically adversary agnostic, i.e., they do not consider the possibility of a malicious attack. In this effort, we explore the vulnerability of Elastic Weight Consolidation (EWC), a popular continual learning algorithm for avoiding catastrophic forgetting. We show that an intelligent adversary can take advantage of EWC's continual learning capabilities to cause gradual and deliberate forgetting by introducing small amounts of misinformation to the model during training. We demonstrate such an adversary's ability to assume control of the model via injection of backdoor attack samples on both permuted and split benchmark variants of the MNIST dataset. Importantly\u00a0\u2026", "num_citations": "1\n", "authors": ["1070"]}
{"title": "Dual axis solar panel control system\n", "abstract": " This paper describes a control system to enhance the performance of a solar panel. A two-axis mechanism is developed that tilts and turns the solar panel to face the highest intensity of light. The system was designed in LabVIEW, and implemented on the Arduino Mega 2560. The physical model of the system was built using servo motors and photoresistors. The pilot plant was tested by applying a source of light from various directions and monitoring its response. The solar panel was able to face towards the highest intensity of light with high level of precision.", "num_citations": "1\n", "authors": ["1070"]}
{"title": "Organ-izing the engineering curriculum with biomedically related learning modules\n", "abstract": " Proposed abstract for the NSF-Grantees Poster Session Organ-izing the Curriculum with hands-on, biomedically-related learning modules The relatively new discipline of biomedical engineering emerged from informalcollaborations between engineers, physicians and life scientists, and is the fastest growingengineering discipline at most universities. Chemical, mechanical, and electricalengineers play an important and expanding role in this burgeoning field because thefundamental core principles of each discipline are critical to biomedical mainstays suchas the design of artificial organs. This project introduces hands-on, biomedically-relatedexperiments and course materials into the engineering curriculum, with a focus onartificial organs. This paper describes several modules that have been developed andintegrated into a variety of courses throughout XXXX\u2019s engineering curriculum. Themodules are designed to be transferrable to other traditional engineering programs suchas chemical, mechanical and electrical as well as biomedical engineering programs.", "num_citations": "1\n", "authors": ["1070"]}
{"title": "Ordering samples along environmental gradients using particle swarm optimization\n", "abstract": " Due to the enormity of the solution space for sequential ordering problems, non-exhaustive heuristic techniques have been the focus of many research efforts, particularly in the field of operations research. In this paper, we outline an ecologically motivated problem in which environmental samples have been obtained along a gradient (e.g. pH), with which we desire to recover the sample order. Not only do we model the problem for the benefit of an optimization approach, we also incorporate hybrid particle swarm techniques to address the problem. The described method is implemented on a real dataset from which 22 biological samples were obtained along a pH gradient. We show that we are able to approach the optimal permutation of samples by evaluating only approximately 5000 solutions - infinitesimally smaller than the 22! possible solutions.", "num_citations": "1\n", "authors": ["1070"]}
{"title": "Ensemble Based Data Fusion from Parietal Region Event Related Potentials for Early Diagnosis of Alzheimer's Disease\n", "abstract": " As a natural consequence of steady increase of average population age in developed countries, Alzheimer's disease is becoming an increasingly important public health concern. The financial and emotional toll of the disease is exacerbated with lack of standard diagnostic procedures available at the community clinics and hospitals, where most patients are evaluated. In our recent preliminary results, we have reported that the event related potentials (ERPs) of the electroencephalogram can be used to train an ensemble-based classifier for automated diagnosis of Alzheimer's disease. In this study, we present an updated alternative approach by combining complementary information provided by ERPs obtained from several parietal region electrodes. The results indicate that ERPs obtained from parietal region of the cortex carry substantial complementary diagnostic information. Specifically, the diagnostic ability of\u00a0\u2026", "num_citations": "1\n", "authors": ["1070"]}
{"title": "Laboratory Integration of Emerging Topics into Existing Curriculum\n", "abstract": " The growing body of scientific and engineering knowledge, against the current economic and political realities restricting the number of credits required to obtain a degree, constitutes a significant challenge in designing tomorrow's engineering curriculum. More novel content from emerging areas of engineering needs to be integrated into the curriculum, without sacrificing the fundamental background, and without increasing the credit count. We propose a laboratory based approach to this dilemma, where the novel content is introduced as applications within the laboratory exercises of the course with the closest topical area within the existing curriculum. We use biomedical engineering concepts as the novel area and electrical & computer engineering courses as the existing curriculum in our implementation, to increase awareness and interest in biomedical engineering. We discuss our reasons for choosing\u00a0\u2026", "num_citations": "1\n", "authors": ["1070"]}
{"title": "Classification of volatile organic compounds with incremental SVMs and RBF networks\n", "abstract": " Support Vector Machines (SVMs) have been applied to solve the classification of volatile organic compounds (VOC) data in some recent studies. SVMs provide good generalization performance in detection and classification of VOC data. However, in many applications involving VOC data, it is not unusual for additional data, which may include new classes, to become available over time, which then requires an SVM classifier that is capable of incremental learning that does not suffer from loss of previously acquired knowledge. In our previous work, we have proposed the incremental SVM approach based on Learn\u2009+\u2009+\u2009.MT. In this contribution, the ability of SVMLearn\u2009+\u2009+\u2009.MT to incrementally classify VOC data is evaluated and compared against a similarly constructed Learn\u2009+\u2009+\u2009.MT algorithm that uses radial basis function neural network as base classifiers.", "num_citations": "1\n", "authors": ["1070"]}
{"title": "Comparison of ERP spectral bands for early diagnosis of Alzheimer Disease using multiresolution wavelet analysis\n", "abstract": " Comparison of ERP spectral bands for early diagnosis of Alzheimer Disease using multiresolution wavelet analysis \u00d7 Close The Infona portal uses cookies, ie strings of text saved by a browser on the user's device. The portal can access those files and use them to remember the user's data, such as their chosen settings (screen view, interface language, etc.), or their login data. By using the Infona portal the user accepts automatic saving and using this information for portal operation purposes. More information on the subject can be found in the Privacy Policy and Terms of Service. By closing this window the user confirms that they have read the information on cookie usage, and they accept the privacy policy and the way cookies are used by the portal. You can change the cookie settings in your browser. I accept Polski English Login or register account remember me Password recovery INFONA - science \u2026", "num_citations": "1\n", "authors": ["1070"]}
{"title": "Digital imaging experiences for undergraduate engineering students\n", "abstract": " Our project is an effort by a multidisciplinary team of engineering faculty members at Rowan University to integrate digital imaging technology (DIT) into the undergraduate engineering curriculum. It builds upon the experience and interest of faculty to promote new topics and innovative methods of teaching. The work is an effort to provide students with the skills directly relevant to the evolving needs of the industry and the marketplace. Projects involve the development of digital imaging curriculum and focus on the creation of a leading edge digital imaging laboratory/studio to facilitate the use of nontraditional learning approaches that encourage interactive learning, team building, and creative problem solving among students and instructors. A number of visual experiemtns will be developed and used to introduce students to the multidisciplinary engineering principles and use of DIT. Some of these activities will be\u00a0\u2026", "num_citations": "1\n", "authors": ["1070"]}
{"title": "Continuous Development Of A New Ece Program\n", "abstract": " NOTE: The first page of text has been automatically extracted and included below in lieu of an abstract", "num_citations": "1\n", "authors": ["1070"]}
{"title": "Multiresolution wavelet analysis of EEG signals for the detection of Alzheimer's disease\n", "abstract": " The processing and analysis of biological signals are of crucial importance in biomedical engineering for the detection of physiological abnormalities in a biological system. The development of signal processing software and hardware has enabled doctors to diagnose a patient's condition without using invasive surgical operations. Today, it is often possible to tell whether a patient has a physiological disorder by analyzing the relevant biological signals. For instance, a cardiovascular disease can often be detected by analyzing the electrocardiogram (ECG), or a neurological disease can often be detected by analyzing the electroencephalogram (EEG), etc. Therefore, the applications of signal processing are of immense value to the medical community. There are many bioelectric signals that can be detected from the body. However, signal processing of biological signals is not limited to bioelectric signals\u00a0\u2026", "num_citations": "1\n", "authors": ["1070"]}