{"title": "PR-Miner: automatically extracting implicit programming rules and detecting violations in large software code\n", "abstract": " Programs usually follow many implicit programming rules, most of which are too tedious to be documented by programmers. When these rules are violated by programmers who are unaware of or forget about them, defects can be easily introduced. Therefore, it is highly desirable to have tools to automatically extract such rules and also to automatically detect violations. Previous work in this direction focuses on simple function-pair based programming rules and additionally requires programmers to provide rule templates.This paper proposes a general method called PR-Miner that uses a data mining technique called frequent itemset mining to efficiently extract implicit programming rules from large software code written in an industrial programming language such as C, requiring little effort from programmers and no prior knowledge of the software. Benefiting from frequent itemset mining, PR-Miner can extract\u00a0\u2026", "num_citations": "608\n", "authors": ["447"]}
{"title": "The Multi-Queue Replacement Algorithm for Second Level Buffer Caches.\n", "abstract": " This paper reports our research results that improve second level buffer cache performance. Several previous studies have shown that a good single level cache replacement algorithm such as LRU does not work well with second level buffer caches. Second level buffer caches have different access pattern from first level buffer caches because Accesses to second level buffer caches are actually misses from first level buffer caches. The paper presents our study of second level buffer cache access patterns using four large traces from various servers. We also introduce a new second level buffer cache replacement algorithm called Multi-Queue (MQ). Our trace-driven simulation results show that MQ performs better than all seven tested alternatives. Our implementation on a real storage system validates these results.", "num_citations": "506\n", "authors": ["447"]}
{"title": "Flashback: A lightweight extension for rollback and deterministic replay for software debugging\n", "abstract": " Software robustness has significant impact on system availability. Unfortunately, finding software bugs is a very challenging task because many bugs are hard to reproduce. While debugging a program, it would be very useful to rollback a crashed program to a previous execution point and deterministically re-execute the``buggy''code region. However, most previous work on rollback and replay support was designed to survive hardware or operating system failures, and is therefore too heavy-weight for the fine-grained rollback and replay needed for software debugging.", "num_citations": "365\n", "authors": ["447"]}
{"title": "Have things changed now? An empirical study of bug characteristics in modern open source software\n", "abstract": " Software errors are a major cause for system failures. To effectively design tools and support for detecting and recovering from software failures requires a deep understanding of bug characteristics. Recently, software and its development process have significantly changed in many ways, including more help from bug detection tools, shift towards multi-threading architecture, the open-source development paradigm and increasing concerns about security and user-friendly interface. Therefore, results from previous studies may not be applicable to present software. Furthermore, many new aspects such as security, concurrency and open-source-related characteristics have not well studied. Additionally, previous studies were based on a small number of bugs, which may lead to non-representative results. To investigate the impacts of the new factors on software errors, we analyze bug characteristics by first sampling\u00a0\u2026", "num_citations": "338\n", "authors": ["447"]}
{"title": "Understanding the propagation of hard errors to software and implications for resilient system design\n", "abstract": " With continued CMOS scaling, future shipped hardware will be increasingly vulnerable to in-the-field faults. To be broadly deployable, the hardware reliability solution must incur low overheads, precluding use of expensive redundancy. We explore a cooperative hardware-software solution that watches for anomalous software behavior to indicate the presence of hardware faults. Fundamental to such a solution is a characterization of how hardware faults indifferent microarchitectural structures of a modern processor propagate through the application and OS. This paper aims to provide such a characterization, resulting in identifying low-cost detection methods and providing guidelines for implementation of the recovery and diagnosis components of such a reliability solution. We focus on hard faults because they are increasingly important and have different system implications than the much studied transients. We\u00a0\u2026", "num_citations": "326\n", "authors": ["447"]}
{"title": "Performance evaluation of two home-based lazy release consistency protocols for shared virtual memory systems\n", "abstract": " This paper investigates the performance of shared virtual memory protocols on large-scale multicomputers. Using experiments on a 64-node Paragon, we show that the traditional Lazy Release Consistency (LRC) protocol does not scale well, because of the large number of messages it requires, the large amount of memory it consumes for protocol overhead data, and because of the difficulty of garbage collecting that data.", "num_citations": "315\n", "authors": ["447"]}
{"title": "Dynamic tracking of page miss ratio curve for memory management\n", "abstract": " Memory can be efficiently utilized if the dynamic memory demands of applications can be determined and analyzed at run-time. The page miss ratio curve(MRC), i.e. page miss rate vs. memory size curve, is a good performance-directed metric to serve this purpose. However, dynamically tracking MRC at run time is challenging in systems with virtual memory because not every memory reference passes through the operating system (OS).This paper proposes two methods to dynamically track MRC of applications at run time. The first method is using a hardware MRC monitor that can track MRC at fine time granularity. Our simulation results show that this monitor has negligible performance and energy overheads. The second method is an OS-only implementation that can track MRC at coarse time granularity. Our implementation results on Linux show that it adds only 7--10% overhead.We have also used the\u00a0\u2026", "num_citations": "313\n", "authors": ["447"]}
{"title": "Reducing energy consumption of disk storage using power-aware cache management\n", "abstract": " Reducing energy consumption is an important issue for data centers. Among the various components of a data center, storage is one of the biggest consumers of energy. Previous studies have shown that the average idle period for a server disk in a data center is very small compared to the time taken to spin down and spin up. This significantly limits the effectiveness of disk power management schemes. This paper proposes several power-aware storage cache management algorithms that provide more opportunities for the underlying disk power management schemes to save energy. More specifically, we present an off-line power-aware greedy algorithm that is more energy-efficient than Belady\u2019s off-line algorithm (which minimizes cache misses only). We also propose an online power-aware cache replacement algorithm. Our trace-driven simulations show that, compared to LRU, our algorithm saves 16% more\u00a0\u2026", "num_citations": "306\n", "authors": ["447"]}
{"title": "An empirical study on configuration errors in commercial and open source systems\n", "abstract": " Configuration errors (ie, misconfigurations) are among the dominant causes of system failures. Their importance has inspired many research efforts on detecting, diagnosing, and fixing misconfigurations; such research would benefit greatly from a real-world characteristic study on misconfigurations. Unfortunately, few such studies have been conducted in the past, primarily because historical misconfigurations usually have not been recorded rigorously in databases.", "num_citations": "284\n", "authors": ["447"]}
{"title": "C-Miner: Mining Block Correlations in Storage Systems.\n", "abstract": " Block correlations are common semantic patterns in storage systems. These correlations can be exploited for improving the effectiveness of storage caching, prefetching, data layout and disk scheduling. Unfortunately, information about block correlations is not available at the storage system level. Previous approaches for discovering file correlations in file systems do not scale well enough to be used for discovering block correlations in storage systems. In this paper, we propose C-Miner, an algorithm which uses a data mining technique called frequent sequence mining to discover block correlations in storage systems. C-Miner runs reasonably fast with feasible space requirement, indicating that it is a practical tool for dynamically inferring correlations in a storage system. Moreover, we have also evaluated the benefits of block correlation-directed prefetching and data layout through experiments. Our results using real system workloads show that correlation-directed prefetching and data layout can reduce average I/O response time by 12-25% compared to the base case, and 7-20% compared to the commonly used sequential prefetching scheme.", "num_citations": "267\n", "authors": ["447"]}
{"title": "Are disks the dominant contributor for storage failures? A comprehensive study of storage subsystem failure characteristics\n", "abstract": " Building reliable storage systems becomes increasingly challenging as the complexity of modern storage systems continues to grow. Understanding storage failure characteristics is crucially important for designing and building a reliable storage system. While several recent studies have been conducted on understanding storage failures, almost all of them focus on the failure characteristics of one component\u2014disks\u2014and do not study other storage component failures. This article analyzes the failure characteristics of storage subsystems. More specifically, we analyzed the storage logs collected from about 39,000 storage systems commercially deployed at various customer sites. The dataset covers a period of 44 months and includes about 1,800,000 disks hosted in about 155,000 storage-shelf enclosures. Our study reveals many interesting findings, providing useful guidelines for designing reliable storage\u00a0\u2026", "num_citations": "201\n", "authors": ["447"]}
{"title": "Second-level buffer cache management\n", "abstract": " Buffer caches are commonly used in servers to reduce the number of slow disk accesses or network messages. These buffer caches form a multilevel buffer cache hierarchy. In such a hierarchy, second-level buffer caches have different access patterns from first-level buffer caches because accesses to a second-level are actually misses from a first-level. Therefore, commonly used cache management algorithms such as the least recently used (LRU) replacement algorithm that work well for single-level buffer caches may not work well for second-level. We investigate multiple approaches to effectively manage second-level buffer caches. In particular, we report our research results in 1) second-level buffer cache access pattern characterization, 2) a new local algorithm called multi-queue (MQ) that performs better than nine tested alternative algorithms for second-level buffer caches, 3) a set of global algorithms that\u00a0\u2026", "num_citations": "201\n", "authors": ["447"]}
{"title": "HARD: Hardware-assisted lockset-based race detection\n", "abstract": " The emergence of multicore architectures will lead to an increase in the use of multithreaded applications that are prone to synchronization bugs, such as data races. Software solutions for detecting data races generally incur large overheads. Hardware support for race detection can significantly reduce that overhead. However, all existing hardware proposals for race detection are based on the happens-before algorithm which is sensitive to thread interleaving and cannot detect races that are not exposed during the monitored run. The lockset algorithm addresses this limitation. Unfortunately, due to the challenging issues such as storing the lockset information and performing complex set operations, so far it has been implemented only in software with 10-30 times performance hit. This paper proposes the first hardware implementation (called HARD) of the lockset algorithm to exploit the race detection capability of\u00a0\u2026", "num_citations": "186\n", "authors": ["447"]}
{"title": "Using likely program invariants to detect hardware errors\n", "abstract": " In the near future, hardware is expected to become increasingly vulnerable to faults due to continuously decreasing feature size. Software-level symptoms have previously been used to detect permanent hardware faults. However, they can not detect a small fraction of faults, which may lead to silent data corruptions(SDCs). In this paper, we present a system that uses invariants to improve the coverage and latency of existing detection techniques for permanent faults. The basic idea is to use training inputs to create likely invariants based on value ranges of selected program variables and then use them to identify faults at runtime. Likely invariants, however, can have false positives which makes them challenging to use for permanent faults. We use our on-line diagnosis framework for detecting false positives at runtime and limit the number of false positives to keep the associated overhead minimal. Experimental\u00a0\u2026", "num_citations": "176\n", "authors": ["447"]}
{"title": "Log correlation for intrusion detection: A proof of concept\n", "abstract": " Intrusion detection is an important part of networked-systems security protection. Although commercial products exist, finding intrusions has proven to be a difficult task with limitations under current techniques. Therefore, improved techniques are needed. We argue the need for correlating data among different logs to improve intrusion detection systems accuracy. We show how different attacks are reflected in different logs and argue that some attacks are not evident when a single log is analyzed. We present experimental results using anomaly detection for the virus Yaha. Through the use of data mining tools (RIPPER) and correlation among logs we improve the effectiveness of an intrusion detection system while reducing false positives.", "num_citations": "173\n", "authors": ["447"]}
{"title": "Ad Hoc Synchronization Considered Harmful.\n", "abstract": " Many synchronizations in existing multi-threaded programs are implemented in an ad hoc way. The first part of this paper does a comprehensive characteristic study of ad hoc synchronizations in concurrent programs. By studying 229 ad hoc synchronizations in 12 programs of various types (server, desktop and scientific), including Apache, MySQL, Mozilla, etc., we find several interesting and perhaps alarming characteristics:(1) Every studied application uses ad hoc synchronizations. Specifically, there are 6\u201383 ad hoc synchronizations in each program.(2) Ad hoc synchronizations are error-prone. Significant percentages (22\u201367%) of these ad hoc synchronizations introduced bugs or severe performance issues.(3) Ad hoc synchronization implementations are diverse and many of them cannot be easily recognized as synchronizations, ie have poor readability and maintainability. The second part of our work builds a tool called SyncFinder to automatically identify and annotate ad hoc synchronizations in concurrent programs written in C/C++ to assist programmers in porting their code to better structured implementations, while also enabling other tools to recognize them as synchronizations. Our evaluation using 25 concurrent programs shows that, on average, SyncFinder can automatically identify 96% of ad hoc synchronizations with 6% false positives. We also build two use cases to leverage SyncFinder\u2019s auto-annotation. The first one uses annotation to detect 5 deadlocks (including 2 new ones) and 16 potential issues missed by previous analysis tools in Apache, MySQL and Mozilla. The second use case reduces Valgrind data race checker\u2019s\u00a0\u2026", "num_citations": "167\n", "authors": ["447"]}
{"title": "Power-aware storage cache management\n", "abstract": " Reducing energy consumption is an important issue for data centers. Among the various components of a data center, storage is one of the biggest energy consumers. Previous studies have shown that the average idle period for a server disk in a data center is very small compared to the time taken to spin down and spin up. This significantly limits the effectiveness of disk power management schemes. This article proposes several power-aware storage cache management algorithms that provide more opportunities for the underlying disk power management schemes to save energy. More specifically, we present an offline energy-optimal cache replacement algorithm using dynamic programming, which minimizes the disk energy consumption. We also present an offline power-aware greedy algorithm that is more energy-efficient than Belady's offline algorithm (which minimizes cache misses only). We also propose\u00a0\u2026", "num_citations": "158\n", "authors": ["447"]}
{"title": "Hey, you have given me too many knobs!: Understanding and dealing with over-designed configuration in system software\n", "abstract": " Configuration problems are not only prevalent, but also severely impair the reliability of today's system software. One fundamental reason is the ever-increasing complexity of configuration, reflected by the large number of configuration parameters (\" knobs\"). With hundreds of knobs, configuring system software to ensure high reliability and performance becomes a daunting, error-prone task. This paper makes a first step in understanding a fundamental question of configuration design:\" do users really need so many knobs?\" To provide the quantitatively answer, we study the configuration settings of real-world users, including thousands of customers of a commercial storage system (Storage-A), and hundreds of users of two widely-used open-source system software projects. Our study reveals a series of interesting findings to motivate software architects and developers to be more cautious and disciplined in\u00a0\u2026", "num_citations": "138\n", "authors": ["447"]}
{"title": "Eviction-based Cache Placement for Storage Caches.\n", "abstract": " Most previous work on buffer cache management uses an access-based placement policy that places a data block into a buffer cache at the block\u2019s access time. This paper presents an eviction-based placement policy for a storage cache that usually sits in the lower level of a multi-level buffer cache hierarchy and thereby has different access patterns from upper levels. The main idea of the eviction-based placement policy is to delay a block\u2019s placement in the cache until it is evicted from the upper level. This paper also presents a method of using a client content tracking table to obtain eviction information from client buffer caches, which can avoid modifying client application source code. We have evaluated the performance of this eviction-based placement by using both simulations with real-world workloads, and implementations on a storage system connected to a Microsoft SQL server database. Our simulation results show that the eviction-based cache placement has an up to 500% improvement on cache hit ratios over the commonly used access-based placement policy. Our evaluation results using OLTP workloads have demonstrated that the eviction-based cache placement has a speedup of 1.2 on OLTP transaction rates.", "num_citations": "135\n", "authors": ["447"]}
{"title": "Performance directed energy management for main memory and disks\n", "abstract": " Much research has been conducted on energy management for memory and disks. Most studies use control algorithms that dynamically transition devices to low power modes after they are idle for a certain threshold period of time. The control algorithms used in the past have two major limitations. First, they require painstaking, application-dependent manual tuning of their thresholds to achieve energy savings without significantly degrading performance. Second, they do not provide performance guarantees. In one case, they slowed down an application by 835.This paper addresses these two limitations for both memory and disks, making memory/disk energy-saving schemes practical enough to use in real systems. Specifically, we make three contributions: (1) We propose a technique that provides a performance guarantee for control algorithms. We show that our method works well for all tested cases, even with\u00a0\u2026", "num_citations": "132\n", "authors": ["447"]}
{"title": "Encore: Exploiting system environment and correlation information for misconfiguration detection\n", "abstract": " As software systems become more complex and configurable, failures due to misconfigurations are becoming a critical problem. Such failures often have serious functionality, security and financial consequences. Further, diagnosis and remediation for such failures require reasoning across the software stack and its operating environment, making it difficult and costly. We present a framework and tool called EnCore to automatically detect software misconfigurations. EnCore takes into account two important factors that are unexploited before: the interaction between the configuration settings and the executing environment, as well as the rich correlations between configuration entries. We embrace the emerging trend of viewing systems as data, and exploit this to extract information about the execution environment in which a configuration setting is used. EnCore learns configuration rules from a given set of sample\u00a0\u2026", "num_citations": "123\n", "authors": ["447"]}
{"title": "PB-LRU: A self-tuning power aware storage cache replacement algorithm for conserving disk energy\n", "abstract": " Energy consumption is an important concern at data centers, where storage systems consume a significant fraction of the total energy. A recent study proposed power-aware storage cache management to provide more opportunities for the underlying disk power management scheme to save energy. However, the on-line algorithm proposed in that study requires cumbersome parameter tuning for each workload and is therefore difficult to apply to real systems. This paper presents a new power-aware on-line algorithm called PB-LRU (Partition-Based LRU) that requires little parameter tuning. Our results with both real system and synthetic workloads show that PB-LRU without any parameter tuning provides similar or even better performance and energy savings than the previous power-aware algorithm with the best parameter setting for each workload.", "num_citations": "110\n", "authors": ["447"]}
{"title": "DMA-aware memory energy management\n", "abstract": " As increasingly larger memories are used to bridge the widening gap between processor and disk speeds, main memory energy consumption is becoming increasingly dominant. Even though much prior research has been conducted on memory energy management, no study has focused on data servers, where main memory is predominantly accessed by DMAs instead of processors. In this paper, we study DMA-aware techniques for memory energy management in data servers. We first characterize the effect of DMA accesses on memory energy and show that, due to the mismatch between memory and I/O bus band-widths, significant energy is wasted when memory is idle but still active during DMA transfers. To reduce this waste, we propose two novel performance-directed energy management techniques that maximize the utilization of memory devices by increasing the level of concurrency between multiple\u00a0\u2026", "num_citations": "107\n", "authors": ["447"]}
{"title": "Do I use the wrong definition? DefUse: Definition-use invariants for detecting concurrency and sequential bugs\n", "abstract": " Software bugs, such as concurrency, memory and semantic bugs, can significantly affect system reliability. Although much effort has been made to address this problem, there are still many bugs that cannot be detected, especially concurrency bugs due to the complexity of concurrent programs. Effective approaches for detecting these common bugs are therefore highly desired.", "num_citations": "103\n", "authors": ["447"]}
{"title": "Relaxed consistency and coherence granularity in DSM systems: A performance evaluation\n", "abstract": " During the past few years, two main approaches have been taken to improve the performance of software shared memory implementations: relaxing consistency models and providing fine-grained access control. Their performance tradeoffs, however, we not well understood. This paper studies these tradeoffs on a platform that provides access control in hardware but runs coherence protocols in software, We compare the performance of three protocols across four coherence granularities, using 12 applications on a 16-node cluster of workstations. Our results show that no single combination of protocol and granularity performs best for all the applications. The combination of a sequentially consistent (SC) protocol and fine granularity works well with 7 of the 12 applications. The combination of a multiple-writer, home-based lazy release consistency (HLRC) protocol and page granularity works well with 8 out of the 12\u00a0\u2026", "num_citations": "103\n", "authors": ["447"]}
{"title": "Systems approaches to tackling configuration errors: A survey\n", "abstract": " In recent years, configuration errors (i.e., misconfigurations) have become one of the dominant causes of system failures, resulting in many severe service outages and downtime. Unfortunately, it is notoriously difficult for system users (e.g., administrators and operators) to prevent, detect, and troubleshoot configuration errors due to the complexity of the configurations as well as the systems under configuration. As a result, the cost of resolving configuration errors is often tremendous from the aspects of both compensating the service disruptions and diagnosing, recovering from the failures. The prevalence, severity, and cost have made configuration errors one of the most thorny system problems that desire to be addressed. This survey article provides a holistic and structured overview of the systems approaches that tackle configuration errors. To understand the problem fundamentally, we first discuss the\u00a0\u2026", "num_citations": "97\n", "authors": ["447"]}
{"title": "Research advances in the Mesozoic tectonic regimes during the formation of Jiaodong ore cluster area\n", "abstract": " Based on research advances of the tectonic regime in Jiaodong ore cluster area and the related tectonic regime transformation in Mesozoic era in the eastern region of North China, in this paper, we first summarize some key problems required to be studied further on. Then we suggest an approach to dealing with these problems. It is known that the gold deposits in Jiaodong ore cluster area, which are of different mineralization styles, spatial istributions and geological settings, might be as a result from one or more geologic events in Mesozoic. Till now, this kind of research on the temporal evolution and spatial migration sequence, especially on the geodynamic mechanism of the above events, is far from sufficient. Moreover, quantitatively describing the action mode and the temporal-spatial framework of tectonic dynamic regimes and formulating the relative contribution of every tectonic dynamic regime for\u00a0\u2026", "num_citations": "95\n", "authors": ["447"]}
{"title": "Empirical evaluation of multi-level buffer cache collaboration for storage systems\n", "abstract": " To bridge the increasing processor-disk performance gap, buffer caches are used in both storage clients (eg database systems) and storage servers to reduce the number of slow disk accesses. These buffer caches need to be managed effectively to deliver the performance commensurate to the aggregate buffer cache size. To address this problem, two paradigms have been proposed recently to collaboratively manage these buffer caches together: the hierarchy-aware caching maintains the same I/O interface and is fully transparent to the storage client software, and the aggressively-collaborative caching trades off transparency for performance and requires changes to both the interface and the storage client software. Before storage industry starts to implement collaborative caching in real systems, it is crucial to find out whether sacrificing transparency is really worthwhile, ie, how much can we gain by using the\u00a0\u2026", "num_citations": "90\n", "authors": ["447"]}
{"title": "Understanding customer problem troubleshooting from storage system logs\n", "abstract": " Customer problem troubleshooting has been a critically important issue for both customers and system providers. This paper makes two major contributions to better understand this topic.", "num_citations": "80\n", "authors": ["447"]}
{"title": "Trace-based microarchitecture-level diagnosis of permanent hardware faults\n", "abstract": " As devices continue to scale, future shipped hardware will likely fail due to in-the-field hardware faults. As traditional redundancy-based hardware reliability solutions that tackle these faults will be too expensive to be broadly deployable, recent research has focused on low-overhead reliability solutions. One approach is to employ low-overhead (ldquoalways-onrdquo) detection techniques that catch high-level symptoms and pay a higher overhead for (rarely invoked) diagnosis. This paper presents trace-based fault diagnosis, a diagnosis strategy that identifies permanent faults in microarchitectural units by analyzing the faulty corepsilas instruction trace. Once a fault is detected, the faulty core is rolled back and re-executes from a previous checkpoint, generating a faulty instruction trace and recording the microarchitecture-level resource usage. A diagnosis process on another fault-free core then generates a fault\u00a0\u2026", "num_citations": "73\n", "authors": ["447"]}
{"title": "Mining block correlations to improve storage performance\n", "abstract": " Block correlations are common semantic patterns in storage systems. They can be exploited for improving the effectiveness of storage caching, prefetching, data layout, and disk scheduling. Unfortunately, information about block correlations is unavailable at the storage system level. Previous approaches for discovering file correlations in file systems do not scale well enough for discovering block correlations in storage systems.In this article, we propose two algorithms, C-Miner and C-Miner*, that use a data mining technique called frequent sequence mining to discover block correlations in storage systems. Both algorithms run reasonably fast with feasible space requirement, indicating that they are practical for dynamically inferring correlations in a storage system. C-Miner is a direct application of a frequent-sequence mining algorithm with a few modifications; compared with C-Miner, C-Miner* is redesigned for\u00a0\u2026", "num_citations": "72\n", "authors": ["447"]}
{"title": "Adaptive multi-resource prediction in distributed resource sharing environment\n", "abstract": " Resource prediction can greatly assist resource selection and scheduling in a distributed resource sharing environment such as a computational Grid. Existing resource prediction models are either based on the auto-correlation of a single resource or based on the cross correlation between two resources. In this paper, we propose a multi-resource prediction model (MModel) that uses both kinds of correlations to achieve higher prediction accuracy. We also present two adaptation techniques that enable the MModel to adapt to the time-varying characteristics of the underlying resources. Experimental results with CPU load prediction in both workstation and Grid environment show that on average, the adaptive MModel (called MModel-a) can achieve from 6% to more than 96% reduction in prediction errors compared with the autoregressive (AR) model, which has previously been shown to work well for CPU load\u00a0\u2026", "num_citations": "67\n", "authors": ["447"]}
{"title": "Cross-component energy management: Joint adaptation of processor and memory\n", "abstract": " Researchers have proposed the use of adaptation to reduce the energy consumption of different hardware components, such as the processor, memory, disk, and display for general-purpose applications. Previous algorithms to control these adaptations, however, have focused on a single component. This work takes the first step toward developing algorithms that can jointly control adaptations in multiple interacting components for general-purpose applications, with the goal of minimizing the total energy consumed within a specified performance loss. Specifically, we develop a joint-adaptation algorithm for processor and memory adaptations. We identify two properties that enable per-component algorithms to be easily used in a cross-component context---the algorithms' performance impact must be guaranteed and composable. We then modify a current processor and a memory algorithm to obey these properties\u00a0\u2026", "num_citations": "66\n", "authors": ["447"]}
{"title": "Managing energy-performance tradeoffs for multithreaded applications on multiprocessor architectures\n", "abstract": " In modern computers, non-performance metrics such as energy consumption have become increasingly important, requiring tradeoff with performance. A recent work has proposed performance-guaranteed energy management, but it is designed specifically for sequential applications and cannot be used to a large class of multithreaded applications running on high end computers and data servers.", "num_citations": "64\n", "authors": ["447"]}
{"title": "Applications of wavelet Galerkin FEM to bending of beam and plate structures\n", "abstract": " In this paper, an approach is proposed for taking calculations of high order differentials of scaling functions in wavelet theory in order to apply the wavelet Galerkin FEM to numerical analysis of those boundary-value problems with order higher than 2. After that, it is realized that the wavalet Galerkin FEM is used to solve mechanical problems such as bending of beams and plates. The numerical results show that this method has good precision.", "num_citations": "64\n", "authors": ["447"]}
{"title": "Performance directed energy management for main memory and disks\n", "abstract": " Much research has been conducted on energy management for memory and disks. Most studies use control algorithms that dynamically transition devices to low power modes after they are idle for a certain threshold period of time. The control algorithms used in the past have two major limitations. First, they require painstaking, application-dependent manual tuning of their thresholds to achieve energy savings without significantly degrading performance. Second, they do not provide performance guarantees.This article addresses these two limitations for both memory and disks, making memory/disk energy-saving schemes practical enough to use in real systems. Specifically, we make four main contributions. (1) We propose a technique that provides a performance guarantee for control algorithms. We show that our method works well for all tested cases, even with previously proposed algorithms that are not\u00a0\u2026", "num_citations": "63\n", "authors": ["447"]}
{"title": "Reslice: Selective re-execution of long-retired misspeculated instructions using forward slicing\n", "abstract": " As more data value speculation mechanisms are being proposed to speed-up processors, there is growing pressure on the critical processor structures that must buffer the state of the speculative instructions. A scalable solution is to checkpoint the processor and retire speculative instructions. However, in this environment, misprediction recovery becomes very wasteful, as it involves discarding and re-executing all the instructions executed since the checkpoint. To speed-up execution in this environment, this paper presents a novel architecture (ReSlice) that selectively re-executes only the speculatively-retired instructions that directly depended on the mispredicted value, namely its Forward Slice. ReSlice buffers the (typically very few) instructions in the forward slice of the predicted value as such instructions initially execute. Then, potentially thousands of instructions later, ReSlice can quickly re-execute the slice if a\u00a0\u2026", "num_citations": "55\n", "authors": ["447"]}
{"title": "Towards understanding bugs in open source router software\n", "abstract": " Software errors and vulnerabilities in core Internet routers have led to several high-profile attacks on the Internet infrastructure and numerous outages. Building an understanding of bugs in open-source router software is a first step towards addressing these problems. In this paper, we study router bugs found in two widely-used open-source router implementations. We evaluate the root cause of bugs, ease of diagnosis and detectability, ease of prevention and avoidance, and their effect on network behavior.", "num_citations": "41\n", "authors": ["447"]}
{"title": "Swat: An error resilient system\n", "abstract": " As devices continue to scale, future shipped hardware is more likely to fail due to in-the-field hardware faults. As traditional redundancy-based hardware reliability solutions are too expensive to be broadly deployable, recent research has focused on low-overhead reliability solutions. One approach is to employ low-overhead detection (always-on) techniques that catch high-level symptoms and pay a higher overhead for diagnosis (rarely invoked). To this end, we are developing SWAT (SoftWare Anomaly Treatment)\u2013a low-cost reliability solution that effectively handles multiple sources of faults by detecting anomalous software behavior. At the last SELSE, we motivated SWAT and presented a preliminary detection component that detects hardware failures by monitoring simple software level symptoms. This paper presents two significant enhancements to the SWAT system over the last year:(1) an effective diagnosis strategy that identifies the faulty microarchitectural unit by exploiting a checkpoint/replay based recovery mechanism and analyzing the faulty core\u2019s instruction trace, and (2) a sophisticated detection mechanism that specifically targets silent data corruptions by using compiler-inserted range-based invariants to further improve detection coverage and latency. The detection strategy leverages the online diagnosis strategy in a novel way to enable aggressive use of invariants while minimizing the impact of false positives at runtime.", "num_citations": "36\n", "authors": ["447"]}
{"title": "Memory resource allocation for file system prefetching: from a supply chain management perspective\n", "abstract": " As an important technique to hide disk I/O latency, prefetching has been widely studied, and dynamic adaptive prefetching techniques have been deployed in diverse storage environments. However, two issues are not well addressed by previous research:(1) how to handle the prefetching resource allocation between concurrent sequential access streams with different request rates, and (2) how to coordinate prefetching at multiple levels in the data access path.", "num_citations": "35\n", "authors": ["447"]}
{"title": "Indexing and querying semi-structured data\n", "abstract": " Generating an inverted index is disclosed. Semi-structured data from a plurality of sources is parsed to extract structure from at least a portion of the semi-structured data. The inverted index is generated using the extracted structure. The inverted index includes a location identifier and a data type identifier for one or more entries of the inverted index.", "num_citations": "33\n", "authors": ["447"]}
{"title": "Architecture support system and method for memory monitoring\n", "abstract": " Methods and systems for memory monitoring. A triggering access is detected at one or more monitored memory regions. When a triggering access is detected, a function is accessed for determining a monitoring function, and a monitoring function associated with a particular triggered memory location address is automatically determined.", "num_citations": "32\n", "authors": ["447"]}
{"title": "Uclog: A unified, correlated logging architecture for intrusion detection\n", "abstract": " Activity logs can be used for intrusion detection; however, most previous work on intrusion detection examines only activity logs from a single component. Doing so fails to take advantage of the naturally existing correlations among activities in different types of logs, such as network logs and system call logs.This paper explores correlation for intrusion detection. Specifically, we propose UCLog, a unified logging architecture that can effectively capture correlations among entries in different types of logs. UCLog enables the intrusion detection system to make some sense of the myriad of different available logs and correlate the information the logs present to enhance the intrusion detection process. We have evaluated UCLog by using it to detect the infection of a host with the Yaha virus. Our results show significant improvement when the information available in several logs is correlated.", "num_citations": "30\n", "authors": ["447"]}
{"title": "iwatcher: Simple, general architectural support for software debugging\n", "abstract": " We propose Intelligent Watcher (iWatcher), a combination of hardware and software support that can detect large variations of software bugs with only modest hardware changes to current processor implementations. iWatcher lets programmers associate specified functions to \"watched\" memory locations or objects. Access to any such location automatically triggers the monitoring function in the hardware. Relative to other approaches, iWatcher detects many real bugs at a fraction of the execution-time overhead", "num_citations": "29\n", "authors": ["447"]}
{"title": "A tyrosinase biosensor based on ZnO nanorod clusters/nanocrystalline diamond electrodes for biosensing of phenolic compounds\n", "abstract": " An amperometric biosensor was constructed by using ZnO nanorod clusters as platforms for immobilizing tyrosinase on the nanocrystalline diamond (NCD) electrodes. The results showed that ZnO nanorod clusters provided an advantageous microenvironment due to their favorable isoelectric point (IEP) for tyrosinase loading; immobilized tyrosinase generally retained its activity. The tyrosinase/ZnO/NCD electrode showed a linear response range of 1\u2013210 and sensitivity of 179.9 \u00b5A mmol\u20131 cm\u20132 for p-cresol. The corresponding values were 1\u2013190 and 90.2 for phenol, and 1\u2013250 and 121.3 for 4-chlorophenol. The low detection limits were estimated to be 0.2 \u00b5M for p-cresol, 0.5 \u00b5M for phenol, and 0.4 \u00b5M for 4-chlorophenol (S/N= 3). The prepared enzyme electrode could keep 85% of its original activity after intermittent use for 4 weeks when stored in a dry state at 277 K. Therefore, the ZnO nanorod cluster thin films have potential applications as platforms to immobilize other enzymes and bioactive molecules in biosensors.", "num_citations": "25\n", "authors": ["447"]}
{"title": "FTXen: Making hypervisor resilient to hardware faults on relaxed cores\n", "abstract": " As CMOS technology scales, the Increasingly smaller transistor components are susceptible to a variety of in-field hardware errors. Traditional redundancy techniques to deal with the increasing error rates are expensive and energy inefficient. To address this emerging challenge, many researchers have recently proposed the idea of relaxed hardware design and exposing errors to software. For such relaxed hardware to become a reality, it is crucially important for system software, such as the virtual machine hypervisor, to be resilient to hardware faults. To address the above fundamental software challenge in enabling relaxed hardware design, we are making a major effort in restructuring an important part of system software, namely the virtual machine hypervisor, to be resilient to faulty cores. A fault in a relaxed core can only affect those virtual machines (and applications) running on that core, but the hypervisor\u00a0\u2026", "num_citations": "21\n", "authors": ["447"]}
{"title": "Available online at www. sciencedirect. com\n", "abstract": " Results: The curves highlighting the permeability k as a function of packing density for both configurations (staggered and in-line) behave the same way and obey an exponential law. This permeability tends towards 0 for low packing densities which means that the viscous resistance tends towards infinity in the solid matrix: the minimal packing density is reached when hollowfibers are contiguous and under such conditions, the fluid flow through the cylinders bank is theoretically impossible. This means that the produced permeate (production step) or the permeate inMected to clean the hollow-fibers (backwash step) no longer flows outside the hollowfibers. It can be noted that the module configuration brings a little pressure drop, except for unrealistic conditions of very high permeability and inlet pressure. It was shown that during inside-out filtration and for the three tested module configurations and regardless the conditions of filtration, hollow-fibers work in a homogeneous way+/-0.4%. However, in the case of the backwash, a greater heterogeneity may appear.During the backwash, hollow-fibers are subMected to a pressure and the fluid motion tends to compact the hollow-fibers together. For this part of the study, the arrangement effect, the variation of the permeability and the pressure, the arrangement effect and the influence of packing density, temperature and gravity were taken into account. For the realistic case of backwash the flow losses of the entire module can be estimated: considering a permeability of 200 Lh-1. bar-1. m-2, an inlet pressure of 2 bar, the industrial module developing a high membrane", "num_citations": "20\n", "authors": ["447"]}
{"title": "How do system administrators resolve access-denied issues in the real world?\n", "abstract": " The efficacy of access control largely depends on how system administrators (sysadmins) resolve access-denied issues. A correct resolution should only permit the expected access, while maintaining the protection against illegal access. However, anecdotal evidence suggests that correct resolutions are occasional---sysadmins often grant too much access (known as security misconfigurations) to allow the denied access, posing severe security risks. This paper presents a quantitative study on real-world practices of resolving access-denied issues, with a particular focus on how and why security misconfigurations are introduced during problem solving. We characterize the real-world security misconfigurations introduced in the field, and show that many of these misconfigurations were the results of trial-and-error practices commonly adopted by sysadmins to work around access denials. We argue that the lack of\u00a0\u2026", "num_citations": "18\n", "authors": ["447"]}
{"title": "Thread scheduling for out-of-core applications with memory server on multicomputers\n", "abstract": " Out-of-core applications perform poorly in paged virtual memory (VM) systems because demand paging involves slow disk I/O accesses. Much research has been done on reducing the I/O overhead in such applications by either reducing the number of I/OS or lowering the cost of each I/O operation.In this paper, we investigate a method that combines finegrained threading with a memory eerver model to improve the performance of out-of-core applications on multicomputers. The memory server model decreases the average cost of I/O operations by paging to remote memory, while the fine-grained thread scheduling reduces the number of l/O accesses by improving the data locality of applications. We have evaluated this method on an Intel Paragon with 7 ap plications. Our results show that the memory server system performs better than the VM disk paging by B factor of 5 for sequential applications and a factor of 1\u00a0\u2026", "num_citations": "13\n", "authors": ["447"]}
{"title": "Towards continuous access control validation and forensics\n", "abstract": " Access control is often reported to be\" profoundly broken\" in real-world practices due to prevalent policy misconfigurations introduced by system administrators (sysadmins). Given the dynamics of resource and data sharing, access control policies need to be continuously updated. Unfortunately, to err is human-sysadmins often make mistakes such as over-granting privileges when changing access control policies. With today's limited tooling support for continuous validation, such mistakes can stay unnoticed for a long time until eventually being exploited by attackers, causing catastrophic security incidents. We present P-DIFF, a practical tool for monitoring access control behavior to help sysadmins early detect unintended access control policy changes and perform postmortem forensic analysis upon security attacks. P-DIFF continuously monitors access logs and infers access control policies from them. To handle\u00a0\u2026", "num_citations": "12\n", "authors": ["447"]}
{"title": "Limits to the performance of software shared memory: A layered approach\n", "abstract": " Much research has been done in fast communication on clusters and in protocols for supporting software shared memory across them. However, the end performance of applications that were written for the more proven hardware-coherent shared memory is still not very good on these systems. Three major layers of software (and hardware) stand between the end user and parallel performance, each with its own functionality and performance characteristics. They include the communication layer, the software protocol layer that supports the programming model, and the application layer. These layers provide a useful framework to identify the key remaining limitations and bottlenecks in software shared memory systems, as well as the areas where optimization efforts might yield the greatest performance improvements. This paper performs such an integrated study, using this layered framework, for two types of\u00a0\u2026", "num_citations": "10\n", "authors": ["447"]}
{"title": "Pracextractor: Extracting configuration good practices from manuals to detect server misconfigurations\n", "abstract": " Configuration has become ever so complex and error-prone in today\u2019s server software. To mitigate this problem, software vendors provide user manuals to guide system admins on configuring their systems. Usually, manuals describe not only the meaning of configuration parameters but also good practice recommendations on how to configure certain parameters. Unfortunately, manuals usually also have a large number of pages, which are time-consuming for humans to read and understand. Therefore, system admins often do not refer to manuals but rely on their own guesswork or unreliable sources when setting up systems, which can lead to configuration errors and system failures.", "num_citations": "9\n", "authors": ["447"]}
{"title": "A case for smartphone reuse to augment elementary school education\n", "abstract": " The rapid growth of information technology has led to substantial economic and societal benefits. Unfortunately, rapid improvements in technology has also led to an unsustainable \"disposable\" model in which devices are replaced in a matter of months. This model is especially problematic in the cell phone area, where over a billion phones are manufactured per year. To mitigate the impact of future devices, we propose a design for reuse model in which obsolete devices will be reused for a class of applications that can be satisfied with older, less reliable technology. In particular, we find a good match between the reuse of smartphones and educational applications at the primary school level. Our experiments on the HTC Nexus One indicate that the resource requirements of educational applications, including functional features, storage, memories, power and network communication can all be well satisfied by\u00a0\u2026", "num_citations": "9\n", "authors": ["447"]}
{"title": "Performance-directed energy management for storage systems\n", "abstract": " Energy consumption has become an important issue in the design of battery-operated mobile devices and sophisticated data centers. The storage hierarchy, which includes memory and disks, is a major energy consumer in such systems; especially for high-end servers at data centers. Much work has focused on energy control algorithms for storage systems that transition a device into a low power mode when a certain usage function exceeds a specified threshold. These algorithms are difficult to use in real systems, however, because designers must painstakingly and manually tune threshold values, and even then a performance guarantee is difficult. To address these limitations, we develop three algorithms: 1) a performance guarantee technique that designers can use with any underlying energy-control algorithm 2) a performance-directed control algorithm that periodically assigns a static configuration to\u00a0\u2026", "num_citations": "9\n", "authors": ["447"]}
{"title": "Views and transactional storage for large graphs\n", "abstract": " A growing number of applications store and analyze graph-structured data. These applications impose challenging infrastructure demands due to a need for scalable, high-throughput, and low-latency graph processing. Existing state-of-the-art storage systems and data processing systems are limited in at least one of these dimensions, and simply layering these technologies is inadequate.               We present Concerto, a graph store based on distributed, in-memory data structures. In addition to enabling efficient graph traversals by co-locating graph nodes and associated edges where possible, Concerto provides transactional updates while scaling to hundreds of nodes. Concerto introduces graph views to denote sub-graphs on which user-defined functions can be invoked. Using graph views, programmers can perform event-driven analysis and dynamically optimize application performance. Our results\u00a0\u2026", "num_citations": "8\n", "authors": ["447"]}
{"title": "Power consumption of wastewater treatment and the measures of energy saving.\n", "abstract": " With the rapid increase of waste water treatment practice and the enactment of strict standards, the power consumption in wastewater treatment wastewater treatment Subject Category: Miscellaneous", "num_citations": "8\n", "authors": ["447"]}
{"title": "Snippet search\n", "abstract": " Indexing data is disclosed. A plurality of subunits of data is determined within received data. For a first subunit, a first mapping between the first subunit and a first dictionary entry is determined. For a second subunit, a second mapping between the second subunit and a second dictionary entry is determined. At least the first and second dictionary entries are aggregated into an aggregation and stored in an index. Searching data is also disclosed. A plurality of subunits of data is determined within a received query. For a first subunit, a first mapping is determined between the first subunit and a first dictionary entry. For a second subunit, a second mapping is determined between the second subunit and a second dictionary entry. The first and second dictionary entries are aggregated and used to search an index.", "num_citations": "5\n", "authors": ["447"]}
{"title": "Efficient execution of multiple queries on deep memory hierarchy\n", "abstract": " This paper proposes a complementary novel idea, called MiniTasking to further reduce the number of cache misses by improving the data temporal locality for multiple concurrent queries. Our idea is based on the observation that, in many workloads such as decision support systems (DSS), there is usually significant amount of data sharing among different concurrent queries. MiniTasking exploits such data sharing to improve data temporal locality by scheduling query execution at three levels: query level batching, operator level grouping and mini-task level scheduling. The experimental results with various types of concurrent TPC-H query workloads show that, with the traditional N-ary Storage Model (NSM) layout, MiniTasking significantly reduces the L2 cache misses by up to 83, and thereby achieves 24% reduction in execution time. With the Partition Attributes Across (PAX) layout, MiniTasking further\u00a0\u2026", "num_citations": "4\n", "authors": ["447"]}
{"title": "ANEL: robust mobile network programming using a declarative language\n", "abstract": " The dynamics of mobile networks make it difficult for mobile apps to deliver a seamless user experience. In particular, intermittent connections and weak signals pose challenges for app developers. While recent network libraries have simplified network programming, much expert knowledge is still required. However, most mobile app developers are relative novices and tend to assume a reliable network connection, paying little attention to handling network errors in programming until users complain and leave bad reviews.", "num_citations": "2\n", "authors": ["447"]}
{"title": "Can Systems Explain Permissions Better? Understanding Users' Misperceptions under Smartphone Runtime Permission Model\n", "abstract": " Current smartphone operating systems enable users to manage permissions according to their personal preferences with a runtime permission model. Nonetheless, the systems provide very limited information when requesting permissions, making it difficult for users to understand permissions' capabilities and potentially induced risks.", "num_citations": "1\n", "authors": ["447"]}
{"title": "Tuning applications for efficient GPU offloading to in-memory processing\n", "abstract": " Data movement between processors and main memory is a critical bottleneck for data-intensive applications. This problem is more severe with Graphics Processing Units (GPUs) applications due to their massive parallel data processing characteristics. Recent research has shown that in-memory processing can greatly alleviate this data movement bottleneck by reducing traffic between GPUs and memory devices. It offloads execution to in-memory processors, and avoids transferring enormous data between memory devices and processors. However, while in-memory processing is promising, to fully take advantage of such architecture, we need to solve several issues. For example, the conventional GPU application code that is highly optimized for the locality to execute efficiently in GPU does not necessarily have good locality for in-memory processing. As such, the GPU may mistakenly offload application routines\u00a0\u2026", "num_citations": "1\n", "authors": ["447"]}