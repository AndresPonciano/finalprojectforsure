{"title": "Cause clue clauses: error localization using maximum satisfiability\n", "abstract": " Much effort is spent by programmers everyday in trying to reduce long, failing execution traces to the cause of the error. We present an algorithm for error cause localization based on a reduction to the maximal satisfiability problem (MAX-SAT), which asks what is the maximum number of clauses of a Boolean formula that can be simultaneously satisfied by an assignment. At an intuitive level, our algorithm takes as input a program and a failing test, and comprises the following three steps. First, using bounded model checking, and a bound obtained from the execution of the test, we encode the semantics of a bounded unrolling of the program as a Boolean trace formula. Second, for a failing program execution (e.g., one that violates an assertion or a post-condition), we construct an unsatisfiable formula by taking the formula and additionally asserting that the input is the failing test and that the assertion condition does\u00a0\u2026", "num_citations": "286\n", "authors": ["1615"]}
{"title": "Beyond HyTech: Hybrid Systems Analysis Using Interval Numerical Methods\n", "abstract": " Since hybrid embedded systems are pervasive and often safety-critical, guarantees about their correct performance are desirable. The hybrid systems model checker HyTech provides such guarantees and has successfully verified some systems. However, HyTech severely restricts the continuous dynamics of the system being analyzed and, therefore, often forces the use of prohibitively expensive discrete and polyhedral abstractions. We have designed a new algorithm, which is capable of directly verifying hybrid systems with general continuous dynamics, such as linear and nonlinear differential equations. The new algorithm conservatively overapproximates the reachable states of a hybrid automaton by using interval numerical methods. Interval numerical methods return sets of points that enclose the true result of numerical computation and, thus, avoid distortions due to the accumulation of round-off\u00a0\u2026", "num_citations": "210\n", "authors": ["1615"]}
{"title": "Discounting the future in systems theory\n", "abstract": " Discounting the future means that the value, today, of a unit payoffis 1 if the payoffo ccurs today, a if it occurs tomorrow, a                         2 if it occurs the day after tomorrow, and so on, for some real-valued discount factor 0 < a < 1. Discounting (or inflation) is a key paradigm in economics and has been studied in Markov decision processes as well as game theory. We submit that discounting also has a natural place in systems engineering: for nonterminating systems, a potential bug in the far-away future is less troubling than a potential bug today. We therefore develop a systems theory with discounting. Our theory includes several basic elements: discounted versions of system properties that correspond to the \u03c9-regular properties, fixpoint-based algorithms for checking discounted properties, and a quantitative notion of bisimilarity for capturing the difference between two states with respect to discounted\u00a0\u2026", "num_citations": "184\n", "authors": ["1615"]}
{"title": "Quantitative solution of omega-regular games\n", "abstract": " We consider two-player games played for an infinite number of rounds, with \u03c9-regular winning conditions. The games may be concurrent, in that the players choose their moves simultaneously and independently, and probabilistic, in that the moves determine a probability distribution for the successor state. We introduce quantitative game \u03bc-calculus, and we show that the maximal probability of winning such games can be expressed as the fixpoint formulas in this calculus. We develop the arguments both for deterministic and for probabilistic concurrent games; as a special case, we solve probabilistic turn-based games with \u03c9-regular winning conditions, which was also open. We also characterize the optimality, and the memory requirements, of the winning strategies. In particular, we show that while memoryless strategies suffice for winning games with safety and reachability conditions, B\u00fcchi conditions require the\u00a0\u2026", "num_citations": "170\n", "authors": ["1615"]}
{"title": "The element of surprise in timed games\n", "abstract": " We consider concurrent two-person games played in real time, in which the players decide both which action to play, and when to play it. Such timed games differ from untimed games in two essential ways. First, players can take each other by surprise, because actions are played with delays that cannot be anticipated by the opponent. Second, a player should not be able to win the game by preventing time from diverging. We present a model of timed games that preserves the element of surprise and accounts for time divergence in a way that treats both players symmetrically and applies to all \u03c9-regular winning conditions. We prove that the ability to take each other by surprise adds extra power to the players. For the case that the games are specified in the style of timed automata, we provide symbolic algorithms for their solution with respect to all \u03c9-regular winning conditions. We also show that for these\u00a0\u2026", "num_citations": "169\n", "authors": ["1615"]}
{"title": "Directed test generation using symbolic grammars\n", "abstract": " We present CESE, a tool that combines exhaustive enumeration of test inputs from a structured domain with symbolic execution driven test generation. We target programs whose valid inputs are determined by some context free grammar. We abstract the concrete input syntax with symbolic grammars, where some original tokens are replaced with symbolic constants. This reduces the set of input strings that must be enumerated exhaustively. For each enumerated input string, which may contain symbolic constants, symbolic execution based test generation instantiates the constants based on program execution paths. The\" template\" generated by enumerating valid strings reduces the burden on the symbolic execution to generate syntactically valid inputs and helps exercise interesting code paths. Together, symbolic grammars provide a link between exhaustive enumeration of valid inputs and execution-directed\u00a0\u2026", "num_citations": "160\n", "authors": ["1615"]}
{"title": "Markov decision processes with multiple objectives\n", "abstract": " We consider Markov decision processes (MDPs) with multiple discounted reward objectives. Such MDPs occur in design problems where one wishes to simultaneously optimize several criteria, for example, latency and power. The possible trade-offs between the different objectives are characterized by the Pareto curve. We show that every Pareto-optimal point can be achieved by a memoryless strategy; however, unlike in the single-objective case, the memoryless strategy may require randomization. Moreover, we show that the Pareto curve can be approximated in polynomial time in the size of the MDP. Additionally, we study the problem if a given value vector is realizable by any strategy, and show that it can be decided in polynomial time; but the question whether it is realizable by a deterministic memoryless strategy is NP-complete. These results provide efficient algorithms for design exploration in MDP\u00a0\u2026", "num_citations": "148\n", "authors": ["1615"]}
{"title": "Race detection for android applications\n", "abstract": " Programming environments for smartphones expose a concurrency model that combines multi-threading and asynchronous event-based dispatch. While this enables the development of efficient and feature-rich applications, unforeseen thread interleavings coupled with non-deterministic reorderings of asynchronous tasks can lead to subtle concurrency errors in the applications. In this paper, we formalize the concurrency semantics of the Android programming model. We further define the happens-before relation for Android applications, and develop a dynamic race detection technique based on this relation. Our relation generalizes the so far independently studied happens-before relations for multi-threaded programs and single-threaded event-driven programs. Additionally, our race detection technique uses a model of the Android runtime environment to reduce false positives. We have implemented a tool\u00a0\u2026", "num_citations": "145\n", "authors": ["1615"]}
{"title": "Rectangular hybrid games\n", "abstract": " In order to study control problems for hybrid systems, we generalize hybrid automata to hybrid games \u2014say, controller vs. plant. If we specify the continuous dynamics by constant lower and upper bounds, we obtain rectangular games. We show that for rectangular games with objectives expressed in Ltl (linear temporal logic), the winning states for each player can be computed, and winning strategies can be synthesized. Our result is sharp, as already reachability is undecidable for generalizations of rectangular systems, and optimal \u2014singly exponential in the size of the game structure and doubly exponential in the size of the Ltl objective. Our proof systematically generalizes the theory of hybrid systems from automata (single-player structures) [9] to games (multi-player structures): we show that the successively more general infinite-state classes of timed, 2D rectangular, and rectangular games induce\u00a0\u2026", "num_citations": "122\n", "authors": ["1615"]}
{"title": "On Nash equilibria in stochastic games\n", "abstract": " We study infinite stochastic games played by n-players on a finite graph with goals given by sets of infinite traces. The games are stochastic (each player simultaneously and independently chooses an action at each round, and the next state is determined by a probability distribution depending on the current state and the chosen actions), infinite (the game continues for an infinite number of rounds), nonzero sum (the players\u2019 goals are not necessarily conflicting), and undiscounted. We show that if each player has a reachability objective, that is, if the goal for each player i is to visit some subset R i of the states, then there exists an \u03b5-Nash equilibrium in memoryless strategies, for every \u03b5 >0. However, exact Nash equilibria need not exist. We study the complexity of finding such Nash equilibria, and show that the payoff of some \u03b5-Nash equilibrium in memoryless strategies can be \u03b5-approximated in NP\u00a0\u2026", "num_citations": "120\n", "authors": ["1615"]}
{"title": "Symbolic algorithms for infinite-state games\n", "abstract": " A procedure for the analysis of state spaces is called symbolic if it manipulates not individual states, but sets of states that are represented by constraints. Such a procedure can be used for the analysis of infinite state spaces, provided termination is guaranteed. We present symbolic procedures, and corresponding termination criteria, for the solution of infinite-state games, which occur in the control and modular verification of infinite-state systems. To characterize the termination of symbolic procedures for solving infinite-state games, we classify these game structures into four increasingly restrictive categories:                                         1                                             Class 1 consists of infinite-state structures for which all safety and reachability games can be solved.                                                                                2                                             Class 2 consists of infinite-state structures for which all \u03c9-regular games can be\u00a0\u2026", "num_citations": "114\n", "authors": ["1615"]}
{"title": "Interpolation for data structures\n", "abstract": " Interpolation based automatic abstraction is a powerful and robust technique for the automated analysis of hardware and software systems. Its use has however been limited to control-dominated applications because of a lack of algorithms for computing interpolants for data structures used in software programs. We present efficient procedures to construct interpolants for the theories of arrays, sets, and multisets using the reduction approach for obtaining decision procedures for complex data structures. The approach taken is that of reducing the theories of such data structures to the theories of equality and linear arithmetic for which efficient interpolating decision procedures exist. This enables interpolation based techniques to be applied to proving properties of programs that manipulate these data structures.", "num_citations": "107\n", "authors": ["1615"]}
{"title": "Engage: a deployment management system\n", "abstract": " Many modern applications are built by combining independently developed packages and services that are distributed over many machines with complex inter-dependencies. The assembly, installation, and management of such applications is hard, and usually performed either manually or by writing customized scripts. We present Engage, a system for configuring, installing, and managing complex application stacks. Engage consists of three components: a domain-specific model to describe component metadata and inter-component dependencies; a constraint-based algorithm that takes a partial installation specification and computes a full installation plan; and a runtime system that co-ordinates the deployment of the application across multiple machines and manages the deployed system. By explicitly modeling configuration metadata and inter-component dependencies, Engage enables static checking of\u00a0\u2026", "num_citations": "99\n", "authors": ["1615"]}
{"title": "Algorithmic verification of asynchronous programs\n", "abstract": " Asynchronous programming is a ubiquitous systems programming idiom for managing concurrent interactions with the environment. In this style, instead of waiting for time-consuming operations to complete, the programmer makes a non-blocking call to the operation and posts a callback task to a task buffer that is executed later when the time-consuming operation completes. A cooperative scheduler mediates the interaction by picking and executing callback tasks from the task buffer to completion (and these callbacks can post further callbacks to be executed later). Writing correct asynchronous programs is hard because the use of callbacks, while efficient, obscures program control flow. We provide a formal model underlying asynchronous programs and study verification problems for this model. We show that the safety verification problem for finite-data asynchronous programs is expspace-complete. We show\u00a0\u2026", "num_citations": "99\n", "authors": ["1615"]}
{"title": "Model checking discounted temporal properties\n", "abstract": " Temporal logic is two-valued: formulas are interpreted as either true or false. When applied to the analysis of stochastic systems, or systems with imprecise formal models, temporal logic is therefore fragile: even small changes in the model can lead to opposite truth values for a specification. We present a generalization of the branching-time logic C TL which achieves robustness with respect to model perturbations by giving a quantitative interpretation to predicates and logical operators, and by discounting the importance of events according to how late they occur. In every state, the value of a formula is a real number in the interval [0, 1], where 1 corresponds to truth and 0 to falsehood. The boolean operators and and or are replaced by min and max, the path quantifiers\u2203 and\u2200 determine sup and inf over all paths from a given state, and the temporal operators\u22c4 and\u25a1 specify sup and inf over a given path; a new\u00a0\u2026", "num_citations": "99\n", "authors": ["1615"]}
{"title": "MrCrypt: Static analysis for secure cloud computations\n", "abstract": " In a common use case for cloud computing, clients upload data and computation to servers that are managed by a third-party infrastructure provider. We describe MrCrypt, a system that provides data confidentiality in this setting by executing client computations on encrypted data. MrCrypt statically analyzes a program to identify the set of operations on each input data column, in order to select an appropriate homomorphic encryption scheme for that column, and then transforms the program to operate over encrypted data. The encrypted data and transformed program are uploaded to the server and executed as usual, and the result of the computation is decrypted on the client side. We have implemented MrCrypt for Java and illustrate its practicality on three standard benchmark suites for the Hadoop MapReduce framework. We have also formalized the approach and proven several soundness and security\u00a0\u2026", "num_citations": "93\n", "authors": ["1615"]}
{"title": "Tasks: language support for event-driven programming\n", "abstract": " The event-driven programming style is pervasive as an efficient method for interacting with the environment. Unfortunately, the event-driven style severely complicates program maintenance and understanding, as it requires each logical flow of control to be fragmented across multiple independent callbacks.", "num_citations": "83\n", "authors": ["1615"]}
{"title": "Quantifying similarities between timed systems\n", "abstract": " We define quantitative similarity functions between timed transition systems that measure the degree of closeness of two systems as a real, in contrast to the traditional boolean yes/no approach to timed simulation and language inclusion. Two systems are close if for each timed trace of one system, there exists a corresponding timed trace in the other system with the same sequence of events and closely corresponding event timings. We show that timed CTL is robust with respect to our quantitative version of bisimilarity, in particular, if a system satisfies a formula, then every close system satisfies a close formula. We also define a discounted version of CTL over timed systems, which assigns to every CTL formula a real value that is obtained by discounting real time. We prove the robustness of discounted CTL by establishing that close states in the bisimilarity metric have close values for all discounted CTL\u00a0\u2026", "num_citations": "81\n", "authors": ["1615"]}
{"title": "A classification of symbolic transition systems\n", "abstract": " We define five increasingly comprehensive classes of infinite-state systems, called STS1--STS5, whose state spaces have finitary structure. For four of these classes, we provide examples from hybrid systems.STS1 These are the systems with finite bisimilarity quotients. They can be analyzed symbolically by iteratively applying predecessor and Boolean operations on state sets, starting from a finite number of observable state sets. Any such iteration is guaranteed to terminate in that only a finite number of state sets can be generated. This enables model checking of the \u03bc-calculus.STS2 These are the systems with finite similarity quotients. They can be analyzed symbolically by iterating the predecessor and positive Boolean operations. This enables model checking of the existential and universal fragments of the \u03bc-calculus.STS3 These are the systems with finite trace-equivalence quotients. They can be analyzed\u00a0\u2026", "num_citations": "80\n", "authors": ["1615"]}
{"title": "From verification to control: Dynamic programs for omega-regular objectives\n", "abstract": " Dynamic programs, or fixpoint iteration schemes, are useful for solving many problems on state spaces. For Kripke structures, a rich fixpoint theory is available in the form of the /spl mu/-calculus, yet few connections have been made between different interpretations of fixpoint algorithms. We study the question of when a particular fixpoint iteration scheme /spl phi/ for verifying an /spl omega/-regular property /spl Psi/ on a Kripke structure can be used also for solving a two-player game on a game graph with winning objective /spl Psi/. We provide a sufficient and necessary criterion for the answer to be affirmative in the form of an extremal-model theorem for games: under a game interpretation, the dynamic program /spl phi/ solves the game with objective /spl Psi/ iff both (1) under an existential interpretation on Kripke structures, /spl phi/ is equivalent to /spl exist//spl Psi/, and (2) under a universal interpretation on Kripke\u00a0\u2026", "num_citations": "75\n", "authors": ["1615"]}
{"title": "Automatic verification of control system implementations\n", "abstract": " Software implementations of controllers for physical subsystems form the core of many modern safety-critical systems such as aircraft flight control and automotive engine control. A fundamental property of such implementations is stability, the guarantee that the physical plant converges to a desired behavior under the actions of the controller. We present a methodology and a tool to perform automated static analysis of embedded controller code for stability of the controlled physical system.", "num_citations": "74\n", "authors": ["1615"]}
{"title": "Approximate counting in SMT and value estimation for probabilistic programs\n", "abstract": " #SMT, or model counting for logical theories, is a well-known hard problem that generalizes such tasks as counting the number of satisfying assignments to a Boolean formula and computing the volume of a polytope. In the realm of satisfiability modulo theories (SMT) there is a growing need for model counting solvers, coming from several application domains (quantitative information flow, static analysis of probabilistic programs). In this paper, we show a reduction from an approximate version of #SMT to SMT.                 We focus on the theories of integer arithmetic and linear real arithmetic. We propose model counting algorithms that provide approximate solutions with formal bounds on the approximation error. They run in polynomial time and make a polynomial number of queries to the SMT solver for the underlying theory, exploiting \u201cfor free\u201d the sophisticated heuristics implemented within modern SMT\u00a0\u2026", "num_citations": "70\n", "authors": ["1615"]}
{"title": "Symbolic robustness analysis\n", "abstract": " A key feature of control systems is robustness, the property that small perturbations in the system inputs cause only small changes in its outputs. Robustness is key to designing systems that work under uncertain or imprecise environments. While continuous control design algorithms can explicitly incorporate robustness as a design goal, it is not clear if robustness is maintained at the software implementation level of the controller: two ``close'' inputs can execute very different code paths which may potentially produce vastly different outputs. We present an algorithm and a tool to characterize the robustness of a control software implementation. Our algorithm is based on symbolic execution and non-linear optimization, and computes the maximum difference in program outputs over all program paths when a program input is perturbed. As a by-product, our algorithm generates a set of test vectors which demonstrate\u00a0\u2026", "num_citations": "68\n", "authors": ["1615"]}
{"title": "Bug-Assist: assisting fault localization in ANSI-C programs\n", "abstract": " Several verification tools exist for checking safety properties of programs and reporting errors. However, a large part of the program development cycle is spend in analyzing the error trace to isolate locations in the code that are potential causes of the bug. Currently, this is usually performed manually, by stepping through the error trace in a debugger. We describe Bug-Assist, a tool that assists programmers localize error causes to a few lines of code. Bug-Assist takes as input an ANSI-C program annotated with assertions, performs bounded model checking to find potential assertion violations, and for each error trace returned by the model checker, returns a set of lines of code which can be changed to eliminate the error trace. Bug-Assist formulates error localization as a MAX-SAT problem and uses scalable MAX-SAT solvers. In experiments on a set of C benchmarks, Bug-Assist was able to reduce error\u00a0\u2026", "num_citations": "64\n", "authors": ["1615"]}
{"title": "Kuai: A model checker for software-defined networks\n", "abstract": " In software-defined networking (SDN), a software controller manages a distributed collection of switches by installing and uninstalling packet-forwarding rules in the switches. SDNs allow flexible implementations for expressive and sophisticated network management policies. We consider the problem of verifying that an SDN satisfies a given safety property. We describe Kuai, a distributed enumerative model checker for SDNs. Kuai takes as input a controller implementation written in Murphi, a description of the network topology (switches and connections), and a safety property, and performs a distributed enumerative reachability analysis on a cluster of machines. Kuai uses a set of partial order reduction techniques specific to the SDN domain that help reduce the state space dramatically. In addition, Kuai performs an automatic abstraction to handle unboundedly many packets traversing the network at a given time\u00a0\u2026", "num_citations": "62\n", "authors": ["1615"]}
{"title": "Time-safety checking for embedded programs\n", "abstract": " Giotto is a platform-independent language for specifying software for high-performance control applications. In this paper we present a new approach to the compilation of Giotto. Following this approach, the Giotto compiler generates code for a virtual machine, called the E machine, which can be ported to different platforms. The Giotto compiler also checks if the generated E code is time safe for a given platform, that is, if the platform offers sufficient performance to ensure that the E code is executed in a timely fashion that conforms with the Giotto semantics. Time-safety checking requires a schedulability analysis. We show that while for arbitrary E code, the analysis is exponential, for E code generated from typical Giotto programs, the analysis is polynomial. This supports our claim that Giotto identifies a useful fragment of embedded programs.", "num_citations": "61\n", "authors": ["1615"]}
{"title": "Symbolic model checking for rectangular hybrid systems\n", "abstract": " An important case of hybrid systems are the rectangular automata. First, rectangular dynamics can naturally and arbitrarily closely approximate more general, nonlinear dynamics. Second, rectangular automata are the most general type of hybrid systems for which model checking -in particular, Ltl model checking- is decidable. However, on one hand, the original proofs of decidability did not suggest practical algorithms and, on the other hand, practical symbolic model-checking procedures -such as those implemented in HyTech- were not known to terminate on rectangular automata. We remedy this unsatisfactory situation: we present a symbolic method for Ltl model checking which can be performed by HyTech and is guaranteed to terminate on all rectangular automata. We do so by proving that our method for symbolic Ltl model checking terminates on an infinite-state transition system if the trace\u00a0\u2026", "num_citations": "61\n", "authors": ["1615"]}
{"title": "A classification of symbolic transition systems\n", "abstract": " We define five increasingly comprehensive classes of infinite-state systems, called STS1\u20135, whose state spaces have finitary structure. For four of these classes, we provide examples from hybrid systems.             STS1 These are the systems with finite bisimilarity quotients. They can be analyzed symbolically by (1) iterating the predecessor and boolean operations starting from a finite set of observable state sets, and (2) terminating when no new state sets are generated. This enables model checking of the \u03bc-calculus.             STS2 These are the systems with finite similarity quotients. They can be analyzed symbolically by iterating the predecessor and positive boolean operations. This enables model checking of the existential and universal fragments of the \u03bc-calculus.             STS3 These are the systems with finite trace-equivalence quotients. They can be analyzed symbolically by iterating the predecessor\u00a0\u2026", "num_citations": "55\n", "authors": ["1615"]}
{"title": "Towards robustness for cyber-physical systems\n", "abstract": " While the importance of robustness in engineering design is well accepted, it is less clear how to design cyber-physical systems (CPS) for robustness. With the objective of developing a robustness theory for CPS, we introduce a notion of robustness for cyber systems inspired by existing notions of input-output stability in control theory. We show that the proposed notion of robustness captures two intuitive goals: bounded disturbances lead to bounded deviations from nominal behavior, and the effect of a sporadic disturbance disappears in finitely many steps. For cyber systems modeled as finite-state transducers, the proposed notion of robustness can be verified in pseudo-polynomial time. The synthesis problem, consisting of designing a controller enforcing robustness, can also be solved in pseudo-polynomial time.", "num_citations": "54\n", "authors": ["1615"]}
{"title": "Reducing test inputs using information partitions\n", "abstract": " Automatic symbolic techniques to generate test inputs, for example, through concolic execution, suffer from path explosion: the number of paths to be symbolically solved for grows exponentially with the number of inputs. In many applications though, the inputs can be partitioned into \u201cnon-interfering\u201d blocks such that symbolically solving for each input block while keeping all other blocks fixed to concrete values can find the same set of assertion violations as symbolically solving for the entire input. This can greatly reduce the number of paths to be solved (in the best case, from exponentially many to linearly many in the number of inputs). We present an algorithm that combines test input generation by concolic execution with dynamic computation and maintenance of information flow between inputs. Our algorithm iteratively constructs a partition of the inputs, starting with the finest (all inputs separate) and\u00a0\u2026", "num_citations": "54\n", "authors": ["1615"]}
{"title": "Fine-grained access control with object-sensitive roles\n", "abstract": " Role-based access control (RBAC) is a common paradigm to ensure that users have sufficient rights to perform various system operations. In many cases though, traditional RBAC does not easily express application-level security requirements. For instance, in a medical records system it is difficult to express that doctors should only update the records of their own patients. Further, traditional RBAC frameworks like Java\u2019s Enterprise Edition rely solely on dynamic checks, which makes application code fragile and difficult to ensure correct.               We introduce Object-sensitive RBAC (ORBAC), a generalized RBAC model for object-oriented languages. ORBAC resolves the expressiveness limitations of RBAC by allowing roles to be parameterized by properties of the business objects being manipulated. We formalize and prove sound a dependent type system that statically validates a program\u2019s conformance\u00a0\u2026", "num_citations": "53\n", "authors": ["1615"]}
{"title": "Abstract interpretation of game properties\n", "abstract": " We apply the theory of abstract interpretation to the verification of game properties for reactive systems. Unlike properties expressed in standard temporal logics, game properties can distinguish adversarial from collaborative relationships between the processes of a concurrent program, or the components of a parallel system. We consider two-player concurrent games \u2013say, component vs. environment\u2013 and specify properties of such games \u2013say, the component has a winning strategy to obtain a resource, no matter how the environment behaves\u2013 in the alternating-time \u03bc-calculus (A\u03bc ). A sound abstraction of such a game must at the same time restrict the behaviors of the component and increase the behaviors of the environment: if a less powerful component can win against a more powerful environment, then surely the original component can win against the original environment.               We formalize the\u00a0\u2026", "num_citations": "51\n", "authors": ["1615"]}
{"title": "Robust FPGA resynthesis based on fault-tolerant Boolean matching\n", "abstract": " We present FPGA logic synthesis algorithms for stochastic fault rate reduction in the presence of both permanent and transient defects. We develop an algorithm for fault tolerant Boolean matching (FTBM), which exploits the flexibility of the LUT configuration to maximize the stochastic yield rate for a logic function. Using FTBM, we propose a robust resynthesis algorithm (ROSE) which maximizes stochastic yield rate for an entire circuit. Finally, we show that existing PLB (programmable logic block) templates for area-aware Boolean matching and logic resynthesis are not effective for fault tolerance, and propose a new robust template with path re-convergence. Compared to the state-of-the-art academic technology mapper Berkeley ABC, ROSE using the proposed robust PLB template reduces the fault rate by 25% with 1% fewer LUTs, and increases MTBF (mean time between failures) by 31%, while preserving the\u00a0\u2026", "num_citations": "48\n", "authors": ["1615"]}
{"title": "Stack size analysis for interrupt-driven programs\n", "abstract": " We study the problem of determining stack boundedness and the exact maximum stack size for three classes of interrupt-driven programs. Interrupt-driven programs are used in many real-time applications that require responsive interrupt handling. In order to ensure responsiveness, programmers often enable interrupt processing in the body of lower-priority interrupt handlers. In such programs a programming error can allow interrupt handlers to be interrupted in cyclic fashion to lead to an unbounded stack, causing the system to crash. For a restricted class of interrupt-driven programs, we show that there is a polynomial-time procedure to check stack boundedness, while determining the exact maximum stack size is PSPACE-complete. For a larger class of programs, the two problems are both PSPACE-complete, and for the largest class of programs we consider, the two problems are PSPACE-hard and can\u00a0\u2026", "num_citations": "48\n", "authors": ["1615"]}
{"title": "Game relations and metrics\n", "abstract": " We consider two-player games played over finite state spaces for an infinite number of rounds. At each state, the players simultaneously choose moves; the moves determine a successor state. It is often advantageous for players to choose probability distributions over moves, rather than single moves. Given a goal (e.g., \"reach a target state\"), the question of winning is thus a probabilistic one: \"what is the maximal probability of winning from a given state?\". On these game structures, two fundamental notions are those of equivalences and metrics. Given a set of winning conditions, two states are equivalent if the players can win the same games with the same probability from both states. Metrics provide a bound on the difference in the probabilities of winning across states, capturing a quantitative notion of state \"similarity\". We introduce equivalences and metrics for two-player game structures, and we show that they\u00a0\u2026", "num_citations": "47\n", "authors": ["1615"]}
{"title": "Pessoa 2.0: a controller synthesis tool for cyber-physical systems\n", "abstract": " We introduce PESSOA 2.0, a tool that automatically synthesizes controllers for cyber-physical systems based on correct-by-design methodology. PESSOA 2.0 accepts a cyber-physical system represented by a set of smooth differential equations and automata and a specification in a fragment of Linear Temporal Logic that is expressive enough to describe interesting properties but simple enough to avoid Safra's construction. It outputs, if possible, a controller for the system that enforces the specification up to an abstraction parameter. We report on examples illustrating the expressiveness of the fragment and the controllers synthesized by the tool.", "num_citations": "45\n", "authors": ["1615"]}
{"title": "Backstepping controller synthesis and characterizations of incremental stability\n", "abstract": " Incremental stability is a property of dynamical and control systems, requiring the uniform asymptotic stability of every trajectory, rather than that of an equilibrium point or a particular time-varying trajectory. Similarly to stability, Lyapunov functions and contraction metrics play important roles in the study of incremental stability. In this paper, we provide characterizations and descriptions of incremental stability in terms of existence of coordinate-invariant notions of incremental Lyapunov functions and contraction metrics, respectively. Most design techniques providing controllers rendering control systems incrementally stable have two main drawbacks: they can only be applied to control systems in either parametric-strict-feedback or strict-feedback form, and they require these control systems to be smooth. In this paper, we propose a design technique that is applicable to larger classes of control systems, including a\u00a0\u2026", "num_citations": "44\n", "authors": ["1615"]}
{"title": "Multi-layered abstraction-based controller synthesis for continuous-time systems\n", "abstract": " We present multi-layered abstraction-based controller synthesis, which extends standard abstraction-based controller synthesis (ABCS) algorithms for continuous-time control systems by simultaneously maintaining several\" layers\" of abstract systems with decreasing precision. The resulting abstract multi-layered controller uses the coarsest abstraction whenever this is feasible, and dynamically adjusts the precision---by moving to a more precise abstraction and back to a coarser abstraction---based on the structure of the given control problem. Abstract multi-layered controllers can be refined to controllers with non-uniform resolution using feedback refinement relations established between each abstract layer and the concrete system, resulting in a sound ABCS method. We provide multi-layered controller synthesis algorithms for reachability, safety, and generalized B\u00fcchi specifications; our approach can be\u00a0\u2026", "num_citations": "42\n", "authors": ["1615"]}
{"title": "Exploiting symmetry in SAT-based Boolean matching for heterogeneous FPGA technology mapping\n", "abstract": " The Boolean matching problem is a key procedure in technology mapping for heterogeneous field programmable gate arrays (FPGA), and SAT-based Boolean matching (SAT-BM) provides a highly flexible solution for various FPGA architectures. However, the computational complexity of state-of-the-art SAT-BM prohibits its application practically. In this paper we propose an efficient SAT-BM algorithm by exploring function and architectural symmetries. While the most recent work obtained up to 13times speedup, we achieve up to 200times speedup, when both are compared to the original SAT-BM algorithm.", "num_citations": "40\n", "authors": ["1615"]}
{"title": "Testing cyber-physical systems through bayesian optimization\n", "abstract": " Many problems in the design and analysis of cyber-physical systems (CPS) reduce to the following optimization problem: given a CPS which transforms continuous-time input traces in Rm to continuous-time output traces in Rn and a cost function over output traces, find an input trace which minimizes the cost. Cyber-physical systems are typically so complex that solving the optimization problem analytically by examining the system dynamics is not feasible. We consider a black-box approach, where the optimization is performed by testing the input-output behaviour of the CPS. We provide a unified, tool-supported methodology for CPS testing and optimization. Our tool is the first CPS testing tool that supports Bayesian optimization. It is also the first to employ fully automated dimensionality reduction techniques. We demonstrate the potential of our tool by running experiments on multiple industrial case studies. We\u00a0\u2026", "num_citations": "39\n", "authors": ["1615"]}
{"title": "Performance-aware scheduler synthesis for control systems\n", "abstract": " We consider the problem of designing a cyber-physical system where several control loops share the same architectural resources. Typically, the design of such systems proceeds in two steps. In the platform independent step, for each control loop in the system, the control designer calculates a control law and a sampling time that together ensure that the control loop has certain desired performance. Then, in the platform dependent step, these control tasks are scheduled on the platform, and a schedulability analysis determines if (and how) the control laws can be implemented and scheduled without missing the sampling deadlines. In this paper, we explore an alternative controller-scheduler co-design approach that aims to achieve optimal performance for all the individual control loops maintaining fairness. We first analyze the control systems to find out the rates at which control signals should be dropped to\u00a0\u2026", "num_citations": "39\n", "authors": ["1615"]}
{"title": "Stochastic limit-average games are in EXPTIME\n", "abstract": " The value of a finite-state two-player zero-sum stochastic game with limit-average payoff can be approximated to within  in time exponential in a polynomial in the size of the game times polynomial in logarithmic in  , for all  .", "num_citations": "38\n", "authors": ["1615"]}
{"title": "Robust discrete synthesis against unspecified disturbances\n", "abstract": " Systems working in uncertain environments should possess a robustness property, which ensures that the behaviours of the system remain close to the original behaviours under the influence of unmodeled, but bounded, disturbances. We present a theory and algorithmic tools for the design of robust discrete controllers for \u03c0-regular properties on discrete transition systems. Formally, we define metric automata-automata equipped with a metric on states-and strategies on metric automata which guarantee robustness for \u03c0-regular properties. We present graph-theoretic algorithms to construct such strategies in polynomial time. In contrast to strategies computed by classical automata-theoretic algorithms, the strategies computed by our algorithm ensure that the behaviours of the controlled system under disturbances satisfy a related property which depends on the magnitude of the disturbance. We show an application\u00a0\u2026", "num_citations": "35\n", "authors": ["1615"]}
{"title": "Compositional synthesis of finite-state abstractions\n", "abstract": " Controller-synthesis techniques for continuous systems with respect to temporal logic specifications typically use a finite-state symbolic abstraction of the system model. Constructing this abstraction for the entire system is computationally expensive, and does not exploit natural decompositions of many systems into interacting components. We describe a methodology for compositional symbolic abstraction to help scale controller synthesis for temporal logic to larger systems. We introduce disturbance bisimulation, which strengthens the standard approximate alternating bisimulation relation used in control. It extends naturally to systems that are composed of weakly interconnected subcomponents, possibly connected in feedback, and models the coupling signals as disturbances. We show how networks of incrementally input-to-state stable, nonlinear, continuous-time control systems can be abstracted\u00a0\u2026", "num_citations": "34\n", "authors": ["1615"]}
{"title": "Language-theoretic abstraction refinement\n", "abstract": " We give a language-theoretic counterexample-guided abstraction refinement (CEGAR) algorithm for the safety verification of recursive multi-threaded programs. First, we reduce safety verification to the (undecidable) language emptiness problem for the intersection of context-free languages. Initially, our CEGAR procedure overapproximates the intersection by a context-free language. If the overapproximation is empty, we declare the system safe. Otherwise, we compute a bounded language from the overapproximation and check emptiness for the intersection of the context free languages and the bounded language (which is decidable). If the intersection is non-empty, we report a bug. If empty, we refine the overapproximation by removing the bounded language and try again. The key idea of the CEGAR loop is the language-theoretic view: different strategies to get regular overapproximations and bounded\u00a0\u2026", "num_citations": "34\n", "authors": ["1615"]}
{"title": "Algorithms for game metrics\n", "abstract": " Simulation and bisimulation metrics for stochastic systems provide a quantitative generalization of the classical simulation and bisimulation relations. These metrics capture the similarity of states with respect to quantitative specifications written in the quantitative {\\mu}-calculus and related probabilistic logics. We first show that the metrics provide a bound for the difference in long-run average and discounted average behavior across states, indicating that the metrics can be used both in system verification, and in performance evaluation. For turn-based games and MDPs, we provide a polynomial-time algorithm for the computation of the one-step metric distance between states. The algorithm is based on linear programming; it improves on the previous known exponential-time algorithm based on a reduction to the theory of reals. We then present PSPACE algorithms for both the decision problem and the problem of approximating the metric distance between two states, matching the best known algorithms for Markov chains. For the bisimulation kernel of the metric our algorithm works in time O(n^4) for both turn-based games and MDPs; improving the previously best known O(n^9\\cdot log(n)) time algorithm for MDPs. For a concurrent game G, we show that computing the exact distance between states is at least as hard as computing the value of concurrent reachability games and the square-root-sum problem in computational geometry. We show that checking whether the metric distance is bounded by a rational r, can be done via a reduction to the theory of real closed fields, involving a formula with three quantifier alternations, yielding O(|G|^O(|G\u00a0\u2026", "num_citations": "33\n", "authors": ["1615"]}
{"title": "IPR: In-place reconfiguration for FPGA fault tolerance\n", "abstract": " We describe In-Place Reconfiguration (IPR) for LUT-based FPGAs, an algorithm that maximizes identical configuration bits for complementary inputs of a LUT thereby reducing the propagation of faults seen at a pair of complementary inputs. Based on IPR, we develop a fault-tolerant logic resynthesis algorithm which decreases the circuit fault rate while preserving functionality and topology of the LUT-based logic network. Since the topology is preserved, the resynthesis algorithm can be applied post-layout and without changes in physical design. Compared to the state-of-the-art academic technology mapper Berkeley ABC, IPR reduces the relative fault rate by 48% and increases MTTF by 1.94\u00d7 with the same area and performance, and IPR combined with a previous fault-tolerant logic resynthesis algorithm (ROSE) reduces the relative fault rate by 49% and increases MTTF by 2.40\u00d7 with 19% less area but same\u00a0\u2026", "num_citations": "32\n", "authors": ["1615"]}
{"title": "Quantifying conformance using the skorokhod metric\n", "abstract": " The conformance testing problem for dynamical systems asks, given two dynamical models (e.g., as Simulink diagrams), whether their behaviors are \u201cclose\u201d to each other. In the semi-formal approach to conformance testing, the two systems are simulated on a large set of tests, and a metric, defined on pairs of real-valued, real-timed trajectories, is used to determine a lower bound on the distance. We show how\u00a0the Skorokhod metric on continuous dynamical systems can be used as the foundation for conformance testing of complex dynamical models. The Skorokhod metric allows for both state value mismatches and timing distortions, and is thus well suited for checking conformance between idealized models of dynamical systems and their implementations. We demonstrate the robustness of the metric by proving a transference theorem: trajectories close under the Skorokhod metric satisfy \u201cclose\u201d logical\u00a0\u2026", "num_citations": "31\n", "authors": ["1615"]}
{"title": "Game refinement relations and metrics\n", "abstract": " We consider two-player games played over finite state spaces for an infinite number of rounds. At each state, the players simultaneously choose moves; the moves determine a successor state. It is often advantageous for players to choose probability distributions over moves, rather than single moves. Given a goal, for example, reach a target state, the question of winning is thus a probabilistic one: what is the maximal probability of winning from a given state? On these game structures, two fundamental notions are those of equivalences and metrics. Given a set of winning conditions, two states are equivalent if the players can win the same games with the same probability from both states. Metrics provide a bound on the difference in the probabilities of winning across states, capturing a quantitative notion of state similarity. We introduce equivalences and metrics for two-player game structures, and we show that they characterize the difference in probability of winning games whose goals are expressed in the quantitative mu-calculus. The quantitative mu-calculus can express a large set of goals, including reachability, safety, and omega-regular properties. Thus, we claim that our relations and metrics provide the canonical extensions to games, of the classical notion of bisimulation for transition systems. We develop our results both for equivalences and metrics, which generalize bisimulation, and for asymmetrical versions, which generalize simulation.", "num_citations": "31\n", "authors": ["1615"]}
{"title": "Model checking discounted temporal properties\n", "abstract": " Temporal logic is two-valued: a property is either true or false. When applied to the analysis of stochastic systems, or systems with imprecise formal models, temporal logic is therefore fragile: even small changes in the model can lead to opposite truth values for a specification. We present a generalization of the branching-time logic Ctl which achieves robustness with respect to model perturbations by giving a quantitative interpretation to predicates and logical operators, and by discounting the importance of events according to how late they occur. In every state, the value of a formula is a real number in the interval [0,1], where 1 corresponds to truth and 0 to falsehood. The boolean operators and and or are replaced by min and max, the path quantifiers \u2203 and \u2200 determine sup and inf over all paths from a given state, and the temporal operators  and \u25a1 specify sup and inf over a given path; a new operator\u00a0\u2026", "num_citations": "31\n", "authors": ["1615"]}
{"title": "Synthesis of minimal-error control software\n", "abstract": " Software implementations of controllers for physical systems are at the core of many embedded systems. The design of controllers uses the theory of dynamical systems to construct a mathematical control law that ensures that the controlled system has certain properties, such as asymptotic convergence to an equilibrium point, and optimizes some performance criteria such as LQR-LQG. However, owing to quantization errors arising from the use of fixed-point arithmetic, the implementation of this control law can only guarantee practical stability: under the actions of the implementation, the trajectories of the controlled system converge to a bounded set around the equilibrium point, and the size of the bounded set is proportional to the error in the implementation. The problem of verifying whether a controller implementation achieves practical stability for a given bounded set has been studied before. In this paper, we\u00a0\u2026", "num_citations": "30\n", "authors": ["1615"]}
{"title": "Approximately bisimilar symbolic models for digital control systems\n", "abstract": " Symbolic approaches to control hybrid systems construct a discrete approximately-bisimilar abstraction of a continuous control system and apply automata-theoretic techniques to construct controllers enforcing given specifications. For the class of digital control systems (i.e., whose control signals are piecewise constant) satisfying incremental input-to-state stability (\u03b4-ISS), existing techniques to compute discrete abstractions begin with a quantization of the state and input sets, and show that the quantized system is approximately bisimilar to the original if the sampling time is sufficiently large or if the Lyapunov functions of the system decrease fast enough. If the sampling time is not sufficiently large, the former technique fails to apply. While abstraction based on Lyapunov functions may be applicable, because of the conservative nature of Lyapunov functions in practice, the size of the discrete abstraction may\u00a0\u2026", "num_citations": "30\n", "authors": ["1615"]}
{"title": "Fault-tolerant resynthesis with dual-output LUTs\n", "abstract": " We present a fault-tolerant post-mapping resynthesis for FPGA-based designs that exploits the dual-output feature of modern FPGA architectures to improve the reliability of a mapped circuit against faults. Emerging FPGA architectures, such as 6-LUTs in Xilinx Virtex-5 and 8-input ALMs in Altera Stratix-III, have a secondary LUT output that allows access to non-occupied SRAM bits. We show that this architectural feature can be used to build redundancy for fault masking with limited area and performance overhead. Our algorithm improves reliability of a mapping by performing two basic operations: duplication (in which free configuration bits are used to duplicate a logic function whose value is obtained at the secondary output) and encoding (in which two copies of the same logic function are ANDed or ORed together in the fanout of the duplicated logic). The problem of fault tolerant post-mapping resynthesis is then\u00a0\u2026", "num_citations": "30\n", "authors": ["1615"]}
{"title": "Compositional abstractions of interconnected discrete-time stochastic control systems\n", "abstract": " This paper is concerned with a compositional approach for constructing abstractions of interconnected discrete-time stochastic control systems. The abstraction framework is based on new notions of so-called stochastic simulation functions, using which one can quantify the distance between original interconnected stochastic control systems and their abstractions in the probabilistic setting. Accordingly, one can leverage the proposed results to perform analysis and synthesis over abstract interconnected systems, and then carry the results over concrete ones. In the first part of the paper, we derive sufficient small-gain type conditions for the compositional quantification of the distance in probability between the interconnection of stochastic control subsystems and that of their abstractions. In the second part of the paper, we focus on the class of discrete-time linear stochastic control systems with independent noises in\u00a0\u2026", "num_citations": "29\n", "authors": ["1615"]}
{"title": "Bounded underapproximations\n", "abstract": " We show a new and constructive proof of the following language-theoretic result: for every context-free language L, there is a bounded context-free language L\u2032\u2286L which has the same Parikh (commutative) image as L. Bounded languages, introduced by Ginsburg and Spanier, are subsets of regular languages of the form  for some w                 1,\u2026,w                                    m                 \u2208\u03a3                 \u2217. In particular bounded context-free languages have nice structural and decidability properties. Our proof proceeds in two parts. First, we give a new construction that shows that each context free language L has a subset L                                    N                  that has the same Parikh image as L and that can be represented as a sequence of substitutions on a linear language. Second, we inductively construct a Parikh-equivalent bounded context-free subset of L                                    N                 .               We show\u00a0\u2026", "num_citations": "27\n", "authors": ["1615"]}
{"title": "Bounded underapproximations\n", "abstract": " We show a new and constructive proof of the following language-theoretic result: for every context-free language L, there is a bounded context-free language L\u2032\u2009\u2286\u2009L which has the same Parikh (commutative) image as L. Bounded languages, introduced by Ginsburg and Spanier, are subsets of regular languages of the form  for some . In particular bounded context-free languages have nice structural and decidability properties. Our proof proceeds in two parts. First, using Newton\u2019s iterations on the language semiring, we construct a context-free subset L                                    N                  of L that can be represented as a sequence of substitutions on a linear language and has the same Parikh image as L. Second, we inductively construct a Parikh-equivalent bounded context-free subset of L                                    N                 .               As an application of this result in model checking, we\u00a0\u2026", "num_citations": "26\n", "authors": ["1615"]}
{"title": "Code aware resource management\n", "abstract": " Multithreaded programs coordinate their interaction through synchronization primitives like mutexes and semaphores, which are managed by an OS-provided resource manager. We propose algorithms for the automatic construction of code-aware resource managers for multithreaded embedded applications. Such managers use knowledge about the structure and resource usage (mutex and semaphore usage) of the threads to guarantee deadlock freedom and progress while managing resources in an efficient way. Our algorithms compute managers as winning strategies in certain infinite games, and produce a compact code description of these strategies. We have implemented the algorithms in the tool Cynthesis. Given a multithreaded program in C, the tool produces C~ code implementing a code-aware resource manager. We show in experiments that Cynthesis produces compact resource managers within a\u00a0\u2026", "num_citations": "26\n", "authors": ["1615"]}
{"title": "Antlab: A multi-robot task server\n", "abstract": " We present Antlab, an end-to-end system that takes streams of user task requests and executes them using collections of robots. In Antlab, each request is specified declaratively in linear temporal logic extended with quantifiers over robots. The user does not program robots individually, nor know how many robots are available at any time or the precise state of the robots. The Antlab runtime system manages the set of robots, schedules robots to perform tasks, automatically synthesizes robot motion plans from the task specification, and manages the co-ordinated execution of the plan. We provide a constraint-based formulation for simultaneous task assignment and plan generation for multiple robots working together to satisfy a task specification. In order to scalably handle multiple concurrent tasks, we take a separation of concerns view to plan generation. First, we solve each planning problem in isolation, with an\u00a0\u2026", "num_citations": "25\n", "authors": ["1615"]}
{"title": "Verification of population protocols\n", "abstract": " Population protocols [Angluin et al., PODC, 2004] are a formal model of sensor networks consisting of identical mobile devices. Two devices can interact and thereby change their states. Computations are infinite sequences of interactions satisfying a strong fairness constraint. A population protocol is well-specified if for every initial configuration C of devices, and every computation starting at C, all devices eventually agree on a consensus value depending only on C. If a protocol is well-specified, then it is said to compute the predicate that assigns to each initial configuration its consensus value. While the predicates computable by well-specified protocols have been extensively studied, the two basic verification problems remain open: is a given protocol well-specified? Does a protocol compute a given predicate? We prove that both problems are decidable. Our results also prove decidability of a natural question about home spaces of Petri nets.", "num_citations": "25\n", "authors": ["1615"]}
{"title": "Compositional quantitative reasoning\n", "abstract": " We present a compositional theory of system verification, where specifications assign real-numbered costs to systems. These costs can express a wide variety of quantitative system properties, such as resource consumption, price, or a measure of how well a system satisfies its specification. The theory supports the composition of systems and specifications, and the hiding of variables. Boolean refinement relations are replaced by real-numbered distances between descriptions of a system at different levels of detail. We show that the classical Boolean rules for compositional reasoning have quantitative counterparts in our setting. While our general theory allows costs to be specified by arbitrary cost functions, we also consider a class of linear cost functions, which give rise to an instance of our framework where all operations are computable in polynomial time", "num_citations": "25\n", "authors": ["1615"]}
{"title": "Dynamic scheduling for networked control systems\n", "abstract": " An integrated approach, embracing both control and scheduling theories, is proposed to implement multiple control loops upon shared network and computational resources, where the network may additionally introduce packet losses. Each control system is first analyzed from a control-theoretic perspective in order to determine the asymptotic rate at which control signals must be computed to maintain stability and optimal performance despite network losses. Since required completion rates for control tasks are asymptotic, and network packet drops uncertain, the problem of scheduling multiple such control tasks upon shared computational resources does not map to known problems in real-time scheduling. It is therefore formalized here as a new form of periodic task scheduling problem--one in which each task has an associated asymptotic completion rate requirement. Sufficient schedulability conditions are\u00a0\u2026", "num_citations": "24\n", "authors": ["1615"]}
{"title": "Stack size analysis for interrupt-driven programs\n", "abstract": " We study the problem of determining stack boundedness and the exact maximum stack size for three classes of interrupt-driven programs. Interrupt-driven programs are used in many real-time applications that require responsive interrupt handling. In order to ensure responsiveness, programmers often enable interrupt processing in the body of lower-priority interrupt handlers. In such programs a programming error can allow interrupt handlers to be interrupted in a cyclic fashion to lead to an unbounded stack, causing the system to crash. For a restricted class of interrupt-driven programs, we show that there is a polynomial-time procedure to check stack boundedness, while determining the exact maximum stack size is PSPACE-complete. For a larger class of programs, the two problems are both PSPACE-complete, and for the largest class of programs we consider, the two problems are PSPACE-hard and can be\u00a0\u2026", "num_citations": "24\n", "authors": ["1615"]}
{"title": "Rely/guarantee reasoning for asynchronous programs\n", "abstract": " Asynchronous programming has become ubiquitous in smartphone and web application development, as well as in the development of server-side and system applications. Many of the uses of asynchrony can be modeled by extending programming languages with asynchronous procedure calls-procedures not executed immediately, but stored and selected for execution at a later point by a non-deterministic scheduler. Asynchronous calls induce a flow of control that is difficult to reason about, which in turn makes formal verification of asynchronous programs challenging. In response, we take a rely/guarantee approach: Each asynchronous procedure is verified separately with respect to its rely and guarantee predicates; the correctness of the whole program then follows from the natural conditions the rely/guarantee predicates have to satisfy. In this way, the verification of asynchronous programs is modularly decomposed into the more usual verification of sequential programs with synchronous calls. For the sequential program verification we use Hoare-style deductive reasoning, which we demonstrate on several simplified examples. These examples were inspired from programs written in C using the popular Libevent library; they are manually annotated and verified within the state-of-the-art Frama-C platform.", "num_citations": "23\n", "authors": ["1615"]}
{"title": "Input-output robustness for discrete systems\n", "abstract": " Robustness is the property that a system only exhibits small deviations from the nominal behavior upon the occurrence of small disturbances. While the importance of robustness in engineering design is well accepted, it is less clear how to verify and design discrete systems for robustness. We present a theory of input-output robustness for discrete systems inspired by existing notions of input-output stability (IO-stability) in continuous control theory. We show that IO-stability captures two intuitive goals of robustness: bounded disturbances lead to bounded deviations from nominal behavior, and the effect of a sporadic disturbance disappears in finitely many steps. We show that existing notions of robustness for discrete systems do not have these two properties. For systems modeled as finite-state transducers, we show that IO-stability can be verified and the synthesis problem can be solved in polynomial time. We\u00a0\u2026", "num_citations": "23\n", "authors": ["1615"]}
{"title": "CLSE: Closed-loop symbolic execution\n", "abstract": " We present CLSE, a closed-loop symbolic execution engine for control system implementations. CLSE takes as input the description of a physical plant represented by a system of linear ordinary differential equations, the software implementation and execution frequency for a discrete-time controller that senses and actuates the plant, and a time horizon, and symbolically executes the closed-loop system \u2014the combination of the plant and the controller\u2014 up to the time horizon. The execution helps capture the bounded-time dynamics of the system in terms of the finite sequences of the plant\u2019s sampled state-sets and symbolic control inputs. We show the use of CLSE in symbolic execution of a set of control systems benchmarks. Using the symbolic execution engine, we also build a robustness analysis tool which computes the maximum deviation of the states of the plant due to measurement uncertainties in\u00a0\u2026", "num_citations": "23\n", "authors": ["1615"]}
{"title": "Rewiring for robustness\n", "abstract": " Logic synthesis for soft error mitigation is increasingly important in a wide range of applications of FPGAs. We present R2, an algorithm for rewiring a post-layout LUT-based circuit that reduces the overall criticality of the circuit, where criticality is the fraction of primary inputs that lead to observable errors at the primary outputs if an single event upset inverts a configuration bit. Our algorithm explicitly optimizes the robustness of the interconnect, the dominant component of FPGAs. The key idea of R2 is to exploit Boolean flexibilities in the circuit implementation to replace wires with high criticality with those with lower criticality while preserving the circuit functionality. We estimate criticalities using a Monte Carlo fault simulation. We represent flexibilities using SPFDs (Set of Pairs of Functions to be Distinguished), and use criticality information to choose candidates for rewiring, assigning the maximum flexibility to high\u00a0\u2026", "num_citations": "23\n", "authors": ["1615"]}
{"title": "Quadratic word equations with length constraints, counter systems, and presburger arithmetic with divisibility\n", "abstract": " Word equations are a crucial element in the theoretical foundation of constraint solving over strings. A word equation relates two words over string variables and constants. Its solution amounts to a function mapping variables to constant strings that equate the left and right hand sides of the equation. While the problem of solving word equations is decidable, the decidability of the problem of solving a word equation with a length constraint (i.e., a constraint relating the lengths of words in the word equation) has remained a long-standing open problem. We focus on the subclass of quadratic word equations, i.e., in which each variable occurs at most twice. We first show that the length abstractions of solutions to quadratic word equations are in general not Presburger-definable. We then describe a class of counter systems with Presburger transition relations which capture the length abstraction of a quadratic\u00a0\u2026", "num_citations": "22\n", "authors": ["1615"]}
{"title": "Shrinking horizon model predictive control with chance-constrained signal temporal logic specifications\n", "abstract": " We present Shrinking Horizon Model Predictive Control (SHMPC) for linear dynamical systems, under stochastic disturbances, with probabilistic constraints encoded as Signal Temporal Logic (STL) specifications. The control objective is to minimize a cost function under the restriction that the given STL specification be satisfied with some minimum probability. The presented approach utilizes the knowledge of the disturbance distribution to synthesize the controller in SHMPC. We show that this synthesis problem can be (conservatively) transformed into sequential optimizations involving linear constraints. We experimentally demonstrate the effectiveness of our proposed approach by evaluating its performance on room temperature control of a building.", "num_citations": "22\n", "authors": ["1615"]}
{"title": "Parameterized verification of asynchronous shared-memory systems\n", "abstract": " We characterize the complexity of the safety verification problem for parameterized systems consisting of a leader process and arbitrarily many anonymous and identical contributors. Processes communicate through a shared, bounded-value register. While each operation on the register is atomic, there is no synchronization primitive to execute a sequence of operations atomically. We analyze the complexity of the safety verification problem when processes are modeled by finite-state machines, pushdown machines, and Turing machines. The problem is coNP-complete when all processes are finite-state machines, and is PSPACE-complete when they are pushdown machines. The complexity remains coNP-complete when each Turing machine is allowed boundedly many interactions with the register. Our proofs use combinatorial characterizations of computations in the model, and in the case of pushdown\u00a0\u2026", "num_citations": "22\n", "authors": ["1615"]}
{"title": "Model checking database applications\n", "abstract": " We describe the design of DPF, an explicit-state model checker for database-backed web applications. DPF interposes between the program and the database layer, and precisely tracks the effects of queries made to the database. We experimentally explore several implementation choices for the model checker: stateful vs. stateless search, state storage and backtracking strategies, and dynamic partial-order reduction. In particular, we define independence relations at different granularity levels of the database (at the database, relation, record, attribute, or cell level), and show the effectiveness of dynamic partial-order reduction based on these relations.               We apply DPF to look for atomicity violations in web applications. Web applications maintain shared state in databases, and typically there are relatively few database accesses for each request. This implies concurrent interactions are limited to\u00a0\u2026", "num_citations": "22\n", "authors": ["1615"]}
{"title": "Controller synthesis with budget constraints\n", "abstract": " We study the controller synthesis problem under budget constraints. In this problem, there is a cost associated with making an observation, and a controller can make only a limited number of observations in each round so that the total cost of the observations does not exceed a given fixed budget. The controller must ensure some \u03c9-regular requirement subject to the budget constraint. Budget constraints arise in designing and implementing controllers for resource-constrained embedded systems, where a controller may not have enough power, time, or bandwidth to obtain data from all sensors in each round. They lead to games of imperfect information, where the unknown information is not fixed a priori, but can vary from round to round, based on the choices made by the controller how to allocate its budget.               We show that the budget-constrained synthesis problem for \u03c9-regular objectives is\u00a0\u2026", "num_citations": "22\n", "authors": ["1615"]}
{"title": "Joint inference of reward machines and policies for reinforcement learning\n", "abstract": " Incorporating high-level knowledge is an effective way to expedite reinforcement learning (RL), especially for complex tasks with sparse rewards. We investigate an RL problem where the high-level knowledge is in the form of reward machines, a type of Mealy machines that encode non-Markovian reward functions. We focus on a setting in which this knowledge is a priori not available to the learning agent. We develop an iterative algorithm that performs joint inference of reward machines and policies for RL (more specifically, q-learning). In each iteration, the algorithm maintains a hypothesis reward machine and a sample of RL episodes. It uses a separate q-function defined for each state of the current hypothesis reward machine to determine the policy and performs RL to update the q-functions. While performing RL, the algorithm updates the sample by adding RL episodes along which the obtained rewards are inconsistent with the rewards based on the current hypothesis reward machine. In the next iteration, the algorithm infers a new hypothesis reward machine from the updated sample. Based on an equivalence relation between states of reward machines, we transfer the q-functions between the hypothesis reward machines in consecutive iterations. We prove that the proposed algorithm converges almost surely to an optimal policy in the limit. The experiments show that learning high-level knowledge in the form of reward machines leads to fast convergence to optimal policies in RL, while the baseline RL methods fail to converge to optimal policies after a substantial number of training steps.", "num_citations": "21\n", "authors": ["1615"]}
{"title": "Symbolic controller synthesis for B\u00fcchi specifications on stochastic systems\n", "abstract": " We consider the policy synthesis problem for continuous-state controlled Markov processes evolving in discrete time, when the specification is given as a B\u00fcchi condition (visit a set of states infinitely often). We decompose computation of the maximal probability of satisfying the B\u00fcchi condition into two steps. The first step is to compute the maximal qualitative winning set, from where the B\u00fcchi condition can be enforced with probability one. The second step is to find the maximal probability of reaching the already computed qualitative winning set. In contrast with finite-state models, we show that such a computation only gives a lower bound on the maximal probability where the gap can be non-zero.", "num_citations": "21\n", "authors": ["1615"]}
{"title": "Fair termination for parameterized probabilistic concurrent systems\n", "abstract": " We consider the problem of automatically verifying that a parameterized family of probabilistic concurrent systems terminates with probability one for all instances against adversarial schedulers. A parameterized family defines an infinite-state system: for each number n, the family consists of an instance with n finite-state processes. In contrast to safety, the parameterized verification of liveness is currently still considered extremely challenging especially in the presence of probabilities in the model. One major challenge is to provide a sufficiently powerful symbolic framework. One well-known symbolic framework for the parameterized verification of non-probabilistic concurrent systems is regular model checking. Although the framework was recently extended to probabilistic systems, incorporating fairness in the framework\u2014often crucial for verifying termination\u2014has been especially difficult due to the\u00a0\u2026", "num_citations": "21\n", "authors": ["1615"]}
{"title": "Partial order reduction for event-driven multi-threaded programs\n", "abstract": " Event-driven multi-threaded programming is fast becoming a preferred style of developing efficient and responsive applications. In this concurrency model, multiple threads execute concurrently, communicating through shared objects as well as by posting asynchronous events. In this work, we consider partial order reduction (POR) for this concurrency model. Existing POR techniques treat event queues associated with threads as shared objects and reorder every pair of events handled on the same thread even if reordering them does not lead to different states. We do not treat event queues as shared objects and propose a new POR technique based on a backtracking set called the dependence-covering set. Our POR technique reorders events handled by the same thread only if necessary. We prove that exploring dependence-covering sets suffices to detect all deadlock cycles and assertion violations\u00a0\u2026", "num_citations": "21\n", "authors": ["1615"]}
{"title": "Deductive control synthesis for alternating-time logics\n", "abstract": " Algorithmic design of control laws for continuous systems for complex temporal specifications is a key step toward automatic synthesis of controllers for cyber-physical systems. Current approaches either abstract the dynamical system to a finite-state approximation or search for certificates that imply invariance or reachability properties (barriers and Lyapunov functions, respectively). The first approach is limited by an exponential blow-up in the abstraction process; the second in the properties that can be controlled for. We present a deductive proof system for the control of alternating-time temporal properties on continuous systems. We show that reasoning about temporal logic constraints in ATL*, an expressive branching-time logic that allows for quantification over control strategies, can be reduced effectively to reasoning about combinations of barrier certificates and Lyapunov functions. Our approach enables the\u00a0\u2026", "num_citations": "21\n", "authors": ["1615"]}
{"title": "Scalable testing of file system checkers\n", "abstract": " File system checkers (like e2fsck) are critical, complex, and hard to develop, and developers today rely on hand-written tests to exercise this intricate code. Test suites for file system checkers take a lot of effort to develop and require careful reasoning to cover a sufficiently comprehensive set of inputs and recovery mechanisms. We present a tool and methodology for testing file system checkers that reduces the need for a specification of the recovery process and the development of a test suite. Our methodology splits the correctness of the checker into two objectives: consistency and completeness of recovery. For each objective, we leverage either the file system checker code itself or a comparison among the outputs of multiple checkers to extract an implicit specification of correct behavior. Our methodology is embodied in a testing tool called SWIFT, which uses a mix of symbolic and concrete execution; it introduces\u00a0\u2026", "num_citations": "21\n", "authors": ["1615"]}
{"title": "A Lyapunov approach in incremental stability\n", "abstract": " The notion of incremental stability was proposed by several researchers as a strong property of dynamical and control systems. Incremental stability describes the convergence of trajectories with respect to themselves, rather than with respect to an equilibrium point or a particular trajectory. Similarly to stability, Lyapunov functions play an important role in the study of incremental stability. In this paper, we propose new notions of incremental Lyapunov functions which are coordinate independent and provide the description of incremental stability in terms of the proposed Lyapunov functions. Moreover, we develop a backstepping design approach providing a recursive way of constructing controllers, enforcing incremental stability, as well as incremental Lyapunov functions. The effectiveness of the proposed method is illustrated by synthesizing a controller rendering a single-machine infinitebus electrical power\u00a0\u2026", "num_citations": "21\n", "authors": ["1615"]}
{"title": "Randomized testing of distributed systems with probabilistic guarantees\n", "abstract": " Several recently proposed randomized testing tools for concurrent and distributed systems come with theoretical guarantees on their success. The key to these guarantees is a notion of bug depth\u2014the minimum length of a sequence of events sufficient to expose the bug\u2014and a characterization of d-hitting families of schedules\u2014a set of schedules guaranteed to cover every bug of given depth d. Previous results show that in certain cases the size of a d-hitting family can be significantly smaller than the total number of possible schedules. However, these results either assume shared-memory multithreading, or that the underlying partial ordering of events is known statically and has special structure. These assumptions are not met by distributed message-passing applications.  In this paper, we present a randomized scheduling algorithm for testing distributed systems. In contrast to previous approaches, our algorithm\u00a0\u2026", "num_citations": "20\n", "authors": ["1615"]}
{"title": "Quantifying conformance using the Skorokhod metric.\n", "abstract": " The conformance testing problem for dynamical systems asks, given two dynamical models (eg, as Simulink diagrams), whether their behaviors are \u201cclose\u201d to each other. In the semi-formal approach to conformance testing, the two systems are simulated on a large set of tests, and a metric, defined on pairs of realvalued, real-timed trajectories, is used to determine a lower bound on the distance. We show how the Skorokhod metric on continuous dynamical systems can be used as the foundation for conformance testing of complex dynamical models. The Skorokhod metric allows for both state value mismatches and timing distortions, and is thus well suited for checking conformance between idealized models of dynamical systems and their implementations. We demonstrate the robustness of the metric by proving a transference theorem: trajectories close under the Skorokhod metric satisfy \u201cclose\u201d logical properties in the timed linear time logic FLTL (Freeze LTL) containing a rich class of temporal and spatial constraint predicates involving time and value freeze variables. We provide efficient window-based streaming algorithms to compute the Skorokhod metric for both piecewise affine and piecewise constant traces, and use these as a basis for a conformance testing tool for Simulink. We experimentally demonstrate the effectiveness of our tool in finding discrepant behaviors on a set of control system benchmarks, including an industrial challenge problem.", "num_citations": "20\n", "authors": ["1615"]}
{"title": "Computing the Skorokhod distance between polygonal traces\n", "abstract": " The Skorokhod distance is a natural metric on traces of continuous and hybrid systems. It measures the best match between two traces, each mapping a time interval [0, T] to a metric space O, when continuous bijective timing distortions are allowed. Formally, it computes the infimum, over all timing distortions, of the maximum of two components: the first component quantifies the timing discrepancy of the timing distortion, and the second quantifies the mismatch (in the metric space O) of the values after the timing distortion. Skorokhod distances appear in various fundamental hybrid systems analysis concerns: from definitions of hybrid systems semantics and notions of equivalence, to practical problems such as checking the closeness of models or the quality of simulations. Despite its extensive use in semantics, the computation problem for the Skorokhod distance between two finite sampled-time hybrid traces\u00a0\u2026", "num_citations": "20\n", "authors": ["1615"]}
{"title": "A theory of partitioned global address spaces\n", "abstract": " Partitioned global address space (PGAS) is a parallel programming model for the development of applications on clusters. It provides a global address space partitioned among the cluster nodes, and is supported in programming languages like C, C++, and Fortran by means of APIs. In this paper we provide a formal model for the semantics of single instruction, multiple data programs using PGAS APIs. Our model reflects the main features of popular real-world APIs such as SHMEM, ARMCI, GASNet, GPI, and GASPI. A key feature of PGAS is the support for one-sided communication: a node may directly read and write the memory located at a remote node, without explicit synchronization with the processes running on the remote side. One-sided communication increases performance by decoupling process synchronization from data transfer, but requires the programmer to reason about appropriate synchronizations between reads and writes. As a second contribution, we propose and investigate robustness, a criterion for correct synchronization of PGAS programs. Robustness corresponds to acyclicity of a suitable happens-before relation defined on PGAS computations. The requirement is finer than the classical data race freedom and rules out most false error reports. Our main result is an algorithm for checking robustness of PGAS programs. The algorithm makes use of two insights. Using combinatorial arguments we first show that, if a PGAS program is not robust, then there are computations in a certain normal form that violate happens-before acyclicity. Intuitively, normal-form computations delay remote accesses in an ordered way. We then\u00a0\u2026", "num_citations": "20\n", "authors": ["1615"]}
{"title": "Efficient may happen in parallel analysis for async-finish parallelism\n", "abstract": " For concurrent and parallel languages, the may-happen-in-parallel (MHP) decision problem asks, given two actions in the program, if there is an execution in which they can execute in parallel. Closely related, the MHP computation problem asks, given a program, which pairs of statements may happen in parallel. MHP analysis is the basis for many program analysis problems, such as data race detection and determinism checking, and researchers have devised MHP analyses for a variety of programming models.               We present algorithms for static MHP analysis of a storeless abstraction of X10-like languages that have async-finish parallelism and procedures. For a program of size n, our first algorithm solves the MHP decision problem in O(n) time, via a reduction to constrained dynamic pushdown networks (CDPNs). Our second algorithm solves the MHP computation problem in O(n \u00b7 max (n, k)) time\u00a0\u2026", "num_citations": "20\n", "authors": ["1615"]}
{"title": "Systematic testing for control applications\n", "abstract": " Software controllers for physical processes are at the core of many safety-critical systems such as avionics, automotive engine control, and process control. Despite their importance, the design and implementation of software controllers remains an art form; dependability is generally poor, and the cost of verifying systems is prohibitive. We illustrate the potential of applying program analysis tools on problems in controller design and implementation by focusing on concolic execution, a technique for systematic testing for software. In particular, we demonstrate how a concolic execution tool can be modified to automatically analyze controller implementations and (a) produce test cases achieving a coverage goal, (b) synthesize ranges for controller variables that can be used to allocate bits in a fixed-point implementation, and (c) verify robustness of an implementation under input uncertainties. We have implemented\u00a0\u2026", "num_citations": "20\n", "authors": ["1615"]}
{"title": "Ensuring consistency in long running transactions\n", "abstract": " Flow composition languages permit the construction of long-running transactions from collections of independent atomic services. Due to environmental limitations, such transactions usually cannot be made to conform to standard ACID semantics. We propose set consistency, a powerful, yet intuitive, notion of consistency for long-running transactions. Set consistency considers the collection of permanent (non-intermittent) changes made by a process, when viewed at the end of its execution. Consistency requirements for such collections of changes are specified as predicates over the atomic actions of a process. Set consistency generalizes self-cancellation, a standard consistency requirement for long-running transactions, where failed processes are responsible for undoing any partially completed work. Set consistency can also express strictly stronger requirements, such as mutual exclusion or dependency.", "num_citations": "20\n", "authors": ["1615"]}
{"title": "Paracosm: A language and tool for testing autonomous driving systems\n", "abstract": " Systematic testing of autonomous vehicles operating in complex real-world scenarios is a difficult and expensive problem. We present Paracosm, a reactive language for writing test scenarios for autonomous driving systems. Paracosm allows users to programmatically describe complex driving situations with specific visual features, e.g., road layout in an urban environment, as well as reactive temporal behaviors of cars and pedestrians. Paracosm programs are executed on top of a game engine that provides realistic physics simulation and visual rendering. The infrastructure allows systematic exploration of the state space, both for visual features (lighting, shadows, fog) and for reactive interactions with the environment (pedestrians, other traffic). We define a notion of test coverage for Paracosm configurations based on combinatorial testing and low dispersion sequences. Paracosm comes with an automatic test case generator that uses random sampling for discrete parameters and deterministic quasi-Monte Carlo generation for continuous parameters. Through an empirical evaluation, we demonstrate the modeling and testing capabilities of Paracosm on a suite of autonomous driving systems implemented using deep neural networks developed in research and education. We show how Paracosm can expose incorrect behaviors or degraded performance.", "num_citations": "17\n", "authors": ["1615"]}
{"title": "Why is random testing effective for partition tolerance bugs?\n", "abstract": " Random testing has proven to be an effective way to catch bugs in distributed systems in the presence of network partition faults. This is surprising, as the space of potentially faulty executions is enormous, and the bugs depend on a subtle interplay between sequences of operations and faults.   We provide a theoretical justification of the effectiveness of random testing in this context. First, we show a general construction, using the probabilistic method from combinatorics, that shows that whenever a random test covers a fixed coverage goal with sufficiently high probability, a small randomly-chosen set of tests achieves full coverage with high probability. In particular, we show that our construction can give test sets exponentially smaller than systematic enumeration. Second, based on an empirical study of many bugs found by random testing in production distributed systems, we introduce notions of test coverage\u00a0\u2026", "num_citations": "17\n", "authors": ["1615"]}
{"title": "Compositional abstraction-based controller synthesis for continuous-time systems\n", "abstract": " Controller synthesis techniques for continuous systems with respect to temporal logic specifications typically use a finite-state symbolic abstraction of the system model. Constructing this abstraction for the entire system is computationally expensive, and does not exploit natural decompositions of many systems into interacting components. We describe a methodology for compositional symbolic abstraction to help scale controller synthesis for temporal logic to larger systems. We introduce a new relation, called (approximate) disturbance bisimulation, as the basis for compositional symbolic abstractions. Disturbance bisimulation strengthens the standard approximate alternating bisimulation relation used in control. It extends naturally to systems which are composed of weakly interconnected sub-components possibly connected in feedback, and models the coupling signals as disturbances. After proving this composability of disturbance bisimulation for metric systems we apply this result to the compositional abstraction of networks of input-to-state stable deterministic non-linear control systems. We give conditions that allow to construct finite-state abstractions compositionally for each component in such a network, so that the abstractions are simultaneously disturbance bisimilar to their continuous counterparts. Combining these two results, we show conditions under which one can compositionally abstract a network of non-linear control systems in a modular way while ensuring that the final composed abstraction is disturbance bisimilar to the original system. We discuss how we get a compositional abstraction-based controller synthesis methodology\u00a0\u2026", "num_citations": "17\n", "authors": ["1615"]}
{"title": "Shrinking horizon model predictive control with signal temporal logic constraints under stochastic disturbances\n", "abstract": " We present shrinking horizon model predictive control for discrete-time linear systems under stochastic disturbances with constraints encoded as signal temporal logic (STL) specification. The control objective is to satisfy a given STL specification with high probability against stochastic uncertainties while maximizing the robust satisfaction of an STL specification with minimum control effort. We formulate a general solution, which does not require precise knowledge of probability distributions of (possibly dependent) stochastic disturbances; only the bounded support of the density functions and moment intervals are used. For the specific case of disturbances that are normally distributed, we optimize the controllers by utilizing knowledge of the probability distribution of the disturbance. We show that in both cases, the control law can be obtained by solving optimization problems with linear constraints at each step. We\u00a0\u2026", "num_citations": "16\n", "authors": ["1615"]}
{"title": "RALF: Reliability analysis for logic faults\u2014An exact algorithm and its applications\n", "abstract": " Reliability analysis for a logic circuit is one of the primary tasks in fault-tolerant logic synthesis. Given a fault model, it quantifies the impact of faults on the full-chip fault rate. We present RALF, an exact algorithm for calculating the reliability of a logic circuit. RALF is based on the compilation of a circuit to deterministic decomposable negation normal form (d-DNNF), a representation for Boolean formulas that can be more succinct than BDDs. Our algorithm can solve a large set of MCNC benchmark circuits within 5 minutes, enabling an optimality study of Monte Carlo simulation, a popular estimation method for reliability analysis, on real benchmark circuits. Our study shows that Monte Carlo simulation with a small set of random vectors generally has a high fidelity for the computation of full-chip fault rates and the criticality of single gates. While we focus on reliability analysis, RALF can also be used to efficiently locate\u00a0\u2026", "num_citations": "16\n", "authors": ["1615"]}
{"title": "A theory of role composition\n", "abstract": " We study the access control integration problem for web services. Organizations frequently use many services, each with its own access control policies, which must interoperate while maintaining secure access to information. The integration problem is to take the set of such services and to find a globally consistent access control policy that ensures that the system composed from the services does not have any authorization failures or information disclosures. We give a sound and complete algorithm for access control integration by reducing the problem to Boolean constraint solving. We have implemented ROLEMATCHER, a tool to infer global role-based access control schemas for a set of services, and show on examples that it can quickly infer global roles for composed systems, or determine the absence of a globally consistent role schema.", "num_citations": "16\n", "authors": ["1615"]}
{"title": "Compositional equivalence checking for models and code of control systems\n", "abstract": " We present CSEC (Compositional Symbolic Equivalence Checker), a tool to perform automatic and compositional equivalence checking of C code against Simulink models. Such equivalence checking is important in model-based development of safety-critical control software in industrial settings, where either the Simulink models are hand-generated to correspond to existing legacy code bases, or the C code is generated from Simulink models using code generators. In the former case, manual translations may not preserve behavior; in the latter case, equivalence checking is necessary to ensure that the code generator has not introduced bugs. CSEC constructs proofs of equivalence of two call graphs compositionally, by constructing a formula that is valid iff two functions are equivalent, when all called functions are assumed equivalent. The validity of the formula is checked using an SMT solver. We have applied\u00a0\u2026", "num_citations": "14\n", "authors": ["1615"]}
{"title": "Behavior-level observability analysis for operation gating in low-power behavioral synthesis\n", "abstract": " Many techniques for power reduction in advanced RTL synthesis tools rely explicitly or implicitly on observability don\u2019t-care conditions. In this article we propose a systematic approach to maximize the effectiveness of these techniques by generating power-friendly RTL descriptions in behavioral synthesis. This is done using operation gating, that is, explicitly adding a predicate to an operation based on its observability condition, so that the operation, once identified as unobservable at runtime, can be avoided using RTL power optimization techniques such as clock gating. We first introduce the concept of behavior-level observability and its approximations in the context of behavioral synthesis. We then propose an efficient procedure to compute an approximated behavior-level observability of every operation in a dataflow graph. Unlike previous techniques which work at the bit level in Boolean networks, our method\u00a0\u2026", "num_citations": "14\n", "authors": ["1615"]}
{"title": "Exploiting symmetries to speed up SAT-based Boolean matching for logic synthesis of FPGAs\n", "abstract": " Boolean matching is one of the enabling techniques for technology mapping and logic resynthesis of field-programmable gate arrays (FPGAs). Boolean satisfiability (SAT)-based Boolean matching (SAT-BM) has been proposed, but computational complexity prohibits its practical deployment. In this paper, we leverage symmetries present in both Boolean functions and target FPGA architectures to prune the solution space, and we also propose some techniques to reduce the replication runtime for SAT instance generation using the incremental SAT reasoning engine. Experiment shows that our SAT-BM reduces runtime by 226times compared with the original SAT-BM algorithm, making SAT-BM more practical.", "num_citations": "14\n", "authors": ["1615"]}
{"title": "Asynchronous liquid separation types\n", "abstract": " We present a refinement type system for reasoning about asynchronous programs manipulating shared mutable state. Our type system guarantees the absence of races and the preservation of user-specified invariants using a combination of two ideas: refinement types and concurrent separation logic. Our type system allows precise reasoning about programs using two ingredients. First, our types are indexed by sets of resource names and the type system tracks the effect of program execution on individual heap locations and task handles. In particular, it allows making strong updates to the types of heap locations. Second, our types track ownership of shared state across concurrently posted tasks and allow reasoning about ownership transfer between tasks using permissions. We demonstrate through several examples that these two ingredients, on top of the framework of liquid types, are powerful enough to reason about correct behavior of practical, complex, asynchronous systems manipulating shared heap resources. We have implemented type inference for our type system and have used it to prove complex invariants of asynchronous OCaml programs. We also show how the type system detects subtle concurrency bugs in a file system implementation.", "num_citations": "13\n", "authors": ["1615"]}
{"title": "Using stratified attribute tracking (SAT) diagrams for learning analytics\n", "abstract": " We have created a visual representation called Stratified Attribute Tracking (SAT) Diagram to explicate trends that are otherwise implicit in learning analytics data. SAT Diagram is a unified graph that enables tracking individual attribute values in a dataset and stratifying them according to criteria set by the researcher. SAT diagram represents the transition of samples between strata across attributes. In this paper we introduce the SAT diagram and illustrate how to generate, interpret and analyze them. We believe the process of SAT diagram generation would enable exploring deeper research questions on learning data.", "num_citations": "13\n", "authors": ["1615"]}
{"title": "A theory of robust omega-regular software synthesis\n", "abstract": " A key property for systems subject to uncertainty in their operating environment is robustness: ensuring that unmodeled but bounded disturbances have only a proportionally bounded effect upon the behaviors of the system. Inspired by ideas from robust control and dissipative systems theory, we present a formal definition of robustness as well as algorithmic tools for the design of optimally robust controllers for \u03c9-regular properties on discrete transition systems. Formally, we define metric automata\u2014automata equipped with a metric on states\u2014and strategies on metric automata which guarantee robustness for \u03c9-regular properties. We present fixed-point algorithms to construct optimally robust strategies in polynomial time. In contrast to strategies computed by classical graph theoretic approaches, the strategies computed by our algorithm ensure that the behaviors of the controlled system gracefully degrade under the\u00a0\u2026", "num_citations": "13\n", "authors": ["1615"]}
{"title": "Expand, enlarge, and check for branching vector addition systems\n", "abstract": " Expand, enlarge, and check (EEC) is a successful heuristic for the coverability problem of well-structured transition systems. EEC constructs a sequence of under- and over-approximations with the property that the presence of a bug is eventually exhibited by some under-approximation and the absence of a bug is eventually exhibited by some over-approximation.               In this paper, we consider the application of EEC to the coverability problem for branching vector addition systems (BVAS), an expressive model that subsumes Petri nets. We describe an EEC algorithm for BVAS, and prove its termination and correctness. We prove an upper bound on the number of iterations for our EEC algorithm, both for BVAS and, as a special case, vector addition systems (or Petri nets). We show that in addition to practical effectiveness, the EEC heuristic is asymptotically optimal. For BVAS, it requires at most doubly\u00a0\u2026", "num_citations": "13\n", "authors": ["1615"]}
{"title": "Framework for teaching bharatanatyam through digital medium\n", "abstract": " Bharatanatyam is one of the most ancient Indian classical dance forms. There are students spread across the globe who learn this dance form at dance schools. Yet there exists no digital platform to help them systematically understand and independently practice the dance. This paper illustrates an effort to develop a digital Bharatanatyam interaction. A hierarchical architecture is extracted from the dance movements by analyzing its grammar. This is used in developing a framework to digitize the dance form. A mobile-based applet can then be implemented, as a teaching aid for this dance form, to the enthused in a game based approach. This would enhance thestudents' understanding and also assist them in a virtual guided practice.", "num_citations": "13\n", "authors": ["1615"]}
{"title": "Team incentives in bittorrent systems\n", "abstract": " Although the popular BitTorrent protocol strives to limit free-riding via its tit-for-tat incentives, recent research efforts have shown that it does not strictly enforce fairness. Free-riding opportunities indeed exist, mainly via optimistic unchokes, a BitTorrent mechanism that facilitates the continuous discovery of better peers to interact with. Our results in this work also show that increasing numbers of free-riders can considerably hurt the performance of compliant peers. In an effort to address this problem, this paper proposes a new BitTorrent-like protocol that dynamically organizes peers of similar upload bandwidth in teams-groups of peers collaborating for mutual benefit. Team members mostly satisfy their data download needs inside their team and only perform optimistic unchokes when absolutely necessary. As a result, this team-based protocol improves peer performance via explicit cooperation. At the same time, it\u00a0\u2026", "num_citations": "13\n", "authors": ["1615"]}
{"title": "FPGA area reduction by multi-output function based sequential resynthesis\n", "abstract": " We propose a new resynthesis algorithm for FPGA area reduction. In contrast to existing resynthesis techniques, which consider only single-output Boolean functions and the combinational portion of a circuit, we consider multi-output functions and retiming, and develop effective algorithms that incorporate recent improvements to SAT-based Boolean matching. Our experimental results show that with the optimal logic depth, the resynthesis considering multi-output functions reduces area by up to 0.4% compared to the one considering single-output functions, and the sequential resynthesis reduces area by up to 10% compared to combinational resynthesis when both consider multi-output functions. Furthermore, our proposed resynthesis algorithm reduces area by up to 16% compared to the best existing academic technology mapper, Berrylikei ABC.", "num_citations": "13\n", "authors": ["1615"]}
{"title": "Symbolic algorithms for verification and control\n", "abstract": " Methods for the formal specification and verification of systems are indispensible for the development of complex yet correct systems. In formal verification, the designer describes the system in a modeling language with a well-defined semantics, and this system description is analyzed against a set of correctness requirements. Model checking is an algorithmic technique to check that a system description indeed satisfies correctness requirements given as logical specifications. While successful in hardware verification, the potential for model checking for software and embedded systems has not yet been realized. This is because traditional model checking focuses on systems modeled as finite state-transition graphs. While a natural model for hardware (especially synchronous hardware), state-transition graphs often do not capture software and embedded systems at an appropriate level of granularity. This\u00a0\u2026", "num_citations": "13\n", "authors": ["1615"]}
{"title": "Lazy abstraction-based control for safety specifications\n", "abstract": " We present a lazy version of multi-layered abstraction-based controller synthesis (ABCS) for continuous-time nonlinear dynamical systems against safety specifications. State-of-the-art multi-layered ABCS uses pre-computed finite-state abstractions of different coarseness. Our new algorithm improves this technique by computing transitions on-the-fly, and only when a particular region of the state space needs to be explored by the controller synthesis algorithm for a specific coarseness. Additionally, our algorithm improves upon existing techniques by using coarser cells on a larger subset of the state space, which leads to significant computational savings.", "num_citations": "12\n", "authors": ["1615"]}
{"title": "A theory of name boundedness\n", "abstract": " We develop a theory of name-bounded \u03c0-calculus processes, which have a bound on the number of restricted names that holds for all reachable processes. Name boundedness reflects resource constraints in practical reconfigurable systems, like available communication channels in networks and address space limitations in software.               Our focus is on the algorithmic analysis of name-bounded processes. First, we provide an extension of the Karp-Miller construction that terminates and computes the coverability set for any name-bounded process. Moreover, the Karp-Miller tree shows that name-bounded processes have a pumping bound as follows. When a restricted name is distributed to a number of sequential processes that exceeds this bound, the name may be distributed arbitrarily. Second, using the bound, we construct a Petri net bisimilar to the name-bounded process. The Petri net keeps a\u00a0\u2026", "num_citations": "12\n", "authors": ["1615"]}
{"title": "Hybrid systems: computation and control\n", "abstract": " This volume contains the proceedings of the 12th International Conference on Hybrid Systems Computation and Control (HSCC 2009) held in San Francisco, California during April 13-15, 2009. The annual conference on hybrid systems focuses on research in embedded, reactive systems involving the interplay between discrete switching and continuous dynamics. HSCC is a forum for academic and industrial researchers and practitioners to exchange information on the latest advancements, both practical and theoretical, in the design, analysis, control, optimization, and implementation of hybrid systems. HSCC 2009 was the 12th in a series of successful meetings. Previous versions were held in Berkeley (1998), Nijmegen (1999), Pittsburgh (2000), Rome (2001), Palo Alto (2002), Prague (2003), Philadelphia (2004), Zurich (2005), Santa Barbara (2006), Pisa (2007), and St. Louis (2008). HSCC 2009 was part of\u00a0\u2026", "num_citations": "12\n", "authors": ["1615"]}
{"title": "On the relation between reactive synthesis and supervisory control of non-terminating processes\n", "abstract": " Reactive synthesis and supervisory control theory both provide a design methodology for the automatic and algorithmic design of digital systems from declarative specifications. The reactive synthesis approach originates in computer science, and seeks to synthesise a system that interacts with its environment over time and that, doing so, satisfies a prescribed specification. Here, the distinguishing feature when compared to other synthesis problems in computer science is that the interaction is temporal in that it explicitly refers to a sequence of computation cycles. Supervisory control originates in control theory and seeks to synthesise a controller that \u2013 in closed-loop configuration with a plant \u2013 enforces a prescribed specification over time. The distinguishing feature compared to other branches of control is that all dynamics are driven by discrete events as opposed to continuous signals. While both methods\u00a0\u2026", "num_citations": "11\n", "authors": ["1615"]}
{"title": "Debugar: Mixed dimensional displays for immersive debugging of distributed systems\n", "abstract": " Distributed systems are very complex and in case of errors hard to debug. The high number of messages with non deterministic delivery timings, as well as message losses, data corruption and node crashes cannot be efficiently analyzed with traditional GUI tools. We propose to use immersive technologies in a multi-display environment to tackle these shortcomings. Our DebugAR approach shows a representation of the current systems state, message provenance, and the lifetime of participating nodes and offers layouting techniques. By providing a screen that shows a traditional text-log, we bridge the gap to conventional tools. Additionally, we propose an interactive 3D visualization of the message flow, combining an interactive tabletop with augmented reality using a head-mounted display. We are confident that our proposed solution can not only be used to analyze distributed system, but also for other time\u00a0\u2026", "num_citations": "11\n", "authors": ["1615"]}
{"title": "The enactive equation: Exploring how multiple external representations are integrated, using a fully controllable interface and eye-tracking\n", "abstract": " Representational competence (RC), defined as \"the ability to simultaneously process and integrate multiple external representations (MERs) in a domain\", is a marker of expertise in science and engineering. However, the cognitive mechanisms underlying this ability and how this ability develops in learners, is poorly understood. In this paper, we report a fully controllable interface, designed to help school students develop RC. Further, as the design emerged from the application of distributed and embodied cognition theory to the RC problem, the design also seeks to shed light on the cognitive mechanisms underlying the integration of MERs. Here we report a preliminary eye and mouse tracking study, which sought to develop a detailed understanding of how students interacted with our interface, under self and text-guided exploration conditions. We also examined how the interaction process related to students'\u00a0\u2026", "num_citations": "11\n", "authors": ["1615"]}
{"title": "Planar wave propagation through a tapered flagellated nanoswimmer\n", "abstract": " Nanoswimmers are important because of their potential use for the purpose of drug delivery, monitoring, and diagnostics for in vivo biomedical application. They mimic microorganisms and mostly modeled as propelled by beating or rotating flagella. In the vast literature available on modeling of flagellar propulsion, the flagellum is considered constant diameter where as the actual microorganism have tapered flagella. The present study deals with the modeling and simulation of planar wave propagation through a tapered flagellum of a nanoswimmer for a given taper ratio. The performance parameters of velocity and efficiency are compared with the uniform diameter case. Taper diameter modeling of flagellum gives a superior performance by indicating higher velocity and efficiency. The parametric study with respect to the elasticity of the material of the flagellum and its beat frequency is also analyzed. The\u00a0\u2026", "num_citations": "11\n", "authors": ["1615"]}
{"title": "Compositional construction of finite state abstractions for stochastic control systems\n", "abstract": " Controller synthesis techniques for continuous systems with respect to temporal logic specifications typically use a finite-state symbolic abstraction of the system. Constructing this abstraction for the entire system is computationally expensive, and does not exploit natural decompositions of many systems into interacting components. We have recently introduced a new relation, called (approximate) disturbance bisimulation for compositional symbolic abstraction to help scale controller synthesis for temporal logic to larger systems. In this paper, we extend the results to stochastic control systems modeled by stochastic differential equations. Given any stochastic control system satisfying a stochastic version of the incremental input-to-state stability property and a positive error bound, we show how to construct a finite-state transition system (if there exists one) which is disturbance bisimilar to the given stochastic control\u00a0\u2026", "num_citations": "10\n", "authors": ["1615"]}
{"title": "iSAT: a visual learning analytics tool for instructors\n", "abstract": " Interactive Stratified Attribute Tracking (iSAT) is a visual analytics tool for cohort analysis. In this paper, we show how instructors can use iSAT to visualize transitions of groups of students during teaching-learning activities. Interactive visual analytics gives the instructor the affordance of understanding the dynamics of the class of students and their activities from the data collected in their own teaching-learning context. We take an example of a peer instruction (PI) activity and describe how iSAT can be used to analyze its clicker responses. During PI, typically instructors only use histograms to visualize the distribution of clicker responses in the pre- and post-discussion phases. We show that the use of iSAT to analyze clicker data in real time to trace transitions of participants\u2019 responses during various voting phases can support them in planning for their post-PI activities. Seven patterns of transitions that emerge are\u00a0\u2026", "num_citations": "10\n", "authors": ["1615"]}
{"title": "Computing distances between reach flowpipes\n", "abstract": " We investigate quantifying the difference between two hybrid dynamical systems under noise and initial-state uncertainty. While the set of traces for these systems is infinite, it is possible to symbolically approximate trace sets using\\emph {reachpipes} that compute upper and lower bounds on the evolution of the reachable sets with time. We estimate distances between corresponding sets of trajectories of two systems in terms of distances between the reachpipes.", "num_citations": "10\n", "authors": ["1615"]}
{"title": "Interactive Stratified Attribute Tracking diagram for learning analytics\n", "abstract": " Interactive Stratified Attribute Tracking Diagram (iSAT) is a data visualization and tool to assist interactive visual analytics of multi-attribute learning dataset. The present work reports the evolution of this diagram through a design based research methodology following its three design iterations. There are two output at the current stage i) iSAT and its Web-based interaction. ii) A Learning Analytics method suitable for both researchers and practitioners to trace student attribute value. We received satisfactory user testing score for Pre-test and post-test marks visualization through a two-phase iSAT.", "num_citations": "10\n", "authors": ["1615"]}
{"title": "Bounds on mobility\n", "abstract": " We study natural semantic fragments of the \u03c0-calculus: depth-bounded processes (there is a bound on the longest communication path), breadth-bounded processes (there is a bound on the number of parallel processes sharing a name), and name-bounded processes (there is a bound on the number of shared names). We give a complete characterization of the decidability frontier for checking if a \u03c0-calculus process in one subclass belongs to another. Our main construction is a general acceleration scheme for \u03c0-calculus processes. Based on this acceleration, we define a Karp and Miller (KM) tree construction for the depth-bounded \u03c0-calculus. The KM tree can be used to decide if a depth-bounded process is name-bounded, if a depth-bounded process is breadth-bounded by a constant k, and if a name-bounded process is additionally breadth-bounded. Moreover, we give a procedure that decides\u00a0\u2026", "num_citations": "10\n", "authors": ["1615"]}
{"title": "In search of materials for artificial flagella of nanoswimmers\n", "abstract": " Localized drug delivery and nano manipulation in fluid media like blood is an important application in biomedicine. Nanoswimmers are potential drug delivery agents for inter-vascular and intra-cellular systems. The bio-mimic modeling of flagellar propulsion mechanism of nanoswimmers has been widely attempted in literature. Mathematical models of the flagellated nanoswimmers show dependence of motion on multiple parameters like geometry and material of flagella, and viscosity of the surrounding medium. The literature also provides constraints to the material property depending on the mimicked biological system. Although modeling of shape and size of nanoswimmers is widely investigated in the literature, the material selection for the flagella needs to be assessed on the criteria like biocompatibility, physical properties, and technological feasibility. The shortlisting is quintessential for attempts to\u00a0\u2026", "num_citations": "10\n", "authors": ["1615"]}
{"title": "Minimum attention controller synthesis for omega-regular objectives\n", "abstract": " A controller for a discrete game with \u03c9-regular objectives requires attention if, intuitively, it requires measuring the state and switching from the current control action. Minimum attention controllers are preferable in modern shared implementations of cyber-physical systems because they produce the least burden on system resources such as processor time or communication bandwidth. We give algorithms to compute minimum attention controllers for \u03c9-regular objectives in imperfect information discrete two-player games. We show a polynomial-time reduction from minimum attention controller synthesis to synthesis of controllers for mean-payoff parity objectives in games of incomplete information. This gives an optimal EXPTIME-complete synthesis algorithm. We show that the minimum attention controller problem is decidable for infinite state systems with finite bisimulation quotients. In particular, the\u00a0\u2026", "num_citations": "10\n", "authors": ["1615"]}
{"title": "Multilevel monte carlo method for statistical model checking of hybrid systems\n", "abstract": " We study statistical model checking of continuous-time stochastic hybrid systems. The challenge in applying statistical model checking to these systems is that one cannot simulate such systems exactly. We employ the multilevel Monte Carlo method (MLMC) and work on a sequence of discrete-time stochastic processes whose executions approximate and converge weakly to that of the original continuous-time stochastic hybrid system with respect to satisfaction of the property of interest. With focus on bounded-horizon reachability, we recast the model checking problem as the computation of the distribution of the exit time, which is in turn formulated as the expectation of an indicator function. This latter computation involves estimating discontinuous functionals, which reduces the bound on the convergence rate of the Monte Carlo algorithm. We propose a smoothing step with tunable precision and formally\u00a0\u2026", "num_citations": "9\n", "authors": ["1615"]}
{"title": "Static provenance verification for message passing programs\n", "abstract": " Provenance information records the source and ownership history of an object. We study the problem of provenance tracking in concurrent programs, in which several principals execute concurrent processes and exchange messages over unbounded but unordered channels. The provenance of a message, roughly, is a function of the sequence of principals that have transmitted the message in the past. The provenance verification problem is to statically decide, given a message passing program and a set of allowed provenances, whether the provenance of all messages in all possible program executions, belongs to the allowed set.             We formalize the provenance verification problem abstractly in terms of well-structured provenance domains, and show a general decidability result for it. In particular, we show that if the provenance of a message is a sequence of principals who have sent the message\u00a0\u2026", "num_citations": "9\n", "authors": ["1615"]}
{"title": "Simulation of Swimming nanorobots in biological fluids\n", "abstract": " Nanotechnology is an emerging area with very useful applications in medicine. Study of flagellar propulsion in microorganisms gives us an idea of how to design swimming nanorobots. Resistive force theory gives good results for small amplitudes of bending waves. Resistive force theory based modeling of swimming nanorobots with small amplitude and an inert head is done. The nature of change of efficiency and velocity fraction with other non-dimensional parameters are simulated and analyzed. The expression for the total thrust force on the moving robot is also derived and discussed.", "num_citations": "9\n", "authors": ["1615"]}
{"title": "Probabilistic Bisimulation for Parameterized Systems\n", "abstract": " Probabilistic bisimulation is a fundamental notion of process equivalence for probabilistic systems. It has important applications, including the formalisation of the anonymity property of several communication protocols. While there is a large body of work on verifying probabilistic bisimulation for finite systems, the problem is in general undecidable for parameterized systems, i.e., for infinite families of finite systems with an arbitrary number n of processes. In this paper we provide a general framework for reasoning about probabilistic bisimulation for parameterized systems. Our approach is in the spirit of software verification, wherein we encode proof rules for probabilistic bisimulation and use a decidable first-order theory to specify systems and candidate bisimulation relations, which can then be checked automatically against the proof rules.                 We work in the framework of regular model checking, and\u00a0\u2026", "num_citations": "8\n", "authors": ["1615"]}
{"title": "PGCD: robot programming and verification with geometry, concurrency, and dynamics\n", "abstract": " Robotics applications are typically programmed in low-level imperative programming languages, leaving the programmer to deal with dynamic controllers affecting the physical state, geometric constraints on components, and concurrency and synchronization. The combination of these features-dynamics, geometry, and concurrency-makes developing robotic applications difficult. We present PGCD, a programming model for robotics applications consisting of assemblies of robotic components, together with its runtime and a verifier. PGCD combines message-passing concurrent processes with motion primitives, which represent continuous evolution of trajectories in geometric space under the action of dynamic controllers, and explicit modeling of geometric frame shifts, which allow relative coordinate transformations between components evolving in space. We describe a verification algorithm for PGCD programs\u00a0\u2026", "num_citations": "8\n", "authors": ["1615"]}
{"title": "Parameter optimization in control software using statistical fault localization techniques\n", "abstract": " Embedded controllers for cyber-physical systems are often parameterized by look-up maps representing discretizations of continuous functions on metric spaces. For example, a non-linear control action may be represented as a table of pre-computed values, and the output action of the controller for a given input computed by using interpolation. For industrial-scale control systems, several man-hours of effort are spent in tuning the values within the look-up maps. %and sub-optimal performance is often associated with %inappropriate values in look-up maps. Suppose that during testing, the controller code is found to have sub-optimal performance. The parameter fault localization problem asks which parameter values in the code are potential causes of the sub-optimal behavior. We present a statistical parameter fault localization approach based on binary similarity coefficients and set spectra methods. Our\u00a0\u2026", "num_citations": "8\n", "authors": ["1615"]}
{"title": "Hitting families of schedules for asynchronous programs\n", "abstract": " We consider the following basic task in the testing of concurrent systems. The input to the task is a partial order of events, which models actions performed on or by the system and specifies ordering constraints between them. The task is to determine if some scheduling of these events can result in a bug. The number of schedules to be explored can, in general, be exponential.                 Empirically, many bugs in concurrent programs have been observed to have small bug depth; that is, these bugs are exposed by every schedule that orders d specific events in a particular way, irrespective of how the other events are ordered, and d is small compared to the total number of events. To find all bugs of depth d, one needs to only test a d-hitting family of schedules: we call a set of schedules a d-hitting family if for each set of d events, and for each allowed ordering of these events, there is some schedule in the\u00a0\u2026", "num_citations": "8\n", "authors": ["1615"]}
{"title": "Complexity results for may-happen-in-parallel analysis\n", "abstract": " For concurrent and parallel languages, may-happen-in-parallel (MHP) analysis is useful as a basis for tools such as data race detectors. While many approximate static MHP analyses exist, researchers have published only a few papers on decidability results for MHP analysis. We study MHP analysis for a model of X10, a parallel language with async-finish parallelism. For programs with procedures, we show that the MHP decision problem is decidable in linear time, and hence the set of pairs of actions that may happen in parallel can be computed in cubic time. For programs without procedures, we present a practical recursive decision procedure that does multiple-query MHP analysis in cubic time. Our results indicate that MHP analysis is tractable for a standard storeless abstraction of X10 programs.", "num_citations": "8\n", "authors": ["1615"]}
{"title": "Analyzing real-time event-driven programs\n", "abstract": " Embedded real-time systems are typically programmed in low-level languages which provide support for event-driven task processing and real-time interrupts. We show that the model checking problem for real-time event-driven Boolean programs for safety properties is undecidable. In contrast, the model checking problem is decidable for languages such as Giotto which statically limit the creation of tasks. This gives a technical reason (static analyzability) to prefer higher-level programming models for real-time programming, in addition to the usual readability and maintainability arguments.", "num_citations": "8\n", "authors": ["1615"]}
{"title": "Fair watermarking using combinatorial isolation lemmas\n", "abstract": " Watermarking is one of the most effective mechanisms for intellectual property protection (IPP) of hardware and software artifacts. Numerous watermarking-based IPP techniques have been proposed that satisfy a spectrum of IPP desiderata, including full preservation of functionality, low timing, area and power overhead, transparency to the synthesis and compilation process, and resilience against attacks. Two objectives that are very important, but, until now have not yet been properly addressed, are credibility and fairness. We present a new watermarking technique that specifically targets credibility and fairness. Using a combinatorial result by Valiant and Vazirani, we demonstrate how these two desiderata can be achieved during the watermarking of a satisfiability (SAT) instance. The effectiveness of the technique is demonstrated on both specially created examples, where the number of solutions is known, as\u00a0\u2026", "num_citations": "8\n", "authors": ["1615"]}
{"title": "On decidability of time-bounded reachability in CTMDPs\n", "abstract": " We consider the time-bounded reachability problem for continuous-time Markov decision processes. We show that the problem is decidable subject to Schanuel's conjecture. Our decision procedure relies on the structure of optimal policies and the conditional decidability (under Schanuel's conjecture) of the theory of reals extended with exponential and trigonometric functions over bounded domains. We further show that any unconditional decidability result would imply unconditional decidability of the bounded continuous Skolem problem, or equivalently, the problem of checking if an exponential polynomial has a non-tangential zero in a bounded interval. We note that the latter problems are also decidable subject to Schanuel's conjecture but finding unconditional decision procedures remain longstanding open problems.", "num_citations": "7\n", "authors": ["1615"]}
{"title": "Environmentally-friendly GR (1) synthesis\n", "abstract": " Many problems in reactive synthesis are stated using two formulas ---an environment assumption and a system guarantee--- and ask for an implementation that satisfies the guarantee in environments that satisfy their assumption. Reactive synthesis tools often produce strategies that formally satisfy such specifications by actively preventing an environment assumption from holding. While formally correct, such strategies do not capture the intention of the designer. We introduce an additional requirement in reactive synthesis, non-conflictingness, which asks that a system strategy should always allow the environment to fulfill its liveness requirements. We give an algorithm for solving GR(1) synthesis that produces non-conflicting strategies. Our algorithm is given by a 4-nested fixed point in the -calculus, in contrast to the usual 3-nested fixed point for GR(1). Our algorithm ensures that, in every environment that satisfies its assumptions on its own, traces of the resulting implementation satisfy both the assumptions and the guarantees. In addition, the asymptotic complexity of our algorithm is the same as that of the usual GR(1) solution. We have implemented our algorithm and show how its performance compares to the usual GR(1) synthesis algorithm.", "num_citations": "7\n", "authors": ["1615"]}
{"title": "Motion session types for robotic interactions (brave new idea paper)\n", "abstract": " Robotics applications involve programming concurrent components synchronising through messages while simultaneously executing motion primitives that control the state of the physical world. Today, these applications are typically programmed in low-level imperative programming languages which provide little support for abstraction or reasoning. We present a unifying programming model for concurrent message-passing systems that additionally control the evolution of physical state variables, together with a compositional reasoning framework based on multiparty session types. Our programming model combines message-passing concurrent processes with motion primitives. Processes represent autonomous components in a robotic assembly, such as a cart or a robotic arm, and they synchronise via discrete messages as well as via motion primitives. Continuous evolution of trajectories under the action of controllers is also modelled by motion primitives, which operate in global, physical time. We use multiparty session types as specifications to orchestrate discrete message-passing concurrency and continuous flow of trajectories. A global session type specifies the communication protocol among the components with joint motion primitives. A projection from a global type ensures that jointly executed actions at end-points are communication safe and deadlock-free, ie, session-typed components do not get stuck. Together, these checks provide a compositional verification methodology for assemblies of robotic components with respect to concurrency invariants such as a progress property of communications as well as dynamic invariants\u00a0\u2026", "num_citations": "7\n", "authors": ["1615"]}
{"title": "Idea: an immersive debugger for actors\n", "abstract": " We present iDeA, an immersive user interface for debugging concurrent actor programs communicating through asynchronous message passing. iDeA is based on the hypothesis that debugging and understanding actor programs is a cognitive task which can be greatly facilitated by the visualization and interaction capabilities of modern immersive environments. The fundamental abstraction for visualization in iDeA is a concurrent trace: a partially ordered sequence of asynchronous messages exchanged in the execution. iDeA provides a 3D interface in virtual reality for users to visualize and manipulate program traces: users can set breakpoints, query actor state, step through traces forward and backward, and perform causal history of messages in a trace.", "num_citations": "7\n", "authors": ["1615"]}
{"title": "Robust model predictive control with signal temporal logic constraints for Barcelona wastewater system\n", "abstract": " We propose a traceable approach for the control of the Barcelona wastewater system that is subject to sudden weather-change events within the Mediterranean climate. Due to the unpredictable weather changes, lack of appropriate control methodologies may result in overflow in the sewage system, which causes environmental contamination (pollution). In order to improve the management of the wastewater system and to reduce the contamination, we propose robust model predictive control, which is an online control approach that designs the control actions (i.e., flows through network actuators) under the worst-case scenario while minimizing the associated operational costs. We employ signal temporal logic to specify the desired behavior of the controlled system once an overflow occurs and encode this behavior as constraints so that the synthesized controller reacts in time to decrease and eliminate the\u00a0\u2026", "num_citations": "7\n", "authors": ["1615"]}
{"title": "Unary pushdown automata and straight-line programs\n", "abstract": " We consider decision problems for deterministic pushdown automata over the unary alphabet (udpda, for short). Udpda are a simple computation model that accept exactly the unary regular languages, but can be exponentially more succinct than finite-state automata. We complete the complexity landscape for udpda by showing that emptiness (and thus universality) is P-hard, equivalence and compressed membership problems are P-complete, and inclusion is coNP-complete. Our upper bounds are based on a translation theorem between udpda and straight-line programs over the binary alphabet (SLPs). We show that the characteristic sequence of any udpda can be represented as a pair of SLPs\u2014one for the prefix, one for the lasso\u2014that have size linear in the size of the udpda and can be computed in polynomial time. Hence, decision problems on udpda are reduced to decision problems on SLPs\u00a0\u2026", "num_citations": "7\n", "authors": ["1615"]}
{"title": "The complexity of coverage\n", "abstract": " We study the problem of generating a test sequence that achieves maximal coverage for a reactive system under test. We formulate the problem as a repeated game between the tester and the system, where the system state space is partitioned according to some coverage criterion and the objective of the tester is to maximize the set of partitions (or coverage goals) visited during the game. We show the complexity of the maximal coverage problem for non-deterministic systems is PSPACE-complete, but is NP-complete for deterministic systems. For the special case of non-deterministic systems with a re-initializing \u201creset\u201d action, which represent running a new test input on a re-initialized system, we show that the complexity is coNP-complete. Our proof technique for reset games uses randomized testing strategies that circumvent the exponentially large memory requirement of deterministic testing strategies.", "num_citations": "7\n", "authors": ["1615"]}
{"title": "Watermarking of SAT using combinatorial isolation lemmas\n", "abstract": " Watermarking of hardware and software designs is an effective mechanism for intellectual property protection (IPP). Two important criteria for watermarking schemes are credibility and fairness. In this paper, we present the unique solution-based watermarking technique which provides, in a sense, the ultimate answer to both credibility and fairness requirements. Leveraging on a combinatorial theorem of Valiant and Vazirani, we demonstrate how ultimate credibility and complete fairness can almost always be achieved with high probability during the watermarking of the solution of the satisfiability (SAT) problem. The effectiveness of the technique is demonstrated on both specially created examples where the number of solutions is known, as well as on common CAD and operation research SAT instances.", "num_citations": "7\n", "authors": ["1615"]}
{"title": "Causality analysis for concurrent reactive systems\n", "abstract": " We present a comprehensive language theoretic causality analysis framework for explaining safety property violations in the setting of concurrent reactive systems. Our framework allows us to uniformly express a number of causality notions studied in the areas of artificial intelligence and formal methods, as well as define new ones that are of potential interest in these areas. Furthermore, our formalization provides means for reasoning about the relationships between individual notions which have mostly been considered independently in prior work; and allows us to judge the appropriateness of the different definitions for various applications in system design. In particular, we consider causality analysis notions for debugging, error resilience, and liability resolution in concurrent reactive systems. Finally, we present automata-based algorithms for computing various causal sets based on our language-theoretic encoding, and derive the algorithmic complexities.", "num_citations": "6\n", "authors": ["1615"]}
{"title": "On the relation between reactive synthesis and supervisory control of input/output behaviours\n", "abstract": " Reactive synthesis (RS) and supervisory control theory (SCT) both provide a design methodology for digital systems. RS takes a computer science perspective and seeks to synthesise a system that interacts with its environment in computation cycles and which, doing so, satisfies a prescribed specification. SCT takes a control theoretic perspective and seeks to synthesise a controller that - in closed-loop configuration with a plant - enforces a prescribed specification, where all dynamics are driven by discrete events. While both synthesis techniques seem superficially very similar, their technical details differ significantly. We provide a formal comparison allowing us to identify conditions under which one can solve one synthesis problem via the other one and we discuss how the resulting solutions compare. To facilitate this comparison, we give a unified introduction to RS and SCT and derive formal problem\u00a0\u2026", "num_citations": "6\n", "authors": ["1615"]}
{"title": "Controller synthesis for reward collecting Markov processes in continuous space\n", "abstract": " We propose and analyze a generic mathematical model for optimizing rewards in continuous-space, dynamic environments, called Reward Collecting Markov Processes. Our model is motivated by request-serving applications in robotics, where the objective is to control a dynamical system to respond to stochastically generated environment requests, while minimizing wait times. Our model departs from usual discounted reward Markov decision processes in that the reward function is not determined by the current state and action. Instead, a background process generates rewards whose values depend on the number of steps between generation and collection. For example, a reward is declared whenever there is a new request for a robot and the robot gets higher reward the sooner it is able to serve the request. A policy in this setting is a sequence of control actions which determines a (random) trajectory over the\u00a0\u2026", "num_citations": "6\n", "authors": ["1615"]}
{"title": "Safety verification of continuous-space pure jump Markov processes\n", "abstract": " We study the probabilistic safety verification problem for pure jump Markov processes, a class of models that generalizes continuous-time Markov chains over continuous (uncountable) state spaces. Solutions of these processes are piecewise constant, right-continuous functions from time to states. Their jump (or reset) times are realizations of a Poisson process, characterized by a jump rate function that can be both time- and state-dependent. Upon jumping in time, the new state of the solution process is specified according to a (continuous) stochastic conditional kernel. After providing a full characterization of safety properties of these processes, we describe a formal method to abstract the process as a finite-state discrete-time Markov chain; this approach is formal in that it provides a-priori error bounds on the precision of the abstraction, based on the continuity properties of the stochastic kernel of the\u00a0\u2026", "num_citations": "6\n", "authors": ["1615"]}
{"title": "Code aware resource management\n", "abstract": " Multithreaded programs coordinate their interaction through synchronization primitives like mutexes and semaphores, which are managed by an OS-provided resource manager. We propose algorithms for the automatic construction of code-aware resource managers for multithreaded embedded applications. Such managers use knowledge about the structure and resource usage (mutex and semaphore usage) of the threads to guarantee deadlock freedom and progress while managing resources in an efficient way. Our algorithms compute managers as winning strategies in certain infinite games, and produce a compact code description of these strategies. We have implemented the algorithms in the tool Cynthesis. Given a multithreaded program in C, the tool produces C\u00a0code implementing a code-aware resource manager. We show in experiments that Cynthesis produces compact resource managers\u00a0\u2026", "num_citations": "6\n", "authors": ["1615"]}
{"title": "A theory of robust software synthesis\n", "abstract": " A key property for systems subject to uncertainty in their operating environment is robustness, ensuring that unmodelled, but bounded, disturbances have only a proportionally bounded effect upon the behaviours of the system. Inspired by ideas from robust control and dissipative systems theory, we present a formal definition of robustness and algorithmic tools for the design of optimally robust controllers for omega-regular properties on discrete transition systems. Formally, we define metric automata - automata equipped with a metric on states - and strategies on metric automata which guarantee robustness for omega-regular properties. We present fixed point algorithms to construct optimally robust strategies in polynomial time. In contrast to strategies computed by classical graph theoretic approaches, the strategies computed by our algorithm ensure that the behaviours of the controlled system gracefully degrade under the action of disturbances; the degree of degradation is parameterized by the magnitude of the disturbance. We show an application of our theory to the design of controllers that tolerate infinitely many transient errors provided they occur infrequently enough.", "num_citations": "6\n", "authors": ["1615"]}
{"title": "Paracosm: A Test Framework for Autonomous Driving Simulations\n", "abstract": " Systematic testing of autonomous vehicles operating in complex real-world scenarios is a difficult and expensive problem. We present Paracosm, a framework for writing systematic test scenarios for autonomous driving simulations. Paracosm allows users to programmatically describe complex driving situations with specific features, eg, road layouts and environmental conditions, as well as reactive temporal behaviors of other cars and pedestrians. A systematic exploration of the state space, both for visual features and for reactive interactions with the environment is made possible. We define a notion of test coverage for parameter configurations based on combinatorial testing and low dispersion sequences. Using fuzzing on parameter configurations, our automatic test generator can maximize coverage of various behaviors and find problematic cases. Through empirical evaluations, we demonstrate the capabilities of Paracosm in programmatically modeling parameterized test environments, and in finding problematic scenarios.", "num_citations": "5\n", "authors": ["1615"]}
{"title": "Assume\u2013Guarantee Distributed Synthesis\n", "abstract": " Distributed reactive synthesis is the problem of algorithmically constructing controllers of distributed, communicating systems so that each closed-loop system satisfies a given temporal specification. We present an algorithm, called  negotiation , for sound (but necessarily incomplete) distributed reactive synthesis based on assume\u2013guarantee decompositions. The negotiation algorithm iteratively constructs assumptions and guarantees for each system. In each iteration, each system attempts to fulfill its specification and its guarantee (from the previous round), under the current assumption on the other systems, by solving a reactive synthesis problem. If the specification is not realizable, the algorithm computes a sufficient assumption on the other systems that ensures it can realize the specification and guarantee. This additional assumption further constrains the behavior of other systems and they might require an\u00a0\u2026", "num_citations": "5\n", "authors": ["1615"]}
{"title": "On abstraction-based controller design with output feedback\n", "abstract": " We consider abstraction-based design of output-feedback controllers for dynamical systems with a finite set of inputs and outputs against specifications in linear-time temporal logic. The usual procedure for abstraction-based controller design (ABCD) first constructs a finite-state abstraction of the underlying dynamical system, and second, uses reactive synthesis techniques to compute an abstract state-feedback controller on the abstraction. In this context, our contribution is two-fold:(I) we define a suitable relation between the original system and its abstraction which characterizes the soundness and completeness conditions for an abstract state-feedback controller to be refined to a concrete output-feedback controller for the original system, and (II) we provide an algorithm to compute a sound finite-state abstraction fulfilling this relation.", "num_citations": "5\n", "authors": ["1615"]}
{"title": "Trace aware random testing for distributed systems\n", "abstract": " Distributed and concurrent applications often have subtle bugs that only get exposed under specific schedules. While these schedules may be found by systematic model checking techniques, in practice, model checkers do not scale to large systems. On the other hand, naive random exploration techniques often require a very large number of runs to find the specific interactions needed to expose a bug. In recent years, several random testing algorithms have been proposed that, on the one hand, exploit state-space reduction strategies from model checking and, on the other, provide guarantees on the probability of hitting bugs of certain kinds.   These existing techniques exploit two orthogonal strategies to reduce the state space: partial-order reduction and bug depth. Testing algorithms based on partial order techniques, such as RAPOS or POS, ensure non-redundant exploration of independent interleavings\u00a0\u2026", "num_citations": "5\n", "authors": ["1615"]}
{"title": "Adaptive Support for Acquisition of Self-Direction Skills using Learning and Health Data\n", "abstract": " For the 21st century learner, developing self-direction skill is crucial for both academic activities and maintaining one's healthy lifestyle. While there are technology supports for specific self-regulated learning tasks and health monitoring, research is limited on how to support development of meta-skill of self-direction process itself. In our work, we focus on designing seamless technology infrastructure to foster self-directedness of learners. We consider learning and physical activities data as a context and DAPER (data collection-analyze-plan-execution monitoring-reflect), as a data-driven self-direction skill execution and acquisition model. We bridge Learning Analytics and Quantified-Self approaches to develop the GOAL (Goal Oriented Active Learner) system to support synchronize-visualize-analyze multisource data regarding learners' learning and physical activities. This paper proposes a measurement rubric as\u00a0\u2026", "num_citations": "5\n", "authors": ["1615"]}
{"title": "Checking linearizability using hitting families\n", "abstract": " Linearizability is a key correctness property for concurrent data types. Linearizability requires that the behavior of concurrently invoked operations of the data type be equivalent to the behavior in an execution where each operation takes effect at an instantaneous point of time between its invocation and return. Given an execution trace of operations, the problem of verifying its linearizability is NP-complete, and current exhaustive search tools scale poorly.", "num_citations": "5\n", "authors": ["1615"]}
{"title": "Automatic vocabulary study map generation by semantic context and learning material analysis\n", "abstract": " Learning English as a foreign language is a core part of K-12 education for many countries in which English is not the main spoken language, and especially in Asia. One of the fundamental tasks that students encounter is to learn vocabulary that is a part of the assigned curriculum. These are often sourced from reference materials or assigned vocabulary lists and may not consider the learner\u2019s current proficiency or the semantic context of words that were recently learnt. By suggesting vocabulary that have similar proficiency or semantic contexts to what a student has recently studied could improve and support vocabulary learning. In this paper, we propose a method for recommending words that have similar difficulty and semantic context with previous words learnt based on the analysis of prescribed textbooks for Japanese junior high school students. This research could be used to guide a student learning English by helping them select a sequence of vocabulary that is appropriate.", "num_citations": "5\n", "authors": ["1615"]}
{"title": "From iteration to system failure: Characterizing the fitness of periodic weakly-hard systems\n", "abstract": " Estimating metrics such as the Mean Time To Failure (MTTF) or its inverse, the Failures-In-Time (FIT), is a central problem in reliability estimation of safety-critical systems. To this end, prior work in the real-time and embedded systems community has focused on bounding the probability of failures in a single iteration of the control loop, resulting in, for example, the worst-case probability of a message transmission error due to electromagnetic interference, or an upper bound on the probability of a skipped or an incorrect actuation. However, periodic systems, which can be found at the core of most safety-critical real-time systems, are routinely designed to be robust to a single fault or to occasional failures (case in point, control applications are usually robust to a few skipped or misbehaving control loop iterations). Thus, obtaining long-run reliability metrics like MTTF and FIT from single iteration estimates by calculating the time to first fault can be quite pessimistic. Instead, overall system failures for such systems are better characterized using multi-state models such as weakly-hard constraints. In this paper, we describe and empirically evaluate three orthogonal approaches, PMC, Mart, and SAp, for the sound estimation of system's MTTF, starting from a periodic stochastic model characterizing the failure in a single iteration of a periodic system, and using weakly-hard constraints as a measure of system robustness. PMC and Mart are exact analyses based on Markov chain analysis and martingale theory, respectively, whereas SAp is a sound approximation based on numerical analysis. We evaluate these techniques empirically in terms of their\u00a0\u2026", "num_citations": "5\n", "authors": ["1615"]}
{"title": "Approximate time bounded reachability for ctmcs and ctmdps: A lyapunov approach\n", "abstract": " Time bounded reachability is a fundamental problem in model checking continuous-time Markov chains (CTMCs) and Markov decision processes (CTMDPs) for specifications in continuous stochastic logics. It can be computed by numerically solving a characteristic linear dynamical system, which is computationally expensive. We take a control-theoretic approach and propose a reduction technique that finds another dynamical system of lower dimension (number of variables), such that numerically solving the reduced dynamical system provides an approximation to the solution of the original system with guaranteed error bounds. Our technique generalises lumpability (or probabilistic bisimulation) to a quantitative setting. Our main result is a Lyapunov function characterisation of the difference in the trajectories of the two dynamics that depends on the initial mismatch and exponentially decreases over time\u00a0\u2026", "num_citations": "5\n", "authors": ["1615"]}
{"title": "Formal controller synthesis for wastewater systems with signal temporal logic constraints: The Barcelona case study\n", "abstract": " We present an approach for formal controller synthesis of the Barcelona wastewater system. The goal of the controller is to minimize overflow in the system and to reduce environmental contamination (pollution). Due to the influence of sudden and unpredictable weather changes within the Mediterranean climate, we propose robust model predictive control strategy. This approach synthesizes control inputs (i.e., flows through network actuators) that make the system robust to uncertainties in the weather forecast; control inputs are updated in an online fashion to incorporate the newly available measurements from the system and the disturbances. We employ signal temporal logic as a formal mechanism to express the desired behavior of the system. The quantitative semantics of the logic is then used to encode the desired behavior in both the set of constraints and the objective function of the optimization problem. We\u00a0\u2026", "num_citations": "5\n", "authors": ["1615"]}
{"title": "Lazy abstraction-based control for reachability\n", "abstract": " We present lazy abstraction-based controller synthesis (ABCS) for continuous-time nonlinear dynamical systems against reach-avoid specifications. State-of-the-art multi-layered ABCS pre-computes multiple finite-state abstractions of different coarseness and applies reactive synthesis to the coarsest abstraction whenever feasible, but adaptively considers finer abstractions when necessary. Our new algorithm improves this technique by constructing abstractions lazily on demand. Our insight is that the abstract transition relation only needs to be locally computed for a small set of frontier states of the courseness currently required by the synthesis algorithm. We show that lazy ABCS can significantly outperform previous multi-layered ABCS algorithms: on a standard benchmark, lazy ABCS was more than 4 times faster.", "num_citations": "5\n", "authors": ["1615"]}
{"title": "Llsplat: Improving concolic testing by bounded model checking\n", "abstract": " For software testing, concolic testing reasons about data symbolically but enumerates program paths. The existing concolic technique enumerates paths sequentially, leading to poor branch coverage in limited time. In this paper, we improve concolic testing by bounded model checking (BMC). During concolic testing, we identify program regions that can be encoded by BMC on the fly so that program paths within these regions are checked simultaneously. We have implemented the new algorithm on top of KLEE and called the new tool LLSPLAT. We have compared LLSPLAT with KLEE using 10 programs from the Windows NT Drivers Simplified and 88 programs from the GNU Coreutils benchmark sets. With 3600 second testing time for each program, LLSPLAT provides on average 13% relative branch coverage improvement on all 10 programs in the Windows drivers set, and on average 16% relative branch\u00a0\u2026", "num_citations": "5\n", "authors": ["1615"]}
{"title": "Bbs: A Phase-Bounded Model Checker for Asynchronous Programs\n", "abstract": " A popular model of asynchronous programming consists of a single-threaded worker process interacting with a task queue. In each step of such a program, the worker takes a task from the queue and executes its code atomically to completion. Executing a task can call \u201cnormal\u201d functions as well as post additional asynchronous tasks to the queue. Additionally, tasks can be posted to the queue by the environment.                 Bouajjani and Emmi introduced phase-bounding analysis on asynchronous programs with unbounded FIFO task queues, which is a systematic exploration of all program behaviors up\u00a0to a fixed task phase. They showed that phase-bounded exploration can be sequentialized: given a set of recursive tasks, a task queue, and a phase bound , one can construct a sequential recursive program whose behaviors capture all states of the original asynchronous program reachable by an\u00a0\u2026", "num_citations": "5\n", "authors": ["1615"]}
{"title": "How does representational competence develop? Explorations using a fully controllable interface and eye-tracking\n", "abstract": " Representational competence (RC), defined as \u201cthe ability to simultaneously process and integrate multiple external representations (MERs) in a domain\u201d, is a marker of expertise in science and engineering. However, the cognitive mechanisms underlying this ability, and how this ability develops in learners, are poorly understood. In this paper, we present a fully manipulable interface, designed to help school students develop RC, and a pilot eye and mouse tracking study, which sought to develop a detailed understanding of how students interacted with our interface. We developed an analysis methodology for eye and mouse tracking data that characterizes the interaction process in analytical terms, and operationalizes the process of MER integration. We present preliminary results of applying our analysis methodology to student data obtained in our pilot study.", "num_citations": "5\n", "authors": ["1615"]}
{"title": "Bisimilar finite abstractions of stochastic control systems\n", "abstract": " Abstraction-based approaches to the design of complex control systems construct finite-state models that are formally related to the original control systems, then leverage symbolic techniques from finite-state synthesis to compute controllers satisfying specifications given in a temporal logic, and finally refine the obtained control schemes back to the given concrete complex models. While such approaches have been successfully used to perform synthesis over non-probabilistic control systems, there are only few results available for probabilistic models: hence the goal of this paper, which considers continuous-time controlled stochastic differential equations. We show that for every stochastic control system satisfying a stochastic version of incremental input-to-state stability, and for every \u03b5 > 0, there exists a finite-state abstraction that is \u03b5-approximate bisimilar to the stochastic control system (in the sense of moments\u00a0\u2026", "num_citations": "5\n", "authors": ["1615"]}
{"title": "A uniformization theorem for nested word to word transductions\n", "abstract": " We study the class of relations implemented by nested word to word transducers (also known as visibly pushdown transducers). We show that any such relation can be uniformized by a functional relation from the same class, implemented by an unambiguous transducer. We give an exponential upper bound on the state complexity of the uniformization, improving a previous doubly exponential upper bound. Our construction generalizes a classical construction by Sch\u00fctzenberger for the disambiguation of nondeterministic finite-state automata, using determinization and summarization constructions on nested word automata. Besides theoretical interest, our procedure can be the basis for synthesis procedures for nested word to word transductions.", "num_citations": "5\n", "authors": ["1615"]}
{"title": "Trigger memoization in self-triggered control\n", "abstract": " Self-triggered implementations of controllers have been proposed as an alternative to traditional time-triggered implementations. In a self-triggered implementation, the control task computes the actuator signal as well as a triggering time that specifies the next time instant at which the control task should be run. Self-triggered implementations have the potential to decrease communication costs and CPU requirements over time-triggered ones, eg, by running the steady-state plant in open loop for long intervals if there is no disturbance. We show that commonly claimed gains for self-triggered implementations are too optimistic. The analysis of most self-triggering algorithms ignore the execution times for computing the trigger times. We show, using implementations of several self-triggering algorithms proposed in the literature on common embedded platforms, that the execution time to compute the trigger time can be\u00a0\u2026", "num_citations": "5\n", "authors": ["1615"]}
{"title": "Simultaneous test pattern compaction, ordering and X-filling for testing power reduction\n", "abstract": " Minimizing the power dissipation in scan-based testing is an important problem. We provide for the first time an optimal formulation for the problem of simultaneously compacting, ordering, and X-filling a set of test patterns such that the fault coverage is maintained but the (overall or peak) power dissipation is minimized. We model the problem as a sequence of Pseudo-Boolean optimization problems. We give a scalable implementation of the optimization problem based on window-based local search. In contrast to the traditional technique of sequentially optimizing for compaction, ordering, and X-filling, we experimentally demonstrate that our simultaneous optimization can reduce power dissipation by 47% on ISCAS'89 benchmark circuits.", "num_citations": "5\n", "authors": ["1615"]}
{"title": "The consistency of web conversations\n", "abstract": " We describe BPELCheck, a tool for statically analyzing interactions of composite Web services implemented in BPEL. Our algorithm is compositional, and checks each process interacting with an abstraction of its peers, without constructing the product state space. Interactions between pairs of peer processes are modeled using conversation automata which encode the set of valid message exchange sequences between the two processes. A process is consistent if each possible conversation leaves its peer automata in a state labeled as consistent and the overall execution satisfies a user-specified predicate on the automata states. We have implemented BPELCheck in the Enterprise Service Pack of the NetBeans development environment. Our tool handles the major syntactic constructs of BPEL, including sequential and parallel composition, exception handling, flows, and Boolean state variables. We have used\u00a0\u2026", "num_citations": "5\n", "authors": ["1615"]}
{"title": "Static checking for dynamic resource management in sensor network systems\n", "abstract": " Many sensor network systems expose general interfaces to system developers for dynamically creating and/or manipulating resources of various kinds. While these interfaces allow programmers to accomplish common system tasks simply and efficiently, they also admit the potential for programmers to mismanage resources, for example through leaked resources or improper resource sharing. These kinds of errors are particularly problematic for sensor networks, given the resource constraints and lack of memory protection on current sensor platforms.We describe a static analysis technique that brings the safety of static resource management to systems that dynamically manage resources. Our analysis is based on the observation that sensor network applications often manipulate resources in a producerconsumer pattern. In this style, each resource has a unique owner component at any given point in time, who has both the sole capability to manipulate the resource and the responsibility to properly dispose of the resource or transfer ownership to another component. Our analysis enforces this ownership discipline on components at compile time.", "num_citations": "5\n", "authors": ["1615"]}
{"title": "Context-bounded verification of liveness properties for multithreaded shared-memory programs\n", "abstract": " We study context-bounded verification of liveness properties of multi-threaded, shared-memory programs, where each thread can spawn additional threads. Our main result shows that context-bounded fair termination is decidable for the model; context-bounded implies that each spawned thread can be context switched a fixed constant number of times. Our proof is technical, since fair termination requires reasoning about the composition of unboundedly many threads each with unboundedly large stacks. In fact, techniques for related problems, which depend crucially on replacing the pushdown threads with finite-state threads, are not applicable. Instead, we introduce an extension of vector addition systems with states (VASS), called VASS with balloons (VASSB), as an intermediate model; it is an infinite-state model of independent interest. A VASSB allows tokens that are themselves markings (balloons). We show\u00a0\u2026", "num_citations": "4\n", "authors": ["1615"]}
{"title": "FAR-Cubicle\u2014A new reachability algorithm for Cubicle\n", "abstract": " We present a fully automatic algorithm for verifying safety properties of parameterized software systems. This algorithm is based on both IC3 and Lazy Annotation. We implemented it in Cubicle, a model checker for verifying safety properties of array-based systems. Cache-coherence protocols and mutual exclusion algorithms are known examples of such systems. Our algorithm iteratively builds an abstract reachability graph refining the set of reachable states from counter-examples. Refining is made through counter-example approximation. We show the effectiveness and limitations of this algorithm and tradeoffs that results from it.", "num_citations": "4\n", "authors": ["1615"]}
{"title": "Robots at the edge of the cloud\n", "abstract": " Computers have come a long way from their roots as fast calculating devices. We live in a world in which computers collect, store, and analyze huge volumes of data. We are seeing the beginnings of a new revolution in the use of computers. In addition to collecting and analyzing data, computers are influencing the physical world and interacting autonomously, and in complex ways, with large groups of humans. These cyber-physical-social systems have the potential to dramatically alter the way we lead our lives. However, designing these systems in a reliable way is a difficult problem. In this paper, we enumerate a set of research challenges that have to be overcome in order to realize the potential of cyber-physical-social systems.", "num_citations": "4\n", "authors": ["1615"]}
{"title": "Verification of cyber-physical systems (dagstuhl seminar 14122)\n", "abstract": " Cyber-physical systems refer to a new genre of engineered systems consisting of a tight coupling between computation, communication and physical entities. The main focus of the seminar was to discuss issues related to the reliable development of cyber-physical systems by using formal verification. This is a multi-disciplinary area requiring collaboration between areas focusing discrete systems analysis and continuous systems analysis. To this end, the seminar brought together researchers working in the fields of formal methods, control theory and hybrid systems to identify and discuss potential issues and research questions which require collaboration between the communities. This report documents the program and the outcomes of Dagstuhl Seminar 14122\" Verification of Cyber-Physical Systems\".", "num_citations": "4\n", "authors": ["1615"]}
{"title": "LAMP: A framework for large-scale addressing of muddy points\n", "abstract": " Muddy Points (MP) is a strategy to elicit and address individual students' doubts. While this can be effectively implemented in small classes, it is a challenge to do so in a large class. In this paper we propose LAMP, a framework for Large-scale Addressing of Muddy Points, as a mechanism for instructors to ensure that every individual student's doubts are addressed even in large classes. LAMP has three phases: Collection, Addressal, and Closure. In the collection phase, MPs are systematically collected through four different modes. In the addressal phase, MPs are categorized into six categories and addressed accordingly. In the closure phase, the discussions on MPs are summarized. We investigated the effectiveness of LAMP in an introductory computer science course having 450 students. We found that 68% of students confirmed they were able to pose their questions and 57% of students confirmed that there\u00a0\u2026", "num_citations": "4\n", "authors": ["1615"]}
{"title": "On power and fault-tolerance optimization in FPGA physical synthesis\n", "abstract": " Power and fault tolerance are deemed to be two orthogonal optimization objectives in FPGA synthesis, with independent attempts to develop algorithms and CAD tools to optimize each objective. In this paper, we study the relationship between these two optimizations and show empirically that there are strong ties between them. Specifically, we analyze the power and reliability optimization problems in FPGA physical synthesis (i.e., packing, placement, and routing), and show that the intrinsic structures of these two problems are very similar. Supported by the post routing results with detailed power and reliability analysis for a wide selection of benchmark circuits, we show that with minimal changes - fewer than one hundred lines of C code - an existing power-aware physical synthesis tool can be used to minimize the fault rate of a circuit under SEU faults. As a by-product of this study, we also show that one can\u00a0\u2026", "num_citations": "4\n", "authors": ["1615"]}
{"title": "Frugal routing on wireless ad-hoc networks\n", "abstract": " We study game-theoretic mechanisms for routing in ad-hoc networks. Game-theoretic mechanisms capture the non-cooperative and selfish behavior of nodes in a resource-constrained environment. There have been some recent proposals to use incentive-based mechanisms (in particular, VCG) for routing in wireless ad-hoc networks, and some frugality bounds are known when the connectivity graph is essentially complete. We show frugality bounds for random geometric graphs, a well-known model for ad-hoc wireless connectivity. Our main result demonstrates that VCG-based routing in ad-hoc networks exhibits small frugality ratio (i.e., overpayment) with high probability. In addition, we study a more realistic generalization where sets of agents can form communities to maximize total profit. We also analyze the performance of VCG under such a community model and show similar bounds. While some\u00a0\u2026", "num_citations": "4\n", "authors": ["1615"]}
{"title": "Efficient SAT-based Boolean matching for heterogeneous FPGA technology mapping\n", "abstract": " The Boolean matching problem is the key procedure in Fieldprogrammable gate array (FPGA) technology mapping. SAT-based Boolean matching provides a flexible solution for exploring various FPGA architectures. However, the computational complexity of state-of-the-art SAT-based Boolean matching prohibits its integration into real technology mapping applications. In this project we present a thorough study of the SAT-based Boolean matching problem for heterogeneous FPGAs, conducting numerous comparisons among different approaches and heuristics. We propose several novel ideas to improve the efficiency of SAT-based Boolean matching, such as an implicant table-based representation and symmetries exploration. Overall, the experimental results show that our speedup techniques reduce runtime by approximately two orders of magnitude compared to the original SAT-based formulation.", "num_citations": "4\n", "authors": ["1615"]}
{"title": "Symbolic Control for Stochastic Systems via Parity Games\n", "abstract": " We consider the problem of computing the maximal probability of satisfying an -regular specification for stochastic, continuous-state, nonlinear systems evolving in discrete time. The problem reduces, after automata-theoretic constructions, to finding the maximal probability of satisfying a parity condition on a (possibly hybrid) state space. While characterizing the exact satisfaction probability is open, we show that a lower bound on this probability can be obtained by (I) computing an under-approximation of the qualitative winning region, i.e., states from which the parity condition can be enforced almost surely, and (II) computing the maximal probability of reaching this qualitative winning region. The heart of our approach is a technique to symbolically compute the under-approximation of the qualitative winning region in step (I) via a finite-state abstraction of the original system as a -player parity game. Our abstraction procedure uses only the support of the probabilistic evolution; it does not use precise numerical transition probabilities. We prove that the winning set in the abstract -player game induces an under-approximation of the qualitative winning region in the original synthesis problem, along with a policy to solve it. By combining these contributions with (a) existing symbolic fixpoint algorithms to solve -player games and (b) existing techniques for reachability policy synthesis in stochastic nonlinear systems, we get an abstraction-based symbolic algorithm for finding a lower bound on the maximal satisfaction probability. We have implemented our approach and evaluated it on the nonlinear model of the perturbed Dubins vehicle.", "num_citations": "3\n", "authors": ["1615"]}
{"title": "Symbolic qualitative control for stochastic systems via finite parity games\n", "abstract": " We consider the controller synthesis problem for stochastic, continuous-state, nonlinear systems against \u03c9-regular specifications. We synthesize a symbolic controller that ensures almost sure (qualitative) satisfaction of the specification. The problem reduces, after some automata-theoretic constructions, to computing the almost sure winning region\u2014the largest set of states from which a parity condition can be satisfied with probability 1 (on a possibly hybrid state space). While characterizing the exact almost sure winning region is still open for the considered system class, we propose an algorithm for obtaining a tight under-approximation of this set. The heart of our approach is a technique to symbolically compute this under-approximation via a finite-state abstraction as a 21/2-player parity game. Our abstraction procedure uses only the support of the probabilistic evolution; it does not use precise numerical transition\u00a0\u2026", "num_citations": "3\n", "authors": ["1615"]}
{"title": "Incremental abstraction computation for symbolic controller synthesis in a changing environment\n", "abstract": " Abstraction-Based Controller Synthesis (ABCS) is an emerging field for automatic synthesis of correct-by-design controllers for non-linear dynamical systems in the presence of bounded disturbances. A major drawback of existing ABCS techniques is the lack of flexibility against changes in the disturbance model; any change in the model results in a complete re-computation of the abstraction and the controller. This flexibility is relevant to situations when disturbances are learned or estimated during operation in an environment which is previously not known precisely. As time passes, the disturbance model is progressively refined. The monolithic nature and high computational cost of existing algorithms make ABCS unsuited for such scenarios.In this paper, we present an incremental algorithm to locally adapt abstractions to changes in the disturbance model. Only the parts of the space which are affected by the\u00a0\u2026", "num_citations": "3\n", "authors": ["1615"]}
{"title": "Perception-in-the-loop adversarial examples\n", "abstract": " We present a scalable, black box, perception-in-the-loop technique to find adversarial examples for deep neural network classifiers. Black box means that our procedure only has input-output access to the classifier, and not to the internal structure, parameters, or intermediate confidence values. Perception-in-the-loop means that the notion of proximity between inputs can be directly queried from human participants rather than an arbitrarily chosen metric. Our technique is based on covariance matrix adaptation evolution strategy (CMA-ES), a black box optimization approach. CMA-ES explores the search space iteratively in a black box manner, by generating populations of candidates according to a distribution, choosing the best candidates according to a cost function, and updating the posterior distribution to favor the best candidates. We run CMA-ES using human participants to provide the fitness function, using the insight that the choice of best candidates in CMA-ES can be naturally modeled as a perception task: pick the top  inputs perceptually closest to a fixed input. We empirically demonstrate that finding adversarial examples is feasible using small populations and few iterations. We compare the performance of CMA-ES on the MNIST benchmark with other black-box approaches using  norms as a cost function, and show that it performs favorably both in terms of success in finding adversarial examples and in minimizing the distance between the original and the adversarial input. In experiments on the MNIST, CIFAR10, and GTSRB benchmarks, we demonstrate that CMA-ES can find perceptually similar adversarial inputs with a small\u00a0\u2026", "num_citations": "3\n", "authors": ["1615"]}
{"title": "Concentration of Measure for Chance-Constrained Optimization\n", "abstract": " Chance-constrained optimization problems optimize a cost function in the presence of probabilistic constraints. They are convex in very special cases and, in practice, they are solved using approximation techniques. In this paper, we study approximation of chance constraints for the class of probability distributions that satisfy a concentration of measure property. We show that using concentration of measure, we can transform chance constraints to constraints on expectations, which can then be solved based on scenario optimization. Our approach depends solely on the concentration of measure property of the uncertainty and does not require the objective or constraint functions to be convex. We also give bounds on the required number of scenarios for achieving a certain confidence. We demonstrate our approach on a non-convex chanced-constrained optimization, and benchmark our technique against\u00a0\u2026", "num_citations": "3\n", "authors": ["1615"]}
{"title": "Symbolic model checking for factored probabilistic models\n", "abstract": " The long line of research in probabilistic model checking has resulted in efficient symbolic verification engines. Nevertheless, scalability is still a key concern. In this paper we ask two questions. First, can we lift, to the probabilistic world, successful hardware verification techniques that exploit local variable dependencies in the analyzed model? And second, will those techniques lead to significant performance improvement on models with such structure, such as dynamic Bayesian networks?                 To the first question we give a positive answer by proposing a probabilistic model checking approach based on factored symbolic representation of the transition probability matrix of the analyzed model. Our experimental evaluation on several benchmarks designed to favour this approach answers the second question negatively. Intuitively, the reason is that the effect of techniques for reducing the size of BDD\u00a0\u2026", "num_citations": "3\n", "authors": ["1615"]}
{"title": "A notion of dynamic interface for depth-bounded object-oriented packages\n", "abstract": " Programmers using software components have to follow protocols that specify when it is legal to call particular methods with particular arguments. For example, one cannot use an iterator over a set once the set has been changed directly or through another iterator. We formalize the notion of dynamic package interfaces (DPI), which generalize state-machine interfaces for single objects, and give an algorithm to statically compute a sound abstraction of a DPI. States of a DPI represent (unbounded) sets of heap configurations and edges represent the effects of method calls on the heap. We introduce a novel heap abstract domain based on depth-bounded systems to deal with potentially unboundedly many objects and the references among them. We have implemented our algorithm and show that it is effective in computing representations of common patterns of package usage, such as relationships between viewer and label, container and iterator, and JDBC statements and cursors.", "num_citations": "3\n", "authors": ["1615"]}
{"title": "Safety-guarantee controller synthesis for cyber-physical systems\n", "abstract": " The verification and validation of cyber-physical systems is known to be a difficult problem due to the different modeling abstractions used for control components and for software components. A recent trend to address this difficulty is to reduce the need for verification by adopting correct-by-design methodologies. According to the correct-by-design paradigm, one seeks to automatically synthesize a controller that can be refined into code and that enforces temporal specifications on the cyber-physical system. In this paper we consider an instance of this problem where the specifications are given by a fragment of Linear Temporal Logic (LTL) and the physical environment is described by a smooth differential equation. The contribution of this paper is to show that synthesis for cyber-physical systems is viable by considering a fragment of LTL that is expressive enough to describe interesting properties but simple enough to avoid Safra's construction. We report on two examples illustrating a preliminary implementation of these techniques on the tool PESSOALTL.", "num_citations": "3\n", "authors": ["1615"]}
{"title": "Preventing lost messages in event-driven programming\n", "abstract": " The event-driven programming style is pervasive as an efficient method for interacting with the environment. Unfortunately, the event-driven style severely complicates program maintenance and understanding, as it requires each logical flow of control to be fragmented across multiple independent callbacks. We propose a backward-compatible extension to Java, called TaskJava, which supports lightweight, interleaved computations without foregoing standard control mechanisms like procedures and exceptions. At the same time, TaskJava programs can be automatically translated into efficient event-based code. This technical report presents, in detail, a formalization of TaskJava. We formalize the operational semantics, typing rules, and modular compilation strategy for a core sublanguage. We then prove a number of properties of this core language, including type soundness, observational equivalence of translated programs, and freedom from certain classes of bugs. 1", "num_citations": "3\n", "authors": ["1615"]}
{"title": "Beyond hytech: Hybrid systems analysis using interval numerical methods\n", "abstract": " Though the hybrid system model checker HyTech has successfully verified some systems, it restricts the dynamics to linear hybrid automata. We have designed an algorithm capable of verifying systems with more general dynamics. This algorithm uses interval numerical methods to conservatively overapproximate the reachable states of a hybrid automaton. We have implemented our new algorithm in HyTech+. Using three examples, we demonstrate that this algorithm enables both a more accurate and a more direct analysis of hybrid systems. Introduction In a hybrid system, digital controllers interact with a continuous environment. Because of the increasing ubiquity of embedded real-time systems, hybrid systems directly control many of the devices in our daily lives. Moreover, hybrid systems are often components of safety-or mission-critical systems. For these reasons, it is necessary to have rigorous guarantees about the correct performance of hybrid systems. Hybrid automata (Alur et...", "num_citations": "3\n", "authors": ["1615"]}
{"title": "Interactive synthesis of temporal specifications from examples and natural language\n", "abstract": " Motivated by applications in robotics, we consider the task of synthesizing linear temporal logic (LTL) specifications based on examples and natural language descriptions. While LTL is a flexible, expressive, and unambiguous language to describe robotic tasks, it is often challenging for non-expert users. In this paper, we present an interactive method for synthesizing LTL specifications from a single example trace and a natural language description. The interaction is limited to showing a small number of behavioral examples to the user who decides whether or not they exhibit the original intent. Our approach generates candidate LTL specifications and distinguishing examples using an encoding into optimization modulo theories problems. Additionally, we use a grammar extension mechanism and a semantic parser to generalize synthesized specifications to parametric task descriptions for subsequent use. Our\u00a0\u2026", "num_citations": "2\n", "authors": ["1615"]}
{"title": "The complexity of bounded context switching with dynamic thread creation\n", "abstract": " Dynamic networks of concurrent pushdown systems (DCPS) are a theoretical model for multi-threaded recursive programs with shared global state and dynamical creation of threads. The (global) state reachability problem for DCPS is undecidable in general, but Atig et al. (2009) showed that it becomes decidable, and is in 2EXPSPACE, when each thread is restricted to a fixed number of context switches. The best known lower bound for the problem is EXPSPACE-hard and this lower bound follows already when each thread is a finite-state machine and runs atomically to completion (i.e., does not switch contexts). In this paper, we close the gap by showing that state reachability is 2EXPSPACE-hard already with only one context switch. Interestingly, state reachability analysis is in EXPSPACE both for pushdown threads without context switches as well as for finite-state threads with arbitrary context switches. Thus, recursive threads together with a single context switch provide an exponential advantage. Our proof techniques are of independent interest for 2EXPSPACE-hardness results. We introduce transducer-defined Petri nets, a succinct representation for Petri nets, and show coverability is 2EXPSPACE-hard for this model. To show 2EXPSPACE-hardness, we present a modified version of Lipton's simulation of counter machines by Petri nets, where the net programs can make explicit recursive procedure calls up to a bounded depth.", "num_citations": "2\n", "authors": ["1615"]}
{"title": "Multiparty motion coordination: from choreographies to robotics programs\n", "abstract": " We present a programming model and typing discipline for complex multi-robot coordination programming. Our model encompasses both synchronisation through message passing and continuous-time dynamic motion primitives in physical space. We specify \\emph{continuous-time motion primitives} in an assume-guarantee logic that ensures compatibility of motion primitives as well as collision freedom. We specify global behaviour of programs in a \\emph{choreographic} type system that extends multiparty session types with jointly executed motion primitives, predicated refinements, as well as a \\emph{separating conjunction} that allows reasoning about subsets of interacting robots. We describe a notion of \\emph{well-formedness} for global types that ensures motion and communication can be correctly synchronised and provide algorithms for checking well-formedness, projecting a type, and local type checking. A well-typed program is \\emph{communication safe}, \\emph{motion compatible}, and \\emph{collision free}. Our type system provides a compositional approach to ensuring these properties. We have implemented our model on top of the ROS framework. This allows us to program multi-robot coordination scenarios on top of commercial and custom robotics hardware platforms. We show through case studies that we can model and statically verify quite complex manoeuvres involving multiple manipulators and mobile robots---such examples are beyond the scope of previous approaches.", "num_citations": "2\n", "authors": ["1615"]}
{"title": "A Lyapunov approach for time-bounded reachability of CTMCs and CTMDPs\n", "abstract": " Time-bounded reachability is a fundamental problem in model checking continuous-time Markov chains (CTMCs) and Markov decision processes (CTMDPs) for specifications in continuous stochastic logics. It can be computed by numerically solving a characteristic linear dynamical system, but the procedure is computationally expensive. We take a control-theoretic approach and propose a reduction technique that finds another dynamical system of lower dimension (number of variables), such that numerically solving the reduced dynamical system provides an approximation to the solution of the original system with guaranteed error bounds. Our technique generalizes lumpability (or probabilistic bisimulation) to a quantitative setting. Our main result is a Lyapunov function characterization of the difference in the trajectories of the two dynamics that depends on the initial mismatch and exponentially decreases over\u00a0\u2026", "num_citations": "2\n", "authors": ["1615"]}
{"title": "Modeling Self-Planning and Promoting Planning Skills in a Data-Rich Context\n", "abstract": " Students' learning behaviors in an online learning environment can be automatically recorded by learning systems. Such learning records provide new opportunities to model students' learning process. On the other hand, it has become more common to see students having wearable devices that assist in tracking their personal physical activities. These activity tracking can be integrated into a data-rich context for training students for developing their data-informed self-direction skills. We are building the GOAL (Goal Oriented Active Learner) system to support the development of self-direction skills using learning and health activity data. A key phase in any self-directed activity is goal setting and planning. This paper will introduce how to build a new model for self-planning and support the acquisition of planning skills in the GOAL system. We combine learners\u2019 data from the self-directed activity and their interaction trace to build the model in the GOAL system. The modeling involves computing of trend value and degree of plan difficulty, then diagnosis of planning skills using a 5-point scoring criteria. An adaptive support is selected based on the computed score. The contribution of this work is modeling planning and promoting planning skills in a data-driven manner. Our approach grounds the theory of self-direction skills and enables learners to develop the skills in everyday life.", "num_citations": "2\n", "authors": ["1615"]}
{"title": "Lazy abstraction-based controller synthesis\n", "abstract": " Abstraction-based controller synthesis (ABCS) is a general procedure for automatic synthesis of controllers for continuous-time nonlinear dynamical systems against temporal specifications. ABCS works by first abstracting a time-sampled version of the continuous dynamics of the open-loop system by a symbolic finite state model.", "num_citations": "2\n", "authors": ["1615"]}
{"title": "Supporting Data-Driven Decision Making by Learners and Teachers\n", "abstract": " My research focuses on interdisciplinary data driven approach to support students and teachers. For students, I aim to design technology interventions to develop their self-directedness skill (SDS). For teachers, I investigate how learning dashboards can facilitate adopting actionable learning analytics in teaching practices. This two-pronged research agenda uses a proposed core process model, we call DAPER model. In DAPER model, users utilize data to plan, monitor and reflect on one\u2019s practices. We are developing LET\u2019s GOAL system based on the DAPER model to support the students. The model also fits in Learning Evidence Analytics Framework (LEAF), our proposed technology framework for evidence-based education system.", "num_citations": "2\n", "authors": ["1615"]}
{"title": "Deferrability analysis for JavaScript\n", "abstract": " Modern web browsers allow asynchronous loading of JavaScript scripts in order to speed up parsing a web page. Instead of blocking until a script has been downloaded and evaluated, the async and defer tags in a script allow the browser to download the script in a background task, and either evaluate it as soon as it is available (for async) or evaluate it in load-order at the end of parsing (for defer). While asynchronous loading can significantly speed up the time-to-render, i.e., the time that passes until the first page elements are displayed on-screen, the specification for correct loading is complex and the programmer is responsible for understanding the circumstances under which a script can be loaded asynchronously in either mode without breaking page functionality. As a result, many complex web applications do not take full advantage of asynchronous loading. We present an automatic analysis of\u00a0\u2026", "num_citations": "2\n", "authors": ["1615"]}
{"title": "Dynamic hierarchical reactive controller synthesis\n", "abstract": " In the formal approach to reactive controller synthesis, a symbolic controller for a possibly hybrid system is obtained by algorithmically computing a winning strategy in a two-player game. Such game-solving algorithms scale poorly as the size of the game graph increases. However, in many applications, the game graph has a natural hierarchical structure. In this paper, we propose a modeling formalism and a synthesis algorithm that exploits this hierarchical structure for more scalable synthesis. We define local games on hierarchical graphs as a modeling formalism that decomposes a large-scale reactive synthesis problem in two dimensions. First, the construction of a hierarchical game graph introduces abstraction layers, where each layer is again a two-player game graph. Second, every such layer is decomposed into multiple local game graphs, each corresponding to a node in the higher level game\u00a0\u2026", "num_citations": "2\n", "authors": ["1615"]}
{"title": "The robot routing problem for collecting aggregate stochastic rewards\n", "abstract": " We propose a new model for formalizing reward collection problems on graphs with dynamically generated rewards which may appear and disappear based on a stochastic model. The *robot routing problem* is modeled as a graph whose nodes are stochastic processes generating potential rewards over discrete time. The rewards are generated according to the stochastic process, but at each step, an existing reward disappears with a given probability. The edges in the graph encode the (unit-distance) paths between the rewards' locations. On visiting a node, the robot collects the accumulated reward at the node at that time, but traveling between the nodes takes time. The optimization question asks to compute an optimal (or epsilon-optimal) path that maximizes the expected collected rewards. We consider the finite and infinite-horizon robot routing problems. For finite-horizon, the goal is to maximize the total expected reward, while for infinite horizon we consider limit-average objectives. We study the computational and strategy complexity of these problems, establish NP-lower bounds and show that optimal strategies require memory in general. We also provide an algorithm for computing epsilon-optimal infinite paths for arbitrary epsilon > 0.", "num_citations": "2\n", "authors": ["1615"]}
{"title": "Dynamic package interfaces\n", "abstract": " A hallmark of object-oriented programming is the ability to perform computation through a set of interacting objects. A common manifestation of this style is the notion of a package, which groups a set of commonly used classes together. A challenge in using a package is to ensure that a client follows the implicit protocol of the package when calling its methods. Violations of the protocol can cause a runtime error or latent invariant violations. These protocols can extend across different, potentially unboundedly many, objects, and are specified informally in the documentation. As a result, ensuring that a client does not violate the protocol is hard.               We introduce dynamic package interfaces (DPI), a formalism to explicitly capture the protocol of a package. The DPI of a package is a finite set of rules that together specify how any set of interacting objects of the package can evolve through method calls and\u00a0\u2026", "num_citations": "2\n", "authors": ["1615"]}
{"title": "Dynamic package interfaces-extended version\n", "abstract": " A hallmark of object-oriented programming is the ability to perform computation through a set of interacting objects. A common manifestation of this style is the notion of a package, which groups a set of commonly used classes together. A challenge in using a package is to ensure that a client follows the implicit protocol of the package when calling its methods. Violations of the protocol can cause a runtime error or latent invariant violations. These protocols can extend across different, potentially unboundedly many, objects, and are specified informally in the documentation. As a result, ensuring that a client does not violate the protocol is hard. We introduce dynamic package interfaces (DPI), a formalism to explicitly capture the protocol of a package. The DPI of a package is a finite set of rules that together specify how any set of interacting objects of the package can evolve through method calls and under what conditions an error can happen. We have developed a dynamic tool that automatically computes an approximation of the DPI of a package, given a set of abstraction predicates. A key property of DPI is that the unbounded number of configurations of objects of a package are summarized finitely in an abstract domain. This uses the observation that many packages behave monotonically: the semantics of a method call over a configuration does not essentially change if more objects are added to the configuration. We have exploited monotonicity and have devised heuristics to obtain succinct yet general DPIs. We have used our tool to compute DPIs for several commonly used Java packages with complex protocols, such as JDBC, HashSet, and\u00a0\u2026", "num_citations": "2\n", "authors": ["1615"]}
{"title": "Provenance verification\n", "abstract": " The provenance of an object is the history of its origin and derivation. Provenance tracking records the provenance of an object as it evolves. In computer science, provenance tracking has been studied in many different settings, such as databases [7,3,2], scientific workflows [13,5], and programanalysis [4,12,9], often under different names (lineage, dependence analysis, taint analysis) and with varying degrees of (in)formality. Provenance information can be used inmanyways, for example, to identify which sources of data led to a result, to ensure reproducibility of a scientific workflow, or to check security properties such as information flow.", "num_citations": "2\n", "authors": ["1615"]}
{"title": "The complexity of coverage\n", "abstract": " We study the problem of generating a test sequence that achieves maximal coverage for a reactive system under test. We formulate the problem as a repeated game between the tester and the system, where the system state space is partitioned according to some coverage criterion and the objective of the tester is to maximize the set of partitions (or coverage goals) visited during the game. We show the complexity of the maximal coverage problem for non-deterministic systems is PSPACE-complete, but is NP-complete for deterministic systems. For the special case of non-deterministic systems with a re-initializing \u201creset\u201d action, which represent running a new test input on a re-initialized system, we show that the complexity is coNP-complete. Our proof technique for reset games uses randomized testing strategies that circumvent the exponentially large memory requirement of deterministic testing strategies. We also\u00a0\u2026", "num_citations": "2\n", "authors": ["1615"]}
{"title": "Discounting and averaging in games across time scales\n", "abstract": " We introduce two-level discounted and mean-payoff games played by two players on a perfect-information stochastic game graph. The upper level game is a discounted or mean-payoff game and the lower level game is a (undiscounted) reachability game. Two-level games model hierarchical and sequential decision making under uncertainty across different time scales.         For both discounted and mean-payoff two-level games, we show the existence of pure memoryless optimal strategies for both players and an ordered field property. We show that if there is only one player (Markov decision processes), then the values can be computed in polynomial time. It follows that whether the value of a player is equal to a given rational constant in two-level discounted or mean-payoff games can be decided in NP \u2229 coNP. We also give an alternate strategy improvement algorithm to compute the value.", "num_citations": "2\n", "authors": ["1615"]}
{"title": "Input-Output stability for discrete systems\n", "abstract": " Input-Output stability for discrete systems - CISPA CISPA Home About Browse Data Privacy Policy Impressum Login Input-Output stability for discrete systems Tabuada, Paulo and Balkan, Ayca and Caliskan, Sina Yamac and Shoukry, Yasser and Majumdar, Rupak (2012) Input-Output stability for discrete systems. In: Proc. of the International Conference on Embedded Software (EMSOFT 2012). Conference: EMSOFT ACM Conference on Embedded Software Full text not available from this repository. Item Type: Conference or Workshop Item (A Paper) (Paper) Additional Information: pub_id: 619 Bibtex: TaBaCaShMa_12:Input URL date: None Uncontrolled Keywords: security,TODO Divisions: Unspecified Conference: EMSOFT ACM Conference on Embedded Software Depositing User: Sebastian Weisgerber Date Deposited: 26 Jul 2017 10:30 Last Modified: 18 Jul 2019 12:09 Primary Research Area: NRA2: Reliable \u2026", "num_citations": "2\n", "authors": ["1615"]}
{"title": "Branch prediction using neural nets\n", "abstract": " Introduction Modern high-performance architectures require extremely accurate branch prediction to overcome the performance limitations of conditional branches. Most current solutions employ a two-level adaptive scheme [8], such as gshare [5] and bimode [4]. The prediction mechanism uses a table of simple two-bit counters chosen according to some history information and the branch address. In this project we explore predictors with more sophisticated prediction mechanisms based on articial intelligence methods. The problem of branch prediction is an instance of the well-studied problem of predicting the value of data in a time series: given a sequence of values in a time series, the problem asks to predict the value of the series at the next time step. In this paper we consider the application of articial intelligence learning methods, particularly the use of neural networks to the branch prediction problem. Neural networks have been successfully applied to prediction and c", "num_citations": "2\n", "authors": ["1615"]}
{"title": "The computability of LQR and LQG control\n", "abstract": " We consider decision problems associated with the linear quadratic regulator (LQR) and linear quadratic Gaussian (LQG) control problems in continuous time. The decision problems ask, given the parameters of a problem and a threshold rational number r, is the optimal cost less than or equal to the threshold r? LQR and LQG are fundamental problems in the theory of linear systems and it is well known that optimal controllers for these problems have a closed-form solution. However, since the closed-form solutions involve transcendental functions, they can only be evaluated numerically. Thus, it is possible that numerical imprecisions prevent answering the decision problem no matter what precision is used for the computations. Indeed, the computability of these natural decision problems has remained open.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Subcubic Certificates for CFL Reachability\n", "abstract": " Many problems in interprocedural program analysis can be modeled as the context-free language (CFL) reachability problem on graphs and can be solved in cubic time. Despite years of efforts, there are no known truly sub-cubic algorithms for this problem. We study the related certification task: given an instance of CFL reachability, are there small and efficiently checkable certificates for the existence and for the non-existence of a path? We show that, in both scenarios, there exist succinct certificates ( in the size of the problem) and these certificates can be checked in subcubic (matrix multiplication) time. The certificates are based on grammar-based compression of paths (for positive instances) and on invariants represented as matrix constraints (for negative instances). Thus, CFL reachability lies in nondeterministic and co-nondeterministic subcubic time. A natural question is whether faster algorithms for CFL reachability will lead to faster algorithms for combinatorial problems such as Boolean satisfiability (SAT). As a consequence of our certification results, we show that there cannot be a fine-grained reduction from SAT to CFL reachability for a conditional lower bound stronger than , unless the nondeterministic strong exponential time hypothesis (NSETH) fails. Our results extend to related subcubic equivalent problems: pushdown reachability and two-way nondeterministic pushdown automata (2NPDA) language recognition. For example, we describe succinct certificates for pushdown non-reachability (inductive invariants) and observe that they can be checked in matrix multiplication time. We also extract a new hardest 2NPDA\u00a0\u2026", "num_citations": "1\n", "authors": ["1615"]}
{"title": "General Decidability Results for Asynchronous Shared-Memory Programs: Higher-Order and Beyond\n", "abstract": " The model of asynchronous programming arises in many contexts, from low-level systems software to high-level web programming. We take a language-theoretic perspective and show general decidability and undecidability results for asynchronous programs that capture all known results as well as show decidability of new and important classes. As a main consequence, we show decidability of safety, termination and boundedness verification for higher-order asynchronous programs -- such as OCaml programs using Lwt -- and undecidability of liveness verification already for order-2 asynchronous programs. We show that under mild assumptions, surprisingly, safety and termination verification of asynchronous programs with handlers from a language class are decidable iff emptiness is decidable for the underlying language class. Moreover, we show that configuration reachability and liveness (fair termination) verification are equivalent, and decidability of these problems implies decidability of the well-known \"equal-letters\" problem on languages. Our results close the decidability frontier for asynchronous programs.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Supervisory Controller Synthesis for Non-terminating Processes is an Obliging Game\n", "abstract": " We present a new algorithm to solve the supervisory control problem over non-terminating processes modeled as -regular automata. A solution to this problem was obtained by Thistle in 1995 which uses complex manipulations of automata. We show a new solution to the problem through a reduction to obliging games, which, in turn, can be reduced to -regular reactive synthesis. Therefore, our reduction results in a symbolic algorithm based on manipulating sets of states using tools from reactive synthesis. This establishes a new connection between the research areas of (I) supervisory control theory in the field of control engineering and (II) reactive synthesis in the field of computer science.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Accurate abstractions for controller synthesis with non-uniform disturbances\n", "abstract": " Abstraction-Based Controller Synthesis (ABCS) is an emerging field for automatic synthesis of correct-by-design controllers for non-linear dynamical systems in the presence of bounded disturbances. Existing ABCS techniques assume a global (state-independent) and uniform upper bound on disturbances. This can be overly pessimistic, resulting in a failure to find a controller. In this paper, we extend ABCS to accurately compute abstractions for system models with state and input-dependent non-uniform disturbances. This requires a subtle assume-guarantee style computation of the state evolution and the estimation of the error. We empirically show the benefit of our approach with significantly smaller amount of non-determinism in the abstract transitions.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Measuring Analysis Skill in Data-informed Self-directed Activities\n", "abstract": " Current technology enables tracking of various learning and physical activities. User can use the data to analyze issues in the execution of those activities. Current work focuses on this analysis phase of data-informed self-directed activity cycle and proposes a measurement framework of the skill while learners work in a data-rich context. It is a paradigm shift to support and measure analysis skill from previous approaches which mostly rely on questionnaire-based measurements. In our approach, we emphasize the monitoring of learner\u2019s analytical process and the automatic evaluation of the analysis results through system. Based on that, an automated measurement is carried out in the system to depict learner\u2019s analysis skill and changes of skill. Additionally, we elaborate the framework in the context of the GOAL system which provides affordances of analysis based on physical and reading activity data.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Memory-Efficient Mixed-Precision Implementations for Robust Explicit Model Predictive Control\n", "abstract": " We propose an optimization for space-efficient implementations of explicit model-predictive controllers (MPC) for robust control of linear time-invariant (LTI) systems on embedded platforms. We obtain an explicit-form robust model-predictive controller as a solution to a multi-parametric linear programming problem. The structure of the controller is a polyhedral decomposition of the control domain, with an affine map for each domain. While explicit MPC is suited for embedded devices with low computational power, the memory requirements for such controllers can be high. We provide an optimization algorithm for a mixed-precision implementation of the controller, where the deviation of the implemented controller from the original one is within the robustness margin of the robust control problem. The core of the mixed-precision optimization is an iterative static analysis that co-designs a robust controller and a low\u00a0\u2026", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Simultaneous Re-Planning and Plan Execution for Online Job Arrival\n", "abstract": " In many AI planning applications, an agent receives new jobs (additional non-conflicting goals) while plan execution is still ongoing. Vanilla solutions are to (a) finish execution before tackling the new job, or to (b) interrupt execution and re-plan immediately. Option (a) misses opportunities to smoothly integrate the new job into the plan, while (b) leaves the agent idle during re-planning. We introduce simultaneous re-planning and execution (SRE), a planning algorithm that avoids both disadvantages. SRE re-plans for both the old and new jobs while the current plan is still being executed. The key difficulty is that, then, the initial state for the revised plan\u2013the state in which plan execution is at the end of re-planning\u2013depends on the time taken for re-planning. We address this through a variant of A* that starts with several speculative initial states, and incorporates time-aware search information to differentiate between these. On a collection of extended planning competition benchmarks, our algorithm consistently outperforms both (a) and (b).", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Programming event processors with thingflow\n", "abstract": " We present ThingFlow, a software architecture to write event-processing pipelines for Internet-of-things (IoT) applications. Such applications typically involve sensing, stateful transformations of event streams, state estimation, and control/actuation, learning, and data analytics. They are currently programmed using a zoo of languages, systems, and APIs with ad hoc data passing protocols.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Precise but Natural Specification for Robot Tasks\n", "abstract": " We present Flipper, a natural language interface for describing high-level task specifications for robots that are compiled into robot actions. Flipper starts with a formal core language for task planning that allows expressing rich temporal specifications and uses a semantic parser to provide a natural language interface. Flipper provides immediate visual feedback by executing an automatically constructed plan of the task in a graphical user interface. This allows the user to resolve potentially ambiguous interpretations. Flipper extends itself via naturalization: its users can add definitions for utterances, from which Flipper induces new rules and adds them to the core language, gradually growing a more and more natural task specification language. Flipper improves the naturalization by generalizing the definition provided by users. Unlike other task-specification systems, Flipper enables natural language interactions while maintaining the expressive power and formal precision of a programming language. We show through an initial user study that natural language interactions and generalization can considerably ease the description of tasks. Moreover, over time, users employ more and more concepts outside of the initial core language. Such extensions are available to the Flipper community, and users can use concepts that others have defined.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Symbolic model checking in non-Boolean domains\n", "abstract": " We consider symbolic model checking as a general procedure to compute fixed points on general lattices. We show that this view provides a unified approach for formal reasoning about systems that is applicable to many different classes of systems and properties. Our unified view is based on the notion of region algebras together with appropriate generalizations of the modal -calculus. We show applications of our general approach to problems in infinite-state verification, reactive synthesis, and the analysis of probabilistic systems.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Computer Aided Verification: 29th International Conference, CAV 2017, Heidelberg, Germany, July 24-28, 2017, Proceedings, Part II\n", "abstract": " The two-volume set LNCS 10426 and LNCS 10427 constitutes the refereed proceedings of the 29th International Conference on Computer Aided Verification, CAV 2017, held in Heidelberg, Germany, in July 2017. The total of 50 full and 7 short papers presented together with 5 keynotes and tutorials in the proceedings was carefully reviewed and selected from 191 submissions. The CAV conference series is dedicated to the advancement of the theory and practice of computer-aided formal analysis of hardware and software systems. The conference covers the spectrum from theoretical results to concrete applications, with an emphasis on practical verification tools and the algorithms and techniques that are needed for their implementation.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Game theory in AI, logic, and algorithms (dagstuhl seminar 17111)\n", "abstract": " This report documents the program and the outcomes of Dagstuhl Seminar 17111\" Game Theory in AI, Logic, and Algorithms\".", "num_citations": "1\n", "authors": ["1615"]}
{"title": "A partial order reduction technique for event-driven multi-threaded programs\n", "abstract": " Event-driven multi-threaded programming is fast becoming a preferred style of developing efficient and responsive applications. In this concurrency model, multiple threads execute concurrently, communicating through shared objects as well as by posting asynchronous events that are executed in their order of arrival. In this work, we consider partial order reduction (POR) for event-driven multi-threaded programs. The existing POR techniques treat event queues associated with threads as shared objects and thereby, reorder every pair of events handled on the same thread even if reordering them does not lead to different states. We do not treat event queues as shared objects and propose a new POR technique based on a novel backtracking set called the dependence-covering set. Events handled by the same thread are reordered by our POR technique only if necessary. We prove that exploring dependence-covering sets suffices to detect all deadlock cycles and assertion violations defined over local variables. To evaluate effectiveness of our POR scheme, we have implemented a dynamic algorithm to compute dependence-covering sets. On execution traces obtained from a few Android applications, we demonstrate that our technique explores many fewer transitions ---often orders of magnitude fewer--- compared to exploration based on persistent sets, wherein, event queues are considered as shared objects.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Reachability analysis of reversal-bounded automata on series-parallel graphs\n", "abstract": " Extensions to finite-state automata on strings, such as multi-head automata or multi-counter automata, have been successfully used to encode many infinite-state non-regular verification problems. In this paper, we consider a generalization of automata-theoretic infinite-state verification from strings to labeled series-parallel graphs. We define a model of non-deterministic, 2-way, concurrent automata working on series-parallel graphs and communicating through shared registers on the nodes of the graph. We consider the following verification problem: given a family of series-parallel graphs described by a context-free graph transformation system (GTS), and a concurrent automaton over series-parallel graphs, is some graph generated by the GTS accepted by the automaton? The general problem is undecidable already for (one-way) multi-head automata over strings. We show that a bounded version, where the automata make a fixed number of reversals along the graph and use a fixed number of shared registers is decidable, even though there is no bound on the sizes of series-parallel graphs generated by the GTS. Our decidability result is based on establishing that the number of context switches is bounded and on an encoding of the computation of bounded concurrent automata to reduce the emptiness problem to the emptiness problem for pushdown automata.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Edit distance for timed automata\n", "abstract": " The edit distance between two (untimed) traces is the minimum cost of a sequence of edit operations (insertion, deletion, or substitution) needed to transform one trace to the other. Edit distances have been extensively studied in the untimed setting, and form the basis for approximate matching of sequences in different domains such as coding theory, parsing, and speech recognition.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "PULSE: A Framework for Protocol Based Utility to Log Student Engagement\n", "abstract": " Educational researchers use observations to collect information about classroom activities as they occur. Currently the most prevalent methods of logging classroom observations are pen-and-paper or video recording. The former is inefficient, especially in large classes while the latter requires expensive infrastructure. In this paper we propose the design framework for the development of a software application for protocol-based multi-observer data logging and analysis called PULSE. Following design-based research we developed the four aspects of this framework. They were iteratively improved over the research cycles based on the feedback of the previous cycles. In this work-in progress paper, we present an ongoing design prototype of the application.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Supervisor synthesis for controller upgrades\n", "abstract": " During the life cycle of a cyber-physical system, it is sometimes necessary to upgrade a working controller with a new, but unverified, one which provides better performance or additional functionality. To make sure that system invariants are not broken because of bugs in the new controller, an architecture is used in which both controllers are implemented on the platform, and a supervisor process checks that the actions of the new controller keep the system within its safe states. If an invariant may be violated, the supervisor switches over to the old controller that ensures correct behavior, but possibly degraded performance. A key question in the design of such supervisors is the switching strategy: when should the supervisor reinstate the new controller after it has switched to the old one? In general, one would prefer to use the new controller as much as possible, provided it does not violate safety. However, arbitrarily\u00a0\u2026", "num_citations": "1\n", "authors": ["1615"]}
{"title": "On the Generation of Precise Fixed-Point Expressions\n", "abstract": " Several problems in the implementations of control systems, signal-processing systems, and scientific computing systems reduce to compiling a polynomial expression over the reals into an imperative program using fixed-point arithmetic. Fixed-point arithmetic only approximates real values, and its operators do not have the fundamental properties of real arithmetic, such as associativity. Consequently, a naive compilation process can yield a program that significantly deviates from the real polynomial, whereas a different order of evaluation can result in a program that is close to the real value on all inputs in its domain. We present a compilation scheme for real-valued arithmetic expressions to fixed-point arithmetic programs. Given a real-valued polynomial expression t, we find an expression t that is equivalent to t over the reals, but whose implementation as a series of fixed-point operations minimizes the error between the fixed-point value and the value of t over the space of all inputs. We show that the corresponding decision problem, checking whether there is an implementation t of t whose error is less than a given constant, is NP-hard. We then propose a solution technique based on genetic programming. Our technique evaluates the fitness of each candidate program using a static analysis based on affine arithmetic. We show that our tool can significantly reduce the error in the fixed-point implementation on a set of linear control system benchmarks. For example, our tool found implementations whose errors are only one half of the errors in the original fixed-point expressions.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Equivalence of games with probabilistic uncertainty and partial-observation games\n", "abstract": " We introduce games with probabilistic uncertainty, a model for controller synthesis in which the controller observes the state through imprecise sensors that provide correct information about the current state with a fixed probability. That is, in each step, the sensors return an observed state, and given the observed state, there is a probability distribution (due to the estimation error) over the actual current state. The controller must base its decision on the observed state (rather than the actual current state, which it does not know). On the other hand, we assume that the environment can perfectly observe the current state. We show that controller synthesis for qualitative \u03c9-regular objectives in our model can be reduced in polynomial time to standard partial-observation stochastic games, and vice-versa. As a consequence we establish the precise decidability frontier for the new class of games, and establish\u00a0\u2026", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Coordinate-invariant incremental lyapunov functions\n", "abstract": " In this note, we propose coordinate-invariant notions of incremental Lyapunov function and provide characterizations of incremental stability in terms of existence of the proposed Lyapunov functions.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Simulation of planar wave flagellar propulsion of nanorobots using comsol\n", "abstract": " Advancement in the field of Nanorobotics has been facilitated by the current advances in Nano-bio-technology and nanofabrication techniques. Nanorobots can be used in the advancement of medical technology, healthcare and environment monitoring and swim in biological fluids flowing in narrow channels of a few hundred nanometers in the area of bio-medical engineering. The pronounced effects in nanometer scale such as increased apparent viscosity and low Reynolds number make the designing of propulsion mechanism a challenging task. Prominent modes of flagellar locomotion in micro-sized biological organisms are by generating planar waves or through helical rotation. The present work attempts to numerically simulate the shape form of the tail of a swimming nanorobot by solving the governing equation of its flagellar hydro-dynamics. It corroborates with the analytical studies aimed at the modeling of Nanorobot dynamics thorough planar wave propagation.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Paul Ammann and Jeff Offutt Introduction to Software Testing. Cambridge University Press (2008). ISBN: 978-0-521-88038-1.\u00a3 32.99. 322 pp. Hardcover\n", "abstract": " The author of a text book on testing faces a quandary. The book can be written purely for the practitioner, offering a sequence of specific tips, perhaps tied to a testing tool or process. Alternately, the book can cover more technical aspects, including recent research that is not yet mainstream. The first style provides the impression that testing is somehow non-technical and lacking in fundamental principles. The second style can cause the book to be discounted as impractical by testers in the field.Ammann and Offutt\u2019s text is a timely and good effort in trying to walk a middle ground. The book targets undergraduates or beginning graduates, ideally with some exposure to software engineering, but also professional testers and developers. The book has two main parts: the first part describes and classifies coverage criteria, and the second part goes into the testing process and specific applications. The first part, the meat\u00a0\u2026", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Model Checking Software: 15th International SPIN Workshop, Los Angeles, CA, USA, August 10-12, 2008, Proceedings\n", "abstract": " This book constitutes the refereed proceedings of the 15th International SPIN workshop on Model Checking Software, SPIN 2008, held in Los Angeles, CA, USA, in August 2008. The 17 revised full papers presented together with 1 tool paper and 4 invited talks were carefully reviewed and selected from 41 submissions. The main focus of the workshop series is software systems, including models and programs. The papers cover theoretical and algorithmic foundations as well as tools for software model checking and foster interactions and exchanges of ideas with related areas in software engineering, such as static analysis, dynamic analysis, and testing.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Dominance: Modeling heap structures with sharing\n", "abstract": " A number of papers have used predicate languages over sets of abstract locations to model the heap (decorating a heap graph with the predicates, or in conjunction with an access path abstraction). In this work we introduce a new predicate, dominance, which is a generalization of aliasing and is used to model how objects are shared in the heap (eg do two lists contain the same set of objects?) and how sharing influences the results of destructive updates (eg if all the objects in one list are modified does that imply that all the objects in another list are modified?). The dominance relation is introduced in the context of a graph-based heap model but the concept is general and can be incorporated in other frameworks as a high-level primitive.The motivation for introducing a higher-order predicate to model sharing is based on the success of existing approaches which use connectivity, reachability, and sharing predicates to perform shape analysis using high-level graph-based models. Our approach provides an analysis technique that is efficient and scalable while retaining a high level of accuracy. This is in contrast to proposals in the literature based on using logical languages (usually built on top of first-order predicate logic) which either are highly expressive and very general (resulting in a computationally expensive analysis) or utilize only fragments of the full logic (which reduces the computational cost but results in a much less powerful analysis).", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Quantitative compositional reasoning\n", "abstract": " We present a compositional theory of system verifica tion, where specifications assign real-numbered costs to systems. These costs can express a wide variety of quantitative system properties, such as resource consumption, price or a measure of how well a system satisfies its specification. The theory supports the composition of systems and specifications, and the hiding of variables. Boolean refinement relations are replaced by real-numbered distances between descriptions of a system at different levels of detail. We show that classical boolean rules for compositional reseaning have their quantitive counterparts in our setting. While our theory allows costs to be specified by arbitrary cost functions, we also consider a class of linear cost functions, which give rise to an instance of our framework wher all operations are computable in polynomial time.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Design of controllers for linear hybrid systems\n", "abstract": " In this paper, we describe an approach for deriving control laws for linear hybrid systems given the phase transition system and the global invariance. After illustrating the method, we show that the approach can be applied for purposes of verification, viability and discuss extensions to nonlinear hybrid systems.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Identifying Reading Styles from E-book Log Data\n", "abstract": " In this paper, a model for identifying e-book reading style is proposed and applied onto a learning log dataset. Learning log data available as non-structured data source is processed to identify patterns of reading exhibited by users using three main structures: reading sessions, reads and passages. These structures are used to extract information on users\u2019 reading style to be used as part of user modeling process. The proposed model is applied on a set of log data generated by university students during one semester of digital resource use. The findings show students adopt predominantly receptive reading style, while responsive style occurs rarely. Further analysis revealed no significant relationships between reading style variables and student academic success for the Architecture course indicating the variables of responsive and receptive reading bring new information as part of user modeling.", "num_citations": "1\n", "authors": ["1615"]}
{"title": "Beyond HyTech: Hybrid Systems Analysis Using Interval Numerical Methods???\n", "abstract": " Since hybrid embedded systems are pervasive and often safetycritical, guarantees about their correct performance are desirable. The hybrid systems model checker HyTech provides such guarantees and has successfully veri ed some systems. However, HyTech severely restricts the continuous dynamics of the system being analyzed and, therefore, often forces the use of prohibitively expensive discrete and polyhedral abstractions. We have designed a new algorithm, which is capable of directly verifying hybrid systems with general continuous dynamics, such as linear and nonlinear di erential equations. The new algorithm conservatively overapproximates the reachable states of a hybrid automaton by using interval numerical methods. Interval numerical methods return sets of points that enclose the true result of numerical computation and, thus, avoid distortions due to the accumulation of round-o errors. We have implemented the new algorithm in a successor tool to HyTech called HyperTech. We consider three examples: a thermostat with delay, a two-tank water system, and an air-tra c collision avoidance protocol. HyperTech enables the direct, fully automatic analysis of these systems, which is also more accurate than the use of polyhedral abstractions.", "num_citations": "1\n", "authors": ["1615"]}