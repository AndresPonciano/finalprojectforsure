{"title": "A state-based approach to integration testing based on UML models\n", "abstract": " Correct functioning of object-oriented software depends upon the successful integration of classes. While individual classes may function correctly, several new faults can arise when these classes are integrated together. In this paper, we present a technique to enhance testing of interactions among modal classes. The technique combines UML collaboration diagrams and statecharts to automatically generate an intermediate test model, called SCOTEM (State COllaboration TEst Model). The SCOTEM is then used to generate valid test paths. We also define various coverage criteria to generate test paths from the SCOTEM model. In order to assess our technique, we have developed a tool and applied it to a case study to investigate its fault detection capability. The results show that the proposed technique effectively detects all the seeded integration faults when complying with the most demanding adequacy\u00a0\u2026", "num_citations": "151\n", "authors": ["558"]}
{"title": "Understanding Uncertainty in Cyber-Physical Systems: A Conceptual Model\n", "abstract": " Uncertainty is intrinsic in most technical systems, including Cyber-Physical Systems (CPS). Therefore, handling uncertainty in a graceful manner during the real operation of CPS is critical. Since designing, developing, and testing modern and highly sophisticated CPS is an expanding field, a step towards dealing with uncertainty is to identify, define, and classify uncertainties at various levels of CPS. This will help develop a systematic and comprehensive understanding of uncertainty. To that end, we propose a conceptual model for uncertainty specifically designed for CPS. Since the study of uncertainty in CPS development and testing is still irrelatively unexplored, this conceptual model was derived in a large part by reviewing existing work on uncertainty in other fields, including philosophy, physics, statistics, and healthcare. The conceptual model is mapped to the three logical levels of CPS: Application\u00a0\u2026", "num_citations": "117\n", "authors": ["558"]}
{"title": "Minimizing test suites in software product lines using weight-based genetic algorithms\n", "abstract": " Test minimization techniques aim at identifying and eliminating redundant test cases from test suites in order to reduce the total number of test cases to execute, thereby improving the efficiency of testing. In the context of software product line, we can save effort and cost in the selection and minimization of test cases for testing a specific product by modeling the product line. However, minimizing the test suite for a product requires addressing two potential issues: 1) the minimized test suite may not cover all test requirements compared with the original suite; 2) the minimized test suite may have less fault revealing capability than the original suite. In this paper, we apply weight-based Genetic Algorithms (GAs) to minimize the test suite for testing a product, while preserving fault detection capability and testing coverage of the original test suite. The challenge behind is to define an appropriate fitness function, which is\u00a0\u2026", "num_citations": "107\n", "authors": ["558"]}
{"title": "A practical guide to select quality indicators for assessing pareto-based search algorithms in search-based software engineering\n", "abstract": " Many software engineering problems are multi-objective in nature, which has been largely recognized by the Search-based Software Engineering (SBSE) community. In this regard, Pareto-based search algorithms, eg, Non-dominated Sorting Genetic Algorithm II, have already shown good performance for solving multi-objective optimization problems. These algorithms produce Pareto fronts, where each Pareto front consists of a set of non-dominated solutions. Eventually, a user selects one or more of the solutions from a Pareto front for their specific problems. A key challenge of applying Pareto-based search algorithms is to select appropriate quality indicators, eg, hypervolume, to assess the quality of Pareto fronts. Based on the results of an extended literature review, we found that the current literature and practice in SBSE lacks a practical guide for selecting quality indicators despite a large number of published\u00a0\u2026", "num_citations": "104\n", "authors": ["558"]}
{"title": "Cost-effective test suite minimization in product lines using search techniques\n", "abstract": " Cost-effective testing of a product in a product line requires obtaining a set of relevant test cases from the entire test suite via test selection and minimization techniques. In this paper, we particularly focus on test minimization for product lines, which identifies and eliminates redundant test cases from test suites in order to reduce the total number of test cases to execute, thereby improving the efficiency of testing. However, such minimization may result in the minimized test suite with low test coverage, low fault revealing capability, low priority test cases, and require more time than the allowed testing budget (e.g., time) as compared to the original test suite. To deal with the above issues, we formulated the minimization problem as a search problem and defined a fitness function considering various optimization objectives based on the above issues. To assess the performance of our fitness function, we conducted an\u00a0\u2026", "num_citations": "86\n", "authors": ["558"]}
{"title": "Multi-objective test prioritization in software product line testing: an industrial case study\n", "abstract": " Test prioritization is crucial for testing products in a product line considering limited budget in terms of available time and resources. In general, it is not practically feasible to execute all the possible test cases and so, ordering test case execution permits test engineers to discover faults earlier in the testing process. An efficient prioritization of test cases for one or more products requires a clear consideration of the tradeoff among various costs (eg, time, required resources) and effectiveness (eg, feature coverage) objectives. As an integral part of the future Cisco's test scheduling system for validating video conferencing products, we introduce a search-based multi-objective test prioritization technique, considering multiple cost and effectiveness measures. In particular, our multi-objective optimization setup includes the minimization of execution cost (eg, time), and the maximization of number of prioritized test cases\u00a0\u2026", "num_citations": "74\n", "authors": ["558"]}
{"title": "Model-Based Security Engineering for Cyber-Physical Systems: A Systematic Mapping Study\n", "abstract": " ContextCyber-physical systems (CPSs) have emerged to be the next generation of engineered systems driving the so-called fourth industrial revolution. CPSs are becoming more complex, open and more prone to security threats, which urges security to be engineered systematically into CPSs. Model-Based Security Engineering (MBSE) could be a key means to tackle this challenge via security by design, abstraction, and automation.ObjectiveWe aim at providing an initial assessment of the state of the art in MBSE for CPSs (MBSE4CPS). Specifically, this work focuses on finding out 1) the publication statistics of MBSE4CPS studies; 2) the characteristics of MBSE4CPS studies; and 3) the open issues of MBSE4CPS research.MethodWe conducted a systematic mapping study (SMS) following a rigorous protocol that was developed based on the state-of-the-art SMS and systematic review guidelines. From thousands\u00a0\u2026", "num_citations": "72\n", "authors": ["558"]}
{"title": "Uncertainty-Wise Cyber-Physical System test modeling\n", "abstract": " It is important that a Cyber-Physical System (CPS) with uncertainty in its behavior caused by its unpredictable operating environment, to ensure its reliable operation. One method to ensure that the CPS will handle such uncertainty during its operation is by testing the CPS with model-based testing (MBT) techniques. However, existing MBT techniques do not explicitly capture uncertainty in test ready models, i.e., capturing the uncertain expected behavior of a CPS in the presence of environment uncertainty. To fill this gap, we present an Uncertainty-Wise test-modeling framework, named as UncerTum, to create test ready models to support MBT of CPSs facing uncertainty. UncerTum relies on the definition of a UML profile [the UML Uncertainty Profile (UUP)] and a set of UML Model Libraries extending the UML profile for Modeling and Analysis of Real-Time and Embedded Systems (MARTE). UncerTum also\u00a0\u2026", "num_citations": "63\n", "authors": ["558"]}
{"title": "Automated transition from use cases to UML state machines to support state-based testing\n", "abstract": " Use cases are commonly used to structure and document requirements while UML state machine diagrams often describe the behavior of a system and serve as a basis to automate test case generation in many model-based testing (MBT) tools. Therefore, automated support for the transition from use cases to state machines would provide significant, practical help for testing system requirements. Additionally, traceability could be established through automated transformations, which could then be used for instance to link requirements to design decisions and test cases, and assess the impact of requirements changes. In this paper, we propose an approach to automatically generate state machine diagrams from use cases while establishing traceability links. Our approach is implemented in a tool, which we used to perform three case studies, including an industrial case study. The results show that high\u00a0\u2026", "num_citations": "60\n", "authors": ["558"]}
{"title": "Experiences of applying UML/MARTE on three industrial projects\n", "abstract": " MARTE (Modeling and Analysis of Real-Time and Embedded Systems) is a UML profile, which has been developed to model concepts specific to Real-Time and Embedded Systems (RTES). In previous years, we have applied UML/MARTE to three distinct industrial problems in various industry sectors: architecture modeling and configuration of large-scale and highly configurable integrated control systems, model-based robustness testing of communication-intensive systems, and model-based environment simulator generation of large-scale RTES for testing. In this paper, we report on our experiences of solving these problems by applying UML/MARTE on four industrial case studies. Based on our common experiences, we derive a framework to help practitioners for future applications of UML/MARTE. The framework provides a set of detailed guidelines on how to apply MARTE in industrial contexts and\u00a0\u2026", "num_citations": "47\n", "authors": ["558"]}
{"title": "Automated discovery of state transitions and their functions in source code\n", "abstract": " Finite\u2010state machine specifications form the basis for a number of rigorous state\u2010based testing techniques and can help to understand program behaviour. Unfortunately they are rarely maintained during software development, which means that these benefits can rarely be fully exploited. This paper describes a technique that, given a set of states that are of interest to a developer, uses symbolic execution to reverse\u2010engineer state transitions from source code. A particularly novel aspect of our approach is that, besides determining whether or not a state transition can take place, it also identifies the paths through the source code that govern a transition. The technique has been implemented as a prototype, enabling its preliminary evaluation with respect to real software systems. Copyright \u00a9 2007 John Wiley & Sons, Ltd.", "num_citations": "47\n", "authors": ["558"]}
{"title": "Enhancing test case prioritization in an industrial setting with resource awareness and multi-objective search\n", "abstract": " Test case prioritization is an essential part of test execution systems for large organizations developing software systems in the context that their software versions are released very frequently. They must be tested on a variety of compatible hardware with different configurations to ensure correct functioning of a software version on a compatible hardware. In practice, test case execution must not only execute cost-effective test cases in an optimal order, but also optimally allocate required test resources, in order to deliver high quality software releases.", "num_citations": "43\n", "authors": ["558"]}
{"title": "Constraints: The core of supporting automated product configuration of cyber-physical systems\n", "abstract": " In the context of product line engineering of cyber-physical systems, there exists a large number of constraints to support, for example, consistency checking of design decisions made in hardware and software components during configuration. Manual configuration is not feasible in this context considering that managing and manipulating all these constraints in a real industrial context is very complicated and thus warrants an automated solution. Typical automation activities in this context include automated configuration value inference, optimizing configuration steps and consistency checking. However, to this end, relevant constraints have to be well-specified and characterized in the way such that automated configuration can be enabled. In this paper, we classify and characterize constraints that are required to be specified to support most of the key functionalities of any automated product configuration\u00a0\u2026", "num_citations": "43\n", "authors": ["558"]}
{"title": "RTCM: a natural language based, automated, and practical test case generation framework\n", "abstract": " Based on our experience of collaborating with industry, we observed that test case generation usually relies on test case specifications (TCSs), commonly written in natural language, specifying test cases of a System Under Test at a high level of abstraction. In practice, TCSs are commonly used by test engineers as reference documents to perform these activities: 1) Manually executing test cases in TCSs; 2) Manually coding test cases in a test scripting language for automated test case execution. In the latter case, the gap between TCSs and executable test cases has to be filled by test engineers, requiring a significant amount of coding effort and domain knowledge. Motivated by the above observations from the industry, we first propose, in this paper, a TCS language, named as Restricted Test Case Modeling (RTCM), which is based on natural language and composed of an easy-to-use template, a set of restriction\u00a0\u2026", "num_citations": "37\n", "authors": ["558"]}
{"title": "Does aspect-oriented modeling help improve the readability of UML state machines?\n", "abstract": " Aspect-oriented modeling (AOM) is a relatively recent and very active field of research, whose application has, however, been limited in practice. AOM is assumed to yield several potential benefits such as enhanced modularization, easier evolution, increased reusability, and improved readability of models, as well as reduced modeling effort. However, credible, solid empirical evidence of such benefits is lacking. We evaluate the \u201creadability\u201d of state machines when modeling crosscutting behavior using AOM and more specifically AspectSM, a recently published UML profile. This profile extends the UML state machine notation with mechanisms to define aspects using state machines. Readability is indirectly measured through defect identification and fixing rates in state machines, and the scores obtained when answering a comprehension questionnaire about the system behavior. With AspectSM\u00a0\u2026", "num_citations": "36\n", "authors": ["558"]}
{"title": "U-test: Evolving, modelling and testing realistic uncertain behaviours of cyber-physical systems\n", "abstract": " Uncertainty is intrinsic in Cyber-Physical Systems (CPSs) due to novel interactions of embedded systems, networking equipment, cloud infrastructures and humans. Our daily life has been increasing dependent on CPS applications in safety/mission critical domains such as healthcare, aerospace, oil/gas and maritime. For example, the National Institute of Standards and Technology (NIST) reported that direct CPS applications account for more than $32.3 trillions and expect to grow $82 trillions by 2025 (about half of the world economy). Expecting enormous dependence of our lives on CPSs in the future, dealing with uncertainty at an acceptable cost is vital to avoid posing undue threats to its users and environment. To ensure correct delivery of their functions at an acceptable cost even in the presence of uncertainty, CPSs must be reliable, robust, efficient, safe, and secure. All these properties are facets of a more\u00a0\u2026", "num_citations": "35\n", "authors": ["558"]}
{"title": "A systematic test case selection methodology for product lines: results and insights from an industrial case study\n", "abstract": " In the context of product lines, test case selection aims at obtaining a set of relevant test cases for a product from the entire set of test cases available for a product line. While working on a research-based innovation project on automated testing of product lines of Video Conferencing Systems (VCSs) developed by Cisco, we felt the need to devise a cost-effective way of selecting relevant test cases for a product. To fulfill such need, we propose a systematic and automated test selection methodology using: 1) Feature Model for Testing (FM_T) to capture commonalities and variabilities of a product line; 2) Component Family Model for Testing (CFM_T) to model the structure of test case repository; 3) A tool to automatically build restrictions from CFM_T to FM_T and traces from CFM_T to the actual test cases. Using our methodology, a test engineer is only required to select relevant features through FM_T at a\u00a0\u2026", "num_citations": "29\n", "authors": ["558"]}
{"title": "Automated test case selection using feature model: an industrial case study\n", "abstract": " Automated test case selection for a new product in a product line is challenging due to several reasons. First, the variability within the product line needs to be captured in a systematic way; second, the reusable test cases from the repository are required to be identified for testing a new product. The objective of such automated process is to reduce the overall effort for selection (e.g., selection time), while achieving an acceptable level of the coverage of testing functionalities. In this paper, we propose a systematic and automated methodology using a Feature Model for Testing (FM_T) to capture commonalities and variabilities of a product line and a Component Family Model for Testing (CFM_T) to capture the overall structure of test cases in the repository. With our methodology, a test engineer does not need to manually go through the repository to select a relevant set of test cases for a new product. Instead\u00a0\u2026", "num_citations": "29\n", "authors": ["558"]}
{"title": "Nonconformity Resolving Recommendations for Product Line Configuration\n", "abstract": " In the context of large-scale system product line engineering, manual configuration is often mandatory and therefore inevitably introduces nonconformities: violating pre-defined constraints for conformance checking. Resolving nonconformities without proper tool support is more or less random, as there are usually hundreds and thousands of configurable parameters and conformance constraints, in the context of configuring a large-scale and directly deployable system. Moreover, inter-connections among constraints and configurable parameters worsen the feasibility of manual resolving nonconformities without proper tool support. In this paper, we present an automatic approach (named as Zen-FIX) to optimally recommend solutions to resolve nonconformities using multi-objective search. Solutions recommended by Zen-FIX conform to all pre-defined constraints and are optimized in terms of maximizing the overall\u00a0\u2026", "num_citations": "28\n", "authors": ["558"]}
{"title": "A systematic approach to automatically derive test cases from use cases specified in restricted natural languages\n", "abstract": " In many domains, such as avionics, oil and gas, and maritime, a common practice is to derive and execute test cases manually from requirements, where both requirements and test cases are specified in natural language (NL) by domain experts. The manual execution of test cases is largely dependent on the domain experts who wrote the test cases. The process of manual writing of requirements and test cases introduces ambiguity in their description and, in addition, test cases may not be effective since they may not be derived by systematically applying coverage criteria. In this paper, we report on a systematic approach to support automatic derivation of manually executable test cases from use cases. Both use cases and test cases are specified in restricted NLs along with carefully-defined templates implemented in a tool. We evaluate our approach with four case studies (in total having 30 use cases and\u00a0\u2026", "num_citations": "28\n", "authors": ["558"]}
{"title": "Applying UML/MARTE on industrial projects: challenges, experiences, and guidelines\n", "abstract": " Modeling and Analysis of Real-Time and Embedded Systems (MARTE) is a Unified Modeling Language (UML) profile, which has been developed to model concepts specific to Real-Time and Embedded Systems (RTES). In the last 5\u00a0years, we have applied UML/MARTE to three distinct industrial problems in three industry sectors: architecture modeling and configuration of large-scale and highly configurable integrated control systems, model-based robustness testing of communication-intensive systems, and model-based environment simulator generation of large-scale RTES for testing. In this paper, we report on our experience of solving these problems by applying UML/MARTE on four industrial case studies. We highlight the challenges we faced with respect to the industrial adoption of MARTE. Based on our combined experience, we derive a framework to guide practitioners for future applications of\u00a0\u2026", "num_citations": "27\n", "authors": ["558"]}
{"title": "Search-Based Cost-Effective Test Case Selection within a Time Budget: An Empirical Study\n", "abstract": " Due to limited time and resources available for execution, test case selection always remains crucial for cost-effective testing. It is even more prominent when test cases require manual steps, eg, operating physical equipment. Thus, test case selection must consider complicated trade-offs between cost (eg, execution time) and effectiveness (eg, fault detection capability). Based on our industrial collaboration within the Maritime domain, we identified a real-world and multi-objective test case selection problem in the context of robustness testing, where test case execution requires human involvement in certain steps, such as turning on the power supply to a device. The high-level goal is to select test cases for execution within a given time budget, where test engineers provide weights for a set of objectives, depending on testing requirements, standards, and regulations. To address the identified test case selection\u00a0\u2026", "num_citations": "26\n", "authors": ["558"]}
{"title": "Cyber-physical system product line engineering: comprehensive domain analysis and experience report\n", "abstract": " Cyber-Physical Systems (CPSs) are the future generation of highly connected embedded systems having applications in diverse domains including Oil and Gas. Employing Product Line Engineering (PLE) is believed to bring potential benefits with respect to reduced cost, higher productivity, higher quality, and faster time-to-market. However, relatively few industrial field studies are reported regarding the application of PLE to develop large-scale systems, and more specifically CPSs. In this paper, we report about our experiences and insights gained from investigating the application of model-based PLE at a large international organization developing subsea production systems (typical CPSs) to manage the exploitation of oil and gas production fields. We report in this paper 1) how two systematic domain analyses (on requirements engineering and product configuration/derivation) were conducted to elicit CPS PLE\u00a0\u2026", "num_citations": "25\n", "authors": ["558"]}
{"title": "Model-based incremental conformance checking to enable interactive product configuration\n", "abstract": " ContextModel-based product line engineering (PLE) is a paradigm that can enable automated product configuration of large-scale software systems, in which models are used as an abstract specification of commonalities and variabilities of products of a product line.ObjectiveIn the context of PLE, providing immediate feedback on the correctness of a manual configuration step to users has a practical impact on whether a configuration process with tool support can be successfully adopted in practice.MethodIn an existing work, a UML-based variability modeling methodology named as SimPL and an interactive configuration process was proposed. Based on the existing work, we propose an automated, incremental and efficient conformance checking approach to ensure that the manual configuration of a variation point conforms to a set of pre-defined conformance rules specified in the Object Constraint Language\u00a0\u2026", "num_citations": "24\n", "authors": ["558"]}
{"title": "A product line modeling and configuration methodology to support model-based testing: an industrial case study\n", "abstract": " Product Line Engineering (PLE) is expected to enhance quality and productivity, speed up time-to-market and decrease development effort, through reuse\u2014the key mechanism of PLE. In addition, one can also apply PLE to support systematic testing and more specifically model-based testing (MBT) of product lines\u2014the original motivation behind this work. MBT has shown to be cost-effective in many industry sectors but at the expense of building models of the system under test (SUT). However, the modeling effort to support MBT can significantly be reduced if an adequate product line modeling and configuration methodology is followed, which is the main motivation of this paper. The initial motivation for this work emerged while working with MBT for a Video Conferencing product line at Cisco Systems, Norway. In this paper, we report on our experience in modeling product family models and various types\u00a0\u2026", "num_citations": "24\n", "authors": ["558"]}
{"title": "Zen-ReqOptimizer: a search-based approach for requirements assignment optimization\n", "abstract": " At early phases of a product development lifecycle of large scale Cyber-Physical Systems (CPSs), a large number of requirements need to be assigned to stakeholders from different organizations or departments of the same organization for review, clarification and checking their conformance to standards and regulations. These requirements have various characteristics such as extents of importance to the organization, complexity, and dependencies between each other, thereby requiring different effort (workload) to review and clarify. While working with our industrial partners in the domain of CPSs, we discovered an optimization problem, where an optimal solution is required for assigning requirements to various stakeholders by maximizing their familiarity to assigned requirements, meanwhile balancing the overall workload of each stakeholder. In this direction, we propose a fitness function that takes into\u00a0\u2026", "num_citations": "20\n", "authors": ["558"]}
{"title": "REMAP: Using Rule Mining and Multi-objective Search for Dynamic Test Case Prioritization\n", "abstract": " Test case prioritization (TP) prioritizes test cases into an optimal order for achieving specific criteria (e.g., higher fault detection capability) as early as possible. However, the existing TP techniques usually only produce a static test case order before the execution without taking runtime test case execution results into account. In this paper, we propose an approach for black-box dynamic TP using rule mining and multi-objective search (named as REMAP). REMAP has three key components: 1) Rule Miner, which mines execution relations among test cases from historical execution data; 2) Static Prioritizer, which defines two objectives (i.e., fault detection capability (FDC) and test case reliance score (TRS)) and applies multi-objective search to prioritize test cases statically; and 3) Dynamic Executor and Prioritizer, which executes statically-prioritized test cases and dynamically updates the test case order based on the\u00a0\u2026", "num_citations": "18\n", "authors": ["558"]}
{"title": "Product line engineering of monitoring functionality in industrial cyber-physical systems: a domain analysis\n", "abstract": " In recent years, manufacturing technology is evolving and progressively becoming more dynamic and complex. This means that manufacturing technology (eg, based on Industry 4.0) should be able to control the production process at runtime by monitoring physical elements and adapting itself. Such functionality is aimed at increasing production effectiveness and reducing the production cost. We argue that monitoring process can be viewed as a software product line having commonalities and variability. To support our argument, we analyzed and conducted domain analysis of two monitoring systems of Industrial Cyber-Physical Systems (ICPSs) from two industrial domains including automated warehouses and press machines. Based on the domain analysis, we present a common solution for monitoring including a software product line. With such product line, a user can configure, monitor, and visualize data of\u00a0\u2026", "num_citations": "18\n", "authors": ["558"]}
{"title": "CBGA-ES: A Cluster-Based Genetic Algorithm with Elitist Selection for Supporting Multi-Objective Test Optimization\n", "abstract": " Multi-objective search algorithms (e.g., non-dominated sorting genetic algorithm II (NSGA-II)) have been frequently applied to address various testing problems requiring multi-objective optimization such as test case selection. However, existing multi-objective search algorithms have certain randomness when selecting parent solutions for producing offspring solutions. In the worse case, suboptimal parent solutions may result in offspring solutions with bad quality, and thus affect the overall quality of the next generation. To address such a challenge, we propose a cluster-based genetic algorithm with elitist selection (CBGA-ES) with the aim to reduce such randomness for supporting multi-objective test optimization. We empirically compared CBGA-ES with random search, greedy (as baselines) and four commonly used multi-objective search algorithms (e.g., NSGA-II) using two industrial and one real world test\u00a0\u2026", "num_citations": "18\n", "authors": ["558"]}
{"title": "An evaluation of aspect oriented testing techniques\n", "abstract": " Aspect oriented programming (R.T. Alexander, et al) promises to enhance software quality by increasing the cohesion of classes and localizing both core and crosscutting concerns. The quality of software, however, can only be validated by testing the software. Testing aspect oriented programs remains just as important as testing any other software. This paper presents an analysis of the testing strategies for AOPs. Three testing strategies have been examined and their effectiveness is measured in terms of their ability to find different kind of faults as described in a fault model by R.T. Alexander, et al. Based on this analysis, conclusions have been drawn about the current state of the research in the testing of aspect oriented programs and future directions have been explored.", "num_citations": "18\n", "authors": ["558"]}
{"title": "UPMOA: An improved search algorithm to support user-preference multi-objective optimization\n", "abstract": " Multi-objective search algorithms (e.g., non-dominated sorting genetic algorithm II (NSGA-II)) have been applied extensively to solve various multi-objective optimization problems in software engineering such as problems in testing. However, existing multi-objective algorithms usually treat all the objectives with equivalent priorities and do not provide a mechanism to reflect various user preferences when guiding search. The need to have such a mechanism was observed in one of our industrial projects on applying search algorithms for test optimization of a product line of Videoconferencing Systems (VCSs) called Saturn, where user preferences must be incorporated into optimization objectives, based on domain knowledge of test engineers for VCS testing. To address this, we propose an extension to the most commonly-used multi-objective search algorithm NSGA-II, which has shown promising results with user\u00a0\u2026", "num_citations": "17\n", "authors": ["558"]}
{"title": "Using feature model to support model-based testing of product lines: an industrial case study\n", "abstract": " In the context of Model-Based Testing (MBT) of product lines, effort required to develop models can be significantly reduced by applying systematic product line modeling and configuration methodologies. In our previous work, we developed such a methodology to capture variability in configurable UML state machines and aspect state machines. For each product, these state machines are to be configured for generating executable test cases. In this paper, we extended this methodology using Feature Model for Testing (FM_T) and Component Family Model for Behaviors (CFM_B). FM_T captures variable testing functionalities of a product line, whereas CFM_B provides an abstraction layer on top of the configurable state machines. With our current methodology, a test engineer doesn't need to acquire expertise on behavioral modeling and can simply configure models for a product by selecting features in FM_T and\u00a0\u2026", "num_citations": "17\n", "authors": ["558"]}
{"title": "Evaluating Variability Modeling Techniques for Supporting Cyber-Physical System Product Line Engineering\n", "abstract": " Modern society is increasingly dependent on Cyber-Physical Systems (CPSs) in diverse domains such as aerospace, energy and healthcare. Employing Product Line Engineering (PLE) in CPSs is cost-effective in terms of reducing production cost, and achieving high productivity of a CPS development process as well as higher quality of produced CPSs. To apply CPS PLE in practice, one needs to first select an appropriate variability modeling technique (VMT), with which variabilities of a CPS Product Line (PL) can be specified. In this paper, we proposed a set of basic and CPS-specific variation point (VP) types and modeling requirements for proposing CPS-specific VMTs. Based on the proposed set of VP types (basic and CPS-specific) and modeling requirements, we evaluated four VMTs: Feature Modeling, Cardinality Based Feature Modeling, Common Variability Language, and SimPL (a variability\u00a0\u2026", "num_citations": "16\n", "authors": ["558"]}
{"title": "A modeling methodology to facilitate safety\u2010oriented architecture design of industrial avionics software\n", "abstract": " Ensuring that avionics software meets safety requirements at each development stage is very important to warrant the safe operation of an avionics system. Many safety requirements are imposed by various standards and industrial regulations that must be met by avionics software. One of such standards is DO\u2010178B/C, which provides guidelines (e.g., development process and objectives to satisfy in development activities) for meeting safety requirements. This paper presents a modeling methodology including a UML profile for specifying safety requirements on a component\u2010based architecture model and a set of design guidelines on avionics software. These safety requirements were identified from both standards (mainly DO\u2010178B/C) and current engineering practices in the domain of avionics systems. The methodology automatically enforces these safety requirements. We have applied the methodology on an\u00a0\u2026", "num_citations": "16\n", "authors": ["558"]}
{"title": "Towards a Search-based Interactive Configuration of Cyber Physical System Product Lines.\n", "abstract": " Product Line Engineering (PLE) is a technique to improve the quality and productivity of developing (via configuration) Cyber Physical Systems (CPSs). A CPS often contains many heterogeneous components with complex constraints relevant to product configuration in the context of PLE. Manual configuration is error-prone and has low productivity since managing and manipulating such constraints in a real industrial context is very complicated and thus warrants an automated solution. However, fully automated solution is often impossible for CPSs since some decisions must be made manually by users, thus requiring an interactive configuration solution. Therefore, we propose a semi-automated and interactive configuration solution for CPSs. We started our research by analyzing the characteristics of three industrial CPS product lines and constraints required for supporting such a configuration solution. Then we conducted some pilot experiments on applying search algorithms to find optimal decision orders for configuring a product. In this poster, we describe the whole research idea and, discsusion on the work we have completed, the initial results, and the future plan.", "num_citations": "16\n", "authors": ["558"]}
{"title": "STIPI: Using Search to Prioritize Test Cases Based on Multi-objectives Derived from Industrial Practice\n", "abstract": " The importance of cost-effectively prioritizing test cases is undeniable in automated testing practice in industry. This paper focuses on prioritizing test cases developed to test product lines of Video Conferencing Systems (VCSs) at Cisco Systems, Norway. Each test case requires setting up configurations of a set of VCSs, invoking a set of test APIs with specific inputs, and checking statuses of the VCSs under test. Based on these characteristics and available information related with test case execution (e.g., number of faults detected), we identified that the test case prioritization problem in our particular context should focus on achieving high coverage of configurations, test APIs, statuses, and high fault detection capability as quickly as possible. To solve this problem, we propose a search-based test case prioritization approach (named STIPI) by defining a fitness function with four objectives and integrating it\u00a0\u2026", "num_citations": "15\n", "authors": ["558"]}
{"title": "Reliability-redundancy-location allocation with maximum reliability and minimum cost using search techniques\n", "abstract": " ContextA safety critical system requires an automated and optimal allocation of redundant component instances to its existing components, including: 1) the selection of components (locations) on which the redundancy must be applied, 2) how many redundant component instances of varying reliability and cost should be allocated to each selected location.ObjectiveOur work aims to searching for the near optimal allocation solutions achieving the higher reliability of the system within the allowed cost. Such allocation must be made earlier, for example, while designing the architecture of the system to avoid unnecessary complexity of addressing unsafe situations discovered in the system development and deployment phases.MethodWith the above objective in mind, we propose a search-based allocation approach based on the overall objectives of maximizing the overall system reliability and minimizing the cost of\u00a0\u2026", "num_citations": "15\n", "authors": ["558"]}
{"title": "Zen-CC: An Automated and Incremental Conformance Checking Solution to Support Interactive Product Configuration\n", "abstract": " In the context of product line engineering (PLE), providing immediate feedback on the correctness of a manual configuration step to users has a practical impact on whether a configuration process with tool support can be successfully adopted in practice. Model-based PLE has brought opportunities to enable automated product configuration and derivation for large-scale systems/software, in which models are used as the abstract specification of commonalities and variabilities of products of a product line. In our previous work, we have proposed a UML-based variability modeling methodology and an interactive configuration process. Based on these work, in this paper, we propose an automated and incremental conformance checking approach to ensure that the manual configuration to each variation point conforms to a set of pre-defined conformance rules specified in OCL. The proposed approach, called Zen-CC\u00a0\u2026", "num_citations": "15\n", "authors": ["558"]}
{"title": "Applying search algorithms for optimizing stakeholders familiarity and balancing workload in requirements assignment\n", "abstract": " During the early phase of project development lifecycle of large scale cyber-physical systems, a large number of requirements are needed to be assigned to different stakeholders from different organizations or different departments of the same organization for reviewing, clarifying and checking their conformance to industry standards and government or other regulations. These requirements have different characteristics such as various extents of importance to the organization, complexity, and dependencies between each other, thereby requiring different effort (workload) to review and clarify. While working with our industrial partners in the domain of cyber-physical systems, we discovered an optimization problem, where an optimal solution is required for assigning requirements to different stakeholders by maximizing their familiarities to the assigned requirements while balancing the overall workload of each\u00a0\u2026", "num_citations": "15\n", "authors": ["558"]}
{"title": "Uncertainty-Wise Testing of Cyber-Physical Systems\n", "abstract": " As compared with classical software/system testing, uncertainty-wise testing explicitly addresses known uncertainty about the behavior of a System Under Test (SUT), its operating environment, and interactions between the SUT and its operational environment, across all testing phases, including test design, test generation, test optimization, and test execution, with the aim to mainly achieve the following two goals. First, uncertainty-wise testing aims to ensure that the SUT deals with known uncertainty adequately. Second, uncertainty-wise testing should be also capable of learning new (previously unknown) uncertainties such that the SUT's implementation can be improved to guard against newly learned uncertainties during its operation. The necessity to integrate uncertainty in testing is becoming imperative because of the emergence of new types of intelligent and communicating software-based systems such as\u00a0\u2026", "num_citations": "14\n", "authors": ["558"]}
{"title": "Automated product line test case selection: industrial case study and controlled experiment\n", "abstract": " Automated test case selection for a new product in a product line is challenging due to several reasons. First, the variability within the product line needs to be captured in a systematic way; second, the reusable test cases from the repository are required to be identified for testing a new product. The objective of such automated process is to reduce the overall effort for selection (e.g., selection time), while achieving an acceptable level of the coverage of testing functionalities. In this paper, we propose a systematic and automated methodology using a feature model for testing (FM_T) to capture commonalities and variabilities of a product line and a component family model for testing (CFM_T) to capture the overall structure of test cases in the repository. With our methodology, a test engineer does not need to manually go through the repository to select a relevant set of test cases for a new product. Instead, a\u00a0\u2026", "num_citations": "14\n", "authors": ["558"]}
{"title": "Insights on the use of OCL in diverse industrial applications\n", "abstract": " The Object Constraint Language (OCL) is a widely accepted language, standardized by OMG, for specifying constraints at various meta levels (e.g., meta-models and models). Despite its wide acceptance, there is a lack of understanding about terminology and purposes for which OCL can be used. In this paper, we aim to reduce this gap and provide guidance for applying OCL in practical contexts and we report our experience of applying OCL for different industrial projects in diverse domains: Communications and Control, Oil and Gas production, Energy Equipment and Services, and Recycling. Based on our experience, first, we unify the commonly used terminology in the literature for applying OCL in different ways for addressing diverse industrial problems. Second, we report the key results of the industrial application of OCL. Finally, we provide guidance to researchers and practitioners for choosing an\u00a0\u2026", "num_citations": "14\n", "authors": ["558"]}
{"title": "Bridging the Gap between Requirements and Aspect State Machines to Support Non-functional Testing: Industrial Case Studies\n", "abstract": " Requirements are often structured and documented as use cases while UML state machine diagrams often describe the behavior of a system. State machines capture rich and detailed behavior of a system, which can serve as a basis for many automated activities such as automated test case and code generation. The former is of interest in this paper. Non-functional behavior can be modeled using standard UML state machines, but usually results in complex state machines. To cope with such complexity, Aspect-Oriented Modeling (AOM) is often recommended. AspectSM is a UML profile defined to model crosscutting behavior on UML state machines called as aspect state machines with the focus of supporting model-based test case generation for non-functional behavior. Hence, an automatic transition from use cases to aspect state machines would provide significant, practical help for testing system\u00a0\u2026", "num_citations": "14\n", "authors": ["558"]}
{"title": "Specifying uncertainty in use case models\n", "abstract": " ContextLatent uncertainty in the context of software-intensive systems (e.g., Cyber-Physical Systems (CPSs)) demands explicit attention right from the start of development. Use case modeling\u2014a commonly used method for specifying requirements in practice, should also be extended for explicitly specifying uncertainty.ObjectiveSince uncertainty is a common phenomenon in requirements engineering, it is best to address it explicitly by identifying, qualifying, and, where possible, quantifying uncertainty at the beginning stage. The ultimate aim, though not within the scope of this paper, was to use these use cases as the starting point to create test-ready models to support automated testing of CPSs under uncertainty.MethodWe extend the Restricted Use Case Modeling (RUCM) methodology and its supporting tool to specify uncertainty as part of system requirements. Such uncertainties include those caused by\u00a0\u2026", "num_citations": "13\n", "authors": ["558"]}
{"title": "Modeling foundations for executable model-based testing of self-healing cyber-physical systems\n", "abstract": " Self-healing cyber-physical systems (SH-CPSs) detect and recover from faults by themselves at runtime. Testing such systems is challenging due to the complex implementation of self-healing behaviors and their interaction with the physical environment, both of which are uncertain. To this end, we propose an executable model-based approach to test self-healing behaviors under environmental uncertainties. The approach consists of a Modeling Framework of SH-CPSs (MoSH) and an accompanying Test Model Executor (TM-Executor). MoSH provides a set of modeling constructs and a methodology to specify executable test models, which capture expected system behaviors and environmental uncertainties. TM-Executor executes the test models together with the systems under test, to dynamically test their self-healing behaviors under uncertainties. We demonstrated the successful application of MoSH to\u00a0\u2026", "num_citations": "13\n", "authors": ["558"]}
{"title": "Zen-RUCM: A Tool for Supporting a Comprehensive and Extensible Use Case Modeling Framework.\n", "abstract": " The Restricted Use Case Modeling (RUCM) approach is composed of a set of well-defined restriction rules and a new template, aiming to reduce ambiguity and facilitate automated analysis. Zen-RUCM is an RUCM-based framework to tackle the challenges of requirement specification in different application domains (eg, real-time systems) and from various requirement specification concerns (eg, variability). In this demonstration, we discuss an implementation of the Zen-RUCM framework with the focus on its lightweight design architecture and extension mechanism.(Demonstration video link: http://youtu. be/a8YZ_wuVxQg)", "num_citations": "13\n", "authors": ["558"]}
{"title": "Simultaneously searching and solving multiple avoidable collisions for testing autonomous driving systems\n", "abstract": " The oracle problem is a key issue in testing Autonomous Driving Systems (ADS): when a collision is found, it is not always clear whether the ADS is responsible for it. Our recent search-based testing approach offers a solution to this problem by defining a collision as avoidable if a differently configured ADS would have avoided it. This approach searches for both collision scenarios and the ADS configurations capable of avoiding them. However, its main problem is that the ADS configurations generated for avoiding some collisions are not suitable for preventing other ones. Therefore, it does not provide any guidance to automotive engineers for improving the safety of the ADS. To this end, we propose a new search-based approach to generate configurations of the ADS that can avoid as many different types of collisions as possible. We present two versions of the approach, which differ in the way of searching for\u00a0\u2026", "num_citations": "11\n", "authors": ["558"]}
{"title": "Empirically evaluating OCL and Java for specifying constraints on UML models\n", "abstract": " The Object Constraint Language (OCL) has been applied, along with UML models, for various purposes such as supporting model-based testing, code generation, and automated consistency checking of UML models. However, a lot of challenges have been raised in the literature regarding its applicability in industry such as extensive training, slow learning curve, and significant effort to use OCL due to lack of familiarity of practitioners. To confirm these challenges, empirical evidence is needed, which is severely lacking in the literature. To build such preliminary evidence, we report a controlled experiment that was designed to evaluate OCL by comparing it with Java; a programming language that has also been used to specify constraints on UML models. Results show that the participants using OCL perform as good as the participants working with Java in terms of three objective quality metrics (i.e\u00a0\u2026", "num_citations": "11\n", "authors": ["558"]}
{"title": "Ensuring safety of avionics software at the architecture design level: an industrial case study\n", "abstract": " Ensuring that avionics software meets safety requirements at each development stage is very important to warrant the safe operation of an avionics system. Many safety requirements are imposed by various standards and industrial regulations that must be met by avionics software. One of such standards is DO-178B/C, which provides guidelines (e.g. development process and the objectives to satisfy in development activities) for meeting the safety requirements. This paper presents a modeling methodology including a UML profile for specifying safety requirements on a component-based architecture model and a set of design guidelines on avionics software. These safety requirements were identified from both standards (mainly DO-178B/C) and current engineering practices in the domain of avionics system. The methodology enforces safety requirements automatically. We have applied the methodology on an\u00a0\u2026", "num_citations": "11\n", "authors": ["558"]}
{"title": "Employing Rule Mining and Multi-Objective Search for Dynamic Test Case Prioritization\n", "abstract": " Test case prioritization (TP) is widely used in regression testing for optimal reordering of test cases to achieve specific criteria (e.g., higher fault detection capability) as early as possible. In our earlier work, we proposed an approach for black-box dynamic TP using rule mining and multi-objective search (named as REMAP) by defining two objectives (fault detection capability and test case reliance score) and considering test case execution results at runtime. In this paper, we conduct an extensive empirical evaluation of REMAP by employing three different rule mining algorithms and three different multi-objective search algorithms, and we also evaluate REMAP with one additional objective (estimated execution time) for a total of 18 different configurations (i.e., 3\u2009rule\u2009mining\u2009algorithms\u202f\u00d7\u202f\u20093\u2009search\u2009algorithms\u202f\u00d7\u202f\u20092\u2009different\u2009set\u2009of\u2009objectives) of REMAP. Specifically, we empirically evaluated the 18\u00a0\u2026", "num_citations": "10\n", "authors": ["558"]}
{"title": "Testing self-healing cyber-physical systems under uncertainty: a fragility-oriented approach\n", "abstract": " As an essential feature of smart cyber-physical systems (CPSs), self-healing behaviors play a major role in maintaining the normality of CPSs in the presence of faults and uncertainties. It is important to test whether self-healing behaviors can correctly heal faults under uncertainties to ensure their reliability. However, the autonomy of self-healing behaviors and impact of uncertainties make it challenging to conduct such testing. To this end, we devise a fragility-oriented testing approach, which is comprised of two novel algorithms: fragility-oriented testing (FOT) and uncertainty policy optimization (UPO). The two algorithms utilize the fragility, obtained from test executions, to learn the optimal policies for invoking operations and introducing uncertainties, respectively, to effectively detect faults. We evaluated their performance by comparing them against a coverage-oriented testing (COT) algorithm and a random\u00a0\u2026", "num_citations": "10\n", "authors": ["558"]}
{"title": "An empirical evaluation of mutation and crossover operators for multi-objective uncertainty-wise test minimization\n", "abstract": " Multi-objective uncertainty-wise test case minimization focuses on selecting a minimum number of test cases to execute out of all available ones while maximizing effectiveness (e.g., coverage), minimizing cost (e.g., time to execute test cases), and at the same time optimizing uncertainty-related objectives. In our previous unpublished work, we developed four uncertainty-wise test case minimization strategies relying on Uncertainty Theory and multi-objective search (NSGA-II with default settings), which were evaluated with one real Cyber-Physical System (CPS) with inherent uncertainty. However, a fundamental question to answer is whether these default settings of NSGA-II are good enough to provide optimized solutions. In this direction, we report one of the preliminary empirical evaluations, where we performed an experiment with three different mutation operators and three crossover operators, i.e., in total nine\u00a0\u2026", "num_citations": "10\n", "authors": ["558"]}
{"title": "Enabling automated requirements reuse and configuration\n", "abstract": " A system product line (PL) often has a large number of reusable and configurable requirements, which in practice are organized hierarchically based on the architecture of the PL. However, the current literature lacks approaches that can help practitioners to systematically and automatically develop structured and configuration-ready PL requirements repositories. In the context of product line engineering and model-based engineering, automatic requirements structuring can benefit from models. Such a structured PL requirements repository can greatly facilitate the development of product-specific requirements repository, the product configuration at the requirements level, and the smooth transition to downstream product configuration phases (e.g., at the architecture design phase). In this paper, we propose a methodology with tool support, named as Zen-ReqConfig, to tackle the above challenge. Zen\u00a0\u2026", "num_citations": "10\n", "authors": ["558"]}
{"title": "Assessing the quality of industrial avionics software: an extensive empirical evaluation\n", "abstract": " A real-time operating system for avionics (RTOS4A) provides an operating environment for avionics application software. Since an RTOS4A has safety-critical applications, demonstrating a satisfactory level of its quality to its stakeholders is very important. By assessing the variation in quality across consecutive releases of an industrial RTOS4A based on test data collected over 17\u00a0months, we aim to provide a set of guidelines to 1) improve the test effectiveness and thus the quality of subsequent RTOS4A releases and 2) similarly assess the quality of other systems from test data. We carefully defined a set of research questions, for which we defined a number of variables (based on available test data), including release and measures of test effort, test effectiveness, complexity, test efficiency, test strength, and failure density. With these variables, to assess the quality in terms of number of failures found in tests\u00a0\u2026", "num_citations": "10\n", "authors": ["558"]}
{"title": "An evolutionary and automated virtual team making approach for crowdsourcing platforms\n", "abstract": " Crowdsourcing has demonstrated its capability of supporting various software development activities including development and testing as it can be seen by several successful crowdsourcing platforms such as TopCoder and uTest. However, to crowd source large-scale and complex software development and testing tasks, there are several optimization challenges to be addressed such as division of tasks, searching a set of registrants, and assignment of tasks to registrants.Since in crowdsourcing a task can be assigned to registrants geographically distributed with various backgrounds, the quality of final task deliverables is a key issue. As the first step to improve the quality, we propose a systematic and automated approach to optimize the assignment of registrants in a crowdsourcing platform to a crowdsourcing task. The objective is to find the best fit of a group of registrants to the defined task. A few\u00a0\u2026", "num_citations": "10\n", "authors": ["558"]}
{"title": "Automated refactoring of OCL constraints with search\n", "abstract": " Object Constraint Language (OCL) constraints are typically used to provide precise semantics to models developed with the Unified Modeling Language (UML). When OCL constraints evolve regularly, it is essential that they are easy to understand and maintain. For instance, in cancer registries, to ensure the quality of cancer data, more than one thousand medical rules are defined and evolve regularly. Such rules can be specified with OCL. It is, therefore, important to ensure the understandability and maintainability of medical rules specified with OCL. To tackle such a challenge, we propose an automated search-based OCL constraint refactoring approach (SBORA) by defining and applying four semantics-preserving refactoring operators (i.e., Context Change, Swap, Split and Merge) and three OCL quality metrics (Complexity, Coupling, and Cohesion) to measure the understandability and maintainability of OCL\u00a0\u2026", "num_citations": "9\n", "authors": ["558"]}
{"title": "Search and similarity based selection of use case scenarios: An empirical study\n", "abstract": " Use case modeling is a well-known requirements specification method and has been widely applied in practice. Use case scenarios of use case models are input elements for requirements inspection and analysis, requirements-based testing, and other downstream activities. It is, however, a practical challenge to inspect all use case scenarios that can be obtained from any non-trivial use case model, as such an inspection activity is often performed manually by domain experts. Therefore, it is needed to propose an automated solution for selecting a subset of use case scenarios with the ultimate aim of enabling cost-effective requirements (use case) inspection, analysis, and other relevant activities. Our solution is built on a natural language based, restricted use case modeling methodology (named as RUCM), in the sense that requirements specifications are specified as RUCM use case models. Use case\u00a0\u2026", "num_citations": "9\n", "authors": ["558"]}
{"title": "Search-based decision ordering to facilitate product line engineering of cyber-physical system\n", "abstract": " Industrial Cyber Physical Systems (CPSs) are naturally complex. Manual configuration of CPS product lines is error-prone and inefficient, which warrants the need for automated support of product configuration activities such as decision inference and decision ordering. A fully automated solution is often impossible for CPSs since some decisions must be made manually by configuration engineers and thus requiring an interactive and step-by-step configuration solution. Having an interactive solution with tool support in mind, we propose a search-based solution (named as Zen-DO) to support optimal ordering of configuration steps. The optimization objective has three parts: 1) minimizing overall manual configuration steps, 2) configuring most constraining decisions first, and 3) satisfying ordering dependencies among variabilities. We formulated our optimization objective as a fitness function and investigated it\u00a0\u2026", "num_citations": "9\n", "authors": ["558"]}
{"title": "Quality Indicators in Search-based Software Engineering: An Empirical Evaluation\n", "abstract": " Search-Based Software Engineering (SBSE) researchers who apply multi-objective search algorithms (MOSAs) often assess the quality of solutions produced by MOSAs with one or more quality indicators (QIs). However, SBSE lacks evidence providing insights on commonly used QIs, especially about agreements among them and their relations with SBSE problems and applied MOSAs. Such evidence about QIs agreements is essential to understand relationships among QIs, identify redundant QIs, and consequently devise guidelines for SBSE researchers to select appropriate QIs for their specific contexts. To this end, we conducted an extensive empirical evaluation to provide insights on commonly used QIs in the context of SBSE, by studying agreements among QIs with and without considering differences of SBSE problems and MOSAs. In addition, by defining a systematic process based on three common ways\u00a0\u2026", "num_citations": "8\n", "authors": ["558"]}
{"title": "CBGA-ES+: A Cluster-Based Genetic Algorithm with Non-Dominated Elitist Selection for Supporting Multi-Objective Test Optimization\n", "abstract": " Many real-world test optimization problems (e.g., test case prioritization) are multi-objective intrinsically and can be tackled using various multi-objective search algorithms (e.g., Non-dominated Sorting Genetic Algorithm (NSGA-II)). However, existing multi-objective search algorithms have certain randomness when selecting parent solutions for producing offspring solutions. In a worse case, suboptimal parent solutions may result in offspring solutions with bad quality, and thus affect the overall quality of the solutions in the next generation. To address such a challenge, we propose CBGA-ES+, a novel cluster-based genetic algorithm with non-dominated elitist selection to reduce the randomness when selecting the parent solutions to support multi-objective test optimization. We empirically compared CBGA-ES+ with random search and greedy (as baselines), four commonly used multi-objective search algorithms (i.e\u00a0\u2026", "num_citations": "8\n", "authors": ["558"]}
{"title": "MBF4CR: A Model-Based Framework for Supporting an Automated Cancer Registry System\n", "abstract": " The Cancer Registry of Norway (CRN) collects medical information (e.g., laboratory results, clinical procedures and treatment) of cancer patients from different medical entities, for all cancer patients in Norway. The collected data are checked for validity and correctness (i.e., validation) and is the basis for the registration of cancer cases (i.e., aggregation) by employing more than a thousand of medical rules. However, the current practice of CRN lacks of a systematic way to capture the domain knowledge and maintain medical rules at a proper level of abstraction.                 To tackle these challenges, this paper proposes a model-based framework (named as MBF4CR) for capturing the domain knowledge, formalizing medical rules, automating rule selection, and enabling data (cancer messages and cancer cases) validation and aggregation using Unified Modeling Language (UML) and Object Constraint\u00a0\u2026", "num_citations": "8\n", "authors": ["558"]}
{"title": "Random-Weighted Search-Based Multi-objective Optimization Revisited\n", "abstract": " Weight-based multi-objective optimization requires assigning appropriate weights using a weight strategy to each of the objectives such that an overall optimal solution can be obtained with a search algorithm. Choosing weights using an appropriate weight strategy has a huge impact on the obtained solutions and thus warrants the need to seek the best weight strategy. In this paper, we propose a new weight strategy called Uniformly Distributed Weights (UDW), which generates weights from uniform distribution, while satisfying a set of user-defined constraints among various cost and effectiveness measures. We compare UDW with two commonly used weight strategies, i.e., Fixed Weights (FW) and Randomly-Assigned Weights (RAW), based on five cost/effectiveness measures for an industrial problem of test minimization defined in the context of Video Conferencing System Product Line developed by\u00a0\u2026", "num_citations": "8\n", "authors": ["558"]}
{"title": "Assessing the effectiveness of input and output coverage criteria for testing quantum programs\n", "abstract": " Quantum programs implement quantum algorithms solving complex computational problems. Testing such programs is challenging due to the inherent characteristics of Quantum Computing (QC), such as the probabilistic nature and computations in superposition. However, automated and systematic testing is needed to ensure the correct behavior of quantum programs. To this end, we present an approach called Quito (QUantum InpuT Output coverage) consisting of three coverage criteria defined on the inputs and outputs of a quantum program, together with their test generation strategies. Moreover, we define two types of test oracles, together with a procedure to determine the passing and failing of test suites with statistical analyses. To evaluate the cost-effectiveness of the three coverage criteria, we conducted experiments with five quantum programs. We used mutation analysis to determine the coverage\u00a0\u2026", "num_citations": "7\n", "authors": ["558"]}
{"title": "A restricted natural language based use case modeling methodology for real-time systems\n", "abstract": " Time-related properties are a critical type of extrafunctional requirements for designing real-time systems. Modeling and validating time-related properties at the requirements specification and analysis phases is important for the successful development of real-time systems in terms of cost, quality and productivity. In the literature and practice, timing analyses (e.g., Worst Case Execution Time) are often performed to ensure that the design of a real-time system fully conforms to its time-related constraints. However, such analyses are mostly performed at the design and implementation stages, but not at the requirements level. This paper presents a restricted, natural language based, use case modeling methodology (named as RUCM4RT) to specify functional requirements of real-time systems as use case models, along with associated time-related constraints. RUCM4RT was proposed based on the UML profile for\u00a0\u2026", "num_citations": "7\n", "authors": ["558"]}
{"title": "Facilitating requirements inspection with search-based selection of diverse use case scenarios\n", "abstract": " Use case scenarios are often used for conducting requirements inspection and other relevant downstream activities. While working with industrial partners, we discovered that an automated solution is required for optimally selecting a subset of use case scenarios, aiming to enable cost-effective requirements inspection. In this paper, relying on a natural language based use case modeling methodology to specify requirements as use case models and derive use case scenarios automatically, we propose a search based and similarity function based approach to optimally select most diverse use case scenarios from the ones automatically generated from the use case models. We conducted an empirical study to evaluate the performance of various search algorithms together with eight similarity functions, through an industrial case study and six case studies from the literature. Results show that the search algorithms\u00a0\u2026", "num_citations": "7\n", "authors": ["558"]}
{"title": "Assessing quality and effort of applying aspect state machines for robustness testing: a controlled experiment\n", "abstract": " Aspect-Oriented Modeling (AOM) has been the subject of intense research over the last decade and aims to provide numerous benefits to modeling, such as enhanced modularization, easier evolution, higher quality as well as reduced modeling effort. However, these benefits can only be obtained at the cost of learning and applying new modeling approaches. Studying their applicability is therefore important to assess whether they are worth using in practice. In this paper, we report a controlled experiment to assess the applicability of AOM, focusing on a recently published UML profile (AspectSM). This profile was originally designed to support model-based robustness testing in an industrial context but is applicable to the behavioral modeling of other crosscutting concerns. This experiment assesses the applicability of AspectSM from two aspects: the quality of derived state machines and the effort required to build\u00a0\u2026", "num_citations": "7\n", "authors": ["558"]}
{"title": "A comparative study of methods for dynamic reverse-engineering of state models\n", "abstract": " This paper provides a comparison of dynamic analysis techniques to reverse engineer state models of software. Since running a program generates a lot of data, the utility of different techniques is related to their ability to construct models which are both reflecting the relevant characteristics of a program and of manageable size. The classification of techniques in this paper aims to highlight the different approaches to abstraction utilised in the surveyed papers, so that one can mix-and-match different techniques depending on the kind of models which need to be built.", "num_citations": "7\n", "authors": ["558"]}
{"title": "Digital Twin-based Anomaly Detection in Cyber-physical Systems\n", "abstract": " Cyber-Physical Systems (CPS) are susceptible to various anomalies during their operations. Thus, it is important to detect such anomalies. Detecting such anomalies is challenging since it is uncertain when and where anomalies can happen. To this end, we present a novel approach called Anomaly deTection with digiTAl twIN (ATTAIN), which continuously and automatically builds a digital twin with live data obtained from a CPS for anomaly detection. ATTAIN builds a Timed Automaton Machine (TAM) as the digital representation of the CPS, and implements a Generative Adversarial Network (GAN) to detect anomalies. GAN uses a GCN-LSTM-based module as a generator, which can capture temporal and spatial characteristics of the input data and learn to produce realistic unlabeled adversarial samples. TAM labels these adversarial samples, which are then fed into a discriminator along with real labeled\u00a0\u2026", "num_citations": "6\n", "authors": ["558"]}
{"title": "Search-Based Test Case Implantation for Testing Untested Configurations\n", "abstract": " ContextModern large-scale software systems are highly configurable, and thus require a large number of test cases to be implemented and revised for testing a variety of system configurations. This makes testing highly configurable systems very expensive and time-consuming.ObjectiveDriven by our industrial collaboration with a video conferencing company, we aim to automatically analyze and implant existing test cases (i.e., an original test suite) to test the untested configurations.MethodWe propose a search-based test case implantation approach (named as SBI) consisting of two key components: 1) Test case analyzer that statically analyzes each test case in the original test suite to obtain the program dependence graph for test case statements and 2) Test case implanter that uses multi-objective search to select suitable test cases for implantation using three operators, i.e., selection, crossover, and mutation (at\u00a0\u2026", "num_citations": "6\n", "authors": ["558"]}
{"title": "A Practical Use Case Modeling Approach to Specify Crosscutting Concerns\n", "abstract": " Use case diagrams together with use case specifications are commonly used to specify system requirements. To reduce imprecision, ambiguity, and incompleteness in use case specifications, an approach with template and restriction rules is often recommended to achieve better understandability of use cases and improves the quality of derived analysis models. However, when crosscutting concerns are modeled together with non-crosscutting concerns as use case models, resulting use case models often result in cluttered diagrams and redundant information in use case specifications. Therefore, the overall reusability of the use case models is usually low. To tackle this, we extend a general use case approach, named as RUCM, for modeling crosscutting concerns, along with a weaver to automatically weave aspect use case models into their corresponding base model to facilitate, e.g., automated\u00a0\u2026", "num_citations": "6\n", "authors": ["558"]}
{"title": "A Heuristic-Based Approach to Refactor Crosscutting Behaviors in UML State Machines.\n", "abstract": " UML state machines are commonly used to model the state-based behavior of communication and control systems to support various activities such as test cases and code generation. Standard UML state machines are well suited to model functional behavior, however extra-functional behavior such as robustness and security can also be directly modeled on them, but this often results in cluttered models since extra-functional behaviors are often crosscutting. Such modeling crosscutting behavior directly on UML state machines is a common practice. Aspect-Oriented Modeling (AOM) allows systematically modeling of crosscutting behavior and has shown to provide a scalable solution in the recent years. However, due to lack of familiarity of AOM in both academic and industry, extra-functional behavior is often modeled directly on UML state machines and as a result those UML state machines are difficult to read and\u00a0\u2026", "num_citations": "6\n", "authors": ["558"]}
{"title": "Evaluating Normalization Functions with Search Algorithms for Solving OCL Constraints\n", "abstract": " The use of search algorithms requires the definition of a fitness function that guides the algorithms to find an optimal solution. The definition of a fitness function may require the use of a normalization function for various purposes such as assigning equal importance to various factors constituting a fitness function and normalizing only one factor of a fitness function to give it less/more importance than the others. In our previous work, we defined various branch distance functions (a commonly used heuristic in the literature at the code-level) corresponding to the constructs defined in the Object Constraint Language (OCL) to solve OCL constraints to generate test data for supporting automated Model-Based Testing (MBT). The definition of several of these distance functions required the use of a normalization function. In this paper, we extend the empirical evaluation reported in one of the works in the literature\u00a0\u2026", "num_citations": "6\n", "authors": ["558"]}
{"title": "A framework for measuring quality of models: experiences from a series of controlled experiments\n", "abstract": " Controlled experiments in model-based software engineering, especially those involving human subjects performing modeling tasks, often require comparing models produced by experiment subjects with reference models, which are considered to be correct and complete. The purpose of such comparison is to assess the quality of models produced by experiment subjects so that experiment hypotheses can be accepted or rejected. The quality of models is typically measured quantitatively based on metrics. Manually defining such metrics for large modeling languages is often cumbersome and error-prone. It can also result in metrics that do not systematically consider relevant details and in turn may produce biased results.In this paper, we present a generic quality measurement framework to automatically generate quality metrics for MOF-based metamodels (M2 level)(eg, the UML metamodel), which in turn can be used to measure quality of models (M1 level)(instances of the MOF-based metamodels). A conceptual model is provided to formally describe the main concepts and their relationships of the framework. The definition of the framework is formally specified and the transformation algorithm is also presented, which are therefore implemented as a prototype tool. We applied our tool to automatically obtain quality metrics for UML state machine diagrams and successfully applied them in a controlled experiment. The automatically generated metrics for UML class and sequence diagrams were compared with two sets of manually constructed metrics for UML class and sequence diagrams applied in two controlled experiments. Results show\u00a0\u2026", "num_citations": "6\n", "authors": ["558"]}
{"title": "How does the UML Testing Profile Support Risk-Based Testing\n", "abstract": " The increasing complexity of software-intensive systems raises a lot of challenges demanding new techniques for ensuring their overall quality. The risk of not meeting the expected level of quality has negative impact on business, customers, environment and people, especially in the context of safety/security-critical systems. The importance of risk assessment, analysis and management has been well understood both in the literature and practice, which has led to the definition of a number of well-known standards. In the recent years, Risk-Based Testing (RBT) is gaining more attention, especially focusing on test prioritization and selection based on risks. On the other hand, model-based testing (MBT) provides a systematic and automated way to facilitate rigorous testing of software-intensive systems. MBT has been an intense area of research and a large number of MBT techniques have been developed in\u00a0\u2026", "num_citations": "6\n", "authors": ["558"]}
{"title": "Modeling Quantum programs: challenges, initial results, and research directions\n", "abstract": " Quantum programming languages provide necessary constructs to program quantum computers. To write such programs, one needs to understand the characteristics of quantum computers such as superposition and entanglement, which are novel as compared to programming with classical computers. Understanding these characteristics requires an understanding of quantum physics. Thus, there is a need to build high-level modeling abstractions of quantum programs for software engineers who are used to program on classical computers to understand and model quantum programs at a high-level of abstraction and independent of quantum platforms. To this end, we present some ideas for developing such quantum software modeling languages, by presenting a conceptual model of quantum programs and an example of modeling the state-based behavior of quantum entanglement program. Moreover, we\u00a0\u2026", "num_citations": "5\n", "authors": ["558"]}
{"title": "Stability analysis for safety of automotive multi-product lines: a search-based approach\n", "abstract": " Safety assurance for automotive products is crucial and challenging. It becomes even more difficult when the variability in automotive products is considered. Recently, the notion of automotive multi-product lines (multi-PL) is proposed as a unified framework to accommodate different sources of variability in automotive products. In the context of automotive multi-PL, we propose a stability analysis for safety, motivated by our industrial collaboration, where we observed that under certain operation scenarios, safety varies drastically with small fluctuations in production parameters, environmental conditions, or driving inputs. To characterize instability, we formulate a multi-objective optimization problem, and solve it with a search-based approach. The proposed technique is applied to an industrial automotive multi-PL, and experimental results show its effectiveness to spot instability. Moreover, based on information\u00a0\u2026", "num_citations": "5\n", "authors": ["558"]}
{"title": "Using multi-objective search and machine learning to infer rules constraining product configurations\n", "abstract": " Modern systems are being developed by integrating multiple products within/across product lines that communicate with each other through information networks. Runtime behaviors of such systems are related to product configurations and information networks. Cost-effectively supporting Product Line Engineering (PLE) of such systems is challenging mainly because of lacking the support of automation of the configuration process. Capturing rules is the key for automating the configuration process in PLE. However, there does not exist explicitly-specified rules constraining configurable parameter values of such products and product lines. Manually specifying such rules is tedious and time-consuming. To address this challenge, in this paper, we present an improved version (named as SBRM+) of our previously proposed Search-based Rule Mining (SBRM) approach. SBRM+ incorporates two machine learning algorithms (i\u00a0\u2026", "num_citations": "5\n", "authors": ["558"]}
{"title": "Empowering Testing Activities with Modeling\n", "abstract": " 1Simula Research Laboratory, Oslo, Norway 2The University of Oslo, Oslo, Norway 3Cisco Systems, Oslo, Norway {shaukat, shuai, tao}@ simula. no, marliaae@ cisco. com", "num_citations": "5\n", "authors": ["558"]}
{"title": "Towards a framework for the analysis of multi-product lines in the automotive domain\n", "abstract": " Safety analyses in the automotive domain (in particular automated driving) present unprecedented challenges due to its complexity and tight integration with the physical environment. Given the diversity in the types of cars, potentially unlimited number of possible environmental and driving conditions, it is crucial to devise a systematic way of managing variability in hazards, driving and environmental conditions in individual cars, families of cars, and families of families of cars to facilitate analyses efficiently. To this end, we present our ongoing work in a research project that focuses on devising a model-based reasoning framework for systematically managing hazards in the automotive domain and supporting safety analyses (eg, falsification).", "num_citations": "4\n", "authors": ["558"]}
{"title": "Uncovering Unknown System Behaviors in Uncertain Networks with Model and Search-Based Testing\n", "abstract": " Modern software systems rely on information networks for communication. Such information networks are inherently unpredictable and unreliable. Consequently, software systems behave in an unstipulated manner in uncertain network conditions. Discovering unknown behaviors of these software systems in uncertain network conditions is essential to ensure their correct behaviors. Such discovery requires the development of systematic and automated methods. We propose an online and iterative model-based testing approach to evolve test models with search algorithms. Our ultimate aim is to discover unknown expected behaviors that can only be observed in uncertain network conditions. Also, we have implemented an adaptive search-based test case generation strategy to generate test cases that are executed on the system under test. We evaluated our approach with an open source video conference\u00a0\u2026", "num_citations": "4\n", "authors": ["558"]}
{"title": "Specifying uncertainty in use case models in industrial settings\n", "abstract": " Latent uncertainty in the context of software-intensive systems (eg, Cyber-Physical Systems (CPSs)) demands explicit attention right from the start of development. Use case modeling\u2014a commonly used method for specifying requirements in practice, should also be extended for explicitly specifying uncertainty. To this end, we extend the Restricted Use Case Modeling (RUCM) methodology and its supporting tool to specify uncertainty as part of system requirements. Such uncertainties include those caused by insufficient domain expertise of stakeholders, disagreements among them, and known uncertainties pertaining to assumptions about the environment of the system. The extended RUCM, called URUCM, inherits the features of RUCM, such as automated analyses and generation of models, to mention but a few. Consequently, U-RUCM provides all the key benefits offered by RUCM (ie, reducing ambiguities in requirements), but in addition, it allows specification of uncertainties with the possibilities of reasoning and refining existing ones and even uncovering unknown ones.We evaluated U-RUCM in the context of the U-Test project [1], with two industrial CPS case studies. Evaluation results showed that, with U-RUCM, we were able to get a significantly better and more precise characterization of the uncertainties involved compared to RUCM. This suggests that U-RUCM is an effective tool for dealing with uncertainty in requirements engineering. We present our experience, lessons learned, and future challenges based on the two industrial case studies.", "num_citations": "4\n", "authors": ["558"]}
{"title": "Do Quality Indicators Prefer Particular Multi-objective Search Algorithms in Search-Based Software Engineering?\n", "abstract": " In Search-Based Software Engineering (SBSE), users typically select a set of Multi-Objective Search Algorithms (MOSAs) for their experiments without any justification, or they simply choose an MOSA because of its popularity (e.g., NSGA-II). On the other hand, users know certain characteristics of solutions they are interested in. Such characteristics are typically measured with Quality Indicators (QIs) that are commonly used to evaluate the quality of solutions produced by an MOSA. Consequently, these QIs are often employed to empirically evaluate a set of MOSAs for a particular search problem to find the best MOSA. Thus, to guide SBSE users in choosing an MOSA that represents the solutions measured by a specific QI they are interested in, we present an empirical evaluation with a set of SBSE problems to study the relationships among commonly used QIs and MOSAs in SBSE. Our aim, by studying\u00a0\u2026", "num_citations": "3\n", "authors": ["558"]}
{"title": "A multi-objective and cost-aware optimization of requirements assignment for review\n", "abstract": " A typical way to improve the quality of requirements is to assign them to suitable stakeholders for reviewing. Due to different characteristics of requirements and diverse background of stakeholders, it is needed to find an optimal solution for requirements assignment. Existing search-based requirements assignment solutions focus on maximizing stakeholders' familiarities to assigned requirements and balancing the overall workload of each stakeholder. However, a cost-effective requirements assignment solution should also take into account another two optimization objectives: 1) minimizing required time for reviewing requirements, and 2) minimizing the monetary cost required for performing reviewing tasks. We formulated the requirements assignment problem as a search problem and defined a fitness function considering all the five optimization objectives. We conducted an empirical evaluation to assess the\u00a0\u2026", "num_citations": "3\n", "authors": ["558"]}
{"title": "Exploring Model-Based Repositories for a Broad Range of Industrial Applications and Challenges\n", "abstract": " Nowadays, systems are becoming increasingly complex and large and the process of developing such large-scale systems is becoming complicated with high cost and enormous effort required. Such a complicated process has a prominent challenge to ensure the quality of delivered artifacts. Therefore there is clearly a need to facilitate reuse of developed artifacts (e.g., requirements, architecture, tests) and enable automated analyses such as risk analyses, prioritizing test cases, change impact analysis, with the objective to reduce cost, effort and improve quality. Model-based engineering provides a promising mechanism to facilitate reuse and enable automation. The key idea is to use models as the backbone of structuring repositories that contain reusable artifacts (e.g., test cases, requirements). Such a backbone model is subse-quently used to enable various types of automation such as model-based testing\u00a0\u2026", "num_citations": "3\n", "authors": ["558"]}
{"title": "A MOF-Based Framework for Defining Metrics to Measure the Quality of Models\n", "abstract": " Controlled experiments in model-based software engineering, especially those involving human subjects performing modeling tasks, often require comparing models produced by experiment subjects with reference models, which are considered to be correct and complete. The purpose of such comparison is to assess the quality of models produced by experiment subjects so that experiment hypotheses can be accepted or rejected. The quality of models is typically measured quantitatively based on metrics. Manually defining such metrics for a rich modeling language is often cumbersome and error-prone. It can also result in metrics that do not systematically consider relevant details and in turn may produce biased results. In this paper, we present a framework to automatically generate quality metrics for MOF-based metamodels, which in turn can be used to measure the quality of models (instances of the\u00a0\u2026", "num_citations": "3\n", "authors": ["558"]}
{"title": "Experience report: Assessing the reliability of an industrial avionics software: Results, insights and recommendations\n", "abstract": " Real Time Operating System for Avionics (RTOS4A) is responsible for providing an operating environment for avionics application software. Avionics software being safety-critical in nature poses several safety and reliability requirements on RTOS4A in addition to the requirements imposed by standards, for instance, DO-178B. Due to this reason, reliability assessment of RTOS4A is very critical to demonstrate confidence about its reliability to its relevant stakeholders. One common way of assessing reliability is by systematic analyses of testing data such as number of tests, number of failures, and coverage using appropriate statistical tests. In this paper, we report our experience of assessing the reliability of an industrial RTOS4A based on testing data collected for 17 months on eight continuous releases. We studied correlation among various measures including: Testing Effort Measures (e.g., complexity of test cases\u00a0\u2026", "num_citations": "3\n", "authors": ["558"]}
{"title": "Modeling Approach Comparison Criteria for the CMA Workshop at MODELS 2012\n", "abstract": " The comparison criteria described in this document represent a work-in-progress, begun at the Bellairs AOM1 workshop in April 2011, continued at the first CMA2 workshop in October 2011, and further discussed at the Bellairs AOM3 workshop in April/May 2012 as well as the second CMA4 workshop in September 2012 and the third CMA5 workshop in July 2013. The purpose of the criteria is to provide a basis for understanding, analyzing, and comparing various modeling approaches. The focus of this document is hence on modeling approaches and not on models. The term modeling approach may refer to one or more modeling techniques, languages, or notations that are used to model software and, if available, the methodology or methodologies that describe how those modeling techniques, languages, or notations are used.Two groups of criteria are presented: Criteria related to general modeling dimensions (see Section 1) and those related to key modeling concepts (see Section 2). The modeling dimensions criteria characterize a modeling approach by (i) the development phases and activities for which it is most applicable and (ii) the languages or notations used. The key modeling concepts criteria are used to classify a modeling approach in terms of the modeling building blocks, attributes, or qualities targeted for optimization or improvement by the approach.", "num_citations": "3\n", "authors": ["558"]}
{"title": "Understanding digital twins for cyber-physical systems: a conceptual model\n", "abstract": " Digital Twins (DTs) are revolutionizing Cyber-Physical Systems (CPSs) in many ways, including their development and operation. The significant interest of industry and academia in DTs has led to various definitions of DTs and related concepts, as seen in many recently published papers. Thus, there is a need for precisely defining different DT concepts and their relationships. To this end, we present a conceptual model that captures various DT concepts and their relationships, some of which are from the published literature, to provide a unified understanding of these concepts in the context of CPSs. The conceptual model is implemented as a set of Unified Modeling Language (UML) class diagrams and the concepts in the conceptual model are explained with a running example of an automated warehouse case study from published literature and based on the authors\u2019 experience of working with the real\u00a0\u2026", "num_citations": "2\n", "authors": ["558"]}
{"title": "RCIA: Automated Change Impact Analysis to Facilitate a Practical Cancer Registry System\n", "abstract": " The Cancer Registry of Norway (CRN) employs a cancer registry system to collect cancer patient data (e.g., diagnosis and treatments) from various medical entities (e.g., clinic hospitals). The collected data are then checked for validity (i.e., validation) and assembled as cancer cases (i.e., aggregation) based on more than 1000 cancer coding rules in the system. However, it is frequent in practice that the collected cancer data changes due to various reasons (e.g., different treatments) and the cancer coding rules can also change/evolve due to new medical knowledge. Thus, such a cancer registry system requires an efficient means to automatically analyze these changes and provide consequent impacts to medical experts for further actions. This paper proposes an automated Rule-based Change Impact Analysis (CIA) approach named RCIA that includes: 1) a change classification to capture the potential changes\u00a0\u2026", "num_citations": "2\n", "authors": ["558"]}
{"title": "Generating boundary values from OCL constraints using constraints rewriting and search algorithms\n", "abstract": " A key component of model-based testing is the generation of test data from constraints (e.g., specified in the Object Constraint Language (OCL)) associated with models e.g., specified in the Unified Modeling Language (UML). The quality of test data eventually determines the effectiveness of test cases, e.g., fault detection and coverage. A simple way to generate test data from an OCL constraint is to find a set of values for all the variables that satisfies the constraint. One way of improving the quality of test data is by generating test data at the boundaries of each variable in the constraint. In this paper, we extend our search-based test data generation approach to generate test data at the boundaries of each variable involved in a constraint. We present different cases of constraints involving different types of variables and how we rewrite them in order to automatically generate boundary values using our existing OCL\u00a0\u2026", "num_citations": "2\n", "authors": ["558"]}
{"title": "Modeling Approach Comparison Criteria for the CMA@ RE Workshop at RE 2013\n", "abstract": " The comparison criteria described in this document represent a work-in-progress, begun at the Bellairs AOM1 workshop in April 2011, continued at the first CMA2 workshop in October 2011, and further discussed at the Bellairs AOM3 workshop in April/May 2012 as well as the second CMA4 workshop. The purpose of the criteria is to provide a basis for understanding, analyzing, and comparing various modeling approaches. The focus of this document is hence on modeling approaches and not on models. The term modeling approach may refer to one or more modeling techniques, languages, or notations that are used to model software and, if available, the methodology or methodologies that describe how those modeling techniques, languages, or notations are used. Two groups of criteria are presented: Criteria related to general modeling dimensions (see Section 1) and those related to key modeling concepts (see Section 2). The modeling dimensions criteria characterize a modeling approach by (i) the development phases and activities for which it is most applicable and (ii) the languages or notations used. The key modeling concepts criteria are used to classify a modeling approach in terms of the modeling building blocks, attributes, or qualities targeted for optimization or improvement by the approach.These criteria are intended to play a particularly important role in situating existing approaches in the current body of work, and in identifying the considerations that must be made when developing new modeling approaches. In order to fulfil their role, it is important that the criteria be defined in terms that are widely and precisely understood by\u00a0\u2026", "num_citations": "2\n", "authors": ["558"]}
{"title": "Modeling Crisis Management System With the Restricted Use Case Modeling Approach.\n", "abstract": " Use case modeling is commonly applied to document requirements. Use case specifications (UCSs) are usually structured, unrestricted textual documents complying with a certain template. However, because they remain essentially textual, ambiguities are inevitable. In our previous work, we proposed a new use case modeling approach, named as Restricted Use Case Modeling (RUCM), which is composed of a set of well-defined restriction rules and a new template. The goal was to reduce ambiguity and facilitate automated analysis. In our works, RUCM has been systematically and empirically evaluated through case studies to be easy to apply and leads to higher quality of UML analysis models. In this paper, we modeled the Crisis Management System (CMS) case study using RUCM and our experience proved that RUCM is easy to apply and sufficient to capture the requirements provided for the case study.", "num_citations": "2\n", "authors": ["558"]}
{"title": "Scalable Model-based Robustness Testing: Novel Methodologies and Industrial Application\n", "abstract": " Embedded systems, as for example communication and control systems, are being increasingly used in our daily lives and hence require thorough and systematic testing before their actual use. Many of these systems interact with their environment and, therefore, their functionality is largely dependent on this environment whose behavior can be unpredictable. Robustness testing aims at testing the behavior of a system in the presence of faulty situations in its operating environment (e.g., sensors and actuators). In such situations, the system should gracefully degrade its performance instead of abruptly stopping execution. To systematically perform robustness testing, one option is to resort to Model-Based Robustness Testing (MBRT), which is a systematic, rigorous, and automated way of conducting robustness testing. However, to successfully apply MBRT in industrial contexts, new technologies need to be developed to scale to the complexity of real industrial systems. This thesis presents a solution for MBRT on industrial systems, including scalable robustness modeling and executable test case generation.  One important contribution of this thesis is a scalable RobUstness Modeling Methodology (RUMM), which is achieved using Aspect-Oriented Modeling (AOM). It is a complete, automated, and practical methodology that covers all features of state machines and aspect concepts necessary for MBRT. Such methodology, relying on a standard (Unified Modeling Language or UML) and using the target notation as the basis to model the aspects themselves, is expected to make the practical adoption of robustness modeling easier in industrial\u00a0\u2026", "num_citations": "2\n", "authors": ["558"]}
{"title": "A Pilot Experiment to Assess Interactive OCL Specification in a Real Setting\n", "abstract": " The Object Constraint Language (OCL) is a formal, declarative, and side-effect free language, standardized by the Object Management Group, for specifying constraints or queries on models specified in the Unified Modeling Language (UML). OCL was designed with the aim to bridge the gap between natural language and traditional formal languages requiring a strong mathematical background to understand and apply. OCL, along with UML, have been applied in practice for various purposes such as facilitating automated model-based testing. In most of such contexts of OCL, engineers with software engineering backgrounds specify OCL constraints. However, it is still a challenge for constraint authors (eg, medical coders) who have no such background to apply OCL for other purposes (eg, specifying medical rules). In this direction, in our previous work, we proposed a user-interactive specification framework, named iOCL, for facilitating OCL constraint specification and validation. The aim was to ease its adoption in practice in a wider application scope. In this paper, we present a pilot experiment that was conducted to assess the practical applicability of iOCL in the Cancer Registry of Norway with real users of iOCL in terms of specifying medical cancer coding rules with iOCL. Results of the pilot experiment showed that, with iOCL, time to specify OCL constraints can be significantly reduced as compared to specifying OCL constraints directly without the tool support. In addition, participants of the experiment found iOCL easy to use.", "num_citations": "2\n", "authors": ["558"]}
{"title": "A Practical Use Case Modeling Approach to Specify Crosscutting Concerns: Industrial Applications\n", "abstract": " Use case diagrams together with use case specifications are commonly used to specify system requirements. To reduce imprecision, ambiguity, and incompleteness in use case specifications, an approach with template and restriction rules is often recommended to achieve better understandability of use cases and improves the quality of derived analysis models. However, when crosscutting concerns are modeled together with non-crosscutting concerns as use case models, resulting use case models often result in cluttered diagrams and redundant information in use case specifications. Therefore, the overall reusability of the use case models is usually low. To cope with these, we extend a general use case approach, named as RUCM, for modeling crosscutting concerns, along with a weaver to automatically weave aspect use case models into their corresponding base model to facilitate, eg, automated requirements analysis. The extended RUCM approach has been evaluated with three industrial applications from communication, maritime and energy domains and aviation. We also compared the modeling effort required to model three sets of crosscutting concerns from the industrial applications, when using and not using the extended RUCM approach. Results show that more than 80% of modeling effort can be saved.", "num_citations": "2\n", "authors": ["558"]}
{"title": "Prediction Surface Uncertainty Quantification in Object Detection Models for Autonomous Driving\n", "abstract": " Object detection in autonomous cars is commonly based on camera images and Lidar inputs, which are often used to train prediction models such as deep artificial neural networks for decision making for object recognition, adjusting speed, etc. A mistake in such decision making can be damaging; thus, it is vital to measure the reliability of decisions made by such prediction models via uncertainty measurement. Uncertainty, in deep learning models, is often measured for classification problems. However, deep learning models in autonomous driving are often multi-output regression models. Hence, we propose a novel method called PURE (Prediction sURface uncErtainty) for measuring prediction uncertainty of such regression models. We formulate the object recognition problem as a regression model with more than one outputs for finding object locations in a 2-dimensional camera view. For evaluation, we\u00a0\u2026", "num_citations": "1\n", "authors": ["558"]}
{"title": "Testing self-healing cyber-physical systems under uncertainty with reinforcement learning: an empirical study\n", "abstract": " Self-healing is becoming an essential feature of Cyber-Physical Systems (CPSs). CPSs with this feature are named Self-Healing CPSs (SH-CPSs). SH-CPSs detect and recover from errors caused by hardware or software faults at runtime and handle uncertainties arising from their interactions with environments. Therefore, it is critical to test if SH-CPSs can still behave as expected under uncertainties. By testing an SH-CPS in various conditions and learning from testing results, reinforcement learning algorithms can gradually optimize their testing policies and apply the policies to detect failures, ie, cases that the SH-CPS fails to behave as expected. However, there is insufficient evidence to know which reinforcement learning algorithms perform the best in terms of testing SH-CPSs behaviors including their self-healing behaviors under uncertainties. To this end, we conducted an empirical study to evaluate the\u00a0\u2026", "num_citations": "1\n", "authors": ["558"]}
{"title": "Uncertainty-wise Requirements Prioritization with Search\n", "abstract": " Requirements review is an effective technique to ensure the quality of requirements in practice, especially in safety-critical domains (e.g., avionics systems, automotive systems). In such contexts, a typical requirements review process often prioritizes requirements, due to limited time and monetary budget, by, for instance, prioritizing requirements with higher implementation cost earlier in the review process. However, such a requirement implementation cost is typically estimated by stakeholders who often lack knowledge about (future) requirements implementation scenarios, which leads to uncertainty in cost overrun. In this article, we explicitly consider such uncertainty (quantified as cost overrun probability) when prioritizing requirements based on the assumption that a requirement with higher importance, a higher number of dependencies to other requirements, and higher implementation cost will be reviewed with\u00a0\u2026", "num_citations": "1\n", "authors": ["558"]}
{"title": "Search-based test optimization for software systems\n", "abstract": " Search-based test optimization for software systems | Proceedings of the Genetic and Evolutionary Computation Conference Companion ACM Digital Library Logo ACM Logo Google, Inc. (search) Advanced Search Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced Search gecco Conference Proceedings Upcoming Events Authors Affiliations Award Winners More HomeConferencesGECCOProceedingsGECCO '18Search-based test optimization for software systems research-article Search-based test optimization for software systems Share on Author: Shaukat Ali Simula Research Laboratory, Kyoto, Japan Simula Research Laboratory, Kyoto, Japan Search about this author Authors Info & Affiliations Publication: GECCO '18: Proceedings of the Genetic and Evolutionary Computation \u2026", "num_citations": "1\n", "authors": ["558"]}
{"title": "Assessing the Modeling of Aspect State Machines for Testing from the Perspective of Modelers\n", "abstract": " Aspect state machines (ASMs) are extended UML state machines that use stereotypes from a UML profile called AspectSM. In our previous experiments, we empirically evaluated ASMs from the perspectives of readability, comprehensibility, understand ability, modeling errors, and modeling effort and the results showed that ASMs are significantly better than the standard UML state machines for modeling robustness behavior for testing. However, a fundamental question still remained to be answered about how modelers/testers modeling ASMs feel about their use. With this in mind, we report results from a series of controlled experiments that were conducted to evaluate subjective opinions of modelers/testers from various perspectives using several questionnaires. The results of the experiment showed that the participants found it difficult to apply AspectSM and weren't confident about their solutions. We further\u00a0\u2026", "num_citations": "1\n", "authors": ["558"]}
{"title": "Automated Product Line Methodologies to Support Model-Based Testing.\n", "abstract": " Testing products in a cost-efficient way remains an attractive topic for Model-Based Testing (MBT) of product lines in both academia and industry, which can be addressed by employing systematic and automated approaches based on models (such as feature models and UML models). Cost-effective testing products can be divided into three main problems, ie, test selection, test generation, and test minimization. Driven by the needs of our industrial problems for testing Video Conferencing Systems (VCSs) product line developed by Cisco, Norway, this paper presents Product Line Model-based Testing Methodologies (PL-MTM) to tackle the above-mentioned three problems for costeffective testing a product in product line, which includes: 1) an systematic and automated test selection methodology; 2) an automated test minimization approach; and 3) an automated and systematic test generation methodology.", "num_citations": "1\n", "authors": ["558"]}
{"title": "Modeling bCMS Product Line Using Feature Model, Component Family Model and UML.\n", "abstract": " In the context of Model-Based Engineering (MBE) of product lines, effort required to develop models can be significantly reduced by applying systematic product line modeling and configuration methodologies. Our previous work presented models of bCMS developed using AspectSM, a UML profile for Aspect-Oriented Modeling (AOM), which was defined to model crosscutting behaviors using extended UML state machines, with the objectives of minimizing modeling effort and the learning curve for modeling crosscutting behavior. However, such approach still requires users to be familiar with specific expertise and concepts on various UML behavior models. In this paper, we extend our previous work using Feature Model (FM) and Component Family Model (CFM) to model bCMS product line. More specifically, a FM is designed and developed to capture all variations points for bCMS product line and a CFM is built to provide an abstraction layer on top of the configurable state machines. With our current methodology, a user doesn\u2019t need to acquire expertise on behavioral modeling and can simply configure models for a product by selecting features in FM and configuring provided attributes in CFM.", "num_citations": "1\n", "authors": ["558"]}
{"title": "Comprehensively evaluating conformance error rates of applying aspect state machines\n", "abstract": " Aspect Oriented Modeling (AOM) aims to provide enhanced separation of concerns during the design phase and proclaims many benefits (eg, easier model evolution, reduced modeling effort, and reduced modeling errors) over traditional modeling paradigms such as object-oriented modeling. However, empirical evaluations of these benefits is severely lacking in the AOM community. In this paper, we empirically evaluate one of the AOM profiles: AspectSM, via a controlled experiment to assess if it can help in reducing modeling errors (referred as conformance errors in this paper), which is one of the benefits offered by AOM. AspectSM is a UML profile, which is developed to support automated state-based robustness testing. With AspectSM, crosscutting behaviors are modeled as aspect state machines using the stereotypes defined in AspectSM. We evaluate the conformance error rates of applying AspectSM from\u00a0\u2026", "num_citations": "1\n", "authors": ["558"]}
{"title": "Modeling bCMS using AspectSM\n", "abstract": " In this document, we present models of bCMS developed using AspectSM, a UML profile for Aspect-Oriented Modeling (AOM), which was defined to model crosscutting behaviors using extended UML state machines, with the objectives of minimizing modeling effort and the learning curve for modeling crosscutting behavior. The AspectSM profile focuses on UML state machines as they are extensively used in practice, for example in model-based test case generation in the context of control and communication systems. AspectSM has been successfully applied to model robustness behavior of video conferencing systems for the purpose of model-based robustness testing at Cisco Systems Inc., Norway.", "num_citations": "1\n", "authors": ["558"]}
{"title": "A Practical and Scalable Use Case Modeling Approach to Specify Crosscutting Concerns: Industrial Applications\n", "abstract": " Use case diagrams are commonly used to capture system requirements. Using template and restriction rules is a common feature of natural language analysis for reducing imprecision and incompleteness in use case specifications. Use case diagrams, together with template and restriction rules, form a use case modeling approach, which helps achieve better understandability of use cases and improved quality of derived analysis models. However, when crosscutting concerns are modeled together with use cases, it will contain redundant information and hence reduce the readability and maintenance of use case models. To cope with this, we extend a general use case approach (RUCM) for modeling crosscutting concerns, along with a weaver to automatically weave aspect use case models into their corresponding base use case models. The usability and applicability of the extended RUCM approach are evaluated by applying them to two industrial applications from communication and maritime and energy domains. We also compared the modeling effort required to model two sets of crosscutting concerns from two industrial applications, when using and not using the extended RUCM approach. Results show that more than 80% of modeling effort can be saved.", "num_citations": "1\n", "authors": ["558"]}
{"title": "AutoAbstract: Problem statement and hypothetical solutions\n", "abstract": " Automated abstraction of code into state-based specification and test generation (AutoAbstract) is a project funded by EPSRC. The aim of the project is to devise methods and a tool to abstract out specifications from the code using some hints from the developer. These specifications will be in the form of X-machines. It is assumed that these hints are available in the form of incomplete specifications and are refined using reverse-engineered X-machines. Finally, a method will be developed to generate concrete test cases from the refined X-machines and the tool will be updated accordingly. The main theme of my PhD lies within the AutoAbstract project. This PhD extended abstract will contain the technical challenges involved in the project followed by the parts of the work involved in the project that are linked to my interests. The proposed solutions to these parts will also be discussed", "num_citations": "1\n", "authors": ["558"]}
{"title": "Technical Report 2010-01: Model Transformations as a Strategy to Automate Model-Based Testing\u2013A Tool and Industrial Case Studies, Version 1.0\n", "abstract": " In recent years, Model-Based Testing (MBT) has attracted an increasingly wide interest from industry and academia. The beneficial use of MBT, however, requires tools that not only automate the testing process, but that also rely in an extensible and configurable architecture that make them adaptable to various contexts of application. Though a number of tools have been developed to support MBT, this technical report introduces a new approach for designing and developing MBT tools that is based on model transformation technology. We report on the experimental development of a novel MBT tool, TRansformation-based tool for Uml-baSed Testing (TRUST), which software architecture and implementation strategy supports configurable and extensible features such as input models, test models, coverage criteria, test data generation strategies, and test script languages. Based on two industrial case studies, we demonstrate the configurability and extensibility of TRUST. We also investigate the challenges and likely cost savings when compared to manual test generation.", "num_citations": "1\n", "authors": ["558"]}