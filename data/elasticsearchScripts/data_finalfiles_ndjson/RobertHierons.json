{"title": "Search algorithms for regression test case prioritization\n", "abstract": " Regression testing is an expensive, but important, process. Unfortunately, there may be insufficient resources to allow for the reexecution of all test cases during regression testing. In this situation, test case prioritization techniques aim to improve the effectiveness of regression testing by ordering the test cases so that the most beneficial are executed first. Previous work on regression test case prioritization has focused on greedy algorithms. However, it is known that these algorithms may produce suboptimal results because they may construct results that denote only local minima within the search space. By contrast, metaheuristic and evolutionary search algorithms aim to avoid such problems. This paper presents results from an empirical study of the application of several greedy, metaheuristic, and evolutionary search algorithms to six programs, ranging from 374 to 11,148 lines of code for three choices of fitness\u00a0\u2026", "num_citations": "869\n", "authors": ["543"]}
{"title": "An overview of program slicing\n", "abstract": " MARK HARMAN and ROBERT HIERONS review three semantic paradigms for slicing \u2014 static, dynamic and conditioned; and two syntactic paradigms \u2014 syntax\u2010preserving and amorphous. Slicing has been applied to many software development problems including testing, reuse, maintenance and evolution. This paper describes the main forms of program slice and some of the applications to which slicing has been put. Copyright \u00a9 2001 John Wiley & Sons, Ltd.", "num_citations": "222\n", "authors": ["543"]}
{"title": "A multiple hill climbing approach to software module clustering\n", "abstract": " Automated software module clustering is important for maintenance of legacy systems written in a 'monolithic format' with inadequate module boundaries. Even where systems were originally designed with suitable module boundaries, structure tends to degrade as the system evolves, making re-modularization worthwhile. This paper focuses upon search-based approaches to the automated module clustering problem, where hitherto, the local search approach of hill climbing has been found to be most successful. In the paper we show that results from a set of multiple hill climbs can be combined to locate good 'building blocks' for subsequent searches. Building blocks are formed by identifying the common features in a selection of best hill climbs. This process reduces the search space, while simultaneously 'hard wiring' parts of the solution. The paper reports the results of an empirical study that show that the\u00a0\u2026", "num_citations": "198\n", "authors": ["543"]}
{"title": "Testing from a Z specification\n", "abstract": " This paper looks at the formal analysis of Z specifications in order to enhance the testing process. An algorithm is given that rewrites the specification to a form from which both a partition of the input domain and the states of a finite state automaton model can be derived. Test cases can be derived from the former and an automated system to control the testing process can be based upon the latter. \u00a9\u20091997 by John Wiley & Sons, Ltd.", "num_citations": "180\n", "authors": ["543"]}
{"title": "Generating feasible transition paths for testing from an extended finite state machine (EFSM)\n", "abstract": " The problem of testing from an extended finite state machine (EFSM) can be expressed in terms of finding suitable paths through the EFSM and then deriving test data to follow the paths. A chosen path may be infeasible and so it is desirable to have methods that can direct the search for appropriate paths through the EFSM towards those that are likely to be feasible. However, generating feasible transition paths (FTPs) for model based testing is a challenging task and is an open research problem. This paper introduces a novel fitness metric that analyzes data flow dependence among the actions and conditions of the transitions of a path in order to estimate its feasibility. The proposed fitness metric is evaluated by being used in a genetic algorithm to guide the search for FTPs.", "num_citations": "138\n", "authors": ["543"]}
{"title": "Improving Evolutionary Testing By Flag Removal.\n", "abstract": " This paper argues that Evolutionary testing can be improved by transforming programs with flags into flag free programs. The approach is evaluated by comparing results from the application of the Daimler-Chrysler Evolutionary Testing \u00cbystem to programs with flags and their transformed flagfree counterparts. The results of this empirical study are very encouraging. Programs which could not be fully covered become fully coverable and the number of generations required to achieve full coverage is greatly reduced.", "num_citations": "131\n", "authors": ["543"]}
{"title": "Do moods affect programmers\u2019 debug performance?\n", "abstract": " There is much research that shows people\u2019s mood can affect their activities. This paper argues that this also applies to programmers, especially their debugging. Literature-based framework is presented linking programming with various cognitive activities as well as linking cognitive activities with moods. Further, the effect of mood on debugging was tested in two experiments. In the first experiment, programmers (n\u00a0=\u00a072) saw short movie clips selected for their ability to provoke specific moods. Afterward, they completed a debugging test. Results showed the video clips had a significant effect on programmers\u2019 debugging performance; especially, there was a significant difference after watching low- and high-arousal-evoking video clips. In the second experiment, programmers\u2019 mood was manipulated by asking participants (n\u00a0=\u00a019) to dry run algorithms for at least 16\u00a0min. They performed some physical\u00a0\u2026", "num_citations": "114\n", "authors": ["543"]}
{"title": "Optimizing the length of checking sequences\n", "abstract": " A checking sequence, generated from a finite state machine, is a test sequence that is guaranteed to lead to a failure if the system under test is faulty and has no more states than the specification. The problem of generating a checking sequence for a finite state machine M is simplified if M has a distinguishing sequence: an input sequence D~ with the property that the output sequence produced by M in response to D is different for the different states of M. Previous work has shown that, where a distinguishing sequence is known, an efficient checking sequence can be produced from the elements of a set A of sequences that verify the distinguishing sequence used and the elements of a set /spl gamma/ of subsequences that test the individual transitions by following each transition t by the distinguishing sequence that verifies the final state of t. In this previous work, A is a predefined set and /spl gamma/ is defined in\u00a0\u2026", "num_citations": "108\n", "authors": ["543"]}
{"title": "Reduced length checking sequences\n", "abstract": " Here, the method proposed by Ural, Wu and Zhang (1997) for constructing minimal-length checking sequences based on distinguishing sequences is improved. The improvement is based on optimizations of the state recognition sequences and their use in constructing test segments. It is shown that the proposed improvement further reduces the length of checking sequences produced from minimal, completely specified, and deterministic finite state machines.", "num_citations": "102\n", "authors": ["543"]}
{"title": "Testing from a nondeterministic finite state machine using adaptive state counting\n", "abstract": " The problem of generating a checking experiment from a nondeterministic finite state machine has been represented in terms of state counting. However, test techniques that use state counting traditionally produce preset test suites. We extend the notion of state counting in order to allow the input/output sequences observed in testing to be utilized: Adaptive state counting is introduced. The main benefit of the proposed approach is that it may result in a reduction in the size of the test suite used. An additional benefit is that, where a failure is observed, it is possible to terminate test generation at this point.", "num_citations": "99\n", "authors": ["543"]}
{"title": "An integrated search-based approach for automatic testing from extended finite state machine (EFSM) models\n", "abstract": " ContextThe extended finite state machine (EFSM) is a modelling approach that has been used to represent a wide range of systems. When testing from an EFSM, it is normal to use a test criterion such as transition coverage. Such test criteria are often expressed in terms of transition paths (TPs) through an EFSM. Despite the popularity of EFSMs, testing from an EFSM is difficult for two main reasons: path feasibility and path input sequence generation. The path feasibility problem concerns generating paths that are feasible whereas the path input sequence generation problem is to find an input sequence that can traverse a feasible path.ObjectiveWhile search-based approaches have been used in test automation, there has been relatively little work that uses them when testing from an EFSM. In this paper, we propose an integrated search-based approach to automate testing from an EFSM.MethodThe approach has\u00a0\u2026", "num_citations": "83\n", "authors": ["543"]}
{"title": "Evolving transformation sequences using genetic algorithms\n", "abstract": " Program transformation is useful in a number of applications including program comprehension, reverse engineering and compiler optimization. In all these applications, transformation algorithms are constructed by hand for each different transformation goal. Loosely speaking, a transformation algorithm defines a sequence of transformation steps to apply to a given program. It is notoriously hard to find good transformation sequences automatically, and so much (costly) human intervention is required. This work shows how search-based meta-heuristic algorithms can be used to automate, or partly automate the problem of finding good transformation sequences. In this case, the goal of transformation is to reduce program size, but the approach is sufficiently general that it can be used to optimize any source-code level metric. The search techniques used are random search (RS), hill climbing (HC) and genetic\u00a0\u2026", "num_citations": "79\n", "authors": ["543"]}
{"title": "Mutation testing from probabilistic and stochastic finite state machines\n", "abstract": " Specification mutation involves mutating a specification, and for each mutation a test is derived that distinguishes the behaviours of the mutated and original specifications. This approach has been applied with finite state machine based models. This paper extends mutation testing to finite state machine models that contain non-functional properties. The paper describes several ways of mutating a finite state machine with probabilities (PFSM) or stochastic time (PSFSM) attached to its transitions and shows how we can generate test sequences that distinguish between such a model and its mutants. Testing then involves applying each test sequence multiple times, observing the resultant behaviours and using results from statistical sampling theory in order to compare the observed frequency and execution time of each output sequence with that expected.", "num_citations": "70\n", "authors": ["543"]}
{"title": "Computing unique input/output sequences using genetic algorithms\n", "abstract": " The problem of computing Unique Input/Ouput sequences (UIOs) is NP-hard. Genetic algorithms (GAs) have been proven to be effective in providing good solutions for some NP-hard problems. In this work, we investigated the construction of UIOs using GAs. We defined a fitness function to guide the search of potential UIOs and introduce a DO NOT CARE character to improve the GA\u2019s diversity. Experimental results suggest that, in a small system, the performance of the GA based approaches is no worse than that of random search while, in a more complex system, the GA based approaches outperform random search.", "num_citations": "66\n", "authors": ["543"]}
{"title": "An analysis of the relationship between conditional entropy and failed error propagation in software testing\n", "abstract": " Failed error propagation (FEP) is known to hamper software testing, yet it remains poorly understood. We introduce an information theoretic formulation of FEP that is based on measures of conditional entropy. This formulation considers the situation in which we are interested in the potential for an incorrect program state at statement s to fail to propagate to incorrect output. We define five metrics that differ in two ways: whether we only consider parts of the program that can be reached after executing s and whether we restrict attention to a single program path of interest. We give the results of experiments in which it was found that on average one in 10 tests suffered from FEP, earlier studies having shown that this figure can vary significantly between programs. The experiments also showed that our metrics are well-correlated with FEP. Our empirical study involved 30 programs, for which we executed a total of 7,140\u00a0\u2026", "num_citations": "63\n", "authors": ["543"]}
{"title": "Measuring personality from keyboard and mouse use\n", "abstract": " Motivation\u2013To measure computer users\u2019 personality from their use of keyboard and mouse.Research approach\u2013Two explorative studies were conducted. In first study a background application was executed on 20 participants\u2019 computers to record keys pressed and mouse clicks on an average of eight days. In a second Study 15 participants\u2019 completed a programming task in an hour while a background application recorded keys pressed and mouse clicks. Participants were asked to complete the short form of IPIP-NEO personality inventory afterwards. Pearson correlation analysis was done between participants\u2019 behaviour on keyboard, mouse events and personality ratings.", "num_citations": "62\n", "authors": ["543"]}
{"title": "Semantic mutation testing\n", "abstract": " Mutation testing is a powerful and flexible test technique. Traditional mutation testing makes a small change to the syntax of a description (usually a program) in order to create a mutant. A test suite is considered to be good if it distinguishes between the original description and all of the (functionally non-equivalent) mutants. These mutants can be seen as representing potential small slips and thus mutation testing aims to produce a test suite that is good at finding such slips. It has also been argued that a test suite that finds such small changes is likely to find larger changes. This paper describes a new approach to mutation testing, called semantic mutation testing. Rather than mutate the description, semantic mutation testing mutates the semantics of the language in which the description is written. The mutations of the semantics of the language represent possible misunderstandings of the description language and\u00a0\u2026", "num_citations": "55\n", "authors": ["543"]}
{"title": "Testing a system specified using Statecharts and Z\n", "abstract": " A hybrid specification language \u03bcSZ, in which the dynamic behaviour of a system is described using Statecharts and the data and the data transformations are described using Z, has been developed for the specification of embedded systems. This paper describes an approach to testing from a deterministic sequential specification written in \u03bcSZ. By considering the Z specifications of the operations, the extended finite state machine (EFSM) defined by the Statechart can be rewritten to produce an EFSM that has a number of properties that simplify test generation. Test generation algorithms are introduced and applied to an example. While this paper considers \u03bcSZ specifications, the approaches described might be applied whenever the specification is an EFSM whose states and transitions are specified using a language similar to Z.", "num_citations": "54\n", "authors": ["543"]}
{"title": "Avoiding coincidental correctness in boundary value analysis\n", "abstract": " In partition analysis we divide the input domain to form subdomains on which the system's behaviour should be uniform. Boundary value analysis produces test inputs near each subdomain's boundaries to find failures caused by incorrect implementation of the boundaries. However, boundary value analysis can be adversely affected by coincidental correctness---the system produces the expected output, but for the wrong reason. This article shows how boundary value analysis can be adapted in order to reduce the likelihood of coincidental correctness. The main contribution is to cases of automated test data generation in which we cannot rely on the expertise of a tester.", "num_citations": "53\n", "authors": ["543"]}
{"title": "Estimating the feasibility of transition paths in extended finite state machines\n", "abstract": " There has been significant interest in automating testing on the basis of an extended finite state machine (EFSM) model of the required behaviour of the implementation under test (IUT). Many test criteria require that certain parts of the EFSM are executed. For example, we may want to execute every transition of the EFSM. In order to find a test suite (set of input sequences) that achieves this we might first derive a set of paths through the EFSM that satisfy the criterion using, for example, algorithms from graph theory. We then attempt to produce input sequences that trigger these paths. Unfortunately, however, the EFSM might have infeasible paths and the problem of determining whether a path is feasible is generally undecidable. This paper describes an approach in which a fitness function is used to estimate how easy it is to find an input sequence to trigger a given path through an EFSM. Such a fitness\u00a0\u2026", "num_citations": "52\n", "authors": ["543"]}
{"title": "Implementation relations for the distributed test architecture\n", "abstract": " Some systems interact with their environment at a number of physically distributed interfaces called ports. When testing such a system under test (SUT) it is normal to place a local tester at each port and the local testers form a local test case. If the local testers cannot interact with one another and there is no global clock then we are testing in the distributed test architecture. In this paper we explore the effect of the distributed test architecture when testing an SUT against an input output transition system, adapting the ioco implementation relation to this situation. In addition, we define what it means for a local test case to be deterministic, showing that we cannot always implement a deterministic global test case as a deterministic local test case. Finally, we show how a global test case can be mapped to a local test case.", "num_citations": "52\n", "authors": ["543"]}
{"title": "Comparing test sets and criteria in the presence of test hypotheses and fault domains\n", "abstract": " A number of authors have considered the problem of comparing test sets and criteria. Ideally test sets are compared using a preorder with the property that test set T1 is at least as strong as T2 if whenever T2 determines that an implementation p is faulty, T1 will also determine that p is faulty. This notion can be extended to test criteria. However, it has been noted that very few test sets and criteria are comparable under such an ordering; instead orderings are based on weaker properties such as subsumes. This article explores an alternative approach, in which comparisons are made in the presence of a test hypothesis or fault domain. This approach allows strong statements about fault detecting ability to be made and yet for a number of test sets and criteria to be comparable. It may also drive incremental test generation.", "num_citations": "51\n", "authors": ["543"]}
{"title": "JPEG steganography: a performance evaluation of quantization tables\n", "abstract": " The two most important aspects of any image based steganographic system are the imperceptibility and the capacity of the stego image. This paper evaluates the performance and efficiency of using optimized quantization tables instead of default JPEG tables within JPEG steganography. We found that using optimized tables significantly improves the quality of stego-images. Moreover, we used this optimization strategy to generate a 16x16 quantization table to be used instead of that suggested. The quality of stego-images was greatly improved when these optimized tables were used. This led us to suggest a new hybrid steganographic method in order to increase the embedding capacity. This new method is based on both and Jpeg-Jsteg methods. In this method, for each 16 x 16 quantized DCT block, the least two significant bits (2-LSBs) of each middle frequency coefficient are modified to embed two secret bits\u00a0\u2026", "num_citations": "49\n", "authors": ["543"]}
{"title": "The effect of the distributed test architecture on the power of testing\n", "abstract": " There has been much interest in testing from finite-state machines (FSMs). If the system under test can be modelled by the (minimal) FSM N then testing from an (minimal) FSM M is testing to check that N is isomorphic to M. In the distributed test architecture, there are multiple interfaces/ports and there is a tester at each port. This can introduce controllability/synchronization and observability problems. This paper shows that the restriction to test sequences that do not cause controllability problems and the inability to observe the global behaviour in the distributed test architecture, and thus relying only on the local behaviour at remote testers, introduces fundamental limitations into testing. There exist minimal FSMs that are not equivalent, and so are not isomorphic, and yet cannot be distinguished by testing in this architecture without introducing controllability problems. Similarly, an FSM may have non-equivalent\u00a0\u2026", "num_citations": "48\n", "authors": ["543"]}
{"title": "High capacity steganographic method based upon JPEG\n", "abstract": " The two most important aspects of any image-based steganographic system are the quality of the stego-image and the capacity of the cover image. This paper proposes a novel and high capacity steganographic approach based on Discrete Cosine Transformation (DCT) and JPEG compression. JPEG technique divides the input image into non-overlapping blocks of 8times8 pixels and uses the DCT transformation. However, our proposed method divides the cover image into non- overlapping blocks of 16times16 pixels. For each quantized DCT block, the least two-significant bits (2-LSBs) of each middle frequency coefficient are modified to embed two secret bits. Our aim is to investigate the data hiding efficiency using larger blocks for JPEG compression. Our experiment result shows that the proposed approach can provide a higher information- hiding capacity than Jpeg-Jsteg and Chang et al. methods based on\u00a0\u2026", "num_citations": "47\n", "authors": ["543"]}
{"title": "Mutation testing from probabilistic finite state machines\n", "abstract": " Mutation testing traditionally involves mutating a program in order to produce a set of mutants and using these mutants in order to either estimate the effectiveness of a test suite or to drive test generation. Recently, however, this approach has been applied to specifications such as those written as finite state machines. This paper extends mutation testing to finite state machine models in which transitions have associated probabilities. The paper describes several ways of mutating a probabilistic finite state machine (PFSM) and shows how test sequences that distinguish between a PFSM and its mutants can be generated. Testing then involves applying each test sequence multiple times, observing the resultant output sequences and using results from statistical sampling theory in order to compare the observed frequency of each output sequence with that expected.", "num_citations": "47\n", "authors": ["543"]}
{"title": "CONSIT: a fully automated conditioned program slicer\n", "abstract": " Conditioned slicing is a source code extraction technique. The extraction is performed with respect to a slicing criterion which contains a set of variables and conditions of interest. Conditioned slicing removes the parts of the original program which cannot affect the variables at the point of interest, when the conditions are satisfied. This produces a conditioned slice, which preserves the behaviour of the original with respect to the slicing criterion. Conditioned slicing has applications in source code comprehension, reuse, restructuring and testing. Unfortunately, implementation is not straightforward because the full exploitation of conditions requires the combination of symbolic execution, theorem proving and traditional static slicing. Hitherto, this difficultly has hindered development of fully automated conditioning slicing tools. This paper describes the first fully automated conditioned slicing system, CONSIT, detailing\u00a0\u2026", "num_citations": "47\n", "authors": ["543"]}
{"title": "Adaptive testing of a deterministic implementation against a nondeterministic finite state machine\n", "abstract": " A number of authors have looked at the problem of deriving a checking experiment from a nondeterministic finite state machine that models the required behaviour of a system. We show that these methods can be extended if it is known that the implementation is equivalent to some (unknown) deterministic finite state machine. When testing a deterministic implementation, the test output provides information about the implementation under test and can thus guide future testing. The use of an adaptive test process is thus proposed.", "num_citations": "47\n", "authors": ["543"]}
{"title": "Oracles for distributed testing\n", "abstract": " The problem of deciding whether an observed behavior is acceptable is the oracle problem. When testing from a finite state machine (FSM), it is easy to solve the oracle problem and so it has received relatively little attention for FSMs. However, if the system under test has physically distributed interfaces, called ports, then in distributed testing, we observe a local trace at each port and we compare the set of local traces with the set of allowed behaviors (global traces). This paper investigates the oracle problem for deterministic and nondeterministic FSMs and for two alternative definitions of conformance for distributed testing. We show that the oracle problem can be solved in polynomial time for the weaker notion of conformance (\u2286 w ) but is NP-hard for the stronger notion of conformance (\u2286), even if the FSM is deterministic. However, when testing from a deterministic FSM with controllable input sequences, the\u00a0\u2026", "num_citations": "46\n", "authors": ["543"]}
{"title": "Search-based amorphous slicing\n", "abstract": " Amorphous slicing is an automated source code extraction technique with applications in many areas of software engineering, including comprehension, reuse, testing and reverse engineering. Algorithms for syntax-preserving slicing are well established, but amorphous slicing is harder because it requires arbitrary transformation; finding good general purpose amorphous slicing algorithms therefore remains as hard as general program transformation. In this paper we show how amorphous slices can be computed using search techniques. The paper presents results from a set of experiments designed to explore the application of genetic algorithms, hill climbing, random search and systematic search to a set of six subject programs. As a benchmark, the results are compared to those from an existing analytical algorithm for amorphous slicing, which was written specifically to perform well with the sorts of program\u00a0\u2026", "num_citations": "46\n", "authors": ["543"]}
{"title": "Testing from a stochastic timed system with a fault model\n", "abstract": " In this paper we present a method for testing a system against a non-deterministic stochastic finite state machine. As usual, we assume that the functional behaviour of the system under test (SUT) is deterministic but we allow the timing to be non-deterministic. We extend the state counting method of deriving tests, adapting it to the presence of temporal requirements represented by means of random variables. The notion of conformance is introduced using an implementation relation considering temporal aspects and the limitations imposed by a black-box framework. We propose a new group of implementation relations and an algorithm for generating a test suite that determines the conformance of a deterministic SUT with respect to a non-deterministic specification. We show how previous work on testing from stochastic systems can be encoded into the framework presented in this paper as an instantiation of our\u00a0\u2026", "num_citations": "44\n", "authors": ["543"]}
{"title": "Testing a distributed system: generating minimal synchronised test sequences that detect output-shifting faults\n", "abstract": " A distributed system may have a number of separate interfaces called ports and in testing it may be necessary to have a separate tester at each port. This introduces a number of issues, including the necessity to use synchronised test sequences and the possibility that output-shifting faults go undetected. This paper considers the problem of generating a minimal synchronised test sequence that detects output-shifting faults when the system is specified using a finite state machine with multiple ports. The set of synchronised test sequences that detect output-shifting faults is represented by a directed graph G and test generation involves finding appropriate tours of G. This approach is illustrated using the test criterion that the test sequence contains a test segment for each transition.", "num_citations": "43\n", "authors": ["543"]}
{"title": "Eliminating redundant tests in a checking sequence\n", "abstract": " Under certain well\u2013defined conditions, determining the correctness of a system under test (SUT) is based on a checking sequence generated from a finite state machine (FSM) specification of the SUT. When there is a distinguishing sequence for the FSM, an efficient checking sequence may be produced from the elements of a set E                                \u03b1\u2032 of \u03b1\u2032-sequences that verify subsets of states and the elements of a set E                                C                of subsequences that test the individual transitions. An optimization algorithm may be used in order to produce a shortest checking sequence by connecting the elements of E                                \u03b1\u2032 and E                                C                using transitions drawn from an acyclic set. Previous work did not consider whether some transition tests may be omitted from E                                C               . This paper investigates the problem of eliminating subsequences from E\u00a0\u2026", "num_citations": "41\n", "authors": ["543"]}
{"title": "Testing from a finite-state machine: extending invertibility to sequences\n", "abstract": " When testing a system modelled as a finite state machine it is desirable to minimize the effort required. It has been demonstrated that it is possible to utilize test sequence overlap in order to reduce the test effort and this overlap has been represented by using invertible transitions. In this paper invertibility will be extended to sequences in order to reduce the test effort further and encapsulate a more general type of test sequence overlap. It will also be shown that certain properties of invertible sequences can be used in the generation of state identification sequences.", "num_citations": "40\n", "authors": ["543"]}
{"title": "The effectiveness of refactoring, based on a compatibility testing taxonomy and a dependency graph\n", "abstract": " In this paper, we describe and then appraise a testing taxonomy proposed by van Deursen and Moonen (VD&M) based on the post-refactoring repeatability of tests. Four categories of refactoring are identified by VD&M ranging from semantic-preserving to incompatible, where, for the former, no new tests are required and for the latter, a completely new test set has to be developed. In our appraisal of the taxonomy, we heavily stress the need for the inter-dependence of the refactoring categories to be considered when making refactoring decisions and we base that need on a refactoring dependency graph developed as part of the research. We demonstrate that while incompatible refactorings may be harmful and time-consuming from a testing perspective, semantic-preserving refactorings can have equally unpleasant hidden ramifications despite their advantages. In fact, refactorings which fall into neither category\u00a0\u2026", "num_citations": "39\n", "authors": ["543"]}
{"title": "Towards estimating computer users\u2019 mood from interaction behaviour with keyboard and mouse\n", "abstract": " The purpose of this exploratory research was to study the relationship between the mood of computer users and their use of keyboard and mouse to examine the possibility of creating a generic or individualized mood measure. To examine this, a field study (n = 26) and a controlled study (n = 16) were conducted. In the field study, interaction data and self-reported mood measurements were collected during normal PC use over several days. In the controlled study, participants worked on a programming task while listening to high or low arousing background music. Besides subjective mood measurement, galvanic skin response (GSR) data was also collected. Results found no generic relationship between the interaction data and the mood data. However, the results of the studies found significant average correlations between mood measurement and personalized regression models based on keyboard\u00a0\u2026", "num_citations": "38\n", "authors": ["543"]}
{"title": "Implementation relations and test generation for systems with distributed interfaces\n", "abstract": " Some systems interact with their environment at physically distributed interfaces called ports and we separately observe sequences of inputs and outputs at each port. As a result we cannot reconstruct the global sequence that occurred and this reduces our ability to distinguish different systems in testing or in use. In this paper we explore notions of conformance for an input output transition system that has multiple ports, adapting the widely used ioco implementation relation to this situation. We consider two different scenarios. In the first scenario the agents at the different ports are entirely independent. Alternatively, it may be feasible for some external agent to receive information from more than one of the agents at the ports of the system, these local behaviours potentially being brought together and here we require a stronger implementation relation. We define implementation relations for these scenarios\u00a0\u2026", "num_citations": "38\n", "authors": ["543"]}
{"title": "Extending test sequence overlap by invertibility\n", "abstract": " Finite state automata can be used to model a system; in particular they can be used to model the control section of a communications protocol. A number of authors have produced algorithms that represent the problem of minimizing the testing against a finite state automaton model as a max flow/min cost problem for an associated network. We extend this work by introducing the use of invertibility to utilize test sequence overlap.", "num_citations": "38\n", "authors": ["543"]}
{"title": "On the testability of SDL specifications\n", "abstract": " The problem of testing from an SDL specification is often complicated by the presence of infeasible paths. This paper introduces an approach for transforming a class of SDL specification in order to eliminate or reduce the infeasible path problem. This approach is divided into two phases in order to aid generality. First the SDL specification is rewritten to create a normal form extended finite state machine (NF-EFSM). This NF-EFSM is then expanded in order to produce a state machine in which the test criterion may be satisfied using paths that are known to be feasible. The expansion process is guaranteed to terminate. Where the expansion process may lead to an excessively large state machine, this process may be terminated early and feasible paths added. The approach is illustrated through being applied to the Initiator process of the Inres protocol.", "num_citations": "37\n", "authors": ["543"]}
{"title": "Squeeziness: An information theoretic measure for avoiding fault masking\n", "abstract": " Fault masking can reduce the effectiveness of a test suite. We propose an information theoretic measure, Squeeziness, as the theoretical basis for avoiding fault masking. We begin by explaining fault masking and the relationship between collisions and fault masking. We then define Squeeziness and demonstrate by experiment that there is a strong correlation between Squeeziness and the likelihood of collisions. We conclude with comments on how Squeeziness could be the foundation for generating test suites that minimise the likelihood of fault masking.", "num_citations": "36\n", "authors": ["543"]}
{"title": "Checking states and transitions of a set of communicating finite state machines\n", "abstract": " This paper considers the problem of testing to check the transitions of implementation I against those of a model M consisting of communicating finite state machines. One approach is to generate the product machine from M and then apply standard finite state machine test techniques. This approach may, however, suffer from a combinatorial explosion. Instead, this paper introduces approaches that may allow local states and transitions of I to be checked without the generation of the product machine. The paper then extends these approaches to the checking of global states.", "num_citations": "36\n", "authors": ["543"]}
{"title": "A search-based approach for automatic test generation from extended finite state machine (efsm)\n", "abstract": " The extended finite state machine is a powerful model that can capture almost all the aspects of a system. However, testing from an EFSM is yet a challenging task due to two main problems: path feasibility and path test data generation. Although optimization algorithms are efficient, their applications to EFSM testing have received very little attention. The aim of this paper is to develop a novel approach that utilizes optimization algorithms to test from EFSM models.", "num_citations": "35\n", "authors": ["543"]}
{"title": "Expanding an extended finite state machine to aid testability\n", "abstract": " The problem of testing from an extended finite state machine (EFSM) is complicated by the presence of infeasible paths. This paper considers the problem of expanding an EFSM in order to bypass the infeasible path problem. The approach is developed for the specification language SDL but, in order to aid generality, the rewriting process is broken down into two phases: producing a normal form EFSM (NF-EFSM) from an SDL specification and then expanding this NF-EFSM.", "num_citations": "35\n", "authors": ["543"]}
{"title": "Testing conformance to a quasi-non-deterministic stream X-machine\n", "abstract": " Stream X-machines have been used in order to specify a range of systems. One of the strengths of this approach is that, under certain well-defined conditions, it is possible to produce a finite test that is guaranteed to determine the correctness of the implementation under test (IUT). Initially only deterministic stream X-machines were considered in the literature. This is largely because the standard test algorithm relies on the stream X-machine being deterministic.               More recently the problem of testing to determine whether the IUT is equivalent to a non-deterministic stream X-machine specification has been tackled. Since non-determinism can be important for specifications, this is an extremely useful extension. In many cases, however, we wish to test for a weaker notion of correctness called conformance. This paper considers a particular form of non-determinism, within stream X-machines, that will be\u00a0\u2026", "num_citations": "34\n", "authors": ["543"]}
{"title": "Conditions for resolving observability problems in distributed testing\n", "abstract": " Controllability and observability problems may manifest themselves during the application of a\u00a0test or checking sequence in a\u00a0test architecture where there are multiple remote testers. These problems often require the use of external coordination message exchanges among testers during testing. It is desired to construct a\u00a0test or checking sequence from the specification of the system under test such that it will be free from these problems without requiring the use of external coordination messages. This paper investigates conditions that allow us to construct such a\u00a0test or checking sequence. For specifications satisfying these conditions, procedures for constructing subsequences that eliminate the need for using external coordination messages are given.", "num_citations": "33\n", "authors": ["543"]}
{"title": "Testing real-time embedded systems using timed automata based approaches\n", "abstract": " Real-Time Embedded Systems (RTESs) have an increasing role in controlling the IT that we use on a day-to-day basis. The behaviour of an RTES is not based solely on the interactions it might have with its surrounding environment, but also on the timing requirements it induces. As a result, ensuring that an RTES behaves correctly is non-trivial, especially after adding time as a new dimension to the complexity of the testing process. We previously introduced the \u2018priority-based\u2019 approach which tests the logical and timing behaviour of an RTES modelled formally as UPPAAL automata. The \u2018priority-based\u2019 approach was based on producing sets of timed test traces by achieving clock region coverage. In this paper, we empirically validate the \u2018priority-based\u2019 approach with comparison to well-known timed testing approaches based on a Timed Automata (TA) formalism using a complete test bed based on an industrial\u00a0\u2026", "num_citations": "32\n", "authors": ["543"]}
{"title": "Generating feasible input sequences for extended finite state machines (EFSMs) using genetic algorithms\n", "abstract": " Testing is an important part of the software engineering process but can be time consuming, error-prone and expensive. Test automation can help reduce these problems. Many state based systems, like protocols, have been modelled as finite state machines (FSMs) and extended finite state machines (EFSMs). They have been an effective method of modelling because a variety of techniques and automated tools exist that work with them. To ensure the reliability of these systems once implemented they must be tested for conformance to their specification. Usually the implementation of a system specified by an FSM or EFSM is tested for conformance by applying a sequence of inputs and verifying that the corresponding sequence of outputs is that which is expected. This commonly involves executing a number of transition paths, until all transitions have been tested at least once. In EFSMs the feasibility of a\u00a0\u2026", "num_citations": "31\n", "authors": ["543"]}
{"title": "Using a minimal number of resets when testing from a finite state machine\n", "abstract": " Finite State Machines (FSMs) are used to model a number of classes of systems, including communications protocols and control systems. There has thus been much interest in automating the generation of tests from FSMs [1, 5, 7, 8]. A reset is an operation that takes the system from each state to the initial state. The use of a reset may increase the cost of testing and reduce its effectiveness [2, 3, 9]. Thus, it is often desirable to minimize the number of resets used in testing. This paper investigates problems of the form: produce a test sequence p, that contains each element of some non-empty set T of sequences, such that there does not exist a test sequence p that contains each element of T and has fewer resets than p. The proposed (polynomial time) algorithm is guaranteed to produce a test sequence that has the minimum number of resets when considering test sequences that connect the sequences from T but do not utilize overlap.", "num_citations": "29\n", "authors": ["543"]}
{"title": "Generating candidates when testing a deterministic implementation against a non-deterministic finite-state machine\n", "abstract": " This paper considers the problem of testing a deterministic system against a non-deterministic finite-state machine. An adaptive test process, with two phases, is proposed. The paper focuses on the first stage which involves testing to generate a candidate deterministic finite-state machine. This candidate has the property that, under the test hypotheses used, the implementation is correct if and only if it is equivalent to the candidate. A test may then be derived from the candidate.", "num_citations": "28\n", "authors": ["543"]}
{"title": "Using genetic algorithms to generate test sequences for complex timed systems\n", "abstract": " The generation of test data for state-based specifications is a computationally expensive process. This problem is magnified if we consider that time constraints have to be taken into account to govern the transitions of the studied system. The main goal of this paper is to introduce a complete methodology, supported by tools, that addresses this issue by representing the test data generation problem as an optimization problem. We use heuristics to generate test cases. In order to assess the suitability of our approach we consider two different case studies: a communication protocol and the scientific application BIPS3D. We give details concerning how the test case generation problem can be presented as a search problem and automated. Genetic algorithms (GAs) and random search are used to generate test data and evaluate the approach. GAs outperform random search and seem to scale well as the\u00a0\u2026", "num_citations": "27\n", "authors": ["543"]}
{"title": "Verdict functions in testing with a fault domain or test hypotheses\n", "abstract": " In state-based testing, it is common to include verdicts within test cases, the result of the test case being the verdict reached by the test run. In addition, approaches that reason about test effectiveness or produce tests that are guaranteed to find certain classes of faults are often based on either a fault domain or a set of test hypotheses. This article considers how the presence of a fault domain or test hypotheses affects our notion of a test verdict. The analysis reveals the need for new verdicts that provide more information than the current verdicts and for verdict functions that return a verdict based on a set of test runs rather than a single test run. The concepts are illustrated in the contexts of testing from a nondeterministic finite state machine and the testing of a datatype specified using an algebraic specification language but are potentially relevant whenever fault domains or test hypotheses are used.", "num_citations": "26\n", "authors": ["543"]}
{"title": "Bounded reordering in the distributed test architecture\n", "abstract": " In the distributed test architecture, the system under test (SUT) interacts with its environment at multiple physically distributed ports and the local testers at these ports do not synchronize their actions. This presents many challenges and, in particular, apparently incorrect behaviors can be the consequence of an erroneous assumption about the exact order in which actions were performed at different ports. In previous work, we defined a conformance relation for the distributed test architecture. Essentially, the SUT is faulty if we observe a trace \u03c3 such that no admissible reordering of the actions in \u03c3 could have been produced by the specification. However, this notion can be weak if the compared traces might be  too  different. This paper introduces conformance relations where, for a given metric, a reordering is only considered if the distance between the two traces is at most a certain bound  k . We introduce two\u00a0\u2026", "num_citations": "25\n", "authors": ["543"]}
{"title": "Resolving observability problems in distributed test architectures\n", "abstract": " The introduction of multiple remote testers to apply a test or checking sequence in a test architecture brings out the possibility of controllability and observability problems. These problems often require the use of external coordination message exchanges among testers. In this paper, we consider constructing a test or checking sequence from the specification of the system under test such that it will be free from these problems and will not require the use of external coordination messages. We give an algorithm that can check whether it is possible to construct subsequences from a given specification that eliminate the need for using external coordination message exchanges, and when it is possible actually produces such subsequences.", "num_citations": "25\n", "authors": ["543"]}
{"title": "UIO sequence based checking sequences for distributed test architectures\n", "abstract": " This study addresses the construction of a preset checking sequence that will not pose controllability (synchronization) and observability (undetectable output shift) problems when applied in distributed test architectures that utilize remote testers. The controllability problem manifests itself when a tester is required to send the current input and because it did not send the previous input nor did it receive the previous output it cannot determine when to send the input. The observability problem manifests itself when a tester is expecting an output in response to either the previous input or the current input and because it is not the one to send the current input, it cannot determine when to start and stop waiting for the output. Based on UIO sequences, a checking sequence construction method is proposed to yield a sequence that is free from controllability and observability problems.", "num_citations": "25\n", "authors": ["543"]}
{"title": "SMT-C: A semantic mutation testing tools for C\n", "abstract": " Semantic Mutation Testing (SMT) is a technique that aims to capture errors caused by possible misunderstandings of the semantics of a description language. It is intended to target a class of errors which is different from those captured by traditional Mutation Testing (MT). This paper describes our experiences in the development of an SMT tool for the C programming language: SMT-C. In addition to implementing the essential requirements of SMT (generating semantic mutants and running SMT analysis) we also aimed to achieve the following goals: weak MT/SMT for C, good portability between different configurations, seamless integration into test routines of programming with C and an easy to use front-end.", "num_citations": "23\n", "authors": ["543"]}
{"title": "Generating a checking sequence with a minimum number of reset transitions\n", "abstract": " Given a finite state machine M, a checking sequence is an input sequence that is guaranteed to lead to a failure if the implementation under test is faulty and has no more states than M. There has been much interest in the automated generation of a short checking sequence from a finite state machine. However, such sequences can contain reset transitions whose use can adversely affect both the cost of applying the checking sequence and the effectiveness of the checking sequence. Thus, we sometimes want a checking sequence with a minimum number of reset transitions rather than a shortest checking sequence. This paper describes a new algorithm for generating a checking sequence, based on a distinguishing sequence, that minimises the number of reset transitions used.", "num_citations": "23\n", "authors": ["543"]}
{"title": "Reaching and distinguishing states of distributed systems\n", "abstract": " Some systems interact with their environment at physically distributed interfaces, called ports, and in testing such a system it is normal to place a tester at each port. Each tester observes only the events at its port and it is known that this limited observational power introduces additional controllability and observability problems into testing. Given a multiport finite state machine (FSM) M, we consider the problems of defining strategies for the testers either to reach a given state of M or to distinguish two states of M. These are important problems since most techniques for testing from a single-port FSM use sequences that reach and distinguish states. Both problems can be solved in low-order polynomial time for single-port FSMs but we prove that the corresponding decision problems are undecidable for multiport FSMs. However, we also show that they can be solved in low-order polynomial times for deterministic FSMs\u00a0\u2026", "num_citations": "23\n", "authors": ["543"]}
{"title": "Checking sequences for distributed test architectures\n", "abstract": " Controllability and observability problems may manifest themselves during the application of a checking sequence in a test architecture where there are multiple remote testers. These problems often require the use of external coordination message exchanges among testers during testing. However, the use of coordination messages requires the existence of an external network that can increase the cost of testing and can be difficult to implement. In addition, the use of coordination messages introduces delays and this can cause problems where there are timing constraints. Thus, sometimes it is desired to construct a checking sequence from the specification of the system under test that will be free from controllability and observability problems without requiring the use of external coordination message exchanges. This paper gives conditions under which it is possible to produce such a checking sequence\u00a0\u2026", "num_citations": "23\n", "authors": ["543"]}
{"title": "Parallel algorithms for testing finite state machines: Generating UIO sequences\n", "abstract": " This paper describes an efficient parallel algorithm that uses many-core GPUs for automatically deriving Unique Input Output sequences (UIOs) from Finite State Machines. The proposed algorithm uses the global scope of the GPU's global memory through coalesced memory access and minimises the transfer between CPU and GPU memory. The results of experiments indicate that the proposed method yields considerably better results compared to a single core UIO construction algorithm. Our algorithm is scalable and when multiple GPUs are added into the system the approach can handle FSMs whose size is larger than the memory available on a single GPU.", "num_citations": "22\n", "authors": ["543"]}
{"title": "Estimation of failure rate using random and partition testing\n", "abstract": " Failure rate, given an operational profile, is a common measure of reliability. A number of approaches to estimating failure rate are described and it is demonstrated that, under certain conditions, a functional partition can provide a better estimator than random\u2010testing\u2010based estimators. \u00a9 1997 John Wiley & Sons, Ltd.", "num_citations": "22\n", "authors": ["543"]}
{"title": "Passive testing with asynchronous communications and timestamps\n", "abstract": " We develop a formal passive testing framework for software systems where parties communicate asynchronously. Monitors, placed in between the entities, check that a certain property holds over the observations of the interaction between users and the system under test (SUT). Due to the asynchronous nature of communications, the trace observed by the monitor might differ from the one produced by the SUT: the monitor observes inputs before they are received by the SUT and outputs are observed after they are sent by the SUT. It is necessary to take this into account in passive testing; otherwise we might obtain false positives or false negatives. In order to better assess the real causality between actions, we consider the case where each action is labelled with a timestamp giving the time when it was observed at the monitor. We also assume that we know bounds on network latency and so the\u00a0\u2026", "num_citations": "21\n", "authors": ["543"]}
{"title": "Distinguishing sequences for partially specified FSMs\n", "abstract": " Distinguishing Sequences (DSs) are used inmany Finite State Machine (FSM) based test techniques. Although Partially Specified FSMs (PSFSMs) generalise FSMs, the computational complexity of constructing Adaptive and Preset DSs (ADSs/PDSs) for PSFSMs has not been addressed. This paper shows that it is possible to check the existence of an ADS in polynomial time but the corresponding problem for PDSs is PSPACE-complete. We also report on the results of experiments with benchmarks and over 8 \u2217 106 PSFSMs.", "num_citations": "21\n", "authors": ["543"]}
{"title": "Mood independent programming\n", "abstract": " Motivation--The motivation behind this study is to improve the programmer's coding and debugging performance by considering their moods.Research approach--This study will use an empirical research approach that involves the use of un-controlled and controlled experimentation.", "num_citations": "21\n", "authors": ["543"]}
{"title": "Using time to add order to distributed testing\n", "abstract": " Many systems interact with their environment at physically distributed interfaces called ports. In testing such a system we might use a distributed approach in which there is a separate tester at each port. If the testers do not synchronise during testing then we cannot always determine the relative order of events observed at different ports and corresponding implementation relations have been developed for distributed testing. One possible method for strengthening the implementation relation is for testers to synchronise through exchanging coordination messages but this requires sufficiently fast communications channels and can increase the cost of testing. This paper explores an alternative in which each tester has a local clock and timestamps its observations. If we know nothing about how the local clocks relate then this does not help while if the local clocks agree exactly then we can reconstruct the\u00a0\u2026", "num_citations": "20\n", "authors": ["543"]}
{"title": "Conformance testing from message sequence charts\n", "abstract": " There are several industries in which Message Sequence Charts (MSCs) and the corresponding UML notation (Sequence Diagrams) are used to describe requirements. However, most work on model based testing has looked at testing from other languages such as input output transition systems and finite state machines. This paper explores the problem of testing on the basis of an MSC specification. We develop a formal test framework and explore the notion of a test hypothesis in this context. It transpires that there are several possible test architectures and each defines the observational power of the tester(s) and so we describe a flexible test architecture. In this paper we explore these alternatives and define corresponding implementation relations, explaining how verdicts can be produced for these relations. We then show how test suites can be generated and executed and define test coverage criteria.", "num_citations": "20\n", "authors": ["543"]}
{"title": "Is a strategy for code smell assessment long overdue?\n", "abstract": " Code smells reflect code decay and, as such, developers should seek to eradicate such smells through application of'deodorant'in the form of one or more refactorings. However, a dearth of studies exploring code smells either theoretically or empirically suggests that there are reasons why smell eradication is neither being applied in anger, nor the subject of significant research. In this paper, we present three studies as supporting evidence for this claim. The first is an analysis of a set of five, open-source Java systems, the second an empirical study of a sub-system of a proprietary, C# web-based application and the third, a theoretical enumeration of smell-related refactorings. Key findings of the study were first, that developers seemed to avoid eradicating superficially'simple'smells in favor of more'obscure'ones; second, a wide range of conflicts and anomalies soon emerged when trying to identify smelly code\u00a0\u2026", "num_citations": "20\n", "authors": ["543"]}
{"title": "Aiding test case generation in temporally constrained state based systems using genetic algorithms\n", "abstract": " Generating test data is computationally expensive. This paper improves a framework that addresses this issue by representing the test data generation problem as an optimisation problem and uses heuristics to help generate test cases. The paper considers the temporal constraints and behaviour of a certain class of (timed) finite state machines. A very simple fitness function is defined that can be used with several evolutionary search techniques and automated test case generation tools.", "num_citations": "20\n", "authors": ["543"]}
{"title": "Implementation relations and probabilistic schedulers in the distributed test architecture\n", "abstract": " We present a complete framework to formally test systems with distributed ports where some choices are probabilistically quantified while other choices are non-deterministic. We define different implementation relations, that is, relations that state what it means for a system to be a valid implementation of a specification. We also study how these relate. In order to define these implementation relations we use probabilistic schedulers, a more powerful version, including probabilistic choices, of a notion of scheduler introduced in our previous work. Probabilistic schedulers, when applied to either a specification or an implementation, resolve all the possible non-determinism, so that we can compare purely probabilistic systems.", "num_citations": "19\n", "authors": ["543"]}
{"title": "A methodology for validating cloud models using metamorphic testing\n", "abstract": " Cloud computing is a paradigm that provides access to a flexible, elastic and on-demand computing infrastructure, allowing users to dynamically request virtual resources. However, researchers typically cannot experiment with critical parts of cloud systems such as the underlying cloud architecture, resource-provisioning policies and the configuration of resource virtualisation. This problem can be partially addressed through using simulations of cloud systems. Unfortunately, the problem of testing cloud systems is still challenging due to the many parameters that such systems typically have and the difficulty in determining whether an observed behaviour is correct. In order to alleviate these issues, we propose a methodology to semi-automatically test and validate cloud models by integrating simulation techniques and metamorphic testing.", "num_citations": "19\n", "authors": ["543"]}
{"title": "Timed implementation relations for the distributed test architecture\n", "abstract": " In order to test systems that have physically distributed interfaces, called ports, we might use a distributed approach in which there is a separate tester at each port. If the testers do not synchronise during testing then we cannot always determine the relative order of events observed at different ports and this leads to new notions of correctness that have been described using corresponding implementation relations. We study the situation in which each tester has a local clock and timestamps its observations. If we know nothing about how the local clocks relate then this does not affect the implementation relation while if the local clocks agree exactly then we can reconstruct the sequence of observations made. In practice, however, we are likely to be between these extremes: the local clocks will not agree exactly but we have some information regarding how they can differ. We start by assuming that a local\u00a0\u2026", "num_citations": "19\n", "authors": ["543"]}
{"title": "Specification mutation analysis for validating timed testing approaches based on timed automata\n", "abstract": " Testing real-time systems is a non-trivial validation task, especially after adding time as a new dimension to its complexity. In previous research, we introduced a 'priority-based' approach which tested the logical and timing behaviour of real-time systems modelled formally as UPPAAL Timed Automata (UTA). In this paper, we validate the 'priority-based' approach with a comparison to four well-known timed testing approaches based on a Timed Automata (TA) formalism using Specification Mutation Analysis (SMA). We introduce a set of timed and functional mutation operators based on TA. Three case studies are used to run the mutation analysis and mutants are generated according to the proposed mutation operators. The effectiveness of timed testing approaches are determined and contrasted according to the mutation score; we show that our testing approach achieves high mutation adequacy score when\u00a0\u2026", "num_citations": "19\n", "authors": ["543"]}
{"title": "Using communication coverage criteria and partial model generation to assist software integration testing\n", "abstract": " This paper considers the problem of integration testing the components of a timed distributed software system. We assume that communication between the components is specified using timed interface automata and use computational tree logic (CTL) to define communication-based coverage criteria that refer to send- and receive-statements and communication paths. The proposed method enables testers to focus during component integration on such parts of the specification, e.g. behaviour specifications or Markovian usage models, that are involved in the communication between components to be integrated. A more specific application area of this approach is the integration of test-models, e.g. a transmission gear can be tested based on separated models for the driver behaviour, the engine condition, and the mechanical and hydraulical transmission states. Given such a state-based specification of a\u00a0\u2026", "num_citations": "19\n", "authors": ["543"]}
{"title": "Using adaptive distinguishing sequences in checking sequence constructions\n", "abstract": " A number of methods have been published to construct checking sequences for testing from Finite State Machine-based specifications. Many of these methods require the existence of a preset distinguishing sequence in the model. In this paper, we show that usually an adaptive distinguishing sequence is sufficient for these methods to work. This result is significant because adaptive distinguishing sequences are strictly more common and up to exponentially shorter than preset ones.", "num_citations": "19\n", "authors": ["543"]}
{"title": "Separating sequence overlap for automated test sequence generation\n", "abstract": " Finite state machines have been used to model a number of classes of system and there has thus been much interest in the automatic generation of test sequences from finite state machines. Many finite state machine based test techniques utilize sequences that check the final states of transitions, the most general such sequence being a separating sequence: an input sequence that distinguishes between two states of an FSM. When using such techniques the test sequence length can be reduced by utilizing overlap. This paper investigates overlap for separating sequences and shows how this can be incorporated into test sequence generation.", "num_citations": "19\n", "authors": ["543"]}
{"title": "Applying adaptive test cases to nondeterministic implementations\n", "abstract": " The testing of a state-based system involves the application of sequences of inputs and the observation of the resultant input/output sequences (traces). These traces can result from preset input sequences or adaptive test cases in which the choice of the next input depends on the trace that has observed up to that input. Adaptive test cases are used in a number of areas including protocol conformance testing and adaptivity forms the basis of the standardised test language TTCN. Suppose that we apply adaptive test case \u00b0 to the system under test (SUT) and observe the trace \u00af\u00be. If the SUT is deterministic and we apply \u00b0 again, after resetting the SUT, then we will observe \u00af\u00be again. Further, if we have another adaptive test case \u00b00 where a prefix \u00af\u00be0 of \u00af\u00be is a possible response to \u00b00 then we know that the application of \u00b00 must lead to \u00af\u00be0. Thus, for a deterministic SUT the response of the SUT to an adaptive test case \u00b00 might be deduced from the response of the SUT to another adaptive test case. This observation can be used to reduce the cost of testing: we only apply adaptive test case \u00b00 if we cannot deduce the response to \u00b00 from the set of observations. While many systems are deterministic, nondeterminism is becoming increasingly common. Nondeterminism in the SUT is typically a consequence of limits in the ability to observe the SUT. For example, it could be a result of information hiding, real time properties, or of different possible interleavings in a concurrent system (see, for example. This paper investigates the case where the SUT is nondeterministic. We consider the situation in which a set O of traces has been observed in testing and\u00a0\u2026", "num_citations": "19\n", "authors": ["543"]}
{"title": "Concerning the ordering of adaptive test sequences\n", "abstract": " The testing of a state-based system may involve the application of a number of adaptive test sequences. Where the implementation under test (IUT) is deterministic, the response of the IUT to some adaptive test sequence \u03b3               1 may be capable of determining the response of the IUT to some other adaptive test sequence \u03b3               2. Thus, the expected cost of applying a set of adaptive test sequences depends upon the order in which they are applied. This paper explores properties of adaptive test sequences and the problem of finding an order of application, of the elements from some set of adaptive test sequences, that minimises the expected cost of testing.", "num_citations": "19\n", "authors": ["543"]}
{"title": "A tool supported methodology to passively test asynchronous systems with multiple users\n", "abstract": " Context: Testing usually involves the interaction of the tester with the system under test. However, there are many situations in which this interaction is not feasible and so one requires a passive approach in which the system is analysed to look for failures or unexpected behaviours. The entities of a complex system usually communicate in an asynchronous manner and this complicates the testing tasks since the observed order of events need not be the same as the order in which the events were produced. In previous work, we presented a formal passive testing theory for a single user and system communicating through an asynchronous channel. We were able to check that a trace generated by the system satisfies a given property.Objective: This papers extends our work, for detecting potential intrusions and unexpected behaviours, to the case where many users simultaneously communicate with a central server\u00a0\u2026", "num_citations": "18\n", "authors": ["543"]}
{"title": "Generating complete controllable test suites for distributed testing\n", "abstract": " A test suite is m-complete for finite state machine (FSM) M if it distinguishes between M and all faulty FSMs with m states or fewer. While there are several algorithms that generate m-complete test suites, they cannot be directly used in distributed testing since there can be additional controllability and observability problems. Indeed, previous results show that there is no general method for generating an m-complete test suite for distributed testing and so the focus has been on conditions under which this is possible. This paper takes a different approach, which is to generate what we call cm-complete test suites: controllable test suites that distinguish an FSM N with no more than m states from M if this is possible in controllable testing. Thus, under the hypothesis that the system under test has no more than m states, a cm-complete test suite achieves as much as is possible given the restriction that testing should be\u00a0\u2026", "num_citations": "18\n", "authors": ["543"]}
{"title": "Heuristics for fault diagnosis when testing from finite state machines\n", "abstract": " When testing from finite state machines, a failure observed in the implementation under test (IUT) is called a symptom. A symptom could have been caused by an earlier state transfer failure. Transitions that may be used to explain the observed symptoms are called diagnosing candidates. Finding strategies to generate an optimal set of diagnosing candidates that could effectively identify faults in the IUT is of great value in reducing the cost of system development and testing. This paper investigates fault diagnosis when testing from finite state machines and proposes heuristics for fault isolation and identification. The proposed heuristics attempt to lead to a symptom being observed in some shorter test sequences, which helps to reduce the cost of fault isolation and identification. The complexity of the proposed method is analysed. A case study is presented, which shows how the proposed approach assists in fault\u00a0\u2026", "num_citations": "18\n", "authors": ["543"]}
{"title": "Overcoming observability problems in distributed test architectures\n", "abstract": " This paper investigates conditions that must be satisfied by an FSM for the existence of input sequences that can be applied in a distributed test architecture without encountering controllability and observability problems and without using external coordination messages. Such conditions have two potential values. First, they can be used to determine whether we require coordination messages and thus a network that connects the testers. Second, if we wish to avoid the use of coordination messages in testing then these conditions can be seen as testability conditions that can inform the design process. Results given in this paper differ from those in the following ways. First, the conditions are strictly weaker than those in since we are less restrictive in the ways we achieve our goals. Second, only considered observability problems; we consider both controllability and observability problems. In addition, only considered a particular type of observability problem and we generalize this. Finally, we investigate the situation in which we need only add input sequences to complement a given test/checking sequence \u03c1 and prove that the conditions for this problem are equivalent to those for the original problem.", "num_citations": "18\n", "authors": ["543"]}
{"title": "Testing from semi-independent communicating finite state machines with a slow environment\n", "abstract": " Some systems may be modelled as a set of communicating finite state machines with a slow environment. These machines communicate through the exchange of values. While it is possible to convert such a model into one finite state machine, from which test cases can be derived, this process may lead to an explosion in the number of states. Alternatively it is possible to utilise any independence that exists. The problem of producing a minimal test set, in the presence of certain types of independence and unique input/output sequences, can be represented as a variant of the vehicle routing problem. Possible heuristics for solving this problem are outlined and the method is applied to an example.", "num_citations": "18\n", "authors": ["543"]}
{"title": "An extended framework for passive asynchronous testing\n", "abstract": " In passive testing a monitor observes the trace (sequence of inputs and outputs) of the system under test (SUT) and checks that this trace satisfies a given property P, potentially triggering a response if an incorrect behaviour is observed. Recent work has explored a variant of passive testing, in which we have a required property P of the traces of the SUT and there is a first-in-first-out (FIFO) network between the SUT and the monitor. The problem here is that the trace observed by the monitor need not be that produced by the SUT. Previous work has shown how such asynchronous passive testing can be performed if the property P is defined by a pair (\u03c1, O \u03c1) that represents the requirement that if trace \u03c1 is produced by the SUT then the next output must be from the set O \u03c1. This paper generalises the previous work to the case where the property P is defined by a finite automaton.", "num_citations": "17\n", "authors": ["543"]}
{"title": "An evolutionary study of fan-in and fan-out metrics in OSS\n", "abstract": " Excessive coupling between object-oriented classes is widely acknowledged as a maintenance problem that can result in a higher propensity for faults in systems and a `stored up' future problem. The aim of this paper is to explore the relationship between `fan-in' and `fan-out' coupling metrics over multiple versions of open-source software. More specifically, we explore the relationship between the two metrics to determine patterns of growth in each over the course of time. The JHawk tool was used to extract the two metrics from five open-source systems. Two questions were posed for each system. First, what are the characteristics of classes exhibiting the highest fan-in values? Second, do fan-in and fan-out increase in corresponding and consistent amounts over time? Results show a wide range of traits in the classes to explain both high and low levels of fan-in and fan-out. We also found evidence of certain `key'\u00a0\u2026", "num_citations": "17\n", "authors": ["543"]}
{"title": "Incomplete distinguishing sequences for finite state machines\n", "abstract": " Given a finite state machine (FSM) , a distinguishing sequence (DS) is a test that identifies the state of . While there are two types of DSs, preset DSs (PDSs) and adaptive DSs (ADSs), not all FSMs possess a DS. In this paper, we examine the problem of finding incomplete PDSs and ADSs, exploring associated optimization problems: finding a largest set of states that has a DS and finding a smallest set of DSs that, between them, distinguish all of the states. We also propose a greedy algorithm to produce a small set of incomplete ADSs and use experiments to compare this with two previously published algorithms for generating state identifiers. We show that the optimization problems related to incomplete ADSs and PDSs are  as are corresponding approximation problems. In the experiments, we found that incomplete ADSs produced by the proposed greedy algorithm led to relatively\u00a0\u2026", "num_citations": "16\n", "authors": ["543"]}
{"title": "Scenarios\u2010based testing of systems with distributed ports\n", "abstract": " Distributed systems are usually composed of several distributed components that communicate with their environment through specific ports. When testing such a system we separately observe sequences of inputs and outputs at each port rather than a global sequence and potentially cannot reconstruct the global sequence that occurred. Typically, the users of such a system cannot synchronize their actions during use or testing. However, the use of the system might correspond to a sequence of scenarios, where each scenario involves a sequence of interactions with the system that, for example, achieves a particular objective. When this is the case there is the potential for a significant delay between two scenarios and this effectively allows the users of the system to synchronize between scenarios. If we represent the specification of the global system by using a state\u2010based notation, we say that ait scenario is any\u00a0\u2026", "num_citations": "16\n", "authors": ["543"]}
{"title": "Checking sequence construction using adaptive and preset distinguishing sequences\n", "abstract": " Methods for testing from finite state machine-based specifications often require the existence of a preset distinguishing sequence for constructing checking sequences. It has been shown that an adaptive distinguishing sequence is sufficient for these methods. This result is significant because adaptive distinguishing sequences are strictly more common and up to exponentially shorter than preset ones. However, there has been no study on the actual effect of using adaptive distinguishing sequences on the length of checking sequences. This paper describes experiments that show that checking sequences constructed using adaptive distinguishing sequences are almost consistently shorter than those based on preset distinguishing sequences. This is investigated for three different checking sequence generation methods and the results obtained from an extensive experimental study are given.", "num_citations": "16\n", "authors": ["543"]}
{"title": "Combining centralised and distributed testing\n", "abstract": " Many systems interact with their environment at distributed interfaces (ports) and sometimes it is not possible to place synchronised local testers at the ports of the system under test (SUT). There are then two main approaches to testing: having independent local testers or a single centralised tester that interacts asynchronously with the SUT. The power of using independent testers has been captured using implementation relation dioco. In this article, we define implementation relation diococ for the centralised approach and prove that dioco and diococ are incomparable. This shows that the frameworks detect different types of faults and so we devise a hybrid framework and define an implementation relation diocos for this. We prove that the hybrid framework is more powerful than the distributed and centralised approaches. We then prove that the Oracle problem is NP-complete for diococ and diocos but can be\u00a0\u2026", "num_citations": "15\n", "authors": ["543"]}
{"title": "Testing with inputs and outputs in CSP\n", "abstract": " This paper addresses refinement and testing based on CSP models, when we distinguish input and output events. From a testing perspective, there is an asymmetry:\u00a0the tester\u00a0(or the environment) controls the inputs, and the system under test controls the outputs. The standard models and refinement relations of CSP are, therefore, not entirely suitable for testing. Here, we adapt the CSP stable-failures model, resulting in the notion of input-output failures refinement. We compare that with the ioco relation often used in testing.Finally, we adapt the CSP testing theory, and show that some tests become unnecessary.", "num_citations": "15\n", "authors": ["543"]}
{"title": "Exploring the eradication of code smells: An empirical and theoretical perspective\n", "abstract": " Code smells reflect code decay, and, as such, developers should seek to eradicate such smells through application of \u201cdeodorant\u201d in the form of one or more refactorings. However, a relative lack of studies exploring code smells either theoretically or empirically when compared with literature on refactoring suggests that there are reasons why smell eradication is neither being applied in anger, nor the subject of significant research. In this paper, we present three studies as supporting evidence for this stance. The first is an analysis of a set of five, open-source Java systems in which we show very little tendency for smells to be eradicated by developers; the second is an empirical study of a subsystem of a proprietary, C# web-based application where practical problems arise in smell identification and the third, a theoretical enumeration of smell-related refactorings to suggest why smells may be left alone from an effort perspective. Key findings of the study were that first, smells requiring application of simple refactorings were eradicated in favour of smells requiring more complex refactorings; second, a wide range of conflicts and anomalies soon emerged when trying to identify smelly code; an interesting result with respect to comment lines was also observed. Finally, perceived (estimated) effort to eradicate a smell may be a key factor in explaining why smell eradication is avoided by developers. The study thus highlights the need for a clearer research strategy on the issue of code smells and all aspects of their identification and measurement.", "num_citations": "15\n", "authors": ["543"]}
{"title": "Controllable testing from nondeterministic finite state machines with multiple ports\n", "abstract": " Some systems have physically distributed interfaces, called ports, at which they interact with their environment. We place a tester at each port and if the testers cannot directly communicate and there is no global clock then we are using the distributed test architecture. It is known that this test architecture introduces controllability problems when testing from a deterministic finite state machine. This paper investigates the problem of testing from a nondeterministic finite state machine in the distributed test architecture and explores controllability. It shows how we can decide in polynomial time whether an input sequence is controllable. It also gives an algorithm for generating such an input sequence x\u0305 and shows how we can produce testers that implement x\u0305.", "num_citations": "15\n", "authors": ["543"]}
{"title": "Parallel algorithms for generating harmonised state identifiers and characterising sets\n", "abstract": " Many automated finite state machine (FSM) based test generation algorithms require that a characterising set or a set of harmonised state identifiers is first produced. The only previously published algorithms for partial FSMs were brute-force algorithms with exponential worst case time complexity. This paper presents polynomial time algorithms and also massively parallel implementations of both the polynomial time algorithms and the brute-force algorithms. In the experiments the parallel algorithms scaled better than the sequential algorithms and took much less time. Interestingly, while the parallel version of the polynomial time algorithm was fastest for most sizes of FSMs, the parallel version of the brute-force algorithm scaled better due to lower memory requirements.", "num_citations": "14\n", "authors": ["543"]}
{"title": "An implementation relation and test framework for timed distributed systems\n", "abstract": " Many systems interact with their environment at physically distributed interfaces and the distributed nature of any observations made is known to complicate testing. This paper concerns distributed testing, where a separate tester is placed at each localised interface and may only observe what happens at this interface. Most previous work on distributed model based testing has used models that are either finite state machines or input output transition systems. In this paper we define a framework for distributed testing from timed input output transition systems along with corresponding test hypotheses and a distributed conformance relation.", "num_citations": "14\n", "authors": ["543"]}
{"title": "Testing probabilistic distributed systems\n", "abstract": " There has been much interest in the testing of systems that have physically distributed interfaces and this has been encouraged by recent trends towards the use of such systems. Most formal work in this area has considered the testing of deterministic systems based on deterministic models. However, distributed systems are usually nondeterministic and often can be seen as probabilistic systems in which required or expected probabilities can be attached to the allowable events. This paper provides a formal testing framework for systems with physically distributed interfaces where nondeterministic decisions among alternatives are probabilistically quantified. It first considers testing from systems where there is a unique type of action. In this setting, a generative interpretation of probabilities is adequate and a formal framework to test these systems is provided. However, the observable events of a system are\u00a0\u2026", "num_citations": "14\n", "authors": ["543"]}
{"title": "Mutation Testing.\n", "abstract": " Traditionally in mutation testing we produce a set of mutants, which are variants of the system under test. The adequacy of a test suite is then judged by determining how many of the mutants it distinguishes from the original system. The aim is to produce mutants that are similar to real faults, in which case the ability of a test suite to distinguish between a program and its mutants should relate to its ability to distinguish between a correct program and a faulty program. This article describes mutation testing, the directions in which it has developed, and some of the main challenges.", "num_citations": "14\n", "authors": ["543"]}
{"title": "Testing in the distributed test architecture\n", "abstract": " The introduction of multiple remote testers to apply a test or checking sequence introduces the possibility of controllability and observability problems. These problems can require the use of external coordination message exchanges among testers. It is desirable to construct a test or checking sequence from the specification of the system under test such that it is free from these problems without requiring the use of external coordination messages. Here we define criteria on the specification of the system under test for this to be possible. For specifications satisfying the criteria, algorithms for constructing subsequences that eliminate the need for external coordination messages are given.", "num_citations": "14\n", "authors": ["543"]}
{"title": "Achieving communication coverage in testing\n", "abstract": " This paper considers the problem of testing the communication between components of a timed distributed software system. We assume that communication is specified using timed interface automata and use computational tree logic (CTL) to define coverage criteria that refer to send- and receive-statements and communication paths. Given such a state-based specification of a distributed system and a concrete coverage goal, a model checker is used in order to determine the coverage provided by a finite set of test-cases, expressed using sequence diagrams. If parts of the specification remain uncovered then a goal is derived so that the model checker can be used to generate test cases that increase the coverage provided by the test suite. A major benefit of the presented approach is the generation of a potentially minimal set of test cases with the confidence that every interaction between components is executed\u00a0\u2026", "num_citations": "14\n", "authors": ["543"]}
{"title": "The complexity of asynchronous model based testing\n", "abstract": " In model based testing (MBT), testing is based on a model M that typically is expressed using a state-based language such as an input output transition system (IOTS). Most approaches to MBT assume that communications between the system under test (SUT) and its environment are synchronous. However, many systems interact with their environment through asynchronous channels and the presence of such channels changes the nature of testing. In this paper we investigate the situation in which the SUT interacts with its environment through asynchronous channels and the problems of producing test cases to reach a state, execute a transition, or to distinguish two states. In addition, we investigate the Oracle Problem. All four problems are explored for both FIFO and non-FIFO channels. It is known that the Oracle Problem can be solved in polynomial time for FIFO channels but we also show that the three test\u00a0\u2026", "num_citations": "13\n", "authors": ["543"]}
{"title": "Non-local choice and implied scenarios\n", "abstract": " A number of issues, such as non-local choice and implied scenarios, that arise in Message Sequence Charts (MSCs) have been investigated in the past. However, existing research on these two issues show disagreements regarding how they are related. In this paper, we analyse the relations among existing conditions for non-local choice free and Closure Conditions (CCs) for implied scenarios. On the basis of this, we propose a new definition for non-local choice and a non-local choice free condition derived from CCs of implied scenarios. Compared to existing conditions, we argue that the new condition covers more non-local choices that satisfy the informal idea of non-local choice. We formally show that the existence of non-local choices in an MSC specification results in implied scenarios and the appearance of implied scenarios according to corresponding CCs means there are non-local choices in the\u00a0\u2026", "num_citations": "13\n", "authors": ["543"]}
{"title": "Improving test quality using robust unique input/output circuit sequences (UIOCs)\n", "abstract": " In finite state machine (FSM) based testing, the problem of fault masking in the unique input/output (UIO) sequence may degrade the test performance of the UIO based methods. This paper investigates this problem and proposes the use of a new type of unique input/output circuit (UIOC) sequence for state verification, which may help to overcome the drawbacks that exist in the UIO based techniques. When constructing a UIOC, overlap and internal state observation schema are used to increase the robustness of a test sequence. Test quality is compared by using the forward UIO method (F-method), the backward UIO method (B-method) and the UIOC method (C-method) separately. Robustness of the UIOCs constructed by the algorithm given in this paper is also compared with those constructed by the algorithm given previously. Experimental results suggest that the C-method outperforms the F- and the B-methods\u00a0\u2026", "num_citations": "13\n", "authors": ["543"]}
{"title": "Implementation relations for testing through asynchronous channels\n", "abstract": " This paper concerns testing from an input\u2013output transition system (IOTS) model of a system under test that interacts with its environment through asynchronous first in first out (FIFO) channels. It explores methods for analysing an IOTS without modelling the channels. If IOTS M produces sequence \u03c3, then, since communications are asynchronous, output can be delayed and so a different sequence might be observed. Thus, M defines a language Tr(M) of sequences that can be observed when interacting with M through FIFO channels. We define implementation relations and equivalences in terms of Tr(M): an implementation relation says how IOTS N must relate to IOTS M in order for N to be a correct implementation of M. It is important to use an appropriate implementation relation since otherwise the verdict from a test run might be incorrect and also because it influences test generation. It transpires that it is\u00a0\u2026", "num_citations": "12\n", "authors": ["543"]}
{"title": "Overcoming controllability problems in distributed testing from an input output transition system\n", "abstract": " This paper concerns the testing of a system with physically distributed interfaces, called ports, at which it interacts with its environment. We place a tester at each port and the tester at port p observes events at p only. This can lead to controllability problems, where the observations made by the tester at a port p are not sufficient for it to be able to know when to send an input. It is known that there are test objectives, such as executing a particular transition, that cannot be achieved if we restrict attention to test cases that have no controllability problems. This has led to interest in schemes where the testers at the individual ports send coordination messages to one another through an external communications network in order to overcome controllability problems. However, such approaches have largely been studied in the context of testing from a deterministic finite state machine. This paper investigates the use\u00a0\u2026", "num_citations": "12\n", "authors": ["543"]}
{"title": "A case study on the use of genetic algorithms to generate test cases for temporal systems\n", "abstract": " Generating test data for formal state based specifications is computationally expensive. In previous work we presented a framework that addressed this issue by representing the test data generation problem as an optimisation problem. In this paper we analyze a communications protocol to illustrate how the test case generation problem can be presented as a search problem and automated. Genetic algorithms (GAs) and random search are used to generate test data and evaluate the approach. GAs show to outperform random search and seem to scale well as the problem size increases. We consider a very simple fitness function that can be used with other evolutionary search techniques and automated test case generation suites.", "num_citations": "12\n", "authors": ["543"]}
{"title": "Testing timed systems modeled by stream X-machines\n", "abstract": " Stream X-machines have been used to specify real systems where complex data structures. They are a variety of extended finite state machine where a shared memory is used to represent communications between the components of systems. In this paper we introduce an extension of the Stream X-machines formalism in order to specify systems that present temporal requirements. We add time in two different ways. First, we consider that (output) actions take time to be performed. Second, our formalism allows to specify timeouts. Timeouts represent the time a system can wait for the environment to react without changing its internal state. Since timeous affect the set of available actions of the system, a relation focusing on the functional behavior of systems, that is, the actions that they can perform, must explicitly take into account the possible timeouts. In this paper we also propose a formal testing\u00a0\u2026", "num_citations": "12\n", "authors": ["543"]}
{"title": "A thread-tag based semantics for Sequence Diagrams\n", "abstract": " The sequence diagram is one of the most popular behaviour modelling languages which offers an intuitive and visual way of describing expected behaviour of object-oriented software. Much research work has investigated ways of providing a formal semantics for sequence diagrams. However, these proposed semantics may not properly interpret sequence diagrams when lifelines do not correspond to threads of controls. In this paper, we address this problem and propose a thread-tag based sequence diagram as a solution. A formal, partially ordered multiset based semantics for the thread-tag based sequence diagrams is proposed.", "num_citations": "12\n", "authors": ["543"]}
{"title": "Mutation testing using genetic algorithms: A co-evolution approach\n", "abstract": " Mutation Testing Using Genetic Algorithms: A Co-evolution Approach - Research Portal, King's College, London King's College London King's main site Research portal Home Researchers Research Groups Research Outputs Research Funding Internal Research Outputs Theses . Journals Publishers Mutation Testing Using Genetic Algorithms: A Co-evolution Approach Research output: Chapter in Book/Report/Conference proceeding \u203a Conference paper Konstantinos Adamopoulos, Mark Harman, Robert Mark Hierons Overview Citation formats Original language English Title of host publication Genetic and Evolutionary Computation Conference (GECCO 2004), LNCS 3103 Place of Publication Seattle, Washington, USA Publisher Springer Finance Pages 1338-1349 Number of pages 12 Published 2004 King's Authors Konstantinos Adamopoulos (Informatics) Mark Harman (Informatics) Post to Twitter Post to \u2026", "num_citations": "12\n", "authors": ["543"]}
{"title": "A framework for pathologies of message sequence charts\n", "abstract": " Context It is known that a Message Sequence Chart (MSC) specification can contain different types of pathology. However, definitions of different types of pathology and the problems caused by pathologies are unclear, let alone the relationships between them. In this circumstance, it can be problematic for software engineers to accurately predict the possible problems that may exist in implementations of MSC specifications and to trace back to the design problems in MSC specifications from the observed problems of an implementation. Objective We focus on generating a clearer view on MSC pathologies and building formal relationships between pathologies and the problems that they may cause. Method By concentrating on the problems caused by pathologies, a categorisation of problems that a distributed system may suffer is first introduced. We investigate the different types of problems and map them to\u00a0\u2026", "num_citations": "11\n", "authors": ["543"]}
{"title": "Canonical finite state machines for distributed systems\n", "abstract": " There has been much interest in testing from finite state machines (FSMs) as a result of their suitability for modelling or specifying state-based systems. Where there are multiple ports/interfaces a multi-port FSM is used and in testing, a tester is placed at each port. If the testers cannot communicate with one another directly and there is no global clock then we are testing in the distributed test architecture. It is known that the use of the distributed test architecture can affect the power of testing and recent work has characterised this in terms of local s-equivalence: in the distributed test architecture we can distinguish two FSMs, such as an implementation and a specification, if and only if they are not locally s-equivalent. However, there may be many FSMs that are locally s-equivalent to a given FSM and the nature of these FSMs has not been explored. This paper examines the set of FSMs that are locally s-equivalent to a\u00a0\u2026", "num_citations": "11\n", "authors": ["543"]}
{"title": "Does an 80: 20 rule apply to Java coupling?\n", "abstract": " Objective.  To explore whether an 80:20 rule exists in Java from six coupling metrics over multiple versions of open-source software and, if so, whether that relationship is exacerbated over time. Methods.  We used the automated tool JHawk to extract the 6 different coupling metrics from four Open-Source Systems. We then ranked the classes on each of these 6 coupling metrics and then analysed the top 20% of classes to see whether 80% of total coupling was contained therein. Conclusions.  Only one metric appeared consistently to have an 80:20 relationship and that was the \u2018fan-in\u2019 metric. Evidence suggests that fan-in and fan-out have a complementary relationship. We found many of the other metrics had few, if any such relationships. The RFC was typical in this sense - no 80:20 relationship was found in any of the systems or any version in those systems. We also found no evidence to support the view that over time, the 80:20 is exacerbated.", "num_citations": "11\n", "authors": ["543"]}
{"title": "Towards a computer interaction-based mood measurement instrument\n", "abstract": " The purpose of this explorative research was to explore the mood of a computer user and his or her use of keyboard and mouse. Twenty-six users (13 programmers and 13 frequent computer users) took part in the study. A background software application executing on participants\u2019 computers logged the keyboard key press and mouse click events. The correlations between moods of the participants and their use of keyboard and mouse show that it might be possible to create individual tailor made mood measures based on individuals keyboard and mouse use. The highest and lowest significant correlations found were r (63)= 0.39, p<= 0.01 and r (73)=-0.24, p<= 0.05 respectively. About 31% of participants showed significant correlations towards valence whereas about 27% showed significant correlations toward arousal. Further, the data shows that experience and self discipline might be a factor to predict people who show significant correlation between their behaviour and valence level. Similarly dutifulness might help in predicting people who show significant correlation between their behaviour and arousal level.", "num_citations": "11\n", "authors": ["543"]}
{"title": "The zero-free intervals for characteristic polynomials of matroids\n", "abstract": " Let M be a loopless matroid with rank r and c components. Let P(M, t) be the characteristic polynomial of M. We shall show that (\u22121)rP(M, t)[ges ](1\u2212t)r for t\u2208(\u2212\u221e, 1), that the multiplicity of the zeros of P(M, t) at t=1 is equal to c, and that (\u22121)r+cP(M, t)[ges ](t\u22121)r for t\u2208(1, 32/27]. Using a result of C. Thomassen we deduce that the maximal zero-free intervals for characteristic polynomials of loopless matroids are precisely (\u2212\u221e, 1) and (1, 32/27].", "num_citations": "11\n", "authors": ["543"]}
{"title": "Using Squeeziness to test component-based systems defined as Finite State Machines\n", "abstract": " Context:Testing is the main validation technique used to increase the reliability of software systems. The effectiveness of testing can be strongly reduced by Failed Error Propagation. This situation happens when the System Under Test executes a faulty statement, the state of the system is affected by this fault, but the expected output is observed. Squeeziness is an information theoretic measure designed to quantify the likelihood of Failed Error Propagation and previous work has shown that Squeeziness correlates strongly with Failed Error Propagation in white-box scenarios. Despite its usefulness, this measure, in its current formulation, cannot be used in a black-box scenario where we do not have access to the source code of the components.Objective:The main goal of this paper is to adapt Squeeziness to a black-box scenario and evaluate whether it can be used to estimate the likelihood that a component of a\u00a0\u2026", "num_citations": "10\n", "authors": ["543"]}
{"title": "A mapping study on testing non-testable systems\n", "abstract": " The terms \u201cOracle Problem\u201d and \u201cNon-testable system\u201d interchangeably refer to programs in which the application of test oracles is infeasible. Test oracles are an integral part of conventional testing techniques; thus, such techniques are inoperable in these programs. The prevalence of the oracle problem has inspired the research community to develop several automated testing techniques that can detect functional software faults in such programs. These techniques include N-Version testing, Metamorphic Testing, Assertions, Machine Learning Oracles, and Statistical Hypothesis Testing. This paper presents a Mapping Study that covers these techniques. The Mapping Study presents a series of discussions about each technique, from different perspectives, e.g. effectiveness, efficiency, and usability. It also presents a comparative analysis of these techniques in terms of these perspectives. Finally, potential\u00a0\u2026", "num_citations": "10\n", "authors": ["543"]}
{"title": "Parallel algorithms for generating distinguishing sequences for observable non-deterministic FSMs\n", "abstract": " A distinguishing sequence (DS) for a finite-state machine (FSM) is an input sequence that distinguishes every pair of states of the FSM. There are techniques that generate a test sequence with guaranteed fault detection power, and it has been found that shorter test sequences can be produced if DSs are used. Despite these benefits, however, until recently the only published DS generation algorithms have been for deterministic FSMs. This article develops a massively parallel algorithm, which can be used in Graphics Processing Units (GPUs) Computing, to generate DSs from partial observable non-deterministic FSMs. We also present the results of experiments using randomly generated FSMs and some benchmark FSMs. The results are promising and indicate that the proposed algorithm can derive DSs from partial observable non-deterministic FSMs with 32,000 states in an acceptable amount of time.", "num_citations": "10\n", "authors": ["543"]}
{"title": "Semantic mutation analysis of floating-point comparison\n", "abstract": " Semantic Mutation Testing (SMT) is a technique that aims to capture errors caused by possible misunderstandings of the semantics of a description language. This paper focuses on the use of SMT to represent possible problems caused by the use of Floating Point Comparison (FPC) since this feature of programming languages can lead to subtle errors. We describe six FPC semantic mutation operators that have been implemented in a C SMT tool. These operators mutate a C program by introducing tolerances using three different algorithms. The paper reports on the results of experiments that explored the proposed mutation operators. It was found that random test suites were not good at killing the resultant mutants, suggesting also that random test suites are poor at revealing FPC problems. We therefore devised a new approach to generate test data to kill these mutants. The manually generated test suites\u00a0\u2026", "num_citations": "10\n", "authors": ["543"]}
{"title": "A testability transformation approach for state-based programs\n", "abstract": " Search based testing approaches are efficient in test data generation; however they are likely to perform poorly when applied to programs with state variables. The problem arises when the target function includes guards that reference some of the program state variables whose values depend on previous function calls. Thus, merely considering the target function to derive test data is not sufficient. This paper introduces a testability transformation approach based on the analysis of control and data flow dependencies to bypass the state variable problem. It achieves this by eliminating state variables from guards and/ or determining which functions to call in order to satisfy guards with state variables. A number of experiments demonstrate the value of the proposed approach.", "num_citations": "10\n", "authors": ["543"]}
{"title": "Automatic generation of test sequences form EFSM models using evolutionary algorithms\n", "abstract": " Automated test data generation through evolutionary testing (ET) is a topic of interest to the software engineering community. While there are many ET-based techniques for automatically generating test data from code, the problem of generating test data from an extended finite state machine (EFSMs) is more complex and has received little attention. In this paper, we introduce a novel approach that addresses the problem of generating input test sequences that trigger given feasible paths in an EFSM model by employing an ET-based technique. The proposed approach expresses the problem as a search for input parameters to be applied to a set of functions to be called sequentially. In order to apply ET-based technique, a new fitness function is introduced to cope with the case when a test target involves calls to a set of transitions sequentially. We evaluate our approach empirically using five sets of randomly generated paths through two EFSM case studies: INRES and class 2 transport protocols. In the experiments, we apply two search techniques: a random and an ET-based which utilizes our new fitness function. Experimental results show that the proposed approach produces input test sequences that trigger all the feasible paths used with a success rate of 100%, however, the random technique failed in most cases with a success rate of 20.8%.", "num_citations": "10\n", "authors": ["543"]}
{"title": "TEA-Cloud: A Formal Framework for Testing Cloud Computing Systems\n", "abstract": " The validation of a cloud system can be complicated by the size of the system, the number of users that can concurrently request services, and the virtualization used to give the illusion of using dedicated machines. Unfortunately, it is not feasible to use conventional testing methods with cloud systems. This article proposes a framework, called TEA- Cloud , that integrates simulation with testing methods for validating cloud system designs. Testing is applied on both functional and nonfunctional aspects of the cloud, like performance and cost. The aim of the framework is to provide a complete methodology to help users to model both software and hardware parts of cloud systems and automatically test the validity of these clouds using a cost-effective approach.  Metamorphic testing  is used to overcome the lack of an  oracle  that checks whether the behavior observed in testing is allowed. Metamorphic testing is based\u00a0\u2026", "num_citations": "9\n", "authors": ["543"]}
{"title": "Passive testing with asynchronous communications\n", "abstract": " Testing is usually understood to involve the tester interacting with the studied system by supplying input and observing output. However, sometimes this active interaction is not possible and testing becomes more passive. In this setting, passive testing can be considered to be the process of checking that the observations made regarding the system satisfy certain required properties. In this paper we study a formal passive testing framework for systems where there is an asynchronous communications channel between the tester and the system. We consider a syntactic definition of a class of properties and provide a semantic representation, as automata, that take into account the different observations that we can expect due to the assumption of asynchrony. Our solution checks properties against traces in polynomial time, with a low need for storage. Therefore, our proposal is very suitable for real-time\u00a0\u2026", "num_citations": "9\n", "authors": ["543"]}
{"title": "Overcoming controllability problems with fewest channels between testers\n", "abstract": " When testing a system that has multiple physically distributed ports/interfaces it is normal to place a tester at each port. Each tester observes only the events at its port and it is known that this can lead to additional controllability problems. While such controllability problems can be overcome by the exchange of external coordination messages between the testers, this requires the deployment of an external network and may thus increase the costs of testing. The problem studied in this paper is finding a minimum number of coordination channels to overcome controllability problems in distributed testing. Three instances of this problem are considered. The first problem is to find a minimum number of channels between testers in order to overcome the controllability problems in a given test sequence to be applied in testing. The second problem is finding a minimal set of channels that allow us to overcome controllability\u00a0\u2026", "num_citations": "9\n", "authors": ["543"]}
{"title": "Thread\u2013Based Analysis of Sequence Diagrams\n", "abstract": " Sequence Diagrams (SDs) offer an intuitive and visual way of describing expected behaviour of Object Oriented (OO) software. They focus on modelling the method calls among participants of a software system at runtime. This is an essential difference from its ancestor, basic Message Sequence Charts (bMSCs), which are mainly used to model the exchange of asynchronous messages. Since method calls are regarded as synchronous messages in the Unified Modelling Language (UML) Version 2.0, synchronous messages play a significantly more important role in SDs than in bMSCs. However, the effect of this difference has not been fully explored in previous work on the semantics of SDs. One important aim of this paper is to identify the differences between SDs and bMSCs. We observe that using traditional semantics to interpret SDs may not interpret SDs correct under certain circumstances\u00a0\u2026", "num_citations": "9\n", "authors": ["543"]}
{"title": "Moods and Programmers' Performance.\n", "abstract": " We tested the impact of mood on the debugging performance of programmers. Four movie clips were used to induce programmer\u2019s mood. In the test, 72 programmers watched both a neutral video clip and one of the four mood evoking video clips and after each of these they took a debugging test. Examination of the test results revealed an almost significant effect for the arousal mood-dimension on both debug score (F (1, 70)= 3.33, p= 0.07) and on the number of questions attempted within the required time (F (1, 70)= 6.26, p= 0.015). However, no significant effect was found for the valance mood dimension. These results seem to suggest that the programmer\u2019s ability to find and correct errors in program code depends on their level of arousal.", "num_citations": "9\n", "authors": ["543"]}
{"title": "Testing from partial finite state machines without harmonised traces\n", "abstract": " This paper concerns the problem of testing from a partial, possibly non-deterministic, finite state machine (FSM) S. Two notions of correctness (quasi-reduction and quasi-equivalence) have previously been defined for partial FSMs but these, and the corresponding test generation techniques, only apply to FSMs that have harmonised traces. We show how quasi-reduction and quasi-equivalence can be generalised to all partial FSMs. We also consider the problem of generating an m-complete test suite from a partial FSM S: a test suite that is guaranteed to determine correctness as long as the system under test has no more than m states. We prove that we can complete S to form a completely-specified non-deterministic FSM S' such that any m-complete test suite generated from S' can be converted into an m-complete test suite for S. We also show that there is a correspondence between test suites that are reduced\u00a0\u2026", "num_citations": "8\n", "authors": ["543"]}
{"title": "Resolving the equivalent mutant problem in the presence of non-determinism and coincidental correctness\n", "abstract": " In this paper, we develop a new mutation testing technique called Interlocutory Mutation Testing (IMT) that mitigates the equivalent mutant problem in the presence of coincidental correctness and non-determinism. The accuracy of IMT was evaluated; it obtained a classification accuracy of 93.33\u00a0% for non-equivalent mutants and 100\u00a0% for equivalent mutants in a non-deterministic system with coincidental correctness.", "num_citations": "8\n", "authors": ["543"]}
{"title": "Using schedulers to test probabilistic distributed systems\n", "abstract": " Formal methods are one of the most important approaches to increasing the confidence in the correctness of software systems. A formal specification can be used as an oracle in testing since one can determine whether an observed behaviour is allowed by the specification. This is an important feature of formal testing: behaviours of the system observed in testing are compared with the specification and ideally this comparison is automated. In this paper we study a formal testing framework to deal with systems that interact with their environment at physically distributed interfaces, called ports, and where choices between different possibilities are probabilistically quantified. Building on previous work, we introduce two families of schedulers to resolve nondeterministic choices among different actions of the system. The first type of schedulers, which we call global schedulers, resolves nondeterministic choices\u00a0\u2026", "num_citations": "8\n", "authors": ["543"]}
{"title": "GeTeX: a tool for testing real-time embedded systems using CAN applications\n", "abstract": " Real-Time Embedded Systems (RTES) have an increasing role in controlling the IT that we use on a day-to-day basis. The behaviour of an RTES is not based solely on the interactions it might have with its surrounding environment, but also on the timing requirements it induces. As a result, ensuring that an RTES behaves correctly is non-trivial, especially after adding time as a new dimension to the complexity of the testing process. In previous research, we introduced a 'priority-based' approach which tested the logical and timing behaviour of an RTES modeled formally as UPPAAL Timed Automata (UTA). The 'priority-based' approach was based on producing sets of timed test traces by achieving timing constraints coverage according to three sets of priorities, namely boundary, out-boundary and in-boundary. In this paper, we introduce a new testing tool 'GeTeX' that deploys the \"priority-based\" testing approach\u00a0\u2026", "num_citations": "8\n", "authors": ["543"]}
{"title": "Using status messages in the distributed test architecture\n", "abstract": " If the system under test has multiple interfaces/ports and these are physically distributed then in testing we place a tester at each port. If these testers cannot directly communicate with one another and there is no global clock then we are testing in the distributed test architecture. If the distributed test architecture is used then there may be input sequences that cannot be applied in testing without introducing controllability problems. Additionally, observability problems can allow fault masking. In this paper we consider the situation in which the testers can apply a status message: an input that causes the system under test to identify its current state. We show how such a status message can be used in order to overcome controllability and observability problems.", "num_citations": "8\n", "authors": ["543"]}
{"title": "Extending stream X-machines to specify and test systems with timeouts\n", "abstract": " Stream X-machines are a kind of extended finite state machine used to specify real systems where communication between the components is modeled by using a shared memory.In this paper we introduce an extension of the Stream X-machines formalism in order to specify delays/timeouts.The time spent by a system waiting for the environment to react has the capability of affecting the set of available outputs of the system. So, a relation focusing on functional aspects must explicitly take into account the possible timeouts.We also propose a formal testing methodology allowing to systematically test a system with respect to a specification. Finally, we introduce a test derivation algorithm. Given a specification, the derived test suite is sound and complete, that is, a system under test successfully passes the test suite if and only if this system conforms to the specification.", "num_citations": "8\n", "authors": ["543"]}
{"title": "-branching UIO sequences for partially specified observable non-deterministic FSMs\n", "abstract": " In black-box testing, test sequences may be constructed from systems modelled as deterministic finite-state machines (DFSMs) or, more generally, non-deterministic observable finite state machines (NOFSMs). Test sequences usually contain state identification sequences, with unique input output sequences (UIOs) often being used with DFSMs. This paper extends the notion of UIOs to NOFSMs. One challenge is that, as a result of non-determinism, the application of an input sequence can lead to exponentially many expected output sequences. To address this scalability problem, we introduce   UIOs: UIOs that lead to at most K output sequences from states of M. We show that checking   UIO existence is PSPACE-Complete if the problem is suitably bounded; otherwise it is in EXPSPACE and PSPACE-Hard. We provide a massively parallel algorithm for constructing   UIOs and the results of experiments on\u00a0\u2026", "num_citations": "7\n", "authors": ["543"]}
{"title": "Checking experiments for stream X-machines\n", "abstract": " Stream X-machines are a state based formalism that has associated with it a particular development process in which a system is built from trusted components. Testing thus essentially checks that these components have been combined in a correct manner and that the orders in which they can occur are consistent with the specification. Importantly, there are test generation methods that return a checking experiment: a test that is guaranteed to determine correctness as long as the implementation under test (IUT) is functionally equivalent to an unknown element of a given fault domain \u03a8. Previous work has show how three methods for generating checking experiments from a finite state machine (FSM) can be adapted to testing from a stream X-machine. However, there are many other methods for generating checking experiments from an FSM and these have a variety of benefits that correspond to different testing\u00a0\u2026", "num_citations": "7\n", "authors": ["543"]}
{"title": "The \u2018deception\u2019of code smells: An empirical investigation\n", "abstract": " Code smells represent code decay and as such should be eradicated from a system to prevent future maintenance problems. A range of twenty smells described by Fowler and Beck each require varying numbers and combinations of refactorings in order to be eradicated - but exactly how many are needed when we consider related, nested refactorings is unclear. In this paper, we enumerate these refactorings when categorised according to Mantyla's smell taxonomy. We then show how, ironically, the `smelliest' of smells (and hence most difficult to eradicate) are actually those best understood by developers. So, code smells are not only unpleasant to have around but are deceptive in their nature and make-up. The study is thus a warning against attempting what are seemingly easily eradicated smells - these are often the smells the developer needs to be most wary of.", "num_citations": "7\n", "authors": ["543"]}
{"title": "Bayesian inference and optimal release times for two software failure models\n", "abstract": " We carry out Bayesian inference for the Jelinski-Moranda and Littlewood software failure models given asampIe of failure times. Furthermore, we illustrate how to assess the optimal length of an additional pre-release testing period undereach of these models. Modern Bayesian computational methods are used to estimate the posterior expected utility of testing for and additional time.", "num_citations": "7\n", "authors": ["543"]}
{"title": "Using formal specifications to enhance the software testing process.\n", "abstract": " British Library EThOS: Using formal specifications to enhance the software testing process. New search | Advanced search | Search results Login / Register | About | Help | FAQ | Follow dividing line Use this URL to cite or link to this record in EThOS: https://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.315529 Title: Using formal specifications to enhance the software testing process. Author: Hierons, Robert M. ISNI: 0000 0001 3556 0305 Awarding Body: Brunel University Current Institution: Brunel University Date of Award: 1992 Availability of Full Text: Full text unavailable from EThOS. Please contact the current institution\u2019s library for further details. Abstract: No abstract available Supervisor: Not available Sponsor: Not available Qualification Name: Thesis (Ph.D.) Qualification Level: Doctoral EThOS ID: uk.bl.ethos.315529 DOI: Not available Keywords: Computer software & programming Share: Terms and Conditions | \u2026", "num_citations": "7\n", "authors": ["543"]}
{"title": "Normalised squeeziness and failed error propagation\n", "abstract": " Failed Error Propagation (FEP) can reduce test effectiveness and recent work proposed an information theoretic measure, Squeeziness, as the theoretical basis for avoiding FEP. This paper demonstrates that Squeeziness is not suitable for comparing programs with different input domains. We then extend Squeeziness to Normalised Squeeziness and demonstrate that this is more generally useful.", "num_citations": "6\n", "authors": ["543"]}
{"title": "A suspension-trace semantics for CSP\n", "abstract": " CSP is well established as a process algebra for refinement. Most refinement relations for CSP do not differentiate between inputs and outputs, and so are unsuitable for testing. This paper provides CSP with a denotational semantics based on suspension traces; it gives the traditional CSP operators a novel view, catering for the differences between inputs and outputs. We identify healthiness conditions for the suspension-traces model and include a treatment of termination not contemplated in the context of input-output labelled transition systems. Using our suspension-traces semantics, we provide for CSP a characterisation of the conformance relation ioco, which is widely used in testing. Finally, we propose a strategy to mechanise the verification of conformance according to ioco and suspension-trace refinement using CSP tools. This work provides the basis for a theory of testing for CSP with inputs and outputs\u00a0\u2026", "num_citations": "6\n", "authors": ["543"]}
{"title": "Decidability and complexity for quiescent consistency\n", "abstract": " Quiescent consistency is a notion of correctness for a concurrent object that gives meaning to the object's behaviours in quiescent states, i.e., states in which none of the object's operations are being executed. The condition enables greater flexibility in object design by allowing more behaviours to be admitted, which in turn allows the algorithms implementing quiescent consistent objects to be more efficient (when executed in a multithreaded environment).Quiescent consistency of an implementation object is defined in terms of a corresponding abstract specification. This gives rise to two important verification questions: membership (checking whether a behaviour of the implementation is allowed by the specification) and correctness (checking whether all behaviours of the implementation are allowed by the specification). In this paper, we consider the membership and correctness conditions for quiescent\u00a0\u2026", "num_citations": "6\n", "authors": ["543"]}
{"title": "Conformance relations for distributed testing based on CSP\n", "abstract": " CSP is a well established process algebra that provides comprehensive theoretical and practical support for refinement-based design and verification of systems. Recently, a testing theory for CSP has also been presented. In this paper, we explore the problem of testing from a CSP specification when observations are made by a set of distributed testers. We build on previous work on input-output transition systems, but the use of CSP leads to significant differences, since some of its conformance\u00a0(refinement) relations consider failures as well as traces. In addition, we allow events to be observed by more than one tester. We show how the CSP notions of refinement can be adapted to distributed testing. We consider two contexts:\u00a0when the testers are entirely independent and when they can cooperate. Finally, we give some preliminary results on test-case generation and the use of coordination messages.", "num_citations": "6\n", "authors": ["543"]}
{"title": "Package evolvability and its relationship with refactoring\n", "abstract": " In this paper, we address a set of research questions investigating trends in changes to an open-source system (OSS). An interesting \u00e2peak and trough\u00e2 effect trend was found to exist in the system studied, suggesting that developer activity comprises of a set of high and low periods. Trends in overall changes applied to the system were complemented with empirical evidence in refactoring data for the same system; this showed a similar peak and trough effect but at different versions of the same system. This result suggests a contrasting motivation between regular maintenance practice and that of refactoring. Our analysis of high-level package trends informed some interesting cross-comparisons with refactoring practice, and some insights into why refactoring might be applied after a burst of regular change activity, rather than consistently. We use data extracted from seven Java OSS as a basis for our refactoring analysis.", "num_citations": "6\n", "authors": ["543"]}
{"title": "Applications of linear program schematology in dependence analysis\n", "abstract": " Applications of linear program schematology in dependence analysis - Goldsmiths Research Online Research Online Research Online Logo Goldsmiths - University of London Login Menu Applications of linear program schematology in dependence analysis Tools + Tools Danicic, Sebastian; Harman, Mark; Hierons, Robert; Howroyd, John; Laurence, Michael and Danicic, Sebastian. 2004. 'Applications of linear program schematology in dependence analysis'. In: 1st International Workshop on Programming Language Interference and Dependence. Verona, Italy. [Conference or Workshop Item] No full text available Item Type: Conference or Workshop Item (Paper) Departments, Centres and Research Units: Computing Dates: Date Event August 2004 [\"eprint_fieldopt_dates_date_type_shown\" not defined] Event Location: Verona, Italy Item ID: 15231 Date Deposited: 02 Dec 2015 16:05 Last Modified: 13 Jun 2016 12:\u2026", "num_citations": "6\n", "authors": ["543"]}
{"title": "ConSIT: A conditioned program slicer\n", "abstract": " Conditioned slicing is a powerful generalisation of static and dynamic slicing which has applications to many problems in software maintenance and evolution, including re-use, reengineering and program comprehension. However, there has been relatively little work on the implementation of conditioned slicing. Algorithms for implementing conditioned slicing necessarily involve reasoning about the values of program predicates in certain sets of states derived from the conditioned slicing criterion, making implementation particularly demanding. This paper introduces ConSIT, a conditional slicing system which is based upon conventional static slicing, symbolic execution and theorem proving. ConSIT is the first fully automated implementation of conditioned slicing. 1.", "num_citations": "6\n", "authors": ["543"]}
{"title": "FSM quasi-equivalence testing via reduction and observing absences\n", "abstract": " There has been significant interest in automatically generating test cases from a non-deterministic finite state machine (FSM). Most approaches check that the behaviours of the system under test (SUT) are allowed by the specification FSM; they therefore test for reduction. However, sometimes one wants all of the behaviours, and so features, of the specification to be implemented and then one is testing for equivalence. In this paper we first note that in order to test for equivalence one must effectively be able to observe the SUT not being able to produce an output y in response to an input x after trace \u03c3\u00af; we model this as the absence of an output. We prove that the problem of testing for equivalence to FSM M can be mapped to testing for reduction to an FSM R (M) that extends M with absences. Thus, one can use techniques developed for testing for reduction when testing for equivalence. We then consider the case\u00a0\u2026", "num_citations": "5\n", "authors": ["543"]}
{"title": "Constraint-based oracles for timed distributed systems\n", "abstract": " This paper studies the situation in which the system under test and the system model are distributed and have the same structure; they have corresponding remote components that communicate asynchronously. In testing, a component with interface  has its own local tester that interacts with  and this local tester observes a local trace consisting of inputs, outputs and durations as perceived by . An observation made in testing is thus a multi-trace: a tuple of (timed) local traces, one for each . The conformance relation for such distributed systems combines a classical unitary conformance relation for localised components and the requirement that the communication policy was satisfied. By expressing the communication policy as a constraint satisfaction problem, we were able to implement the computation of test verdicts by orchestrating localised off-line testing algorithms and the verification of\u00a0\u2026", "num_citations": "5\n", "authors": ["543"]}
{"title": "Distinguishing sequences for distributed testing: Adaptive distinguishing sequences\n", "abstract": " This paper concerns the problem of testing from a finite state machine (FSM)    modelling a system that interacts with its environment at multiple physically distributed interfaces, called ports. We assume that the distributed test architecture is used: there is a local tester at each port, the tester at port    only observes events at    and the testers do not interact during testing. This paper formalizes the notion of an adaptive test strategy and what it means for an adaptive test strategy to be controllable. We provide algorithms to check whether a global strategy is controllable and to generate a controllable adaptive distinguishing sequence (ADS). We prove that controllable ADS existence is PSPACE-Hard and that the problem of deciding whether    has a controllable ADS with length    is NP-Hard. In practice, there is likely to be a polynomial upper bound on the length of ADS in which we are interested and for this case\u00a0\u2026", "num_citations": "5\n", "authors": ["543"]}
{"title": "A more precise implementation relation for distributed testing\n", "abstract": " There has been significant interest in distributed testing from an input\u2013output transition system. Previous work introduced an implementation relation    that was defined in terms of an equivalence relation on traces (sequences of observations). This paper considers an alternative approach in which an observation made in testing is a tuple of local traces, one for each tester. This paper defines such an implementation relation    in terms of the possible observations regarding the system under test and the specification. It shows that    is strictly weaker than    but is equivalent to    if processes cannot be output-divergent. Interestingly, this shows that the previous definition of    is too strong for output-divergent processes. We also prove that the Oracle problem is NP-complete but can be solved in polynomial time if there is an upper bound on the number of local testers.", "num_citations": "5\n", "authors": ["543"]}
{"title": "Test selection for traces refinement\n", "abstract": " Theories for model-based testing identify exhaustive test sets: typically infinite sets of tests whose execution establishes the conformance relation of interest. Practical techniques rely on selection strategies to identify finite subsets of these tests, and popular approaches are based on requirements to cover the model. In previous work, we have defined testing theories for refinement-based process algebra, namely, CSP and Circus, a state-rich process algebra. In this paper, we consider the selection of tests designed to establish traces refinement. In this case, conformance does not require that all traces of the model are available in the system under test, and this can raise challenges regarding coverage criteria for selection. To address these difficulties, we present a framework for formalising a variety of selection strategies. We exemplify its use in the formalisation of a selection criterion based on coverage of process\u00a0\u2026", "num_citations": "5\n", "authors": ["543"]}
{"title": "10421 Abstracts Collection--Model-Based Testing in Practice\n", "abstract": " From 17.10. to 22.10. 2010, the Dagstuhl Seminar 10421``Model-Based Testing in Practice''was held in Schloss Dagstuhl~--~ Leibniz Center for Informatics. During the seminar, several participants presented their current research, and ongoing work and open problems were discussed. Abstracts of the presentations given during the seminar as well as abstracts of seminar results and ideas are put together in this paper. The first section describes the seminar topics and goals in general. Links to extended abstracts or full papers are provided, if available.", "num_citations": "5\n", "authors": ["543"]}
{"title": "Testing a deterministic implementation against a non-controllable non-deterministic stream X-machine\n", "abstract": " A stream X-machine (SXM) is a type of extended finite state machine with an associated development approach that consists of building a system from a set of trusted components. One of the great benefits of using SXMs for the purpose of specification is the existence of test generation techniques that produce test suites that are guaranteed to determine correctness as long as certain well-defined conditions hold. One of the conditions that is traditionally assumed to hold is controllability: this insists that all paths through the SXM are feasible. This restrictive condition has recently been weakened for testing from a deterministic SXM. This paper shows how controllability can be replaced by a weaker condition when testing a deterministic system against a non-deterministic SXM. This paper therefore develops a new, more general, test generation algorithm for testing from a non-deterministic SXM.", "num_citations": "5\n", "authors": ["543"]}
{"title": "Hierons, Search algorithms for regression test case prioritization\n", "abstract": " Regression testing is an expensive, but important, process. Unfortunately, there may be insufficient resources to allow for the reexecution of all test cases during regression testing. In this situation, test case prioritization techniques aim to improve the effectiveness of regression testing by ordering the test cases so that the most beneficial are executed first. Previous work on regression test case prioritization has focused on Greedy Algorithms. However, it is known that these algorithms may produce suboptimal results because they may construct results that denote only local minima within the search space. By contrast, metaheuristic and evolutionary search algorithms aim to avoid such problems. This paper presents results from an empirical study of the application of several greedy, metaheuristic, and evolutionary search algorithms to six programs, ranging from 374 to 11,148 lines of code for three choices of fitness metric. The paper addresses the problems of choice of fitness metric, characterization of landscape modality, and determination of the most suitable search technique to apply. The empirical results replicate previous results concerning Greedy Algorithms. They shed light on the nature of the regression testing search space, indicating that it is multimodal. The results also show that Genetic Algorithms perform well, although Greedy approaches are surprisingly effective, given the multimodal nature of the landscape. Index Terms\u2014Search techniques, test case prioritization, regression testing. \u00c7 1", "num_citations": "5\n", "authors": ["543"]}
{"title": "Minimizing the cost of fault location when testing from a finite state machine\n", "abstract": " If a test does not produce the expected output, the incorrect output may have been caused by an earlier state transfer failure. Ghedamsi and coworkers generate a set of candidates and then produce further tests to locate the failures within this set. We consider a special case where there is a state identification process that is known to be correct. A number of preset and adaptive approaches to fault location are described and the problem of minimizing the cost is explored. Some of the approaches lead to NP-hard optimization problems for which possible heuristics are suggested.", "num_citations": "5\n", "authors": ["543"]}
{"title": "Implementation relations and testing for cyclic systems with refusals and discrete time\n", "abstract": " We present a formalism to represent cyclic models and study different semantic frameworks that support testing. These models combine sequences of observable actions and the passing of (discrete) time and can be used to specify a number of classes of reactive systems, an example being robotic systems. We use implementation relations in order to formally define a notion of correctness of a system under test (SUT) with respect to a specification. As usual, the aim is to devise an extension of the classical ioco implementation relation but available timed variants of ioco are not suitable for cyclic models. This paper thus defines new implementation relations that encapsulate the discrete nature of time and take into account not only the actions that models can perform but also the ones that they can refuse. In addition to defining these relations, we study a number of their properties and provide alternative\u00a0\u2026", "num_citations": "4\n", "authors": ["543"]}
{"title": "Inputs and outputs in CSP: a model and a testing theory\n", "abstract": " This article addresses refinement and testing based on CSP models, when we distinguish input and output events. In a testing experiment, the tester (or the environment) controls the inputs, and the system under test controls the outputs. The standard models and refinement relations of CSP, however, do not differentiate inputs and outputs and are not, therefore, entirely suitable for testing. Here, we consider an alphabet of events partitioned into inputs and outputs, and we present a novel refusal-testing model for CSP with a notion of input-output refusal-traces refinement. We compare that with the ioco relation often used in testing, and we find that it is more widely applicable and stronger. This means that mistakes found using traditional ioco testing do indicate mistakes in the development. Finally, we provide a CSP testing theory that takes into account inputs and outputs. With our theory, it becomes feasible to\u00a0\u2026", "num_citations": "4\n", "authors": ["543"]}
{"title": "A mechanised proof of an adaptive state counting algorithm\n", "abstract": " In this paper it is demonstrated that the capabilities of state-of-the-art proof assistant tools are sufficient to present mechanised and, at the same time, human-readable proofs establishing completeness properties of test methods and the correctness of associated test generation algorithms. To this end, the well-known Isabelle/HOL proof assistant is used to mechanically verify a complete test theory elaborated by the second author for checking the reduction conformance relation between a possibly nondeterministic finite state machine (FSM) serving as reference model and an implementation whose behaviour can also be represented by an FSM. The formalisation also helps to clarify an ambiguity in the original test generation algorithm which was specified in natural language and could be misinterpreted in a way leading to insufficient fault coverage.", "num_citations": "4\n", "authors": ["543"]}
{"title": "Testing robots using CSP\n", "abstract": " This paper presents a technique for automatic generation of tests for robotic systems based on a domain-specific notation called RoboChart. This is a UML-like diagrammatic notation that embeds a component model suitable for robotic systems, and supports the definition of behavioural models using enriched state machines that can feature time properties. The formal semantics of RoboChart is given using tock-CSP, a discrete-time variant of the process algebra CSP. In this paper, we use the example of a simple drone to illustrate an approach to generate tests from RoboChart models using a mutation tool called Wodel. From mutated models, tests are generated using the CSP model checker FDR. The testing theory of CSP justifies the soundness of the tests.", "num_citations": "4\n", "authors": ["543"]}
{"title": "An analysis of the relationship between information squeeziness and failed error propagation in software testing\n", "abstract": " Failed error propagation (FEP) is known to hamper software testing, yet it remains poorly understood. We introduce an information theoretic formulation of FEP that is based on measures of conditional entropy. This formulation considers the situation in which we are interested in the potential for an incorrect program state at statement s to fail to propagate to incorrect output. We define five metrics that differ in two ways: whether we only consider parts of the program that can be reached after executing s and whether we restrict attention to a single program path of interest. We give the results of experiments in which it was found that on average one in 10 tests suffered from FEP, earlier studies having shown that this figure can vary significantly between programs. The experiments also showed that our metrics are well-correlated with FEP. Our empirical study involved 30 programs, for which we executed a total of 7,140,000 test cases. The results reveal that the metrics differ in their performance but the Spearman rank correlation with failed error propagation is just under 0.95 for one metric and just over 0.95 for another. These strong correlations in an experimental setting in which all information about both FEP and conditional entropy is known opens up the possibility in the longer term of devising inexpensive information theory based metrics that allow us to minimise the effect of FEP.", "num_citations": "4\n", "authors": ["543"]}
{"title": "Verifying and comparing finite state machines for systems that have distributed interfaces\n", "abstract": " This paper concerns state-based systems that interact with their environment at physically distributed interfaces, called ports. When such a system is used a projection of the global trace, a local trace, is observed at each port. As a result the environment has reduced observational power: the set of local traces observed need not define the global trace that occurred. We consider the previously defined implementation relation \u2286 s  and prove that it is undecidable whether N \u2286 s  M and so it is also undecidable whether testing can distinguishing two states or FSMs. We also prove that a form of model-checking is undecidable when we have distributed observations and give conditions under which N \u2286 s  M is decidable. We then consider implementation relation \u2286 s k  that concerns input sequences of length \u03ba or less. If we place bounds on \u03ba and the number of ports then we can decide N \u2286 s k  M in polynomial time but\u00a0\u2026", "num_citations": "4\n", "authors": ["543"]}
{"title": "On the computational complexity of dynamic slicing problems for program schemas\n", "abstract": " Given a program, a quotient can be obtained from it by deleting zero or more statements. The field of program slicing is concerned with computing a quotient of a program that preserves part of the behaviour of the original program. All program slicing algorithms take account of the structural properties of a program, such as control dependence and data dependence, rather than the semantics of its functions and predicates, and thus work, in effect, with program schemas. The dynamic slicing criterion of Korel and Laski requires only that program behaviour is preserved in cases where the original program follows a particular path, and that the slice/quotient follows this path. In this paper we formalise Korel and Laski's definition of a dynamic slice as applied to linear schemas, and also formulate a less restrictive definition in which the path through the original program need not be preserved by the slice. The less\u00a0\u2026", "num_citations": "4\n", "authors": ["543"]}
{"title": "The precursor to an industrial software metrics program\n", "abstract": " A common reason for why software metric programs dasiafailpsila is through lack of participant support and commitment. In this paper, we describe the results of a study which examined the knowledge that subjects had and the opinions they had formed of previous metrics initiatives in the same organization. The research was undertaken by one of the authors as a precursor to a planned metrics initiative in the same large, UK-based company. The study attempted to understand the likely issues that would have to be addressed by that planned metrics program. A key theme to emerge from the analysis was the importance of all participants being aware of the program objectives, and the purpose and use of the data being collected. As part of the analysis, the study also draws on the role that \"timely\" involvement plays within a metrics program and how that can influence its associated practicalities.", "num_citations": "4\n", "authors": ["543"]}
{"title": "Reducing the cost of applying adaptive test cases\n", "abstract": " The testing of a state-based system may involve the application of a number of adaptive test cases. Where the implementation under test (IUT) is deterministic, the response of the IUT to some adaptive test case \u03b31 could be capable of determining the response of the IUT to another adaptive test case \u03b32. Thus, the expected cost of applying a set of adaptive test cases depends upon the order in which they are applied. This paper explores properties of adaptive test cases and considers the problem of finding an order of application of the elements from some set of adaptive test cases, which minimises the expected cost of testing.", "num_citations": "4\n", "authors": ["543"]}
{"title": "Distinguishing Sequences for Distributed Testing: Preset Distinguishing Sequences\n", "abstract": " There has been long-standing interest in automatically generating test sequences from a finite state machine (FSM) and more recently this has been extended to the case where there are multiple physically distributed testers and so we are testing from a multi-port FSM. This paper explores the problem of generating a controllable preset distinguishing sequence (PDS) from a multi-port FSM, motivated by the fact that many FSM-based test generation algorithms use PDSs. We prove that it is generally undecidable whether a multi-port FSM has a controllable PDS but provide a class of multi-port FSMs for which the problem is decidable. We also consider the important case where there is an upper bound \u2113 on the length of PDSs of interest, proving that controllable PDS existence is PSPACE-hard and in EXPSPACE. In practice the upper bound \u2113 is likely to be a polynomial in terms of the size of the multi-port FSM\u00a0\u2026", "num_citations": "3\n", "authors": ["543"]}
{"title": "Controllability through nondeterminism in distributed testing\n", "abstract": " If the system under test interacts with its environment at physically distributed ports, there is a separate independent tester at each port, and there is no global clock then we are testing in the distributed test architecture. It is known that the distributed test architecture can lead to additional controllability problems in which a tester cannot know when to send an input and this has led to most test generation techniques aiming to produce controllable test cases. However, there may be no controllable test case that achieves a given objective. This paper introduces the notion of a test section, in which each tester has a fixed input sequence to apply and there is no attempt to synchronise the testers. It defines the notion of a test section being convergent and shows how convergent test sections can be used as the basis of a less restrictive form of controllability.", "num_citations": "3\n", "authors": ["543"]}
{"title": "The dreaded desk reject\n", "abstract": " After months of carefully developing a paper, one submits it to a journal and 2 weeks later it is rejected without review (a \u2018desk reject\u2019). Most of us have experienced this scenario; I certainly have. What has happened, and why? Unfortunately, the \u2018desk reject\u2019is part of the journal editor\u2019s job, and I suspect most do not enjoy it. Papers are desk rejected for three main reasons. The first is simply that the paper does not fit with the journal\u2019s scope. The second is that the paper appears to have deficiencies that mean that it is not worth sending out to review. This might be a result of weaknesses in the research or in the presentation (usually the standard of English). With both reasons, all benefit from the decision: reviewer time is saved, and authors receive faster feedback. The final reason is plagiarism, which was the topic of a previous editorial. Authors can do certain things to make a desk reject less likely. Does the research\u00a0\u2026", "num_citations": "3\n", "authors": ["543"]}
{"title": "Controllability problems in MSC-based testing\n", "abstract": " In testing systems with distributed interfaces/ports, we may place a separate tester at each port. It is known that this approach can introduce controllability problems which have received much attention in testing from finite state machines. Message sequence charts (MSCs) form an alternative, commonly used, language for modelling distributed systems. However, controllability problems in testing from MSCs have not been thoroughly investigated. In this paper, controllability problems in MSC test cases are analysed with three notions of observability: local, tester and global. We identify two types of controllability problem in MSC-based testing. It transpires that each type of controllability problem is related to a type of MSC pathology. Controllability problems of timing are caused by races but not every race causes controllability problems; controllability problems of choice are caused by non-local choices and not\u00a0\u2026", "num_citations": "3\n", "authors": ["543"]}
{"title": "Complexity of data dependence problems for program schemas with concurrency\n", "abstract": " The problem of deciding whether one point in a program is data dependent upon another is fundamental to program analysis and has been widely studied. In this article we consider this problem at the abstraction level of program schemas in which computations occur in the Herbrand domain of terms and predicate symbols, which represent arbitrary predicate functions, are allowed. Given a vertex l in the flowchart of a schema S having only equality (variable copying) assignments, and variables v, w, we show that it is PSPACE-hard to decide whether there exists an execution of a program defined by S in which v holds the initial value of w at at least one occurrence of l on the path of execution, with membership in PSPACE holding provided there is a constant upper bound on the arity of any predicate in S. We also consider the \u2018dual\u2019 problem in which v is required to hold the initial value of w at every occurrence of l\u00a0\u2026", "num_citations": "3\n", "authors": ["543"]}
{"title": "A Longitudinal Study of Fan-In and Fan-Out Coupling in Open-Source Systems\n", "abstract": " Excessive coupling between object-oriented classes is widely acknowledged as a maintenance problem that can result in a higher propensity for faults in systems and a \u2018stored up\u2019future problem. This paper explores the relationship between \u2018fan-in\u2019and \u2018fan-out\u2019coupling metrics over multiple versions of open-source software. More specifically, the relationship between the two metrics is explored to determine patterns of growth in each over the course of time. The JHawk tool was used to extract the two metrics from five open-source systems. Results show a wide range of traits in the classes to explain both high and low levels of fan-in and fan-out. Evidence was also found of certain \u2018key\u2019classes (with both high fan-in and fan-out) and \u2018client\u2019and \u2018server\u2019-type classes with high fan-out and fan-in, respectively. This paper provides an explanation of the composition and existence of such classes as well as for\u00a0\u2026", "num_citations": "3\n", "authors": ["543"]}
{"title": "Creating adaptive sequences with genetic algorithms to reach a certain state in a non-deterministic FSM\n", "abstract": " This paper aims to construct an evolutionary system, based on genetic algorithms, to solve the problem of univocally reaching a target state in a non-deterministic Finite State Machine. Our approach proposes the creation of an adaptive sequence, which is a tree of input and outputs that contains the possible behaviors of the non-deterministic Finite State Machine, through a Genetic Algorithm. Essentially, we will characterize the DNA of the individuals as an adaptive sequence and allow the population to evolve until a solution is found. To assure the validity of our approach, we compare it with other methodologies such as hillclimbing and random. We show that the Genetic Algorithm obtains a higher rate of success in creating the adaptive sequences.", "num_citations": "3\n", "authors": ["543"]}
{"title": "Decidability of strong equivalence for subschemas of a class of linear, free, near-liberal program schemas\n", "abstract": " Abstract program schema defines a class of programs, all of which have identical statement structure, but whose functions and predicates may differ. A schema thus defines an entire class of programs according to how its symbols are interpreted. Two schemas are strongly equivalent if they always define the same function from initial states to final states for every interpretation. A subschema of a schema is obtained from a schema by deleting some of its statements. A schema S is liberal if there exists an initial state in the Herbrand domain such that the same term is not generated more than once along any executable path through S. In this paper, we introduce near-liberal schemas, in which this non-repeating condition applies only to terms not having the form g () for a constant function symbol g. Given a schema S that is linear (no function or predicate symbol occurs more than once in S) and a variable v, we\u00a0\u2026", "num_citations": "3\n", "authors": ["543"]}
{"title": "Practitioner-based measurement: a collaborative approach\n", "abstract": " Introduction The established philosophy within the software development industry is that an organization implementing a program to improve software quality can expect to recoup the cost of the implementation many times over through the reduced cost associated with improvements in quality. Measurement initiatives are perceived to provide a key contribution to quality improvement as evidenced by the focus of early measurement based initiatives and the place of measurement in the higher echelons of process initiatives. In general, organizations pursue measurement initiatives from a perspective that, without measurement, control is not possible. While organizations recognize that there are potential benefits to measuring their processes and products, however, they typically find it difficult to structure ad-hoc measures into a formal program -- a situation that is compounded by the significant cost of implementing\u00a0\u2026", "num_citations": "3\n", "authors": ["543"]}
{"title": "An Empirical Study of \u201cRemoved\u201d Classes in Java Open-Source Systems\n", "abstract": " Coupling is an omni-present and necessary feature of OO systems; ideally, classes with excessive coupling should be either refactored and/or removed from the system. However, a problem that immediately arises is the practical difficulty of effecting the removal of such classes due to the many coupling dependencies they have; it is often easier to leave classes where they are and \u2018work around\u2019 the problem. In this paper, we describe empirical coupling and size data of classes removed from multiple versions of four open-source systems. We investigated three related, research questions. First, does the amount of coupling influence the choice of removed class? Second, does class size play a role in that choice? Finally, is there a relationship between the frequency with which a class is changed and its point of removal from a system? Results showed a strong tendency for classes with low \u2018fan-in\u2019 and \u2018fan-out\u00a0\u2026", "num_citations": "3\n", "authors": ["543"]}
{"title": "A search-based technique for testing from extended finite state machine model\n", "abstract": " Extended finite state machines (EFSMs), and languages such as state-charts that are similar to EFSMs, are widely used to model state-based systems. When testing from an EFSM M it is common to aim to produce a set of test sequences (input sequences) that satisfies a test criterion that relates to the transition paths (TPs) of M that are executed by the test sequences. For example, we might require that the set of TPs triggered includes all of the transitions of M. One approach to generating such a set of test sequences is to split the problem into two stages: choosing a set of TPs that achieves the test criterion and then producing test sequences to trigger these TPs. However, the EFSM may contain infeasible TPs and the problem of generating a test sequence to trigger a given feasible TP (FTP) is generally uncomputable. In this paper we present a search-based approach that uses two techniques: (1) A TP fitness metric based on our previous work that estimates the feasibility of a given transition path; and (2) A fitness function to guide the search for a test sequence to trigger a given FTP. We evaluated our approach on five EFSMs: A simple in-flight safety system; a class II transport protocol; a lift system; an ATM; and the Inres initiator. In the experiments the proposed approach successfully tested approximately 96.75 % of the transitions and the proposed test sequence generation technique triggered all of the generated FTPs.", "num_citations": "3\n", "authors": ["543"]}
{"title": "Testing in the distributed test architecture\n", "abstract": " Some systems interact with their environment at a number of physically distributed interfaces/ports and when testing such a system it is normal to place a local tester at each port. If the local testers cannot interact with one another and there is no global clock then we are testing in the distributed test architecture and this can introduce additional controllability and observability problems. While there has been interest in test generation algorithms that overcome controllability and observability problems, such algorithms lack generality since controllability and observability problems cannot always be overcome. In addition, traditionally only deterministic systems and models have been considered despite distributed systems often being non-deterministic. This paper describes recent work that characterized the power of testing in the distributed test architecture in the context of testing from a deterministic finite state\u00a0\u2026", "num_citations": "3\n", "authors": ["543"]}
{"title": "Using mutual information to test from Finite State Machines: Test suite selection\n", "abstract": " Context:Mutual Information is an information theoretic measure designed to quantify the amount of similarity between two random variables ranging over two sets. In this paper, we adapt this concept and show how it can be used to select a good test suite to test from a Finite State Machine (FSM) based on a maximise diversity approach.Objective:The main goal of this paper is to use Mutual Information in order to select test suites to test from FSMs and evaluate whether we obtain better results, concerning the quality of the selected test suite, than current state-of-the-art measures.Method:First, we defined our scenario. We considered the case where we receive two (or more) test suites and we have to choose between them. We were interested in this scenario because it is a recurrent case in regression testing. Second, we defined our notion based on Mutual Information: Biased Mutual Information. Finally, we carried\u00a0\u2026", "num_citations": "2\n", "authors": ["543"]}
{"title": "A partial oracle for uniformity statistics\n", "abstract": " This paper investigates the problem of testing implementations of uniformity statistics. In this paper, we used metamorphic testing to address the oracle problem of checking the output of one or more test executions, for uniformity statistics. We defined a partial oracle that uses regression analysis (a regression model\u2013based metamorphic relation). We investigated the effectiveness of our partial oracle. We found that the technique can achieve mutation scores ranging from 77.78 to 100% and tends towards higher mutation scores in this range. These results are promising and suggest that the regression model\u2013based metamorphic relation approach is a viable method of alleviating the oracle problem in implementations of uniformity statistics, and potentially other classes of statistics, e.g. correlation statistics.", "num_citations": "2\n", "authors": ["543"]}
{"title": "Test and production classes of an industrial c# system: a refactoring and fault perspective\n", "abstract": " In a unit testing environment, understanding the relationship between production classes and test classes has implications for overall maintenance and hence systems development costs. Equally, the fault-proneness of each type may have a similar influence on the level or required maintenance. In this paper, we explore two aspects of the differences between test and production classes in a commercial C# system. From a refactoring perspective, a bespoke tool was used to extract fifteen types of refactoring from the system over a period of twelve months. Two research issues were then explored. Firstly, on the overlap and correspondence between refactorings applied to each class type (whether test or production). Secondly, when refactorings were undertaken in each type of class, we explored evolutionary refactoring trends as a means of understanding this issue.", "num_citations": "2\n", "authors": ["543"]}
{"title": "A new test framework for communications-critical large scale systems\n", "abstract": " Today's large-scale systems couldn't function without the reliable availability of a range of network communications capabilities. Software, hardware, and communications technologies have been advancing throughout the past two decades. However, the methods that industry commonly uses to test large-scale systems that incorporate critical communications interfaces haven't kept pace. The need exists for a specifically tailored framework to achieve effective, precise testing of communications-critical large-scale systems. A proposed test framework offers an alternative to the current generic approaches that lead to inefficient, costly testing in industry. A case study illustrates its benefits, which can also be realized with other comparable systems.", "num_citations": "2\n", "authors": ["543"]}
{"title": "Experimental comparison of different techniques to generate adaptive sequences\n", "abstract": " The focus of this paper is to present the results of a set of experiments regarding the construction of an adaptive sequence by a genetic algorithm and other techniques in order to reach a goal state in a non-deterministic finite state machine.", "num_citations": "2\n", "authors": ["543"]}
{"title": "Correction to: Reduced length checking sequences\n", "abstract": " This paper describes corrections to a previous paper, Reduced Length Checking Sequecnes, that appeared in IEEE Transactions on Computers in 2002 (51 9, pp. 1111-1117).", "num_citations": "2\n", "authors": ["543"]}
{"title": "A search-based technique for automatic test generation from an extended finite state machine\n", "abstract": " Extended finite state machines (EFSMs), and languages such as state-charts that are similar to EFSMs, are widely used to model state-based systems. When testing from an EFSM M it is common to aim to produce a set of test sequences (input sequences) that satisfies a test criterion that relates to the transition paths (TPs) of M that are executed by the test sequences. For example, we might require that the set of TPs triggered includes all of the transitions of M. One approach to generating such a set of test sequences is to split the problem into two stages: choosing a set of TPs that achieves the test criterion and then producing test sequences to trigger these TPs. However, the EFSM may contain infeasible TPs and the problem of generating a test sequence to trigger a given feasible TP (FTP) is generally uncomputable. In this paper we present a search-based approach that uses two techniques:(1) A TP fitness metric based on our previous work that estimates the feasibility of a given transition path; and (2) A fitness function to guide the search for a test sequence to trigger a given FTP. We evaluated our approach on five EFSMs: A simple in-flight safety system; a class II transport protocol; a lift system; an ATM; and the Inres initiator. In the experiments the proposed approach successfully tested approximately 96.75% of the transitions and the proposed test sequence generation technique triggered all of the generated FTPs.", "num_citations": "2\n", "authors": ["543"]}
{"title": "Using partial models to support the testing of distributed systems\n", "abstract": " This paper considers the problem of testing the communication between components of a timed distributed software system. We assume that communication is specified using timed interface automata. One of the practical issues with such systems is that components might be of reasonable size and complexity, whereas the system as a product of its components is not. Test sequences can be generated from such a state-based specification of a distributed system, possibly to achieve a concrete test coverage goal. However, we may have to apply test sequences many times in order to provoke sporadic failures that may occur as a consequence of the system's calibration, eg throughput, communication load, processor load, or memory usage. In order to cope with these problems we automatically derive a Markov chain model from a given set of test sequences and use this test-model to direct testing. We introduce an algorithm for generating a test-model from a set of sequences of use in such a way that each test sequence is a trace of the test-model and the testmodel may contain additional traces. We demonstrate that the presented approach increases test effectiveness regarding sporadically occurring failures and through additionally covered uses of the system. Furthermore, we argue that this approach can form part of an iterative integration process for distributed software systems. A major benefit of the presented approach lies in its applicability and scalability to large distributed systems, since the complexity of partial model generation depends only on the number and length of test sequences used.", "num_citations": "2\n", "authors": ["543"]}
{"title": "A flexible environment to evaluate state-based test techniques\n", "abstract": " In this position paper we argue that the presence of a flexible test environment, that allows the rapid prototyping of test techniques, would facilitate empirical research in software testing. Such an environment could be combined with a set of benchmark systems and specifications in order to allow researchers to rapidly prototype and evaluate new techniques. In this paper we focus on some of the requirements for a description language to be used by such an environment.", "num_citations": "2\n", "authors": ["543"]}
{"title": "Test case generation for agent-based models: A systematic literature review\n", "abstract": " Context:Agent-based models play an important role in simulating complex emergent phenomena and supporting critical decisions. In this context, a software fault may result in poorly informed decisions that lead to disastrous consequences. The ability to rigorously test these models is therefore essential.Objective:Our objective is to summarise the state-of-the-art techniques for test case generation in agent-based models and identify future research directions.Method:We have conducted a systematic literature review in which we pose five research questions related to the key aspects of test case generation in agent-based models: What are the information artifacts used to generate tests? How are these tests generated? How is a verdict assigned to a generated test? How is the adequacy of a generated test suite measured? What level of abstraction of an agent-based model is targeted by a generated test\u00a0\u2026", "num_citations": "1\n", "authors": ["543"]}
{"title": "An Implementation Relation for Cyclic Systems with Refusals and Discrete Time\n", "abstract": " This paper explores a particular type of model, a cyclic model, in which there are sequences of observable actions separated by discrete time intervals, introduces a novel implementation relation and studies some properties of this relation. Implementation relations formalise what it means for an unknown model of the system under test (SUT) to be a correct implementation of a specification. Many implementation relations are variants of the well known ioco implementation relation, and this includes several timed versions of ioco. It transpires that the timed variants of ioco are not suitable for cyclic models. Our implementation relation encapsulates the discrete nature of time in cyclic models and takes into account not only the actions that models can perform but also the ones that they can refuse at each point of time. We prove that our implementation relation is a conservative extension of trace containment\u00a0\u2026", "num_citations": "1\n", "authors": ["543"]}
{"title": "Decidability and complexity for quiescent consistency and its variations\n", "abstract": " Quiescent consistency is a notion of correctness for a concurrent object that gives meaning the object's behaviour in its quiescent states. This paper shows that the membership problem for quiescent consistency is NP-complete and that the correctness problem is decidable, but coNEXPTIME-complete. We consider restricted versions of quiescent consistency by assuming an upper limit on the number of events between two quiescent points. Here, we show that the membership problem is in PTIME, whereas correctness is PSPACE-complete.We also consider quiescent sequential consistency, which strengthens quiescent consistency with an additional sequential consistency condition. We show that the unrestricted versions of membership and correctness are NP-complete and undecidable, respectively. When placing a limit on the number of events between two quiescent points, membership is in PTIME, while\u00a0\u2026", "num_citations": "1\n", "authors": ["543"]}
{"title": "The oracle problem when testing from MSCs\n", "abstract": " Message sequence charts (MSCs) form a popular language in which scenario-based specifications and models can be written. There has been significant interest in automating aspects of testing from MSCs. This paper concerns the Oracle Problem, in which we have an observation made in testing and wish to know whether this is consistent with the specification. We assume that there is an MSC specification and consider the case where we have entirely independent local testers (local observability) and where the observations of the local testers are logged and brought together (tester observability). It transpires that, under local observability, the Oracle Problem can be solved in low-order polynomial time if we use sequencing, loops and choices, but becomes NP-complete if we also allow parallel components; if we place a bound on the number of parallel components, then it again can be solved in polynomial\u00a0\u2026", "num_citations": "1\n", "authors": ["543"]}
{"title": "Augmenting sequence enumeration with string-rewriting for requirements analysis and behavioral specification\n", "abstract": " Sequence enumeration is a method for deriving a system model based on informal requirements. Under sequence enumeration, stimulus (input) sequences are considered in a breadth-first manner, with the expected system response to each sequence given. Not all sequences of stimuli are considered since a sequence need not be extended if either it is illegal (it cannot be applied in practice) or it can be reduced to another sequence previously considered (the sequences take the system to the same state). Sequence enumeration is mostly a manual process, which leads to a model that can be used as the basis for automation. This paper describes a method, based on string-rewriting, that automates parts of sequence enumeration. This automation has the potential to reduce both the cost and time involved in sequence enumeration but also to reduce the scope for human error. In addition to outlining this\u00a0\u2026", "num_citations": "1\n", "authors": ["543"]}
{"title": "Characterizing minimal semantics-preserving slices of predicate-linear, free, liberal program schemas\n", "abstract": " A program schema defines a class of programs, all of which have identical statement structure, but whose functions and predicates may differ. A schema thus defines an entire class of programs according to how its symbols are interpreted. A subschema of a schema is obtained from a schema by deleting some of its statements. We prove that given a schema S which is predicate-linear, free and liberal, such that the true and false parts of every if predicate satisfy a simple additional condition, and a slicing criterion defined by the final value of a given variable after execution of any program defined by S, the minimal subschema of S which respects this slicing criterion contains all the function and predicate symbols \u2018needed\u2019 by the variable according to the data dependence and control dependence relations used in program slicing, which is the symbol set given by Weiser\u2019s static slicing algorithm. Thus this algorithm\u00a0\u2026", "num_citations": "1\n", "authors": ["543"]}
{"title": "A Meta-analysis Approach to Refactoring and XP\n", "abstract": " The mechanics of seventy-two different Java refactorings are described fully in Fowler's text. In the same text, Fowler describes seven categories of refactoring, into which each of the seventy-two refactorings can be placed. A current research problem in the refactoring and XP community is assessing the likely time and testing effort for each refactoring, since any single refactoring may use any number of other refactorings as part of its mechanics and, in turn, can be used by many other refactorings. In this paper, we draw on a dependency analysis carried out as part of our research in which we identify the 'Use' and 'Used By' relationships of refactorings in all seven categories. We offer reasons why refactorings in the 'Dealing with Generalisation' category seem to embrace two distinct refactoring sub-categories and how refactorings in the 'Moving Features between Objects' category also exhibit specific characteristics\u00a0\u2026", "num_citations": "1\n", "authors": ["543"]}
{"title": "Validating our findings\n", "abstract": " If we come up with a new approach such as a new testing technique how do we know that it is any good? In other words, how do we evaluate our research? This is a surprisingly controversial topic in software testing and, indeed, in software engineering as a whole. One of the many nice things about this issue of STVR is the variety of evaluation methods used. At one extreme, the authors of the first paper formally define the problem they are aiming to solve, give two new testing methods and evaluate these by proving that they have the required properties. Naturally, a strength of this theoretical approach is that (assuming the proofs are correct!) we know that the results always hold. However, many other problems are not amenable to this method of evaluation and our other papers both use one of the main alternatives: empirical investigations. Of particular note here is the third paper whose authors replicate a\u00a0\u2026", "num_citations": "1\n", "authors": ["543"]}
{"title": "Testing in the large through the small?\n", "abstract": " We are frequently told that computer systems are becoming increasingly complex. Assuming this is the case, does this make testing more difficult? We are also told that computer systems are becoming increasingly significant. Does this make it even more important that our testing is effective? If the answer to both of these questions is \u2018yes\u2019 then we seem to have a real problem. This might help explain the results of a recent study by the National Institute of Standards and Technology [1]. This concluded that the cost to the US economy, of poor testing, was in the order of 59.5 billion dollars a year. I am sure that such problems are not restricted just to the US! So, what is the solution? If I had the answer to this question it is just possible that I would currently be in rather more luxurious surroundings. However, I hope that the contents of this issue point to one approach that can help and illustrates links between a number of\u00a0\u2026", "num_citations": "1\n", "authors": ["543"]}