{"title": "A machine-learning approach for classifying and categorizing android sources and sinks.\n", "abstract": " Today\u2019s smartphone users face a security dilemma: many apps they install operate on privacy-sensitive data, although they might originate from developers whose trustworthiness is hard to judge. Researchers have addressed the problem with more and more sophisticated static and dynamic analysis tools as an aid to assess how apps use private user data. Those tools, however, rely on the manual configuration of lists of sources of sensitive data as well as sinks which might leak data to untrusted observers. Such lists are hard to come by.We thus propose SUSI, a novel machine-learning guided approach for identifying sources and sinks directly from the code of any Android API. Given a training set of hand-annotated sources and sinks, SUSI identifies other sources and sinks in the entire API. To provide more fine-grained information, SUSI further categorizes the sources (eg, unique identifier, location information, etc.) and sinks (eg, network, file, etc.).", "num_citations": "382\n", "authors": ["270"]}
{"title": "The Soot framework for Java program analysis: a retrospective\n", "abstract": " You can write a compiler pass extending Soot, as either a BodyTransformer, for a intraprocedural analysis; or SceneTransformer, for a whole-program analysis. You choose where this pass should run by putting it in a Pack. Use Maps or attributes to share analysis results. We explicitly disallow subclassing of IR statements, based on past experience.(Mixins would be OK). To run extended Soot, you create a custom main class which calls soot. Main. main ().", "num_citations": "363\n", "authors": ["270"]}
{"title": "Temporal assertions using AspectJ\n", "abstract": " We present a runtime verification framework for Java programs. Properties can be specified in Linear-time Temporal Logic (LTL) over AspectJ pointcuts. These properties are checked during program-execution by an automaton-based approach where transitions are triggered through aspects. No Java source code is necessary since AspectJ works on the bytecode level, thus even allowing instrumentation of third-party applications. As an example, we discuss safety properties and lock-order reversal.", "num_citations": "228\n", "authors": ["270"]}
{"title": "A staged static program analysis to improve the performance of runtime monitoring\n", "abstract": " In runtime monitoring, a programmer specifies a piece of code to execute when a trace of events occurs during program execution. Our work is based on tracematches, an extension to AspectJ, which allows programmers to specify traces via regular expressions with free variables. In this paper we present a staged static analysis which speeds up trace matching by reducing the required runtime instrumentation.               The first stage is a simple analysis that rules out entire tracematches, just based on the names of symbols. In the second stage, a points-to analysis is used, along with a flow-insensitive analysis that eliminates instrumentation points with inconsistent variable bindings. In the third stage the points-to analysis is combined with a flow-sensitive analysis that also takes into consideration the order in which the symbols may execute.               To examine the effectiveness of each stage, we\u00a0\u2026", "num_citations": "151\n", "authors": ["270"]}
{"title": "Harvesting Runtime Values in Android Applications That Feature Anti-Analysis Techniques.\n", "abstract": " It is generally challenging to tell apart malware from benign applications. To make this decision, human analysts are frequently interested in runtime values: targets of reflective method calls, URLs to which data is sent, target telephone numbers of SMS messages, and many more. However, obfuscation and string encryption, used by malware as well as goodware, often not only render human inspections, but also static analyses ineffective. In addition, malware frequently tricks dynamic analyses by detecting the execution environment emulated by the analysis tool and then refraining from malicious behavior.In this work we therefore present HARVESTER, an approach to fully automatically extract runtime values from Android applications. HARVESTER is designed to extract values even from highly obfuscated state-of-the-art malware samples that obfuscate method calls using reflection, hide sensitive values in native code, load code dynamically and apply anti-analysis techniques. The approach combines program slicing with code generation and dynamic execution.", "num_citations": "142\n", "authors": ["270"]}
{"title": "Inter-procedural data-flow analysis with ifds/ide and soot\n", "abstract": " The IFDS and IDE frameworks by Reps, Horwitz and Sagiv are two general frameworks for the inter-procedural analysis of data-flow problems with distributive flow functions over finite domains. Many data-flow problems do have distributive flow functions and are thus expressible as IFDS or IDE problems, reaching from basic analyses like truly-live variables to complex analyses for problems from the current literature such as typestate and secure information-flow.", "num_citations": "132\n", "authors": ["270"]}
{"title": "Racer: Effective race detection using AspectJ\n", "abstract": " Programming errors occur frequently in large software systems, and even more so if these systems are concurrent. In the past researchers have developed specialized programs to aid programmers detecting concurrent programming errors such as deadlocks, livelocks, starvation and data races.", "num_citations": "106\n", "authors": ["270"]}
{"title": "Droidforce: Enforcing complex, data-centric, system-wide policies in android\n", "abstract": " Smartphones are nowadays used to store and process many kinds of privacy-sensitive data such as contacts, photos, and e-mails. Sensors provide access to the phone's physical location, and can record audio and video. While this is convenient for many applications, it also makes smartphones a worthwhile target for attackers providing malicious applications. Current approaches to runtime enforcement try to mitigate unauthorized leaks of confidential data. However, they are often capable of enforcing only a very limited set of policies, like preventing data leaks only within single components or monitoring access only to specific sensitive system resources. In this work, we present Droid Force, an approach for enforcing complex, data-centric, system-wide policies on Android applications. Droid Force allows users to specify fine-grained constraints on how and when which data may be processed on their phones\u00a0\u2026", "num_citations": "104\n", "authors": ["270"]}
{"title": "Finding programming errors earlier by evaluating runtime monitors ahead-of-time\n", "abstract": " Runtime monitoring allows programmers to validate, for instance, the proper use of application interfaces. Given a property specification, a runtime monitor tracks appropriate runtime events to detect violations and possibly execute recovery code. Although powerful, runtime monitoring inspects only one program run at a time and so may require many program runs to find errors. Therefore, in this paper, we present ahead-of-time techniques that can (1) prove the absence of property violations on all program runs, or (2) flag locations where violations are likely to occur. Our work focuses on tracematches, an expressive runtime monitoring notation for reasoning about groups of correlated objects. We describe a novel flow-sensitive static analysis for analyzing monitor states. Our abstraction captures both positive information (a set of objects could be in a particular monitor state) and negative information (the set is known\u00a0\u2026", "num_citations": "103\n", "authors": ["270"]}
{"title": "Collaborative runtime verification with tracematches\n", "abstract": " Perfect pre-deployment test coverage is notoriously difficult to achieve for large applications. With enough end users, many more test cases will be encountered during an application\u2019s deployment than during testing. The use of runtime verification after deployment would enable developers to detect and report on unexpected situations. Unfortunately, the prohibitive performance cost of runtime monitors prevents their use in deployed code.               In this work we study the feasibility of collaborative runtime verification, a verification approach which distributes the burden of runtime verification onto multiple users. Each user executes a partially instrumented program and therefore suffers only a fraction of the instrumentation overhead.               We focus on runtime verification using tracematches. Tracematches are a specification formalism that allows users to specify runtime verification properties via regular\u00a0\u2026", "num_citations": "95\n", "authors": ["270"]}
{"title": "Efficient hybrid typestate analysis by determining continuation-equivalent states\n", "abstract": " Typestate analysis determines whether a program violates a set of finite-state properties. Because the typestate-analysis problem is statically undecidable, researchers have proposed a hybrid approach that uses residual monitors to signal property violations at runtime. We present an efficient novel static typestate analysis that is flow-sensitive, partially context-sensitive, and that generates residual runtime monitors. To gain efficiency, our analysis uses precise, flow-sensitive information on an intra-procedural level only, and models the remainder of the program using a flow-insensitive pointer abstraction. Unlike previous flow-sensitive analyses, our analysis uses an additional backward analysis to partition states into equivalence classes. Code locations that transition between equivalent states are irrelevant and require no monitoring. As we show in this work, this notion of equivalent states is crucial to obtaining\u00a0\u2026", "num_citations": "89\n", "authors": ["270"]}
{"title": "Boomerang: Demand-driven flow-and context-sensitive pointer analysis for java\n", "abstract": " Many current program analyses require highly precise pointer information about small, tar-geted parts of a given program. This motivates the need for demand-driven pointer analyses that compute information only where required. Pointer analyses generally compute points-to sets of program variables or answer boolean alias queries. However, many client analyses require richer pointer information. For example, taint and typestate analyses often need to know the set of all aliases of a given variable under a certain calling context. With most current pointer analyses, clients must compute such information through repeated points-to or alias queries, increasing complexity and computation time for them. This paper presents Boomerang, a demand-driven, flow-, field-, and context-sensitive pointer analysis for Java programs. Boomerang computes rich results that include both the possible allocation sites of a given pointer (points-to information) and all pointers that can point to those allocation sites (alias information). For increased precision and scalability, clients can query Boomerang with respect to particular calling contexts of interest. Our experiments show that Boomerang is more precise than existing demand-driven pointer analyses. Additionally, using Boomerang, the taint analysis FlowDroid issues up to 29.4 x fewer pointer queries compared to using other pointer analyses that return simpler pointer infor-mation. Furthermore, the search space of Boomerang can be significantly reduced by requesting calling contexts from the client analysis.", "num_citations": "87\n", "authors": ["270"]}
{"title": "Tracking load-time configuration options\n", "abstract": " Many software systems are highly configurable, despite the fact that configuration options and their interactions make those systems significantly harder to understand and maintain. In this work, we consider load-time configuration options, such as parameters from the command-line or from configuration files. They are particularly hard to reason about: tracking configuration options from the point at which they are loaded to the point at which they influence control-flow decisions is tedious and error-prone, if done manually. We design and implement Lotrack, an extended static taint analysis to track configuration options automatically. Lotrack derives a configuration map that explains for each code fragment under which configurations it may be executed. An evaluation on Android apps and Java applications from different domains shows that Lotrack yields high accuracy with reasonable performance. We use Lotrack\u00a0\u2026", "num_citations": "75\n", "authors": ["270"]}
{"title": "StubDroid: automatic inference of precise data-flow summaries for the android framework\n", "abstract": " Smartphone users suffer from insucient information on how commercial as well as malicious apps handle sensitive data stored on their phones. Automated taint analyses address this problem by allowing users to detect and investigate how applications access and handle this data. A current problem with virtually all those analysis approaches is, though, that they rely on explicit models of the Android runtime library. In most cases, the existence of those models is taken for granted, despite the fact that the models are hard to come by: Given the size and evolution speed of a modern smartphone operating system it is prohibitively expensive to derive models manually from code or documentation. In this work, we therefore present StubDroid, the first fully automated approach for inferring precise and efficient library models for taint-analysis problems. StubDroid automatically constructs these summaries from a binary\u00a0\u2026", "num_citations": "73\n", "authors": ["270"]}
{"title": "Clara: A framework for partially evaluating finite-state runtime monitors ahead of time\n", "abstract": " Researchers have developed a number of runtime verification tools that generate runtime monitors in the form of AspectJ aspects. In this work, we present Clara, a novel framework to statically optimize such monitoring aspects with respect to a given program under test. Clara uses a sequence of increasingly precise static analyses to automatically convert a monitoring aspect into a residual runtime monitor. The residual monitor only watches events triggered by program locations that the analyses failed to prove safe at compile time. In two-thirds of the cases in our experiments, the static analysis succeeds on all locations, proving that the program fulfills the stated properties, and completely obviating the need for runtime monitoring. In the remaining cases, the residual runtime monitor is usually much more efficient than a full monitor, yet still captures all property violations at runtime.", "num_citations": "69\n", "authors": ["270"]}
{"title": "Do android taint analysis tools keep their promises?\n", "abstract": " In recent years, researchers have developed a number of tools to conduct taint analysis of Android applications. While all the respective papers aim at providing a thorough empirical evaluation, comparability is hindered by varying or unclear evaluation targets. Sometimes, the apps used for evaluation are not precisely described. In other cases, authors use an established benchmark but cover it only partially. In yet other cases, the evaluations differ in terms of the data leaks searched for, or lack a ground truth to compare against. All those limitations make it impossible to truly compare the tools based on those published evaluations.", "num_citations": "60\n", "authors": ["270"]}
{"title": "Susi: A tool for the fully automated classification and categorization of android sources and sinks\n", "abstract": " Today\u2019s smartphone users face a security dilemma: many apps they install operate on privacy-sensitive data, although they might originate from developers whose trustworthiness is hard to judge. Researchers have proposed more and more sophisticated static and dynamic analysis tools as an aid to assess the behavior of such applications. Those tools, however, are only as good as the privacy policies they are configured with. Policies typically refer to a list of sources of sensitive data as well as sinks which might leak data to untrusted observers. Sources and sinks are a moving target: new versions of the mobile operating system regularly introduce new methods, and security tools need to be reconfigured to take them into account. In this work we show that, at least for the case of Android, the API comprises hundreds of sources and sinks. We propose SuSi, a novel and fully automated machine-learning approach for identifying sources and sinks directly from the Android source code. On our training set, SuSi achieves a recall and precision of more than 92%. To provide more fine-grained information, SuSi further categorizes the sources (eg, unique identifier, location information, etc.) and sinks (eg, network, file, etc.), with an average precision and recall of about 89%. We also show that many current program analysis tools can be circumvented because they use hand-picked lists of source and sinks which are largely incomplete, hence allowing many potential data leaks to go unnoticed.", "num_citations": "60\n", "authors": ["270"]}
{"title": "Arithmetic coding revealed-a guided tour from theory to praxis\n", "abstract": " CiteSeerX \u2014 Arithmetic Coding revealed - A guided tour from theory to praxis Documents Authors Tables Log in Sign up MetaCart DMCA Donate CiteSeerX logo Documents: Advanced Search Include Citations Authors: Advanced Search Include Citations Tables: DMCA Arithmetic Coding revealed - A guided tour from theory to praxis (2001) Cached Download as a PDF Download Links [www-users.rwth-aachen.de] [www.bodden.de] [www.copro.org] Save to List Add to Collection Correct Errors Monitor Changes by Eric Bodden , Eric Bodden , Malte Clasen , Malte Clasen , Joachim Kneis , Joachim Kneis Citations: 11 - 0 self Summary Citations Active Bibliography Co-citation Clustered Documents Version History Share Facebook Twitter Reddit Bibsonomy OpenURL Abstract Motivation and History 7 2 Keyphrases guided tour arithmetic coding Powered by: Apache Solr About CiteSeerX Submit and Index Documents at \u2026", "num_citations": "60\n", "authors": ["270"]}
{"title": "Reviser: efficiently updating IDE-/IFDS-based data-flow analyses in response to incremental program changes\n", "abstract": " Most application code evolves incrementally, and especially so when being maintained after the applications have been deployed. Yet, most data-flow analyses do not take advantage of this fact. Instead they require clients to recompute the entire analysis even if little code has changed\u2014a time consuming undertaking, especially with large libraries or when running static analyses often, eg, on a continuous-integration server. In this work, we present Reviser, a novel approach for automatically and efficiently updating inter-procedural dataflow analysis results in response to incremental program changes. Reviser follows a clear-and-propagate philosophy, aiming at clearing and recomputing analysis information only where required, thereby greatly reducing the required computational effort. The Reviser algorithm is formulated as an extension to the IDE framework for Inter-procedural Finite Distributed Environment\u00a0\u2026", "num_citations": "56\n", "authors": ["270"]}
{"title": "Join point interfaces for safe and flexible decoupling of aspects\n", "abstract": " In current aspect-oriented systems, aspects usually carry, through their pointcuts, explicit references to the base code. Those references are fragile and hinder important software engineering properties such as modular reasoning and independent evolution of aspects and base code. In this work, we introduce a novel abstraction called Join Point Interface, which, by design, aids modular reasoning and independent evolution by decoupling aspects from base code and by providing a modular type-checking algorithm. Join point interfaces can be used both with implicit announcement through pointcuts, and with explicit announcement, using closure join points. Join point interfaces further offer polymorphic dispatch on join points, with an advice-dispatch semantics akin to multimethods. To support flexible join point matching, we incorporate into our language an earlier proposal for generic advice, and introduce a\u00a0\u2026", "num_citations": "56\n", "authors": ["270"]}
{"title": "Just-in-time static analysis\n", "abstract": " We present the concept of Just-In-Time (JIT) static analysis that interleaves code development and bug fixing in an integrated development environment. Unlike traditional batch-style analysis tools, a JIT analysis tool presents warnings to code developers over time, providing the most relevant results quickly, and computing less relevant results incrementally later. In this paper, we describe general guidelines for designing JIT analyses. We also present a general recipe for transforming static data-flow analyses to JIT analyses through a concept of layered analysis execution. We illustrate this transformation through CHEETAH, a JIT taint analysis for Android applications. Our empirical evaluation of CHEETAH on real-world applications shows that our approach returns warnings quickly enough to avoid disrupting the normal workflow of developers. This result is confirmed by our user study, in which developers fixed\u00a0\u2026", "num_citations": "52\n", "authors": ["270"]}
{"title": "Aspects for trace monitoring\n", "abstract": " A trace monitor observes the sequence of events in a system, and takes appropriate action when a given pattern occurs in that sequence. Aspect-oriented programming provides a convenient framework for writing such trace monitors.               We provide a brief introduction to aspect-oriented programming in AspectJ. AspectJ only provides support for triggering extra code with single events, and we present a new language feature (named tracematches) that allows one to directly express patterns that range over the whole current trace. Implementing this feature efficiently is challenging, and we report on our work towards that goal.               Another drawback of AspectJ is the highly syntactic nature of the event patterns, often requiring the programmer to list all methods that have a certain property, rather than specifying that property itself. We argue that Datalog provides an appropriate notation for describing\u00a0\u2026", "num_citations": "48\n", "authors": ["270"]}
{"title": "Instrumenting android and java applications as easy as abc\n", "abstract": " Program instrumentation is a widely used mechanism in different software engineering areas. It can be used for creating profilers and debuggers, for detecting programming errors at runtime, or for securing programs through inline reference monitoring.               This paper presents a tutorial on instrumenting Android applications using Soot and the AspectBench compiler (abc). We show how two well-known monitoring languages \u2013Tracematches and AspectJ\u2013 can be used for instrumenting Android applications. Furthermore, we also describe the more flexible approach of manual imperative instrumentation directly using Soot\u2019s intermediate representation Jimple. In all three cases no source code of the target application is required.", "num_citations": "43\n", "authors": ["270"]}
{"title": "Avoiding infinite recursion with stratified aspects\n", "abstract": " Infinite recursion is a known problem of aspect-oriented programming with AspectJ: if no special precautions are taken, aspects advising aspects can easily and unintentionally advise themselves. We present a compiler for an extension of the AspectJ programming language that avoids self reference by associating aspects with levels, and by automatically restricting the scope of pointcuts used by an aspect to join points of lower levels. We report on a case study using our language extension, and provide numbers of the changes necessary for migrating existing applications to it. Our results suggest that we can make programming with AspectJ simpler and safer, without restricting its expressive power unduly.", "num_citations": "43\n", "authors": ["270"]}
{"title": "Aspect-oriented race detection in Java\n", "abstract": " In the past, researchers have developed specialized programs to aid programmers in detecting concurrent programming errors such as deadlocks, livelocks, starvation, and data races. In this work, we propose a language extension to the aspect-oriented programming language AspectJ, in the form of three new pointcuts, lock(), unlock(), and maybeShared(). These pointcuts allow programmers to monitor program events where locks are granted or handed back, and where values are accessed that may be shared among multiple Java threads. We decide thread locality using a static thread-local-objects analysis developed by others. Using the three new primitive pointcuts, researchers can directly implement efficient monitoring algorithms to detect concurrent-programming errors online. As an example, we describe a new algorithm which we call RACER, an adaption of the well-known ERASER algorithm to the\u00a0\u2026", "num_citations": "42\n", "authors": ["270"]}
{"title": "Arithmetic coding revealed\n", "abstract": " This document is an updated and translated version of the German paper Arithmetische Kodierung [BCK02] from 2002. It tries to be a comprehensive guide to the art of arithmetic coding.First we give an introduction to the mathematic principles involved. These build the foundation for chapter 3, where we describe the encoding and decoding algorithms for different numerical systems. Here we also mention various problems one can come across as well as solutions for those. This is followed by a proof of uniqueness and an estimation of the efficiency of the algorithm. In the end we briefly mention different kinds of statistical models, which are used to actually gain compression through the encoding. Throughout this paper we occasionally make some comparisons to the related Huffman encoding algorithm. Though, some rudimentary knowledge about Huffman encoding should suffice for the reader to follow the line of reasoning.", "num_citations": "42\n", "authors": ["270"]}
{"title": "Closure joinpoints: block joinpoints without surprises\n", "abstract": " Block joinpoints allow programmers to explicitly mark regions of base code as\" to be advised\", thus avoiding the need to extract the block into a method just for the sake of creating a joinpoint. Block joinpoints appear simple to define and implement. After all, regular block statements in Java-like languages are constructs well-known to the programmer and have simple control-flow and data-flow semantics.", "num_citations": "41\n", "authors": ["270"]}
{"title": "Efficient trace monitoring\n", "abstract": " A wealth of recent research involves generating program monitors from declarative specifications. Doing this efficiently has proved challenging, and available implementations often produce infeasibly slow monitors. We demonstrate how to dramatically improve performance--typically reducing overheads to within an order of magnitude of the program's normal runtime.", "num_citations": "39\n", "authors": ["270"]}
{"title": "How current android malware seeks to evade automated code analysis\n", "abstract": " First we report on a new threat campaign, underway in Korea, which infected around 20,000 Android users within two months. The campaign attacked mobile users with malicious applications spread via different channels, such as email attachments or SMS spam. A detailed investigation of the Android malware resulted in the identification of a new Android malware family Android/BadAccents. The family represents current state-of-the-art in mobile malware development for banking trojans.                 Second, we describe in detail the techniques this malware family uses and confront them with current state-of-the-art static and dynamic code-analysis techniques for Android applications. We highlight various challenges for automatic malware analysis frameworks that significantly hinder the fully automatic detection of malicious components in current Android malware. Furthermore, the malware exploits a\u00a0\u2026", "num_citations": "37\n", "authors": ["270"]}
{"title": "A lightweight LTL runtime verification tool for Java\n", "abstract": " Runtime verification is a special form of runtime testing, employing formal methods and languages. In this work, we utilize next-time free linear-time temporal logic (LTL\\textbackslash X) as formal framework. The discipline serves the purpose of asserting certain design-time assumptions about object-oriented (OO) entities such as objects, methods, and so forth. In this paper we propose a linear-time logic over joinpoints\\citeLaddad03AspectJ, and introduce a lightweight runtime veri\\-fication tool based on this logic, J2SE 5 metadata\\citeJSR175 and an AspectJ-based\\citeAspectJ runtime backend. Implementations have been proposed so far for imperative and functional languages\\citeHuchStolz04a. To our knowledge our approach is the first to allow addressing of entire sets of states, also over subclass boundaries, thus exploiting the OO nature.", "num_citations": "37\n", "authors": ["270"]}
{"title": "Context-, flow-, and field-sensitive data-flow analysis using synchronized pushdown systems\n", "abstract": " Precise static analyses are context-, field- and flow-sensitive. Context- and field-sensitivity are both expressible as context-free language (CFL) reachability problems. Solving both CFL problems along the same data-flow path is undecidable, which is why most flow-sensitive data-flow analyses over-approximate field-sensitivity through k-limited access-path, or through access graphs. Unfortunately, as our experience and this paper show, both representations do not scale very well when used to analyze programs with recursive data structures.  Any single CFL-reachability problem is efficiently solvable, by means of a pushdown system. This work thus introduces the concept of synchronized pushdown systems (SPDS). SPDS encode both procedure calls/returns and field stores/loads as separate but \u201csynchronized\u201d CFL reachability problems. An SPDS solves both individual problems precisely, and approximation\u00a0\u2026", "num_citations": "36\n", "authors": ["270"]}
{"title": "Join point interfaces for modular reasoning in aspect-oriented programs\n", "abstract": " While aspect-oriented programming supports the modular definition of crosscutting concerns, most approaches to aspect-oriented programming fail to improve, or even preserve, modular reasoning. The main problem is that aspects usually carry, through their pointcuts, explicit references to the base code. These dependencies make programs fragile. Changes in the base code can unwittingly break a pointcut definition, rendering the aspect ineffective or causing spurious matches. Conversely, a change in a pointcut definition may cause parts of the base code to be advised without notice. Therefore separate development of aspect-oriented programs is largely compromised, which in turns seriously hinders the adoption of aspect-oriented programming by practitioners. We propose to separate base code and aspects using Join Point Interfaces, which are contracts between aspects and base code. Base code can\u00a0\u2026", "num_citations": "35\n", "authors": ["270"]}
{"title": "Domain-Specific Modelling With Atom3.\n", "abstract": " Using domain-specific modelling environments maximally constrains users, matching their mental model of the problem domain, and allows them to only build syntactically correct models. Anecdotal evidence shows that domain-specific modelling can drastically improve productivity as well as product quality. In this paper, the foundations of (domain-specific) modelling language design are presented. Our guiding principle is to \u201cmodel everything\u201d. It is indeed shown how all aspects of language design can be explicitly (meta-) modelled enabling the efficient synthesis of domain-specific, visual, modelling environments. The case of AToM3, A Tool for Multi-formalism and Meta Modelling, is elaborated. Concepts are illustrated by modelling, analysis, simulation, and eventual synthesis of software for Traffic networks.", "num_citations": "31\n", "authors": ["270"]}
{"title": "An in-depth study of more than ten years of java exploitation\n", "abstract": " When created, the Java platform was among the first runtimes designed with security in mind. Yet, numerous Java versions were shown to contain far-reaching vulnerabilities, permitting denial-of-service attacks or even worse allowing intruders to bypass the runtime's sandbox mechanisms, opening the host system up to many kinds of further attacks.", "num_citations": "30\n", "authors": ["270"]}
{"title": "Incorporating attacker capabilities in risk estimation and mitigation\n", "abstract": " The risk exposure of a given threat to an information system is a function of the likelihood of the threat and the severity of its impacts. Existing methods for estimating threat likelihood assume that the attacker is able to cause a given threat, that exploits existing vulnerabilities, if s/he has the required opportunities (e.g., sufficient attack time) and means (e.g., tools and skills), which is not true; often, s/he can perform an attack and cause the related threat only if s/he has the ability to access related resources (objects) of the system that allow to do so. This paper proposes a risk estimation method that incorporates attacker capabilities in estimating the likelihood of threats as conditions for using the means and opportunities, demonstrates the use of the proposed risk estimation method through two examples: video conferencing systems and connected vehicles, shows that changing attacker capabilities changes the risks of\u00a0\u2026", "num_citations": "30\n", "authors": ["270"]}
{"title": "The Clara framework for hybrid typestate analysis\n", "abstract": " A typestate property describes which operations are available on an object or a group of inter-related objects, depending on this object\u2019s or group\u2019s internal state, the typestate. Researchers in the field of static analysis have devised static program analyses to prove the absence of typestate-property violations on all possible executions of a given program under test. Researchers in runtime verification, on the other hand, have developed powerful monitoring approaches that guarantee to capture property violations on actual executions. Although static analysis can greatly benefit runtime monitoring, up until now, most static analyses are incompatible with most monitoring tools. We present Clara, a novel framework that makes these approaches compatible. With Clara, researchers in static analysis can easily implement powerful typestate analyses. Runtime-verification researchers, on the other hand, can use\u00a0\u2026", "num_citations": "30\n", "authors": ["270"]}
{"title": "PhASAR: An Inter-procedural Static Analysis Framework for C/C++.\n", "abstract": " Static program analysis is used to automatically determine program properties, or to detect bugs or security vulnerabilities in programs. It can be used as a stand-alone tool or to aid compiler optimization as an intermediary step. Developing precise, inter-procedural static analyses, however, is a challenging task, due to the algorithmic complexity, implementation effort, and the threat of state explosion which leads to unsatisfactory performance. Software written in C and C++ is notoriously hard to analyze because of the deliberately unsafe type system, unrestricted use of pointers, and (for C++) virtual dispatch. In this work, we describe the design and implementation of the LLVM-based static analysis framework PhASAR for C/C++ code. PhASAR allows data-flow problems to be solved in a fully automated manner. It provides class hierarchy, call-graph, points-to, and data-flow information, hence requiring analysis developers only to specify a definition of the data-flow problem. PhASAR thus hides the complexity of static analysis behind a high-level API, making static program analysis more accessible and easy to use. PhASAR is available as an open-source project. We evaluate PhASAR\u2019s scalability during whole-program analysis. Analyzing 12 real-world programs using a taint analysis written in PhASAR, we found PhASAR\u2019s abstractions and their implementations to provide a whole-program analysis that scales well to real-world programs. Furthermore, we peek into the details of analysis runs, discuss our experience in developing static analyses for C/C++, and present possible future improvements.", "num_citations": "29\n", "authors": ["270"]}
{"title": "Effective API navigation and reuse\n", "abstract": " Most reuse libraries come with few source-code examples that demonstrate how the library at hand should be used. We have developed a source-code recommendation approach for constructing and delivering relevant code snippets that programmers can use to complete a certain programming task. Our approach is semantic-based; relying on an explicit ontological representation of source-code. We argue that such representation opens new doors for an improved recommendation mechanism that ensures relevancy and accuracy. Current recommendation systems require an existing repository of relevant code samples. However, for many libraries, such a repository does not exist. Therefore, we instead utilize points-to analysis to infer precise type information of library components. We have backed our approach with a tool that has been tested on multiple libraries. The obtained results are promising and\u00a0\u2026", "num_citations": "28\n", "authors": ["270"]}
{"title": "RefaFlex: Safer refactorings for reflective Java programs\n", "abstract": " If programs access types and members through reflection, refactoring tools cannot guarantee that refactorings on those programs are behavior preserving. Refactoring approaches for highly reflective languages like Smalltalk therefore check behavior preservation using regression testing.", "num_citations": "27\n", "authors": ["270"]}
{"title": "j\u00c4k: Using Dynamic Analysis to Crawl and Test Modern Web Applications\n", "abstract": " Web application scanners are popular tools to perform black box testing and are widely used to discover bugs in websites. For them to work effectively, they either rely on a set of URLs that they can test, or use their own implementation of a crawler that discovers new parts of a web application. Traditional crawlers would extract new URLs by parsing HTML documents and applying static regular expressions. While this approach can extract URLs in classic web applications, it fails to explore large parts of modern JavaScript-based applications.                 In this paper, we present a novel technique to explore web applications based on the dynamic analysis of the client-side JavaScript program. We use dynamic analysis to hook JavaScript APIs, which enables us to detect the registration of events, the use of network communication APIs, and dynamically-generated URLs or user forms. We then propose to use\u00a0\u2026", "num_citations": "26\n", "authors": ["270"]}
{"title": "Analyzing the gadgets\n", "abstract": " Current low-level exploits often rely on code-reuse, whereby short sections of code (gadgets) are chained together into a coherent exploit that can be executed without the need to inject any code. Several protection mechanisms attempt to eliminate this attack vector by applying code transformations to reduce the number of available gadgets. Nevertheless, it has emerged that the residual gadgets can still be sufficient to conduct a successful attack. Crucially, the lack of a common metric for \u201cgadget quality\u201d hinders the effective comparison of current mitigations.               This work proposes four metrics that assign scores to a set of gadgets, measuring quality, usefulness, and practicality. We apply these metrics to binaries produced when compiling programs for architectures implementing Intel\u2019s recent MPX CPU extensions. Our results demonstrate a 17\u00a0% increase in useful gadgets in MPX binaries, and a\u00a0\u2026", "num_citations": "24\n", "authors": ["270"]}
{"title": "MOPBox: A library approach to runtime verification\n", "abstract": " In this work we propose MOPBox, a library-based approach to runtime verification. MOPBox is a Java library for defining and evaluating parametric runtime monitors. A user can define monitors through a simple set of API calls. Once a monitor is defined, it is ready to accept events. Events can originate from AspectJ aspects or from other sources, and they can be parametric, i.e., can contain variable bindings that bind abstract specification variables to concrete program values. When a monitor reaches an error state for a binding , MOPBox notifies clients of a match for  through a call-back interface. To map variable bindings to monitors, MOPBox uses re-implementations of efficient indexing algorithms that Chen et al. developed for JavaMOP.               We took care to keep MOPBox as generic as possible. States, transitions and variable bindings can be labeled not just with strings but with general\u00a0\u2026", "num_citations": "24\n", "authors": ["270"]}
{"title": "Method and system for performance profiling of software\n", "abstract": " Performance profiling of software by producing a performance profile of a software processing unit and performing statistical analysis on the performance profile by matching the performance profile with at least one additional performance profile. An algorithmic approach is used to match data related to processes and/or threads and/or similar processing units (PU) over multiple performance profiles. One purpose of the matching algorithm is to identify such PU in order to enable computation of an accumulated or averaged dataset over multiple profiling periods. Various matching strategies, filters, and preprocessing techniques are described, together with level of reliability estimation.", "num_citations": "24\n", "authors": ["270"]}
{"title": "Tracechecks: Defining semantic interfaces with temporal logic\n", "abstract": " Tracechecks are a formalism based on linear temporal logic (LTL) with variable bindings and pointcuts of the aspect-oriented language AspectJ for the purpose of verification. We demonstrate how tracechecks can be used to model temporal assertions. These assertions reason about the dynamic control flow of an application. They can be used to formally define the semantic interface of classes. We explain in detail how we make use of AspectJ pointcuts to derive a formal model of an existing application and use LTL to express temporal assertions over this model.             We developed a reference implementation with the abc compiler showing that the tool can be applied in practice and is memory-efficient.             In addition we show how tracechecks can be deployed as Java5 annotations, yielding a system which is fully compliant with any Java compiler and hiding any peculiarities of aspect\u00a0\u2026", "num_citations": "24\n", "authors": ["270"]}
{"title": "Verifying finite-state properties of large-scale programs\n", "abstract": " Les concepteurs des diff\u00e9rentes composantes logicielles peuvent utiliser les propri\u00e9t\u00e9s des automates finis pour fixer les sp\u00e9cifications de l'interface comportementale qui contr\u00f4leront les r\u00e8gles de programmations d\u00e9finissant l'utilisation des composantes. Ceci permet aux utilisateurs de ces composantes de v\u00e9rifier le respect de ses r\u00e8gles par leurs codes sources, \u00e0 la fois lors d'une analyse statique qu'\u00e0 l'ex\u00e9cution. Dans cette dissertation, nous montrerons la conception de Clara, une structure qui permet de sp\u00e9cifier et de v\u00e9rifier les propri\u00e9t\u00e9s des automates finis dans des programmes \u00e9tendus, puis expliquerons son implantation. Le programmeur, \u00e0 l'aide de Clara, peut d\u00e9finir les propri\u00e9t\u00e9s des automates finis en compl\u00e9ment aux processus de v\u00e9rification \u00e0 l'ex\u00e9cution, en utilisant une extension de la syntaxe d'AspectJ, un langage de programmation orient\u00e9 aspect. Clara utilise alors, en s\u00e9quence, trois analyses statiques de pr\u00e9cision croissante pour d\u00e9terminer si le programme respecte les propri\u00e9t\u00e9s des automates finis. Clara produit une liste des positions dans le code source o\u00f9 il y a risque de violation de ces \u00abpropri\u00e9t\u00e9s\u00bb, en ordre d\u00e9croissant de certitude d'une violation. Quand cela est possible, Clara ajoute au programme des processus de v\u00e9rification permettant d'\u00e9tudier la violation de \u00abpropri\u00e9t\u00e9s\u00bb lors de son ex\u00e9cution. Gr\u00e2ce \u00e0 son analyse statique, Clara n'ajoute pas au code ces processus dans les portions de code qui n'ont pas la possibilit\u00e9 de violer les propri\u00e9t\u00e9s des automates finis, ce qui limite les ralentissements dus aux processus de v\u00e9rification. Lorsque ses ajouts restent consid\u00e9rables, Clara organise les processus de\u00a0\u2026", "num_citations": "23\n", "authors": ["270"]}
{"title": "IDEal: efficient and precise alias-aware dataflow analysis\n", "abstract": " Program analyses frequently track objects throughout a program, which requires reasoning about aliases. Most dataflow analysis frameworks, however, delegate the task of handling aliases to the analysis clients, which causes a number of problems. For instance, custom-made extensions for alias analysis are complex and cannot easily be reused. On the other hand, due to the complex interfaces involved, off-the-shelf alias analyses are hard to integrate precisely into clients. Lastly, for precision many clients require strong updates, and alias abstractions supporting strong updates are often relatively inefficient.   In this paper, we present IDEal, an alias-aware extension to the framework for Interprocedural Distributive Environment (IDE) problems. IDEal relieves static-analysis authors completely of the burden of handling aliases by automatically resolving alias queries on-demand, both efficiently and precisely. IDEal\u00a0\u2026", "num_citations": "22\n", "authors": ["270"]}
{"title": "Using targeted symbolic execution for reducing false-positives in dataflow analysis\n", "abstract": " Static data flow analysis is an indispensable tool for finding potentially malicious data leaks in software programs. Programs, nowadays often consisting of millions of lines of code, have grown much too large to allow for a complete manual inspection. Nevertheless, security experts need to judge whether an application is trustworthy or not, developers need to find bugs, and quality experts need to assess the maturity of software products. Thus, analysts take advantage of automated data flow analysis tools to find candidates for suspicious leaks which are then further investigated. While much progress has been made in the area with a broad variety of static data flow analysis tools proposed in academia and being offered commercially, the number of false alarms raised by these tools is still a concern. Many of the false alarms are reported because the analysis tool detects data flows along paths which are not\u00a0\u2026", "num_citations": "21\n", "authors": ["270"]}
{"title": "Towards ensuring security by design in cyber-physical systems engineering processes\n", "abstract": " Engineering cyber-physical systems secure by design requires engineers to consider security from the ground up. However, current systems engineering processes are not tailored to cyber-physical systems, or lack an integration with security engineering. In this paper, we integrate secure software engineering practices into an engineering process for cyber-physical systems. Thereby, we enable engineers to specify security requirements at the level of systems engineering, and to take effective countermeasures during both platform-independent and platform-specific software engineering. Our key contribution is the integration of threat models for tracing security requirements to countermeasures. We illustrate our approach by an autonomous car with high security requirements.", "num_citations": "20\n", "authors": ["270"]}
{"title": "Partially evaluating finite-state runtime monitors ahead of time\n", "abstract": " Finite-state properties account for an important class of program properties, typically related to the order of operations invoked on objects. Many library implementations therefore include manually written finite-state monitors to detect violations of finite-state properties at runtime. Researchers have recently proposed the explicit specification of finite-state properties and automatic generation of monitors from the specification. However, runtime monitoring only shows the presence of violations, and typically cannot prove their absence. Moreover, inserting a runtime monitor into a program under test can slow down the program by several orders of magnitude. In this work, we therefore present a set of four static whole-program analyses that partially evaluate runtime monitors at compile time, with increasing cost and precision. As we show, ahead-of-time evaluation can often evaluate the monitor completely statically. This\u00a0\u2026", "num_citations": "20\n", "authors": ["270"]}
{"title": "Object representatives: a uniform abstraction for pointer information\n", "abstract": " Pointer analyses enable many subsequent program analyses and transformations by statically disambiguating references to the heap. However, different client analyses may have different sets of pointer analysis needs, and each must pick some pointer analysis along the cost/precision spectrum to meet those needs. Some analysis clients employ combinations of pointer analyses to obtain better precision with reduced analysis times. Our goal is to ease the task of developing client analyses by enabling composition and substitutability for pointer analyses. We therefore propose object representatives, which statically represent runtime objects. A representative encapsulates the notion of object identity, as observed through the representative\u2019s aliasing relations with other representatives. Object representatives enable pointer analysis clients to disambiguate references to the heap in a uniform yet flexible way. Representatives can be generated from many combinations of pointer analyses, and pointer analyses can be freely exchanged and combined without changing client code. We believe that the use of object representatives brings many software engineering benefits to compiler implementations because, at compile time, object representatives are Java objects. We discuss our motivating case for object representatives, namely, the development of an abstract interpreter for tracematches, a language feature for runtime monitoring. We explain one particular algorithm for computing object representatives which combines flow- sensitive intraprocedural must-alias and must-not-alias analyses with a flow-insensitive, context-sensitive whole-program\u00a0\u2026", "num_citations": "19\n", "authors": ["270"]}
{"title": "Time for addressing software security issues: Prediction models and impacting factors\n", "abstract": " Finding and fixing software vulnerabilities have become a major struggle for most software development companies. While generally without alternative, such fixing efforts are a major cost factor, which is why companies have a vital interest in focusing their secure software development activities such that they obtain an optimal return on this investment. We investigate, in this paper, quantitatively the major factors that impact the time it takes to fix a given security issue based on data collected automatically within SAP\u2019s secure development process, and we show how the issue fix time could be used to monitor the fixing process. We use three machine learning methods and evaluate their predictive power in predicting the time to fix issues. Interestingly, the models indicate that vulnerability type has less dominant impact on issue fix time than previously believed. The time it takes to fix an issue instead seems\u00a0\u2026", "num_citations": "18\n", "authors": ["270"]}
{"title": "Clara: Partially evaluating runtime monitors at compile time\n", "abstract": " Clara is a novel static-analysis framework for partially evaluating finite-state runtime monitors at compile time. Clara uses static typestate analyses to automatically convert any AspectJ monitoring aspect into a residual runtime monitor that only monitors events triggered by program locations that the analyses failed to prove safe. If the static analysis succeeds on all locations, this gives strong static guarantees. If not, the efficient residual runtime monitor is guaranteed to capture property violations at runtime. Researchers can use Clara with most runtime-monitoring tools that implement monitors as AspectJ aspects. In this tutorial supplement, we provide references to related reading material that will allow the reader to obtain in-depth knowledge about the context in which Clara can be applied and about the techniques that underlie the Clara framework.", "num_citations": "18\n", "authors": ["270"]}
{"title": "Ropocop\u2014dynamic mitigation of code-reuse attacks\n", "abstract": " Control-flow attacks, usually achieved by exploiting a buffer-overflow vulnerability, have been a serious threat to system security for over fifteen years. Researchers have answered the threat with various mitigation techniques; but nevertheless, new exploits that successfully bypass these technologies still appear on a regular basis.In this paper, we propose ROPocop, a novel approach for detecting and preventing the execution of injected code and for mitigating code-reuse attacks such as return-oriented programming (RoP). ROPocop uses dynamic binary instrumentation, requiring neither access to source code nor debug symbols or changes to the operating system. It mitigates attacks both by monitoring the program counter at potentially dangerous points and by detecting suspicious program flows.We have implemented ROPocop for Windows x86 using PIN, a dynamic program instrumentation framework from\u00a0\u2026", "num_citations": "17\n", "authors": ["270"]}
{"title": "Investigating Users' Reaction to Fine-Grained Data Requests: A Market Experiment\n", "abstract": " The market for smartphone applications is steadily growing. Unfortunately, along with this growth, the number of malicious applications is increasing as well. To identify this malware, various automatic code-analysis tools have been developed. These tools are able to assess the risk associated with a specific app. However, informing users about these findings is often difficult. Currently, on Android, users decide about applications based on coarse-grained permission dialogs during installation. As these dialogs are quite abstract, many users do not read or understand them. Thus, to make the more detailed findings from security research accessible, new mechanisms for privacy communication need to be assessed. In our market experiment, we investigate how fine-grained data requests during runtime affect users' information disclosure. We find that many users reverse their decision when prompted with a fine\u00a0\u2026", "num_citations": "17\n", "authors": ["270"]}
{"title": "Factors impacting the effort required to fix security vulnerabilities\n", "abstract": " To what extent do investments in secure software engineering pay off? Right now, many development companies are trying to answer this important question. A change to a secure development lifecycle can pay off if it decreases significantly the time, and therefore the cost required to find, fix and address security vulnerabilities. But what are the factors involved and what influence do they have? This paper reports about a qualitative study conducted at SAP to identify the factors that impact the vulnerability fix time. The study involves interviews with 12 security experts. Through these interviews, we identified 65 factors that fall into classes which include, beside the vulnerabilities characteristics, the structure of the software involved, the diversity of the used technologies, the smoothness of the communication and collaboration, the availability and quality of information and documentation, the expertise and\u00a0\u2026", "num_citations": "17\n", "authors": ["270"]}
{"title": "Droidsearch: A tool for scaling android app triage to real-world app stores\n", "abstract": " The Android platform now features more than a million apps from thousands of developers. This abundance is convenient, as it caters to almost every need. But users and researchers also worry about the security and trustworthiness of these apps. While precise program-analysis tools are helpful in this context, unfortunately they do not scale to the large number of apps present in current app stores. In this work we thus present DroidSearch, a search engine that aids a multi-staged analysis in which fast pre-filtering techniques allow security experts to quickly retrieve candidate applications that should be subjected to further automated and/or manual analysis. DroidSearch is supported by DroidBase, a middleware and back-end database which associates apps with metadata and the results of lightweight analyses on bytecode and configuration files that DroidBase automatically manages and executes. Experiments\u00a0\u2026", "num_citations": "17\n", "authors": ["270"]}
{"title": "Harvesting runtime data in android applications for identifying malware and enhancing code analysis\n", "abstract": " It is generally a challenging task to tell apart malware from benign applications: obfuscation and string encryption, used by malware as well as goodware, often render static analyses ineffective. In addition, malware frequently tricks dynamic analyses by detecting the execution environment emulated by the analysis tool and then refraining from malicious behavior.In this work, however, we present HARVESTER, a novel approach that combines a variation of program slicing with dynamic execution, and show that it can be highly effective in the triage of current mobile malware families. For this malware, HARVESTER allows a fully automatic extraction of runtime values from any position in the Android bytecode. Target phone numbers and messages of SMS messages, decryption keys or concrete URLs that are called inside an Android application can usually be extracted even if the application is highly obfuscated, and even if the application uses anti-analysis techniques (eg, emulator detection or delayed execution/\u201ctime bombs\u201d), dynamic code loading and native method calls for string decryption. As we show, HARVESTER not only aids human malware analysts, but also acts as an automatic deobfuscation tool that reverts the introduction of encrypted strings and reflective method calls as they are often introduced by obfuscators such as DexGuard.", "num_citations": "17\n", "authors": ["270"]}
{"title": "TS4J: a fluent interface for defining and computing typestate analyses\n", "abstract": " Typestate analyses determine whether a program's use of a given API obeys this API's usage constraints in the sense that the right methods are called on the right objects in the right order. Previously, we and others have described approaches that generate typestate analyses from textual finite-state property definitions written in specialized domain-specific languages. While such an approach is feasible, it requires a heavyweight compiler, hindering an effective integration into the programmer's development environment and thus often also into her software-development practice.", "num_citations": "17\n", "authors": ["270"]}
{"title": "Relational aspects as tracematches\n", "abstract": " The relationships between objects in an object-oriented program are an essential property of the program's design and implementation. Two previous approaches to implement relationships with aspects were association aspects, an AspectJ-based language extension, and the relationship aspects library. While those approaches greatly ease software development, we believe that they are not general enough. For instance, the library approach only works for binary relationships, while the language extension does not allow for the association of primitive values or values from non-weavable classes. Hence, in this work we propose a generalized alternative implementation via a direct reduction to tracematches, a language feature for executing an advice after having matched a sequence of events. This new implementation scheme yields multiple benefits. Firstly, our implementation is more general than existing ones\u00a0\u2026", "num_citations": "17\n", "authors": ["270"]}
{"title": "The soot-based toolchain for analyzing android apps\n", "abstract": " Due to the quality and security requirements that come with an always-on mobile device processing large amounts of highly sensitive information, Android apps are an important target for automated program analysis. Yet, research on new approaches in this field often requires a significant amount of work to be spent on engineering tasks that are not central to the concrete research question at hand. These programming and debugging tasks can significantly delay the progress of the field. We therefore argue that research in the field greatly benefits from having a universal platform of readily usable components and well-tested fundamental algorithms on top of which researchers can build their own prototypes. Besides decreasing the required engineering effort for each new piece of research, such a platform also provides a base for comparing different approaches within one uniform framework, thereby fostering\u00a0\u2026", "num_citations": "16\n", "authors": ["270"]}
{"title": "Likelihoods of Threats to Connected Vehicles.\n", "abstract": " Connected vehicles communicate with neighboring vehicles, road side units, personal devices, and service centers; and have their electronic control units communicate through their in-vehicle networks. This provides cyber-attackers with the opportunity to communicate with the vehicles and to stage attacks. This paper reports about a case study for estimating the likelihoods of threats for connected vehicles; it provides the results of a survey that we conducted to estimate the likelihoods of 7 threats to connected vehicles. The experts rated 6 threats as\" very unlikely\" and one as\" almost impossible\" The survey shows that attacks on connected vehicles needs to be fast (before being discovered or the attack context changes) and be staged by experts who have deep knowledge about the targets. It also shows that developing such attacks does not require long time, neither expensive equipment and tools. Thus, cyber\u00a0\u2026", "num_citations": "16\n", "authors": ["270"]}
{"title": "ACMiner: Extraction and Analysis of Authorization Checks in Android's Middleware\n", "abstract": " Billions of users rely on the security of the Android platform to protect phones, tablets, and many different types of consumer electronics. While Android's permission model is well studied, the enforcement of the protection policy has received relatively little attention. Much of this enforcement is spread across system services, taking the form of hard-coded checks within their implementations. In this paper, we propose Authorization Check Miner (ACMiner), a framework for evaluating the correctness of Android's access control enforcement through consistency analysis of authorization checks. ACMiner combines program and text analysis techniques to generate a rich set of authorization checks, mines the corresponding protection policy for each service entry point, and uses association rule mining at a service granularity to identify inconsistencies that may correspond to vulnerabilities. We used ACMiner to study the\u00a0\u2026", "num_citations": "14\n", "authors": ["270"]}
{"title": "Denial-of-app attack: inhibiting the installation of android apps on stock phones\n", "abstract": " We describe a novel class of attacks called denial-of-app that allows adversaries to inhibit the future installation of attacker-selected applications on mobile phones. Adversaries can use such attacks to entrap users into installing attacker-preferred applications, for instance to generate additional revenue from advertisements on a competitive app market or to increase the rate of malware installation. Another possibility is to block anti-virus applications or security workarounds to complicate malware detection and removal.", "num_citations": "14\n", "authors": ["270"]}
{"title": "Schutzma\u00dfnahmen gegen datenschutz-unfreundliche Smartphone-Apps\n", "abstract": " Privacy Enhancing Technologies, die den Umgang von Smartphone-Apps mit personen bezogenen Daten \u00fcberwachen und unerw\u00fcnschte \u00fcbermittlungen verhindern, k\u00f6nnen mit dem Urheberrecht in Konflikt geraden. Der Beitrag untersucht die technischen M\u00f6glichkeiten des Selbstdatenschutzes und nimmt eine erste rechtliche Bewertung vor.", "num_citations": "14\n", "authors": ["270"]}
{"title": "Stateful breakpoints: a practical approach to defining parameterized runtime monitors\n", "abstract": " A runtime monitor checks a safety property during a program's execution. A parameterized runtime monitor can monitor properties containing free variables, or parameters. For instance, a monitor for the regular expression\" close (s)+ read (s)\" will warn the user when reading from a stream s that has previously been closed. Parameterized runtime monitors are very expressive, and research on this topic has lately gained much traction in the Runtime Verification community. Existing monitoring algorithms are very efficient. Nevertheless, existing tools provide little support for actually defining runtime monitors, probably one reason for why few practitioners are using runtime monitoring so far.", "num_citations": "14\n", "authors": ["270"]}
{"title": "The secret sauce in efficient and precise static analysis: The beauty of distributive, summary-based static analyses (and how to master them)\n", "abstract": " In this paper I report on experiences gained from more than five years of extensively designing static code analysis tools-in particular such ones with a focus on security-to scale to real-world projects within an industrial context. Within this time frame, my team and I were able to design static-analysis algorithms that yield both largely improved precision and performance compared to previous approaches. I will give a number of insights regarding important design decisions that made this possible.", "num_citations": "13\n", "authors": ["270"]}
{"title": "How useful are existing monitoring languages for securing Android apps?\n", "abstract": " The Android operating system is currently dominating the mobile device market in terms of penetration and growth rate. An important contributor to its success are a wealth of cheap and easy-to-install mobile applications, known as apps. Today, installing untrusted apps is the norm, though this comes with risks: malware is ubiquitous and can easily leak confidential and sensitive data. In this work, we investigate the extent to which we can specify complex information flow properties using existing specification languages for runtime monitoring, with the goal to encapsulate potentially harmful apps and prevent private data from leaking. By modelling a set of representative, Android-specific security policies with Tracematches, JavaMOP, Dataflow Pointcuts and PQL, we are able to identify policylanguage features that are crucial for effectively defining runtime-enforceable Android security properties. Our evaluation demonstrates that while certain property languages suit our purposes better than others, they all lack essential features that would, if present, allow users to provide effective security guarantees about apps. We discuss those shortcomings and propose several possible mechanisms to overcome them.", "num_citations": "13\n", "authors": ["270"]}
{"title": "Efficient and expressive runtime verification for Java\n", "abstract": " One of the big advances of software engineering during the last decades was the development of new techniques to modularize code into functional units. Object-oriented programming (OOP) allows for separation of functionality and association of functionality with the state it alters. Aspectoriented programming (AOP) goes a step further and allows for the separation of whole crosscutting concerns into single units, such concerns being code which builds a functional unit but is though scattered through the whole application in OOP.As a result of this development, such units are often being developed by different teams, who do not necessarily share any details about each other\u2019s implementations, though they do share interfaces to the modules they provide. Thus, the need for clear specification of those interfaces is crucial for a smooth and safe software development process. In order to specify those interfaces, various techniques have been proposed. Design by Contract (DBC)[10] is probably the most famous one: The developer of a unit specifies its usage through interfaces and some form of specification, which was so far mostly restricted of pre-and postconditions. Such specification is usually not part of the programming language and often simply marked down as comment and thus not automatically asserted. Some of the available tools however already allow for formal specification of such localised", "num_citations": "13\n", "authors": ["270"]}
{"title": "Static flow-sensitive & context-sensitive information-flow analysis for software product lines: position paper\n", "abstract": " A software product line encodes a potentially large variety of software products as variants of some common code base, eg, through the use of# ifdef statements or other forms of conditional compilation. Traditional information-flow analyses cannot cope with such constructs. Hence, to check for possibly insecure information flow in a product line, one currently has to analyze each resulting product separately, of which there may be thousands, making this task intractable.", "num_citations": "12\n", "authors": ["270"]}
{"title": "InvokeDynamic support in Soot\n", "abstract": " Java Specification Request (JSR) 292, which was realized with Java 7, defines a new java bytecode called invokedynamic, which can be used to call methods by name, without determining statically where the implementation of the called method is to be found. This mechanism eases the implementation of highly dynamic languages for the Java Virtual Machine.", "num_citations": "12\n", "authors": ["270"]}
{"title": "Self-adaptive static analysis\n", "abstract": " Static code analysis is a powerful approach to detect quality deficiencies such as performance bottlenecks, safety violations or security vulnerabilities already during a software system's implementation. Yet, as current software systems continue to grow, current static-analysis systems more frequently face the problem of insufficient scalability. We argue that this is mainly due to the fact that current static analyses are implemented fully manually, often in general-purpose programming languages such as Java or C, or in declarative languages such as Datalog. This design choice predefines the way in which the static analysis evaluates, and limits the optimizations and extensions static-analysis designers can apply.", "num_citations": "11\n", "authors": ["270"]}
{"title": "An investigation of the android/badaccents malware which exploits a new android tapjacking attack\n", "abstract": " We report on a new threat campaign, underway in Korea, which infected around 20,000 Android users within two months. The campaign attacked mobile users with malicious applications spread via different channels, such as email attachments or SMS spam. A detailed investigation of the Android malware resulted in the identification of a new Android malware family Android/BadAccents. The family represents current state-of-the-art in mobile malware development for banking trojans.In this paper, we describe in detail the techniques this malware family uses and confront them with current state-of-the-art static and dynamic code-analysis techniques for Android applications. We highlight various challenges for automatic malware analysis frameworks that significantly hinder the fully automatic detection of malicious components in the malware. Furthermore, the malware exploits a previously unknown tapjacking vulnerability in the Android operating system, which we describe in detail. As a result of this work, the vulnerability, affecting all Android versions, will be patched in one of the next releases of the Android Open Source Project.", "num_citations": "11\n", "authors": ["270"]}
{"title": "Easily instrumenting android applications for security purposes\n", "abstract": " Novel types of malware on mobile devices have raised researchers interest in implementing static and dynamic techniques for detecting and mitigating malicious behavior of mobile applications. In this hands-on tutorial we will demonstrate and explain different techniques for instrumenting Android applications using the Aspect Bench Compiler (abc) and the program analysis and transformation tool Soot. Through high-level abstractions such as AspectJ aspects and Tracematches, abc supports a declarative style of instrumentation that lends itself to the rapid prototyping of at least simple instrumentation schemes. Soot supports instrumentation in an imperative style, which requires more work but allows more fine-grained control. Both abc and Soot are inter operable, as they instrument the same intermediate program representation. Furthermore, as we show, both can be easily integrated with static program analyses\u00a0\u2026", "num_citations": "11\n", "authors": ["270"]}
{"title": "Debugging static analysis\n", "abstract": " Static analysis is increasingly used by companies and individual code developers to detect and fix bugs and security vulnerabilities. As programs grow more complex, the analyses have to support new code concepts, frameworks and libraries. However, static-analysis code itself is also prone to bugs. While more complex analyses are written and used in production systems every day, the cost of debugging and fixing them also increases tremendously. To understand the difficulties of debugging static analysis, we surveyed 115 static-analysis writers. From their responses, we determined the core requirements to build a debugger for static analyses, which revolve around two main issues: abstracting from both the analysis code and the code it analyses at the same time, and tracking the analysis internal state throughout both code bases. Most tools used by our survey participants lack the capabilities to address both\u00a0\u2026", "num_citations": "10\n", "authors": ["270"]}
{"title": "Model checking the information flow security of real-time systems\n", "abstract": " Cyber-physical systems are processing large amounts of sensitive information, but are increasingly often becoming the target of cyber attacks. Thus, it is essential to verify the absence of unauthorized information flow at design time before the systems get deployed. Our paper addresses this problem by proposing a novel approach to model-check the information flow security of cyber-physical systems represented by timed automata. We describe the transformation into so-called test automata, reducing the verification to a reachability test that is carried out using the off-the-shelf model checker Uppaal. Opposed to related work, we analyze the real-time behavior of systems, allowing software engineers to precisely identify timing channels that would enable attackers to draw conclusions from the system\u2019s response times. We illustrate the approach by detecting a timing channel in a simplified model of a cyber\u00a0\u2026", "num_citations": "10\n", "authors": ["270"]}
{"title": "Concern specific languages and their implementation with abc\n", "abstract": " In this work first we introduce the notion of concern specific languages (CSL) which are to a specific crosscutting concern, what domain specific languages are to a specific domain. Implementing such CSLs was a tedious task in the past since no extensible frameworks for implementing crosscutting concerns existed. With the AspectBench Compiler (abc)[1], which was released in October, researchers now have a powerful extensible compiler for the aspect-oriented language AspectJ [6], enabling easy implementation of language extensions or even whole CSL for a specific crosscutting concern. We first motivate CSLs in general and give examples of such languages which exist already. In the subsequent chapters we introduce one specific CSL and report on our implementation using abc and specifically about how CSLs can interact with and reuse each other. We will see that the use of CSLs in general provides better comprehensibility and analyzability.", "num_citations": "9\n", "authors": ["270"]}
{"title": "Arithmetische Kodierung\n", "abstract": " Diese Ausarbeitung beschreibt nach einer kurzen Einleitung grundlegende Begriffe und Zusammenh\u00e4nge der Arithmetischen Kodierung. Diese sind Grundlagen f\u00fcr das 3. Kapitel, in dem wir den Vorgang des Kodierens und Dekodierens in verschiedenen Zahlensystemen vorstellen und gleichzeitig auf dabei auftretende Probleme hinweisen, f\u00fcr die anschlie\u00dfend L\u00f6sungsm\u00f6glichkeiten aufgezeigt werden. Es folgen eine Effizienzbetrachtung sowie der Beweis der Eindeutigkeit des Verfahrens. Abschlie\u00dfend gehen wir noch kurz auf bekannte Modelle ein, denen sich Arithmetische Kodierer zur Berechnung von Wahrscheinlichkeiten bedienen. Gelegentlich stellen wir Vergleiche zur schon bekannten Huffman Kodierung auf, setzen dabei jedoch nur grundlegende Kenntnisse dieses Verfahrens voraus.Diese Ausarbeitung st\u00fctzt sich im Wesentlichen auf [2] und [1]. In Anlehnung an Letzters stellen wir eine selbst entwickelte Implementierung vor, welche im Anhang nachzulesen ist. Anhand dieser Quelltexte werden wir einige Beispiele veranschaulichen. Die mathematischen Definitionen und Beweisf\u00fchrungen sind hingegen stark an [2] und [3] angelehnt. Au\u00dferdem werden wir das bekannte Shannon-Theorem [11] benutzen, das die Entropie als Grenze der verlustlosen Komprimierbarkeit festlegt. Die Beispielquelltexte sind in C++ geschrieben und bedienen sich ausschlie\u00dflich einfacher Syntax, deren Semantik jedem Informatiker bekannt sein sollte.", "num_citations": "9\n", "authors": ["270"]}
{"title": "A qualitative analysis of Android taint-analysis results\n", "abstract": " In the past, researchers have developed a number of popular taint-analysis approaches, particularly in the context of Android applications. Numerous studies have shown that automated code analyses are adopted by developers only if they yield a good \"signal to noise ratio\", i.e., high precision. Many previous studies have reported analysis precision quantitatively, but this gives little insight into what can and should be done to increase precision further. To guide future research on increasing precision, we present a comprehensive study that evaluates static Android taint-analysis results on a qualitative level. To unravel the exact nature of taint flows, we have designed COVA, an analysis tool to compute partial path constraints that inform about the circumstances under which taint flows may actually occur in practice. We have conducted a qualitative study on the taint flows reported by FlowDroid in 1,022 real-world\u00a0\u2026", "num_citations": "8\n", "authors": ["270"]}
{"title": "Codebase-adaptive detection of security-relevant methods\n", "abstract": " More and more companies use static analysis to perform regular code reviews to detect security vulnerabilities in their code, configuring them to detect various types of bugs and vulnerabilities such as the SANS top 25 or the OWASP top 10. For such analyses to be as precise as possible, they must be adapted to the code base they scan. The particular challenge we address in this paper is to provide analyses with the correct security-relevant methods (Srm): sources, sinks, etc. We present SWAN, a fully-automated machine-learning approach to detect sources, sinks, validators, and authentication methods for Java programs. SWAN further classifies the Srm into specific vulnerability classes of the SANS top 25. To further adapt the lists detected by SWAN to the code base and to improve its precision, we also introduce SWANAssist, an extension to SWAN that allows analysis users to refine the classifications. On\u00a0\u2026", "num_citations": "8\n", "authors": ["270"]}
{"title": "Cheetah: just-in-time taint analysis for android apps\n", "abstract": " Current static-analysis tools are often long-running, which causes them to be sidelined into nightly build checks. As a result, developers rarely use such tools to detect bugs when writing code, because they disrupt their workflow. In this paper, we present Cheetah, a static taint analysis tool for Android apps that interleaves bug fixing and code development in the Eclipse integrated development environment. Cheetah is based on the novel concept of Just-in-Time static analysis that discovers and reports the most relevant results to the developer fast, and computes the more complex results incrementally later. Unlike traditional batch-style static-analysis tools, Cheetah causes minimal disruption to the developer's workflow. This video demo showcases the main features of Cheetah: https://www.youtube.com/watch?v=i_KQD-GTBdA.", "num_citations": "8\n", "authors": ["270"]}
{"title": "Toward an automated benchmark management system\n", "abstract": " The systematic evaluation of program analyses as well as software-engineering tools requires benchmark suites that are representative of real-world projects in the domains for which the tools or analyses are designed. Such benchmarks currently only exist for a few research areas and even where they exist, they are often not effectively maintained, due to the required manual effort. This makes evaluating new analyses and tools on software that relies on current technologies often impossible. We describe ABM, a methodology to semi-automatically mine software repositories to extract up-to-date and representative sets of applications belonging to specific domains. The proposed methodology facilitates the creation of such collections and makes it easier to release updated versions of a benchmark suite. Resulting from an instantiation of the methodology, we present a collection of current real-world Java business\u00a0\u2026", "num_citations": "8\n", "authors": ["270"]}
{"title": "A brief tour of join point interfaces\n", "abstract": " In standard AspectJ, aspects and base code are often insufficiently decoupled, as aspects hold pointcuts, which can contain explicit textual references to base code. This hinders aspect evolution and reuse, and may hinder reasoning about aspects on the base-code side. In this demo we present join point interfaces as an extension to the aspect-oriented programming language AspectJ. Opposed to AspectJ, with join point interfaces aspects and base code communicate only through a shared interface abstraction. Aspects themselves go without pointcuts and only reference the interface. Pointcuts are typically defined on the base-code side, or not at all, as join point interfaces also support pure explicit invocation as known from publish-subscribe systems. As a result, users obtain a language which decouples aspects from base code using a modular type-checking algorithm, and which they can use to adopt aspects\u00a0\u2026", "num_citations": "8\n", "authors": ["270"]}
{"title": "Taming Reflection--Static Analysis in the Presence of Reflection and Custom Class Loaders\n", "abstract": " Static program analyses and transformations for Java face many problems when analyzing programs that use reflection or custom class loaders: How can a static analysis know which reflective calls the program will execute? How can the analysis get hold of a class that the program may load from a remote location or even generate on the fly? And if its results are used to transform classes offline, how can it ensure that the transformed classes are re-inserted into a running program that uses custom class loaders? In this paper we present TAMIFLEX, a tool set for taming reflection. TAMIFLEX consists of two novel instrumentation agents. The Play-out Agent logs reflective calls into a log file and gathers all loaded classes, including generated ones. The Play-in Agent re-inserts offline-transformed classes into", "num_citations": "8\n", "authors": ["270"]}
{"title": "State of the systems security\n", "abstract": " Software-intensive systems are increasingly pervading our everyday lives. As they get more and more connected, this opens them up to far-reaching cyber attacks. Moreover, a recent study by the US Department of Homeland Security shows that more than 90% of current cyber-attacks are enabled not by faulty crypto, networks or hardware but by application-level implementation vulnerabilities. I argue that those problems can only be resolved by the widespread introduction of a secure software development lifecycle (SDLC). In this technical briefing I explain where secure engineering currently fails in practice, and what software engineers can do if they want to make a positive impact in the field. I will do so by explaining major open challenges in the field, but also by resorting to success stories from the introduction of SDLCs in industry.", "num_citations": "7\n", "authors": ["270"]}
{"title": "Computation on encrypted data using data flow authentication\n", "abstract": " Encrypting data before sending it to the cloud protects it against hackers and malicious insiders, but requires the cloud to compute on encrypted data. Trusted (hardware) modules, e.g., secure enclaves like Intel's SGX, can very efficiently run entire programs in encrypted memory. However, it already has been demonstrated that software vulnerabilities give an attacker ample opportunity to insert arbitrary code into the program. This code can then modify the data flow of the program and leak any secret in the program to an observer in the cloud via SGX side-channels. Since any larger program is rife with software vulnerabilities, it is not a good idea to outsource entire programs to an SGX enclave. A secure alternative with a small trusted code base would be fully homomorphic encryption (FHE) -- the holy grail of encrypted computation. However, due to its high computational complexity it is unlikely to be adopted in the near future. As a result researchers have made several proposals for transforming programs to perform encrypted computations on less powerful encryption schemes. Yet, current approaches fail on programs that make control-flow decisions based on encrypted data. In this paper, we introduce the concept of data flow authentication (DFAuth). DFAuth prevents an adversary from arbitrarily deviating from the data flow of a program. Hence, an attacker cannot perform an attack as outlined before on SGX. This enables that all programs, even those including operations on control-flow decision variables, can be computed on encrypted data. We implemented DFAuth using a novel authenticated homomorphic encryption scheme, a Java\u00a0\u2026", "num_citations": "7\n", "authors": ["270"]}
{"title": "Information flow analysis for go\n", "abstract": " We present the current state of the art of information flow analyses for Go applications. Based on our findings, we discuss future directions of where static analysis information can be used at runtime to for example achieve higher precision, or optimise runtime checks. We focus specifically on outstanding language features such as closures and message-based communication via channels.", "num_citations": "7\n", "authors": ["270"]}
{"title": "A systematic literature review of model-driven security engineering for cyber\u2013physical systems\n", "abstract": " The last years have elevated the importance of cyber\u2013physical systems like IoT applications, smart cars, or industrial control systems, and, therefore, these systems have also come into the focus of attackers. In contrast to software products running on PCs or smartphones, updating and maintaining cyber\u2013physical systems presents a major challenge. This challenge, combined with the often decades-long lifetime of cyber\u2013physical systems, and with their deployment in often safety-critical contexts, makes it particularly important to consider their security already at design time. When aiming to obtain a provably secure design, model-driven security approaches are key, as they allow to identify and mitigate threats in early phases of the development. As attacks may exploit both code-level as well as physical vulnerabilities, such approaches must consider not just the cyber layer but the physical layer as well. To find out\u00a0\u2026", "num_citations": "6\n", "authors": ["270"]}
{"title": "CogniCryptGEN: generating code for the secure usage of crypto APIs\n", "abstract": " Many software applications are insecure because they misuse cryptographic APIs. Prior attempts to address misuses focused on detecting them after the fact. However, avoiding such misuses in the first place would significantly reduce development cost.", "num_citations": "6\n", "authors": ["270"]}
{"title": "Towards cross-platform cross-language analysis with soot\n", "abstract": " To assess the security and quality of the growing number of programs on desktop computers, mobile devices, and servers, companies often rely on static analysis techniques. While static analysis has been applied successfully to various problems, the academic literature has largely focused on a subset of programming languages and frameworks, and often only on a single language at a time. Many tools have been created for Java and Android. In this paper, we present a first step toward re-using the existing Soot framework and its analyses for other platforms. We implement a frontend for converting the CIL assembly code of the. net Framework into Soot's Jimple code and show that this is possible without modifying Jimple nor overly losing semantic information. The frontend integrates Java/Android with CIL analysis and scales to large programs. A case study demonstrates the detection of real-world malware that\u00a0\u2026", "num_citations": "6\n", "authors": ["270"]}
{"title": "(In)Security of Backend-as-a-Service\n", "abstract": " Since recent years, more and more tasks in personal data processing are performed by smartphone applications. Users store and manage an increasing amount of sensitive information inside these apps and expect the data to be available across devices and platforms. Applica-tion developers, on the other hand, are pressed to deliver new applications faster and with more features. As a consequence, they outsource tasks such as backend provisioning to specialized service providers. In this paper, we perform a study on the security of Backend-as-a-Service (BaaS) and its practical use in real-world Android and iOS applications. As we show, many apps embed hard-coded credentials, putting not only the user\u2019s data, but the whole platform at risk. We show that with current tools attackers can gain access to huge amounts of sensitive data such as millions of verified e-mail addresses, thousands of health records, complete employee and customer databases, voice records, etc. Often, one can manipulate, and delete records at will. Some BaaS instances even suffer from remote code-execution vulnerabilities. We provide HAVOC, a fully-automated tool for finding potentially vul-nerable applications and a fully-automated exploit generator that extracts the required credentials from the app and checks their validity with the BaaS backend. We analyzed over 2,000,000 applications from the Google Play Store and alternative markets and found over 1,000 backend cre-dentials, many of them re-used in several applications. In total over all apps, we found that more than 18,670,000 records with over 56,000,000 individual data items were freely accessible. 1", "num_citations": "6\n", "authors": ["270"]}
{"title": "Modular reasoning with join point interfaces\n", "abstract": " In current aspect-oriented systems, aspects usually carry, through their pointcuts, explicit references to the base code. Those references are fragile and give up important software engineering properties such as modular reasoning and independent evolution of aspects and base code. A well-studied solution to this problem consists in separating base code and aspects using an intermediate interface abstraction. In this work, we show that previous approaches fail at restoring modular reasoning because they do not provide modular type checking; programs can fail to compose when woven, even though their interfaces are compatible. We introduce a novel abstraction called Join Point Interfaces, which, by design, supports modular reasoning and independent evolution by providing a modular type-checking algorithm. Join point interfaces further offer polymorphic dispatch on join points, with an advice-dispatch semantics akin to multi-methods. As we show, our semantics solves important problems present in previous approaches to advice dispatch. We have fully implemented join point interfaces as an opensource extension to the AspectBench Compiler. A study on existing aspect-oriented programs of varying sizes and domains supports our major design choices and reveals potential for exploiting polymorphism through non-trivial join-point type hierarchies.", "num_citations": "6\n", "authors": ["270"]}
{"title": "Instance keys: A technique for sharpening whole-program pointer analyses with intraprocedural information\n", "abstract": " Pointer analyses enable many subsequent program analyses and transformations, since they enable compilers to statically disambiguate references to the heap. Extra precision enables pointer analysis clients to draw stronger conclusions about programs. Flow-sensitive pointer analyses are typically quite precise. Unfortunately, flow-sensitive pointer analyses are also often too expensive to run on whole programs. This paper therefore describes a technique which sharpens results from a whole-program flow-insensitive points-to analysis using two flow-sensitive intraprocedural analyses: a must-not-alias analysis and a must-alias analysis. The main technical idea is the notion of instance keys, which enable client analyses to disambiguate object references. We distinguish two kinds of keys: weak and strong. Strong instance keys guarantee that different keys represent different runtime objects, allowing instance keys to almost transparently substitute for runtime objects in static analyses. Weak instance keys may represent multiple runtime objects, but still enable disambiguation of compile-time values. We assign instance keys based on the results of our analyses. We found that the use of instance keys greatly simplified the design and implementation of subsequent analysis phases.", "num_citations": "6\n", "authors": ["270"]}
{"title": "Dynamically provisioning isolation in hierarchical architectures\n", "abstract": " Physical isolation provides tenants in a cloud with strong security guarantees, yet dedicating entire machines to tenants would go against cloud computing\u2019s tenet of consolidation. A fine-grained isolation model allowing tenants to request fractions of dedicated hardware can provide similar guarantees at a lower cost.                 In this work, we investigate the dynamic provisioning of isolation at various levels of a system\u2019s architecture, primarily at the core, cache, and machine level, as well as their virtualised equivalents. We evaluate recent technological developments, including post-copy VM migration and OS containers, and show how they assist in improving reconfiguration times and utilisation. We incorporate these concepts into a unified framework, dubbed SafeHaven, and apply it to two case studies, showing its efficacy both in a reactive, as well as an anticipatory role. Specifically, we describe its use in\u00a0\u2026", "num_citations": "5\n", "authors": ["270"]}
{"title": "Specifying and exploiting advice-execution ordering using dependency state machines\n", "abstract": " In this paper we present Dependency State Machines, an annotation language that extends AspectJ with finite-state machines that define the order in which pieces of advice must execute to have a visible effect. Dependency State Machines facilitate the automatic verification and optimization of aspects, but also program understanding. In this work we present the syntax and semantics of Dependency State Machines and one possible use case of Dependency State Machines: program understanding. We explain how a set of three static program analyses can exploit the information that Dependency State Machines carry to remove advice-dispatch code from program locations at which dispatching the advice would have no effect. Dependency State Machines hereby help to abstract from the concrete implementation of the aspect, making the approach compatible with a wide range of aspect-generating monitoring tools.Our extensive evaluation using the DaCapo benchmark suite shows that our approach can pinpoint to the user exactly the program locations at which the aspect\u2019s execution matters in many cases. This is particularly useful when the aspect\u2019s purpose is to identify erroneous execution sequences: in these cases, the program locations that our analysis pinpoints resemble possible points of program failure.", "num_citations": "5\n", "authors": ["270"]}
{"title": "Flow-sensitive static optimizations for runtime monitors\n", "abstract": " Runtime monitoring enables developers to specify code that executes whenever certain sequences of events occur during program execution. Tracematches, a Java language extension, permit developers to specify and execute runtime monitors. Tracematches consist of regular expressions over events, where each event may specify free variables that are bound to run-time objects. Na\u0131ve implementations of runtime monitoring are expensive and can cause prohibitive slowdowns. In previous work, we proposed optimizations based on flow-insensitive pointer analyses. While these optimizations worked well in most cases, more difficult cases with large overheads remained. In this paper, we propose three novel intraprocedural optimizations with the goal of eliminating the overhead from runtime monitors. Our optimizations rely on flow-sensitivity and precise local may-alias and must-alias information. The first two optimizations identify and remove unnecessary instrumentation, while the third one hoists instrumentation out of loop bodies. We applied our transformations to seven difficult combinations of tracematches with programs from the DaCapo benchmark suite which defeated our earlier analyses. Our results show that our three optimizations, in combination, can remove much of the instrumentation in this benchmark set. For two of the seven cases, we can remove all instrumentation: our analysis successfully shows that the benchmark programs will always satisfy the verification properties stated in the tracematches. Our results furthermore suggest that our analysis can detect hidden method preconditions which ought to be documented and\u00a0\u2026", "num_citations": "5\n", "authors": ["270"]}
{"title": "Sootdiff: Bytecode comparison across different java compilers\n", "abstract": " Different Java compilers and compiler versions, eg, javac or ecj, produce different bytecode from the same source code. This makes it hard to trace if the bytecode of an open-source library really matches the provided source code. Moreover, it prevents one from detecting which open-source libraries have been re-compiled and rebundled into a single jar, which is a common way to distribute an application. Such rebundling is problematic because it prevents one to check if the jar file contains open-source libraries with known vulnerabilities. To cope with these problems, we propose the tool SootDiff that uses Soot's intermediate representation Jimple, in combination with code clone detection techniques, to reduce dissimilarities introduced by different compilers, and to identify clones. Our results show that SootDiff successfully identifies clones in 102 of 144 cases, whereas bytecode comparison succeeds in 58 cases\u00a0\u2026", "num_citations": "4\n", "authors": ["270"]}
{"title": "Architectural runtime verification\n", "abstract": " Analyzing runtime behavior is an important part of developing and verifying software systems. This is especially true for complex component-based systems used in the vehicle industry. Here, locating the actual cause of (mis-)behavior can be time-consuming, because the analysis is usually not performed on the architecture level, where the system has initially been designed. Instead, it often relies on source code debugging or visualizing signals and events. The results must then be correlated to what is expected regarding the architecture. With an ever-growing complexity of the systems, the advent of model-based development, code generators and the distributed nature of the development process, this becomes increasingly difficult. This paper therefore presents Architectural Runtime Verification (ARV), a generic approach to analyze system behavior on architecture level using the principles of Runtime\u00a0\u2026", "num_citations": "4\n", "authors": ["270"]}
{"title": "Gamifying static analysis\n", "abstract": " In the past decades, static code analysis has become a prevalent means to detect bugs and security vulnerabilities in software systems. As software becomes more complex, analysis tools also report lists of increasingly complex warnings that developers need to address on a daily basis. The novel insight we present in this work is that static analysis tools and video games both require users to take on repetitive and challenging tasks. Importantly, though, while good video games manage to keep players engaged, static analysis tools are notorious for their lacking user experience, which prevents developers from using them to their full potential, frequently resulting in dissatisfaction and even tool abandonment. We show parallels between gaming and using static analysis tools, and advocate that the user-experience issues of analysis tools can be addressed by looking at the analysis tooling system as a whole, and\u00a0\u2026", "num_citations": "4\n", "authors": ["270"]}
{"title": "VisuFlow: a Debugging Environment for Static Analyses\n", "abstract": " VisuFlow: a Debugging Environment for Static Analyses - TUbiblio TUbiblio TU Darmstadt / ULB / TUbiblio VisuFlow: a Debugging Environment for Static Analyses Nguyen, Lisa ; Kr\u00fcger, Stefan ; Hill, Patrick ; Ali, Karim ; Bodden, Eric (2018): VisuFlow: a Debugging Environment for Static Analyses. In: ICSE, ACM, [Konferenzver\u00f6ffentlichung] Typ des Eintrags: Konferenzver\u00f6ffentlichung Erschienen: 2018 Autor(en): Nguyen, Lisa ; Kr\u00fcger, Stefan ; Hill, Patrick ; Ali, Karim ; Bodden, Eric Titel: VisuFlow: a Debugging Environment for Static Analyses Sprache: Deutsch Buchtitel: ICSE Verlag: ACM Freie Schlagworte: Engineering; E1; Debugging, Static analysis, IDE, Survey, User Study, Empirical Software Engineering Fachbereich(e)/-gebiet(e): 20 Fachbereich Informatik 20 Fachbereich Informatik > Security Engineering DFG-Sonderforschungsbereiche (inkl. Transregio) DFG-Sonderforschungsbereiche (inkl. Transregio) > > (-\u2026", "num_citations": "4\n", "authors": ["270"]}
{"title": "Towards a Comprehensive Model of Isolation for Mitigating Illicit Channels\n", "abstract": " The increased sharing of computational resources elevates the risk of side channels and covert channels, where an entity\u2019s security is affected by the entities with which it is co-located. This introduces a strong demand for mechanisms that can effectively isolate individual computations. Such mechanisms should be efficient, allowing resource utilisation to be maximised despite isolation.                 In this work, we develop a model for uniformly describing isolation, co-location and containment relationships between entities at multiple levels of a computer\u2019s architecture and at different granularities. In particular, we examine the formulation of constraints on co-location and placement using partial specifications, as well as the cost of maintaining isolation guarantees on dynamic systems. We apply the model to a number of established attacks and mitigations.", "num_citations": "4\n", "authors": ["270"]}
{"title": "A high-level view of java applications\n", "abstract": " Static analysis of object-oriented applications has become widespread over the last decade, mainly in the context of compile-time optimizations. The paper describes how static analysis of virtual method calls can be employed to provide a high-level view of Java applications. The result is a method call graph that can be built from either source or bytecode, and a graphical browser that enables the user to analyze control flow and the coupling between classes and packages in an intuitive fashion, thereby supporting application design as well as refactoring and debugging. In order to achieve the necessary bijection between source and bytecode representations of classes, we implement a new approach based on source code pre-processing.", "num_citations": "4\n", "authors": ["270"]}
{"title": "Explaining Static Analysis-A Perspective\n", "abstract": " Static code analysis is widely used to support the development of high-quality software. It helps developers detect potential bugs and security vulnerabilities in a program's source code without executing it. While the potential benefits of static analysis tools are beyond question, their usability is often criticised and prevents software developers from using static analysis to its full potential. In the past decade, researchers have studied developer needs and contrasted them to available static analysis tool functionalities. In this paper, we summarize the main design challenges for building usable static analysis tools, and show that they revolve around the notion of explainability, which is a subarea of usability. We present existing analysis tools and current research in static analysis usability, and detail how they approach those challenges. This leads us to proposing potential lines of future work in explainability for static\u00a0\u2026", "num_citations": "3\n", "authors": ["270"]}
{"title": "Reverse Engineering Android Apps With CodeInspect\n", "abstract": " While the Android operating system is popular among users, it has also attracted a broad variety of miscreants and malware. New samples are discovered every day. Purely automatic analysis is often not enough for understanding current state-of-the-art Android malware, though. Miscreants obfuscate and encrypt their code, or hide secrets in native code. Precisely identifying the malware\u2019s behavior and finding information about its potential authors requires tools that assist human experts in a manual investigation. In this paper, we present CodeInspect, a novel reverse engineering tool for Android app that optimally supports investigators and analysts in that task.", "num_citations": "3\n", "authors": ["270"]}
{"title": "Challenges for refinement and composition of instrumentations: Position paper\n", "abstract": " Instrumentation techniques are widely used for implementing dynamic program analysis tools like profilers or debuggers. While there are many toolkits and frameworks to support the development of such low-level instrumentations, there is little support for the refinement or composition of instrumentations. A common practice is thus to copy and paste from existing instrumentation code. This, of course, violates well-established software engineering principles, results in code duplication, and hinders maintenance. In this position paper we identify two challenges regarding the refinement and composition of instrumentations and illustrate them with a running example.", "num_citations": "3\n", "authors": ["270"]}
{"title": "Safe and practical decoupling of aspects with join point interfaces\n", "abstract": " In current aspect-oriented systems, aspects usually carry, through their pointcuts, explicit references to the base code. Those references are fragile and give up important software engineering properties such as modular reasoning and independent evolution of aspects and base code. In this work, we introduce a novel abstraction called Join Point Interfaces, which, by design, supports modular reasoning and independent evolution by decoupling aspects from base code and by providing a modular type-checking algorithm. Join point interfaces can be used both with implicit announcement through pointcuts, and with explicit announcement, using closure join points. Join point interfaces further offer polymorphic dispatch on join points, with an advice-dispatch semantics akin to multi-methods. In this work, we show how our proposal solves a large number of problems observed in previous related approaches. We have implemented join point interfaces as an open-source extension to AspectJ. A first study on existing aspect-oriented programs supports our initial design in general, but also highlights some limitations, which we then address by introducing parametric polymorphism and a more permissive quantification mechanism. As a result, join point interfaces are a safe and practical way of decoupling aspects.", "num_citations": "3\n", "authors": ["270"]}
{"title": "Static analysis techniques for evaluating runtime monitoring properties ahead-of-time\n", "abstract": " Runtime monitoring enables developers to specify code that executes whenever certain sequences of events occur during program execution. In particular, runtime monitors can check for illegal API uses, such as attempts to read from already-closed files. This paper presents techniques for evaluating runtime monitoring properties ahead-of-time. Statically evaluating runtime monitors is advantageous for two reasons: 1) it enables the optimization and removal of unnecessary monitoring code; furthermore, 2) it can increase developers\u2019 confidence that their programs conform to their stated correctness properties. In the best case, static analysis can successfully guarantee that a program never violates those properties at all.Our work focuses on tracematches, a monitoring notation based on regular expressions with free variables over program events that bind these variables to heap objects. Statically deciding properties of tracematches is difficult: tracematches bind heap objects throughout the course of their evaluation. One might expect that an interprocedural flow-sensitive analysis would be required. However, our approach successfully analyzes tracematches by combining inexpensive whole-program summary information with a suite of carefully-designed intraprocedural flow-sensitive analyses. Our analyses use a novel abstraction which captures both positive information, indicating that an object could be associated with a particular monitor state, and negative information, indicating that the object is known not to be in a state. This abstraction enables us to eliminate unnecessary monitoring instrumentation. We implemented our analyses and\u00a0\u2026", "num_citations": "3\n", "authors": ["270"]}
{"title": "The design and implementation of formal monitoring techniques\n", "abstract": " In runtime monitoring, a programmer specifies a piece of code to execute when a trace of events occurs during program execution. Previous and related work has shown that runtime monitoring techniques can beuseful in order to validate or guarantee the safety and security of running programs. Yet, those techniques have not yet been able to make the transition to everyday use in regular software development processes. This is due to two reasons. Firstly, many of the existing runtime monitoring tools cause a significant runtime overhead, lengthening test runs unduly. This is particularly true for tools that allow reasoning about single objects, opposed to classes. Secondly, the kind of specifications that can be verified by such tools often follow a quite cumbersome notation. This leads to the fact that only verification experts, not programmers, can at all understand what a given specification means and in particular\u00a0\u2026", "num_citations": "3\n", "authors": ["270"]}
{"title": "Efficient temporal pointcuts through dynamic advice deployment\n", "abstract": " In previous work we and others have studied the applicability of various trace based matching approaches such as tracematches [2], tracecuts [15] and tracechecks [6, 14, 5](through our prototype tool J-LO, the Java Logical Observer). Such formalisms provide users with an expressive matching language that gives explicit and well-defined access to an application\u2019s execution history. In some approaches, even free variables in expressions can dynamically be bound to objects on the execution trace. This avoids having to use data structures such as hash maps or sets in oder to implement such object-related properties. In this work we demonstrate that besides the aforementioned issues of more convenient programming, such temporal pointcuts yield a large potential for possible optimizations through runtime deployment of aspects, due to their well-defined structure. Functionally equivalent code in pure AspectJ would not necessarily yield such a potential. This feature of trace languages adds well to static optimizations such as control flow and dataflow analysis as it has been proposed in [2]. We do not want to give a fully fledged endto-end solution here, which may restrict us to a certain specification formalism or runtime weaving approach. Instead, we show up general potential for optimizations through dynamic deployment as a pointer to future research on the field.", "num_citations": "3\n", "authors": ["270"]}
{"title": "Explaining static analysis with rule graphs\n", "abstract": " As static data-flow analysis becomes able to report increasingly complex bugs, using an evergrowing set of complex internal rules encoded into flow functions, the analysis tools themselves grow more and more complex. In result, for users to be able to effectively use those tools on specific codebases, they require special configurations\u2014a task which in industry is typically performed by individual developers or dedicated teams. To efficiently use and configure static analysis tools, developers need to build a certain understanding of the analysis' rules, i.e., how the underlying analyses interpret the analyzed code and their reasoning for reporting certain warnings. In this article, we explore how to assist developers in understanding the analysis' warnings, and finding weaknesses in the analysis' rules. To this end, we introduce the concept of rule graphs that expose to the developer selected information about the\u00a0\u2026", "num_citations": "2\n", "authors": ["270"]}
{"title": "ModGuard: Identifying Integrity &Confidentiality Violations in Java Modules\n", "abstract": " With version 9, Java has been given the new module system Jigsaw. Major goals were to simplify maintainability of the JDK and improve its security by encapsulating modules' internal types. While the module system successfully limits the visibility of internal types, it does not prevent sensitive data from escaping. Since the module system reasons about types only, objects are allowed to escape even if that module declares the type as internal. Finding such unintended escapes is important, as they may violate a module's integrity and confidentiality, but is a complex task as it requires one to reason about pointers and type hierarchy. We thus present ModGuard, a novel static analysis based on Doop which complements the Java module system with an analysis to automatically identify instances that escape their declaring module. Along with ModGuard we contribute a complete formal definition of a module's\u00a0\u2026", "num_citations": "2\n", "authors": ["270"]}
{"title": "VISUFLOW: a debugging environment for static analyses\n", "abstract": " Code developers in industry frequently use static analysis tools to detect and fix software defects in their code. But what about defects in the static analyses themselves? While debugging application code is a difficult, time-consuming task, debugging a static analysis is even harder. We have surveyed 115 static analysis writers to determine what makes static analysis difficult to debug, and to identify which debugging features would be desirable for static analysis. Based on this information, we have created Visijflow, a debugging environment for static data-flow analysis. Visuflow is built as an Eclipse plugin, and supports analyses written on top of the program analysis framework Soot. The different components in Visuflow provide analysis writers with visualizations of the internal computations of the analysis, and actionable debugging features to support debugging static analyses. A video demo of Visuflow is\u00a0\u2026", "num_citations": "2\n", "authors": ["270"]}
{"title": "Challenges in defining a programming language for provably correct dynamic analyses\n", "abstract": " Modern software systems are not only famous for being ubiquitous and large scale but also infamous for being inherently insecure. We argue that a large part of this problem is due to the fact that current programming languages do not provide adequate built-in support for addressing security concerns. In this work we outline the challenges involved in developing Codana, a novel programming language for defining provably correct dynamic analyses. Codana analyses form security monitors; they allow programmers to proactively protect their programs from security threats such as insecure information flows, buffer overflows and access-control violations. We plan to design Codana in such a way that program analyses will be simple to write, read and prove correct, easy to maintain and reuse, efficient to compile, easy to parallelize, and maximally amenable to static optimizations. This is difficult as, nevertheless\u00a0\u2026", "num_citations": "2\n", "authors": ["270"]}
{"title": "Clara: a framework for implementing hybrid typestate analyses\n", "abstract": " We present Clara, a novel static-analysis framework for the implementation of hybrid static/dynamic typestate analyses. Clara uses static typestate analyses to automatically convert any AspectJ monitoring aspect into a residual runtime monitor that only monitors events triggered by program locations that the analyses failed to prove safe. If the static analysis succeeds on all locations, this gives strong static guarantees. If not, the efficient residual runtime monitor is guaranteed to capture property violations at runtime. Researchers can easily integrate their own static typestate analyses into Clara. We instantiated Clara with three static typestate analyses and applied these analyses to monitoring aspects generated from tracematches and by the JavaMOP runtime-monitoring tool. Clara is available as open source. We hope that other researchers will soon be joining us in using Clara, and that this will foster progress in the field of typestate analysis.", "num_citations": "2\n", "authors": ["270"]}
{"title": "Transforming timeline specifications into automata for runtime monitoring\n", "abstract": " In runtime monitoring, a programmer specifies code to execute whenever a sequence of events occurs during program execution. Previous and related work has shown that runtime monitoring techniques can be useful in order to validate or guarantee the safety and security of running programs. Those techniques have however not been incorporated in everyday software development processes. One problem that hinders industry adoption is that the required specifications use a cumbersome, textual notation. As a consequence, only verification experts, not programmers, can understand what a given specification means and in particular, whether it is correct. In 2001, researchers at Bell Labs proposed the Timeline formalism. This formalism was designed with ease of use in mind, for the purpose of static verification (and not, as in our work, for runtime monitoring).               In this article, we describe how\u00a0\u2026", "num_citations": "2\n", "authors": ["270"]}
{"title": "Tracechecks: Combining tracematches and temporal logic\n", "abstract": " In this work we introduce tracechecks, a powerful formalism based on linear temporal logic (LTL) with variable bindings and AspectJ pointcuts for the purpose of verification. We demonstrate how tracechecks can be used in order to detect semantic conflicts at runtime. Such conflicts can generally arise in any application. In the presence of aspects, the formal specification of control flow properties becomes even more important, which we demonstrate by examples. We explain in detail how we make use of AspectJ pointcuts to derive a formal model of an existing application and use LTL to express temporal assertions over this model. Tracechecks are closely related to tracematches, an AspectJ extension provided in the AspectBench Compiler (abc). Tracematches allow to specify trace conditions in the form of regular expressions.We provide an extensive comparison of tracechecks and tracematches, specifically\u00a0\u2026", "num_citations": "2\n", "authors": ["270"]}
{"title": "JAnalyzer, a visual static analyzer for Java\n", "abstract": " Object-oriented (OO) programming has well-known benefits, producing reusable, modular, well-structured code. Nevertheless, program development is still hard, especially for large programs that consist of thousands of interacting objects. Faults in one method can propagate to others defined in different classes or even different packages.  The programmer would benefit from a high-level, intuitive, graphical view of these method dependencies. Such a view would aid refactoring by revealing the degree of coupling between different parts of the program as well as save debugging time by allowing design faults to be visualized at implementation time in a straightforward way. Our research concentrated on Java due to its increasing popularity and platform independence.   In contrast to classic imperative programming paradigms, the development of such a view is a non-trivial task for OO languages, because methods are typically invoked through dynamic dispatch . the type of the object on which the method will actually be invoked is not known at compile time. Such polymorphism has the benefit to the programmer of reusable code, but means that the relationship between caller and callee is 1:many rather than 1:1. A type analysis for Java is therefore required to synthesise a set of possible types for each object identifier in the program. Inferring these sets is a complex task, which we explain further below. Our research concentrated on Java due to its platform independence and increasing popularity.  Our standalone tool, JAnalyzer, aids program development by:  construction of call-graphs by state of the art analyses  visual representation of inter\u00a0\u2026", "num_citations": "2\n", "authors": ["270"]}
{"title": "TaintBench: Automatic real-world malware benchmarking of Android taint analyses\n", "abstract": " Due to the lack of established real-world benchmark suites for static taint analyses of Android applications, evaluations of these analyses are often restricted and hard to compare. Even in evaluations that do use real-world apps, details about the ground truth in those apps are rarely documented, which makes it difficult to compare and reproduce the results. To push Android taint analysis research forward, this paper thus recommends criteria for constructing real-world benchmark suites for this specific domain, and presents TaintBench, the first real-world malware benchmark suite with documented taint flows. TaintBench benchmark apps include taint flows with complex structures, and addresses static challenges that are commonly agreed on by the community. Together with the TaintBench suite, we introduce the TaintBench framework, whose goal is to simplify real-world benchmarking of Android taint\u00a0\u2026", "num_citations": "1\n", "authors": ["270"]}
{"title": "Qualitative and Quantitative Analysis of Callgraph Algorithms for Python\n", "abstract": " As one of the most popular programming languages, PYTHON has become a relevant target language for static analysis tools. The primary data structure for performing an inter-procedural static analysis is call-graph (CG), which links call sites to potential call targets in a program. There exists multiple algorithms for constructing callgraphs, tailored to specific languages. However, comparatively few implementations target PYTHON. Moreover, there is still lack of empirical evidence as to how these few algorithms perform in terms of precision and recall. This paper thus presents EVAL_CG, an extensible framework for comparative analysis of Python call-graphs. We conducted two experiments which run the CG algorithms on different Python programming constructs and real-world applications. In both experiments, we evaluate three CG generation frameworks namely, Code2flow, Pyan, and Wala. We record precision\u00a0\u2026", "num_citations": "1\n", "authors": ["270"]}
{"title": "Lossless, Persisted Summarization of Static Callgraph, Points-To and Data-Flow Analysis\n", "abstract": " Static analysis is used to automatically detect bugs and security breaches, and aids compiler optimization. Whole-program analysis (WPA) can yield high precision, however causes long analysis times and thus does not match common software-development workflows, making it often impractical to use for large, real-world applications. This paper thus presents the design and implementation of ModAlyzer, a novel static-analysis approach that aims at accelerating whole-program analysis by making the analysis modular and compositional. It shows how to compute lossless, persisted summaries for callgraph, points-to and data-flow information, and it reports under which circumstances this function-level compositional analysis outperforms WPA. We implemented ModAlyzer as an extension to LLVM and PhASAR, and applied it to 12 real-world C and C++ applications. At analysis time, ModAlyzer modularly and losslessly summarizes the analysis effect of the library code those applications share, hence avoiding its repeated re-analysis. The experimental results show that the reuse of these summaries can save, on average, 72% of analysis time over WPA. Moreover, because it is lossless, the module-wise analysis fully retains precision and recall. Surprisingly, as our results show, it sometimes even yields precision superior to WPA. The initial summary generation, on average, takes about 3.67 times as long as WPA.", "num_citations": "1\n", "authors": ["270"]}
{"title": "PASAPTO: Policy-aware Security and Performance Trade-off Analysis--Computation on Encrypted Data with Restricted Leakage\n", "abstract": " This work considers the trade-off between security and performance when revealing partial information about encrypted data computed on. The focus of our work is on information revealed through control flow side-channels when executing programs on encrypted data. We use quantitative information flow to measure security, running time to measure performance and program transformation techniques to alter the trade-off between the two. Combined with information flow policies, we perform a policy-aware security and performance trade-off (PASAPTO) analysis. We formalize the problem of PASAPTO analysis as an optimization problem, prove the NP-hardness of the corresponding decision problem and present two algorithms solving it heuristically. We implemented our algorithms and combined them with the Dataflow Authentication (DFAuth) approach for outsourcing sensitive computations. Our DFAuth Trade\u00a0\u2026", "num_citations": "1\n", "authors": ["270"]}
{"title": "Security-oriented fault-tolerance in systems engineering: a conceptual threat modelling approach for cyber-physical production systems\n", "abstract": " Faults in the realization and usage of cyber-physical systems can cause significant security issues. Attackers might exploit vulnerabilities in the physical configurations, control systems, or accessibility through internet connections. For CPS, two challenges are combined: Firstly, discipline-specific security measures should be applied. Secondly, new measures have to be created to cover interdisciplinary impacts. For instance, faulty software configurations in cyber-physical production systems (CPPS) might allow attackers to manipulate the correct control of production processes impacting the quality of end products. From liability and publicity perspective, a worst-case scenario is that such a corrupted product is delivered to a customer. In this context, security-oriented fault-tolerance in Systems Engineering (SE) requires measures to evaluate interdisciplinary system designs with regard to potential scenarios of\u00a0\u2026", "num_citations": "1\n", "authors": ["270"]}
{"title": "SWAN_ASSIST: Semi-Automated Detection of Code-Specific, Security-Relevant Methods\n", "abstract": " To detect specific types of bugs and vulnerabilities, static analysis tools must be correctly configured with security-relevant methods (SRM), e.g., sources, sinks, sanitizers and authentication methods-usually a very labour-intensive and error-prone process. This work presents the semi-automated tool SWAN_ASSIST, which aids the configuration with an IntelliJ plugin based on active machine learning. It integrates our novel automated machine-learning approach SWAN, which identifies and classifies Java SRM. SWAN_ASSIST further integrates user feedback through iterative learning. SWAN_ASSIST aids developers by asking them to classify at each point in time exactly those methods whose classification best impact the classification result. Our experiments show that SWAN_ASSIST classifies SRM with a high precision, and requires a relatively low effort from the user. A video demo of SWAN_ASSIST can be\u00a0\u2026", "num_citations": "1\n", "authors": ["270"]}
{"title": "Know your analysis: how instrumentation aids understanding static analysis\n", "abstract": " The development of a high-quality data-flow analysis---one that is precise and scalable---is a challenging task. A concrete client analysis not only requires data-flow but, in addition, type-hierarchy, points-to, and call-graph information, all of which need to be obtained by wisely chosen and correctly parameterized algorithms. Therefore, many static analysis frameworks have been developed that provide analysis writers with generic data-flow solvers as well as those additional pieces of information. Such frameworks ease the development of an analysis by requiring only a description of the data-flow problem to be solved and a set of framework parameters. Yet, analysis writers often struggle when an analysis does not behave as expected on real-world code. It is usually not apparent what causes a failure due to the complex interplay of the several algorithms and the client analysis code within such frameworks. In this\u00a0\u2026", "num_citations": "1\n", "authors": ["270"]}
{"title": "Explainable static analysis\n", "abstract": " Static code analysis is an important tool that aids in the early detection of programming mistakes, including functional aws, performance bottlenecks and security vulnerabilities. Past research in static analysis has mainly focused on the precise and e cient detection of programming mistakes, allowing new analyses to return more accurate results in a shorter time. However, end-user experience in industry has shown high abandonment rates for static analysis tools. Previous work has shown that current analysis tools are ill-adapted to meet the needs of their users, taking a long time to yield results and causing warnings to be frequently misinterpreted. This can quickly make the overall bene t of static analyses deteriorate. In this work, we argue for the need of developing a line of research on aiding users of static analysis tools, e.g., code developers, to better understand the findings reported by those tools. We outline how we plan to address this problem space by a novel line of research that ultimately seeks to change static analysis tools from being tools for static analysis experts to tools that can be mastered by general code developers. To achieve this goal, we plan to develop novel techniques for formulating, inspecting and debugging static analyses and the rule sets they validate programs against.", "num_citations": "1\n", "authors": ["270"]}
{"title": "Toward a just-in-time static analysis\n", "abstract": " Despite years if not decades of research and development on static analysis tools, industrial adaption of much of this tooling remains spotty. Some of this is due to familiar shortcomings with the tooling itself: the effect of false positives on developer satisfaction is well known. However, in this paper, we argue that static-analysis results often run against some cognitive barriers. In other words, the developer is not able to grasp the results easily, leading to higher abandonment rates for analysis tools.In this paper, we propose to improve the current situation with the idea of Just-In-Time (JIT) analyses. In a JIT analysis, results are presented to the user in order of difficulty, starting with easy-to-fix warnings. These warnings are designed to gently \u201ctrain\u201d the developer and prepare them for reasoning about and fixing more complex bugs. The analysis itself is designed to operate in layers, so that the next layer of results is being computed while the previous one is being examined. The desired effect is that static-analysis results are available just-in-time, with the developer never needing to wait for them to be computed.", "num_citations": "1\n", "authors": ["270"]}
{"title": "Zertifizierteapps\n", "abstract": " Was bei typischen IT-Produkten seit Jahren gang und g\u00e4be ist, klappt bei Apps nicht wirklich gut\u2013die Evaluierung und Zertifizierung gem\u00e4\u00df Common Criteria oder Datenschutz-G\u00fctesiegel innerhalb eines vern\u00fcnftigen Zeit-und Kostenrahmens. Apps entwickeln sich derart rasant\u2013und sind meist kostenlos oder g\u00fcnstig zu erwerben\u2013, dass ein v\u00f6llig neuartiges Pr\u00fcf-und Zertifizierungskonzept entwickelt werden muss. Dieses zu leisten, ist Gegenstand des Verbundprojektes \u201eZertApps \u201c, das in diesem Beitrag vorgestellt werden soll.", "num_citations": "1\n", "authors": ["270"]}
{"title": "Zertifizierte Datensicherheit f\u00fcr Android-Anwendungen auf Basis statischer Programmanalysen\n", "abstract": " Smartphones erfreuen sich einer stetig wachsenden Beliebtheit. Ein Grund hierf\u00fcr ist die Vielzahl verschiedenster mobiler Anwendungen. Mit den Chancen, die sich hierdurch f\u00fcr den Benutzer, aber auch Organisationen bieten, sind Risiken verbunden, die beispielsweise zu einer Verletzung der Privatsph\u00e4re f\u00fchren k\u00f6nnen. In diesem Beitrag diskutieren wir, wie statische Programmanalyse dabei helfen kann, Android-Anwendungen bzgl. der Sicherheit zu zertifizieren.", "num_citations": "1\n", "authors": ["270"]}
{"title": "Efficiently updating IDE-based data-flow analyses in response to incremental program changes\n", "abstract": " Most application code evolves incrementally, and especially so when being maintained after the applications have been deployed. Yet, most data-flow analyses do not take advantage of this fact. Instead they require clients to recompute the entire analysis even if little code has changed\u2014a time consuming undertaking, especially with large libraries or when running static analyses often, eg, on a continuous-integration server. In this work, we present Reviser, a novel approach for automatically and efficiently updating inter-procedural dataflow analysis results in response to incremental program changes. Reviser follows a clear-and-propagate philosophy, aiming at clearing and recomputing analysis information only where required, thereby greatly reducing the required computational effort. The Reviser algorithm is formulated as an extension to the IDE framework for Inter-procedural Finite Distributed Environment problems and automatically updates arbitrary IDE-based analyses. We have implemented Reviser as an open-source extension to the Heros IFDS/IDE solver and the Soot program-analysis framework. An evaluation of Reviser on various client analyses and target programs shows performance gains of up to 80% in comparison to a full recomputation. The experiments also show Reviser to compute the same results as a full recomputation on all instances tested.", "num_citations": "1\n", "authors": ["270"]}
{"title": "Delta-Oriented monitor specification\n", "abstract": " Delta-oriented programming allows software developers to define software product lines as variations of a common code base, where variations are expressed as so-called program deltas. Monitor-oriented programming (MOP) provides a mechanism to execute functionality based on the execution history of the program; this is useful, e.g., for the purpose of runtime verification and for enforcing security policies.               In this work we discuss how delta-oriented programming and MOP can benefit from each other in the Abstract Behavior Specification Language (ABS) through a new approach we call Delta-oriented Monitor Specification (DMS). We use deltas over monitor definitions to concisely capture protocol changes induced by feature combinations, and propose a notation to denote these deltas. In addition, we explore the design space for expressing runtime monitors as program deltas in ABS.               A\u00a0\u2026", "num_citations": "1\n", "authors": ["270"]}
{"title": "Towards typesafe weaving for modular reasoning in aspect-oriented programs\n", "abstract": " In previous work, we and others have studied how aspects can implement important cross-cutting concerns, such as runtime monitors, security monitors, and other security primitives. It is hard to design aspects that implement such concerns correctly. Therefore, once written, one desires to reuse the according aspect definitions for other systems. In current aspect-oriented systems, however, aspects usually carry, through their pointcuts, explicit references to the base code. Those references are fragile and give up important software engineering properties such as modular reasoning and independent evolution of aspects and base code, hence hindering aspect reuse. A well-studied solution to this problem is to separate base code and aspects using an intermediate interface abstraction.", "num_citations": "1\n", "authors": ["270"]}
{"title": "Continuation equivalence: a correctness criterion for static optimizations of dynamic analyses\n", "abstract": " Dynamic analyses reason about a program's concrete heap and control flow and hence can report on actual program behavior with high or even perfect accuracy. But many dynamic analyses require extensive program instrumentation, often slowing down the analyzed program considerably.", "num_citations": "1\n", "authors": ["270"]}
{"title": "Efficient and Precise Typestate Analysis by Determining Continuation-Equivalent States\n", "abstract": " Typestate analysis determines whether a program violates a set of finite-state properties. Because the typestate-analysis problem is statically undecidable, researchers have proposed a hybrid approach that uses residual monitors to signal property violations at runtime.We present an efficient novel static typestate analysis that is flow-sensitive, partially context-sensitive, and that generates residual runtime monitors. Our typestate specifications can refer to multiple interacting objects. To gain efficiency, our analysis uses precise, flow-sensitive information on an intra-procedural level only, and models the remainder of the program using a flow-insensitive pointer abstraction. Unlike previous flow-sensitive analyses, our analysis uses an additional backward analysis to partition states into equivalence classes. Code locations that transition between equivalent states are irrelevant and require no monitoring. This approach is simpler than previous approaches, nevertheless yields excellent precision and requires little analysis time. We proved our analysis correct, implemented the analysis in the Clara framework for typestate analysis, and applied it to the DaCapo benchmark suite. In half of the cases, our analysis determined exactly the property-violating program points. For another 25%, the analysis reduced the number of instrumentation points by large amounts, yielding significant speed-ups during runtime monitoring.", "num_citations": "1\n", "authors": ["270"]}
{"title": "Transforming Timeline specifications into automata for runtime monitoring (extended version)\n", "abstract": " In runtime monitoring, a programmer specifies code to execute whenever a sequence of events occurs during program execution. Previous and related work has shown that runtime monitoring techniques can be useful in order to validate or guarantee the safety and security of running programs. Those techniques have however not been incorporated in everyday software development processes. One problem that hinders industry adoption is that the required specifications use a cumbersome, textual notation. As a consequence, only verification experts, not programmers, can understand what a given specification means and in particular, whether it is correct. In 2001, researchers at Bell Labs proposed the Timeline formalism. This formalism was designed with ease of use in mind, for the purpose of static verification (and not, as in our work, for runtime monitoring).In this article, we describe how software safety specifications can be described visually in the Timeline formalism and subsequently transformed into finite automata suitable for runtime monitoring, using our meta-modelling and model transformation tool AToM3. The synthesized automata are subsequently fed into an existing monitoring back-end that generates efficient runtime monitors for them. Those monitors can then automatically be applied to Java programs. Our work shows that the transformation of Timeline models to automata is not only feasible in an efficient and sound way but also helps programmers identify correspondences between the original specification and the generated monitors. We argue that visual specification of safety criteria and subsequent automatic synthesis of\u00a0\u2026", "num_citations": "1\n", "authors": ["270"]}
{"title": "A staged static program analysis to improve the performance of runtime monitoring (extended version)\n", "abstract": " In runtime monitoring, a programmer specifies a piece of code to execute when a trace of events occurs during program execution. Our work is based on tracematches, an extension to AspectJ, which allows programmers to specify traces via regular expressions with free variables. In this paper we present a staged static analysis which speeds up trace matching by reducing the required runtime instrumentation. The first stage is a simple analysis that rules out entire tracematches, just based on the names of symbols. In the second stage, a points-to analysis is used, along with a flow-insensitive analysis that eliminates instrumentation points with inconsistent variable bindings. In the third stage the points-to analysis is combined with a flow-sensitive analysis that also takes into consideration the order in which the symbols may execute.To examine the effectiveness of each stage, we experimented with a set of nine tracematches applied to the DaCapo benchmark suite. We found that about 25% of the tracematch/benchmark combinations had instrumentation overheads greater than 10%. In these cases the first two stages work well for certain classes of tracematches, often leading to significant performance improvements. Somewhat surprisingly, we found the third, flow-sensitive, stage did not add any improvements.", "num_citations": "1\n", "authors": ["270"]}
{"title": "Project Report: Efficient Java bytecode verification by the means of proof-carrying code\n", "abstract": " Bytecode verification is known to be a crucial component in the overall security model of Java programs, in particular applets, a term often used for mobile code serving on the Web, on embedded devices or smart cards. In those environments executable code is often sent over untrusted channels or even downloaded from completely untrusted sources. Hence it is critical, that every piece of code to be executed by a Java Virtual Machine (JVM) is proven to not be able to cause any harm. This is what bytecode verification tries to achieve. In this article we comment on the different approaches to Java bytecode verifications and mention some of the shortcomings of the current reference implementation by Sun. In particular we discuss the problem of complexity-based denial-of-service attacks and explain how it is solved in the upcoming release of Java 6. This new version of Java uses techniques from proof-carrying code to exchange bytecode verification for faster bytecode checking with the same safety properties. Not only do we discuss in detail how this technique works, also we give pointers to how other problems of similar flavor could be addressed with the same technique.", "num_citations": "1\n", "authors": ["270"]}
{"title": "Implementing concern-specific languages with abc\n", "abstract": " In this work first we introduce the notion of concern specific languages (CSL)[Bod05] which are to a specific crosscutting concern, what domain specific languages are to a specific domain. Implementing such CSLs was a tedious task in the past since no extensible frameworks for implementing crosscutting concerns existed. Ostermann and Mezini [OM05] proposed a Prolog based implementation of aspect-oriented programming which would enable easy extension of the programming language. However, it is not yet clear what runtime impact will be involved with such an approach. With the AspectBench Compiler (abc)[ACH+05], which was released in October 2004, researchers now have a powerful extensible compiler for the aspect-oriented language AspectJ, enabling easy implementation of language extensions or even whole CSL for a specific crosscutting concern. We first motivate CSLs in general and then introduce the abc framework. In the subsequent chapters we introduce our specific CSL and report on the steps necessary to implementing it using abc. Finally we recapitulate on the ease of use of abc and conclude with a proposal for further development of this compiler framework.", "num_citations": "1\n", "authors": ["270"]}