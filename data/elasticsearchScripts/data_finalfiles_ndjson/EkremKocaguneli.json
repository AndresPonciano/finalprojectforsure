{"title": "Software effort models should be assessed via leave-one-out validation\n", "abstract": " ContextMore than half the literature on software effort estimation (SEE) focuses on model comparisons. Each of those requires a sampling method (SM) to generate the train and test sets. Different authors use different SMs such as leave-one-out (LOO), 3Way and 10Way cross-validation. While LOO is a deterministic algorithm, the N-way methods use random selection to build their train and test sets. This introduces the problem of conclusion instability where different authors rank effort estimators in different ways.ObjectiveTo reduce conclusion instability by removing the effects of a sampling method's random test case generation.MethodCalculate bias and variance (B&V) values following the assumption that a learner trained on the whole dataset is taken as the true model; then demonstrate that the B&V and runtime values for LOO are similar to N-way by running 90 different algorithms on 20 different SEE datasets\u00a0\u2026", "num_citations": "130\n", "authors": ["417"]}
{"title": "When to use data from other projects for effort estimation\n", "abstract": " Collecting the data required for quality prediction within a development team is time-consuming and expensive. An alternative to make predictions using data that crosses from other projects or even other companies. We show that with/without relevancy filtering, imported data performs the same/worse (respectively) than using local data. Therefore, we recommend the use of relevancy filtering whenever generating estimates using data from another project.", "num_citations": "70\n", "authors": ["417"]}
{"title": "Finding conclusion stability for selecting the best effort predictor in software effort estimation\n", "abstract": " Background:                 Conclusion Instability in software effort estimation (SEE) refers to the inconsistent results produced by a diversity of predictors using different datasets. This is largely due to the \u201cranking instability\u201d problem, which is highly related to the evaluation criteria and the subset of the data being used.                                Aim: To determine stable rankings of different predictors.                                Method: 90 predictors are used with 20 datasets and evaluated using 7 performance measures, whose results are subject to Wilcoxon rank test (95\u00a0%). These results are called the \u201caggregate results\u201d. The aggregate results are challenged by a sanity check, which focuses on a single error measure (MRE) and uses a newly developed evaluation algorithm called CLUSTER. These results are called the \u201cspecific results.\u201d                                Results: Aggregate results show that: (1)\u00a0It is now possible to\u00a0\u2026", "num_citations": "69\n", "authors": ["417"]}
{"title": "Defect prediction between software versions with active learning and dimensionality reduction\n", "abstract": " Accurate detection of defects prior to product release helps software engineers focus verification activities on defect prone modules, thus improving the effectiveness of software development. A common scenario is to use the defects from prior releases to build the prediction model for the upcoming release, typically through a supervised learning method. As software development is a dynamic process, fault characteristics in subsequent releases may vary. Therefore, supplementing the defect information from prior releases with limited information about the defects from the current release detected early seems to offer intuitive and practical benefits. We propose active learning as a way to automate the development of models which improve the performance of defect prediction between successive releases. Our results show that the integration of active learning with uncertainty sampling consistently outperforms the\u00a0\u2026", "num_citations": "64\n", "authors": ["417"]}
{"title": "How to find relevant data for effort estimation?\n", "abstract": " Background: Building effort estimators requires the training data. How can we find that data? It is tempting to cross the boundaries of development type, location, language, application and hardware to use existing datasets of other organizations. However, prior results caution that using such cross data may not be useful. Aim: We test two conjectures: (1) instance selection can automatically prune irrelevant instances and (2) retrieval from the remaining examples is useful for effort estimation, regardless of their source. Method: We selected 8 cross-within divisions (21 pairs of within-cross subsets) out of 19 datasets and evaluated these divisions under different analogy-based estimation (ABE) methods. Results: Between the within & cross experiments, there were few statistically significant differences in (i) the performance of effort estimators, or (ii) the amount of instances retrieved for estimation. Conclusion: For the\u00a0\u2026", "num_citations": "60\n", "authors": ["417"]}
{"title": "Kernel methods for software effort estimation\n", "abstract": " Analogy based estimation (ABE) generates an effort estimate for a new software project through adaptation of similar past projects (a.k.a. analogies). Majority of ABE methods follow uniform weighting in adaptation procedure. In this research we investigated non-uniform weighting through kernel density estimation. After an extensive experimentation of 19 datasets, 3 evaluation criteria, 5 kernels, 5 bandwidth values and a total of 2090 ABE variants, we found that: (1) non-uniform weighting through kernel methods cannot outperform uniform weighting ABE and (2) kernel type and bandwidth parameters do not produce a definite effect on estimation performance. In summary simple ABE approaches are able to perform better than much more complex approaches. Hence,\u2014provided that similar experimental settings are adopted\u2014we discourage the use of kernel methods as a weighting strategy in ABE.", "num_citations": "46\n", "authors": ["417"]}
{"title": "Combining multiple learners induced on multiple datasets for software effort prediction\n", "abstract": " Background: First approaches in software effort prediction depended on regression based models, whereas later models investigated more sophisticated methods like machine learning algorithms. Discussion Points: Single methods or models can discover only a certain part of the high dimensional space of software effort data and a common practice to increase accuracy values is to combine multiple learners. However, merely comparing models over a single dataset on the basis of precision values is not a healthy practice, since each dataset may favor a certain method. Therefore, a solid statistical test is required for comparison. Method: In this study, we adapt a previous study conducted by Khosgoftaar et. al.[1] in the field of software quality analysis to the field of software effort estimation and evaluate our results on the basis of statistical significance tests. Conclusions: Khosgoftaar et. al.\u2019s work [1] was the first of its kind in software quality and we adapted their novel work to software effort prediction. We exploited 14 methods over 3 different software effort prediction datasets under 4 different scenarios and observed similar results to Khosgoftaar et. al., that is multiple learners induced on single dataset do not produce significantly better results.", "num_citations": "36\n", "authors": ["417"]}
{"title": "Prest: An Intelligent Software Metrics Extraction, Analysis and Defect Prediction Tool.\n", "abstract": " Test managers use intelligent predictors to increase testing efficiency and to decide on when to stop testing. However, those predictors would be impractical to use in an industry setting, unless measurement and prediction processes are automated. Prest as an open source tool aims to address this problem. Compared to other open source prediction and analysis tools Prest is unique that it collects source code metrics and call graphs in 5 different programming languages, and performs learning based defect prediction and analysis. So far Prest in real life industry projects helped companies to achieve an average of 32% efficiency increase in testing effort.", "num_citations": "36\n", "authors": ["417"]}
{"title": "Ai-based models for software effort estimation\n", "abstract": " Decision making under uncertainty is a critical problem in the field of software engineering. Predicting the software quality or the cost/ effort requires high level expertise. AI based predictor models, on the other hand, are useful decision making tools that learn from past projects' data. In this study, we have built an effort estimation model for a multinational bank to predict the effort prior to projects' development lifecycle. We have collected process, product and resource metrics from past projects together with the effort values distributed among software life cycle phases, i.e. analysis & test, design & development. We have used Clustering approach to form consistent project groups and Support Vector Regression (SVR) to predict the effort. Our results validate the benefits of using AI methods in real life problems. We attain Pred(25) values as high as 78% in predicting future projects.", "num_citations": "27\n", "authors": ["417"]}
{"title": "A ranking stability indicator for selecting the best effort estimator in software cost estimation\n", "abstract": " Software effort estimation research shows that there is no universal agreement on the \u201cbest\u201d effort estimation approach. This is largely due to the \u201cranking instability\u201d problem, which is highly contingent on the evaluation criteria and the subset of the data used in the investigation. There are a large number of different method combination exists for software effort estimation, selecting the most suitable combination becomes the subject of research in this paper. Unless we can reasonably determine stable rankings of different estimators, we cannot determine the most suitable estimator for effort estimation. This paper reports an empirical study using 90 estimation methods applied to 20 datasets as an attempt to address this question. Performance was assessed using MAR, MMRE, MMER, MBRE, MIBRE, MdMRE, PRED (25) and compared using a Wilcoxon ranked test (95%). An comprehensive empirical experiment was carried out. Result shows prior studies of ranking instability of effort estimation approaches may have been overly pessimistic. Given the large number of datasets, it is now possible to draw stable conclusions about the relative performance of different effort estimation methods and to select the most suitable ones for the study under investigation. In this study, regression trees or analogy-based methods are the best performers in the experiment, and we recommend against neural nets or simple linear regression. Based on the proposed evaluation method, we are able to determine the most suitable local estimator for software cost estimation, an important process in the application of any effort estimation analysis.", "num_citations": "18\n", "authors": ["417"]}
{"title": "Experiences on developer participation and effort estimation\n", "abstract": " Software effort estimation is critical for resource allocation and planning. Accurate estimates enable managers to distribute the workload among resources in a balanced manner. The actual workload of developers may be different from the values observed in project management tools. In this research, we provide a summary of our experiences regarding: a) effort estimation activities, b) the developer workload distribution through churn data and c) a method of using churn data to track estimation process. Our experience report depends on our collaborative work with our industry partners operating in various domains in Turkey. As a result, we observe that effort estimation is taken as an important topic. However, there is a large space for research to transfer the ad-hoc methods employed in industry to empirical ones. Interestingly, we observe that resource allocations based on initial estimates/plans do not conform to\u00a0\u2026", "num_citations": "17\n", "authors": ["417"]}
{"title": "Case-based reasoning for reducing software development effort\n", "abstract": " How can we best find project changes that most improve project estimates? Prior solutions to this problem required the use of standard software process models that may not be relevant to some new project. Also, those prior solutions suffered from limited verification (the only way to assess the results of those studies was to run the recommendations back through the standard process models). Combining case-based reasoning and contrast set learning, the W system requires no underlying model. Hence, it is widely applicable (since there is no need for data to conform to some software process models). Also, W\u2019s results can be verified (using holdout sets). For example, in the experiments reported here, W found changes to projects that greatly reduced estimate median and variance by up to 95% and 83% (respectively).", "num_citations": "16\n", "authors": ["417"]}
{"title": "Building a second opinion: learning cross-company data\n", "abstract": " Background: Developing and maintaining a software effort estimation (SEE) data set within a company (within data) is costly. Often times parts of data may be missing or too difficult to collect, eg effort values. However, information about the past projects-although incomplete-may be helpful, when incorporated with the SEE data sets from other companies (cross data).Aim: Utilizing cross data to aid within company estimates and local experts; Proposing a synergy between semi-supervised, active and cross company learning for software effort estimation.Method: The proposed method: 1) Summarizes existing unlabeled within data; 2) Uses cross data to provide pseudo-labels for the summarized within data; 3) Uses steps 1 and 2 to provide an estimate for the within test data as an input for the local company experts. We use 21 data sets and compare the proposed method to existing state-of-the-art within and cross\u00a0\u2026", "num_citations": "15\n", "authors": ["417"]}
{"title": "Xiruxe: an intelligent fault tracking tool\n", "abstract": " Fault localization in telecommunication sector is a major challenge. Most companies manually try to trace faults back to their origin. Such a process is expensive, time consuming and ineffective. Therefore in this study we automated manual fault localization process by designing and implementing an intelligent software tool (Xiruxe) for a local telecommunications company. Xiruxe has a learning-based engine which uses powerful AI algorithms, such as Na\u00efve Bayes, Decision Tree and Multi Layer Perceptrons, to match keywords and patterns in the fault messages. The initial deployment results show that this intelligent engine can achieve a misclassification rate as low as 1.28%.", "num_citations": "14\n", "authors": ["417"]}
{"title": "Domain specific phase by phase effort estimation in software projects\n", "abstract": " Software cost and effort estimation models mostly focus on predicting the overall project cost rather than the cost of phases separately. In addition to that, no previous research has a domain specific view on phase by phase effort estimation. In this research, domain specific data analysis is conducted to discover the difference in phase distribution profiles in different application domains. Furthermore, a regression model is built in order to see whether a domain specific approach provides improvement in effort estimation accuracy. Our experimental results showed when domain specific data and phase by phase approach is used the prediction accuracy increases up to 74%.", "num_citations": "12\n", "authors": ["417"]}
{"title": "Size doesn't matter? On the value of software size features for effort estimation\n", "abstract": " Background: Size features such as lines of code and function points are deemed essential for effort estimation. No one questions under what conditions size features are actually a\" must\".Aim: To question the need for size features and to propose a method that compensates their absence.Method: A baseline analogy-based estimation method (1NN) and a state-of-the-art learner (CART) are run on reduced (with no size features) and full (with all features) versions of 13 SEE data sets. 1NN is augmented with a popularity-based pre-processor to create\" pop1NN\". The performance of pop1NN is compared to 1NN and CART using 10-way cross validation wrt MMRE, MdMRE, MAR, PRED (25), MBRE, MIBRE, and MMER.Results: Without any pre-processor, removal of size features decreases the performance of 1NN and CART. For 11 out of 13 data sets, pop1NN removes the necessity of size features. pop1NN (using\u00a0\u2026", "num_citations": "11\n", "authors": ["417"]}
{"title": "Predicting more from less: Synergies of learning\n", "abstract": " Thanks to the ever increasing importance of project data, its collection has been one of the primary focuses of software organizations. Data collection activities have resulted in the availability of massive amounts of data through software data repositories. This is great news for the predictive modeling research in software engineering. However, widely used supervised methods for predictive modeling require labeled data that is relevant to the local context of a project. This requirement cannot be met by many of the available data sets, introducing new challenges for software engineering research. How to transfer data between different contexts? How to handle insufficient number of labeled instances? In this position paper, we investigate synergies between different learning methods (transfer, semi-supervised and active learning) which may overcome these challenges.", "num_citations": "10\n", "authors": ["417"]}
{"title": "Lessons learned from software analytics in practice\n", "abstract": " In this chapter, we share our experience and views on software data analytics in practice with a review of our previous work. In more than 10 years of joint research projects with industry, we have encountered similar data analytics patterns in diverse organizations and in different problem cases. We discuss these patterns following a \u201csoftware analytics\u201d framework: problem identification, data collection, descriptive statistics, and decision making. In the discussion, our arguments and concepts are built around our experiences of the research process in six different industry research projects in four different organizations.Methods: Spearman rank correlation, Pearson correlation, Kolmogorov-Smirnov test, chi-square goodness-of-fit test, t test, Mann-Whitney U test, Kruskal-Wallis analysis of variance, k-nearest neighbor, linear regression, logistic regression, na\u00efve Bayes, neural networks, decision trees, ensembles\u00a0\u2026", "num_citations": "9\n", "authors": ["417"]}
{"title": "BITS: Issue Tracking and Project Management Tool in Healthcare Software Development.\n", "abstract": " Healthcare information management systems (HIMS) are critical in day-to-day management of large healthcare institutions to provide timely and accurate patient/diagnosis/treatment information, to improve the quality of service and to lower the costs. Poor implementation of such systems may cause critical failures, such as inaccurate patient records, wrong treatments. It is necessary to prioritize software quality and process management activities during implementation of HIMS. We have worked with a medium size enterprise, which has a HIMS product, to build an in-house Issue Tracking and Project Management Tool. Using this tool, we have managed to a) collect customer requests automatically, b) plan the projects, c) implement software processes, and d) manage the projects in terms of bug tracking, version control and reporting. We have observed that software development effort per a given task has decreased by 82%. Improvements in the quality of service in HIMS have led to increase in customer satisfaction.", "num_citations": "4\n", "authors": ["417"]}
{"title": "A principled methodology: A dozen principles of software effort estimation\n", "abstract": " Software effort estimation (SEE) is the activity of estimating the total effort required to complete a software project. Correctly estimating the effort required for a software project is of vital importance for the competitiveness of the organizations. Both under-and over-estimation leads to undesirable consequences for the organizations. Under-estimation may result in overruns in budget and schedule, which in return may cause the cancellation of projects; thereby, wasting the entire effort spent until that point. Over-estimation may cause promising projects not to be funded; hence, harming the organizational competitiveness.", "num_citations": "1\n", "authors": ["417"]}
{"title": "What is\" Enough\" Quality for Data Repositories?\n", "abstract": " This article conducts an in-depth study of \u0394-resiliency on six real-world data sets. Since \u0394-resiliency requires some operational definition of how data are used to make decisions, the authors will assume an instance-based reasoning decision framework. Instance-based reasoning is a general method for reasoning about, say, software engineering data (Auer et al. 2006; Walkerden and Jeffery 1999; Kirsopp,[M. Shepperd], and House 2003; Shepperd and Schofield 1997; Shepperd, Schofield, and [B.", "num_citations": "1\n", "authors": ["417"]}
{"title": "Bulutlarda Ak\u0131ll\u0131 Bir Yaz\u0131l\u0131m \u00d6l\u00e7\u00fcmleme, Hata Analiz ve Tahmin Arac\u0131: Prest\n", "abstract": " G\u00fcn\u00fcm\u00fcz yaz\u0131l\u0131m projelerinde test safhas\u0131, bir yaz\u0131l\u0131m projesindeki t\u00fcm gayretin (efor)% 50\u2019sini olu\u015fturmas\u0131 bak\u0131m\u0131ndan son derece \u00f6nemlidir. Test eforunu azaltmak ve test s\u00fcrecini y\u00f6nlendirebilmek de bir o kadar \u00f6nem ta\u015f\u0131r. Ancak bu s\u00fcreci desteklemek i\u00e7in bilgisayar destekli tahmin ara\u00e7lar\u0131n\u0131n, proje y\u00f6neticilerinin hizmetine sunulmas\u0131 gerekmektedir. A\u00e7\u0131k kaynak kodlu olarak geli\u015ftirilmi\u015f olan ve kullan\u0131c\u0131lara SciDesktop bulut hesaplama platformu vas\u0131tas\u0131yla sunulan Prest bu problemin \u00e7\u00f6zmekle birlikte be\u015f dilde yaz\u0131l\u0131m \u00f6l\u00e7\u00fct\u00fc toplayabilen, \u00e7a\u011fr\u0131 grafi\u011fi \u00fcreten ve \u00f6\u011frenme tabanl\u0131 analiz ger\u00e7ekle\u015ftirebilen, bu anlamda tek olma \u00f6zelli\u011fi ta\u015f\u0131yan bir ara\u00e7t\u0131r.", "num_citations": "1\n", "authors": ["417"]}