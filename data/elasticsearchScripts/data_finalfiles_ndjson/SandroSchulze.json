{"title": "Towards a refactoring guideline using code clone classification\n", "abstract": " Evolution of software often decreases desired properties like readability and maintainability of the evolved code. The process of refactoring aims at increasing the same desired properties by restructuring the code. New paradigms like AOP allow aspect-oriented refactorings as counterparts of object-oriented refactoring with the same aim. However, it is not obvious to the user, when to use which paradigm for achieving certain goals. In this paper we present an approach of code clone classification, which advises the developer when to use a respective refactoring technique or concept.", "num_citations": "38\n", "authors": ["798"]}
{"title": "QuEval: Beyond high-dimensional indexing \u00e0 la carte\n", "abstract": " In the recent past, the amount of high-dimensional data, such as feature vectors extracted from multimedia data, increased dramatically. A large variety of indexes have been proposed to store and access such data efficiently. However, due to specific requirements of a certain use case, choosing an adequate index structure is a complex and time-consuming task. This may be due to engineering challenges or open research questions. To overcome this limitation, we present QuEval, an open-source framework that can be flexibly extended w.r.t. index structures, distance metrics, and data sets. QuEval provides a unified environment for a sound evaluation of different indexes, for instance, to support tuning of indexes. In an empirical evaluation, we show how to apply our framework, motivate benefits, and demonstrate analysis possibilities.", "num_citations": "36\n", "authors": ["798"]}
{"title": "On the Robustness of Clone Detection to Code Obfuscation\n", "abstract": " Code clones are a common reuse mechanism in software development. While there is an ongoing discussion about harmfulness and advantages of code cloning, this discussion is mainly centered around aspects of software quality. However, recent research has shown, that code cloning may have legal implications as well such as license violations. From this point of view, a developer may favor to hide his cloning activities. To this end, he could obfuscate the cloned code to deceive clone detectors. However, it is unknown how robust certain clone detection techniques are against code obfuscations. In this paper, we present a framework for semi-automated code obfuscations. Additionally, we present a case study to evaluate the robustness of selected clone detectors against such obfuscations.", "num_citations": "25\n", "authors": ["798"]}
{"title": "Advanced analysis for code clone removal\n", "abstract": " Code cloning, ie, the process of replicating code fragments by copy-paste (-and-adaption), is common in software development [1]. Although it comes along with some short-term advantages (eg, timeto-market or reusing functioning code), it has crucial drawbacks in the long run, eg, increased maintenance costs or inconsistent changes [1]. As a consequence, it is important to be aware of such code clones in the system. To this end, clone detection techniques have been proposed and widely applied [1]. However, the detection of clones is not enough but further processing steps are necessary to overcome or at least minimize the mentioned drawbacks. One approach which aims at a durable elimination of code clones is refactoring [2]. Several approaches exist (eg,[3, 4]), that differ in the underlying clone detection technique and thus, in the information provided for the refactoring process. However, each of these approaches has one or more of the following problems:\u2022 Only some refactorings are provided (mostly Extract Method and Pull Up Method [2]) and thus, a considerable fraction of clones is not covered.\u2022 The information passed to the refactorings allows only the removal of coarse-grained clones (eg, functions) which furthermore have to be of specific types [5].", "num_citations": "22\n", "authors": ["798"]}
{"title": "Continuous detection of design flaws in evolving object-oriented programs using incremental multi-pattern matching\n", "abstract": " Design flaws in object-oriented programs may seriously corrupt code quality thus increasing the risk for introducing subtle errors during software maintenance and evolution. Most recent approaches identify design flaws in an ad-hoc manner, either focusing on software metrics, locally restricted code smells, or on coarse-grained architectural anti-patterns. In this paper, we utilize an abstract program model capturing high-level object-oriented code entities, further augmented with qualitative and quantitative design-related information such as coupling/cohesion. Based on this model, we propose a comprehensive methodology for specifying object-oriented design flaws by means of compound rules integrating code metrics, code smells and anti-patterns in a modular way. This approach allows for efficient, automated design-flaw detection through incremental multi-pattern matching, by facilitating systematic information\u00a0\u2026", "num_citations": "21\n", "authors": ["798"]}
{"title": "Analyzing the effect of preprocessor annotations on code clones\n", "abstract": " The C preprocessor cpp is a powerful and language-independent tool, widely used to implement variable software in different programming languages (C, C++) using conditional compilation. Preprocessor annotations can used on different levels of granularity such as functions or statements. In this paper, we investigate whether there is a relation between code clones and preprocessor annotations. Specifically, we address the question whether the discipline of annotation has an effect on code clones. To this end, we perform a case study on fifteen different C programs and analyze them regarding code clones and #ifdef occurrences. We found only minor effects of annotations on code clones, but a relationship between annotations that align with the code structure (and code clones). With this work, we provide new insights why code clones occur in C programs. Furthermore, the results can support the decision\u00a0\u2026", "num_citations": "20\n", "authors": ["798"]}
{"title": "Analysis and Removal of Code Clones in Software Product Lines\n", "abstract": " Software maintenance is the main driver of total costs in the lifecycle of long-living software systems. Code clones, that is, the replication of code fragments across the system, decrease maintainability: It increases the code size and hinders manual code change, inspection, and analysis. Intensive research has been spent in the last two decades to determine the nature of clones, specifically why and where they occur as well as whether they impair the maintenance of software systems. While recent studies expressed doubt on the general harmfulness of clones, it is commonly accepted that the awareness of existing code clones in software system is indispensable in any case.Recently, software product line engineering gained momentum since it provides a systematic approach for reuse amongst a set of similar programs, commonly referred to as software product lines (SPL). An SPL allows the programmer to manage a set of programs by describing variabilities and commonalities between them in terms of features. In this context, a feature is an increment in end-user visible functionality. As a result, a particular program can be derived by selecting the desired features and subsequently composing all corresponding assets.", "num_citations": "18\n", "authors": ["798"]}
{"title": "Implementing refactorings for FOP: Lessons learned and challenges ahead\n", "abstract": " Software product lines (SPL) gain momentum as a mean for developing and managing a set of related software systems under one umbrella. While intensive research on design and implementation of SPLs exist, the consequences of continuous evolution over time such as a decay of design or implementation have been neglected so far. In this context, refactoring has been shown to be an appropriate mean for improving the structure of source code. In this paper, we provide support for fine-grained program refactoring of feature-oriented SPLs. Particularly, we extend existing, object-oriented refactorings by taking the additional dimension of variability into account. To this end, we present the tool VAmPiRE as a basic framework for such refactorings and explain our considerations during implementation, which has been mainly guided by the idea of decomposing refactorings for ease and understandability\u00a0\u2026", "num_citations": "17\n", "authors": ["798"]}
{"title": "Incremental co-evolution of Java programs based on bidirectional graph transformation\n", "abstract": " Modern Java IDE aim at assisting object-oriented software development workflows with continuously interleaved co-evolution steps of program editing and program refactoring. Program editing usually comprises manually performed program changes applied by a programmer at source code level. In contrast, refactorings consist of behavior-preserving program restructuring rules with complex preconditions, usually formulated over an appropriate program abstraction. To integrate both steps into a comprehensive program evolution framework, we present a graph-based approach for incremental co-evolution of Java programs. Our approach is based on a concise graph-based representation of Java programs by means of a reduced abstract syntax tree, augmented with additional cross-tree edges denoting crucial semantic information. On this basis, a precise formal specification of object-oriented program\u00a0\u2026", "num_citations": "10\n", "authors": ["798"]}
{"title": "Object-oriented design in feature-oriented programming\n", "abstract": " Object-oriented programming is the state-of-the-art programming paradigm for developing large and complex software systems. To support the development of maintainable and evolvable code, a developer can rely on different mechanisms and concepts such as inheritance and design patterns. Recently, feature-oriented programming (FOP) gained attention, specifically for developing software product lines (SPLs). Although FOP is an own paradigm with dedicated language mechanisms, it partly relies on object-oriented programming. However, only little is known about feature-oriented design and how object-oriented design mechanisms and design principles are used within FOP. In this paper, we want to raise awareness on design patterns in FOP and stimulate discussion on related topics. To this end, we present an exemplary review of using OO design patterns in FOP and limitations thereof from our\u00a0\u2026", "num_citations": "8\n", "authors": ["798"]}
{"title": "Program Slicing in the Presence of Preprocessor Variability\n", "abstract": " Program slicing is a common means to support developers in examining the source code with respect to debugging, program comprehension, or regression testing. While a vast amount of techniques exist, they are mostly tailored to single software systems. However, with the increasing importance of variable and highly-configurable systems, such as the Linux kernel, the number of software variants, subject to analysis, increases dramatically. Consequently, it is infeasible to apply slicing on each variant in isolation. To overcome this problem, we propose variability-aware slicing, a technique that can deal with source code variability, specifically conditional compilation as introduced by the C preprocessor. Particularly, we provide details of our variability-aware dependence analysis for program slicing, point out benefits of our slicing technique, and mention current limitations and future work.", "num_citations": "7\n", "authors": ["798"]}
{"title": "Database-centric chain-of-custody in biometric forensic systems\n", "abstract": " Biometric systems gain more and more attention in everyday life regarding authentication and surveillance of persons. This includes, amongst others, the login on a notebook based on fingerprint verification, controlling of airports or train stations, and the biometric identity card. Although these systems have several advantages in comparison to traditional approaches, they exhibit high risks regarding confidentiality and data protection issues. For instance, tampering biometric data or general misuse could have devastating consequences for the owner of the respective data. Furthermore, the digital nature of biometric data raises specific requirements for the usage of the data for crime detection or at court to convict a criminal. Here, the chain-of-custody has to be proven without any doubt. In this paper, we present a database-centric approach for ensuring the chain-of-custody in a forensic digital fingerprint system.", "num_citations": "7\n", "authors": ["798"]}
{"title": "Feature terms prediction: a feasible way to indicate the notion of features in software product line\n", "abstract": " In Software Product Lines (SPL), feature extraction from software requirements specifications has been subject to intense research in order to assist domain analysis in a time-saving way. Although various approaches are proposed to extract features, there still exists a gap to achieve the complete view of features, that is, how to figure out the intention of a feature. Feature terms as the smallest units in a feature can be regarded as vital indicators for describing a feature. Automated feature term extraction can provide key information regarding the intention of a feature, which improves the efficiency of domain analysis. In this paper, we propose an approach to train prediction models by using machine learning techniques to identify feature terms. To this end, we extract candidate terms from requirement specifications in one domain and take six attributes of each term into account to create a labeled dataset. Subsequently\u00a0\u2026", "num_citations": "4\n", "authors": ["798"]}
{"title": "IT Security in Automotive Software Development\n", "abstract": " In the last years, automotive systems evolved to be more and more software-intensive systems. As a result, considerable attention has been paid to establish an efficient software development process of such systems, where reliability is an important criterion. Hence, model-driven development (MDD), software engineering and requirements engineering (amongst others) found their way into the systems engineering domain. However, one important aspect regarding the reliability of such systems, has been largely neglected on a holistic level: the IT security. In this paper, we introduce a potential approach for integrating IT security in the requirements engineering process of automotive software development using function net modeling.", "num_citations": "4\n", "authors": ["798"]}
{"title": "Automated extraction of domain knowledge in practice: the case of feature extraction from requirements at danfoss\n", "abstract": " Software product line supports structured reuse of software artifacts in order to realize the maintenance and evolution of the typically large number of variants, which promotes the industrialization of software development, especially for software-intensive products. However, for a legacy system, it is non-trivial to gain information about commonalities and differences of the variants. Meanwhile, software requirements specifications as the initial artifacts can be used to achieve this information to generate a domain model. Unfortunately, manually analyzing these requirements is time-consuming and inefficient. To address this problem, we explored the usage of feature extraction techniques to automatically extract domain knowledge from requirements to assist domain engineers. In detail, we applied Doc2Vec and a clustering algorithm to process the requirements for achieving the initial feature tree. Moreover, we utilized\u00a0\u2026", "num_citations": "1\n", "authors": ["798"]}
{"title": "Analyzing Malware Putty using Function Alignment in the Binary\n", "abstract": " This paper shows a representation of executables and an alignment of functions in an executable to be used when reverse engineering embedded systems. These techniques are not limited to this application and can also be used when studying code variations, code clone-and-own scenarios, and when locating hotspots for software quality inspections.", "num_citations": "1\n", "authors": ["798"]}
{"title": "Towards an Update-Enabled Mediator System using Semantic Web Technology.\n", "abstract": " A large part of implementing information retrieval or data mining systems consists of joining data from different sources to connect related items, enrich data sets and find similarities or contradictions. Mediators take care of the conversion between different formats and access to the data sources to provide a unified view, however these systems either only support read operations or are limited to a schema derived from a fixed set of data sources. We sketch a concept for a mediator based on Semantic Web technology\u2013especially RDF/OWL and SPARQL\u2013enriched with semantics from the wrappers and an ontology describing the schema integration. Our system is able to handle updates on the unified view, feeding them back to the respective data sources and therefore extends the capabilities of classic data warehouses of federated databases. Furthermore we analyze how CARSA, a meta-search engine framework, can be extended to implement the concept and discuss upcoming problems and ideas for their solution.", "num_citations": "1\n", "authors": ["798"]}
{"title": "A holistic approach for processing of detected code clones\n", "abstract": " Code cloning, ie, the replication of code fragments in software systems, is a severe problem in industrial as well as in open source systems. In comparison to clone detection and analysis, which is a widely covered topic in research, only little work has been done regarding comprehension of clones or further processing strategies. Our current research aims at classifying code clones by adding semantic and syntactic informations in order to eliminate them durable, including a semi-automated refactoring process and source code enrichment which ensures maintainability and understandability of the overall system.Code duplication is considered to be a common and harmful practice which evokes various problems, eg, increased maintenance costs, bloated or dead code and others [1],[2],[3]. To detect such code clones, different techniques exist, such as string-based [2], metric-based [4], token-based [3] or tree/graph-based [5]. However, after the detection step, these approaches (or rather tools implementing them) stop without useful information about the code clones or subsequent clone processing (eg, elimination). In some cases, visualizations or metrics are provided, reflecting the detected clones, but mostly, this information is blurred and thus, rather obfuscates the user.", "num_citations": "1\n", "authors": ["798"]}
{"title": "Modelling Data Requirements for a Secure Data Management in Automotive Systems\n", "abstract": " IT security and data management are two emerging aspects in automotive systems. In this paper we propose a model which supports the integration of these aspects, already starting in the early stages of development. This systematisation of different kinds of data processed within automobiles, including their specific requirements (with respect to safety, security, comfort etc.), allows for a wide range of applications like implementation guidelines and verification. Such holistic approaches are essential for future automotive data management, especially to cope with the increasing complexity and IT security requirements in data management.", "num_citations": "1\n", "authors": ["798"]}