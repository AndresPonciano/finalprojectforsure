{"title": "Towards characterizing cloud backend workloads: insights from google compute clusters\n", "abstract": " The advent of cloud computing promises highly available, efficient, and flexible computing services for applications such as web search, email, voice over IP, and web search alerts. Our experience at Google is that realizing the promises of cloud computing requires an extremely scalable backend consisting of many large compute clusters that are shared by application tasks with diverse service level requirements for throughput, latency, and jitter. These considerations impact (a) capacity planning to determine which machine resources must grow and by how much and (b) task scheduling to achieve high machine utilization and to meet service level objectives. Both capacity planning and task scheduling require a good understanding of task resource consumption (e.g., CPU and memory usage). This in turn demands simple and accurate approaches to workload classification-determining how to form groups of tasks\u00a0\u2026", "num_citations": "465\n", "authors": ["499"]}
{"title": "ViChaR: A dynamic virtual channel regulator for network-on-chip routers\n", "abstract": " The advent of deep sub-micron technology has recently highlighted the criticality of the on-chip interconnects. As diminishing feature sizes have led to increases in global wiring delays, network-on-chip (NoC) architectures are viewed as a possible solution to the wiring challenge and have recently crystallized into a significant research thrust. Both NoC performance and energy budget depend heavily on the routers' buffer resources. This paper introduces a novel unified buffer structure, called the dynamic virtual channel regulator (ViChaR), which dynamically allocates virtual channels (VC) and buffer resources according to network traffic conditions. ViChaR maximizes throughput by dispensing a variable number of VCs on demand. Simulation results using a cycle-accurate simulator show a performance increase of 25% on average over an equal-size generic router buffer, or similar performance using a 50\u00a0\u2026", "num_citations": "389\n", "authors": ["499"]}
{"title": "A novel dimensionally-decomposed router for on-chip communication in 3D architectures\n", "abstract": " Much like multi-storey buildings in densely packed metropolises, three-dimensional (3D) chip structures are envisioned as a viable solution to skyrocketing transistor densities and burgeoning die sizes in multi-core architectures. Partitioning a larger die into smaller segments and then stacking them in a 3D fashion can significantly reduce latency and energy consumption. Such benefits emanate from the notion that inter-wafer distances are negligible compared to intra-wafer distances. This attribute substantially reduces global wiring length in 3D chips. The work in this paper integrates the increasingly popular idea of packet-based Networks-on-Chip (NoC) into a 3D setting. While NoCs have been studied extensively in the 2D realm, the microarchitectural ramifications of moving into the third dimension have yet to be fully explored. This paper presents a detailed exploration of inter-strata communication architectures\u00a0\u2026", "num_citations": "366\n", "authors": ["499"]}
{"title": "A low latency router supporting adaptivity for on-chip interconnects\n", "abstract": " The increased deployment of system-on-chip designs has drawn attention to the limitations of on-chip interconnects. As a potential solution to these limitations, networks-on-chip (NoC) have been proposed. The NoC routing algorithm significantly influences the performance and energy consumption of the chip. We propose a router architecture which utilizes adaptive routing while maintaining low latency. The two-stage pipelined architecture uses look ahead routing, speculative allocation, and optimal output path selection concurrently. The routing algorithm benefits from congestion-aware flow control, making better routing decisions. We simulate and evaluate the proposed architecture in terms of network latency and energy consumption. Our results indicate that the architecture is effective in balancing the performance and energy of NoC designs.", "num_citations": "334\n", "authors": ["499"]}
{"title": "OWL: cooperative thread array aware scheduling techniques for improving GPGPU performance\n", "abstract": " Emerging GPGPU architectures, along with programming models like CUDA and OpenCL, offer a cost-effective platform for many applications by providing high thread level parallelism at lower energy budgets. Unfortunately, for many general-purpose applications, available hardware resources of a GPGPU are not efficiently utilized, leading to lost opportunity in improving performance. A major cause of this is the inefficiency of current warp scheduling policies in tolerating long memory latencies. In this paper, we identify that the scheduling decisions made by such policies are agnostic to thread-block, or cooperative thread array (CTA), behavior, and as a result inefficient. We present a coordinated CTA-aware scheduling policy that utilizes four schemes to minimize the impact of long memory latencies. The first two schemes, CTA-aware two-level warp scheduling and locality aware warp scheduling, enhance per\u00a0\u2026", "num_citations": "328\n", "authors": ["499"]}
{"title": "Cache revive: Architecting volatile STT-RAM caches for enhanced performance in CMPs\n", "abstract": " High density, low leakage and non-volatility are the attractive features of Spin-Transfer-Torque-RAM (STT-RAM), which has made it a strong competitor against SRAM as a universal memory replacement in multi-core systems. However, STT-RAM suffers from high write latency and energy which has impeded its widespread adoption. To this end, we look at trading-off STT-RAM's non-volatility property (data-retention-time) to overcome these problems. We formulate the relationship between retention-time and write-latency, and find optimal retention-time for architecting an efficient cache hierarchy using STT-RAM. Our results show that, compared to SRAM-based design, our proposal can improve performance and energy consumption by 18% and 60%, respectively.", "num_citations": "311\n", "authors": ["499"]}
{"title": "Exploring fault-tolerant network-on-chip architectures\n", "abstract": " The advent of deep sub-micron technology has exacerbated reliability issues in on-chip interconnects. In particular, single event upsets, such as soft errors, and hard faults are rapidly becoming a force to be reckoned with. This spiraling trend highlights the importance of detailed analysis of these reliability hazards and the incorporation of comprehensive protection measures into all network-on-chip (NoC) designs. In this paper, we examine the impact of transient failures on the reliability of on-chip interconnects and develop comprehensive counter-measures to either prevent or recover from them. In this regard, we propose several novel schemes to remedy various kinds of soft error symptoms, while keeping area and power overhead at a minimum. Our proposed solutions are architected to fully exploit the available infrastructures in an NoC and enable versatile reuse of valuable resources. The effectiveness of the\u00a0\u2026", "num_citations": "310\n", "authors": ["499"]}
{"title": "MIRA: A multi-layered on-chip interconnect router architecture\n", "abstract": " Recently, Network-on-Chip (NoC) architectures have gained popularity to address the interconnect delay problem for designing CMP / multi-core/SoC systems in deep sub-micron technology. However, almost all prior studies have focused on 2D NoC designs. Since three dimensional (3D) integration has emerged to mitigate the interconnect delay problem, exploring the NoC design space in 3D can provide ample opportunities to design high performance and energy-efficient NoC architectures. In this paper, we propose a 3D stacked NoC router architecture, called MIRA, which unlike the 3D routers in previous works, is stacked into multiple layers and optimized to reduce the overall area requirements and power consumption. We discuss the design details of a four-layer 3D NoC and its enhanced version with additional express channels, and compare them against a (6times6) 2D design and a baseline 3D design\u00a0\u2026", "num_citations": "306\n", "authors": ["499"]}
{"title": "Neither more nor less: Optimizing thread-level parallelism for GPGPUs\n", "abstract": " General-purpose graphics processing units (GPG-PUs) are at their best in accelerating computation by exploiting abundant thread-level parallelism (TLP) offered by many classes of HPC applications. To facilitate such high TLP, emerging programming models like CUDA and OpenCL allow programmers to create work abstractions in terms of smaller work units, called cooperative thread arrays (CTAs). CTAs are groups of threads and can be executed in any order, thereby providing ample opportunities for TLP. The state-of-the-art GPGPU schedulers allocate maximum possible CTAs per-core (limited by available on-chip resources) to enhance performance by exploiting TLP. However, we demonstrate in this paper that executing the maximum possible number of CTAs on a core is not always the optimal choice from the performance perspective. High number of concurrently executing threads might cause more\u00a0\u2026", "num_citations": "301\n", "authors": ["499"]}
{"title": "A gracefully degrading and energy-efficient modular router architecture for on-chip networks\n", "abstract": " Packet-based on-chip networks are increasingly being adopted in complex System-on-Chip (SoC) designs supporting numerous homogeneous and heterogeneous functional blocks. These Network-on-Chip (NoC) architectures are required to not only provide ultra-low latency, but also occupy a small footprint and consume as little energy as possible. Further, reliability is rapidly becoming a major challenge in deep sub-micron technologies due to the increased prominence of permanent faults resulting from accelerated aging effects and manufacturing/testing challenges. Towards the goal of designing low-latency, energy efficient and reliable on-chip communication networks, we propose a novel fine-grained modular router architecture. The proposed architecture employs decoupled parallel arbiters and uses smaller crossbars for row and column connections to reduce output port contention probabilities as\u00a0\u2026", "num_citations": "294\n", "authors": ["499"]}
{"title": "Cooperative cache-based data access in ad hoc networks\n", "abstract": " Cooperative caching, in which multiple nodes share and coordinate cached data, is widely used to improve Web performance in wired networks. However, resource constraints and node mobility have limited the application of these techniques in ad hoc networks. We propose caching techniques that use the underlying routing protocols to overcome these constraints and further improve performance.", "num_citations": "285\n", "authors": ["499"]}
{"title": "Aergia: Exploiting packet latency slack in on-chip networks\n", "abstract": " Traditional Network-on-Chips (NoCs) employ simple arbitration strategies, such as round-robin or oldest-first, to decide which packets should be prioritized in the network. This is counter-intuitive since different packets can have very different effects on system performance due to, e.g., different level of memory-level parallelism (MLP) of applications. Certain packets may be performance-critical because they cause the processor to stall, whereas others may be delayed for a number of cycles with no effect on application-level performance as their latencies are hidden by other outstanding packets'latencies. In this paper, we define slack as a key measure that characterizes the relative importance of a packet. Specifically, the slack of a packet is the number of cycles the packet can be delayed in the network with no effect on execution time. This paper proposes new router prioritization policies that exploit the available\u00a0\u2026", "num_citations": "242\n", "authors": ["499"]}
{"title": "Application-aware prioritization mechanisms for on-chip networks\n", "abstract": " Network-on-Chips (NoCs) are likely to become a critical shared resource in future many-core processors. The challenge is to develop policies and mechanisms that enable multiple applications to efficiently and fairly share the network, to improve system performance. Existing local packet scheduling policies in the routers fail to fully achieve this goal, because they treat every packet equally, regardless of which application issued the packet. This paper proposes prioritization policies and architectural extensions to NoC routers that improve the overall application-level throughput, while ensuring fairness in the network. Our prioritization policies are application-aware, distinguishing applications based on the stall-time criticality of their packets. The idea is to divide processor execution time into phases, rank applications within a phase based on stall-time criticality, and have all routers in the network prioritize packets\u00a0\u2026", "num_citations": "241\n", "authors": ["499"]}
{"title": "Design and evaluation of a hierarchical on-chip interconnect for next-generation CMPs\n", "abstract": " Performance and power consumption of an on-chip interconnect that forms the backbone of chip multiprocessors (CMPs), are directly influenced by the underlying network topology. Both these parameters can also be optimized by application induced communication locality since applications mapped on a large CMP system will benefit from clustered communication, where data is placed in cache banks closer to the cores accessing it. Thus, in this paper, we design a hierarchical network topology that takes advantage of such communication locality. The two-tier hierarchical topology consists of local networks that are connected via a global network. The local network is a simple, high-bandwidth, low-power shared bus fabric, and the global network is a low-radix mesh. The key insight that enables the hybrid topology is that most communication in CMP applications can be limited to the local network, and thus, using\u00a0\u2026", "num_citations": "240\n", "authors": ["499"]}
{"title": "MDCSim: A multi-tier data center simulation, platform\n", "abstract": " Performance and power issues are becoming increasingly important in the design of large, cluster-based multi-tier data centers for supporting a multitude of services. The design and analysis of such large/complex distributed systems often suffer from the lack of availability of an adequate physical infrastructure. This paper presents a comprehensive, flexible, and scalable simulation platform for in-depth analysis of multi-tier data centers. Designed as a pluggable three-level architecture, our simulator captures all the important design specifics of the underlying communication paradigm, kernel level scheduling artifacts, and the application level interactions among the tiers of a three-tier data center. The flexibility of the simulator is attributed to its ability in experimenting with different design alternatives in the three layers, and in analyzing both the performance and power consumption with realistic workloads. The\u00a0\u2026", "num_citations": "233\n", "authors": ["499"]}
{"title": "Modeling and synthesizing task placement constraints in Google compute clusters\n", "abstract": " Evaluating the performance of large compute clusters requires benchmarks with representative workloads. At Google, performance benchmarks are used to obtain performance metrics such as task scheduling delays and machine resource utilizations to assess changes in application codes, machine configurations, and scheduling algorithms. Existing approaches to workload characterization for high performance computing and grids focus on task resource requirements for CPU, memory, disk, I/O, network, etc. Such resource requirements address how much resource is consumed by a task. However, in addition to resource requirements, Google workloads commonly include task placement constraints that determine which machine resources are consumed by tasks. Task placement constraints arise because of task dependencies such as those related to hardware architecture and kernel version.", "num_citations": "232\n", "authors": ["499"]}
{"title": "Orchestrated scheduling and prefetching for GPGPUs\n", "abstract": " In this paper, we present techniques that coordinate the thread scheduling and prefetching decisions in a General Purpose Graphics Processing Unit (GPGPU) architecture to better tolerate long memory latencies. We demonstrate that existing warp scheduling policies in GPGPU architectures are unable to effectively incorporate data prefetching. The main reason is that they schedule consecutive warps, which are likely to access nearby cache blocks and thus prefetch accurately for one another, back-to-back in consecutive cycles. This either 1) causes prefetches to be generated by a warp too close to the time their corresponding addresses are actually demanded by another warp, or 2) requires sophisticated prefetcher designs to correctly predict the addresses required by a future\" far-ahead\" warp while executing the current warp.", "num_citations": "225\n", "authors": ["499"]}
{"title": "Hypercube communication delay with wormhole routing\n", "abstract": " We present an analytical model for the performance evaluation of hypercube computers. This analysis is aimed at modeling a deadlock-free wormhole routing scheme prevalent on second generation hypercube systems. Probability of blocking and average message delay are the two performance measures discussed. We start with the communication traffic to find the probability of blocking. The traffic analysis can capture any message destination distribution. Next, we find the average message delay that consists of two parts. The first part is the actual message transfer delay between any source and destination nodes. The second part of the delay is due to blocking caused by the wormhole routing scheme. The analysis is also extended to virtual cut-through routing and random wormhole routing techniques. The validity of the model is demonstrated by comparing analytical results with those from simulation.< >", "num_citations": "169\n", "authors": ["499"]}
{"title": "Scheduling techniques for GPU architectures with processing-in-memory capabilities\n", "abstract": " Processing data in or near memory (PIM), as opposed to in conventional computational units in a processor, can greatly alleviate the performance and energy penalties of data transfers from/to main memory. Graphics Processing Unit (GPU) architectures and applications, where main memory bandwidth is a critical bottleneck, can benefit from the use of PIM. To this end, an application should be properly partitioned and scheduled to execute on either the main, powerful GPU cores that are far away from memory or the auxiliary, simple GPU cores that are close to memory (eg, in the logic layer of 3D-stacked DRAM).", "num_citations": "157\n", "authors": ["499"]}
{"title": "Characterizing network traffic in a cluster-based, multi-tier data center\n", "abstract": " With the increasing use of various Web-based services, design of high performance, scalable and dependable data centers has become a critical issue. Recent studies show that a clustered, multi-tier architecture is a cost-effective approach to design such servers. Since these servers are highly distributed and complex, understanding the workloads driving them is crucial for the success of the ongoing research to improve them. In view of this, there has been a significant amount of work to characterize the workloads of Web-based services. However, all of the previous studies focus on a high level view of these servers, and analyze request-based or session-based characteristics of the workloads. In this paper, we focus on the characteristics of the network behavior within a clustered, multi-tiered data center. Using a real implementation of a clustered three-tier data center, we analyze the arrival rate and inter-arrival\u00a0\u2026", "num_citations": "157\n", "authors": ["499"]}
{"title": "Managing GPU concurrency in heterogeneous architectures\n", "abstract": " Heterogeneous architectures consisting of general-purpose CPUs and throughput-optimized GPUs are projected to be the dominant computing platforms for many classes of applications. The design of such systems is more complex than that of homogeneous architectures because maximizing resource utilization while minimizing shared resource interference between CPU and GPU applications is difficult. We show that GPU applications tend to monopolize the shared hardware resources, such as memory and network, because of their high thread-level parallelism (TLP), and discuss the limitations of existing GPU-based concurrency management techniques when employed in heterogeneous systems. To solve this problem, we propose an integrated concurrency management strategy that modulates the TLP in GPUs to control the performance of both CPU and GPU applications. This mechanism considers both\u00a0\u2026", "num_citations": "155\n", "authors": ["499"]}
{"title": "Design and analysis of an NoC architecture from performance, reliability and energy perspective\n", "abstract": " Network-on-chip (NoC) architectures employing packet-based communication are being increasingly adopted in system-on-chip (SoC) designs. In addition to providing high performance, the fault-tolerance and reliability of these networks is becoming a critical issue due to several artifacts of deep sub-micron technologies. Consequently, it is important for a designer to have access to fast methods for evaluating the performance, reliability, and energy-efficiency of an on-chip network. Towards this end, first, we propose a novel path-sensitive router architecture for low-latency applications. Next, we present a queuing-theory-based model for evaluating the performance and energy behavior of on-chip networks. Then the model is used to demonstrate the effectiveness of our proposed router. The performance (average latency) and energy consumption results from the analytical model are validated with those obtained\u00a0\u2026", "num_citations": "150\n", "authors": ["499"]}
{"title": "A case for heterogeneous on-chip interconnects for CMPs\n", "abstract": " Network-on-chip (NoC) has become a critical shared resource in the emerging Chip Multiprocessor (CMP) era. Most prior NoC designs have used the same type of router across the entire network. While this homogeneous network design eases the burden on a network designer, partitioning the resources equally among all routers across the network does not lead to optimal resource usage, and hence, affects the performance-power envelope. In this work, we propose to apportion the resources in an NoC to leverage the non-uniformity in network resource demand. Our proposal includes partitioning the network resources, specifically buffers and links, in an optimal manner. This approach results in redistributing resources such that routers that require more resources are allocated more buffers and wider links compared to routers demanding fewer resources. This results in a novel heterogeneous network, called\u00a0\u2026", "num_citations": "147\n", "authors": ["499"]}
{"title": "A case for dynamic frequency tuning in on-chip networks\n", "abstract": " Performance and power are the first order design metrics for network-on-chips (NoCs) that have become the de-facto standard in providing scalable communication backbones for multicores/CMPs. However, NoCs can be plagued by higher power consumption and degraded throughput if the network and router are not designed properly. Towards this end, this paper proposes a novel router architecture, where we tune the frequency of a router in response to network load to manage both performance and power. We propose three dynamic frequency tuning techniques, FreqBoost, FreqThrtl and FreqTune, targeted at congestion and power management in NoCs. As enablers for these techniques, we exploit Dynamic Voltage and Frequency Scaling (DVFS) and the imbalance in a generic router pipeline through time stealing. Experiments using synthetic workloads on a 8x8 wormhole-switched mesh interconnect show\u00a0\u2026", "num_citations": "135\n", "authors": ["499"]}
{"title": "Bandwidth availability of multiple-bus multiprocessors\n", "abstract": " The effect of failures on the performance of multiple-bus multiprocessors is considered. Bandwidth expressions for this architecture are derived for uniform and nonuniform memory references. Mathematical models are developed to compute the reliability and the performance-related bandwidth availability (BA). The results obtained for the multiple-bus interconnection are compared with those of a crossbar. The models are also extended to analyze the partial bus structure, where the memories are divided into groups and each group is connected to a subset of buses. The reliability and the BA of the multiple-bus and partial bus architectures are compared.", "num_citations": "133\n", "authors": ["499"]}
{"title": "A novel caching scheme for improving internet-based mobile ad hoc networks performance\n", "abstract": " Internet-based mobile ad hoc network (Imanet) is an emerging technique that combines a wired network (e.g. Internet) and a mobile ad hoc network (Manet) for developing a ubiquitous communication infrastructure. To fulfill users\u2019 demand to access various kinds of information, however, an Imanet has several limitations such as limited accessibility to the wired Internet, insufficient wireless bandwidth, and longer message latency. In this paper, we address the issues involved in information search and access in Imanets. An aggregate caching mechanism and a broadcast-based Simple Search (SS) algorithm are proposed for improving the information accessibility and reducing average communication latency in Imanets. As a part of the aggregate cache, a cache admission control policy and a cache replacement policy, called Time and Distance Sensitive (TDS) replacement, are developed to reduce the cache miss\u00a0\u2026", "num_citations": "132\n", "authors": ["499"]}
{"title": "Cooperative caching in wireless p2p networks: Design, implementation, and evaluation\n", "abstract": " Some recent studies have shown that cooperative cache can improve the system performance in wireless P2P networks such as ad hoc networks and mesh networks. However, all these studies are at a very high level, leaving many design and implementation issues unanswered. In this paper, we present our design and implementation of cooperative cache in wireless P2P networks, and propose solutions to find the best place to cache the data. We propose a novel asymmetric cooperative cache approach, where the data requests are transmitted to the cache layer on every node, but the data replies are only transmitted to the cache layer at the intermediate nodes that need to cache the data. This solution not only reduces the overhead of copying data between the user space and the kernel space, it also allows data pipelines to reduce the end-to-end delay. We also study the effects of different MAC layers, such as\u00a0\u2026", "num_citations": "130\n", "authors": ["499"]}
{"title": "Energy optimization techniques in cluster interconnects\n", "abstract": " Designing energy-efficient clusters has recently become an important concern to make these systems economically attractive for many applications. Since the links and switch buffers consume the major portion of the power budget of the cluster, the focus of this paper is to optimize the energy consumption in these two components. To minimize power in the links, we propose a novel dynamic link shutdown (DLS) technique. The DLS technique makes use of an appropriate adaptive routing algorithm to shutdown the links intelligently. We also present an optimized buffer design for reducing leakage energy. Our analysis on different networks using a complete system simulator reveals that the proposed DLS technique can provide optimized performance-energy behavior (up to 40% energy savings with less than 5% performance degradation in the best case) for the cluster interconnects.", "num_citations": "130\n", "authors": ["499"]}
{"title": "A top-down processor allocation scheme for hypercube computers\n", "abstract": " An efficient processor allocation policy is presented for hypercube computers. The allocation policy is called free list since it maintains a list of free subcubes available in the system. An incoming request of dimension k (2/sup k/nodes) is allocated by finding a free subcube of dimension k or by decomposing an available subcube of dimension greater than k. This free list policy uses a top-down allocation rule in contrast to the bottom-up approach used by the previous bit-map allocation algorithms. This allocation scheme is compared to the buddy, gray code (GC), and modified buddy allocation policies reported for the hypercubes. It is shown that the free list policy is optimal in a static environment, as are the other policies, and it also gives better subcube recognition ability compared to the previous schemes in a dynamic environment. The performance of this policy, in terms of parameters such as average delay\u00a0\u2026", "num_citations": "130\n", "authors": ["499"]}
{"title": "Architecting on-chip interconnects for stacked 3D STT-RAM caches in CMPs\n", "abstract": " Emerging memory technologies such as STT-RAM, PCRAM, and resistive RAM are being explored as potential replacements to existing on-chip caches or main memories for future multi-core architectures. This is due to the many attractive features these memory technologies posses: high density, low leakage, and non-volatility. However, the latency and energy overhead associated with the write operations of these emerging memories has become a major obstacle in their adoption. Previous works have proposed various circuit and architectural level solutions to mitigate the write overhead. In this paper, we study the integration of STT-RAM in a 3D multi-core environment and propose solutions at the on-chip network level to circumvent the write overhead problem in the cache architecture with STT-RAM technology. Our scheme is based on the observation that instead of staggering requests to a write-busy STT\u00a0\u2026", "num_citations": "119\n", "authors": ["499"]}
{"title": "Performance and power optimization through data compression in network-on-chip architectures\n", "abstract": " The trend towards integrating multiple cores on the same die has accentuated the need for larger on-chip caches. Such large caches are constructed as a multitude of smaller cache banks interconnected through a packet-based network-on-chip (NoC) communication fabric. Thus, the NoC plays a critical role in optimizing the performance and power consumption of such non-uniform cache-based multicore architectures. While almost all prior NoC studies have focused on the design of router microarchitectures for achieving this goal, in this paper, we explore the role of data compression on NoC performance and energy behavior. In this context, we examine two different configurations that explore combinations of storage and communication compression: (1) Cache compression (CC) and (2) Compression in the NIC (NC). We also address techniques to hide the decompression latency by overlapping with NoC\u00a0\u2026", "num_citations": "117\n", "authors": ["499"]}
{"title": "A hybrid SoC interconnect with dynamic TDMA-based transaction-less buses and on-chip networks\n", "abstract": " The two dominant architectural choices for implementing efficient communication fabrics for SoC's have been transaction-based buses and packet-based networks-on-chip (NoC). Both implementations have some inherent disadvantages - the former resulting from poor scalability and the transactional character of their operation, and the latter from inconsistent access times and deterioration of performance at high injection rates. In this paper, we propose a transaction-less, time-division-based bus architecture, which dynamically allocates timeslots on-the-fly - the dTDMA bus. This architecture addresses the contention issues of current bus architectures, while avoiding the multi-hop overhead of NoC's. It is compared to traditional bus architectures and NoC's and shown to outperform both for configurations with fewer than 10 PE's. In order to exploit the advantages of the dTDMA bus for smaller configurations, and the\u00a0\u2026", "num_citations": "115\n", "authors": ["499"]}
{"title": "A case for core-assisted bottleneck acceleration in GPUs: enabling flexible data compression with assist warps\n", "abstract": " Modern Graphics Processing Units (GPUs) are well provisioned to support the concurrent execution of thousands of threads. Unfortunately, different bottlenecks during execution and heterogeneous application requirements create imbalances in utilization of resources in the cores. For example, when a GPU is bottlenecked by the available off-chip memory bandwidth, its computational resources are often overwhelmingly idle, waiting for data from memory to arrive. This paper introduces the Core-Assisted Bottleneck Acceleration (CABA) framework that employs idle on-chip resources to alleviate different bottlenecks in GPU execution. CABA provides flexible mechanisms to automatically generate \"assist warps\" that execute on GPU cores to perform specific tasks that can improve GPU performance and efficiency. CABA enables the use of idle computational units and pipelines to alleviate the memory bandwidth\u00a0\u2026", "num_citations": "112\n", "authors": ["499"]}
{"title": "A fast and efficient processor allocation scheme for mesh-connected multicomputers\n", "abstract": " Efficient processor allocation is crucial for obtaining high performance in space-shared parallel computers. A good processor allocation algorithm should find available processors for incoming jobs, if they exist, with minimum overhead. In this paper, we propose such a fast and efficient processor allocation scheme for mesh-connected multicomputers. By using simple coordinate calculation and spatial subtraction, the proposed scheme reduces the search space drastically and, hence, can locate a free submesh very quickly. The algorithm is implemented efficiently using a stack and therefore is called the stack-based allocation (SBA) algorithm. Extensive simulation reveals that our scheme incurs much less allocation overhead than all of the existing allocation algorithms, while delivering competitive performance.", "num_citations": "107\n", "authors": ["499"]}
{"title": "Fault-tolerant routing in mesh networks\n", "abstract": " CiNii \u8ad6\u6587 - Fault-tolerant routing in mesh networks CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf [\u30b5\u30a4\u30cb\u30a3] \u65e5\u672c\u306e\u8ad6\u6587\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 \u65b0\u898f\u767b\u9332 \u30ed\u30b0\u30a4\u30f3 English \u691c\u7d22 \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u3059\u3079\u3066 \u672c\u6587\u3042\u308a \u9589\u3058\u308b \u30bf\u30a4\u30c8\u30eb \u8457\u8005\u540d \u8457\u8005ID \u8457\u8005\u6240\u5c5e \u520a\u884c\u7269\u540d ISSN \u5dfb\u53f7\u30da\u30fc\u30b8 \u51fa\u7248\u8005 \u53c2\u8003\u6587\u732e \u51fa\u7248\u5e74 \u5e74\u304b\u3089 \u5e74\u307e\u3067 \u691c\u7d22 \u691c\u7d22 \u691c\u7d22 CiNii\u306e\u30b5\u30fc\u30d3\u30b9\u306b\u95a2\u3059\u308b \u30a2\u30f3\u30b1\u30fc\u30c8\u3092\u5b9f\u65bd\u4e2d\u3067\u3059\uff0811/11(\u6c34)-12/23(\u6c34)\uff09 Fault-tolerant routing in mesh networks BOURA YM \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6 \u8457\u8005 BOURA YM \u53ce\u9332\u520a\u884c\u7269 International Conference on Parallel Processing International Conference on Parallel Processing, 1995 \u88ab\u5f15\u7528\u6587\u732e: 1\u4ef6\u4e2d 1-1\u4ef6\u3092 \u8868\u793a 1 A Fault-Tolerant Deadlock-Free Routing Algorithm in a Meshed Network* LEE Deogkyoo , MOON Daekeun , YUN Ilgu , KIM Hagbae IEICE transactions on information and systems 85(4), 722-726, 2002-04-01 \u53c2\u8003\u6587\u732e8\u4ef6 CiNii\u5229\u7528\u8005\u30a2\u30f3\u30b1\u30fc\u30c8 Tweet \u5404\u7a2e\u30b3\u30fc\u30c9 NII\u8ad6\u6587ID() \u306b\u2026", "num_citations": "106\n", "authors": ["499"]}
{"title": "Efficient fully adaptive wormhole routing in n-dimensional meshes\n", "abstract": " An efficient fully adaptive wormhole routing algorithm for n-dimensional meshes is developed. The routing algorithm provides full adaptivity at a cost of one additional virtual channel per physical channel irrespective of the number of dimensions of the network. The algorithm is based on dividing the network graph into two acyclic graphs that contain all of the physical channels in the system. Virtual channels are classified as either waiting or nonwaiting channels. Busy channels that a message waits for to become available are classified as waiting channels, otherwise they are classified as nonwaiting channels. Thus, a message considers nonwaiting channels first to reach its destination. If all non-waiting channels are busy, the message considers waiting channels. Messages acquire waiting channels in two phases. In each phase, waiting channels belonging to one acyclic network graph are traversed. This 2-phase\u00a0\u2026", "num_citations": "106\n", "authors": ["499"]}
{"title": "Performance evaluation and benchmarking\n", "abstract": " Computer and microprocessor architectures are advancing at an astounding pace. However, increasing demands on performance coupled with a wide variety of specialized operating environments act to slow this pace by complicating the performance evaluation process. Carefully balancing efficiency and accuracy is key to avoid slowdowns, and such a balance can be achieved with an in-depth understanding of the available evaluation methodologies. Performance Evaluation and Benchmarking outlines a variety of evaluation methods and benchmark suites, considering their strengths, weaknesses, and when each is appropriate to use.", "num_citations": "101\n", "authors": ["499"]}
{"title": "Caching and scheduling in NAD-based multimedia servers\n", "abstract": " Multimedia-on-demand (MOD) applications have grown dramatically in popularity, especially in the domains of education, business, and entertainment. Current MOD servers waste precious resources in performing store-and-forward copying. This excessive overhead increases cost and severely limits the scalability of these servers. In this paper, we propose using the network-attached disk (NAD) architecture to design highly scalable and cost-effective MOD servers. In order to ensure enhanced performance, we propose a scheme, called distributed interval caching (DIG), which utilizes the on-disk buffers for caching intervals between successive streams. We also propose another scheme, called multiobjective scheduling (MOS), which increases the degrees of resource sharing by scheduling the waiting requests for service intelligently. We then integrate the two schemes and study the overall performance benefits\u00a0\u2026", "num_citations": "98\n", "authors": ["499"]}
{"title": "CloudPD: Problem determination and diagnosis in shared dynamic clouds\n", "abstract": " In this work, we address problem determination in virtualized clouds. We show that high dynamism, resource sharing, frequent reconfiguration, high propensity to faults and automated management introduce significant new challenges towards fault diagnosis in clouds. Towards this, we propose CloudPD, a fault management framework for clouds. CloudPD leverages (i) a canonical representation of the operating environment to quantify the impact of sharing; (ii) an online learning process to tackle dynamism; (iii) a correlation-based performance models for higher detection accuracy; and (iv) an integrated end-to-end feedback loop to synergize with a cloud management ecosystem. Using a prototype implementation with cloud representative batch and transactional workloads like Hadoop, Olio and RUBiS, it is shown that CloudPD detects and diagnoses faults with low false positives (<; 16%) and high accuracy of 88\u00a0\u2026", "num_citations": "97\n", "authors": ["499"]}
{"title": "A heterogeneous multiple network-on-chip design: an application-aware approach\n", "abstract": " Current network-on-chip designs in chip-multiprocessors are agnostic to application requirements and hence are provisioned for the general case, leading to wasted energy and performance. We observe that applications can generally be classified as either network bandwidth-sensitive or latency-sensitive. We propose the use of two separate networks on chip, where one network is optimized for bandwidth and the other for latency, and the steering of applications to the appropriate network. We further observe that not all bandwidth (latency) sensitive applications are equally sensitive to network bandwidth (latency). Hence, within each network, we prioritize packets based on the relative sensitivity of the applications they belong to. We introduce two metrics, network episode height and length, as proxies to estimate bandwidth and latency sensitivity, to classify and rank applications. Our evaluations show that the\u00a0\u2026", "num_citations": "97\n", "authors": ["499"]}
{"title": "METE: meeting end-to-end QoS in multicores through system-wide resource management\n", "abstract": " Management of shared resources in emerging multicores for achieving predictable performance has received considerable attention in recent times. In general, almost all these approaches attempt to guarantee a certain level of performance QoS (weighted IPC, harmonic speedup, etc) by managing a single shared resource or at most a couple of interacting resources. A fundamental shortcoming of these approaches is the lack of coordination between these shared resources to satisfy a system level QoS. This is undesirable because providing end-to-end QoS in future multicores is essential for supporting wide-spread adoption of these architectures in virtualized servers and cloud computing systems. An initial step towards such an end-to-end QoS support in multicores is to ensure that at least the major computational and memory resources on-chip are managed efficiently in a coordinated fashion.", "num_citations": "97\n", "authors": ["499"]}
{"title": "Hybridmr: A hierarchical mapreduce scheduler for hybrid data centers\n", "abstract": " Virtualized environments are attractive because they simplify cluster management, while facilitating cost-effective workload consolidation. As a result, virtual machines in public clouds or private data centers, have become the norm for running transactional applications like web services and virtual desktops. On the other hand, batch workloads like MapReduce, are typically deployed in a native cluster to avoid the performance overheads of virtualization. While both these virtual and native environments have their own strengths and weaknesses, we demonstrate in this work that it is feasible to provide the best of these two computing paradigms in a hybrid platform. In this paper, we make a case for a hybrid data center consisting of native and virtual environments, and propose a 2-phase hierarchical scheduler, called HybridMR, for the effective resource management of interactive and batch workloads. In the first\u00a0\u2026", "num_citations": "90\n", "authors": ["499"]}
{"title": "Exploiting inter-warp heterogeneity to improve gpgpu performance\n", "abstract": " In a GPU, all threads within a warp execute the same instruction in lockstep. For a memory instruction, this can lead to memory divergence: the memory requests for some threads are serviced early, while the remaining requests incur long latencies. This divergence stalls the warp, as it cannot execute the next instruction until all requests from the current instruction complete. In this work, we make three new observations. First, GPGPU warps exhibit heterogeneous memory divergence behavior at the shared cache: some warps have most of their requests hit in the cache (high cache utility), while other warps see most of their request miss (low cache utility). Second, a warp retains the same divergence behavior for long periods of execution. Third, due to high memory level parallelism, requests going to the shared cache can incur queuing delays as large as hundreds of cycles, exacerbating the effects of memory\u00a0\u2026", "num_citations": "83\n", "authors": ["499"]}
{"title": "Anatomy of gpu memory system for multi-application execution\n", "abstract": " As GPUs make headway in the computing landscape spanning mobile platforms, supercomputers, cloud and virtual desktop platforms, supporting concurrent execution of multiple applications in GPUs becomes essential for unlocking their full potential. However, unlike CPUs, multi-application execution in GPUs is little explored. In this paper, we study the memory system of GPUs in a concurrently executing multi-application environment. We first present an analytical performance model for many-threaded architectures and show that the common use of misses-per-kilo-instruction (MPKI) as a proxy for performance is not accurate without considering the bandwidth usage of applications. We characterize the memory interference of applications and discuss the limitations of existing memory schedulers in mitigating this interference. We extend the analytical model to multiple applications and identify the key metrics to\u00a0\u2026", "num_citations": "81\n", "authors": ["499"]}
{"title": "CPM in CMPs: Coordinated power management in chip-multiprocessors\n", "abstract": " Multiple clock domain architectures have recently been proposed to alleviate the power problem in CMPs by having different frequency/voltage values assigned to each domain based on workload requirements. However, accurate allocation of power to these voltage/frequency islands based on time varying workload characteristics as well as controlling the power consumption at the provisioned power level is quite non-trivial. Toward this end, we propose a two-tier feedback-based control theoretic solution. Our first-tier consists of a global power manager that allocates power targets to individual islands based on the workload dynamics. The power consumptions of these islands are in turn controlled by a second-tier, consisting of local controllers that regulate island power using dynamic voltage and frequency scaling in response to workload requirements.", "num_citations": "81\n", "authors": ["499"]}
{"title": "RandomCast: An energy-efficient communication scheme for mobile ad hoc networks\n", "abstract": " In mobile ad hoc networks (MANETs), every node overhears every data transmission occurring in its vicinity and thus, consumes energy unnecessarily. However, since some MANET routing protocols such as dynamic source routing (DSR) collect route information via overhearing, they would suffer if they are used in combination with 802.11 PSM. Allowing no overhearing may critically deteriorate the performance of the underlying routing protocol, while unconditional overhearing may offset the advantage of using PSM. This paper proposes a new communication mechanism, called RandomCast, via which a sender can specify the desired level of overhearing, making a prudent balance between energy and routing performance. In addition, it reduces redundant rebroadcasts for a broadcast packet, and thus, saves more energy. Extensive simulation using NS-2 shows that RandomCast is highly energy-efficient\u00a0\u2026", "num_citations": "81\n", "authors": ["499"]}
{"title": "A novel caching scheme for internet based mobile ad hoc networks\n", "abstract": " Internet based mobile ad hoc network (IMANET) is an emerging technique that combines a wired network (e.g. Internet) and a mobile ad hoc network (manet) for developing a ubiquitous communication infrastructure. However, imanet has several limitations to fulfill users' demands to access various kinds of information such as limited accessibility to the wired Internet, insufficient wireless bandwidth, and longer message latency. In this paper, we address the issues involved in information search and access in IMANET. A broadcast based simple search (SS) algorithm and an aggregate caching mechanism are proposed for improving the information accessibility and reducing average communication latency in imanet. As part of the aggregate cache, a cache admission control policy and a cache replacement policy, called time and distance sensitive (TDS) replacement, are developed to reduce the cache miss ratio\u00a0\u2026", "num_citations": "79\n", "authors": ["499"]}
{"title": "Clustered mobility model for scale-free wireless networks\n", "abstract": " Recently, researchers have discovered that many of social, natural and biological networks are characterized by scale-free power-law connectivity distribution and a few densely populated nodes, known as hubs. We envision that wireless communication or sensor networks are directly deployed over such real-world networks to facilitate communication among participating entities. Here nodes move in such a way that they exhibit scale-free connectivity distribution at any instance, which cannot be modeled by most of the prior mobility models such as random waypoint (RWP) mobility model. This paper proposes clustered mobility model (CMM), which facilitates in forming hubs in a network satisfying the scale-free property. We call this a scale-free wireless network (SFWN). In CMM, it is possible to control the degree of node concentration or non-homogeneity to easily assess the strengths and weaknesses of the\u00a0\u2026", "num_citations": "77\n", "authors": ["499"]}
{"title": "Towards a communication characterization methodology for parallel applications\n", "abstract": " The interconnection network (ICN) is a vital component of a parallel machine and is often the limiting factor in the performance of several parallel applications. While ICN performance evaluation has been a widely researched topic, there have been very few studies that have used real applications to drive this research. In this paper we develop a framework for characterizing the communication properties of parallel applications. Message generation frequency, spatial distribution of messages and message length are the three attributes that quantify any communication. We develop a methodology to quantify these attributes, in particular the first two attributes. We employ two strategies, namely dynamic and static, in our methodology. In the former, the applications are executed on an execution-driven simulator called SPASM, while in the latter they are executed on a parallel machine, IBM SP2. We gather\u00a0\u2026", "num_citations": "75\n", "authors": ["499"]}
{"title": "Application-aware memory system for fair and efficient execution of concurrent gpgpu applications\n", "abstract": " The available computing resources in modern GPUs are growing with each new generation. However, as many general purpose applications with limited thread-scalability are tuned to take advantage of GPUs, available compute resources might not be optimally utilized. To address this, modern GPUs will need to execute multiple kernels simultaneously. As current generations of GPUs (eg, NVIDIA Kepler, AMD Radeon) already enable concurrent execution of kernels from the same application, in this paper we address the next logical step: executing multiple concurrent applications in GPUs. We show that while this paradigm has a potential to improve the overall system performance, negative interactions among concurrently executing applications in the memory system can severely hamper the performance and fairness among applications. We show that the current application agnostic GPU memory system\u00a0\u2026", "num_citations": "71\n", "authors": ["499"]}
{"title": "On the effects of process variation in network-on-chip architectures\n", "abstract": " The advent of diminutive technology feature sizes has led to escalating transistor densities. Burgeoning transistor counts are casting a dark shadow on modern chip design: global interconnect delays are dominating gate delays and affecting overall system performance. Networks-on-Chip (NoC) are viewed as a viable solution to this problem because of their scalability and optimized electrical properties. However, on-chip routers are susceptible to another artifact of deep submicron technology, Process Variation (PV). PV is a consequence of manufacturing imperfections, which may lead to degraded performance and even erroneous behavior. In this work, we present the first comprehensive evaluation of NoC susceptibility to PV effects, and we propose an array of architectural improvements in the form of a new router design-called SturdiSwitch-to increase resiliency to these effects. Through extensive reengineering\u00a0\u2026", "num_citations": "69\n", "authors": ["499"]}
{"title": "Performance analysis of communications & radar coexistence in a covert UWB OSA system\n", "abstract": " Far-field target detection, multi-sensor communications, and security are essential requirements of first-emergency networks. A radar-communications system is a potential opportunistic spectrum access (OSA) solution, harnessing the coexisting advantages of radio detection and ranging (RADAR), and wireless communications. A multi-functional waveform has been designed, by embedding an Orthogonal Frequency Division Multiplexing (OFDM) signal within a spectrally notched ultra-wideband (UWB) random noise waveform. Extending that development, this paper analyzes the waveform's Bit-Error-Rate (BER) and Ambiguity Function (AF) formulations to demonstrate its OSA ability, that offers reliable multi-user communications, and high range and Doppler resolution in target detection. We further conclude that up to 30% of the available UWB bandwidth can be simultaneously utilized for concealed data\u00a0\u2026", "num_citations": "66\n", "authors": ["499"]}
{"title": "A closer look at coscheduling approaches for a network of workstations\n", "abstract": " Efficient scheduling of processes on processors of a Network of Workstations (NOW) is essential for good system performance. However, the design of such schedulers is challenging because of the complex interaction between several system and workload parameters. Coscheduling, though desirable, is impractical for such a loosely coupled environment. 71vo operations, waiting for a message and arrival of a message, can be used to take remedial actions that can guide the behavior of the system towards coscheduling using local information. We present a taxonomy of three possibilities for each of these two operations, leading to a design space of 3 x 3 scheduling mechanisms. This paper presents an extensive implementation and evaluation exercise in studying these mechanisms. Adhering to the philosophy that scheduling and communication are intertwined and should be studied in conjunction, a complete\u00a0\u2026", "num_citations": "66\n", "authors": ["499"]}
{"title": "Network-on-chip architectures: A holistic design exploration\n", "abstract": " [2]. The Cell Processor from Sony, Toshiba and IBM (STI)[3], and the Sun UltraSPARC T1 (formerly codenamed Niagara)[4] signal the growing popularity of such systems. Furthermore, Intel\u2019s very recently announced 80-core TeraFLOP chip [5] exemplifies the irreversible march toward many-core systems with tens or even hundreds of processing elements. 1.2 The Dawn of the Communication-Centric Revolution The multi-core thrust has ushered the gradual displacement of the computati-centric design model by a more communication-centric approach [6]. The large, sophisticated monolithic modules are giving way to several smaller, simpler p-cessing elements working in tandem. This trend has led to a surge in the popularity of multi-core systems, which typically manifest themselves in two distinct incarnations: heterogeneous Multi-Processor Systems-on-Chip (MPSoC) and homogeneous Chip Multi-Processors (CMP). The SoC philosophy revolves around the technique of Platform-Based Design (PBD)[7], which advocates the reuse of Intellectual Property (IP) cores in flexible design templates that can be customized accordingly to satisfy the demands of particular implementations. The appeal of such a modular approach lies in the substantially reduced Time-To-Market (TTM) incubation period, which is a direct outcome of lower circuit complexity and reduced design effort. The whole system can now be viewed as a diverse collection of pre-existing IP components integrated on a single die.", "num_citations": "63\n", "authors": ["499"]}
{"title": "Mrorchestrator: A fine-grained resource orchestration framework for mapreduce clusters\n", "abstract": " Efficient resource management in data centers and clouds running large distributed data processing frameworks like MapReduce is crucial for enhancing the performance of hosted applications and increasing resource utilization. However, existing resource scheduling schemes in Hadoop MapReduce allocate resources at the granularity of fixed-size, static portions of nodes, called slots. In this work, we show that MapReduce jobs have widely varying demands for multiple resources, making the static and fixed-size slot-level resource allocation a poor choice both from the performance and resource utilization standpoints. Furthermore, lack of coordination in the management of multiple resources across nodes prevents dynamic slot reconfiguration, and leads to resource contention. Motivated by this, we propose MROrchestrator, a MapReduce resource Orchestrator framework, which can dynamically identify\u00a0\u2026", "num_citations": "62\n", "authors": ["499"]}
{"title": "Performance comparison of cache invalidation strategies for Internet-based mobile ad hoc networks\n", "abstract": " Internet-based mobile ad hoc network (IMANET) combines a mobile ad hoc network (MANET) and the Internet to provide universal information accessibility. Although caching frequently accessed data items in mobile terminals (MTs) improves the communication performance in an IMANET, it brings a critical design issue when data items are updated. We analyze several push and pull-based cache invalidation strategies for IMANETS. A global positioning system (GPS) based connectivity estimation (GPSCE) scheme is first proposed to assess the connectivity of an MT for supporting any cache invalidation mechanism. Then, we propose a pull-based approach, called aggregate cache based on demand (ACOD) scheme, to find the queried data items efficiently. In addition, we modify two push-based cache invalidation strategies, proposed for cellular networks, to work in IMANETs. These are a modified timestamp\u00a0\u2026", "num_citations": "62\n", "authors": ["499"]}
{"title": "Design of a dynamic priority-based fast path architecture for on-chip interconnects\n", "abstract": " In modern multi-core system-on-chip (SoC) architectures, the design of innovative interconnection fabrics is indispensable. The concept of the network-on-chip (NoC) architecture has been proposed recently to better suit this requirement. Especially, the router architecture has a significant effect on the overall performance and energy consumption of the chip. We propose a dynamic path management scheme that exploits network traffic information during switch arbitration. Consequently, flits transferred across frequently used paths are expedited by traversing a reduced router pipeline. This technique, based on pipeline bypassing, is simulated and evaluated in terms of network latency and average power consumption. Simulation results with real-world application traces show that the architecture improves the performance up to 30% while incurring only minimal area/power overhead.", "num_citations": "61\n", "authors": ["499"]}
{"title": "D-factor: a quantitative model of application slow-down in multi-resource shared systems\n", "abstract": " Scheduling multiple jobs onto a platform enhances system utilization by sharing resources. The benefits from higher resource utilization include reduced cost to construct, operate, and maintain a system, which often include energy consumption. Maximizing these benefits, while satisfying performance limits, comes at a price -- resource contention among jobs increases job completion time. In this paper, we analyze slow-downs of jobs due to contention for multiple resources in a system; referred to as dilation factor. We observe that multiple-resource contention creates non-linear dilation factors of jobs. From this observation, we establish a general quantitative model for dilation factors of jobs in multi-resource systems. A job is characterized by a vector-valued loading statistics and dilation factors of a job set are given by a quadratic function of their loading vectors. We demonstrate how to systematically characterize a\u00a0\u2026", "num_citations": "60\n", "authors": ["499"]}
{"title": "A control theoretic approach for designing adaptive AQM schemes\n", "abstract": " In this paper, we use a control theoretic approach to develop a generic framework for analyzing various active queue management (AQM) schemes as proportional-integral-derivative (PID) controllers. Based on this PID model, we propose an adaptive control mechanism to improve the system stability and performance under changing network conditions. We then present a generic implementation of the PID controller by introducing a derivative control into a PI controller. In addition, we propose an improved adaptive virtual queue (AVQ) scheme with explicit queue length control. A simulation study under a wide range of traffic conditions suggests that the proposed algorithms outperform the existing AQM schemes in achieving better system performance and stability.", "num_citations": "59\n", "authors": ["499"]}
{"title": "Performance analysis of buffering schemes in wormhole routers\n", "abstract": " Wormhole switched input-buffered and middle-buffered routers with virtual channels are analyzed in this paper. Middle buffering refers to the placement of virtual channels between the demultiplexers and multiplexers of a crossbar switch. An analytical model for multistage interconnection networks using middle-buffered switches is developed. In addition, extensive simulation is conducted to assess the performance of the two buffering techniques in different network topologies. The study demonstrates that middle buffering with virtual channels provides better performance than input buffering with virtual channels in multistage interconnection networks, two-dimensional meshes, and hypercubes.", "num_citations": "59\n", "authors": ["499"]}
{"title": "Reliability evaluation of hypercube multicomputers\n", "abstract": " An analytic model for the reliability evaluation of hypercube multicomputers is presented. The model is based on the decomposition principle, where a hypercube of a higher dimension is recursively decomposed into smaller hypercubes, until the reliability of the smallest cube is modeled exactly. The reliability of the large n-cube is then obtained from this smallest base model using a recursive equation. The reliability model used is task-based, i.e., it is assumed that the system is operational if a task can be executed on the system. Analytic results are given for n-dimensional hypercubes with up to 75% system degradation. The model is validated by comparison of analytic results with simulation results.< >", "num_citations": "59\n", "authors": ["499"]}
{"title": "Processor allocation scheme for hypercube computers\n", "abstract": " A processor allocation policy for hypercube computers is presented. The allocation policy is called free list since it maintains a list of free subcubes available in the system. An incoming request of dimension k (2 k nodes) is allocated by finding a free subcube of dimension k. The free list policy is different from other hypercube allocation schemes in that it uses a top-down allocation rule in contrast to the bottom-up approach used by all other allocations. This new policy is compared with the buddy, the gray code, and the modified buddy allocation policies reported for the hypercubes. It is shown that the free list policy is statically optimal, as are the other policies, but it gives better subcube recognition ability compared to the previous schemes in a dynamic environment. The performance of this policy, in terms of parameters such as the time complexity, average delay, and system utilization, is compared with those of the other schemes, demonstrating its effectiveness.", "num_citations": "55\n", "authors": ["499"]}
{"title": "Controlled kernel launch for dynamic parallelism in GPUs\n", "abstract": " Dynamic parallelism (DP) is a promising feature for GPUs, which allows on-demand spawning of kernels on the GPU without any CPU intervention. However, this feature has two major drawbacks. First, the launching of GPU kernels can incur significant performance penalties. Second, dynamically-generated kernels are not always able to efficiently utilize the GPU cores due to hardware-limits. To address these two concerns cohesively, we propose SPAWN, a runtime framework that controls the dynamically-generated kernels, thereby directly reducing the associated launch overheads and queuing latency. Moreover, it allows a better mix of dynamically-generated and original (parent) kernels for the scheduler to effectively hide the remaining overheads and improve the utilization of the GPU resources. Our results show that, across 13 benchmarks, SPAWN achieves 69% and 57% speedup over the flat (non-DP\u00a0\u2026", "num_citations": "52\n", "authors": ["499"]}
{"title": "Addressing end-to-end memory access latency in noc-based multicores\n", "abstract": " To achieve high performance in emerging multicores, it is crucial to reduce the number of memory accesses that suffer from very high latencies. However, this should be done with care as improving latency of an access can worsen the latency of another as a result of resource sharing. Therefore, the goal should be to balance latencies of memory accesses issued by an application in an execution phase, while ensuring a low average latency value. Targeting Network-on-Chip (NoC) based multicores, we propose two network prioritization schemes that can cooperatively improve performance by reducing end-to-end memory access latencies. Our first scheme prioritizes memory response messages such that, in a given period of time, messages of an application that experience higher latencies than the average message latency for that application are expedited and a more uniform memory latency pattern is achieved\u00a0\u2026", "num_citations": "52\n", "authors": ["499"]}
{"title": "Exploiting core criticality for enhanced GPU performance\n", "abstract": " Modern memory access schedulers employed in GPUs typically optimize for memory throughput. They implicitly assume that all requests from different cores are equally important. However, we show that during the execution of a subset of CUDA applications, different cores can have different amounts of tolerance to latency. In particular, cores with a larger fraction of warps waiting for data to come back from DRAM are less likely to tolerate the latency of an outstanding memory request. Requests from such cores are more critical than requests from others. Based on this observation, this paper introduces a new memory scheduler, called (C) ritica (L) ity (A) ware (M) emory (S) cheduler (CLAMS), which takes into account the latency-tolerance of the cores that generate memory requests. The key idea is to use the fraction of critical requests in the memory request buffer to switch between scheduling policies optimized for\u00a0\u2026", "num_citations": "50\n", "authors": ["499"]}
{"title": "QoS provisioning in clusters: an investigation of router and NIC design\n", "abstract": " Design of high performance cluster networks (routers) with Quality-of-Service (QoS) guarantees is becoming increasingly important to support a variety of multimedia applications, many of which have real-time constraints. Most commercial routers, which are based on the wormhole-switching paradigm, can deliver high performance, but lack QoS provisioning. In this paper we present a pipelined wormhole router architecture that can provide high and predictable performance for integrated traffic in clusters. We consider two different implementations-a non-preemptive model and a more aggressive preemptive model. We also present the design of a network interface card (NIC) based on the Virtual Interface Architecture (VIA) design paradigm to support QoS in the NIC. The QoS capable router and NIC designs are evaluated with a mixed workload consisting of best-effort traffic, multimedia streams, and control traffic\u00a0\u2026", "num_citations": "50\n", "authors": ["499"]}
{"title": "Power-aware prefetch in mobile environments\n", "abstract": " Most of the prefetch techniques used in the current cache management schemes do not consider the power constraints of the mobile clients and other factors such as the size of the data items, the data access rate, and the data update rate. We address these issues by proposing a power-aware prefetch scheme, called the value-based adaptive prefetch (VAP) scheme. The VAP scheme defines a value function which can optimize the prefetch cost to achieve better performance. Also, VAP dynamically adjusts the number of prefetches based on the current energy level to prolong the system running time. As stretch is widely adopted as a performance metric for variable-size data requests, we show by analysis that the proposed algorithm can indeed achieve the optimal performance in terms of stretch when power consumption is considered. Simulation results demonstrate that our algorithm significantly outperforms\u00a0\u2026", "num_citations": "48\n", "authors": ["499"]}
{"title": "Exploiting intra-request slack to improve SSD performance\n", "abstract": " With Solid State Disks (SSDs) offering high degrees of parallelism, SSD controllers place data and direct requests to exploit the maximum offered hardware parallelism. In the quest to maximize parallelism and utilization, sub-requests of a request that are directed to different flash chips by the scheduler can experience differential wait times since their individual queues are not coordinated and load balanced at all times. Since the macro request is considered complete only when its last sub-request completes, some of its sub-requests that complete earlier have to necessarily wait for this last sub-request. This paper opens the door to a new class of schedulers to leverage such slack between sub-requests in order to improve response times. Specifically, the paper presents the design and implementation of a slack-enabled re-ordering scheduler, called Slacker, for sub-requests issued to each flash chip. Layered\u00a0\u2026", "num_citations": "47\n", "authors": ["499"]}
{"title": "Migration, assignment, and scheduling of jobs in virtualized environment\n", "abstract": " Migration is an interesting issue for managing resource utilization and performance in clusters. Recent advances in server virtualization have made migration a practical method to achieve these goals. Especially, the live migration of virtualized servers made their pausing times negligible. However, migration of a virtual machine (VM) can slow down other collocated VMs in multiresource shared systems, where all the system resources are shared among collocated VMs. In parallel execution environment, such sudden slow-down phase of systems is called system noise; it may slow down overall systems while increasing the variability of system performance. When we consider the virtual machine assignment problem as resource allocation, those performance issues are hard to be properly treated. In this work, we address how to consider performance in assigning VMs. To achieve this goal, we model a migration process of a VM instance as a pair of jobs that run at the hosts of sender and receiver. We propose a method to analyze the migration time and the performance impact on multiresource shared systems for completing given VM assignment plan. This study may contribute to create more robust performance in virtualized environment.", "num_citations": "47\n", "authors": ["499"]}
{"title": "Impact of virtual channels and adaptive routing on application performance\n", "abstract": " Research on multiprocessor interconnection networks has primarily focused on wormhole switching, virtual channel flow control, and routing algorithms to enhance their performance. The rationale behind this research is that by alleviating the network latency for high network loads, the overall system performance would improve; many studies have used synthetic workloads to support this claim. However, such workloads may not necessarily capture the behavior of real applications. In this paper, we have used parallel applications for a closer examination of the network behavior. In particular, the performance benefit from enhancing a 2D mesh with virtual channels (VCs) and a fully adaptive routing algorithm is examined with a set of shared-memory and message passing applications. Execution time and average message latency of shared memory applications are measured using execution-driven simulation and\u00a0\u2026", "num_citations": "47\n", "authors": ["499"]}
{"title": "A class of partially adaptive routing algorithms for n_dimensional meshes\n", "abstract": " A simple model, called the direction restriction model, for developing partially adaptive routing algorithms for n_dimensional meshes is introduced in this paper. This model is based on dividing a system into two unidirectional networks that contain all physical channels of the system.", "num_citations": "47\n", "authors": ["499"]}
{"title": "Phoenix: A constraint-aware scheduler for heterogeneous datacenters\n", "abstract": " Today's datacenters are increasingly becoming diverse with respect to both hardware and software architectures in order to support a myriad of applications. These applications are also heterogeneous in terms of job response times and resource requirements (eg., Number of Cores, GPUs, Network Speed) and they are expressed as task constraints. Constraints are used for ensuring task performance guarantees/Quality of Service(QoS) by enabling the application to express its specific resource requirements. While several schedulers have recently been proposed that aim to improve overall application and system performance, few of these schedulers consider resource constraints across tasks while making the scheduling decisions. Furthermore, latencycritical workloads and short-lived jobs that typically constitute about 90% of the total jobs in a datacenter have strict QoS requirements, which can be ensured by\u00a0\u2026", "num_citations": "46\n", "authors": ["499"]}
{"title": "OSCAR: Orchestrating STT-RAM cache traffic for heterogeneous CPU-GPU architectures\n", "abstract": " As we integrate data-parallel GPUs with general-purpose CPUs on a single chip, the enormous cache traffic generated by GPUs will not only exhaust the limited cache capacity, but also severely interfere with CPU requests. Such heterogeneous multicores pose significant challenges to the design of shared last-level cache (LLC). This problem can be mitigated by replacing SRAM LLC with emerging non-volatile memories like Spin-Transfer Torque RAM (STT-RAM), which provides larger cache capacity and near-zero leakage power. However, without careful design, the slow write operations of STT-RAM may offset the capacity benefit, and the system may still suffer from contention in the shared LLC and on-chip interconnects. While there are cache optimization techniques to alleviate such problems, we reveal that the true potential of STT-RAM LLC may still be limited because now that the cache hit rate has been\u00a0\u2026", "num_citations": "46\n", "authors": ["499"]}
{"title": "\u03bcC-States: Fine-grained GPU datapath power management\n", "abstract": " To improve the performance of Graphics Processing Units (GPUs) beyond simply increasing core count, architects are recently adopting a scale-up approach: the peak throughput and individual capabilities of the GPU cores are increasing rapidly. This big-core trend in GPUs leads to various challenges, including higher static power consumption and lower and imbalanced utilization of the datapath components of a big core. As we show in this paper, two key problems ensue: (1) the lower and imbalanced datapath utilization can waste power as an application does not always utilize all portions of the big core datapath, and (2) the use of big cores can lead to application performance degradation in some cases due to the higher memory system contention caused by the more memory requests generated by each big core. This paper introduces a new analysis of datapath component utilization in big-core GPUs based\u00a0\u2026", "num_citations": "46\n", "authors": ["499"]}
{"title": "PEPON: performance-aware hierarchical power budgeting for NoC based multicores\n", "abstract": " Targeting NoC based multicores, we propose a two-level power budget distribution mechanism, called PEPON, where the first level distributes the overall power budget of the multicore system among various types of on-chip resources like the cores, caches, and NoC, and the second level determines the allocation of power to individual instances of each type of resource. Both these distributions are oriented towards maximizing workload performance without exceeding the specified power budget. Extensive experimental evaluations of the proposed power distribution scheme using a full system simulation and detailed power models emphasize the importance of power budget partitioning at both levels. Specifically, our results show that the proposed scheme can provide up to 29% performance improvement as compared to no power budgeting, and performs 13% better than a competing scheme, under the same\u00a0\u2026", "num_citations": "46\n", "authors": ["499"]}
{"title": "An adaptive power-conserving service discipline for bluetooth\n", "abstract": " Bluetooth is a new short-range radio technology to form a small wireless system. In most of the current Bluetooth products, the master polls the slaves in a round robin manner and it may waste a significant amount of power. We propose an adaptive power conserving scheme to address this problem. The proposed solution schedules each flow based on its predictive rate and achieves power optimization based on a low-power mode existing in Bluetooth standard. Unlike other research work related to low-power, we also consider QoS of each flow. Theoretical analyses verify that our scheme can achieve throughput guarantees, delay guarantees, and fairness guarantees. Simulation results demonstrate that our scheme can save a significant amount of power compared to the round robin scheme and it shows that there exists a tradeoff between power and delay under various traffic models.", "num_citations": "45\n", "authors": ["499"]}
{"title": "Boosting access parallelism to PCM-based main memory\n", "abstract": " Despite its promise as a DRAM main memory replacement, Phase Change Memory (PCM) has high write latencies which can be a serious detriment to its widespread adoption. Apart from slowing down a write request, the consequent high latency can also keep other chips of the same rank, that are not involved in this write, idle for long times. There are several practical considerations that make it difficult to allow subsequent reads and/or writes to be served concurrently from the same chips during the long latency write. This paper proposes and evaluates several novel mechanisms - re-constructing data from error correction bits instead of waiting for chips currently busy to serve a read, rotating word mappings across chips of a PCM rank, and rotating the mapping of error detection/correction bits across these chips - to overlap several reads with an ongoing write (RoW) and even a write with an ongoing write (WoW\u00a0\u2026", "num_citations": "44\n", "authors": ["499"]}
{"title": "GemDroid: A framework to evaluate mobile platforms\n", "abstract": " As the demand for feature-rich mobile systems such as smartphones and tablets has outpaced other computing systems and is expected to continue at a faster rate, it is projected that SoCs with tens of cores and hundreds of IPs (or accelerator) will be designed to provide unprecedented level of features and functionality in future. Design of such mobile systems with required QoS and power budgets along with other design constraints will be a daunting task for computer architects since any ad hoc, piece-meal solution is unlikely to result in an optimal design. This requires early exploration of the complete design space to understand the system-level design trade-offs. To the best of our knowledge, there is no such publicly available tool to conduct a holistic evaluation of mobile platforms consisting of cores, IPs and system software. This paper presents GemDroid, a comprehensive simulation infrastructure to address\u00a0\u2026", "num_citations": "44\n", "authors": ["499"]}
{"title": "Botnet detection through fine flow classification\n", "abstract": " The prevalence of botnets, which is defined as a group of infected machines, have become the predominant factor among all the internet malicious attacks such as DDoS, Spam, and Click fraud. The number of botnets is steadily increasing, and the characteristic C&C channels have evolved from IRC to HTTP, FTP, and DNS, etc., and from the centralized structure to P2P and Fast Flux Network Services. In counter to the escalations of the botnet developments, the internet security community have designed many botnet detection and disruption systems which can be summarized into two categories: Honeynet-based and Passive Traffic Monitoring, while the Passive Traffic Monitoring could be further divided into Behavior-based, DNS-based, and Mining-based techniques. Among all the Intrusion Detection System designs, the mining-based method, operated on the flow level internet traffic, has shown some promising resilience against the botnets evolutions. A preliminary experiment has been conducted in this paper observing the discriminating capabilities of the Hierarchical and K mean clustering algorithms and exploring a RTT adjustment procedure to mix the botnet trace with the background internet traffic.", "num_citations": "44\n", "authors": ["499"]}
{"title": "Proxy-RED: an AQM scheme for wireless local area networks\n", "abstract": " Wireless access points act as bridges between wired and wireless networks. Since the actually available bandwidth in wireless networks is much smaller than the bandwidth in wired networks, there is a disparity in channel capacity which makes the access point a significant network congestion point in the downstream direction. A current architectural trend in wireless local area networks (WLAN) is to move functionality from access points to a centralized gateway in order to reduce cost and improve features. In this paper, we study the use of RED, a well known active queue management (AQM) scheme, and explicit congestion notification (ECN) to handle bandwidth disparity between the wired and the wireless interface of an access point Then, we propose the proxy-RED scheme, as a solution for reducing the AQM overhead from the access point. Simulations-based performance analysis indicates that the proposed\u00a0\u2026", "num_citations": "44\n", "authors": ["499"]}
{"title": "Alternatives to coscheduling a network of workstations\n", "abstract": " Efficient scheduling of processes on processors of a Network of Workstations (NOW) is essential for good system performance. However, the design of such schedulers is challenging because of the complex interaction between several system and workload parameters. Coscheduling, though desirable, is impractical for such a loosely coupled environment. Two operations, waiting for a message and arrival of a message, can be used to take remedial actions that can guide the behavior of the system toward coscheduling using local information. We present a taxonomy of three possibilities for each of these two operations, leading to a design space of 3\u00d73 scheduling mechanisms. This paper presents an extensive implementation and evaluation exercise in studying these mechanisms. Adhering to the philosophy that scheduling and communication are intertwined and should be studied in conjunction, a complete\u00a0\u2026", "num_citations": "44\n", "authors": ["499"]}
{"title": "Cache invalidation strategies for internet-based mobile ad hoc networks\n", "abstract": " Internet-based mobile ad hoc network (Imanet) is an emerging technique that combines a mobile ad hoc network (Manet) and the Internet to provide universal information accessibility. Although caching frequently accessed data items in mobile terminals (MTs) improves the communication performance in an Imanet, it brings a critical design issue when data updates. In this paper, we analyze several push and pull-based cache invalidation strategies for Imanets. A global positioning system (GPS) based connectivity estimation (GPSCE) scheme is first proposed to assess the connectivity of an MT for supporting cache invalidation mechanisms. Then, we propose a pull-based approach, called aggregate cache based on demand (ACOD) scheme that uses an efficient search algorithm for finding the queried data items. In addition, we modify two push-based cache invalidation strategies, proposed for cellular networks, to\u00a0\u2026", "num_citations": "42\n", "authors": ["499"]}
{"title": "Domain knowledge based energy management in handhelds\n", "abstract": " Energy management in handheld devices is becoming a daunting task with the growing number of accelerators, increasing memory demands and high computing capacities required to support applications with stringent QoS needs. Current DVFS techniques that modulate power states of a single hardware component, or even recent proposals that manage multiple components, can lose out opportunities for attaining high energy efficiencies that may be possible by leveraging application domain knowledge. Thus, this paper proposes a coordinated multi-component energy optimization mechanism for handheld devices, where the energy profile of different components such as CPU, memory, GPU and IP cores are considered in unison to trigger the appropriate DVFS state by exploiting the application domain knowledge. Specifically, we show that for the important class of frame-based applications, the domain\u00a0\u2026", "num_citations": "41\n", "authors": ["499"]}
{"title": "Meeting midway: Improving CMP performance with memory-side prefetching\n", "abstract": " Both on-chip resource contention and off-chip latencies have a significant impact on memory requests in large-scale chip multiprocessors. We propose a memory-side prefetcher, which brings data on-chip from DRAM, but does not proactively further push this data to the cores/caches. Sitting close to memory, it avails close knowledge of DRAM state and memory channels to leverage DRAM row buffer locality and channel state to bring data (from the current row buffer) on-chip ahead of need. This not only reduces the number of off-chip accesses for demand requests, but also reduces row buffer conflicts, effectively improving DRAM access times. At the same time, our prefetcher maintains this data in a small buffer at each memory controller instead of pushing it into the caches to avoid on-chip resource contention. We show that the proposed memory-side prefetcher outperforms a state-of-the-art core-side prefetcher\u00a0\u2026", "num_citations": "40\n", "authors": ["499"]}
{"title": "A unified task-based dependability model for hypercube computers\n", "abstract": " A unified analytical model for computing the task-based dependability (TDB) of hypercube architectures is presented. A hypercube is deemed operational as long as a task can be executed on the system. The technique can compute both reliability and availability for two types of task requirements\u2014I-connected model and subcube model. The I-connected TBD assumes that a connected group of at least I working nodes is required for task execution. The subcube TBD needs at least an m-cube in an n-cube, m greater than or equals n, for task execution. The dependability is computed by multiplying the probability that x nodes (math) are working in an n-cube at time t by the conditional probability that the hypercube can satisfy any one of the two task requirements from x working nodes. Recursive models are proposed for the two types of task requirements to find the connection probability. The subcube requirement is\u00a0\u2026", "num_citations": "40\n", "authors": ["499"]}
{"title": "Race-to-sleep+ content caching+ display caching: A recipe for energy-efficient video streaming on handhelds\n", "abstract": " Video streaming has become the most common application in handhelds and this trend is expected to grow in future to account for about 75% of all mobile data traffic by 2021. Thus, optimizing the performance and energy consumption of video processing in mobile devices is critical for sustaining the handheld market growth. In this paper, we propose three complementary techniques, race-to-sleep, content caching and display caching, to minimize the energy consumption of the video processing flows. Unlike the state-of-the-art frame-by-frame processing of a video decoder, the first scheme, race-to-sleep, uses two approaches, called batching of frames and frequency boosting to prolong its sleep state for saving energy, while avoiding any frame drops. The second scheme, content caching, exploits the content similarity of smaller video blocks, called macroblocks, to design a novel cache organization for reducing\u00a0\u2026", "num_citations": "39\n", "authors": ["499"]}
{"title": "LAPSES: A recipe for high performance adaptive router design\n", "abstract": " Earlier research has shown that adaptive routing can help in improving network performance. However, it has not received adequate attention in commercial routers mainly due to the additional hardware complexity, and the perceived cost and performance degradation that may result from this complexity. These concerns can be mitigated if one can design a cost-effective router that can support adaptive routing. This paper proposes a three step recipe-Look-Ahead routing, intelligent Path Selection, and an Economic Storage implementation, called the LAPSES approach-for cost-effective high performance pipelined adaptive router design. The first step, look-ahead routing, reduces a pipeline stage in the router by making table lookup and arbitration concurrent. Next, three new traffic-sensitive path selection heuristics (LRU, LFU and MAX-CREDIT) are proposed to select one of the available alternate paths. Finally\u00a0\u2026", "num_citations": "38\n", "authors": ["499"]}
{"title": "Evaluation of a parallel branch-and-bound algorithm on a class of multiprocessors\n", "abstract": " We propose and evaluate a parallel \"decomposite best-first\" search branch-and-bound algorithm (dbs) for MIN-based multiprocessor systems. We start with a new probabilistic model to estimate the number of evaluated nodes for a serial best-first search branch-and-bound algorithm. This analysis is used in predicting the parallel algorithm speed-up. The proposed algorithm initially decomposes a problem into N subproblems, where N is the number of processors available in a multiprocessor. Afterwards, each processor executes the serial best-first search to find a local feasible solution. Local solutions are broadcasted through the network to compute the final solution. A conflict-free mapping scheme, known as the step-by-step spread, is used for subproblem distribution on the MIN. A speedup expression for the parallel algorithm is then derived using the serial best-first search node evaluation model. Our analysis\u00a0\u2026", "num_citations": "38\n", "authors": ["499"]}
{"title": "Dependability modeling for multiprocessors\n", "abstract": " A tutorial on dependability and performance-related dependability models for multiprocessors is presented. Multiprocessors are classified as having shared-memory or distributed-memory architectures, and some fundamental dependability modeling concepts. Reliability models based on four types of reliability evaluation techniques (terminal, multiterminal, task-based, and network reliability) are examined. The status of research efforts on performance-related dependability is discussed, and the models' effectiveness is illustrated with a few numerical examples. A brief survey of software packages for dependability computation in included.< >", "num_citations": "38\n", "authors": ["499"]}
{"title": "ACCESS: Smart scheduling for asymmetric cache CMPs\n", "abstract": " In current Chip-multiprocessors (CMPs), a significant portion of the die is consumed by the last-level cache. Until recently, the balance of cache and core space has been primarily guided by the needs of single applications. However, as multiple applications or virtual machines (VMs) are consolidated on such a platform, researchers have observed that not all VMs or applications require significant amount of cache space. In order to take advantage of this phenomenon, we explore the use of asymmetric last-level caches in a CMP platform. While asymmetric cache CMPs provide the benefit of reduced power and area, it is important to build in hardware/software support to appropriately schedule applications on to cores with suitable cache capacity. In this paper, we address this problem with our ACCESS architecture comprising of: (a) asymmetric caches across a group of cores, (b) hardware support that enables\u00a0\u2026", "num_citations": "37\n", "authors": ["499"]}
{"title": "Coscheduling in clusters: Is it a viable alternative?\n", "abstract": " In this paper, we conduct an in-depth evaluation of a broad spectrum of scheduling alternatives for clusters. These include the widely used batch scheduling, local scheduling, gang scheduling, all prior communication-driven coscheduling algorithms (Dynamic Coscheduling (DCS), Spin Block (SB), Periodic Boost (PB), and Co-ordinated Coscheduling (CC)) and a newly proposed HYBRID coscheduling algorithm on a 16-node, Myrinet-connected Linux cluster. Performance and energy measurements using several NAS, LLNL and ANL benchmarks on the Linux cluster provide several interesting conclusions. First, although batch scheduling is currently used in most clusters, all blocking-based coscheduling techniques such as SB, CC and HYBRID and the gang scheduling can provide much better performance even in a dedicated cluster platform. Second, in contrast to some of the prior studies, we observe that\u00a0\u2026", "num_citations": "37\n", "authors": ["499"]}
{"title": "Investigating QoS support for traffic mixes with the MediaWorm router\n", "abstract": " With the increasing use of clusters in real-time applications, it has become essential to design high performance networks with quality of service (QoS) guarantees. In this paper, we explore the feasibility of providing QoS in worm-hole switched routers, which are otherwise well known for designing high performance interconnects. In particular, we are interested in supporting multimedia video streams, in addition to the conventional best-effort traffic. The proposed MediaWorm router uses a rate-based bandwidth allocation mechanism, called Virtual Clock, to schedule network resources for different traffic classes. Our simulation results on an 8-port router indicate that it is possible to provide jitter-free delivery to VBR/CBR traffic up to an input load of 70-80% of link bandwidth, and the presence of best effort traffic has no adverse effect on the real-time traffic. Although the MediaWorm router shows a slightly lower\u00a0\u2026", "num_citations": "37\n", "authors": ["499"]}
{"title": "Performance benefits of virtual channels and adaptive routing: An application-driven study\n", "abstract": " Recent research on multiprocessor interconnection networks has primarily focussed on wormhole switching, virtual channel flow control and routing algorithms. These architectural features are aimed at enhancing the network performance by reducing the network latency, which in turn should improve the overall system performance. Many research results support this design philosophy by claiming significant reduction in average message latency. However, these conclusions are drawn using synthetic workloads that may not necessarily capture the behavior of real applications. In this paper, we have used parallel applications for a closer examination of the network behavior. In particular, the performance benefit from enhancing a 2-D mesh with virtual channels (VCs) and a routing algorithm (oblivious or fully adaptive) is examined with five shared memory applications using an execution-driven simulator, SPASM.In\u00a0\u2026", "num_citations": "37\n", "authors": ["499"]}
{"title": "RAFT: A router architecture with frequency tuning for on-chip networks\n", "abstract": " With increasing number of cores being integrated on a single die, Network-on-Chips (NoCs) have become the de-facto standard in providing scalable communication backbones for these multi-core chips. NoCs have a significant impact on the system\u2019s performance, power and reliability. However, NoCs can be plagued by higher power consumption and degraded throughput if the network and router are not designed properly. Towards this end, this paper proposes a novel router architecture, where we tune the frequency of a router in response to network load to manage both performance and power. We propose three dynamic frequency tuning techniques, FreqBoost, FreqThrtl and FreqTune, targeted at congestion and power management in NoCs. We also propose and evaluate a novel fine-grained frequency tuning scheme where we vary the number of virtual-channels in a router dynamically. As a further\u00a0\u2026", "num_citations": "36\n", "authors": ["499"]}
{"title": "A dynamic energy management scheme for multi-tier data centers\n", "abstract": " Multi-tier data centers have become a norm for hosting modern Internet applications because they provide a flexible, modular, scalable and high performance environment. However, these benefits come at a price of the economic dent incurred in powering and cooling these large hosting centers. Thus, energy efficiency has become a critical consideration in designing Internet data centers. In this paper, we propose a multifaceted approach, Hybrid, consisting of dynamic provisioning, frequency scaling and dynamic power management (DPM) schemes to reduce the energy consumption of multi-tier data centers, while meeting the Service Level Agreements (SLAs). We formulate a mathematical model of the energy and performance/SLA optimization problem followed by a queueing theory based approach to develop two heuristics for solving the optimization problem. The first heuristic dynamically provisions the\u00a0\u2026", "num_citations": "36\n", "authors": ["499"]}
{"title": "A case for integrated processor-cache partitioning in chip multiprocessors\n", "abstract": " Existing cache partitioning schemes are designed in a manner oblivious to the implicit processor partitioning enforced by the operating system. This paper examines an operating system directed integrated processor-cache partitioning scheme that partitions both the available processors and the shared cache in a chip multiprocessor among different multi-threaded applications. Extensive simulations using a set of multiprogrammed workloads show that our integrated processor-cache partitioning scheme facilitates achieving better performance isolation as compared to state of the art hardware/software based solutions. Specifically, our integrated processor-cache partitioning approach performs, on an average, 20.83% and 14.14% better than equal partitioning and the implicit partitioning enforced by the underlying operating system, respectively, on the fair speedup metric on an 8 core system. We also compare our\u00a0\u2026", "num_citations": "36\n", "authors": ["499"]}
{"title": "A holistic approach to designing energy-efficient cluster interconnects\n", "abstract": " Designing energy-efficient clusters has recently become an important concern to make these systems economically attractive for many applications. Since the cluster interconnect is a major part of the system, the focus of this paper is to characterize and optimize the energy consumption in the entire interconnect. Using a cycle-accurate simulator of an InfiniBand Architecture (IBA) compliant interconnect fabric and actual designs of its components, we investigate the energy behavior on regular and irregular interconnects. The energy profile of the three major components (switches, network interface cards (NICs), and links) reveals that the links and switch buffers consume the major portion of the power budget. Hence, we focus on energy optimization of these two components. To minimize power in the links, first we investigate the dynamic voltage scaling (DVS) algorithm and then propose a novel dynamic link\u00a0\u2026", "num_citations": "36\n", "authors": ["499"]}
{"title": "A strategy to compute the InfiniBand arbitration tables\n", "abstract": " The InfiniBand Architecture (IBA) is a new industry standard architecture for server I/O and interprocessor communication. InfiniBand is very likely to become the de facto standard in a few years. It is being developed by the InfiniBand Trade Association (IBTA) to provide the levels of reliability, availability, performance, scalability, and quality of service (QoS) necessary for present and future server systems. The provision of QoS in data communication networks is currently the focus of much discussion and research in industry and academia. IBA enables QoS support with some mechanisms. In this paper, we examine these mechanisms and describe a way to use them. We propose a traffic segregation strategy based on mean bandwidth requirements. Moreover, we propose a very effective strategy to compute the virtual lane arbitration tables for IBA switches. We evaluate our proposal with different network topologies\u00a0\u2026", "num_citations": "35\n", "authors": ["499"]}
{"title": "Exploring the potentials of parallel garbage collection in ssds for enterprise storage systems\n", "abstract": " In the last decade, NAND flash-based SSDs have been widely adopted for high-end enterprise systems in an attempt to provide a high-performance and reliable storage. However, inferior performance is frequently attained mainly due to the need for Garbage Collection (GC). GC in flash memory is the process of identifying and clearing the blocks of unneeded data to create space for the new data to be allocated. GC is a high-latency operation and once it is scheduled for service to a block of a plane in a flash chip (each flash chip consists of multiple planes), it can increase latency for later arriving I/O requests to the same plane. Apart from that, the consequent high latency also keep other planes of the same chip, that are not involved in this GC, idle for a long time. We show that for the baseline SSD with modern FTL, GC considerably reduces the plane-level parallelism, causing significant performance degradation\u00a0\u2026", "num_citations": "34\n", "authors": ["499"]}